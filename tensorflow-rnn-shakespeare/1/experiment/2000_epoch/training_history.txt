TRAINING STATS: batch 0/486 in epoch 0,      batch loss: 4.43753, batch accuracy: 0.14583
Time: 2018-07-14 21:11:41
TRAINING STATS: batch 50/486 in epoch 0,     batch loss: 2.73484, batch accuracy: 0.19400
Time: 2018-07-14 21:11:46
TRAINING STATS: batch 100/486 in epoch 0,    batch loss: 2.22934, batch accuracy: 0.38183
Time: 2018-07-14 21:11:49
TRAINING STATS: batch 150/486 in epoch 0,    batch loss: 1.61967, batch accuracy: 0.56183
Time: 2018-07-14 21:11:52
TRAINING STATS: batch 200/486 in epoch 0,    batch loss: 1.10888, batch accuracy: 0.69733
Time: 2018-07-14 21:11:57
TRAINING STATS: batch 250/486 in epoch 0,    batch loss: 1.10301, batch accuracy: 0.69183
Time: 2018-07-14 21:12:00
TRAINING STATS: batch 300/486 in epoch 0,    batch loss: 0.98586, batch accuracy: 0.71583
Time: 2018-07-14 21:12:04
TRAINING STATS: batch 350/486 in epoch 0,    batch loss: 0.90753, batch accuracy: 0.74133
Time: 2018-07-14 21:12:08
TRAINING STATS: batch 400/486 in epoch 0,    batch loss: 0.77865, batch accuracy: 0.77800
Time: 2018-07-14 21:12:12
TRAINING STATS: batch 450/486 in epoch 0,    batch loss: 0.86025, batch accuracy: 0.74917
Time: 2018-07-14 21:12:15
TRAINING STATS: batch 14/486 in epoch 1,     batch loss: 0.74983, batch accuracy: 0.78533
Time: 2018-07-14 21:12:19
TRAINING STATS: batch 64/486 in epoch 1,     batch loss: 0.85435, batch accuracy: 0.75000
Time: 2018-07-14 21:12:23
TRAINING STATS: batch 114/486 in epoch 1,    batch loss: 0.77413, batch accuracy: 0.77367
Time: 2018-07-14 21:12:26
TRAINING STATS: batch 164/486 in epoch 1,    batch loss: 0.68482, batch accuracy: 0.80200
Time: 2018-07-14 21:12:31
TRAINING STATS: batch 214/486 in epoch 1,    batch loss: 0.73464, batch accuracy: 0.79417
Time: 2018-07-14 21:12:34
TRAINING STATS: batch 264/486 in epoch 1,    batch loss: 0.70405, batch accuracy: 0.79400
Time: 2018-07-14 21:12:38
TRAINING STATS: batch 314/486 in epoch 1,    batch loss: 0.74976, batch accuracy: 0.77983
Time: 2018-07-14 21:12:42
TRAINING STATS: batch 364/486 in epoch 1,    batch loss: 0.67871, batch accuracy: 0.80317
Time: 2018-07-14 21:12:46
TRAINING STATS: batch 414/486 in epoch 1,    batch loss: 0.62561, batch accuracy: 0.82133
Time: 2018-07-14 21:12:49
TRAINING STATS: batch 464/486 in epoch 1,    batch loss: 0.59778, batch accuracy: 0.82817
Time: 2018-07-14 21:12:54
TRAINING STATS: batch 28/486 in epoch 2,     batch loss: 0.58138, batch accuracy: 0.83100
Time: 2018-07-14 21:12:57
TRAINING STATS: batch 78/486 in epoch 2,     batch loss: 0.66775, batch accuracy: 0.80383
Time: 2018-07-14 21:13:01
TRAINING STATS: batch 128/486 in epoch 2,    batch loss: 0.62240, batch accuracy: 0.81883
Time: 2018-07-14 21:13:05
TRAINING STATS: batch 178/486 in epoch 2,    batch loss: 0.53298, batch accuracy: 0.84633
Time: 2018-07-14 21:13:09
TRAINING STATS: batch 228/486 in epoch 2,    batch loss: 0.53502, batch accuracy: 0.84683
Time: 2018-07-14 21:13:12
TRAINING STATS: batch 278/486 in epoch 2,    batch loss: 0.57291, batch accuracy: 0.82967
Time: 2018-07-14 21:13:17
TRAINING STATS: batch 328/486 in epoch 2,    batch loss: 0.59468, batch accuracy: 0.83083
Time: 2018-07-14 21:13:20
TRAINING STATS: batch 378/486 in epoch 2,    batch loss: 0.55552, batch accuracy: 0.84033
Time: 2018-07-14 21:13:24
TRAINING STATS: batch 428/486 in epoch 2,    batch loss: 0.60014, batch accuracy: 0.82667
Time: 2018-07-14 21:13:28
TRAINING STATS: batch 478/486 in epoch 2,    batch loss: 0.55629, batch accuracy: 0.83583
Time: 2018-07-14 21:13:32
TRAINING STATS: batch 42/486 in epoch 3,     batch loss: 0.52828, batch accuracy: 0.84983
Time: 2018-07-14 21:13:35
TRAINING STATS: batch 92/486 in epoch 3,     batch loss: 0.56910, batch accuracy: 0.83550
Time: 2018-07-14 21:13:40
TRAINING STATS: batch 142/486 in epoch 3,    batch loss: 0.50725, batch accuracy: 0.85017
Time: 2018-07-14 21:13:44
TRAINING STATS: batch 192/486 in epoch 3,    batch loss: 0.57545, batch accuracy: 0.83367
Time: 2018-07-14 21:13:47
TRAINING STATS: batch 242/486 in epoch 3,    batch loss: 0.53941, batch accuracy: 0.84133
Time: 2018-07-14 21:13:52
TRAINING STATS: batch 292/486 in epoch 3,    batch loss: 0.56591, batch accuracy: 0.83733
Time: 2018-07-14 21:13:56
TRAINING STATS: batch 342/486 in epoch 3,    batch loss: 0.54146, batch accuracy: 0.84233
Time: 2018-07-14 21:13:59
TRAINING STATS: batch 392/486 in epoch 3,    batch loss: 0.49410, batch accuracy: 0.85700
Time: 2018-07-14 21:14:04
TRAINING STATS: batch 442/486 in epoch 3,    batch loss: 0.46987, batch accuracy: 0.85850
Time: 2018-07-14 21:14:08
TRAINING STATS: batch 6/486 in epoch 4,      batch loss: 0.59053, batch accuracy: 0.82850
Time: 2018-07-14 21:14:11
TRAINING STATS: batch 56/486 in epoch 4,     batch loss: 0.52980, batch accuracy: 0.84700
Time: 2018-07-14 21:14:16
TRAINING STATS: batch 106/486 in epoch 4,    batch loss: 0.53979, batch accuracy: 0.84167
Time: 2018-07-14 21:14:20
TRAINING STATS: batch 156/486 in epoch 4,    batch loss: 0.52269, batch accuracy: 0.85150
Time: 2018-07-14 21:14:23
TRAINING STATS: batch 206/486 in epoch 4,    batch loss: 0.55205, batch accuracy: 0.83583
Time: 2018-07-14 21:14:28
TRAINING STATS: batch 256/486 in epoch 4,    batch loss: 0.49520, batch accuracy: 0.85317
Time: 2018-07-14 21:14:32
TRAINING STATS: batch 306/486 in epoch 4,    batch loss: 0.52102, batch accuracy: 0.84383
Time: 2018-07-14 21:14:35
TRAINING STATS: batch 356/486 in epoch 4,    batch loss: 0.53667, batch accuracy: 0.84717
Time: 2018-07-14 21:14:40
TRAINING STATS: batch 406/486 in epoch 4,    batch loss: 0.54462, batch accuracy: 0.83500
Time: 2018-07-14 21:14:44
TRAINING STATS: batch 456/486 in epoch 4,    batch loss: 0.45228, batch accuracy: 0.86900
Time: 2018-07-14 21:14:47
TRAINING STATS: batch 20/486 in epoch 5,     batch loss: 0.51096, batch accuracy: 0.85000
Time: 2018-07-14 21:14:52
TRAINING STATS: batch 70/486 in epoch 5,     batch loss: 0.43535, batch accuracy: 0.87267
Time: 2018-07-14 21:14:56
TRAINING STATS: batch 120/486 in epoch 5,    batch loss: 0.49265, batch accuracy: 0.85983
Time: 2018-07-14 21:14:59
TRAINING STATS: batch 170/486 in epoch 5,    batch loss: 0.46226, batch accuracy: 0.86617
Time: 2018-07-14 21:15:04
TRAINING STATS: batch 220/486 in epoch 5,    batch loss: 0.46490, batch accuracy: 0.86350
Time: 2018-07-14 21:15:08
TRAINING STATS: batch 270/486 in epoch 5,    batch loss: 0.46243, batch accuracy: 0.86367
Time: 2018-07-14 21:15:11
TRAINING STATS: batch 320/486 in epoch 5,    batch loss: 0.47074, batch accuracy: 0.86083
Time: 2018-07-14 21:15:16
TRAINING STATS: batch 370/486 in epoch 5,    batch loss: 0.48712, batch accuracy: 0.86083
Time: 2018-07-14 21:15:20
TRAINING STATS: batch 420/486 in epoch 5,    batch loss: 0.49145, batch accuracy: 0.85750
Time: 2018-07-14 21:15:24
TRAINING STATS: batch 470/486 in epoch 5,    batch loss: 0.52429, batch accuracy: 0.84583
Time: 2018-07-14 21:15:28
TRAINING STATS: batch 34/486 in epoch 6,     batch loss: 0.50372, batch accuracy: 0.84867
Time: 2018-07-14 21:15:32
TRAINING STATS: batch 84/486 in epoch 6,     batch loss: 0.47432, batch accuracy: 0.86450
Time: 2018-07-14 21:15:36
TRAINING STATS: batch 134/486 in epoch 6,    batch loss: 0.48606, batch accuracy: 0.85617
Time: 2018-07-14 21:15:40
TRAINING STATS: batch 184/486 in epoch 6,    batch loss: 0.48220, batch accuracy: 0.85800
Time: 2018-07-14 21:15:44
TRAINING STATS: batch 234/486 in epoch 6,    batch loss: 0.51754, batch accuracy: 0.85033
Time: 2018-07-14 21:15:48
TRAINING STATS: batch 284/486 in epoch 6,    batch loss: 0.47643, batch accuracy: 0.86250
Time: 2018-07-14 21:15:52
TRAINING STATS: batch 334/486 in epoch 6,    batch loss: 0.44870, batch accuracy: 0.86800
Time: 2018-07-14 21:15:56
TRAINING STATS: batch 384/486 in epoch 6,    batch loss: 0.46055, batch accuracy: 0.86783
Time: 2018-07-14 21:16:00
TRAINING STATS: batch 434/486 in epoch 6,    batch loss: 0.48453, batch accuracy: 0.85867
Time: 2018-07-14 21:16:04
TRAINING STATS: batch 484/486 in epoch 6,    batch loss: 0.46391, batch accuracy: 0.86083
Time: 2018-07-14 21:16:08
TRAINING STATS: batch 48/486 in epoch 7,     batch loss: 0.44840, batch accuracy: 0.86883
Time: 2018-07-14 21:16:12
TRAINING STATS: batch 98/486 in epoch 7,     batch loss: 0.40950, batch accuracy: 0.88100
Time: 2018-07-14 21:16:17
TRAINING STATS: batch 148/486 in epoch 7,    batch loss: 0.46321, batch accuracy: 0.86517
Time: 2018-07-14 21:16:20
TRAINING STATS: batch 198/486 in epoch 7,    batch loss: 0.48016, batch accuracy: 0.86400
Time: 2018-07-14 21:16:24
TRAINING STATS: batch 248/486 in epoch 7,    batch loss: 0.48005, batch accuracy: 0.85850
Time: 2018-07-14 21:16:29
TRAINING STATS: batch 298/486 in epoch 7,    batch loss: 0.44935, batch accuracy: 0.86850
Time: 2018-07-14 21:16:32
TRAINING STATS: batch 348/486 in epoch 7,    batch loss: 0.43508, batch accuracy: 0.87283
Time: 2018-07-14 21:16:36
TRAINING STATS: batch 398/486 in epoch 7,    batch loss: 0.45639, batch accuracy: 0.86033
Time: 2018-07-14 21:16:41
TRAINING STATS: batch 448/486 in epoch 7,    batch loss: 0.45645, batch accuracy: 0.87017
Time: 2018-07-14 21:16:44
TRAINING STATS: batch 12/486 in epoch 8,     batch loss: 0.43160, batch accuracy: 0.87567
Time: 2018-07-14 21:16:48
TRAINING STATS: batch 62/486 in epoch 8,     batch loss: 0.45926, batch accuracy: 0.86200
Time: 2018-07-14 21:16:53
TRAINING STATS: batch 112/486 in epoch 8,    batch loss: 0.42987, batch accuracy: 0.87233
Time: 2018-07-14 21:16:57
TRAINING STATS: batch 162/486 in epoch 8,    batch loss: 0.43975, batch accuracy: 0.87017
Time: 2018-07-14 21:17:00
TRAINING STATS: batch 212/486 in epoch 8,    batch loss: 0.41799, batch accuracy: 0.88017
Time: 2018-07-14 21:17:05
TRAINING STATS: batch 262/486 in epoch 8,    batch loss: 0.46378, batch accuracy: 0.86300
Time: 2018-07-14 21:17:09
TRAINING STATS: batch 312/486 in epoch 8,    batch loss: 0.39311, batch accuracy: 0.88567
Time: 2018-07-14 21:17:12
TRAINING STATS: batch 362/486 in epoch 8,    batch loss: 0.47272, batch accuracy: 0.85867
Time: 2018-07-14 21:17:17
TRAINING STATS: batch 412/486 in epoch 8,    batch loss: 0.40133, batch accuracy: 0.87983
Time: 2018-07-14 21:17:21
TRAINING STATS: batch 462/486 in epoch 8,    batch loss: 0.46362, batch accuracy: 0.86483
Time: 2018-07-14 21:17:24
TRAINING STATS: batch 26/486 in epoch 9,     batch loss: 0.48600, batch accuracy: 0.86117
Time: 2018-07-14 21:17:29
TRAINING STATS: batch 76/486 in epoch 9,     batch loss: 0.47301, batch accuracy: 0.86367
Time: 2018-07-14 21:17:33
TRAINING STATS: batch 126/486 in epoch 9,    batch loss: 0.44630, batch accuracy: 0.86633
Time: 2018-07-14 21:17:36
TRAINING STATS: batch 176/486 in epoch 9,    batch loss: 0.40805, batch accuracy: 0.88217
Time: 2018-07-14 21:17:41
TRAINING STATS: batch 226/486 in epoch 9,    batch loss: 0.42004, batch accuracy: 0.87567
Time: 2018-07-14 21:17:45
TRAINING STATS: batch 276/486 in epoch 9,    batch loss: 0.44929, batch accuracy: 0.86950
Time: 2018-07-14 21:17:49
TRAINING STATS: batch 326/486 in epoch 9,    batch loss: 0.40625, batch accuracy: 0.88067
Time: 2018-07-14 21:17:53
TRAINING STATS: batch 376/486 in epoch 9,    batch loss: 0.45014, batch accuracy: 0.86933
Time: 2018-07-14 21:17:57
TRAINING STATS: batch 426/486 in epoch 9,    batch loss: 0.40269, batch accuracy: 0.88100
Time: 2018-07-14 21:18:01
TRAINING STATS: batch 476/486 in epoch 9,    batch loss: 0.38903, batch accuracy: 0.88683
Time: 2018-07-14 21:18:06
TRAINING STATS: batch 40/486 in epoch 10,    batch loss: 0.42583, batch accuracy: 0.87417
Time: 2018-07-14 21:18:09
TRAINING STATS: batch 90/486 in epoch 10,    batch loss: 0.41310, batch accuracy: 0.87833
Time: 2018-07-14 21:18:13
TRAINING STATS: batch 140/486 in epoch 10,   batch loss: 0.38564, batch accuracy: 0.89250
Time: 2018-07-14 21:18:18
TRAINING STATS: batch 190/486 in epoch 10,   batch loss: 0.39259, batch accuracy: 0.88350
Time: 2018-07-14 21:18:21
TRAINING STATS: batch 240/486 in epoch 10,   batch loss: 0.41988, batch accuracy: 0.87850
Time: 2018-07-14 21:18:25
TRAINING STATS: batch 290/486 in epoch 10,   batch loss: 0.43383, batch accuracy: 0.87200
Time: 2018-07-14 21:18:30
TRAINING STATS: batch 340/486 in epoch 10,   batch loss: 0.43271, batch accuracy: 0.87183
Time: 2018-07-14 21:18:34
TRAINING STATS: batch 390/486 in epoch 10,   batch loss: 0.38067, batch accuracy: 0.88550
Time: 2018-07-14 21:18:37
TRAINING STATS: batch 440/486 in epoch 10,   batch loss: 0.44538, batch accuracy: 0.86317
Time: 2018-07-14 21:18:42
TRAINING STATS: batch 4/486 in epoch 11,     batch loss: 0.41685, batch accuracy: 0.87633
Time: 2018-07-14 21:18:46
TRAINING STATS: batch 54/486 in epoch 11,    batch loss: 0.44800, batch accuracy: 0.87167
Time: 2018-07-14 21:18:49
TRAINING STATS: batch 104/486 in epoch 11,   batch loss: 0.40710, batch accuracy: 0.88267
Time: 2018-07-14 21:18:54
TRAINING STATS: batch 154/486 in epoch 11,   batch loss: 0.36969, batch accuracy: 0.88833
Time: 2018-07-14 21:18:58
TRAINING STATS: batch 204/486 in epoch 11,   batch loss: 0.45291, batch accuracy: 0.86617
Time: 2018-07-14 21:19:02
TRAINING STATS: batch 254/486 in epoch 11,   batch loss: 0.39485, batch accuracy: 0.88417
Time: 2018-07-14 21:19:06
TRAINING STATS: batch 304/486 in epoch 11,   batch loss: 0.40614, batch accuracy: 0.88000
Time: 2018-07-14 21:19:10
TRAINING STATS: batch 354/486 in epoch 11,   batch loss: 0.41094, batch accuracy: 0.88033
Time: 2018-07-14 21:19:14
TRAINING STATS: batch 404/486 in epoch 11,   batch loss: 0.38271, batch accuracy: 0.88800
Time: 2018-07-14 21:19:18
TRAINING STATS: batch 454/486 in epoch 11,   batch loss: 0.35736, batch accuracy: 0.89750
Time: 2018-07-14 21:19:22
TRAINING STATS: batch 18/486 in epoch 12,    batch loss: 0.41500, batch accuracy: 0.88083
Time: 2018-07-14 21:19:26
TRAINING STATS: batch 68/486 in epoch 12,    batch loss: 0.36164, batch accuracy: 0.89183
Time: 2018-07-14 21:19:30
TRAINING STATS: batch 118/486 in epoch 12,   batch loss: 0.39800, batch accuracy: 0.88150
Time: 2018-07-14 21:19:34
TRAINING STATS: batch 168/486 in epoch 12,   batch loss: 0.36787, batch accuracy: 0.89267
Time: 2018-07-14 21:19:38
TRAINING STATS: batch 218/486 in epoch 12,   batch loss: 0.39240, batch accuracy: 0.88533
Time: 2018-07-14 21:19:43
TRAINING STATS: batch 268/486 in epoch 12,   batch loss: 0.38510, batch accuracy: 0.88633
Time: 2018-07-14 21:19:46
TRAINING STATS: batch 318/486 in epoch 12,   batch loss: 0.41221, batch accuracy: 0.87833
Time: 2018-07-14 21:19:50
TRAINING STATS: batch 368/486 in epoch 12,   batch loss: 0.43713, batch accuracy: 0.86967
Time: 2018-07-14 21:19:55
TRAINING STATS: batch 418/486 in epoch 12,   batch loss: 0.39040, batch accuracy: 0.87967
Time: 2018-07-14 21:19:58
TRAINING STATS: batch 468/486 in epoch 12,   batch loss: 0.42143, batch accuracy: 0.87667
Time: 2018-07-14 21:20:02
TRAINING STATS: batch 32/486 in epoch 13,    batch loss: 0.37132, batch accuracy: 0.89167
Time: 2018-07-14 21:20:07
TRAINING STATS: batch 82/486 in epoch 13,    batch loss: 0.41285, batch accuracy: 0.87967
Time: 2018-07-14 21:20:11
TRAINING STATS: batch 132/486 in epoch 13,   batch loss: 0.40056, batch accuracy: 0.87983
Time: 2018-07-14 21:20:14
TRAINING STATS: batch 182/486 in epoch 13,   batch loss: 0.40018, batch accuracy: 0.88117
Time: 2018-07-14 21:20:19
TRAINING STATS: batch 232/486 in epoch 13,   batch loss: 0.42121, batch accuracy: 0.87850
Time: 2018-07-14 21:20:23
TRAINING STATS: batch 282/486 in epoch 13,   batch loss: 0.36354, batch accuracy: 0.89683
Time: 2018-07-14 21:20:27
TRAINING STATS: batch 332/486 in epoch 13,   batch loss: 0.43220, batch accuracy: 0.87200
Time: 2018-07-14 21:20:31
TRAINING STATS: batch 382/486 in epoch 13,   batch loss: 0.41515, batch accuracy: 0.87767
Time: 2018-07-14 21:20:35
TRAINING STATS: batch 432/486 in epoch 13,   batch loss: 0.35742, batch accuracy: 0.89433
Time: 2018-07-14 21:20:39
TRAINING STATS: batch 482/486 in epoch 13,   batch loss: 0.36093, batch accuracy: 0.89283
Time: 2018-07-14 21:20:43
TRAINING STATS: batch 46/486 in epoch 14,    batch loss: 0.40184, batch accuracy: 0.88433
Time: 2018-07-14 21:20:47
TRAINING STATS: batch 96/486 in epoch 14,    batch loss: 0.42091, batch accuracy: 0.87567
Time: 2018-07-14 21:20:51
TRAINING STATS: batch 146/486 in epoch 14,   batch loss: 0.40154, batch accuracy: 0.88417
Time: 2018-07-14 21:20:56
TRAINING STATS: batch 196/486 in epoch 14,   batch loss: 0.42994, batch accuracy: 0.86950
Time: 2018-07-14 21:20:59
TRAINING STATS: batch 246/486 in epoch 14,   batch loss: 0.39282, batch accuracy: 0.88733
Time: 2018-07-14 21:21:03
TRAINING STATS: batch 296/486 in epoch 14,   batch loss: 0.40571, batch accuracy: 0.88033
Time: 2018-07-14 21:21:08
TRAINING STATS: batch 346/486 in epoch 14,   batch loss: 0.36466, batch accuracy: 0.89600
Time: 2018-07-14 21:21:11
TRAINING STATS: batch 396/486 in epoch 14,   batch loss: 0.40390, batch accuracy: 0.87633
Time: 2018-07-14 21:21:15
TRAINING STATS: batch 446/486 in epoch 14,   batch loss: 0.39188, batch accuracy: 0.88350
Time: 2018-07-14 21:21:20
TRAINING STATS: batch 10/486 in epoch 15,    batch loss: 0.38203, batch accuracy: 0.89000
Time: 2018-07-14 21:21:24
TRAINING STATS: batch 60/486 in epoch 15,    batch loss: 0.38855, batch accuracy: 0.88483
Time: 2018-07-14 21:21:27
TRAINING STATS: batch 110/486 in epoch 15,   batch loss: 0.42941, batch accuracy: 0.87400
Time: 2018-07-14 21:21:32
TRAINING STATS: batch 160/486 in epoch 15,   batch loss: 0.38863, batch accuracy: 0.88483
Time: 2018-07-14 21:21:36
TRAINING STATS: batch 210/486 in epoch 15,   batch loss: 0.35607, batch accuracy: 0.89300
Time: 2018-07-14 21:21:39
TRAINING STATS: batch 260/486 in epoch 15,   batch loss: 0.42454, batch accuracy: 0.87367
Time: 2018-07-14 21:21:44
TRAINING STATS: batch 310/486 in epoch 15,   batch loss: 0.37806, batch accuracy: 0.89183
Time: 2018-07-14 21:21:48
TRAINING STATS: batch 360/486 in epoch 15,   batch loss: 0.40717, batch accuracy: 0.88200
Time: 2018-07-14 21:21:52
TRAINING STATS: batch 410/486 in epoch 15,   batch loss: 0.36462, batch accuracy: 0.89150
Time: 2018-07-14 21:21:56
TRAINING STATS: batch 460/486 in epoch 15,   batch loss: 0.46285, batch accuracy: 0.86133
Time: 2018-07-14 21:22:00
TRAINING STATS: batch 24/486 in epoch 16,    batch loss: 0.42870, batch accuracy: 0.87467
Time: 2018-07-14 21:22:04
TRAINING STATS: batch 74/486 in epoch 16,    batch loss: 0.42427, batch accuracy: 0.87733
Time: 2018-07-14 21:22:09
TRAINING STATS: batch 124/486 in epoch 16,   batch loss: 0.39157, batch accuracy: 0.88283
Time: 2018-07-14 21:22:12
TRAINING STATS: batch 174/486 in epoch 16,   batch loss: 0.43558, batch accuracy: 0.87333
Time: 2018-07-14 21:22:16
TRAINING STATS: batch 224/486 in epoch 16,   batch loss: 0.42466, batch accuracy: 0.87333
Time: 2018-07-14 21:22:21
TRAINING STATS: batch 274/486 in epoch 16,   batch loss: 0.41743, batch accuracy: 0.87400
Time: 2018-07-14 21:22:24
TRAINING STATS: batch 324/486 in epoch 16,   batch loss: 0.37818, batch accuracy: 0.88883
Time: 2018-07-14 21:22:28
TRAINING STATS: batch 374/486 in epoch 16,   batch loss: 0.43896, batch accuracy: 0.86917
Time: 2018-07-14 21:22:33
TRAINING STATS: batch 424/486 in epoch 16,   batch loss: 0.37003, batch accuracy: 0.88883
Time: 2018-07-14 21:22:37
TRAINING STATS: batch 474/486 in epoch 16,   batch loss: 0.39159, batch accuracy: 0.88733
Time: 2018-07-14 21:22:40
TRAINING STATS: batch 38/486 in epoch 17,    batch loss: 0.42251, batch accuracy: 0.87367
Time: 2018-07-14 21:22:45
TRAINING STATS: batch 88/486 in epoch 17,    batch loss: 0.39332, batch accuracy: 0.88250
Time: 2018-07-14 21:22:49
TRAINING STATS: batch 138/486 in epoch 17,   batch loss: 0.39746, batch accuracy: 0.88083
Time: 2018-07-14 21:22:52
TRAINING STATS: batch 188/486 in epoch 17,   batch loss: 0.39042, batch accuracy: 0.88317
Time: 2018-07-14 21:22:57
TRAINING STATS: batch 238/486 in epoch 17,   batch loss: 0.41490, batch accuracy: 0.88017
Time: 2018-07-14 21:23:01
TRAINING STATS: batch 288/486 in epoch 17,   batch loss: 0.41096, batch accuracy: 0.87817
Time: 2018-07-14 21:23:05
TRAINING STATS: batch 338/486 in epoch 17,   batch loss: 0.38995, batch accuracy: 0.88600
Time: 2018-07-14 21:23:09
TRAINING STATS: batch 388/486 in epoch 17,   batch loss: 0.38837, batch accuracy: 0.88500
Time: 2018-07-14 21:23:13
TRAINING STATS: batch 438/486 in epoch 17,   batch loss: 0.40950, batch accuracy: 0.88033
Time: 2018-07-14 21:23:17
TRAINING STATS: batch 2/486 in epoch 18,     batch loss: 0.39450, batch accuracy: 0.88150
Time: 2018-07-14 21:23:21
TRAINING STATS: batch 52/486 in epoch 18,    batch loss: 0.38702, batch accuracy: 0.88417
Time: 2018-07-14 21:23:25
TRAINING STATS: batch 102/486 in epoch 18,   batch loss: 0.40750, batch accuracy: 0.87967
Time: 2018-07-14 21:23:29
TRAINING STATS: batch 152/486 in epoch 18,   batch loss: 0.36746, batch accuracy: 0.88800
Time: 2018-07-14 21:23:33
TRAINING STATS: batch 202/486 in epoch 18,   batch loss: 0.40764, batch accuracy: 0.87850
Time: 2018-07-14 21:23:37
TRAINING STATS: batch 252/486 in epoch 18,   batch loss: 0.39603, batch accuracy: 0.87883
Time: 2018-07-14 21:23:41
TRAINING STATS: batch 302/486 in epoch 18,   batch loss: 0.38820, batch accuracy: 0.88417
Time: 2018-07-14 21:23:46
TRAINING STATS: batch 352/486 in epoch 18,   batch loss: 0.37651, batch accuracy: 0.89183
Time: 2018-07-14 21:23:49
TRAINING STATS: batch 402/486 in epoch 18,   batch loss: 0.35387, batch accuracy: 0.89550
Time: 2018-07-14 21:23:53
TRAINING STATS: batch 452/486 in epoch 18,   batch loss: 0.39496, batch accuracy: 0.88333
Time: 2018-07-14 21:23:58
TRAINING STATS: batch 16/486 in epoch 19,    batch loss: 0.36666, batch accuracy: 0.89133
Time: 2018-07-14 21:24:02
TRAINING STATS: batch 66/486 in epoch 19,    batch loss: 0.41249, batch accuracy: 0.87833
Time: 2018-07-14 21:24:05
TRAINING STATS: batch 116/486 in epoch 19,   batch loss: 0.36651, batch accuracy: 0.89017
Time: 2018-07-14 21:24:10
TRAINING STATS: batch 166/486 in epoch 19,   batch loss: 0.31723, batch accuracy: 0.90867
Time: 2018-07-14 21:24:14
TRAINING STATS: batch 216/486 in epoch 19,   batch loss: 0.39649, batch accuracy: 0.88233
Time: 2018-07-14 21:24:17
TRAINING STATS: batch 266/486 in epoch 19,   batch loss: 0.38536, batch accuracy: 0.88800
Time: 2018-07-14 21:24:22
TRAINING STATS: batch 316/486 in epoch 19,   batch loss: 0.37240, batch accuracy: 0.88967
Time: 2018-07-14 21:24:26
TRAINING STATS: batch 366/486 in epoch 19,   batch loss: 0.43296, batch accuracy: 0.87000
Time: 2018-07-14 21:24:30
TRAINING STATS: batch 416/486 in epoch 19,   batch loss: 0.41764, batch accuracy: 0.87217
Time: 2018-07-14 21:24:34
TRAINING STATS: batch 466/486 in epoch 19,   batch loss: 0.31546, batch accuracy: 0.90617
Time: 2018-07-14 21:24:38
TRAINING STATS: batch 30/486 in epoch 20,    batch loss: 0.34622, batch accuracy: 0.89733
Time: 2018-07-14 21:24:42
TRAINING STATS: batch 80/486 in epoch 20,    batch loss: 0.40376, batch accuracy: 0.87983
Time: 2018-07-14 21:24:46
TRAINING STATS: batch 130/486 in epoch 20,   batch loss: 0.39814, batch accuracy: 0.87933
Time: 2018-07-14 21:24:50
TRAINING STATS: batch 180/486 in epoch 20,   batch loss: 0.33786, batch accuracy: 0.90283
Time: 2018-07-14 21:24:54
TRAINING STATS: batch 230/486 in epoch 20,   batch loss: 0.39448, batch accuracy: 0.88550
Time: 2018-07-14 21:24:59
TRAINING STATS: batch 280/486 in epoch 20,   batch loss: 0.38538, batch accuracy: 0.88633
Time: 2018-07-14 21:25:02
TRAINING STATS: batch 330/486 in epoch 20,   batch loss: 0.40656, batch accuracy: 0.87933
Time: 2018-07-14 21:25:06
TRAINING STATS: batch 380/486 in epoch 20,   batch loss: 0.36515, batch accuracy: 0.89150
Time: 2018-07-14 21:25:11
TRAINING STATS: batch 430/486 in epoch 20,   batch loss: 0.36702, batch accuracy: 0.89217
Time: 2018-07-14 21:25:14
TRAINING STATS: batch 480/486 in epoch 20,   batch loss: 0.36249, batch accuracy: 0.89350
Time: 2018-07-14 21:25:18
TRAINING STATS: batch 44/486 in epoch 21,    batch loss: 0.37028, batch accuracy: 0.89150
Time: 2018-07-14 21:25:23
TRAINING STATS: batch 94/486 in epoch 21,    batch loss: 0.38508, batch accuracy: 0.88700
Time: 2018-07-14 21:25:27
TRAINING STATS: batch 144/486 in epoch 21,   batch loss: 0.41842, batch accuracy: 0.87633
Time: 2018-07-14 21:25:30
TRAINING STATS: batch 194/486 in epoch 21,   batch loss: 0.43014, batch accuracy: 0.87300
Time: 2018-07-14 21:25:35
TRAINING STATS: batch 244/486 in epoch 21,   batch loss: 0.38736, batch accuracy: 0.88583
Time: 2018-07-14 21:25:39
TRAINING STATS: batch 294/486 in epoch 21,   batch loss: 0.34715, batch accuracy: 0.89650
Time: 2018-07-14 21:25:42
TRAINING STATS: batch 344/486 in epoch 21,   batch loss: 0.41217, batch accuracy: 0.88067
Time: 2018-07-14 21:25:47
TRAINING STATS: batch 394/486 in epoch 21,   batch loss: 0.39603, batch accuracy: 0.88350
Time: 2018-07-14 21:25:51
TRAINING STATS: batch 444/486 in epoch 21,   batch loss: 0.34290, batch accuracy: 0.89317
Time: 2018-07-14 21:25:55
TRAINING STATS: batch 8/486 in epoch 22,     batch loss: 0.37149, batch accuracy: 0.88900
Time: 2018-07-14 21:25:59
TRAINING STATS: batch 58/486 in epoch 22,    batch loss: 0.38536, batch accuracy: 0.88467
Time: 2018-07-14 21:26:03
TRAINING STATS: batch 108/486 in epoch 22,   batch loss: 0.38739, batch accuracy: 0.88817
Time: 2018-07-14 21:26:07
TRAINING STATS: batch 158/486 in epoch 22,   batch loss: 0.38296, batch accuracy: 0.88983
Time: 2018-07-14 21:26:12
TRAINING STATS: batch 208/486 in epoch 22,   batch loss: 0.38436, batch accuracy: 0.88500
Time: 2018-07-14 21:26:15
TRAINING STATS: batch 258/486 in epoch 22,   batch loss: 0.39981, batch accuracy: 0.88217
Time: 2018-07-14 21:26:19
TRAINING STATS: batch 308/486 in epoch 22,   batch loss: 0.38037, batch accuracy: 0.88750
Time: 2018-07-14 21:26:24
TRAINING STATS: batch 358/486 in epoch 22,   batch loss: 0.38213, batch accuracy: 0.89050
Time: 2018-07-14 21:26:27
TRAINING STATS: batch 408/486 in epoch 22,   batch loss: 0.39532, batch accuracy: 0.87900
Time: 2018-07-14 21:26:31
TRAINING STATS: batch 458/486 in epoch 22,   batch loss: 0.40162, batch accuracy: 0.88300
Time: 2018-07-14 21:26:36
TRAINING STATS: batch 22/486 in epoch 23,    batch loss: 0.39483, batch accuracy: 0.88483
Time: 2018-07-14 21:26:40
TRAINING STATS: batch 72/486 in epoch 23,    batch loss: 0.36889, batch accuracy: 0.88967
Time: 2018-07-14 21:26:43
TRAINING STATS: batch 122/486 in epoch 23,   batch loss: 0.32519, batch accuracy: 0.90167
Time: 2018-07-14 21:26:48
TRAINING STATS: batch 172/486 in epoch 23,   batch loss: 0.36876, batch accuracy: 0.89483
Time: 2018-07-14 21:26:52
TRAINING STATS: batch 222/486 in epoch 23,   batch loss: 0.40448, batch accuracy: 0.87783
Time: 2018-07-14 21:26:55
TRAINING STATS: batch 272/486 in epoch 23,   batch loss: 0.39933, batch accuracy: 0.88200
Time: 2018-07-14 21:27:00
TRAINING STATS: batch 322/486 in epoch 23,   batch loss: 0.35151, batch accuracy: 0.89733
Time: 2018-07-14 21:27:04
TRAINING STATS: batch 372/486 in epoch 23,   batch loss: 0.35797, batch accuracy: 0.89367
Time: 2018-07-14 21:27:08
TRAINING STATS: batch 422/486 in epoch 23,   batch loss: 0.32722, batch accuracy: 0.90250
Time: 2018-07-14 21:27:13
TRAINING STATS: batch 472/486 in epoch 23,   batch loss: 0.39641, batch accuracy: 0.88383
Time: 2018-07-14 21:27:16
TRAINING STATS: batch 36/486 in epoch 24,    batch loss: 0.42909, batch accuracy: 0.87367
Time: 2018-07-14 21:27:20
TRAINING STATS: batch 86/486 in epoch 24,    batch loss: 0.35276, batch accuracy: 0.89867
Time: 2018-07-14 21:27:25
TRAINING STATS: batch 136/486 in epoch 24,   batch loss: 0.40205, batch accuracy: 0.88017
Time: 2018-07-14 21:27:28
TRAINING STATS: batch 186/486 in epoch 24,   batch loss: 0.38477, batch accuracy: 0.88867
Time: 2018-07-14 21:27:32
TRAINING STATS: batch 236/486 in epoch 24,   batch loss: 0.38945, batch accuracy: 0.88483
Time: 2018-07-14 21:27:37
TRAINING STATS: batch 286/486 in epoch 24,   batch loss: 0.40114, batch accuracy: 0.88467
Time: 2018-07-14 21:27:40
TRAINING STATS: batch 336/486 in epoch 24,   batch loss: 0.38130, batch accuracy: 0.88733
Time: 2018-07-14 21:27:44
TRAINING STATS: batch 386/486 in epoch 24,   batch loss: 0.38636, batch accuracy: 0.88517
Time: 2018-07-14 21:27:49
TRAINING STATS: batch 436/486 in epoch 24,   batch loss: 0.37457, batch accuracy: 0.89017
Time: 2018-07-14 21:27:53
TRAINING STATS: batch 0/486 in epoch 25,     batch loss: 0.38282, batch accuracy: 0.88600
Time: 2018-07-14 21:27:56
TRAINING STATS: batch 50/486 in epoch 25,    batch loss: 0.34554, batch accuracy: 0.89900
Time: 2018-07-14 21:28:01
TRAINING STATS: batch 100/486 in epoch 25,   batch loss: 0.36723, batch accuracy: 0.88950
Time: 2018-07-14 21:28:05
TRAINING STATS: batch 150/486 in epoch 25,   batch loss: 0.39185, batch accuracy: 0.88167
Time: 2018-07-14 21:28:09
TRAINING STATS: batch 200/486 in epoch 25,   batch loss: 0.30711, batch accuracy: 0.90850
Time: 2018-07-14 21:28:13
TRAINING STATS: batch 250/486 in epoch 25,   batch loss: 0.40325, batch accuracy: 0.87850
Time: 2018-07-14 21:28:17
TRAINING STATS: batch 300/486 in epoch 25,   batch loss: 0.39081, batch accuracy: 0.88417
Time: 2018-07-14 21:28:21
TRAINING STATS: batch 350/486 in epoch 25,   batch loss: 0.37553, batch accuracy: 0.88833
Time: 2018-07-14 21:28:25
TRAINING STATS: batch 400/486 in epoch 25,   batch loss: 0.34598, batch accuracy: 0.89767
Time: 2018-07-14 21:28:29
TRAINING STATS: batch 450/486 in epoch 25,   batch loss: 0.38481, batch accuracy: 0.88250
Time: 2018-07-14 21:28:33
TRAINING STATS: batch 14/486 in epoch 26,    batch loss: 0.33131, batch accuracy: 0.90267
Time: 2018-07-14 21:28:38
TRAINING STATS: batch 64/486 in epoch 26,    batch loss: 0.41325, batch accuracy: 0.87733
Time: 2018-07-14 21:28:41
TRAINING STATS: batch 114/486 in epoch 26,   batch loss: 0.37301, batch accuracy: 0.88650
Time: 2018-07-14 21:28:45
TRAINING STATS: batch 164/486 in epoch 26,   batch loss: 0.33124, batch accuracy: 0.89800
Time: 2018-07-14 21:28:50
TRAINING STATS: batch 214/486 in epoch 26,   batch loss: 0.38890, batch accuracy: 0.88450
Time: 2018-07-14 21:28:54
TRAINING STATS: batch 264/486 in epoch 26,   batch loss: 0.36532, batch accuracy: 0.89283
Time: 2018-07-14 21:28:57
TRAINING STATS: batch 314/486 in epoch 26,   batch loss: 0.39222, batch accuracy: 0.88533
Time: 2018-07-14 21:29:02
TRAINING STATS: batch 364/486 in epoch 26,   batch loss: 0.37954, batch accuracy: 0.88833
Time: 2018-07-14 21:29:06
TRAINING STATS: batch 414/486 in epoch 26,   batch loss: 0.34663, batch accuracy: 0.89833
Time: 2018-07-14 21:29:10
TRAINING STATS: batch 464/486 in epoch 26,   batch loss: 0.33095, batch accuracy: 0.90283
Time: 2018-07-14 21:29:14
TRAINING STATS: batch 28/486 in epoch 27,    batch loss: 0.35041, batch accuracy: 0.89550
Time: 2018-07-14 21:29:18
TRAINING STATS: batch 78/486 in epoch 27,    batch loss: 0.38947, batch accuracy: 0.88600
Time: 2018-07-14 21:29:22
TRAINING STATS: batch 128/486 in epoch 27,   batch loss: 0.38237, batch accuracy: 0.88517
Time: 2018-07-14 21:29:26
TRAINING STATS: batch 178/486 in epoch 27,   batch loss: 0.30561, batch accuracy: 0.91333
Time: 2018-07-14 21:29:30
TRAINING STATS: batch 228/486 in epoch 27,   batch loss: 0.31007, batch accuracy: 0.91100
Time: 2018-07-14 21:29:34
TRAINING STATS: batch 278/486 in epoch 27,   batch loss: 0.35269, batch accuracy: 0.89900
Time: 2018-07-14 21:29:39
TRAINING STATS: batch 328/486 in epoch 27,   batch loss: 0.37971, batch accuracy: 0.88883
Time: 2018-07-14 21:29:42
TRAINING STATS: batch 378/486 in epoch 27,   batch loss: 0.34917, batch accuracy: 0.89533
Time: 2018-07-14 21:29:46
TRAINING STATS: batch 428/486 in epoch 27,   batch loss: 0.39124, batch accuracy: 0.88333
Time: 2018-07-14 21:29:51
TRAINING STATS: batch 478/486 in epoch 27,   batch loss: 0.34955, batch accuracy: 0.89850
Time: 2018-07-14 21:29:55
TRAINING STATS: batch 42/486 in epoch 28,    batch loss: 0.35301, batch accuracy: 0.89517
Time: 2018-07-14 21:29:58
TRAINING STATS: batch 92/486 in epoch 28,    batch loss: 0.37963, batch accuracy: 0.88800
Time: 2018-07-14 21:30:03
TRAINING STATS: batch 142/486 in epoch 28,   batch loss: 0.32451, batch accuracy: 0.90433
Time: 2018-07-14 21:30:07
TRAINING STATS: batch 192/486 in epoch 28,   batch loss: 0.37832, batch accuracy: 0.88717
Time: 2018-07-14 21:30:10
TRAINING STATS: batch 242/486 in epoch 28,   batch loss: 0.36321, batch accuracy: 0.89067
Time: 2018-07-14 21:30:15
TRAINING STATS: batch 292/486 in epoch 28,   batch loss: 0.37949, batch accuracy: 0.89050
Time: 2018-07-14 21:30:19
TRAINING STATS: batch 342/486 in epoch 28,   batch loss: 0.37644, batch accuracy: 0.89067
Time: 2018-07-14 21:30:23
TRAINING STATS: batch 392/486 in epoch 28,   batch loss: 0.34384, batch accuracy: 0.89883
Time: 2018-07-14 21:30:27
TRAINING STATS: batch 442/486 in epoch 28,   batch loss: 0.32774, batch accuracy: 0.89867
Time: 2018-07-14 21:30:31
TRAINING STATS: batch 6/486 in epoch 29,     batch loss: 0.40316, batch accuracy: 0.88433
Time: 2018-07-14 21:30:35
TRAINING STATS: batch 56/486 in epoch 29,    batch loss: 0.37223, batch accuracy: 0.88383
Time: 2018-07-14 21:30:40
TRAINING STATS: batch 106/486 in epoch 29,   batch loss: 0.38653, batch accuracy: 0.88333
Time: 2018-07-14 21:30:43
TRAINING STATS: batch 156/486 in epoch 29,   batch loss: 0.36750, batch accuracy: 0.88967
Time: 2018-07-14 21:30:47
TRAINING STATS: batch 206/486 in epoch 29,   batch loss: 0.39035, batch accuracy: 0.88250
Time: 2018-07-14 21:30:52
TRAINING STATS: batch 256/486 in epoch 29,   batch loss: 0.34171, batch accuracy: 0.89833
Time: 2018-07-14 21:30:55
TRAINING STATS: batch 306/486 in epoch 29,   batch loss: 0.37736, batch accuracy: 0.88283
Time: 2018-07-14 21:30:59
TRAINING STATS: batch 356/486 in epoch 29,   batch loss: 0.37508, batch accuracy: 0.89067
Time: 2018-07-14 21:31:04
TRAINING STATS: batch 406/486 in epoch 29,   batch loss: 0.38240, batch accuracy: 0.88250
Time: 2018-07-14 21:31:08
TRAINING STATS: batch 456/486 in epoch 29,   batch loss: 0.32261, batch accuracy: 0.90050
Time: 2018-07-14 21:31:11
TRAINING STATS: batch 20/486 in epoch 30,    batch loss: 0.36440, batch accuracy: 0.89133
Time: 2018-07-14 21:31:16
TRAINING STATS: batch 70/486 in epoch 30,    batch loss: 0.30953, batch accuracy: 0.90500
Time: 2018-07-14 21:31:20
TRAINING STATS: batch 120/486 in epoch 30,   batch loss: 0.37153, batch accuracy: 0.88767
Time: 2018-07-14 21:31:23
TRAINING STATS: batch 170/486 in epoch 30,   batch loss: 0.32717, batch accuracy: 0.90200
Time: 2018-07-14 21:31:28
TRAINING STATS: batch 220/486 in epoch 30,   batch loss: 0.34225, batch accuracy: 0.89667
Time: 2018-07-14 21:31:32
TRAINING STATS: batch 270/486 in epoch 30,   batch loss: 0.35134, batch accuracy: 0.89683
Time: 2018-07-14 21:31:36
TRAINING STATS: batch 320/486 in epoch 30,   batch loss: 0.34266, batch accuracy: 0.90100
Time: 2018-07-14 21:31:40
TRAINING STATS: batch 370/486 in epoch 30,   batch loss: 0.36303, batch accuracy: 0.89550
Time: 2018-07-14 21:31:44
TRAINING STATS: batch 420/486 in epoch 30,   batch loss: 0.35609, batch accuracy: 0.89600
Time: 2018-07-14 21:31:48
TRAINING STATS: batch 470/486 in epoch 30,   batch loss: 0.38490, batch accuracy: 0.88250
Time: 2018-07-14 21:31:53
TRAINING STATS: batch 34/486 in epoch 31,    batch loss: 0.38368, batch accuracy: 0.88500
Time: 2018-07-14 21:31:56
TRAINING STATS: batch 84/486 in epoch 31,    batch loss: 0.34771, batch accuracy: 0.89417
Time: 2018-07-14 21:32:00
TRAINING STATS: batch 134/486 in epoch 31,   batch loss: 0.36084, batch accuracy: 0.89583
Time: 2018-07-14 21:32:05
TRAINING STATS: batch 184/486 in epoch 31,   batch loss: 0.37689, batch accuracy: 0.89083
Time: 2018-07-14 21:32:09
TRAINING STATS: batch 234/486 in epoch 31,   batch loss: 0.39362, batch accuracy: 0.88583
Time: 2018-07-14 21:32:12
TRAINING STATS: batch 284/486 in epoch 31,   batch loss: 0.37611, batch accuracy: 0.89117
Time: 2018-07-14 21:32:17
TRAINING STATS: batch 334/486 in epoch 31,   batch loss: 0.33854, batch accuracy: 0.89850
Time: 2018-07-14 21:32:21
TRAINING STATS: batch 384/486 in epoch 31,   batch loss: 0.35221, batch accuracy: 0.89750
Time: 2018-07-14 21:32:24
TRAINING STATS: batch 434/486 in epoch 31,   batch loss: 0.39052, batch accuracy: 0.88317
Time: 2018-07-14 21:32:29
TRAINING STATS: batch 484/486 in epoch 31,   batch loss: 0.35794, batch accuracy: 0.89467
Time: 2018-07-14 21:32:33
TRAINING STATS: batch 48/486 in epoch 32,    batch loss: 0.35851, batch accuracy: 0.89750
Time: 2018-07-14 21:32:37
TRAINING STATS: batch 98/486 in epoch 32,    batch loss: 0.31900, batch accuracy: 0.90600
Time: 2018-07-14 21:32:41
TRAINING STATS: batch 148/486 in epoch 32,   batch loss: 0.36709, batch accuracy: 0.89233
Time: 2018-07-14 21:32:45
TRAINING STATS: batch 198/486 in epoch 32,   batch loss: 0.37717, batch accuracy: 0.89150
Time: 2018-07-14 21:32:49
TRAINING STATS: batch 248/486 in epoch 32,   batch loss: 0.37455, batch accuracy: 0.88700
Time: 2018-07-14 21:32:53
TRAINING STATS: batch 298/486 in epoch 32,   batch loss: 0.35864, batch accuracy: 0.89583
Time: 2018-07-14 21:32:57
TRAINING STATS: batch 348/486 in epoch 32,   batch loss: 0.34759, batch accuracy: 0.89583
Time: 2018-07-14 21:33:01
TRAINING STATS: batch 398/486 in epoch 32,   batch loss: 0.37068, batch accuracy: 0.89067
Time: 2018-07-14 21:33:06
TRAINING STATS: batch 448/486 in epoch 32,   batch loss: 0.38348, batch accuracy: 0.88567
Time: 2018-07-14 21:33:09
TRAINING STATS: batch 12/486 in epoch 33,    batch loss: 0.34354, batch accuracy: 0.89967
Time: 2018-07-14 21:33:13
TRAINING STATS: batch 62/486 in epoch 33,    batch loss: 0.37245, batch accuracy: 0.89000
Time: 2018-07-14 21:33:18
TRAINING STATS: batch 112/486 in epoch 33,   batch loss: 0.34171, batch accuracy: 0.89717
Time: 2018-07-14 21:33:22
TRAINING STATS: batch 162/486 in epoch 33,   batch loss: 0.34766, batch accuracy: 0.89783
Time: 2018-07-14 21:33:25
TRAINING STATS: batch 212/486 in epoch 33,   batch loss: 0.34249, batch accuracy: 0.89983
Time: 2018-07-14 21:33:30
TRAINING STATS: batch 262/486 in epoch 33,   batch loss: 0.38618, batch accuracy: 0.88783
Time: 2018-07-14 21:33:34
TRAINING STATS: batch 312/486 in epoch 33,   batch loss: 0.32473, batch accuracy: 0.90483
Time: 2018-07-14 21:33:37
TRAINING STATS: batch 362/486 in epoch 33,   batch loss: 0.38423, batch accuracy: 0.88533
Time: 2018-07-14 21:33:42
TRAINING STATS: batch 412/486 in epoch 33,   batch loss: 0.32928, batch accuracy: 0.90250
Time: 2018-07-14 21:33:46
TRAINING STATS: batch 462/486 in epoch 33,   batch loss: 0.37670, batch accuracy: 0.88767
Time: 2018-07-14 21:33:49
TRAINING STATS: batch 26/486 in epoch 34,    batch loss: 0.38729, batch accuracy: 0.88617
Time: 2018-07-14 21:33:54
TRAINING STATS: batch 76/486 in epoch 34,    batch loss: 0.39378, batch accuracy: 0.88167
Time: 2018-07-14 21:33:58
TRAINING STATS: batch 126/486 in epoch 34,   batch loss: 0.36752, batch accuracy: 0.88783
Time: 2018-07-14 21:34:02
TRAINING STATS: batch 176/486 in epoch 34,   batch loss: 0.34459, batch accuracy: 0.89717
Time: 2018-07-14 21:34:06
TRAINING STATS: batch 226/486 in epoch 34,   batch loss: 0.34447, batch accuracy: 0.90017
Time: 2018-07-14 21:34:10
TRAINING STATS: batch 276/486 in epoch 34,   batch loss: 0.37031, batch accuracy: 0.88983
Time: 2018-07-14 21:34:14
TRAINING STATS: batch 326/486 in epoch 34,   batch loss: 0.34144, batch accuracy: 0.89683
Time: 2018-07-14 21:34:19
TRAINING STATS: batch 376/486 in epoch 34,   batch loss: 0.37458, batch accuracy: 0.89083
Time: 2018-07-14 21:34:22
TRAINING STATS: batch 426/486 in epoch 34,   batch loss: 0.34378, batch accuracy: 0.90067
Time: 2018-07-14 21:34:26
TRAINING STATS: batch 476/486 in epoch 34,   batch loss: 0.32985, batch accuracy: 0.90250
Time: 2018-07-14 21:34:31
TRAINING STATS: batch 40/486 in epoch 35,    batch loss: 0.35638, batch accuracy: 0.89533
Time: 2018-07-14 21:34:35
TRAINING STATS: batch 90/486 in epoch 35,    batch loss: 0.34619, batch accuracy: 0.89883
Time: 2018-07-14 21:34:38
TRAINING STATS: batch 140/486 in epoch 35,   batch loss: 0.32016, batch accuracy: 0.90700
Time: 2018-07-14 21:34:43
TRAINING STATS: batch 190/486 in epoch 35,   batch loss: 0.33904, batch accuracy: 0.89900
Time: 2018-07-14 21:34:47
TRAINING STATS: batch 240/486 in epoch 35,   batch loss: 0.35525, batch accuracy: 0.89333
Time: 2018-07-14 21:34:50
TRAINING STATS: batch 290/486 in epoch 35,   batch loss: 0.37646, batch accuracy: 0.88483
Time: 2018-07-14 21:34:55
TRAINING STATS: batch 340/486 in epoch 35,   batch loss: 0.37032, batch accuracy: 0.88917
Time: 2018-07-14 21:34:59
TRAINING STATS: batch 390/486 in epoch 35,   batch loss: 0.31487, batch accuracy: 0.90717
Time: 2018-07-14 21:35:03
TRAINING STATS: batch 440/486 in epoch 35,   batch loss: 0.37726, batch accuracy: 0.88933
Time: 2018-07-14 21:35:07
TRAINING STATS: batch 4/486 in epoch 36,     batch loss: 0.35546, batch accuracy: 0.89683
Time: 2018-07-14 21:35:11
TRAINING STATS: batch 54/486 in epoch 36,    batch loss: 0.38800, batch accuracy: 0.88717
Time: 2018-07-14 21:35:15
TRAINING STATS: batch 104/486 in epoch 36,   batch loss: 0.34981, batch accuracy: 0.89667
Time: 2018-07-14 21:35:20
TRAINING STATS: batch 154/486 in epoch 36,   batch loss: 0.31091, batch accuracy: 0.91117
Time: 2018-07-14 21:35:23
TRAINING STATS: batch 204/486 in epoch 36,   batch loss: 0.39310, batch accuracy: 0.87933
Time: 2018-07-14 21:35:27
TRAINING STATS: batch 254/486 in epoch 36,   batch loss: 0.34145, batch accuracy: 0.89700
Time: 2018-07-14 21:35:32
TRAINING STATS: batch 304/486 in epoch 36,   batch loss: 0.35408, batch accuracy: 0.89450
Time: 2018-07-14 21:35:35
TRAINING STATS: batch 354/486 in epoch 36,   batch loss: 0.35321, batch accuracy: 0.89483
Time: 2018-07-14 21:35:39
TRAINING STATS: batch 404/486 in epoch 36,   batch loss: 0.33107, batch accuracy: 0.90250
Time: 2018-07-14 21:35:44
TRAINING STATS: batch 454/486 in epoch 36,   batch loss: 0.30896, batch accuracy: 0.91000
Time: 2018-07-14 21:35:48
TRAINING STATS: batch 18/486 in epoch 37,    batch loss: 0.36233, batch accuracy: 0.89467
Time: 2018-07-14 21:35:51
TRAINING STATS: batch 68/486 in epoch 37,    batch loss: 0.30816, batch accuracy: 0.90650
Time: 2018-07-14 21:35:56
TRAINING STATS: batch 118/486 in epoch 37,   batch loss: 0.33945, batch accuracy: 0.89750
Time: 2018-07-14 21:36:00
TRAINING STATS: batch 168/486 in epoch 37,   batch loss: 0.31250, batch accuracy: 0.90950
Time: 2018-07-14 21:36:03
TRAINING STATS: batch 218/486 in epoch 37,   batch loss: 0.33671, batch accuracy: 0.90167
Time: 2018-07-14 21:36:08
TRAINING STATS: batch 268/486 in epoch 37,   batch loss: 0.32828, batch accuracy: 0.90033
Time: 2018-07-14 21:36:12
TRAINING STATS: batch 318/486 in epoch 37,   batch loss: 0.35763, batch accuracy: 0.89500
Time: 2018-07-14 21:36:16
TRAINING STATS: batch 368/486 in epoch 37,   batch loss: 0.37779, batch accuracy: 0.88617
Time: 2018-07-14 21:36:20
TRAINING STATS: batch 418/486 in epoch 37,   batch loss: 0.33016, batch accuracy: 0.90033
Time: 2018-07-14 21:36:24
TRAINING STATS: batch 468/486 in epoch 37,   batch loss: 0.35615, batch accuracy: 0.89450
Time: 2018-07-14 21:36:28
TRAINING STATS: batch 32/486 in epoch 38,    batch loss: 0.31902, batch accuracy: 0.90517
Time: 2018-07-14 21:36:33
TRAINING STATS: batch 82/486 in epoch 38,    batch loss: 0.35972, batch accuracy: 0.89533
Time: 2018-07-14 21:36:36
TRAINING STATS: batch 132/486 in epoch 38,   batch loss: 0.34173, batch accuracy: 0.89817
Time: 2018-07-14 21:36:40
TRAINING STATS: batch 182/486 in epoch 38,   batch loss: 0.35319, batch accuracy: 0.89233
Time: 2018-07-14 21:36:45
TRAINING STATS: batch 232/486 in epoch 38,   batch loss: 0.36687, batch accuracy: 0.89317
Time: 2018-07-14 21:36:49
TRAINING STATS: batch 282/486 in epoch 38,   batch loss: 0.32906, batch accuracy: 0.90383
Time: 2018-07-14 21:36:52
TRAINING STATS: batch 332/486 in epoch 38,   batch loss: 0.38112, batch accuracy: 0.88933
Time: 2018-07-14 21:36:57
TRAINING STATS: batch 382/486 in epoch 38,   batch loss: 0.35983, batch accuracy: 0.89533
Time: 2018-07-14 21:37:01
TRAINING STATS: batch 432/486 in epoch 38,   batch loss: 0.31655, batch accuracy: 0.90500
Time: 2018-07-14 21:37:04
TRAINING STATS: batch 482/486 in epoch 38,   batch loss: 0.32588, batch accuracy: 0.90133
Time: 2018-07-14 21:37:09
TRAINING STATS: batch 46/486 in epoch 39,    batch loss: 0.35421, batch accuracy: 0.89350
Time: 2018-07-14 21:37:13
TRAINING STATS: batch 96/486 in epoch 39,    batch loss: 0.36894, batch accuracy: 0.89150
Time: 2018-07-14 21:37:17
TRAINING STATS: batch 146/486 in epoch 39,   batch loss: 0.34865, batch accuracy: 0.90033
Time: 2018-07-14 21:37:21
TRAINING STATS: batch 196/486 in epoch 39,   batch loss: 0.37940, batch accuracy: 0.88300
Time: 2018-07-14 21:37:25
TRAINING STATS: batch 246/486 in epoch 39,   batch loss: 0.33828, batch accuracy: 0.89867
Time: 2018-07-14 21:37:29
TRAINING STATS: batch 296/486 in epoch 39,   batch loss: 0.36337, batch accuracy: 0.88617
Time: 2018-07-14 21:37:33
TRAINING STATS: batch 346/486 in epoch 39,   batch loss: 0.33462, batch accuracy: 0.90200
Time: 2018-07-14 21:37:37
TRAINING STATS: batch 396/486 in epoch 39,   batch loss: 0.35108, batch accuracy: 0.89483
Time: 2018-07-14 21:37:41
TRAINING STATS: batch 446/486 in epoch 39,   batch loss: 0.35021, batch accuracy: 0.89517
Time: 2018-07-14 21:37:46
TRAINING STATS: batch 10/486 in epoch 40,    batch loss: 0.34469, batch accuracy: 0.89767
Time: 2018-07-14 21:37:49
TRAINING STATS: batch 60/486 in epoch 40,    batch loss: 0.32287, batch accuracy: 0.90167
Time: 2018-07-14 21:37:53
TRAINING STATS: batch 110/486 in epoch 40,   batch loss: 0.36528, batch accuracy: 0.89200
Time: 2018-07-14 21:37:58
TRAINING STATS: batch 160/486 in epoch 40,   batch loss: 0.32845, batch accuracy: 0.90017
Time: 2018-07-14 21:38:02
TRAINING STATS: batch 210/486 in epoch 40,   batch loss: 0.31071, batch accuracy: 0.90567
Time: 2018-07-14 21:38:05
TRAINING STATS: batch 260/486 in epoch 40,   batch loss: 0.37261, batch accuracy: 0.88783
Time: 2018-07-14 21:38:10
TRAINING STATS: batch 310/486 in epoch 40,   batch loss: 0.32242, batch accuracy: 0.90417
Time: 2018-07-14 21:38:14
TRAINING STATS: batch 360/486 in epoch 40,   batch loss: 0.35041, batch accuracy: 0.89917
Time: 2018-07-14 21:38:17
TRAINING STATS: batch 410/486 in epoch 40,   batch loss: 0.31568, batch accuracy: 0.90650
Time: 2018-07-14 21:38:22
TRAINING STATS: batch 460/486 in epoch 40,   batch loss: 0.40488, batch accuracy: 0.88117
Time: 2018-07-14 21:38:26
TRAINING STATS: batch 24/486 in epoch 41,    batch loss: 0.37462, batch accuracy: 0.88567
Time: 2018-07-14 21:38:30
TRAINING STATS: batch 74/486 in epoch 41,    batch loss: 0.35045, batch accuracy: 0.89583
Time: 2018-07-14 21:38:34
TRAINING STATS: batch 124/486 in epoch 41,   batch loss: 0.35876, batch accuracy: 0.89550
Time: 2018-07-14 21:38:38
TRAINING STATS: batch 174/486 in epoch 41,   batch loss: 0.38287, batch accuracy: 0.88833
Time: 2018-07-14 21:38:42
TRAINING STATS: batch 224/486 in epoch 41,   batch loss: 0.38351, batch accuracy: 0.88700
Time: 2018-07-14 21:38:47
TRAINING STATS: batch 274/486 in epoch 41,   batch loss: 0.37502, batch accuracy: 0.88267
Time: 2018-07-14 21:38:50
TRAINING STATS: batch 324/486 in epoch 41,   batch loss: 0.33114, batch accuracy: 0.90367
Time: 2018-07-14 21:38:54
TRAINING STATS: batch 374/486 in epoch 41,   batch loss: 0.38364, batch accuracy: 0.88817
Time: 2018-07-14 21:38:59
TRAINING STATS: batch 424/486 in epoch 41,   batch loss: 0.32525, batch accuracy: 0.90283
Time: 2018-07-14 21:39:02
TRAINING STATS: batch 474/486 in epoch 41,   batch loss: 0.33891, batch accuracy: 0.90317
Time: 2018-07-14 21:39:06
TRAINING STATS: batch 38/486 in epoch 42,    batch loss: 0.37897, batch accuracy: 0.88617
Time: 2018-07-14 21:39:11
TRAINING STATS: batch 88/486 in epoch 42,    batch loss: 0.33828, batch accuracy: 0.90083
Time: 2018-07-14 21:39:15
TRAINING STATS: batch 138/486 in epoch 42,   batch loss: 0.34779, batch accuracy: 0.89717
Time: 2018-07-14 21:39:18
TRAINING STATS: batch 188/486 in epoch 42,   batch loss: 0.35489, batch accuracy: 0.89183
Time: 2018-07-14 21:39:23
TRAINING STATS: batch 238/486 in epoch 42,   batch loss: 0.35728, batch accuracy: 0.89817
Time: 2018-07-14 21:39:27
TRAINING STATS: batch 288/486 in epoch 42,   batch loss: 0.36451, batch accuracy: 0.89267
Time: 2018-07-14 21:39:31
TRAINING STATS: batch 338/486 in epoch 42,   batch loss: 0.34907, batch accuracy: 0.89867
Time: 2018-07-14 21:39:35
TRAINING STATS: batch 388/486 in epoch 42,   batch loss: 0.33871, batch accuracy: 0.90133
Time: 2018-07-14 21:39:39
TRAINING STATS: batch 438/486 in epoch 42,   batch loss: 0.36689, batch accuracy: 0.89100
Time: 2018-07-14 21:39:43
TRAINING STATS: batch 2/486 in epoch 43,     batch loss: 0.35045, batch accuracy: 0.89450
Time: 2018-07-14 21:39:47
TRAINING STATS: batch 52/486 in epoch 43,    batch loss: 0.34983, batch accuracy: 0.89183
Time: 2018-07-14 21:39:51
TRAINING STATS: batch 102/486 in epoch 43,   batch loss: 0.35941, batch accuracy: 0.89067
Time: 2018-07-14 21:39:55
TRAINING STATS: batch 152/486 in epoch 43,   batch loss: 0.31802, batch accuracy: 0.90517
Time: 2018-07-14 21:40:00
TRAINING STATS: batch 202/486 in epoch 43,   batch loss: 0.35736, batch accuracy: 0.89350
Time: 2018-07-14 21:40:03
TRAINING STATS: batch 252/486 in epoch 43,   batch loss: 0.35224, batch accuracy: 0.89500
Time: 2018-07-14 21:40:07
TRAINING STATS: batch 302/486 in epoch 43,   batch loss: 0.35367, batch accuracy: 0.89667
Time: 2018-07-14 21:40:12
TRAINING STATS: batch 352/486 in epoch 43,   batch loss: 0.32964, batch accuracy: 0.90067
Time: 2018-07-14 21:40:16
TRAINING STATS: batch 402/486 in epoch 43,   batch loss: 0.31538, batch accuracy: 0.90633
Time: 2018-07-14 21:40:19
TRAINING STATS: batch 452/486 in epoch 43,   batch loss: 0.36219, batch accuracy: 0.89383
Time: 2018-07-14 21:40:24
TRAINING STATS: batch 16/486 in epoch 44,    batch loss: 0.31957, batch accuracy: 0.90500
Time: 2018-07-14 21:40:28
TRAINING STATS: batch 66/486 in epoch 44,    batch loss: 0.37412, batch accuracy: 0.89100
Time: 2018-07-14 21:40:31
TRAINING STATS: batch 116/486 in epoch 44,   batch loss: 0.31933, batch accuracy: 0.90700
Time: 2018-07-14 21:40:36
TRAINING STATS: batch 166/486 in epoch 44,   batch loss: 0.28015, batch accuracy: 0.91667
Time: 2018-07-14 21:40:40
TRAINING STATS: batch 216/486 in epoch 44,   batch loss: 0.36265, batch accuracy: 0.89250
Time: 2018-07-14 21:40:44
TRAINING STATS: batch 266/486 in epoch 44,   batch loss: 0.35412, batch accuracy: 0.89567
Time: 2018-07-14 21:40:48
TRAINING STATS: batch 316/486 in epoch 44,   batch loss: 0.33725, batch accuracy: 0.90017
Time: 2018-07-14 21:40:52
TRAINING STATS: batch 366/486 in epoch 44,   batch loss: 0.37614, batch accuracy: 0.88950
Time: 2018-07-14 21:40:56
TRAINING STATS: batch 416/486 in epoch 44,   batch loss: 0.38331, batch accuracy: 0.88850
Time: 2018-07-14 21:41:01
TRAINING STATS: batch 466/486 in epoch 44,   batch loss: 0.29050, batch accuracy: 0.91167
Time: 2018-07-14 21:41:04
TRAINING STATS: batch 30/486 in epoch 45,    batch loss: 0.30395, batch accuracy: 0.90817
Time: 2018-07-14 21:41:08
TRAINING STATS: batch 80/486 in epoch 45,    batch loss: 0.35902, batch accuracy: 0.89233
Time: 2018-07-14 21:41:13
TRAINING STATS: batch 130/486 in epoch 45,   batch loss: 0.36291, batch accuracy: 0.89133
Time: 2018-07-14 21:41:16
TRAINING STATS: batch 180/486 in epoch 45,   batch loss: 0.30237, batch accuracy: 0.91367
Time: 2018-07-14 21:41:20
TRAINING STATS: batch 230/486 in epoch 45,   batch loss: 0.35061, batch accuracy: 0.89683
Time: 2018-07-14 21:41:25
TRAINING STATS: batch 280/486 in epoch 45,   batch loss: 0.34088, batch accuracy: 0.89767
Time: 2018-07-14 21:41:29
TRAINING STATS: batch 330/486 in epoch 45,   batch loss: 0.36109, batch accuracy: 0.89483
Time: 2018-07-14 21:41:32
TRAINING STATS: batch 380/486 in epoch 45,   batch loss: 0.31939, batch accuracy: 0.90550
Time: 2018-07-14 21:41:37
TRAINING STATS: batch 430/486 in epoch 45,   batch loss: 0.33471, batch accuracy: 0.89950
Time: 2018-07-14 21:41:41
TRAINING STATS: batch 480/486 in epoch 45,   batch loss: 0.31021, batch accuracy: 0.91000
Time: 2018-07-14 21:41:45
TRAINING STATS: batch 44/486 in epoch 46,    batch loss: 0.33336, batch accuracy: 0.90200
Time: 2018-07-14 21:41:49
TRAINING STATS: batch 94/486 in epoch 46,    batch loss: 0.34841, batch accuracy: 0.89617
Time: 2018-07-14 21:41:53
TRAINING STATS: batch 144/486 in epoch 46,   batch loss: 0.37672, batch accuracy: 0.88817
Time: 2018-07-14 21:41:57
TRAINING STATS: batch 194/486 in epoch 46,   batch loss: 0.38035, batch accuracy: 0.88967
Time: 2018-07-14 21:42:02
TRAINING STATS: batch 244/486 in epoch 46,   batch loss: 0.34862, batch accuracy: 0.89817
Time: 2018-07-14 21:42:05
TRAINING STATS: batch 294/486 in epoch 46,   batch loss: 0.31036, batch accuracy: 0.90967
Time: 2018-07-14 21:42:09
TRAINING STATS: batch 344/486 in epoch 46,   batch loss: 0.38381, batch accuracy: 0.88600
Time: 2018-07-14 21:42:14
TRAINING STATS: batch 394/486 in epoch 46,   batch loss: 0.34998, batch accuracy: 0.89800
Time: 2018-07-14 21:42:17
TRAINING STATS: batch 444/486 in epoch 46,   batch loss: 0.30444, batch accuracy: 0.90783
Time: 2018-07-14 21:42:21
TRAINING STATS: batch 8/486 in epoch 47,     batch loss: 0.33525, batch accuracy: 0.90017
Time: 2018-07-14 21:42:26
TRAINING STATS: batch 58/486 in epoch 47,    batch loss: 0.35534, batch accuracy: 0.89633
Time: 2018-07-14 21:42:30
TRAINING STATS: batch 108/486 in epoch 47,   batch loss: 0.34598, batch accuracy: 0.90450
Time: 2018-07-14 21:42:33
TRAINING STATS: batch 158/486 in epoch 47,   batch loss: 0.35318, batch accuracy: 0.89500
Time: 2018-07-14 21:42:38
TRAINING STATS: batch 208/486 in epoch 47,   batch loss: 0.34377, batch accuracy: 0.90083
Time: 2018-07-14 21:42:42
TRAINING STATS: batch 258/486 in epoch 47,   batch loss: 0.36279, batch accuracy: 0.88817
Time: 2018-07-14 21:42:46
TRAINING STATS: batch 308/486 in epoch 47,   batch loss: 0.34575, batch accuracy: 0.89850
Time: 2018-07-14 21:42:50
TRAINING STATS: batch 358/486 in epoch 47,   batch loss: 0.35238, batch accuracy: 0.89633
Time: 2018-07-14 21:42:54
TRAINING STATS: batch 408/486 in epoch 47,   batch loss: 0.35661, batch accuracy: 0.88817
Time: 2018-07-14 21:42:58
TRAINING STATS: batch 458/486 in epoch 47,   batch loss: 0.36420, batch accuracy: 0.89467
Time: 2018-07-14 21:43:02
TRAINING STATS: batch 22/486 in epoch 48,    batch loss: 0.35912, batch accuracy: 0.89400
Time: 2018-07-14 21:43:06
TRAINING STATS: batch 72/486 in epoch 48,    batch loss: 0.32854, batch accuracy: 0.89900
Time: 2018-07-14 21:43:10
TRAINING STATS: batch 122/486 in epoch 48,   batch loss: 0.29849, batch accuracy: 0.91067
Time: 2018-07-14 21:43:15
TRAINING STATS: batch 172/486 in epoch 48,   batch loss: 0.33286, batch accuracy: 0.90117
Time: 2018-07-14 21:43:18
TRAINING STATS: batch 222/486 in epoch 48,   batch loss: 0.36546, batch accuracy: 0.88900
Time: 2018-07-14 21:43:22
TRAINING STATS: batch 272/486 in epoch 48,   batch loss: 0.36331, batch accuracy: 0.89133
Time: 2018-07-14 21:43:27
TRAINING STATS: batch 322/486 in epoch 48,   batch loss: 0.32856, batch accuracy: 0.89867
Time: 2018-07-14 21:43:31
TRAINING STATS: batch 372/486 in epoch 48,   batch loss: 0.33534, batch accuracy: 0.90117
Time: 2018-07-14 21:43:34
TRAINING STATS: batch 422/486 in epoch 48,   batch loss: 0.30218, batch accuracy: 0.90850
Time: 2018-07-14 21:43:39
TRAINING STATS: batch 472/486 in epoch 48,   batch loss: 0.37240, batch accuracy: 0.88833
Time: 2018-07-14 21:43:43
TRAINING STATS: batch 36/486 in epoch 49,    batch loss: 0.39554, batch accuracy: 0.88250
Time: 2018-07-14 21:43:46
TRAINING STATS: batch 86/486 in epoch 49,    batch loss: 0.31927, batch accuracy: 0.90350
Time: 2018-07-14 21:43:51
TRAINING STATS: batch 136/486 in epoch 49,   batch loss: 0.36494, batch accuracy: 0.89017
Time: 2018-07-14 21:43:55
TRAINING STATS: batch 186/486 in epoch 49,   batch loss: 0.35376, batch accuracy: 0.89533
Time: 2018-07-14 21:43:59
TRAINING STATS: batch 236/486 in epoch 49,   batch loss: 0.34942, batch accuracy: 0.89533
Time: 2018-07-14 21:44:03
TRAINING STATS: batch 286/486 in epoch 49,   batch loss: 0.35891, batch accuracy: 0.89550
Time: 2018-07-14 21:44:07
TRAINING STATS: batch 336/486 in epoch 49,   batch loss: 0.34564, batch accuracy: 0.89717
Time: 2018-07-14 21:44:11
TRAINING STATS: batch 386/486 in epoch 49,   batch loss: 0.37563, batch accuracy: 0.88700
Time: 2018-07-14 21:44:16
TRAINING STATS: batch 436/486 in epoch 49,   batch loss: 0.35769, batch accuracy: 0.89167
Time: 2018-07-14 21:44:19
TRAINING STATS: batch 0/486 in epoch 50,     batch loss: 0.36142, batch accuracy: 0.89433
Time: 2018-07-14 21:44:23
TRAINING STATS: batch 50/486 in epoch 50,    batch loss: 0.32649, batch accuracy: 0.90083
Time: 2018-07-14 21:44:28
TRAINING STATS: batch 100/486 in epoch 50,   batch loss: 0.34910, batch accuracy: 0.89633
Time: 2018-07-14 21:44:31
TRAINING STATS: batch 150/486 in epoch 50,   batch loss: 0.37349, batch accuracy: 0.89017
Time: 2018-07-14 21:44:35
TRAINING STATS: batch 200/486 in epoch 50,   batch loss: 0.30193, batch accuracy: 0.91350
Time: 2018-07-14 21:44:40
TRAINING STATS: batch 250/486 in epoch 50,   batch loss: 0.37782, batch accuracy: 0.88317
Time: 2018-07-14 21:44:44
TRAINING STATS: batch 300/486 in epoch 50,   batch loss: 0.37793, batch accuracy: 0.89117
Time: 2018-07-14 21:44:47
TRAINING STATS: batch 350/486 in epoch 50,   batch loss: 0.34796, batch accuracy: 0.89483
Time: 2018-07-14 21:44:52
TRAINING STATS: batch 400/486 in epoch 50,   batch loss: 0.33396, batch accuracy: 0.90067
Time: 2018-07-14 21:44:56
TRAINING STATS: batch 450/486 in epoch 50,   batch loss: 0.36246, batch accuracy: 0.88833
Time: 2018-07-14 21:44:59
TRAINING STATS: batch 14/486 in epoch 51,    batch loss: 0.32378, batch accuracy: 0.90250
Time: 2018-07-14 21:45:04
TRAINING STATS: batch 64/486 in epoch 51,    batch loss: 0.39514, batch accuracy: 0.88233
Time: 2018-07-14 21:45:08
TRAINING STATS: batch 114/486 in epoch 51,   batch loss: 0.34688, batch accuracy: 0.89833
Time: 2018-07-14 21:45:12
TRAINING STATS: batch 164/486 in epoch 51,   batch loss: 0.32093, batch accuracy: 0.90367
Time: 2018-07-14 21:45:16
TRAINING STATS: batch 214/486 in epoch 51,   batch loss: 0.37067, batch accuracy: 0.88883
Time: 2018-07-14 21:45:20
TRAINING STATS: batch 264/486 in epoch 51,   batch loss: 0.34187, batch accuracy: 0.90267
Time: 2018-07-14 21:45:24
TRAINING STATS: batch 314/486 in epoch 51,   batch loss: 0.37101, batch accuracy: 0.89150
Time: 2018-07-14 21:45:29
TRAINING STATS: batch 364/486 in epoch 51,   batch loss: 0.35264, batch accuracy: 0.89583
Time: 2018-07-14 21:45:32
TRAINING STATS: batch 414/486 in epoch 51,   batch loss: 0.33041, batch accuracy: 0.90567
Time: 2018-07-14 21:45:36
TRAINING STATS: batch 464/486 in epoch 51,   batch loss: 0.31395, batch accuracy: 0.90833
Time: 2018-07-14 21:45:41
TRAINING STATS: batch 28/486 in epoch 52,    batch loss: 0.32591, batch accuracy: 0.90117
Time: 2018-07-14 21:45:44
TRAINING STATS: batch 78/486 in epoch 52,    batch loss: 0.37418, batch accuracy: 0.88833
Time: 2018-07-14 21:45:48
TRAINING STATS: batch 128/486 in epoch 52,   batch loss: 0.35864, batch accuracy: 0.89267
Time: 2018-07-14 21:45:53
TRAINING STATS: batch 178/486 in epoch 52,   batch loss: 0.29647, batch accuracy: 0.91500
Time: 2018-07-14 21:45:57
TRAINING STATS: batch 228/486 in epoch 52,   batch loss: 0.30239, batch accuracy: 0.91200
Time: 2018-07-14 21:46:00
TRAINING STATS: batch 278/486 in epoch 52,   batch loss: 0.33715, batch accuracy: 0.89967
Time: 2018-07-14 21:46:05
TRAINING STATS: batch 328/486 in epoch 52,   batch loss: 0.35186, batch accuracy: 0.89933
Time: 2018-07-14 21:46:09
TRAINING STATS: batch 378/486 in epoch 52,   batch loss: 0.33378, batch accuracy: 0.90417
Time: 2018-07-14 21:46:13
TRAINING STATS: batch 428/486 in epoch 52,   batch loss: 0.37206, batch accuracy: 0.88717
Time: 2018-07-14 21:46:17
TRAINING STATS: batch 478/486 in epoch 52,   batch loss: 0.33033, batch accuracy: 0.90350
Time: 2018-07-14 21:46:21
TRAINING STATS: batch 42/486 in epoch 53,    batch loss: 0.34686, batch accuracy: 0.90067
Time: 2018-07-14 21:46:25
TRAINING STATS: batch 92/486 in epoch 53,    batch loss: 0.35564, batch accuracy: 0.89067
Time: 2018-07-14 21:46:29
TRAINING STATS: batch 142/486 in epoch 53,   batch loss: 0.31712, batch accuracy: 0.90617
Time: 2018-07-14 21:46:33
TRAINING STATS: batch 192/486 in epoch 53,   batch loss: 0.35731, batch accuracy: 0.89600
Time: 2018-07-14 21:46:37
TRAINING STATS: batch 242/486 in epoch 53,   batch loss: 0.33701, batch accuracy: 0.89967
Time: 2018-07-14 21:46:42
TRAINING STATS: batch 292/486 in epoch 53,   batch loss: 0.37304, batch accuracy: 0.89083
Time: 2018-07-14 21:46:45
TRAINING STATS: batch 342/486 in epoch 53,   batch loss: 0.35128, batch accuracy: 0.89783
Time: 2018-07-14 21:46:49
TRAINING STATS: batch 392/486 in epoch 53,   batch loss: 0.33469, batch accuracy: 0.90083
Time: 2018-07-14 21:46:54
TRAINING STATS: batch 442/486 in epoch 53,   batch loss: 0.31569, batch accuracy: 0.90733
Time: 2018-07-14 21:46:58
TRAINING STATS: batch 6/486 in epoch 54,     batch loss: 0.38836, batch accuracy: 0.88983
Time: 2018-07-14 21:47:01
TRAINING STATS: batch 56/486 in epoch 54,    batch loss: 0.36680, batch accuracy: 0.89033
Time: 2018-07-14 21:47:06
TRAINING STATS: batch 106/486 in epoch 54,   batch loss: 0.36216, batch accuracy: 0.89383
Time: 2018-07-14 21:47:10
TRAINING STATS: batch 156/486 in epoch 54,   batch loss: 0.34477, batch accuracy: 0.89633
Time: 2018-07-14 21:47:13
TRAINING STATS: batch 206/486 in epoch 54,   batch loss: 0.36451, batch accuracy: 0.89333
Time: 2018-07-14 21:47:18
TRAINING STATS: batch 256/486 in epoch 54,   batch loss: 0.33765, batch accuracy: 0.89733
Time: 2018-07-14 21:47:22
TRAINING STATS: batch 306/486 in epoch 54,   batch loss: 0.35627, batch accuracy: 0.89650
Time: 2018-07-14 21:47:26
TRAINING STATS: batch 356/486 in epoch 54,   batch loss: 0.34842, batch accuracy: 0.89933
Time: 2018-07-14 21:47:30
TRAINING STATS: batch 406/486 in epoch 54,   batch loss: 0.36924, batch accuracy: 0.89050
Time: 2018-07-14 21:47:34
TRAINING STATS: batch 456/486 in epoch 54,   batch loss: 0.31323, batch accuracy: 0.90750
Time: 2018-07-14 21:47:38
TRAINING STATS: batch 20/486 in epoch 55,    batch loss: 0.34995, batch accuracy: 0.89583
Time: 2018-07-14 21:47:43
TRAINING STATS: batch 70/486 in epoch 55,    batch loss: 0.30129, batch accuracy: 0.90750
Time: 2018-07-14 21:47:46
TRAINING STATS: batch 120/486 in epoch 55,   batch loss: 0.36367, batch accuracy: 0.89367
Time: 2018-07-14 21:47:50
TRAINING STATS: batch 170/486 in epoch 55,   batch loss: 0.31888, batch accuracy: 0.90700
Time: 2018-07-14 21:47:55
TRAINING STATS: batch 220/486 in epoch 55,   batch loss: 0.32537, batch accuracy: 0.90167
Time: 2018-07-14 21:47:58
TRAINING STATS: batch 270/486 in epoch 55,   batch loss: 0.33648, batch accuracy: 0.90117
Time: 2018-07-14 21:48:02
TRAINING STATS: batch 320/486 in epoch 55,   batch loss: 0.32688, batch accuracy: 0.90267
Time: 2018-07-14 21:48:07
TRAINING STATS: batch 370/486 in epoch 55,   batch loss: 0.35092, batch accuracy: 0.89450
Time: 2018-07-14 21:48:11
TRAINING STATS: batch 420/486 in epoch 55,   batch loss: 0.34344, batch accuracy: 0.89800
Time: 2018-07-14 21:48:14
TRAINING STATS: batch 470/486 in epoch 55,   batch loss: 0.36948, batch accuracy: 0.88633
Time: 2018-07-14 21:48:19
TRAINING STATS: batch 34/486 in epoch 56,    batch loss: 0.37133, batch accuracy: 0.89050
Time: 2018-07-14 21:48:23
TRAINING STATS: batch 84/486 in epoch 56,    batch loss: 0.33493, batch accuracy: 0.90300
Time: 2018-07-14 21:48:27
TRAINING STATS: batch 134/486 in epoch 56,   batch loss: 0.35059, batch accuracy: 0.89917
Time: 2018-07-14 21:48:31
TRAINING STATS: batch 184/486 in epoch 56,   batch loss: 0.36523, batch accuracy: 0.89150
Time: 2018-07-14 21:48:35
TRAINING STATS: batch 234/486 in epoch 56,   batch loss: 0.37449, batch accuracy: 0.89017
Time: 2018-07-14 21:48:39
TRAINING STATS: batch 284/486 in epoch 56,   batch loss: 0.36610, batch accuracy: 0.89250
Time: 2018-07-14 21:48:43
TRAINING STATS: batch 334/486 in epoch 56,   batch loss: 0.32479, batch accuracy: 0.90200
Time: 2018-07-14 21:48:47
TRAINING STATS: batch 384/486 in epoch 56,   batch loss: 0.34250, batch accuracy: 0.89850
Time: 2018-07-14 21:48:51
TRAINING STATS: batch 434/486 in epoch 56,   batch loss: 0.37224, batch accuracy: 0.88883
Time: 2018-07-14 21:48:56
TRAINING STATS: batch 484/486 in epoch 56,   batch loss: 0.34074, batch accuracy: 0.89750
Time: 2018-07-14 21:48:59
TRAINING STATS: batch 48/486 in epoch 57,    batch loss: 0.34251, batch accuracy: 0.90200
Time: 2018-07-14 21:49:03
TRAINING STATS: batch 98/486 in epoch 57,    batch loss: 0.30586, batch accuracy: 0.90917
Time: 2018-07-14 21:49:08
TRAINING STATS: batch 148/486 in epoch 57,   batch loss: 0.35113, batch accuracy: 0.89700
Time: 2018-07-14 21:49:12
TRAINING STATS: batch 198/486 in epoch 57,   batch loss: 0.34706, batch accuracy: 0.89783
Time: 2018-07-14 21:49:15
TRAINING STATS: batch 248/486 in epoch 57,   batch loss: 0.35302, batch accuracy: 0.89783
Time: 2018-07-14 21:49:20
TRAINING STATS: batch 298/486 in epoch 57,   batch loss: 0.35805, batch accuracy: 0.89600
Time: 2018-07-14 21:49:24
TRAINING STATS: batch 348/486 in epoch 57,   batch loss: 0.32326, batch accuracy: 0.90400
Time: 2018-07-14 21:49:28
TRAINING STATS: batch 398/486 in epoch 57,   batch loss: 0.34957, batch accuracy: 0.89367
Time: 2018-07-14 21:49:32
TRAINING STATS: batch 448/486 in epoch 57,   batch loss: 0.35859, batch accuracy: 0.89400
Time: 2018-07-14 21:49:36
TRAINING STATS: batch 12/486 in epoch 58,    batch loss: 0.34129, batch accuracy: 0.89917
Time: 2018-07-14 21:49:40
TRAINING STATS: batch 62/486 in epoch 58,    batch loss: 0.36785, batch accuracy: 0.89000
Time: 2018-07-14 21:49:44
TRAINING STATS: batch 112/486 in epoch 58,   batch loss: 0.34144, batch accuracy: 0.89767
Time: 2018-07-14 21:49:48
TRAINING STATS: batch 162/486 in epoch 58,   batch loss: 0.34196, batch accuracy: 0.90050
Time: 2018-07-14 21:49:52
TRAINING STATS: batch 212/486 in epoch 58,   batch loss: 0.33219, batch accuracy: 0.90050
Time: 2018-07-14 21:49:57
TRAINING STATS: batch 262/486 in epoch 58,   batch loss: 0.37392, batch accuracy: 0.88983
Time: 2018-07-14 21:50:00
TRAINING STATS: batch 312/486 in epoch 58,   batch loss: 0.31663, batch accuracy: 0.90600
Time: 2018-07-14 21:50:04
TRAINING STATS: batch 362/486 in epoch 58,   batch loss: 0.36622, batch accuracy: 0.88950
Time: 2018-07-14 21:50:09
TRAINING STATS: batch 412/486 in epoch 58,   batch loss: 0.30761, batch accuracy: 0.91067
Time: 2018-07-14 21:50:13
TRAINING STATS: batch 462/486 in epoch 58,   batch loss: 0.36446, batch accuracy: 0.89400
Time: 2018-07-14 21:50:16
TRAINING STATS: batch 26/486 in epoch 59,    batch loss: 0.38277, batch accuracy: 0.88900
Time: 2018-07-14 21:50:21
TRAINING STATS: batch 76/486 in epoch 59,    batch loss: 0.38658, batch accuracy: 0.88517
Time: 2018-07-14 21:50:25
TRAINING STATS: batch 126/486 in epoch 59,   batch loss: 0.34221, batch accuracy: 0.89583
Time: 2018-07-14 21:50:28
TRAINING STATS: batch 176/486 in epoch 59,   batch loss: 0.33253, batch accuracy: 0.90267
Time: 2018-07-14 21:50:33
TRAINING STATS: batch 226/486 in epoch 59,   batch loss: 0.34248, batch accuracy: 0.89883
Time: 2018-07-14 21:50:37
TRAINING STATS: batch 276/486 in epoch 59,   batch loss: 0.36317, batch accuracy: 0.89217
Time: 2018-07-14 21:50:41
TRAINING STATS: batch 326/486 in epoch 59,   batch loss: 0.32490, batch accuracy: 0.90233
Time: 2018-07-14 21:50:45
TRAINING STATS: batch 376/486 in epoch 59,   batch loss: 0.36156, batch accuracy: 0.89150
Time: 2018-07-14 21:50:49
TRAINING STATS: batch 426/486 in epoch 59,   batch loss: 0.33903, batch accuracy: 0.90017
Time: 2018-07-14 21:50:53
TRAINING STATS: batch 476/486 in epoch 59,   batch loss: 0.31093, batch accuracy: 0.90800
Time: 2018-07-14 21:50:58
TRAINING STATS: batch 40/486 in epoch 60,    batch loss: 0.33136, batch accuracy: 0.90050
Time: 2018-07-14 21:51:01
TRAINING STATS: batch 90/486 in epoch 60,    batch loss: 0.33218, batch accuracy: 0.90417
Time: 2018-07-14 21:51:05
TRAINING STATS: batch 140/486 in epoch 60,   batch loss: 0.30952, batch accuracy: 0.90867
Time: 2018-07-14 21:51:10
TRAINING STATS: batch 190/486 in epoch 60,   batch loss: 0.33219, batch accuracy: 0.90217
Time: 2018-07-14 21:51:13
TRAINING STATS: batch 240/486 in epoch 60,   batch loss: 0.34869, batch accuracy: 0.89867
Time: 2018-07-14 21:51:17
TRAINING STATS: batch 290/486 in epoch 60,   batch loss: 0.36940, batch accuracy: 0.88867
Time: 2018-07-14 21:51:22
TRAINING STATS: batch 340/486 in epoch 60,   batch loss: 0.35163, batch accuracy: 0.89517
Time: 2018-07-14 21:51:26
TRAINING STATS: batch 390/486 in epoch 60,   batch loss: 0.31190, batch accuracy: 0.90533
Time: 2018-07-14 21:51:29
TRAINING STATS: batch 440/486 in epoch 60,   batch loss: 0.36931, batch accuracy: 0.89200
Time: 2018-07-14 21:51:34
TRAINING STATS: batch 4/486 in epoch 61,     batch loss: 0.34824, batch accuracy: 0.89867
Time: 2018-07-14 21:51:38
TRAINING STATS: batch 54/486 in epoch 61,    batch loss: 0.37571, batch accuracy: 0.88900
Time: 2018-07-14 21:51:41
TRAINING STATS: batch 104/486 in epoch 61,   batch loss: 0.33805, batch accuracy: 0.90050
Time: 2018-07-14 21:51:46
TRAINING STATS: batch 154/486 in epoch 61,   batch loss: 0.30568, batch accuracy: 0.91050
Time: 2018-07-14 21:51:50
TRAINING STATS: batch 204/486 in epoch 61,   batch loss: 0.38644, batch accuracy: 0.88083
Time: 2018-07-14 21:51:54
TRAINING STATS: batch 254/486 in epoch 61,   batch loss: 0.33865, batch accuracy: 0.89683
Time: 2018-07-14 21:51:58
TRAINING STATS: batch 304/486 in epoch 61,   batch loss: 0.34194, batch accuracy: 0.89667
Time: 2018-07-14 21:52:02
TRAINING STATS: batch 354/486 in epoch 61,   batch loss: 0.34115, batch accuracy: 0.89967
Time: 2018-07-14 21:52:06
TRAINING STATS: batch 404/486 in epoch 61,   batch loss: 0.32607, batch accuracy: 0.90617
Time: 2018-07-14 21:52:11
TRAINING STATS: batch 454/486 in epoch 61,   batch loss: 0.30634, batch accuracy: 0.91133
Time: 2018-07-14 21:52:14
TRAINING STATS: batch 18/486 in epoch 62,    batch loss: 0.34924, batch accuracy: 0.89783
Time: 2018-07-14 21:52:18
TRAINING STATS: batch 68/486 in epoch 62,    batch loss: 0.31589, batch accuracy: 0.90633
Time: 2018-07-14 21:52:23
TRAINING STATS: batch 118/486 in epoch 62,   batch loss: 0.34309, batch accuracy: 0.89433
Time: 2018-07-14 21:52:26
TRAINING STATS: batch 168/486 in epoch 62,   batch loss: 0.30754, batch accuracy: 0.91050
Time: 2018-07-14 21:52:30
TRAINING STATS: batch 218/486 in epoch 62,   batch loss: 0.32902, batch accuracy: 0.89967
Time: 2018-07-14 21:52:35
TRAINING STATS: batch 268/486 in epoch 62,   batch loss: 0.33145, batch accuracy: 0.90350
Time: 2018-07-14 21:52:39
TRAINING STATS: batch 318/486 in epoch 62,   batch loss: 0.35254, batch accuracy: 0.89550
Time: 2018-07-14 21:52:42
TRAINING STATS: batch 368/486 in epoch 62,   batch loss: 0.36813, batch accuracy: 0.89300
Time: 2018-07-14 21:52:47
TRAINING STATS: batch 418/486 in epoch 62,   batch loss: 0.33767, batch accuracy: 0.89933
Time: 2018-07-14 21:52:51
TRAINING STATS: batch 468/486 in epoch 62,   batch loss: 0.35314, batch accuracy: 0.89467
Time: 2018-07-14 21:52:55
TRAINING STATS: batch 32/486 in epoch 63,    batch loss: 0.31173, batch accuracy: 0.90750
Time: 2018-07-14 21:52:59
TRAINING STATS: batch 82/486 in epoch 63,    batch loss: 0.36108, batch accuracy: 0.89450
Time: 2018-07-14 21:53:03
TRAINING STATS: batch 132/486 in epoch 63,   batch loss: 0.33010, batch accuracy: 0.90267
Time: 2018-07-14 21:53:07
TRAINING STATS: batch 182/486 in epoch 63,   batch loss: 0.35184, batch accuracy: 0.89417
Time: 2018-07-14 21:53:11
TRAINING STATS: batch 232/486 in epoch 63,   batch loss: 0.34902, batch accuracy: 0.89800
Time: 2018-07-14 21:53:15
TRAINING STATS: batch 282/486 in epoch 63,   batch loss: 0.32071, batch accuracy: 0.90383
Time: 2018-07-14 21:53:19
TRAINING STATS: batch 332/486 in epoch 63,   batch loss: 0.36504, batch accuracy: 0.89250
Time: 2018-07-14 21:53:24
TRAINING STATS: batch 382/486 in epoch 63,   batch loss: 0.35500, batch accuracy: 0.89233
Time: 2018-07-14 21:53:27
TRAINING STATS: batch 432/486 in epoch 63,   batch loss: 0.31397, batch accuracy: 0.90617
Time: 2018-07-14 21:53:31
TRAINING STATS: batch 482/486 in epoch 63,   batch loss: 0.31400, batch accuracy: 0.90483
Time: 2018-07-14 21:53:36
TRAINING STATS: batch 46/486 in epoch 64,    batch loss: 0.34205, batch accuracy: 0.89533
Time: 2018-07-14 21:53:40
TRAINING STATS: batch 96/486 in epoch 64,    batch loss: 0.35651, batch accuracy: 0.89467
Time: 2018-07-14 21:53:43
TRAINING STATS: batch 146/486 in epoch 64,   batch loss: 0.34704, batch accuracy: 0.90183
Time: 2018-07-14 21:53:48
TRAINING STATS: batch 196/486 in epoch 64,   batch loss: 0.37079, batch accuracy: 0.88950
Time: 2018-07-14 21:53:52
TRAINING STATS: batch 246/486 in epoch 64,   batch loss: 0.33122, batch accuracy: 0.90250
Time: 2018-07-14 21:53:55
TRAINING STATS: batch 296/486 in epoch 64,   batch loss: 0.35486, batch accuracy: 0.89783
Time: 2018-07-14 21:54:00
TRAINING STATS: batch 346/486 in epoch 64,   batch loss: 0.32251, batch accuracy: 0.90800
Time: 2018-07-14 21:54:04
TRAINING STATS: batch 396/486 in epoch 64,   batch loss: 0.34572, batch accuracy: 0.89567
Time: 2018-07-14 21:54:08
TRAINING STATS: batch 446/486 in epoch 64,   batch loss: 0.34047, batch accuracy: 0.89833
Time: 2018-07-14 21:54:12
TRAINING STATS: batch 10/486 in epoch 65,    batch loss: 0.33994, batch accuracy: 0.90117
Time: 2018-07-14 21:54:16
TRAINING STATS: batch 60/486 in epoch 65,    batch loss: 0.32294, batch accuracy: 0.90600
Time: 2018-07-14 21:54:20
TRAINING STATS: batch 110/486 in epoch 65,   batch loss: 0.34910, batch accuracy: 0.89283
Time: 2018-07-14 21:54:25
TRAINING STATS: batch 160/486 in epoch 65,   batch loss: 0.31871, batch accuracy: 0.90467
Time: 2018-07-14 21:54:28
TRAINING STATS: batch 210/486 in epoch 65,   batch loss: 0.30550, batch accuracy: 0.90817
Time: 2018-07-14 21:54:32
TRAINING STATS: batch 260/486 in epoch 65,   batch loss: 0.36689, batch accuracy: 0.89117
Time: 2018-07-14 21:54:37
TRAINING STATS: batch 310/486 in epoch 65,   batch loss: 0.31225, batch accuracy: 0.90650
Time: 2018-07-14 21:54:40
TRAINING STATS: batch 360/486 in epoch 65,   batch loss: 0.34123, batch accuracy: 0.90067
Time: 2018-07-14 21:54:44
TRAINING STATS: batch 410/486 in epoch 65,   batch loss: 0.31482, batch accuracy: 0.90817
Time: 2018-07-14 21:54:49
TRAINING STATS: batch 460/486 in epoch 65,   batch loss: 0.38445, batch accuracy: 0.88167
Time: 2018-07-14 21:54:53
TRAINING STATS: batch 24/486 in epoch 66,    batch loss: 0.36712, batch accuracy: 0.88967
Time: 2018-07-14 21:54:56
TRAINING STATS: batch 74/486 in epoch 66,    batch loss: 0.34828, batch accuracy: 0.89667
Time: 2018-07-14 21:55:01
TRAINING STATS: batch 124/486 in epoch 66,   batch loss: 0.34527, batch accuracy: 0.89850
Time: 2018-07-14 21:55:05
TRAINING STATS: batch 174/486 in epoch 66,   batch loss: 0.37401, batch accuracy: 0.88700
Time: 2018-07-14 21:55:09
TRAINING STATS: batch 224/486 in epoch 66,   batch loss: 0.36405, batch accuracy: 0.89133
Time: 2018-07-14 21:55:13
TRAINING STATS: batch 274/486 in epoch 66,   batch loss: 0.37047, batch accuracy: 0.88750
Time: 2018-07-14 21:55:17
TRAINING STATS: batch 324/486 in epoch 66,   batch loss: 0.32422, batch accuracy: 0.90417
Time: 2018-07-14 21:55:21
TRAINING STATS: batch 374/486 in epoch 66,   batch loss: 0.37632, batch accuracy: 0.89133
Time: 2018-07-14 21:55:25
TRAINING STATS: batch 424/486 in epoch 66,   batch loss: 0.32302, batch accuracy: 0.90383
Time: 2018-07-14 21:55:29
TRAINING STATS: batch 474/486 in epoch 66,   batch loss: 0.33888, batch accuracy: 0.90067
Time: 2018-07-14 21:55:33
TRAINING STATS: batch 38/486 in epoch 67,    batch loss: 0.37936, batch accuracy: 0.88283
Time: 2018-07-14 21:55:38
TRAINING STATS: batch 88/486 in epoch 67,    batch loss: 0.33746, batch accuracy: 0.89733
Time: 2018-07-14 21:55:41
TRAINING STATS: batch 138/486 in epoch 67,   batch loss: 0.34663, batch accuracy: 0.89900
Time: 2018-07-14 21:55:45
TRAINING STATS: batch 188/486 in epoch 67,   batch loss: 0.34043, batch accuracy: 0.90067
Time: 2018-07-14 21:55:50
TRAINING STATS: batch 238/486 in epoch 67,   batch loss: 0.35130, batch accuracy: 0.89333
Time: 2018-07-14 21:55:54
TRAINING STATS: batch 288/486 in epoch 67,   batch loss: 0.36298, batch accuracy: 0.89517
Time: 2018-07-14 21:55:57
TRAINING STATS: batch 338/486 in epoch 67,   batch loss: 0.33793, batch accuracy: 0.89800
Time: 2018-07-14 21:56:02
TRAINING STATS: batch 388/486 in epoch 67,   batch loss: 0.33365, batch accuracy: 0.90350
Time: 2018-07-14 21:56:06
TRAINING STATS: batch 438/486 in epoch 67,   batch loss: 0.35822, batch accuracy: 0.89517
Time: 2018-07-14 21:56:09
TRAINING STATS: batch 2/486 in epoch 68,     batch loss: 0.34701, batch accuracy: 0.89667
Time: 2018-07-14 21:56:14
TRAINING STATS: batch 52/486 in epoch 68,    batch loss: 0.34211, batch accuracy: 0.89917
Time: 2018-07-14 21:56:18
TRAINING STATS: batch 102/486 in epoch 68,   batch loss: 0.35627, batch accuracy: 0.89283
Time: 2018-07-14 21:56:22
TRAINING STATS: batch 152/486 in epoch 68,   batch loss: 0.31760, batch accuracy: 0.90417
Time: 2018-07-14 21:56:26
TRAINING STATS: batch 202/486 in epoch 68,   batch loss: 0.35548, batch accuracy: 0.89217
Time: 2018-07-14 21:56:30
TRAINING STATS: batch 252/486 in epoch 68,   batch loss: 0.35148, batch accuracy: 0.89750
Time: 2018-07-14 21:56:34
TRAINING STATS: batch 302/486 in epoch 68,   batch loss: 0.34940, batch accuracy: 0.89667
Time: 2018-07-14 21:56:39
TRAINING STATS: batch 352/486 in epoch 68,   batch loss: 0.32452, batch accuracy: 0.90483
Time: 2018-07-14 21:56:42
TRAINING STATS: batch 402/486 in epoch 68,   batch loss: 0.31248, batch accuracy: 0.90750
Time: 2018-07-14 21:56:46
TRAINING STATS: batch 452/486 in epoch 68,   batch loss: 0.35566, batch accuracy: 0.89150
Time: 2018-07-14 21:56:51
TRAINING STATS: batch 16/486 in epoch 69,    batch loss: 0.31498, batch accuracy: 0.90467
Time: 2018-07-14 21:56:55
TRAINING STATS: batch 66/486 in epoch 69,    batch loss: 0.36662, batch accuracy: 0.88933
Time: 2018-07-14 21:56:58
TRAINING STATS: batch 116/486 in epoch 69,   batch loss: 0.31974, batch accuracy: 0.90333
Time: 2018-07-14 21:57:03
TRAINING STATS: batch 166/486 in epoch 69,   batch loss: 0.27967, batch accuracy: 0.91717
Time: 2018-07-14 21:57:07
TRAINING STATS: batch 216/486 in epoch 69,   batch loss: 0.35691, batch accuracy: 0.89250
Time: 2018-07-14 21:57:10
TRAINING STATS: batch 266/486 in epoch 69,   batch loss: 0.34396, batch accuracy: 0.89883
Time: 2018-07-14 21:57:15
TRAINING STATS: batch 316/486 in epoch 69,   batch loss: 0.33739, batch accuracy: 0.90050
Time: 2018-07-14 21:57:19
TRAINING STATS: batch 366/486 in epoch 69,   batch loss: 0.37577, batch accuracy: 0.88700
Time: 2018-07-14 21:57:23
TRAINING STATS: batch 416/486 in epoch 69,   batch loss: 0.36021, batch accuracy: 0.89200
Time: 2018-07-14 21:57:27
TRAINING STATS: batch 466/486 in epoch 69,   batch loss: 0.28668, batch accuracy: 0.91667
Time: 2018-07-14 21:57:31
TRAINING STATS: batch 30/486 in epoch 70,    batch loss: 0.30834, batch accuracy: 0.91067
Time: 2018-07-14 21:57:35
TRAINING STATS: batch 80/486 in epoch 70,    batch loss: 0.36102, batch accuracy: 0.89117
Time: 2018-07-14 21:57:40
TRAINING STATS: batch 130/486 in epoch 70,   batch loss: 0.35604, batch accuracy: 0.89283
Time: 2018-07-14 21:57:43
TRAINING STATS: batch 180/486 in epoch 70,   batch loss: 0.30598, batch accuracy: 0.90967
Time: 2018-07-14 21:57:47
TRAINING STATS: batch 230/486 in epoch 70,   batch loss: 0.33790, batch accuracy: 0.89917
Time: 2018-07-14 21:57:52
TRAINING STATS: batch 280/486 in epoch 70,   batch loss: 0.33697, batch accuracy: 0.90083
Time: 2018-07-14 21:57:55
TRAINING STATS: batch 330/486 in epoch 70,   batch loss: 0.35595, batch accuracy: 0.89217
Time: 2018-07-14 21:57:59
TRAINING STATS: batch 380/486 in epoch 70,   batch loss: 0.31747, batch accuracy: 0.90700
Time: 2018-07-14 21:58:04
TRAINING STATS: batch 430/486 in epoch 70,   batch loss: 0.33111, batch accuracy: 0.90017
Time: 2018-07-14 21:58:08
TRAINING STATS: batch 480/486 in epoch 70,   batch loss: 0.31149, batch accuracy: 0.90950
Time: 2018-07-14 21:58:11
TRAINING STATS: batch 44/486 in epoch 71,    batch loss: 0.33560, batch accuracy: 0.89817
Time: 2018-07-14 21:58:16
TRAINING STATS: batch 94/486 in epoch 71,    batch loss: 0.34813, batch accuracy: 0.89633
Time: 2018-07-14 21:58:20
TRAINING STATS: batch 144/486 in epoch 71,   batch loss: 0.38326, batch accuracy: 0.88600
Time: 2018-07-14 21:58:24
TRAINING STATS: batch 194/486 in epoch 71,   batch loss: 0.39908, batch accuracy: 0.88633
Time: 2018-07-14 21:58:28
TRAINING STATS: batch 244/486 in epoch 71,   batch loss: 0.35792, batch accuracy: 0.89267
Time: 2018-07-14 21:58:32
TRAINING STATS: batch 294/486 in epoch 71,   batch loss: 0.32332, batch accuracy: 0.90317
Time: 2018-07-14 21:58:36
TRAINING STATS: batch 344/486 in epoch 71,   batch loss: 0.38105, batch accuracy: 0.88833
Time: 2018-07-14 21:58:40
TRAINING STATS: batch 394/486 in epoch 71,   batch loss: 0.35373, batch accuracy: 0.89800
Time: 2018-07-14 21:58:44
TRAINING STATS: batch 444/486 in epoch 71,   batch loss: 0.30908, batch accuracy: 0.90567
Time: 2018-07-14 21:58:48
TRAINING STATS: batch 8/486 in epoch 72,     batch loss: 0.34222, batch accuracy: 0.89767
Time: 2018-07-14 21:58:53
TRAINING STATS: batch 58/486 in epoch 72,    batch loss: 0.36563, batch accuracy: 0.89000
Time: 2018-07-14 21:58:56
TRAINING STATS: batch 108/486 in epoch 72,   batch loss: 0.37176, batch accuracy: 0.89017
Time: 2018-07-14 21:59:00
TRAINING STATS: batch 158/486 in epoch 72,   batch loss: 0.36525, batch accuracy: 0.89233
Time: 2018-07-14 21:59:05
TRAINING STATS: batch 208/486 in epoch 72,   batch loss: 0.37791, batch accuracy: 0.88817
Time: 2018-07-14 21:59:09
TRAINING STATS: batch 258/486 in epoch 72,   batch loss: 0.38601, batch accuracy: 0.88317
Time: 2018-07-14 21:59:12
TRAINING STATS: batch 308/486 in epoch 72,   batch loss: 0.36614, batch accuracy: 0.89033
Time: 2018-07-14 21:59:17
TRAINING STATS: batch 358/486 in epoch 72,   batch loss: 0.37800, batch accuracy: 0.89117
Time: 2018-07-14 21:59:21
TRAINING STATS: batch 408/486 in epoch 72,   batch loss: 0.38225, batch accuracy: 0.88683
Time: 2018-07-14 21:59:24
TRAINING STATS: batch 458/486 in epoch 72,   batch loss: 0.38317, batch accuracy: 0.88800
Time: 2018-07-14 21:59:29
TRAINING STATS: batch 22/486 in epoch 73,    batch loss: 0.37743, batch accuracy: 0.88683
Time: 2018-07-14 21:59:33
TRAINING STATS: batch 72/486 in epoch 73,    batch loss: 0.35182, batch accuracy: 0.89400
Time: 2018-07-14 21:59:37
TRAINING STATS: batch 122/486 in epoch 73,   batch loss: 0.32014, batch accuracy: 0.90050
Time: 2018-07-14 21:59:41
TRAINING STATS: batch 172/486 in epoch 73,   batch loss: 0.35629, batch accuracy: 0.89300
Time: 2018-07-14 21:59:45
TRAINING STATS: batch 222/486 in epoch 73,   batch loss: 0.38107, batch accuracy: 0.88467
Time: 2018-07-14 21:59:49
TRAINING STATS: batch 272/486 in epoch 73,   batch loss: 0.38561, batch accuracy: 0.88500
Time: 2018-07-14 21:59:54
TRAINING STATS: batch 322/486 in epoch 73,   batch loss: 0.34345, batch accuracy: 0.89717
Time: 2018-07-14 21:59:57
TRAINING STATS: batch 372/486 in epoch 73,   batch loss: 0.35505, batch accuracy: 0.89500
Time: 2018-07-14 22:00:01
TRAINING STATS: batch 422/486 in epoch 73,   batch loss: 0.32771, batch accuracy: 0.90183
Time: 2018-07-14 22:00:06
TRAINING STATS: batch 472/486 in epoch 73,   batch loss: 0.39361, batch accuracy: 0.88500
Time: 2018-07-14 22:00:09
TRAINING STATS: batch 36/486 in epoch 74,    batch loss: 0.40735, batch accuracy: 0.87833
Time: 2018-07-14 22:00:13
TRAINING STATS: batch 86/486 in epoch 74,    batch loss: 0.33994, batch accuracy: 0.89633
Time: 2018-07-14 22:00:18
TRAINING STATS: batch 136/486 in epoch 74,   batch loss: 0.38510, batch accuracy: 0.88283
Time: 2018-07-14 22:00:22
TRAINING STATS: batch 186/486 in epoch 74,   batch loss: 0.37003, batch accuracy: 0.89483
Time: 2018-07-14 22:00:25
TRAINING STATS: batch 236/486 in epoch 74,   batch loss: 0.37923, batch accuracy: 0.88850
Time: 2018-07-14 22:00:30
TRAINING STATS: batch 286/486 in epoch 74,   batch loss: 0.38276, batch accuracy: 0.89117
Time: 2018-07-14 22:00:34
TRAINING STATS: batch 336/486 in epoch 74,   batch loss: 0.36684, batch accuracy: 0.88800
Time: 2018-07-14 22:00:37
TRAINING STATS: batch 386/486 in epoch 74,   batch loss: 0.38510, batch accuracy: 0.88067
Time: 2018-07-14 22:00:42
TRAINING STATS: batch 436/486 in epoch 74,   batch loss: 0.36943, batch accuracy: 0.88867
Time: 2018-07-14 22:00:46
TRAINING STATS: batch 0/486 in epoch 75,     batch loss: 0.36699, batch accuracy: 0.88817
Time: 2018-07-14 22:00:50
TRAINING STATS: batch 50/486 in epoch 75,    batch loss: 0.33501, batch accuracy: 0.90183
Time: 2018-07-14 22:00:54
TRAINING STATS: batch 100/486 in epoch 75,   batch loss: 0.35691, batch accuracy: 0.89033
Time: 2018-07-14 22:00:58
TRAINING STATS: batch 150/486 in epoch 75,   batch loss: 0.37530, batch accuracy: 0.88800
Time: 2018-07-14 22:01:02
TRAINING STATS: batch 200/486 in epoch 75,   batch loss: 0.30592, batch accuracy: 0.90817
Time: 2018-07-14 22:01:07
TRAINING STATS: batch 250/486 in epoch 75,   batch loss: 0.39192, batch accuracy: 0.88133
Time: 2018-07-14 22:01:10
TRAINING STATS: batch 300/486 in epoch 75,   batch loss: 0.38035, batch accuracy: 0.88700
Time: 2018-07-14 22:01:14
TRAINING STATS: batch 350/486 in epoch 75,   batch loss: 0.35649, batch accuracy: 0.89300
Time: 2018-07-14 22:01:19
TRAINING STATS: batch 400/486 in epoch 75,   batch loss: 0.32600, batch accuracy: 0.90250
Time: 2018-07-14 22:01:22
TRAINING STATS: batch 450/486 in epoch 75,   batch loss: 0.36519, batch accuracy: 0.89200
Time: 2018-07-14 22:01:26
TRAINING STATS: batch 14/486 in epoch 76,    batch loss: 0.31951, batch accuracy: 0.90483
Time: 2018-07-14 22:01:31
TRAINING STATS: batch 64/486 in epoch 76,    batch loss: 0.40014, batch accuracy: 0.88200
Time: 2018-07-14 22:01:35
TRAINING STATS: batch 114/486 in epoch 76,   batch loss: 0.35723, batch accuracy: 0.89317
Time: 2018-07-14 22:01:38
TRAINING STATS: batch 164/486 in epoch 76,   batch loss: 0.32848, batch accuracy: 0.89933
Time: 2018-07-14 22:01:43
TRAINING STATS: batch 214/486 in epoch 76,   batch loss: 0.35757, batch accuracy: 0.89583
Time: 2018-07-14 22:01:47
TRAINING STATS: batch 264/486 in epoch 76,   batch loss: 0.35098, batch accuracy: 0.89800
Time: 2018-07-14 22:01:51
TRAINING STATS: batch 314/486 in epoch 76,   batch loss: 0.38488, batch accuracy: 0.89017
Time: 2018-07-14 22:01:55
TRAINING STATS: batch 364/486 in epoch 76,   batch loss: 0.36369, batch accuracy: 0.89617
Time: 2018-07-14 22:01:59
TRAINING STATS: batch 414/486 in epoch 76,   batch loss: 0.32987, batch accuracy: 0.90317
Time: 2018-07-14 22:02:03
TRAINING STATS: batch 464/486 in epoch 76,   batch loss: 0.32283, batch accuracy: 0.90400
Time: 2018-07-14 22:02:08
TRAINING STATS: batch 28/486 in epoch 77,    batch loss: 0.34315, batch accuracy: 0.89517
Time: 2018-07-14 22:02:11
TRAINING STATS: batch 78/486 in epoch 77,    batch loss: 0.36939, batch accuracy: 0.89267
Time: 2018-07-14 22:02:15
TRAINING STATS: batch 128/486 in epoch 77,   batch loss: 0.35574, batch accuracy: 0.89583
Time: 2018-07-14 22:02:20
TRAINING STATS: batch 178/486 in epoch 77,   batch loss: 0.29908, batch accuracy: 0.91267
Time: 2018-07-14 22:02:23
TRAINING STATS: batch 228/486 in epoch 77,   batch loss: 0.30288, batch accuracy: 0.90733
Time: 2018-07-14 22:02:27
TRAINING STATS: batch 278/486 in epoch 77,   batch loss: 0.33150, batch accuracy: 0.90033
Time: 2018-07-14 22:02:32
TRAINING STATS: batch 328/486 in epoch 77,   batch loss: 0.35947, batch accuracy: 0.89600
Time: 2018-07-14 22:02:36
TRAINING STATS: batch 378/486 in epoch 77,   batch loss: 0.33031, batch accuracy: 0.90417
Time: 2018-07-14 22:02:39
TRAINING STATS: batch 428/486 in epoch 77,   batch loss: 0.37415, batch accuracy: 0.88833
Time: 2018-07-14 22:02:44
TRAINING STATS: batch 478/486 in epoch 77,   batch loss: 0.32942, batch accuracy: 0.90183
Time: 2018-07-14 22:02:48
TRAINING STATS: batch 42/486 in epoch 78,    batch loss: 0.33631, batch accuracy: 0.89850
Time: 2018-07-14 22:02:51
TRAINING STATS: batch 92/486 in epoch 78,    batch loss: 0.34565, batch accuracy: 0.89467
Time: 2018-07-14 22:02:56
TRAINING STATS: batch 142/486 in epoch 78,   batch loss: 0.30867, batch accuracy: 0.90750
Time: 2018-07-14 22:03:00
TRAINING STATS: batch 192/486 in epoch 78,   batch loss: 0.35847, batch accuracy: 0.89267
Time: 2018-07-14 22:03:04
TRAINING STATS: batch 242/486 in epoch 78,   batch loss: 0.34078, batch accuracy: 0.89883
Time: 2018-07-14 22:03:09
TRAINING STATS: batch 292/486 in epoch 78,   batch loss: 0.35709, batch accuracy: 0.89433
Time: 2018-07-14 22:03:12
TRAINING STATS: batch 342/486 in epoch 78,   batch loss: 0.35102, batch accuracy: 0.89833
Time: 2018-07-14 22:03:16
TRAINING STATS: batch 392/486 in epoch 78,   batch loss: 0.31302, batch accuracy: 0.90633
Time: 2018-07-14 22:03:21
TRAINING STATS: batch 442/486 in epoch 78,   batch loss: 0.30761, batch accuracy: 0.90617
Time: 2018-07-14 22:03:24
TRAINING STATS: batch 6/486 in epoch 79,     batch loss: 0.38038, batch accuracy: 0.88883
Time: 2018-07-14 22:03:28
TRAINING STATS: batch 56/486 in epoch 79,    batch loss: 0.34913, batch accuracy: 0.89683
Time: 2018-07-14 22:03:33
TRAINING STATS: batch 106/486 in epoch 79,   batch loss: 0.37397, batch accuracy: 0.88717
Time: 2018-07-14 22:03:36
TRAINING STATS: batch 156/486 in epoch 79,   batch loss: 0.33830, batch accuracy: 0.89833
Time: 2018-07-14 22:03:40
TRAINING STATS: batch 206/486 in epoch 79,   batch loss: 0.35915, batch accuracy: 0.89417
Time: 2018-07-14 22:03:45
TRAINING STATS: batch 256/486 in epoch 79,   batch loss: 0.33208, batch accuracy: 0.90067
Time: 2018-07-14 22:03:49
TRAINING STATS: batch 306/486 in epoch 79,   batch loss: 0.36111, batch accuracy: 0.89483
Time: 2018-07-14 22:03:52
TRAINING STATS: batch 356/486 in epoch 79,   batch loss: 0.33482, batch accuracy: 0.90467
Time: 2018-07-14 22:03:57
TRAINING STATS: batch 406/486 in epoch 79,   batch loss: 0.35705, batch accuracy: 0.89300
Time: 2018-07-14 22:04:01
TRAINING STATS: batch 456/486 in epoch 79,   batch loss: 0.30934, batch accuracy: 0.90967
Time: 2018-07-14 22:04:05
TRAINING STATS: batch 20/486 in epoch 80,    batch loss: 0.33312, batch accuracy: 0.90283
Time: 2018-07-14 22:04:09
TRAINING STATS: batch 70/486 in epoch 80,    batch loss: 0.28018, batch accuracy: 0.91667
Time: 2018-07-14 22:04:13
TRAINING STATS: batch 120/486 in epoch 80,   batch loss: 0.34466, batch accuracy: 0.89783
Time: 2018-07-14 22:04:17
TRAINING STATS: batch 170/486 in epoch 80,   batch loss: 0.31485, batch accuracy: 0.90950
Time: 2018-07-14 22:04:22
TRAINING STATS: batch 220/486 in epoch 80,   batch loss: 0.32220, batch accuracy: 0.90267
Time: 2018-07-14 22:04:25
TRAINING STATS: batch 270/486 in epoch 80,   batch loss: 0.32882, batch accuracy: 0.90217
Time: 2018-07-14 22:04:29
TRAINING STATS: batch 320/486 in epoch 80,   batch loss: 0.33149, batch accuracy: 0.90233
Time: 2018-07-14 22:04:34
TRAINING STATS: batch 370/486 in epoch 80,   batch loss: 0.35050, batch accuracy: 0.89600
Time: 2018-07-14 22:04:37
TRAINING STATS: batch 420/486 in epoch 80,   batch loss: 0.33581, batch accuracy: 0.90183
Time: 2018-07-14 22:04:41
TRAINING STATS: batch 470/486 in epoch 80,   batch loss: 0.36012, batch accuracy: 0.89300
Time: 2018-07-14 22:04:46
TRAINING STATS: batch 34/486 in epoch 81,    batch loss: 0.36554, batch accuracy: 0.89117
Time: 2018-07-14 22:04:50
TRAINING STATS: batch 84/486 in epoch 81,    batch loss: 0.34352, batch accuracy: 0.89817
Time: 2018-07-14 22:04:53
TRAINING STATS: batch 134/486 in epoch 81,   batch loss: 0.33301, batch accuracy: 0.90167
Time: 2018-07-14 22:04:58
TRAINING STATS: batch 184/486 in epoch 81,   batch loss: 0.35768, batch accuracy: 0.89367
Time: 2018-07-14 22:05:02
TRAINING STATS: batch 234/486 in epoch 81,   batch loss: 0.36030, batch accuracy: 0.89333
Time: 2018-07-14 22:05:06
TRAINING STATS: batch 284/486 in epoch 81,   batch loss: 0.35345, batch accuracy: 0.89033
Time: 2018-07-14 22:05:10
TRAINING STATS: batch 334/486 in epoch 81,   batch loss: 0.34640, batch accuracy: 0.90100
Time: 2018-07-14 22:05:14
TRAINING STATS: batch 384/486 in epoch 81,   batch loss: 0.32144, batch accuracy: 0.90483
Time: 2018-07-14 22:05:18
TRAINING STATS: batch 434/486 in epoch 81,   batch loss: 0.36380, batch accuracy: 0.89083
Time: 2018-07-14 22:05:23
TRAINING STATS: batch 484/486 in epoch 81,   batch loss: 0.34329, batch accuracy: 0.89833
Time: 2018-07-14 22:05:26
TRAINING STATS: batch 48/486 in epoch 82,    batch loss: 0.33237, batch accuracy: 0.90183
Time: 2018-07-14 22:05:30
TRAINING STATS: batch 98/486 in epoch 82,    batch loss: 0.30175, batch accuracy: 0.91300
Time: 2018-07-14 22:05:35
TRAINING STATS: batch 148/486 in epoch 82,   batch loss: 0.34405, batch accuracy: 0.89800
Time: 2018-07-14 22:05:38
TRAINING STATS: batch 198/486 in epoch 82,   batch loss: 0.35945, batch accuracy: 0.89417
Time: 2018-07-14 22:05:42
TRAINING STATS: batch 248/486 in epoch 82,   batch loss: 0.36598, batch accuracy: 0.89033
Time: 2018-07-14 22:05:47
TRAINING STATS: batch 298/486 in epoch 82,   batch loss: 0.35277, batch accuracy: 0.89667
Time: 2018-07-14 22:05:51
TRAINING STATS: batch 348/486 in epoch 82,   batch loss: 0.32462, batch accuracy: 0.90433
Time: 2018-07-14 22:05:54
TRAINING STATS: batch 398/486 in epoch 82,   batch loss: 0.36027, batch accuracy: 0.89117
Time: 2018-07-14 22:05:59
TRAINING STATS: batch 448/486 in epoch 82,   batch loss: 0.37413, batch accuracy: 0.89033
Time: 2018-07-14 22:06:03
TRAINING STATS: batch 12/486 in epoch 83,    batch loss: 0.33818, batch accuracy: 0.89933
Time: 2018-07-14 22:06:06
TRAINING STATS: batch 62/486 in epoch 83,    batch loss: 0.34983, batch accuracy: 0.89467
Time: 2018-07-14 22:06:11
TRAINING STATS: batch 112/486 in epoch 83,   batch loss: 0.33172, batch accuracy: 0.90133
Time: 2018-07-14 22:06:15
TRAINING STATS: batch 162/486 in epoch 83,   batch loss: 0.33340, batch accuracy: 0.90283
Time: 2018-07-14 22:06:19
TRAINING STATS: batch 212/486 in epoch 83,   batch loss: 0.33692, batch accuracy: 0.89967
Time: 2018-07-14 22:06:24
TRAINING STATS: batch 262/486 in epoch 83,   batch loss: 0.36749, batch accuracy: 0.88933
Time: 2018-07-14 22:06:27
TRAINING STATS: batch 312/486 in epoch 83,   batch loss: 0.30737, batch accuracy: 0.90683
Time: 2018-07-14 22:06:31
TRAINING STATS: batch 362/486 in epoch 83,   batch loss: 0.38058, batch accuracy: 0.88850
Time: 2018-07-14 22:06:36
TRAINING STATS: batch 412/486 in epoch 83,   batch loss: 0.31917, batch accuracy: 0.90483
Time: 2018-07-14 22:06:39
TRAINING STATS: batch 462/486 in epoch 83,   batch loss: 0.37442, batch accuracy: 0.89083
Time: 2018-07-14 22:06:43
TRAINING STATS: batch 26/486 in epoch 84,    batch loss: 0.36963, batch accuracy: 0.89283
Time: 2018-07-14 22:06:48
TRAINING STATS: batch 76/486 in epoch 84,    batch loss: 0.39065, batch accuracy: 0.88667
Time: 2018-07-14 22:06:52
TRAINING STATS: batch 126/486 in epoch 84,   batch loss: 0.35010, batch accuracy: 0.89333
Time: 2018-07-14 22:06:55
TRAINING STATS: batch 176/486 in epoch 84,   batch loss: 0.31938, batch accuracy: 0.90550
Time: 2018-07-14 22:07:00
TRAINING STATS: batch 226/486 in epoch 84,   batch loss: 0.32812, batch accuracy: 0.89833
Time: 2018-07-14 22:07:04
TRAINING STATS: batch 276/486 in epoch 84,   batch loss: 0.35480, batch accuracy: 0.89500
Time: 2018-07-14 22:07:07
TRAINING STATS: batch 326/486 in epoch 84,   batch loss: 0.32289, batch accuracy: 0.90417
Time: 2018-07-14 22:07:12
TRAINING STATS: batch 376/486 in epoch 84,   batch loss: 0.35714, batch accuracy: 0.89400
Time: 2018-07-14 22:07:16
TRAINING STATS: batch 426/486 in epoch 84,   batch loss: 0.32660, batch accuracy: 0.90150
Time: 2018-07-14 22:07:20
TRAINING STATS: batch 476/486 in epoch 84,   batch loss: 0.31590, batch accuracy: 0.90700
Time: 2018-07-14 22:07:24
TRAINING STATS: batch 40/486 in epoch 85,    batch loss: 0.33239, batch accuracy: 0.90567
Time: 2018-07-14 22:07:28
TRAINING STATS: batch 90/486 in epoch 85,    batch loss: 0.32718, batch accuracy: 0.90617
Time: 2018-07-14 22:07:32
TRAINING STATS: batch 140/486 in epoch 85,   batch loss: 0.29826, batch accuracy: 0.91050
Time: 2018-07-14 22:07:37
TRAINING STATS: batch 190/486 in epoch 85,   batch loss: 0.32824, batch accuracy: 0.90417
Time: 2018-07-14 22:07:40
TRAINING STATS: batch 240/486 in epoch 85,   batch loss: 0.33364, batch accuracy: 0.90450
Time: 2018-07-14 22:07:44
TRAINING STATS: batch 290/486 in epoch 85,   batch loss: 0.35559, batch accuracy: 0.89417
Time: 2018-07-14 22:07:49
TRAINING STATS: batch 340/486 in epoch 85,   batch loss: 0.36060, batch accuracy: 0.89500
Time: 2018-07-14 22:07:53
TRAINING STATS: batch 390/486 in epoch 85,   batch loss: 0.31393, batch accuracy: 0.90317
Time: 2018-07-14 22:07:56
TRAINING STATS: batch 440/486 in epoch 85,   batch loss: 0.36934, batch accuracy: 0.88783
Time: 2018-07-14 22:08:01
TRAINING STATS: batch 4/486 in epoch 86,     batch loss: 0.38973, batch accuracy: 0.88800
Time: 2018-07-14 22:08:05
TRAINING STATS: batch 54/486 in epoch 86,    batch loss: 0.39884, batch accuracy: 0.88400
Time: 2018-07-14 22:08:08
TRAINING STATS: batch 104/486 in epoch 86,   batch loss: 0.36314, batch accuracy: 0.89383
Time: 2018-07-14 22:08:13
TRAINING STATS: batch 154/486 in epoch 86,   batch loss: 0.32628, batch accuracy: 0.90133
Time: 2018-07-14 22:08:17
TRAINING STATS: batch 204/486 in epoch 86,   batch loss: 0.39010, batch accuracy: 0.88133
Time: 2018-07-14 22:08:21
TRAINING STATS: batch 254/486 in epoch 86,   batch loss: 0.34713, batch accuracy: 0.89700
Time: 2018-07-14 22:08:25
TRAINING STATS: batch 304/486 in epoch 86,   batch loss: 0.34526, batch accuracy: 0.89917
Time: 2018-07-14 22:08:29
TRAINING STATS: batch 354/486 in epoch 86,   batch loss: 0.36019, batch accuracy: 0.89367
Time: 2018-07-14 22:08:33
TRAINING STATS: batch 404/486 in epoch 86,   batch loss: 0.33641, batch accuracy: 0.90233
Time: 2018-07-14 22:08:38
TRAINING STATS: batch 454/486 in epoch 86,   batch loss: 0.31262, batch accuracy: 0.91067
Time: 2018-07-14 22:08:41
TRAINING STATS: batch 18/486 in epoch 87,    batch loss: 0.35125, batch accuracy: 0.89500
Time: 2018-07-14 22:08:45
TRAINING STATS: batch 68/486 in epoch 87,    batch loss: 0.30982, batch accuracy: 0.90900
Time: 2018-07-14 22:08:50
TRAINING STATS: batch 118/486 in epoch 87,   batch loss: 0.37600, batch accuracy: 0.88733
Time: 2018-07-14 22:08:53
TRAINING STATS: batch 168/486 in epoch 87,   batch loss: 0.32381, batch accuracy: 0.90267
Time: 2018-07-14 22:08:57
TRAINING STATS: batch 218/486 in epoch 87,   batch loss: 0.33876, batch accuracy: 0.89933
Time: 2018-07-14 22:09:02
TRAINING STATS: batch 268/486 in epoch 87,   batch loss: 0.34433, batch accuracy: 0.89833
Time: 2018-07-14 22:09:06
TRAINING STATS: batch 318/486 in epoch 87,   batch loss: 0.36471, batch accuracy: 0.89150
Time: 2018-07-14 22:09:09
TRAINING STATS: batch 368/486 in epoch 87,   batch loss: 0.38160, batch accuracy: 0.88717
Time: 2018-07-14 22:09:14
TRAINING STATS: batch 418/486 in epoch 87,   batch loss: 0.33699, batch accuracy: 0.89967
Time: 2018-07-14 22:09:18
TRAINING STATS: batch 468/486 in epoch 87,   batch loss: 0.38271, batch accuracy: 0.88733
Time: 2018-07-14 22:09:21
TRAINING STATS: batch 32/486 in epoch 88,    batch loss: 0.30512, batch accuracy: 0.90617
Time: 2018-07-14 22:09:26
TRAINING STATS: batch 82/486 in epoch 88,    batch loss: 0.37461, batch accuracy: 0.88767
Time: 2018-07-14 22:09:30
TRAINING STATS: batch 132/486 in epoch 88,   batch loss: 0.33921, batch accuracy: 0.89917
Time: 2018-07-14 22:09:34
TRAINING STATS: batch 182/486 in epoch 88,   batch loss: 0.34896, batch accuracy: 0.89750
Time: 2018-07-14 22:09:38
TRAINING STATS: batch 232/486 in epoch 88,   batch loss: 0.36973, batch accuracy: 0.89367
Time: 2018-07-14 22:09:42
TRAINING STATS: batch 282/486 in epoch 88,   batch loss: 0.33244, batch accuracy: 0.90017
Time: 2018-07-14 22:09:46
TRAINING STATS: batch 332/486 in epoch 88,   batch loss: 0.37213, batch accuracy: 0.89167
Time: 2018-07-14 22:09:51
TRAINING STATS: batch 382/486 in epoch 88,   batch loss: 0.35628, batch accuracy: 0.89300
Time: 2018-07-14 22:09:54
TRAINING STATS: batch 432/486 in epoch 88,   batch loss: 0.31276, batch accuracy: 0.90533
Time: 2018-07-14 22:09:58
TRAINING STATS: batch 482/486 in epoch 88,   batch loss: 0.33092, batch accuracy: 0.89950
Time: 2018-07-14 22:10:03
TRAINING STATS: batch 46/486 in epoch 89,    batch loss: 0.34937, batch accuracy: 0.89467
Time: 2018-07-14 22:10:06
TRAINING STATS: batch 96/486 in epoch 89,    batch loss: 0.36796, batch accuracy: 0.88933
Time: 2018-07-14 22:10:10
TRAINING STATS: batch 146/486 in epoch 89,   batch loss: 0.34832, batch accuracy: 0.89767
Time: 2018-07-14 22:10:15
TRAINING STATS: batch 196/486 in epoch 89,   batch loss: 0.38802, batch accuracy: 0.88417
Time: 2018-07-14 22:10:19
TRAINING STATS: batch 246/486 in epoch 89,   batch loss: 0.35758, batch accuracy: 0.89533
Time: 2018-07-14 22:10:22
TRAINING STATS: batch 296/486 in epoch 89,   batch loss: 0.38558, batch accuracy: 0.88433
Time: 2018-07-14 22:10:27
TRAINING STATS: batch 346/486 in epoch 89,   batch loss: 0.35400, batch accuracy: 0.89767
Time: 2018-07-14 22:10:31
TRAINING STATS: batch 396/486 in epoch 89,   batch loss: 0.37744, batch accuracy: 0.88567
Time: 2018-07-14 22:10:35
TRAINING STATS: batch 446/486 in epoch 89,   batch loss: 0.36167, batch accuracy: 0.89167
Time: 2018-07-14 22:10:39
TRAINING STATS: batch 10/486 in epoch 90,    batch loss: 0.35507, batch accuracy: 0.89350
Time: 2018-07-14 22:10:43
TRAINING STATS: batch 60/486 in epoch 90,    batch loss: 0.34180, batch accuracy: 0.89750
Time: 2018-07-14 22:10:47
TRAINING STATS: batch 110/486 in epoch 90,   batch loss: 0.37921, batch accuracy: 0.88767
Time: 2018-07-14 22:10:51
TRAINING STATS: batch 160/486 in epoch 90,   batch loss: 0.33456, batch accuracy: 0.90017
Time: 2018-07-14 22:10:55
TRAINING STATS: batch 210/486 in epoch 90,   batch loss: 0.32344, batch accuracy: 0.90700
Time: 2018-07-14 22:10:59
TRAINING STATS: batch 260/486 in epoch 90,   batch loss: 0.37687, batch accuracy: 0.89100
Time: 2018-07-14 22:11:04
TRAINING STATS: batch 310/486 in epoch 90,   batch loss: 0.33393, batch accuracy: 0.90233
Time: 2018-07-14 22:11:07
TRAINING STATS: batch 360/486 in epoch 90,   batch loss: 0.35912, batch accuracy: 0.89750
Time: 2018-07-14 22:11:11
TRAINING STATS: batch 410/486 in epoch 90,   batch loss: 0.32440, batch accuracy: 0.90483
Time: 2018-07-14 22:11:16
TRAINING STATS: batch 460/486 in epoch 90,   batch loss: 0.40691, batch accuracy: 0.87867
Time: 2018-07-14 22:11:20
TRAINING STATS: batch 24/486 in epoch 91,    batch loss: 0.38860, batch accuracy: 0.88300
Time: 2018-07-14 22:11:23
TRAINING STATS: batch 74/486 in epoch 91,    batch loss: 0.39032, batch accuracy: 0.88583
Time: 2018-07-14 22:11:28
TRAINING STATS: batch 124/486 in epoch 91,   batch loss: 0.36476, batch accuracy: 0.89133
Time: 2018-07-14 22:11:32
TRAINING STATS: batch 174/486 in epoch 91,   batch loss: 0.38207, batch accuracy: 0.88517
Time: 2018-07-14 22:11:35
TRAINING STATS: batch 224/486 in epoch 91,   batch loss: 0.38025, batch accuracy: 0.89017
Time: 2018-07-14 22:11:40
TRAINING STATS: batch 274/486 in epoch 91,   batch loss: 0.37701, batch accuracy: 0.88883
Time: 2018-07-14 22:11:44
TRAINING STATS: batch 324/486 in epoch 91,   batch loss: 0.33940, batch accuracy: 0.90067
Time: 2018-07-14 22:11:48
TRAINING STATS: batch 374/486 in epoch 91,   batch loss: 0.40113, batch accuracy: 0.88333
Time: 2018-07-14 22:11:53
TRAINING STATS: batch 424/486 in epoch 91,   batch loss: 0.32838, batch accuracy: 0.90217
Time: 2018-07-14 22:11:56
TRAINING STATS: batch 474/486 in epoch 91,   batch loss: 0.35171, batch accuracy: 0.89567
Time: 2018-07-14 22:12:00
TRAINING STATS: batch 38/486 in epoch 92,    batch loss: 0.39066, batch accuracy: 0.88183
Time: 2018-07-14 22:12:05
TRAINING STATS: batch 88/486 in epoch 92,    batch loss: 0.35663, batch accuracy: 0.89250
Time: 2018-07-14 22:12:08
TRAINING STATS: batch 138/486 in epoch 92,   batch loss: 0.34381, batch accuracy: 0.89933
Time: 2018-07-14 22:12:12
TRAINING STATS: batch 188/486 in epoch 92,   batch loss: 0.34817, batch accuracy: 0.89967
Time: 2018-07-14 22:12:17
TRAINING STATS: batch 238/486 in epoch 92,   batch loss: 0.36568, batch accuracy: 0.89250
Time: 2018-07-14 22:12:21
TRAINING STATS: batch 288/486 in epoch 92,   batch loss: 0.38743, batch accuracy: 0.88350
Time: 2018-07-14 22:12:24
TRAINING STATS: batch 338/486 in epoch 92,   batch loss: 0.34060, batch accuracy: 0.89983
Time: 2018-07-14 22:12:29
TRAINING STATS: batch 388/486 in epoch 92,   batch loss: 0.35519, batch accuracy: 0.89517
Time: 2018-07-14 22:12:33
TRAINING STATS: batch 438/486 in epoch 92,   batch loss: 0.37078, batch accuracy: 0.89167
Time: 2018-07-14 22:12:36
TRAINING STATS: batch 2/486 in epoch 93,     batch loss: 0.35890, batch accuracy: 0.89433
Time: 2018-07-14 22:12:41
TRAINING STATS: batch 52/486 in epoch 93,    batch loss: 0.36294, batch accuracy: 0.89183
Time: 2018-07-14 22:12:45
TRAINING STATS: batch 102/486 in epoch 93,   batch loss: 0.38410, batch accuracy: 0.88600
Time: 2018-07-14 22:12:49
TRAINING STATS: batch 152/486 in epoch 93,   batch loss: 0.32730, batch accuracy: 0.89983
Time: 2018-07-14 22:12:53
TRAINING STATS: batch 202/486 in epoch 93,   batch loss: 0.37766, batch accuracy: 0.88933
Time: 2018-07-14 22:12:57
TRAINING STATS: batch 252/486 in epoch 93,   batch loss: 0.35416, batch accuracy: 0.89600
Time: 2018-07-14 22:13:01
TRAINING STATS: batch 302/486 in epoch 93,   batch loss: 0.37217, batch accuracy: 0.89200
Time: 2018-07-14 22:13:06
TRAINING STATS: batch 352/486 in epoch 93,   batch loss: 0.35562, batch accuracy: 0.89450
Time: 2018-07-14 22:13:09
TRAINING STATS: batch 402/486 in epoch 93,   batch loss: 0.32616, batch accuracy: 0.90067
Time: 2018-07-14 22:13:13
TRAINING STATS: batch 452/486 in epoch 93,   batch loss: 0.36097, batch accuracy: 0.89117
Time: 2018-07-14 22:13:18
TRAINING STATS: batch 16/486 in epoch 94,    batch loss: 0.32279, batch accuracy: 0.90617
Time: 2018-07-14 22:13:22
TRAINING STATS: batch 66/486 in epoch 94,    batch loss: 0.37897, batch accuracy: 0.88933
Time: 2018-07-14 22:13:25
TRAINING STATS: batch 116/486 in epoch 94,   batch loss: 0.35065, batch accuracy: 0.89733
Time: 2018-07-14 22:13:30
TRAINING STATS: batch 166/486 in epoch 94,   batch loss: 0.30599, batch accuracy: 0.90933
Time: 2018-07-14 22:13:34
TRAINING STATS: batch 216/486 in epoch 94,   batch loss: 0.37815, batch accuracy: 0.89233
Time: 2018-07-14 22:13:37
TRAINING STATS: batch 266/486 in epoch 94,   batch loss: 0.36820, batch accuracy: 0.89150
Time: 2018-07-14 22:13:42
TRAINING STATS: batch 316/486 in epoch 94,   batch loss: 0.36760, batch accuracy: 0.89267
Time: 2018-07-14 22:13:46
TRAINING STATS: batch 366/486 in epoch 94,   batch loss: 0.39500, batch accuracy: 0.88283
Time: 2018-07-14 22:13:50
TRAINING STATS: batch 416/486 in epoch 94,   batch loss: 0.38805, batch accuracy: 0.88350
Time: 2018-07-14 22:13:54
TRAINING STATS: batch 466/486 in epoch 94,   batch loss: 0.28473, batch accuracy: 0.91283
Time: 2018-07-14 22:13:58
TRAINING STATS: batch 30/486 in epoch 95,    batch loss: 0.31881, batch accuracy: 0.90650
Time: 2018-07-14 22:14:02
TRAINING STATS: batch 80/486 in epoch 95,    batch loss: 0.36790, batch accuracy: 0.88983
Time: 2018-07-14 22:14:07
TRAINING STATS: batch 130/486 in epoch 95,   batch loss: 0.36678, batch accuracy: 0.88783
Time: 2018-07-14 22:14:10
TRAINING STATS: batch 180/486 in epoch 95,   batch loss: 0.32236, batch accuracy: 0.90567
Time: 2018-07-14 22:14:14
TRAINING STATS: batch 230/486 in epoch 95,   batch loss: 0.35743, batch accuracy: 0.89817
Time: 2018-07-14 22:14:19
TRAINING STATS: batch 280/486 in epoch 95,   batch loss: 0.33043, batch accuracy: 0.90200
Time: 2018-07-14 22:14:22
TRAINING STATS: batch 330/486 in epoch 95,   batch loss: 0.36613, batch accuracy: 0.89550
Time: 2018-07-14 22:14:26
TRAINING STATS: batch 380/486 in epoch 95,   batch loss: 0.33012, batch accuracy: 0.90233
Time: 2018-07-14 22:14:31
TRAINING STATS: batch 430/486 in epoch 95,   batch loss: 0.33546, batch accuracy: 0.90050
Time: 2018-07-14 22:14:35
TRAINING STATS: batch 480/486 in epoch 95,   batch loss: 0.32393, batch accuracy: 0.90483
Time: 2018-07-14 22:14:38
TRAINING STATS: batch 44/486 in epoch 96,    batch loss: 0.33113, batch accuracy: 0.90283
Time: 2018-07-14 22:14:43
TRAINING STATS: batch 94/486 in epoch 96,    batch loss: 0.37080, batch accuracy: 0.89100
Time: 2018-07-14 22:14:47
TRAINING STATS: batch 144/486 in epoch 96,   batch loss: 0.38537, batch accuracy: 0.88500
Time: 2018-07-14 22:14:51
TRAINING STATS: batch 194/486 in epoch 96,   batch loss: 0.38214, batch accuracy: 0.89067
Time: 2018-07-14 22:14:55
TRAINING STATS: batch 244/486 in epoch 96,   batch loss: 0.37985, batch accuracy: 0.88633
Time: 2018-07-14 22:14:59
TRAINING STATS: batch 294/486 in epoch 96,   batch loss: 0.32207, batch accuracy: 0.90333
Time: 2018-07-14 22:15:03
TRAINING STATS: batch 344/486 in epoch 96,   batch loss: 0.38082, batch accuracy: 0.88750
Time: 2018-07-14 22:15:07
TRAINING STATS: batch 394/486 in epoch 96,   batch loss: 0.37192, batch accuracy: 0.89000
Time: 2018-07-14 22:15:11
TRAINING STATS: batch 444/486 in epoch 96,   batch loss: 0.31636, batch accuracy: 0.90367
Time: 2018-07-14 22:15:15
TRAINING STATS: batch 8/486 in epoch 97,     batch loss: 0.37165, batch accuracy: 0.89033
Time: 2018-07-14 22:15:20
TRAINING STATS: batch 58/486 in epoch 97,    batch loss: 0.37208, batch accuracy: 0.89133
Time: 2018-07-14 22:15:23
TRAINING STATS: batch 108/486 in epoch 97,   batch loss: 0.38404, batch accuracy: 0.88983
Time: 2018-07-14 22:15:27
TRAINING STATS: batch 158/486 in epoch 97,   batch loss: 0.37348, batch accuracy: 0.89233
Time: 2018-07-14 22:15:32
TRAINING STATS: batch 208/486 in epoch 97,   batch loss: 0.36898, batch accuracy: 0.89317
Time: 2018-07-14 22:15:36
TRAINING STATS: batch 258/486 in epoch 97,   batch loss: 0.37336, batch accuracy: 0.88917
Time: 2018-07-14 22:15:39
TRAINING STATS: batch 308/486 in epoch 97,   batch loss: 0.36657, batch accuracy: 0.89233
Time: 2018-07-14 22:15:44
TRAINING STATS: batch 358/486 in epoch 97,   batch loss: 0.36784, batch accuracy: 0.89317
Time: 2018-07-14 22:15:48
TRAINING STATS: batch 408/486 in epoch 97,   batch loss: 0.36301, batch accuracy: 0.89083
Time: 2018-07-14 22:15:52
TRAINING STATS: batch 458/486 in epoch 97,   batch loss: 0.36477, batch accuracy: 0.89250
Time: 2018-07-14 22:15:56
TRAINING STATS: batch 22/486 in epoch 98,    batch loss: 0.36758, batch accuracy: 0.89183
Time: 2018-07-14 22:16:00
TRAINING STATS: batch 72/486 in epoch 98,    batch loss: 0.36013, batch accuracy: 0.89533
Time: 2018-07-14 22:16:04
TRAINING STATS: batch 122/486 in epoch 98,   batch loss: 0.30048, batch accuracy: 0.90783
Time: 2018-07-14 22:16:09
TRAINING STATS: batch 172/486 in epoch 98,   batch loss: 0.33137, batch accuracy: 0.90267
Time: 2018-07-14 22:16:12
TRAINING STATS: batch 222/486 in epoch 98,   batch loss: 0.35212, batch accuracy: 0.89467
Time: 2018-07-14 22:16:16
TRAINING STATS: batch 272/486 in epoch 98,   batch loss: 0.37385, batch accuracy: 0.88850
Time: 2018-07-14 22:16:21
TRAINING STATS: batch 322/486 in epoch 98,   batch loss: 0.32912, batch accuracy: 0.90283
Time: 2018-07-14 22:16:24
TRAINING STATS: batch 372/486 in epoch 98,   batch loss: 0.33953, batch accuracy: 0.89967
Time: 2018-07-14 22:16:28
TRAINING STATS: batch 422/486 in epoch 98,   batch loss: 0.32547, batch accuracy: 0.90533
Time: 2018-07-14 22:16:33
TRAINING STATS: batch 472/486 in epoch 98,   batch loss: 0.38405, batch accuracy: 0.88567
Time: 2018-07-14 22:16:37
TRAINING STATS: batch 36/486 in epoch 99,    batch loss: 0.40105, batch accuracy: 0.87867
Time: 2018-07-14 22:16:40
TRAINING STATS: batch 86/486 in epoch 99,    batch loss: 0.32354, batch accuracy: 0.90233
Time: 2018-07-14 22:16:45
TRAINING STATS: batch 136/486 in epoch 99,   batch loss: 0.37462, batch accuracy: 0.88617
Time: 2018-07-14 22:16:49
TRAINING STATS: batch 186/486 in epoch 99,   batch loss: 0.34750, batch accuracy: 0.89867
Time: 2018-07-14 22:16:52
TRAINING STATS: batch 236/486 in epoch 99,   batch loss: 0.34901, batch accuracy: 0.89517
Time: 2018-07-14 22:16:57
TRAINING STATS: batch 286/486 in epoch 99,   batch loss: 0.36957, batch accuracy: 0.89267
Time: 2018-07-14 22:17:01
TRAINING STATS: batch 336/486 in epoch 99,   batch loss: 0.36307, batch accuracy: 0.89383
Time: 2018-07-14 22:17:05
TRAINING STATS: batch 386/486 in epoch 99,   batch loss: 0.35848, batch accuracy: 0.89050
Time: 2018-07-14 22:17:09
TRAINING STATS: batch 436/486 in epoch 99,   batch loss: 0.35205, batch accuracy: 0.89667
Time: 2018-07-14 22:17:13
TRAINING STATS: batch 0/486 in epoch 100,    batch loss: 0.35184, batch accuracy: 0.89417
Time: 2018-07-14 22:17:17
TRAINING STATS: batch 50/486 in epoch 100,   batch loss: 0.33271, batch accuracy: 0.90183
Time: 2018-07-14 22:17:22
TRAINING STATS: batch 100/486 in epoch 100,  batch loss: 0.35533, batch accuracy: 0.89400
Time: 2018-07-14 22:17:25
TRAINING STATS: batch 150/486 in epoch 100,  batch loss: 0.36674, batch accuracy: 0.89433
Time: 2018-07-14 22:17:29
TRAINING STATS: batch 200/486 in epoch 100,  batch loss: 0.30541, batch accuracy: 0.91317
Time: 2018-07-14 22:17:34
TRAINING STATS: batch 250/486 in epoch 100,  batch loss: 0.37822, batch accuracy: 0.88600
Time: 2018-07-14 22:17:38
TRAINING STATS: batch 300/486 in epoch 100,  batch loss: 0.36714, batch accuracy: 0.89300
Time: 2018-07-14 22:17:41
TRAINING STATS: batch 350/486 in epoch 100,  batch loss: 0.35626, batch accuracy: 0.89567
Time: 2018-07-14 22:17:46
TRAINING STATS: batch 400/486 in epoch 100,  batch loss: 0.30159, batch accuracy: 0.91050
Time: 2018-07-14 22:17:50
TRAINING STATS: batch 450/486 in epoch 100,  batch loss: 0.34899, batch accuracy: 0.89300
Time: 2018-07-14 22:17:54
TRAINING STATS: batch 14/486 in epoch 101,   batch loss: 0.31302, batch accuracy: 0.90717
Time: 2018-07-14 22:17:58
TRAINING STATS: batch 64/486 in epoch 101,   batch loss: 0.39067, batch accuracy: 0.88883
Time: 2018-07-14 22:18:02
TRAINING STATS: batch 114/486 in epoch 101,  batch loss: 0.34926, batch accuracy: 0.89583
Time: 2018-07-14 22:18:06
TRAINING STATS: batch 164/486 in epoch 101,  batch loss: 0.30867, batch accuracy: 0.90650
Time: 2018-07-14 22:18:10
TRAINING STATS: batch 214/486 in epoch 101,  batch loss: 0.35095, batch accuracy: 0.89667
Time: 2018-07-14 22:18:14
TRAINING STATS: batch 264/486 in epoch 101,  batch loss: 0.34941, batch accuracy: 0.90050
Time: 2018-07-14 22:18:18
TRAINING STATS: batch 314/486 in epoch 101,  batch loss: 0.38390, batch accuracy: 0.88950
Time: 2018-07-14 22:18:23
TRAINING STATS: batch 364/486 in epoch 101,  batch loss: 0.38384, batch accuracy: 0.88700
Time: 2018-07-14 22:18:26
TRAINING STATS: batch 414/486 in epoch 101,  batch loss: 0.35789, batch accuracy: 0.89300
Time: 2018-07-14 22:18:30
TRAINING STATS: batch 464/486 in epoch 101,  batch loss: 0.33225, batch accuracy: 0.90083
Time: 2018-07-14 22:18:35
TRAINING STATS: batch 28/486 in epoch 102,   batch loss: 0.34008, batch accuracy: 0.89850
Time: 2018-07-14 22:18:39
TRAINING STATS: batch 78/486 in epoch 102,   batch loss: 0.39369, batch accuracy: 0.88317
Time: 2018-07-14 22:18:42
TRAINING STATS: batch 128/486 in epoch 102,  batch loss: 0.37041, batch accuracy: 0.89000
Time: 2018-07-14 22:18:47
TRAINING STATS: batch 178/486 in epoch 102,  batch loss: 0.30648, batch accuracy: 0.91317
Time: 2018-07-14 22:18:51
TRAINING STATS: batch 228/486 in epoch 102,  batch loss: 0.31840, batch accuracy: 0.90350
Time: 2018-07-14 22:18:54
TRAINING STATS: batch 278/486 in epoch 102,  batch loss: 0.33833, batch accuracy: 0.90033
Time: 2018-07-14 22:18:59
TRAINING STATS: batch 328/486 in epoch 102,  batch loss: 0.36176, batch accuracy: 0.89450
Time: 2018-07-14 22:19:03
TRAINING STATS: batch 378/486 in epoch 102,  batch loss: 0.35453, batch accuracy: 0.89783
Time: 2018-07-14 22:19:06
TRAINING STATS: batch 428/486 in epoch 102,  batch loss: 0.38196, batch accuracy: 0.88467
Time: 2018-07-14 22:19:11
TRAINING STATS: batch 478/486 in epoch 102,  batch loss: 0.34446, batch accuracy: 0.89700
Time: 2018-07-14 22:19:15
TRAINING STATS: batch 42/486 in epoch 103,   batch loss: 0.34298, batch accuracy: 0.89917
Time: 2018-07-14 22:19:19
TRAINING STATS: batch 92/486 in epoch 103,   batch loss: 0.36517, batch accuracy: 0.88950
Time: 2018-07-14 22:19:24
TRAINING STATS: batch 142/486 in epoch 103,  batch loss: 0.34105, batch accuracy: 0.89800
Time: 2018-07-14 22:19:27
TRAINING STATS: batch 192/486 in epoch 103,  batch loss: 0.36124, batch accuracy: 0.89500
Time: 2018-07-14 22:19:31
TRAINING STATS: batch 242/486 in epoch 103,  batch loss: 0.35675, batch accuracy: 0.89600
Time: 2018-07-14 22:19:36
TRAINING STATS: batch 292/486 in epoch 103,  batch loss: 0.36716, batch accuracy: 0.88817
Time: 2018-07-14 22:19:39
TRAINING STATS: batch 342/486 in epoch 103,  batch loss: 0.34367, batch accuracy: 0.89800
Time: 2018-07-14 22:19:43
TRAINING STATS: batch 392/486 in epoch 103,  batch loss: 0.35641, batch accuracy: 0.89433
Time: 2018-07-14 22:19:48
TRAINING STATS: batch 442/486 in epoch 103,  batch loss: 0.32662, batch accuracy: 0.90150
Time: 2018-07-14 22:19:52
TRAINING STATS: batch 6/486 in epoch 104,    batch loss: 0.41463, batch accuracy: 0.87950
Time: 2018-07-14 22:19:55
TRAINING STATS: batch 56/486 in epoch 104,   batch loss: 0.37018, batch accuracy: 0.88950
Time: 2018-07-14 22:20:00
TRAINING STATS: batch 106/486 in epoch 104,  batch loss: 0.39255, batch accuracy: 0.88650
Time: 2018-07-14 22:20:04
TRAINING STATS: batch 156/486 in epoch 104,  batch loss: 0.35515, batch accuracy: 0.89233
Time: 2018-07-14 22:20:08
TRAINING STATS: batch 206/486 in epoch 104,  batch loss: 0.38515, batch accuracy: 0.88817
Time: 2018-07-14 22:20:12
TRAINING STATS: batch 256/486 in epoch 104,  batch loss: 0.33055, batch accuracy: 0.90383
Time: 2018-07-14 22:20:16
TRAINING STATS: batch 306/486 in epoch 104,  batch loss: 0.36779, batch accuracy: 0.88967
Time: 2018-07-14 22:20:20
TRAINING STATS: batch 356/486 in epoch 104,  batch loss: 0.35740, batch accuracy: 0.89517
Time: 2018-07-14 22:20:24
TRAINING STATS: batch 406/486 in epoch 104,  batch loss: 0.37620, batch accuracy: 0.88783
Time: 2018-07-14 22:20:28
TRAINING STATS: batch 456/486 in epoch 104,  batch loss: 0.31070, batch accuracy: 0.90917
Time: 2018-07-14 22:20:32
TRAINING STATS: batch 20/486 in epoch 105,   batch loss: 0.34525, batch accuracy: 0.89700
Time: 2018-07-14 22:20:37
TRAINING STATS: batch 70/486 in epoch 105,   batch loss: 0.29466, batch accuracy: 0.91100
Time: 2018-07-14 22:20:41
TRAINING STATS: batch 120/486 in epoch 105,  batch loss: 0.34658, batch accuracy: 0.89600
Time: 2018-07-14 22:20:44
TRAINING STATS: batch 170/486 in epoch 105,  batch loss: 0.30611, batch accuracy: 0.91033
Time: 2018-07-14 22:20:49
TRAINING STATS: batch 220/486 in epoch 105,  batch loss: 0.32270, batch accuracy: 0.90383
Time: 2018-07-14 22:20:53
TRAINING STATS: batch 270/486 in epoch 105,  batch loss: 0.31887, batch accuracy: 0.90783
Time: 2018-07-14 22:20:56
TRAINING STATS: batch 320/486 in epoch 105,  batch loss: 0.32344, batch accuracy: 0.90183
Time: 2018-07-14 22:21:01
TRAINING STATS: batch 370/486 in epoch 105,  batch loss: 0.34026, batch accuracy: 0.89783
Time: 2018-07-14 22:21:05
TRAINING STATS: batch 420/486 in epoch 105,  batch loss: 0.34200, batch accuracy: 0.90250
Time: 2018-07-14 22:21:08
TRAINING STATS: batch 470/486 in epoch 105,  batch loss: 0.36348, batch accuracy: 0.89033
Time: 2018-07-14 22:21:13
TRAINING STATS: batch 34/486 in epoch 106,   batch loss: 0.35378, batch accuracy: 0.89533
Time: 2018-07-14 22:21:17
TRAINING STATS: batch 84/486 in epoch 106,   batch loss: 0.33184, batch accuracy: 0.90067
Time: 2018-07-14 22:21:21
TRAINING STATS: batch 134/486 in epoch 106,  batch loss: 0.34655, batch accuracy: 0.89850
Time: 2018-07-14 22:21:26
TRAINING STATS: batch 184/486 in epoch 106,  batch loss: 0.35677, batch accuracy: 0.89917
Time: 2018-07-14 22:21:29
TRAINING STATS: batch 234/486 in epoch 106,  batch loss: 0.39526, batch accuracy: 0.88533
Time: 2018-07-14 22:21:33
TRAINING STATS: batch 284/486 in epoch 106,  batch loss: 0.36298, batch accuracy: 0.89667
Time: 2018-07-14 22:21:38
TRAINING STATS: batch 334/486 in epoch 106,  batch loss: 0.35330, batch accuracy: 0.89533
Time: 2018-07-14 22:21:41
TRAINING STATS: batch 384/486 in epoch 106,  batch loss: 0.32657, batch accuracy: 0.90733
Time: 2018-07-14 22:21:45
TRAINING STATS: batch 434/486 in epoch 106,  batch loss: 0.37044, batch accuracy: 0.89100
Time: 2018-07-14 22:21:50
TRAINING STATS: batch 484/486 in epoch 106,  batch loss: 0.33680, batch accuracy: 0.90233
Time: 2018-07-14 22:21:53
TRAINING STATS: batch 48/486 in epoch 107,   batch loss: 0.34947, batch accuracy: 0.89783
Time: 2018-07-14 22:21:57
TRAINING STATS: batch 98/486 in epoch 107,   batch loss: 0.31537, batch accuracy: 0.91000
Time: 2018-07-14 22:22:02
TRAINING STATS: batch 148/486 in epoch 107,  batch loss: 0.35303, batch accuracy: 0.89883
Time: 2018-07-14 22:22:06
TRAINING STATS: batch 198/486 in epoch 107,  batch loss: 0.35748, batch accuracy: 0.89483
Time: 2018-07-14 22:22:09
TRAINING STATS: batch 248/486 in epoch 107,  batch loss: 0.37184, batch accuracy: 0.89117
Time: 2018-07-14 22:22:14
TRAINING STATS: batch 298/486 in epoch 107,  batch loss: 0.36251, batch accuracy: 0.89367
Time: 2018-07-14 22:22:18
TRAINING STATS: batch 348/486 in epoch 107,  batch loss: 0.31198, batch accuracy: 0.90633
Time: 2018-07-14 22:22:22
TRAINING STATS: batch 398/486 in epoch 107,  batch loss: 0.35351, batch accuracy: 0.89350
Time: 2018-07-14 22:22:26
TRAINING STATS: batch 448/486 in epoch 107,  batch loss: 0.36469, batch accuracy: 0.89217
Time: 2018-07-14 22:22:30
TRAINING STATS: batch 12/486 in epoch 108,   batch loss: 0.33242, batch accuracy: 0.90233
Time: 2018-07-14 22:22:34
TRAINING STATS: batch 62/486 in epoch 108,   batch loss: 0.35356, batch accuracy: 0.89600
Time: 2018-07-14 22:22:39
TRAINING STATS: batch 112/486 in epoch 108,  batch loss: 0.33263, batch accuracy: 0.90167
Time: 2018-07-14 22:22:42
TRAINING STATS: batch 162/486 in epoch 108,  batch loss: 0.34260, batch accuracy: 0.89933
Time: 2018-07-14 22:22:46
TRAINING STATS: batch 212/486 in epoch 108,  batch loss: 0.32605, batch accuracy: 0.90050
Time: 2018-07-14 22:22:51
TRAINING STATS: batch 262/486 in epoch 108,  batch loss: 0.36106, batch accuracy: 0.89167
Time: 2018-07-14 22:22:55
TRAINING STATS: batch 312/486 in epoch 108,  batch loss: 0.31580, batch accuracy: 0.90667
Time: 2018-07-14 22:22:58
TRAINING STATS: batch 362/486 in epoch 108,  batch loss: 0.35855, batch accuracy: 0.89633
Time: 2018-07-14 22:23:03
TRAINING STATS: batch 412/486 in epoch 108,  batch loss: 0.30773, batch accuracy: 0.90950
Time: 2018-07-14 22:23:07
TRAINING STATS: batch 462/486 in epoch 108,  batch loss: 0.36780, batch accuracy: 0.88817
Time: 2018-07-14 22:23:10
TRAINING STATS: batch 26/486 in epoch 109,   batch loss: 0.38925, batch accuracy: 0.88900
Time: 2018-07-14 22:23:15
TRAINING STATS: batch 76/486 in epoch 109,   batch loss: 0.39501, batch accuracy: 0.88100
Time: 2018-07-14 22:23:19
TRAINING STATS: batch 126/486 in epoch 109,  batch loss: 0.33881, batch accuracy: 0.89500
Time: 2018-07-14 22:23:23
TRAINING STATS: batch 176/486 in epoch 109,  batch loss: 0.33362, batch accuracy: 0.90183
Time: 2018-07-14 22:23:27
TRAINING STATS: batch 226/486 in epoch 109,  batch loss: 0.34568, batch accuracy: 0.89683
Time: 2018-07-14 22:23:31
TRAINING STATS: batch 276/486 in epoch 109,  batch loss: 0.35401, batch accuracy: 0.89617
Time: 2018-07-14 22:23:35
TRAINING STATS: batch 326/486 in epoch 109,  batch loss: 0.34314, batch accuracy: 0.89617
Time: 2018-07-14 22:23:40
TRAINING STATS: batch 376/486 in epoch 109,  batch loss: 0.37332, batch accuracy: 0.89383
Time: 2018-07-14 22:23:43
TRAINING STATS: batch 426/486 in epoch 109,  batch loss: 0.34957, batch accuracy: 0.90067
Time: 2018-07-14 22:23:47
TRAINING STATS: batch 476/486 in epoch 109,  batch loss: 0.34496, batch accuracy: 0.89950
Time: 2018-07-14 22:23:52
TRAINING STATS: batch 40/486 in epoch 110,   batch loss: 0.33512, batch accuracy: 0.89967
Time: 2018-07-14 22:23:55
TRAINING STATS: batch 90/486 in epoch 110,   batch loss: 0.33698, batch accuracy: 0.90083
Time: 2018-07-14 22:23:59
TRAINING STATS: batch 140/486 in epoch 110,  batch loss: 0.30623, batch accuracy: 0.90867
Time: 2018-07-14 22:24:04
TRAINING STATS: batch 190/486 in epoch 110,  batch loss: 0.32257, batch accuracy: 0.90300
Time: 2018-07-14 22:24:08
TRAINING STATS: batch 240/486 in epoch 110,  batch loss: 0.35026, batch accuracy: 0.89433
Time: 2018-07-14 22:24:11
TRAINING STATS: batch 290/486 in epoch 110,  batch loss: 0.36761, batch accuracy: 0.88883
Time: 2018-07-14 22:24:16
TRAINING STATS: batch 340/486 in epoch 110,  batch loss: 0.36485, batch accuracy: 0.89333
Time: 2018-07-14 22:24:20
TRAINING STATS: batch 390/486 in epoch 110,  batch loss: 0.30553, batch accuracy: 0.90733
Time: 2018-07-14 22:24:24
TRAINING STATS: batch 440/486 in epoch 110,  batch loss: 0.37659, batch accuracy: 0.89133
Time: 2018-07-14 22:24:28
TRAINING STATS: batch 4/486 in epoch 111,    batch loss: 0.37177, batch accuracy: 0.88967
Time: 2018-07-14 22:24:32
TRAINING STATS: batch 54/486 in epoch 111,   batch loss: 0.37894, batch accuracy: 0.88450
Time: 2018-07-14 22:24:36
TRAINING STATS: batch 104/486 in epoch 111,  batch loss: 0.34381, batch accuracy: 0.89817
Time: 2018-07-14 22:24:41
TRAINING STATS: batch 154/486 in epoch 111,  batch loss: 0.30771, batch accuracy: 0.90783
Time: 2018-07-14 22:24:44
TRAINING STATS: batch 204/486 in epoch 111,  batch loss: 0.37260, batch accuracy: 0.88733
Time: 2018-07-14 22:24:48
TRAINING STATS: batch 254/486 in epoch 111,  batch loss: 0.33156, batch accuracy: 0.90117
Time: 2018-07-14 22:24:53
TRAINING STATS: batch 304/486 in epoch 111,  batch loss: 0.35774, batch accuracy: 0.89267
Time: 2018-07-14 22:24:56
TRAINING STATS: batch 354/486 in epoch 111,  batch loss: 0.33047, batch accuracy: 0.90033
Time: 2018-07-14 22:25:00
TRAINING STATS: batch 404/486 in epoch 111,  batch loss: 0.31822, batch accuracy: 0.90683
Time: 2018-07-14 22:25:05
TRAINING STATS: batch 454/486 in epoch 111,  batch loss: 0.29333, batch accuracy: 0.91317
Time: 2018-07-14 22:25:09
TRAINING STATS: batch 18/486 in epoch 112,   batch loss: 0.34061, batch accuracy: 0.90233
Time: 2018-07-14 22:25:12
TRAINING STATS: batch 68/486 in epoch 112,   batch loss: 0.30708, batch accuracy: 0.91000
Time: 2018-07-14 22:25:17
TRAINING STATS: batch 118/486 in epoch 112,  batch loss: 0.34592, batch accuracy: 0.89617
Time: 2018-07-14 22:25:21
TRAINING STATS: batch 168/486 in epoch 112,  batch loss: 0.30983, batch accuracy: 0.91067
Time: 2018-07-14 22:25:24
TRAINING STATS: batch 218/486 in epoch 112,  batch loss: 0.32343, batch accuracy: 0.90750
Time: 2018-07-14 22:25:29
TRAINING STATS: batch 268/486 in epoch 112,  batch loss: 0.34255, batch accuracy: 0.90050
Time: 2018-07-14 22:25:33
TRAINING STATS: batch 318/486 in epoch 112,  batch loss: 0.33601, batch accuracy: 0.89767
Time: 2018-07-14 22:25:37
TRAINING STATS: batch 368/486 in epoch 112,  batch loss: 0.36597, batch accuracy: 0.89083
Time: 2018-07-14 22:25:41
TRAINING STATS: batch 418/486 in epoch 112,  batch loss: 0.33542, batch accuracy: 0.89967
Time: 2018-07-14 22:25:45
TRAINING STATS: batch 468/486 in epoch 112,  batch loss: 0.36528, batch accuracy: 0.89600
Time: 2018-07-14 22:25:49
TRAINING STATS: batch 32/486 in epoch 113,   batch loss: 0.31417, batch accuracy: 0.90450
Time: 2018-07-14 22:25:54
TRAINING STATS: batch 82/486 in epoch 113,   batch loss: 0.35774, batch accuracy: 0.89350
Time: 2018-07-14 22:25:57
TRAINING STATS: batch 132/486 in epoch 113,  batch loss: 0.32487, batch accuracy: 0.90267
Time: 2018-07-14 22:26:01
TRAINING STATS: batch 182/486 in epoch 113,  batch loss: 0.35822, batch accuracy: 0.89450
Time: 2018-07-14 22:26:06
TRAINING STATS: batch 232/486 in epoch 113,  batch loss: 0.35880, batch accuracy: 0.89717
Time: 2018-07-14 22:26:09
TRAINING STATS: batch 282/486 in epoch 113,  batch loss: 0.31650, batch accuracy: 0.90650
Time: 2018-07-14 22:26:13
TRAINING STATS: batch 332/486 in epoch 113,  batch loss: 0.38080, batch accuracy: 0.89017
Time: 2018-07-14 22:26:18
TRAINING STATS: batch 382/486 in epoch 113,  batch loss: 0.35827, batch accuracy: 0.89600
Time: 2018-07-14 22:26:22
TRAINING STATS: batch 432/486 in epoch 113,  batch loss: 0.32895, batch accuracy: 0.90133
Time: 2018-07-14 22:26:25
TRAINING STATS: batch 482/486 in epoch 113,  batch loss: 0.33293, batch accuracy: 0.90033
Time: 2018-07-14 22:26:30
TRAINING STATS: batch 46/486 in epoch 114,   batch loss: 0.34426, batch accuracy: 0.89950
Time: 2018-07-14 22:26:34
TRAINING STATS: batch 96/486 in epoch 114,   batch loss: 0.34950, batch accuracy: 0.89683
Time: 2018-07-14 22:26:37
TRAINING STATS: batch 146/486 in epoch 114,  batch loss: 0.33215, batch accuracy: 0.90433
Time: 2018-07-14 22:26:42
TRAINING STATS: batch 196/486 in epoch 114,  batch loss: 0.36894, batch accuracy: 0.88883
Time: 2018-07-14 22:26:46
TRAINING STATS: batch 246/486 in epoch 114,  batch loss: 0.32322, batch accuracy: 0.90400
Time: 2018-07-14 22:26:50
TRAINING STATS: batch 296/486 in epoch 114,  batch loss: 0.37689, batch accuracy: 0.88967
Time: 2018-07-14 22:26:55
TRAINING STATS: batch 346/486 in epoch 114,  batch loss: 0.32696, batch accuracy: 0.90517
Time: 2018-07-14 22:26:58
TRAINING STATS: batch 396/486 in epoch 114,  batch loss: 0.36414, batch accuracy: 0.88983
Time: 2018-07-14 22:27:02
TRAINING STATS: batch 446/486 in epoch 114,  batch loss: 0.34761, batch accuracy: 0.89517
Time: 2018-07-14 22:27:07
TRAINING STATS: batch 10/486 in epoch 115,   batch loss: 0.34430, batch accuracy: 0.89550
Time: 2018-07-14 22:27:10
TRAINING STATS: batch 60/486 in epoch 115,   batch loss: 0.33582, batch accuracy: 0.89717
Time: 2018-07-14 22:27:14
TRAINING STATS: batch 110/486 in epoch 115,  batch loss: 0.35775, batch accuracy: 0.89317
Time: 2018-07-14 22:27:19
TRAINING STATS: batch 160/486 in epoch 115,  batch loss: 0.33741, batch accuracy: 0.89800
Time: 2018-07-14 22:27:23
TRAINING STATS: batch 210/486 in epoch 115,  batch loss: 0.30203, batch accuracy: 0.91200
Time: 2018-07-14 22:27:26
TRAINING STATS: batch 260/486 in epoch 115,  batch loss: 0.36891, batch accuracy: 0.89083
Time: 2018-07-14 22:27:31
TRAINING STATS: batch 310/486 in epoch 115,  batch loss: 0.33354, batch accuracy: 0.90100
Time: 2018-07-14 22:27:35
TRAINING STATS: batch 360/486 in epoch 115,  batch loss: 0.35806, batch accuracy: 0.89483
Time: 2018-07-14 22:27:38
TRAINING STATS: batch 410/486 in epoch 115,  batch loss: 0.34633, batch accuracy: 0.89867
Time: 2018-07-14 22:27:43
TRAINING STATS: batch 460/486 in epoch 115,  batch loss: 0.40324, batch accuracy: 0.87967
Time: 2018-07-14 22:27:47
TRAINING STATS: batch 24/486 in epoch 116,   batch loss: 0.38981, batch accuracy: 0.88567
Time: 2018-07-14 22:27:51
TRAINING STATS: batch 74/486 in epoch 116,   batch loss: 0.36489, batch accuracy: 0.89383
Time: 2018-07-14 22:27:55
TRAINING STATS: batch 124/486 in epoch 116,  batch loss: 0.37858, batch accuracy: 0.88283
Time: 2018-07-14 22:27:59
TRAINING STATS: batch 174/486 in epoch 116,  batch loss: 0.39713, batch accuracy: 0.88417
Time: 2018-07-14 22:28:03
TRAINING STATS: batch 224/486 in epoch 116,  batch loss: 0.39469, batch accuracy: 0.88800
Time: 2018-07-14 22:28:08
TRAINING STATS: batch 274/486 in epoch 116,  batch loss: 0.38293, batch accuracy: 0.88433
Time: 2018-07-14 22:28:11
TRAINING STATS: batch 324/486 in epoch 116,  batch loss: 0.33020, batch accuracy: 0.90283
Time: 2018-07-14 22:28:15
TRAINING STATS: batch 374/486 in epoch 116,  batch loss: 0.38302, batch accuracy: 0.88700
Time: 2018-07-14 22:28:20
TRAINING STATS: batch 424/486 in epoch 116,  batch loss: 0.32496, batch accuracy: 0.90733
Time: 2018-07-14 22:28:24
TRAINING STATS: batch 474/486 in epoch 116,  batch loss: 0.36034, batch accuracy: 0.89583
Time: 2018-07-14 22:28:27
TRAINING STATS: batch 38/486 in epoch 117,   batch loss: 0.38367, batch accuracy: 0.88667
Time: 2018-07-14 22:28:32
TRAINING STATS: batch 88/486 in epoch 117,   batch loss: 0.35254, batch accuracy: 0.89667
Time: 2018-07-14 22:28:36
TRAINING STATS: batch 138/486 in epoch 117,  batch loss: 0.35600, batch accuracy: 0.89200
Time: 2018-07-14 22:28:39
TRAINING STATS: batch 188/486 in epoch 117,  batch loss: 0.35830, batch accuracy: 0.89517
Time: 2018-07-14 22:28:44
TRAINING STATS: batch 238/486 in epoch 117,  batch loss: 0.34272, batch accuracy: 0.89883
Time: 2018-07-14 22:28:48
TRAINING STATS: batch 288/486 in epoch 117,  batch loss: 0.38194, batch accuracy: 0.89100
Time: 2018-07-14 22:28:52
TRAINING STATS: batch 338/486 in epoch 117,  batch loss: 0.36026, batch accuracy: 0.89167
Time: 2018-07-14 22:28:56
TRAINING STATS: batch 388/486 in epoch 117,  batch loss: 0.35717, batch accuracy: 0.89567
Time: 2018-07-14 22:29:00
TRAINING STATS: batch 438/486 in epoch 117,  batch loss: 0.37406, batch accuracy: 0.89083
Time: 2018-07-14 22:29:04
TRAINING STATS: batch 2/486 in epoch 118,    batch loss: 0.37851, batch accuracy: 0.88867
Time: 2018-07-14 22:29:09
TRAINING STATS: batch 52/486 in epoch 118,   batch loss: 0.35581, batch accuracy: 0.89850
Time: 2018-07-14 22:29:12
TRAINING STATS: batch 102/486 in epoch 118,  batch loss: 0.37752, batch accuracy: 0.88933
Time: 2018-07-14 22:29:16
TRAINING STATS: batch 152/486 in epoch 118,  batch loss: 0.35210, batch accuracy: 0.89467
Time: 2018-07-14 22:29:21
TRAINING STATS: batch 202/486 in epoch 118,  batch loss: 0.38924, batch accuracy: 0.88567
Time: 2018-07-14 22:29:24
TRAINING STATS: batch 252/486 in epoch 118,  batch loss: 0.37082, batch accuracy: 0.88933
Time: 2018-07-14 22:29:28
TRAINING STATS: batch 302/486 in epoch 118,  batch loss: 0.37609, batch accuracy: 0.88817
Time: 2018-07-14 22:29:33
TRAINING STATS: batch 352/486 in epoch 118,  batch loss: 0.35071, batch accuracy: 0.89433
Time: 2018-07-14 22:29:37
TRAINING STATS: batch 402/486 in epoch 118,  batch loss: 0.35142, batch accuracy: 0.89333
Time: 2018-07-14 22:29:40
TRAINING STATS: batch 452/486 in epoch 118,  batch loss: 0.37518, batch accuracy: 0.88850
Time: 2018-07-14 22:29:45
TRAINING STATS: batch 16/486 in epoch 119,   batch loss: 0.33158, batch accuracy: 0.90350
Time: 2018-07-14 22:29:49
TRAINING STATS: batch 66/486 in epoch 119,   batch loss: 0.38952, batch accuracy: 0.88617
Time: 2018-07-14 22:29:52
TRAINING STATS: batch 116/486 in epoch 119,  batch loss: 0.34582, batch accuracy: 0.89700
Time: 2018-07-14 22:29:57
TRAINING STATS: batch 166/486 in epoch 119,  batch loss: 0.30531, batch accuracy: 0.91150
Time: 2018-07-14 22:30:01
TRAINING STATS: batch 216/486 in epoch 119,  batch loss: 0.35881, batch accuracy: 0.89450
Time: 2018-07-14 22:30:05
TRAINING STATS: batch 266/486 in epoch 119,  batch loss: 0.36208, batch accuracy: 0.89300
Time: 2018-07-14 22:30:09
TRAINING STATS: batch 316/486 in epoch 119,  batch loss: 0.34657, batch accuracy: 0.89917
Time: 2018-07-14 22:30:13
TRAINING STATS: batch 366/486 in epoch 119,  batch loss: 0.38579, batch accuracy: 0.88917
Time: 2018-07-14 22:30:17
TRAINING STATS: batch 416/486 in epoch 119,  batch loss: 0.38528, batch accuracy: 0.88850
Time: 2018-07-14 22:30:22
TRAINING STATS: batch 466/486 in epoch 119,  batch loss: 0.31631, batch accuracy: 0.90583
Time: 2018-07-14 22:30:25
TRAINING STATS: batch 30/486 in epoch 120,   batch loss: 0.32610, batch accuracy: 0.90100
Time: 2018-07-14 22:30:29
TRAINING STATS: batch 80/486 in epoch 120,   batch loss: 0.39550, batch accuracy: 0.88333
Time: 2018-07-14 22:30:34
TRAINING STATS: batch 130/486 in epoch 120,  batch loss: 0.39725, batch accuracy: 0.88183
Time: 2018-07-14 22:30:37
TRAINING STATS: batch 180/486 in epoch 120,  batch loss: 0.35846, batch accuracy: 0.89617
Time: 2018-07-14 22:30:41
TRAINING STATS: batch 230/486 in epoch 120,  batch loss: 0.36272, batch accuracy: 0.89583
Time: 2018-07-14 22:30:46
TRAINING STATS: batch 280/486 in epoch 120,  batch loss: 0.36126, batch accuracy: 0.89183
Time: 2018-07-14 22:30:50
TRAINING STATS: batch 330/486 in epoch 120,  batch loss: 0.39151, batch accuracy: 0.88200
Time: 2018-07-14 22:30:53
TRAINING STATS: batch 380/486 in epoch 120,  batch loss: 0.35132, batch accuracy: 0.89400
Time: 2018-07-14 22:30:58
TRAINING STATS: batch 430/486 in epoch 120,  batch loss: 0.35519, batch accuracy: 0.89450
Time: 2018-07-14 22:31:02
TRAINING STATS: batch 480/486 in epoch 120,  batch loss: 0.34255, batch accuracy: 0.89967
Time: 2018-07-14 22:31:05
TRAINING STATS: batch 44/486 in epoch 121,   batch loss: 0.36145, batch accuracy: 0.89183
Time: 2018-07-14 22:31:10
TRAINING STATS: batch 94/486 in epoch 121,   batch loss: 0.36650, batch accuracy: 0.89583
Time: 2018-07-14 22:31:14
TRAINING STATS: batch 144/486 in epoch 121,  batch loss: 0.38863, batch accuracy: 0.88750
Time: 2018-07-14 22:31:18
TRAINING STATS: batch 194/486 in epoch 121,  batch loss: 0.39675, batch accuracy: 0.88433
Time: 2018-07-14 22:31:22
TRAINING STATS: batch 244/486 in epoch 121,  batch loss: 0.37588, batch accuracy: 0.89083
Time: 2018-07-14 22:31:26
TRAINING STATS: batch 294/486 in epoch 121,  batch loss: 0.32842, batch accuracy: 0.90567
Time: 2018-07-14 22:31:30
TRAINING STATS: batch 344/486 in epoch 121,  batch loss: 0.38931, batch accuracy: 0.88650
Time: 2018-07-14 22:31:35
TRAINING STATS: batch 394/486 in epoch 121,  batch loss: 0.36247, batch accuracy: 0.89333
Time: 2018-07-14 22:31:38
TRAINING STATS: batch 444/486 in epoch 121,  batch loss: 0.31454, batch accuracy: 0.90617
Time: 2018-07-14 22:31:42
TRAINING STATS: batch 8/486 in epoch 122,    batch loss: 0.35225, batch accuracy: 0.89433
Time: 2018-07-14 22:31:47
TRAINING STATS: batch 58/486 in epoch 122,   batch loss: 0.37625, batch accuracy: 0.89100
Time: 2018-07-14 22:31:51
TRAINING STATS: batch 108/486 in epoch 122,  batch loss: 0.37217, batch accuracy: 0.89067
Time: 2018-07-14 22:31:54
TRAINING STATS: batch 158/486 in epoch 122,  batch loss: 0.35972, batch accuracy: 0.89567
Time: 2018-07-14 22:31:59
TRAINING STATS: batch 208/486 in epoch 122,  batch loss: 0.36995, batch accuracy: 0.88900
Time: 2018-07-14 22:32:03
TRAINING STATS: batch 258/486 in epoch 122,  batch loss: 0.37416, batch accuracy: 0.89033
Time: 2018-07-14 22:32:06
TRAINING STATS: batch 308/486 in epoch 122,  batch loss: 0.36772, batch accuracy: 0.89350
Time: 2018-07-14 22:32:11
TRAINING STATS: batch 358/486 in epoch 122,  batch loss: 0.36726, batch accuracy: 0.89000
Time: 2018-07-14 22:32:15
TRAINING STATS: batch 408/486 in epoch 122,  batch loss: 0.35732, batch accuracy: 0.89300
Time: 2018-07-14 22:32:19
TRAINING STATS: batch 458/486 in epoch 122,  batch loss: 0.37477, batch accuracy: 0.88850
Time: 2018-07-14 22:32:23
TRAINING STATS: batch 22/486 in epoch 123,   batch loss: 0.36061, batch accuracy: 0.89183
Time: 2018-07-14 22:32:27
TRAINING STATS: batch 72/486 in epoch 123,   batch loss: 0.35238, batch accuracy: 0.89300
Time: 2018-07-14 22:32:31
TRAINING STATS: batch 122/486 in epoch 123,  batch loss: 0.31062, batch accuracy: 0.90767
Time: 2018-07-14 22:32:36
TRAINING STATS: batch 172/486 in epoch 123,  batch loss: 0.34755, batch accuracy: 0.89933
Time: 2018-07-14 22:32:39
TRAINING STATS: batch 222/486 in epoch 123,  batch loss: 0.35820, batch accuracy: 0.89633
Time: 2018-07-14 22:32:43
TRAINING STATS: batch 272/486 in epoch 123,  batch loss: 0.36374, batch accuracy: 0.89400
Time: 2018-07-14 22:32:48
TRAINING STATS: batch 322/486 in epoch 123,  batch loss: 0.33414, batch accuracy: 0.90483
Time: 2018-07-14 22:32:52
TRAINING STATS: batch 372/486 in epoch 123,  batch loss: 0.35429, batch accuracy: 0.89767
Time: 2018-07-14 22:32:55
TRAINING STATS: batch 422/486 in epoch 123,  batch loss: 0.30715, batch accuracy: 0.91133
Time: 2018-07-14 22:33:00
TRAINING STATS: batch 472/486 in epoch 123,  batch loss: 0.36288, batch accuracy: 0.89533
Time: 2018-07-14 22:33:04
TRAINING STATS: batch 36/486 in epoch 124,   batch loss: 0.39925, batch accuracy: 0.88350
Time: 2018-07-14 22:33:07
TRAINING STATS: batch 86/486 in epoch 124,   batch loss: 0.34755, batch accuracy: 0.89533
Time: 2018-07-14 22:33:12
TRAINING STATS: batch 136/486 in epoch 124,  batch loss: 0.37000, batch accuracy: 0.88967
Time: 2018-07-14 22:33:16
TRAINING STATS: batch 186/486 in epoch 124,  batch loss: 0.34749, batch accuracy: 0.90067
Time: 2018-07-14 22:33:19
TRAINING STATS: batch 236/486 in epoch 124,  batch loss: 0.36380, batch accuracy: 0.89250
Time: 2018-07-14 22:33:24
TRAINING STATS: batch 286/486 in epoch 124,  batch loss: 0.37889, batch accuracy: 0.88817
Time: 2018-07-14 22:33:28
TRAINING STATS: batch 336/486 in epoch 124,  batch loss: 0.35008, batch accuracy: 0.89567
Time: 2018-07-14 22:33:32
TRAINING STATS: batch 386/486 in epoch 124,  batch loss: 0.37191, batch accuracy: 0.88567
Time: 2018-07-14 22:33:37
TRAINING STATS: batch 436/486 in epoch 124,  batch loss: 0.34240, batch accuracy: 0.89850
Time: 2018-07-14 22:33:40
TRAINING STATS: batch 0/486 in epoch 125,    batch loss: 0.36557, batch accuracy: 0.89150
Time: 2018-07-14 22:33:44
TRAINING STATS: batch 50/486 in epoch 125,   batch loss: 0.32973, batch accuracy: 0.90317
Time: 2018-07-14 22:33:49
TRAINING STATS: batch 100/486 in epoch 125,  batch loss: 0.33904, batch accuracy: 0.89650
Time: 2018-07-14 22:33:52
TRAINING STATS: batch 150/486 in epoch 125,  batch loss: 0.36375, batch accuracy: 0.89267
Time: 2018-07-14 22:33:56
TRAINING STATS: batch 200/486 in epoch 125,  batch loss: 0.30103, batch accuracy: 0.91067
Time: 2018-07-14 22:34:01
TRAINING STATS: batch 250/486 in epoch 125,  batch loss: 0.37599, batch accuracy: 0.88817
Time: 2018-07-14 22:34:05
TRAINING STATS: batch 300/486 in epoch 125,  batch loss: 0.37568, batch accuracy: 0.88800
Time: 2018-07-14 22:34:08
TRAINING STATS: batch 350/486 in epoch 125,  batch loss: 0.33455, batch accuracy: 0.90167
Time: 2018-07-14 22:34:13
TRAINING STATS: batch 400/486 in epoch 125,  batch loss: 0.32197, batch accuracy: 0.90433
Time: 2018-07-14 22:34:17
TRAINING STATS: batch 450/486 in epoch 125,  batch loss: 0.37152, batch accuracy: 0.89033
Time: 2018-07-14 22:34:20
TRAINING STATS: batch 14/486 in epoch 126,   batch loss: 0.33601, batch accuracy: 0.90233
Time: 2018-07-14 22:34:25
TRAINING STATS: batch 64/486 in epoch 126,   batch loss: 0.41107, batch accuracy: 0.88267
Time: 2018-07-14 22:34:29
TRAINING STATS: batch 114/486 in epoch 126,  batch loss: 0.35774, batch accuracy: 0.89033
Time: 2018-07-14 22:34:33
TRAINING STATS: batch 164/486 in epoch 126,  batch loss: 0.32170, batch accuracy: 0.90383
Time: 2018-07-14 22:34:37
TRAINING STATS: batch 214/486 in epoch 126,  batch loss: 0.35497, batch accuracy: 0.89683
Time: 2018-07-14 22:34:41
TRAINING STATS: batch 264/486 in epoch 126,  batch loss: 0.34210, batch accuracy: 0.90350
Time: 2018-07-14 22:34:45
TRAINING STATS: batch 314/486 in epoch 126,  batch loss: 0.36004, batch accuracy: 0.89433
Time: 2018-07-14 22:34:50
TRAINING STATS: batch 364/486 in epoch 126,  batch loss: 0.36108, batch accuracy: 0.89850
Time: 2018-07-14 22:34:53
TRAINING STATS: batch 414/486 in epoch 126,  batch loss: 0.33908, batch accuracy: 0.89983
Time: 2018-07-14 22:34:57
TRAINING STATS: batch 464/486 in epoch 126,  batch loss: 0.31745, batch accuracy: 0.90833
Time: 2018-07-14 22:35:02
TRAINING STATS: batch 28/486 in epoch 127,   batch loss: 0.35119, batch accuracy: 0.89667
Time: 2018-07-14 22:35:06
TRAINING STATS: batch 78/486 in epoch 127,   batch loss: 0.38790, batch accuracy: 0.88733
Time: 2018-07-14 22:35:09
TRAINING STATS: batch 128/486 in epoch 127,  batch loss: 0.37086, batch accuracy: 0.88950
Time: 2018-07-14 22:35:14
TRAINING STATS: batch 178/486 in epoch 127,  batch loss: 0.29314, batch accuracy: 0.91733
Time: 2018-07-14 22:35:18
TRAINING STATS: batch 228/486 in epoch 127,  batch loss: 0.30394, batch accuracy: 0.90917
Time: 2018-07-14 22:35:21
TRAINING STATS: batch 278/486 in epoch 127,  batch loss: 0.31796, batch accuracy: 0.90717
Time: 2018-07-14 22:35:26
TRAINING STATS: batch 328/486 in epoch 127,  batch loss: 0.35059, batch accuracy: 0.90000
Time: 2018-07-14 22:35:30
TRAINING STATS: batch 378/486 in epoch 127,  batch loss: 0.31733, batch accuracy: 0.90600
Time: 2018-07-14 22:35:34
TRAINING STATS: batch 428/486 in epoch 127,  batch loss: 0.37359, batch accuracy: 0.89017
Time: 2018-07-14 22:35:38
TRAINING STATS: batch 478/486 in epoch 127,  batch loss: 0.32780, batch accuracy: 0.90417
Time: 2018-07-14 22:35:42
TRAINING STATS: batch 42/486 in epoch 128,   batch loss: 0.34207, batch accuracy: 0.90017
Time: 2018-07-14 22:35:46
TRAINING STATS: batch 92/486 in epoch 128,   batch loss: 0.37022, batch accuracy: 0.88900
Time: 2018-07-14 22:35:50
TRAINING STATS: batch 142/486 in epoch 128,  batch loss: 0.31902, batch accuracy: 0.90200
Time: 2018-07-14 22:35:54
TRAINING STATS: batch 192/486 in epoch 128,  batch loss: 0.35872, batch accuracy: 0.89667
Time: 2018-07-14 22:35:58
TRAINING STATS: batch 242/486 in epoch 128,  batch loss: 0.34170, batch accuracy: 0.89433
Time: 2018-07-14 22:36:03
TRAINING STATS: batch 292/486 in epoch 128,  batch loss: 0.35232, batch accuracy: 0.89333
Time: 2018-07-14 22:36:06
TRAINING STATS: batch 342/486 in epoch 128,  batch loss: 0.35203, batch accuracy: 0.89500
Time: 2018-07-14 22:36:10
TRAINING STATS: batch 392/486 in epoch 128,  batch loss: 0.33722, batch accuracy: 0.90033
Time: 2018-07-14 22:36:15
TRAINING STATS: batch 442/486 in epoch 128,  batch loss: 0.30886, batch accuracy: 0.90833
Time: 2018-07-14 22:36:19
TRAINING STATS: batch 6/486 in epoch 129,    batch loss: 0.38309, batch accuracy: 0.88917
Time: 2018-07-14 22:36:22
TRAINING STATS: batch 56/486 in epoch 129,   batch loss: 0.36110, batch accuracy: 0.89033
Time: 2018-07-14 22:36:27
TRAINING STATS: batch 106/486 in epoch 129,  batch loss: 0.36224, batch accuracy: 0.89233
Time: 2018-07-14 22:36:31
TRAINING STATS: batch 156/486 in epoch 129,  batch loss: 0.40277, batch accuracy: 0.87783
Time: 2018-07-14 22:36:34
TRAINING STATS: batch 206/486 in epoch 129,  batch loss: 0.42134, batch accuracy: 0.87350
Time: 2018-07-14 22:36:39
TRAINING STATS: batch 256/486 in epoch 129,  batch loss: 0.37808, batch accuracy: 0.88700
Time: 2018-07-14 22:36:43
TRAINING STATS: batch 306/486 in epoch 129,  batch loss: 0.40528, batch accuracy: 0.87917
Time: 2018-07-14 22:36:47
TRAINING STATS: batch 356/486 in epoch 129,  batch loss: 0.38920, batch accuracy: 0.88517
Time: 2018-07-14 22:36:51
TRAINING STATS: batch 406/486 in epoch 129,  batch loss: 0.39804, batch accuracy: 0.88167
Time: 2018-07-14 22:36:55
TRAINING STATS: batch 456/486 in epoch 129,  batch loss: 0.35991, batch accuracy: 0.89183
Time: 2018-07-14 22:36:59
TRAINING STATS: batch 20/486 in epoch 130,   batch loss: 0.37783, batch accuracy: 0.88550
Time: 2018-07-14 22:37:04
TRAINING STATS: batch 70/486 in epoch 130,   batch loss: 0.33922, batch accuracy: 0.89650
Time: 2018-07-14 22:37:07
TRAINING STATS: batch 120/486 in epoch 130,  batch loss: 0.39759, batch accuracy: 0.88383
Time: 2018-07-14 22:37:11
TRAINING STATS: batch 170/486 in epoch 130,  batch loss: 0.34697, batch accuracy: 0.89350
Time: 2018-07-14 22:37:16
TRAINING STATS: batch 220/486 in epoch 130,  batch loss: 0.36424, batch accuracy: 0.89183
Time: 2018-07-14 22:37:19
TRAINING STATS: batch 270/486 in epoch 130,  batch loss: 0.36391, batch accuracy: 0.89383
Time: 2018-07-14 22:37:23
TRAINING STATS: batch 320/486 in epoch 130,  batch loss: 0.36103, batch accuracy: 0.89167
Time: 2018-07-14 22:37:28
TRAINING STATS: batch 370/486 in epoch 130,  batch loss: 0.37615, batch accuracy: 0.88967
Time: 2018-07-14 22:37:32
TRAINING STATS: batch 420/486 in epoch 130,  batch loss: 0.35963, batch accuracy: 0.89533
Time: 2018-07-14 22:37:35
TRAINING STATS: batch 470/486 in epoch 130,  batch loss: 0.39381, batch accuracy: 0.88467
Time: 2018-07-14 22:37:40
TRAINING STATS: batch 34/486 in epoch 131,   batch loss: 0.38717, batch accuracy: 0.88000
Time: 2018-07-14 22:37:44
TRAINING STATS: batch 84/486 in epoch 131,   batch loss: 0.35971, batch accuracy: 0.89117
Time: 2018-07-14 22:37:48
TRAINING STATS: batch 134/486 in epoch 131,  batch loss: 0.37130, batch accuracy: 0.88833
Time: 2018-07-14 22:37:52
TRAINING STATS: batch 184/486 in epoch 131,  batch loss: 0.39411, batch accuracy: 0.88567
Time: 2018-07-14 22:37:56
TRAINING STATS: batch 234/486 in epoch 131,  batch loss: 0.39898, batch accuracy: 0.88517
Time: 2018-07-14 22:38:00
TRAINING STATS: batch 284/486 in epoch 131,  batch loss: 0.38089, batch accuracy: 0.88767
Time: 2018-07-14 22:38:05
TRAINING STATS: batch 334/486 in epoch 131,  batch loss: 0.34203, batch accuracy: 0.89783
Time: 2018-07-14 22:38:08
TRAINING STATS: batch 384/486 in epoch 131,  batch loss: 0.34857, batch accuracy: 0.90000
Time: 2018-07-14 22:38:12
TRAINING STATS: batch 434/486 in epoch 131,  batch loss: 0.39389, batch accuracy: 0.88500
Time: 2018-07-14 22:38:17
TRAINING STATS: batch 484/486 in epoch 131,  batch loss: 0.35998, batch accuracy: 0.89433
Time: 2018-07-14 22:38:20
TRAINING STATS: batch 48/486 in epoch 132,   batch loss: 0.34776, batch accuracy: 0.89633
Time: 2018-07-14 22:38:24
TRAINING STATS: batch 98/486 in epoch 132,   batch loss: 0.33879, batch accuracy: 0.90183
Time: 2018-07-14 22:38:29
TRAINING STATS: batch 148/486 in epoch 132,  batch loss: 0.38043, batch accuracy: 0.88650
Time: 2018-07-14 22:38:33
TRAINING STATS: batch 198/486 in epoch 132,  batch loss: 0.35133, batch accuracy: 0.89333
Time: 2018-07-14 22:38:36
TRAINING STATS: batch 248/486 in epoch 132,  batch loss: 0.37153, batch accuracy: 0.88450
Time: 2018-07-14 22:38:41
TRAINING STATS: batch 298/486 in epoch 132,  batch loss: 0.36450, batch accuracy: 0.89183
Time: 2018-07-14 22:38:45
TRAINING STATS: batch 348/486 in epoch 132,  batch loss: 0.33353, batch accuracy: 0.90100
Time: 2018-07-14 22:38:48
TRAINING STATS: batch 398/486 in epoch 132,  batch loss: 0.36790, batch accuracy: 0.89167
Time: 2018-07-14 22:38:53
TRAINING STATS: batch 448/486 in epoch 132,  batch loss: 0.37547, batch accuracy: 0.89167
Time: 2018-07-14 22:38:57
TRAINING STATS: batch 12/486 in epoch 133,   batch loss: 0.34356, batch accuracy: 0.89800
Time: 2018-07-14 22:39:01
TRAINING STATS: batch 62/486 in epoch 133,   batch loss: 0.36386, batch accuracy: 0.88917
Time: 2018-07-14 22:39:05
TRAINING STATS: batch 112/486 in epoch 133,  batch loss: 0.32845, batch accuracy: 0.90517
Time: 2018-07-14 22:39:09
TRAINING STATS: batch 162/486 in epoch 133,  batch loss: 0.34925, batch accuracy: 0.89867
Time: 2018-07-14 22:39:13
TRAINING STATS: batch 212/486 in epoch 133,  batch loss: 0.33992, batch accuracy: 0.90183
Time: 2018-07-14 22:39:18
TRAINING STATS: batch 262/486 in epoch 133,  batch loss: 0.37284, batch accuracy: 0.88950
Time: 2018-07-14 22:39:21
TRAINING STATS: batch 312/486 in epoch 133,  batch loss: 0.30675, batch accuracy: 0.90917
Time: 2018-07-14 22:39:25
TRAINING STATS: batch 362/486 in epoch 133,  batch loss: 0.38691, batch accuracy: 0.88583
Time: 2018-07-14 22:39:30
TRAINING STATS: batch 412/486 in epoch 133,  batch loss: 0.33593, batch accuracy: 0.90133
Time: 2018-07-14 22:39:34
TRAINING STATS: batch 462/486 in epoch 133,  batch loss: 0.35691, batch accuracy: 0.89467
Time: 2018-07-14 22:39:37
TRAINING STATS: batch 26/486 in epoch 134,   batch loss: 0.38804, batch accuracy: 0.88867
Time: 2018-07-14 22:39:42
TRAINING STATS: batch 76/486 in epoch 134,   batch loss: 0.40094, batch accuracy: 0.88400
Time: 2018-07-14 22:39:46
TRAINING STATS: batch 126/486 in epoch 134,  batch loss: 0.34704, batch accuracy: 0.89517
Time: 2018-07-14 22:39:49
TRAINING STATS: batch 176/486 in epoch 134,  batch loss: 0.35132, batch accuracy: 0.89967
Time: 2018-07-14 22:39:54
TRAINING STATS: batch 226/486 in epoch 134,  batch loss: 0.35000, batch accuracy: 0.89750
Time: 2018-07-14 22:39:58
TRAINING STATS: batch 276/486 in epoch 134,  batch loss: 0.36177, batch accuracy: 0.89000
Time: 2018-07-14 22:40:02
TRAINING STATS: batch 326/486 in epoch 134,  batch loss: 0.33606, batch accuracy: 0.90217
Time: 2018-07-14 22:40:06
TRAINING STATS: batch 376/486 in epoch 134,  batch loss: 0.37573, batch accuracy: 0.89067
Time: 2018-07-14 22:40:10
TRAINING STATS: batch 426/486 in epoch 134,  batch loss: 0.34359, batch accuracy: 0.89983
Time: 2018-07-14 22:40:14
TRAINING STATS: batch 476/486 in epoch 134,  batch loss: 0.33870, batch accuracy: 0.89883
Time: 2018-07-14 22:40:19
TRAINING STATS: batch 40/486 in epoch 135,   batch loss: 0.34028, batch accuracy: 0.90050
Time: 2018-07-14 22:40:22
TRAINING STATS: batch 90/486 in epoch 135,   batch loss: 0.35838, batch accuracy: 0.89717
Time: 2018-07-14 22:40:26
TRAINING STATS: batch 140/486 in epoch 135,  batch loss: 0.31784, batch accuracy: 0.91133
Time: 2018-07-14 22:40:31
TRAINING STATS: batch 190/486 in epoch 135,  batch loss: 0.32669, batch accuracy: 0.90250
Time: 2018-07-14 22:40:35
TRAINING STATS: batch 240/486 in epoch 135,  batch loss: 0.37264, batch accuracy: 0.89083
Time: 2018-07-14 22:40:38
TRAINING STATS: batch 290/486 in epoch 135,  batch loss: 0.37997, batch accuracy: 0.88617
Time: 2018-07-14 22:40:43
TRAINING STATS: batch 340/486 in epoch 135,  batch loss: 0.36587, batch accuracy: 0.89483
Time: 2018-07-14 22:40:47
TRAINING STATS: batch 390/486 in epoch 135,  batch loss: 0.31460, batch accuracy: 0.90567
Time: 2018-07-14 22:40:50
TRAINING STATS: batch 440/486 in epoch 135,  batch loss: 0.37167, batch accuracy: 0.89467
Time: 2018-07-14 22:40:55
TRAINING STATS: batch 4/486 in epoch 136,    batch loss: 0.35797, batch accuracy: 0.89550
Time: 2018-07-14 22:40:59
TRAINING STATS: batch 54/486 in epoch 136,   batch loss: 0.37578, batch accuracy: 0.88900
Time: 2018-07-14 22:41:03
TRAINING STATS: batch 104/486 in epoch 136,  batch loss: 0.34738, batch accuracy: 0.90050
Time: 2018-07-14 22:41:07
TRAINING STATS: batch 154/486 in epoch 136,  batch loss: 0.29812, batch accuracy: 0.91300
Time: 2018-07-14 22:41:11
TRAINING STATS: batch 204/486 in epoch 136,  batch loss: 0.37210, batch accuracy: 0.88583
Time: 2018-07-14 22:41:15
TRAINING STATS: batch 254/486 in epoch 136,  batch loss: 0.32066, batch accuracy: 0.90483
Time: 2018-07-14 22:41:20
TRAINING STATS: batch 304/486 in epoch 136,  batch loss: 0.33973, batch accuracy: 0.89783
Time: 2018-07-14 22:41:23
TRAINING STATS: batch 354/486 in epoch 136,  batch loss: 0.33655, batch accuracy: 0.90017
Time: 2018-07-14 22:41:27
TRAINING STATS: batch 404/486 in epoch 136,  batch loss: 0.33110, batch accuracy: 0.90150
Time: 2018-07-14 22:41:32
TRAINING STATS: batch 454/486 in epoch 136,  batch loss: 0.29702, batch accuracy: 0.91583
Time: 2018-07-14 22:41:36
TRAINING STATS: batch 18/486 in epoch 137,   batch loss: 0.34112, batch accuracy: 0.90050
Time: 2018-07-14 22:41:39
TRAINING STATS: batch 68/486 in epoch 137,   batch loss: 0.31836, batch accuracy: 0.90550
Time: 2018-07-14 22:41:44
TRAINING STATS: batch 118/486 in epoch 137,  batch loss: 0.35329, batch accuracy: 0.89550
Time: 2018-07-14 22:41:48
TRAINING STATS: batch 168/486 in epoch 137,  batch loss: 0.30058, batch accuracy: 0.91167
Time: 2018-07-14 22:41:51
TRAINING STATS: batch 218/486 in epoch 137,  batch loss: 0.32023, batch accuracy: 0.90417
Time: 2018-07-14 22:41:56
TRAINING STATS: batch 268/486 in epoch 137,  batch loss: 0.33912, batch accuracy: 0.90300
Time: 2018-07-14 22:42:00
TRAINING STATS: batch 318/486 in epoch 137,  batch loss: 0.35446, batch accuracy: 0.89350
Time: 2018-07-14 22:42:04
TRAINING STATS: batch 368/486 in epoch 137,  batch loss: 0.36205, batch accuracy: 0.89267
Time: 2018-07-14 22:42:08
TRAINING STATS: batch 418/486 in epoch 137,  batch loss: 0.36175, batch accuracy: 0.89300
Time: 2018-07-14 22:42:12
TRAINING STATS: batch 468/486 in epoch 137,  batch loss: 0.35407, batch accuracy: 0.89600
Time: 2018-07-14 22:42:16
TRAINING STATS: batch 32/486 in epoch 138,   batch loss: 0.33360, batch accuracy: 0.90383
Time: 2018-07-14 22:42:21
TRAINING STATS: batch 82/486 in epoch 138,   batch loss: 0.36744, batch accuracy: 0.89133
Time: 2018-07-14 22:42:24
TRAINING STATS: batch 132/486 in epoch 138,  batch loss: 0.35290, batch accuracy: 0.89833
Time: 2018-07-14 22:42:28
TRAINING STATS: batch 182/486 in epoch 138,  batch loss: 0.37903, batch accuracy: 0.89067
Time: 2018-07-14 22:42:33
TRAINING STATS: batch 232/486 in epoch 138,  batch loss: 0.37159, batch accuracy: 0.89067
Time: 2018-07-14 22:42:36
TRAINING STATS: batch 282/486 in epoch 138,  batch loss: 0.33029, batch accuracy: 0.90433
Time: 2018-07-14 22:42:40
TRAINING STATS: batch 332/486 in epoch 138,  batch loss: 0.35541, batch accuracy: 0.89733
Time: 2018-07-14 22:42:45
TRAINING STATS: batch 382/486 in epoch 138,  batch loss: 0.35652, batch accuracy: 0.89617
Time: 2018-07-14 22:42:49
TRAINING STATS: batch 432/486 in epoch 138,  batch loss: 0.31798, batch accuracy: 0.90617
Time: 2018-07-14 22:42:52
TRAINING STATS: batch 482/486 in epoch 138,  batch loss: 0.30398, batch accuracy: 0.90867
Time: 2018-07-14 22:42:57
TRAINING STATS: batch 46/486 in epoch 139,   batch loss: 0.35066, batch accuracy: 0.89917
Time: 2018-07-14 22:43:01
TRAINING STATS: batch 96/486 in epoch 139,   batch loss: 0.34376, batch accuracy: 0.89733
Time: 2018-07-14 22:43:05
TRAINING STATS: batch 146/486 in epoch 139,  batch loss: 0.34734, batch accuracy: 0.89667
Time: 2018-07-14 22:43:09
TRAINING STATS: batch 196/486 in epoch 139,  batch loss: 0.35056, batch accuracy: 0.89400
Time: 2018-07-14 22:43:13
TRAINING STATS: batch 246/486 in epoch 139,  batch loss: 0.33161, batch accuracy: 0.90167
Time: 2018-07-14 22:43:17
TRAINING STATS: batch 296/486 in epoch 139,  batch loss: 0.36116, batch accuracy: 0.89283
Time: 2018-07-14 22:43:21
TRAINING STATS: batch 346/486 in epoch 139,  batch loss: 0.32807, batch accuracy: 0.90733
Time: 2018-07-14 22:43:25
TRAINING STATS: batch 396/486 in epoch 139,  batch loss: 0.37646, batch accuracy: 0.88967
Time: 2018-07-14 22:43:29
TRAINING STATS: batch 446/486 in epoch 139,  batch loss: 0.40100, batch accuracy: 0.88400
Time: 2018-07-14 22:43:34
TRAINING STATS: batch 10/486 in epoch 140,   batch loss: 0.38067, batch accuracy: 0.88867
Time: 2018-07-14 22:43:37
TRAINING STATS: batch 60/486 in epoch 140,   batch loss: 0.38099, batch accuracy: 0.88850
Time: 2018-07-14 22:43:41
TRAINING STATS: batch 110/486 in epoch 140,  batch loss: 0.40929, batch accuracy: 0.87750
Time: 2018-07-14 22:43:46
TRAINING STATS: batch 160/486 in epoch 140,  batch loss: 0.37475, batch accuracy: 0.88867
Time: 2018-07-14 22:43:50
TRAINING STATS: batch 210/486 in epoch 140,  batch loss: 0.36196, batch accuracy: 0.89333
Time: 2018-07-14 22:43:53
TRAINING STATS: batch 260/486 in epoch 140,  batch loss: 0.43611, batch accuracy: 0.86800
Time: 2018-07-14 22:43:58
TRAINING STATS: batch 310/486 in epoch 140,  batch loss: 0.37553, batch accuracy: 0.88900
Time: 2018-07-14 22:44:02
TRAINING STATS: batch 360/486 in epoch 140,  batch loss: 0.40471, batch accuracy: 0.88133
Time: 2018-07-14 22:44:05
TRAINING STATS: batch 410/486 in epoch 140,  batch loss: 0.35975, batch accuracy: 0.89533
Time: 2018-07-14 22:44:10
TRAINING STATS: batch 460/486 in epoch 140,  batch loss: 0.42915, batch accuracy: 0.87317
Time: 2018-07-14 22:44:14
TRAINING STATS: batch 24/486 in epoch 141,   batch loss: 0.42677, batch accuracy: 0.87183
Time: 2018-07-14 22:44:18
TRAINING STATS: batch 74/486 in epoch 141,   batch loss: 0.38553, batch accuracy: 0.88600
Time: 2018-07-14 22:44:23
TRAINING STATS: batch 124/486 in epoch 141,  batch loss: 0.39225, batch accuracy: 0.88367
Time: 2018-07-14 22:44:26
TRAINING STATS: batch 174/486 in epoch 141,  batch loss: 0.43776, batch accuracy: 0.86983
Time: 2018-07-14 22:44:30
TRAINING STATS: batch 224/486 in epoch 141,  batch loss: 0.43425, batch accuracy: 0.87533
Time: 2018-07-14 22:44:35
TRAINING STATS: batch 274/486 in epoch 141,  batch loss: 0.42216, batch accuracy: 0.87567
Time: 2018-07-14 22:44:38
TRAINING STATS: batch 324/486 in epoch 141,  batch loss: 0.38715, batch accuracy: 0.88750
Time: 2018-07-14 22:44:42
TRAINING STATS: batch 374/486 in epoch 141,  batch loss: 0.44272, batch accuracy: 0.87000
Time: 2018-07-14 22:44:47
TRAINING STATS: batch 424/486 in epoch 141,  batch loss: 0.36434, batch accuracy: 0.89517
Time: 2018-07-14 22:44:50
TRAINING STATS: batch 474/486 in epoch 141,  batch loss: 0.40200, batch accuracy: 0.88050
Time: 2018-07-14 22:44:54
TRAINING STATS: batch 38/486 in epoch 142,   batch loss: 0.41893, batch accuracy: 0.87400
Time: 2018-07-14 22:44:59
TRAINING STATS: batch 88/486 in epoch 142,   batch loss: 0.38607, batch accuracy: 0.88450
Time: 2018-07-14 22:45:03
TRAINING STATS: batch 138/486 in epoch 142,  batch loss: 0.37804, batch accuracy: 0.88767
Time: 2018-07-14 22:45:06
TRAINING STATS: batch 188/486 in epoch 142,  batch loss: 0.38023, batch accuracy: 0.88683
Time: 2018-07-14 22:45:11
TRAINING STATS: batch 238/486 in epoch 142,  batch loss: 0.39832, batch accuracy: 0.88467
Time: 2018-07-14 22:45:15
TRAINING STATS: batch 288/486 in epoch 142,  batch loss: 0.43947, batch accuracy: 0.87467
Time: 2018-07-14 22:45:19
TRAINING STATS: batch 338/486 in epoch 142,  batch loss: 0.40606, batch accuracy: 0.88267
Time: 2018-07-14 22:45:23
TRAINING STATS: batch 388/486 in epoch 142,  batch loss: 0.37172, batch accuracy: 0.89350
Time: 2018-07-14 22:45:27
TRAINING STATS: batch 438/486 in epoch 142,  batch loss: 0.40588, batch accuracy: 0.88233
Time: 2018-07-14 22:45:31
TRAINING STATS: batch 2/486 in epoch 143,    batch loss: 0.39193, batch accuracy: 0.88567
Time: 2018-07-14 22:45:36
TRAINING STATS: batch 52/486 in epoch 143,   batch loss: 0.38839, batch accuracy: 0.88650
Time: 2018-07-14 22:45:39
TRAINING STATS: batch 102/486 in epoch 143,  batch loss: 0.40908, batch accuracy: 0.88017
Time: 2018-07-14 22:45:43
TRAINING STATS: batch 152/486 in epoch 143,  batch loss: 0.39553, batch accuracy: 0.88350
Time: 2018-07-14 22:45:48
TRAINING STATS: batch 202/486 in epoch 143,  batch loss: 0.40667, batch accuracy: 0.88133
Time: 2018-07-14 22:45:51
TRAINING STATS: batch 252/486 in epoch 143,  batch loss: 0.39882, batch accuracy: 0.88300
Time: 2018-07-14 22:45:55
TRAINING STATS: batch 302/486 in epoch 143,  batch loss: 0.41306, batch accuracy: 0.87933
Time: 2018-07-14 22:46:00
TRAINING STATS: batch 352/486 in epoch 143,  batch loss: 0.37319, batch accuracy: 0.88850
Time: 2018-07-14 22:46:04
TRAINING STATS: batch 402/486 in epoch 143,  batch loss: 0.36669, batch accuracy: 0.89117
Time: 2018-07-14 22:46:07
TRAINING STATS: batch 452/486 in epoch 143,  batch loss: 0.42068, batch accuracy: 0.87800
Time: 2018-07-14 22:46:12
TRAINING STATS: batch 16/486 in epoch 144,   batch loss: 0.37125, batch accuracy: 0.89300
Time: 2018-07-14 22:46:16
TRAINING STATS: batch 66/486 in epoch 144,   batch loss: 0.40449, batch accuracy: 0.88283
Time: 2018-07-14 22:46:20
TRAINING STATS: batch 116/486 in epoch 144,  batch loss: 0.36813, batch accuracy: 0.89467
Time: 2018-07-14 22:46:24
TRAINING STATS: batch 166/486 in epoch 144,  batch loss: 0.34962, batch accuracy: 0.90067
Time: 2018-07-14 22:46:28
TRAINING STATS: batch 216/486 in epoch 144,  batch loss: 0.41687, batch accuracy: 0.87850
Time: 2018-07-14 22:46:32
TRAINING STATS: batch 266/486 in epoch 144,  batch loss: 0.38402, batch accuracy: 0.89017
Time: 2018-07-14 22:46:36
TRAINING STATS: batch 316/486 in epoch 144,  batch loss: 0.38252, batch accuracy: 0.89100
Time: 2018-07-14 22:46:40
TRAINING STATS: batch 366/486 in epoch 144,  batch loss: 0.42593, batch accuracy: 0.87633
Time: 2018-07-14 22:46:44
TRAINING STATS: batch 416/486 in epoch 144,  batch loss: 0.44210, batch accuracy: 0.87383
Time: 2018-07-14 22:46:49
TRAINING STATS: batch 466/486 in epoch 144,  batch loss: 0.35785, batch accuracy: 0.89567
Time: 2018-07-14 22:46:52
TRAINING STATS: batch 30/486 in epoch 145,   batch loss: 0.33910, batch accuracy: 0.90067
Time: 2018-07-14 22:46:56
TRAINING STATS: batch 80/486 in epoch 145,   batch loss: 0.41682, batch accuracy: 0.87633
Time: 2018-07-14 22:47:01
TRAINING STATS: batch 130/486 in epoch 145,  batch loss: 0.41359, batch accuracy: 0.87367
Time: 2018-07-14 22:47:05
TRAINING STATS: batch 180/486 in epoch 145,  batch loss: 0.35376, batch accuracy: 0.89917
Time: 2018-07-14 22:47:08
TRAINING STATS: batch 230/486 in epoch 145,  batch loss: 0.38706, batch accuracy: 0.88500
Time: 2018-07-14 22:47:13
TRAINING STATS: batch 280/486 in epoch 145,  batch loss: 0.40021, batch accuracy: 0.88250
Time: 2018-07-14 22:47:17
TRAINING STATS: batch 330/486 in epoch 145,  batch loss: 0.40218, batch accuracy: 0.88200
Time: 2018-07-14 22:47:20
TRAINING STATS: batch 380/486 in epoch 145,  batch loss: 0.37269, batch accuracy: 0.88850
Time: 2018-07-14 22:47:25
TRAINING STATS: batch 430/486 in epoch 145,  batch loss: 0.37521, batch accuracy: 0.88950
Time: 2018-07-14 22:47:29
TRAINING STATS: batch 480/486 in epoch 145,  batch loss: 0.36005, batch accuracy: 0.89817
Time: 2018-07-14 22:47:33
TRAINING STATS: batch 44/486 in epoch 146,   batch loss: 0.38503, batch accuracy: 0.88650
Time: 2018-07-14 22:47:37
TRAINING STATS: batch 94/486 in epoch 146,   batch loss: 0.39988, batch accuracy: 0.88333
Time: 2018-07-14 22:47:41
TRAINING STATS: batch 144/486 in epoch 146,  batch loss: 0.42277, batch accuracy: 0.87367
Time: 2018-07-14 22:47:45
TRAINING STATS: batch 194/486 in epoch 146,  batch loss: 0.43721, batch accuracy: 0.87250
Time: 2018-07-14 22:47:50
TRAINING STATS: batch 244/486 in epoch 146,  batch loss: 0.39603, batch accuracy: 0.88517
Time: 2018-07-14 22:47:53
TRAINING STATS: batch 294/486 in epoch 146,  batch loss: 0.35135, batch accuracy: 0.89733
Time: 2018-07-14 22:47:57
TRAINING STATS: batch 344/486 in epoch 146,  batch loss: 0.42825, batch accuracy: 0.87467
Time: 2018-07-14 22:48:02
TRAINING STATS: batch 394/486 in epoch 146,  batch loss: 0.40935, batch accuracy: 0.88350
Time: 2018-07-14 22:48:05
TRAINING STATS: batch 444/486 in epoch 146,  batch loss: 0.35528, batch accuracy: 0.89533
Time: 2018-07-14 22:48:09
TRAINING STATS: batch 8/486 in epoch 147,    batch loss: 0.37586, batch accuracy: 0.89150
Time: 2018-07-14 22:48:14
TRAINING STATS: batch 58/486 in epoch 147,   batch loss: 0.37869, batch accuracy: 0.89067
Time: 2018-07-14 22:48:18
TRAINING STATS: batch 108/486 in epoch 147,  batch loss: 0.36775, batch accuracy: 0.89417
Time: 2018-07-14 22:48:21
TRAINING STATS: batch 158/486 in epoch 147,  batch loss: 0.38189, batch accuracy: 0.88750
Time: 2018-07-14 22:48:26
TRAINING STATS: batch 208/486 in epoch 147,  batch loss: 0.38764, batch accuracy: 0.88583
Time: 2018-07-14 22:48:30
TRAINING STATS: batch 258/486 in epoch 147,  batch loss: 0.39859, batch accuracy: 0.88350
Time: 2018-07-14 22:48:33
TRAINING STATS: batch 308/486 in epoch 147,  batch loss: 0.40792, batch accuracy: 0.88517
Time: 2018-07-14 22:48:38
TRAINING STATS: batch 358/486 in epoch 147,  batch loss: 0.39922, batch accuracy: 0.88367
Time: 2018-07-14 22:48:42
TRAINING STATS: batch 408/486 in epoch 147,  batch loss: 0.39906, batch accuracy: 0.87950
Time: 2018-07-14 22:48:46
TRAINING STATS: batch 458/486 in epoch 147,  batch loss: 0.40745, batch accuracy: 0.88517
Time: 2018-07-14 22:48:50
TRAINING STATS: batch 22/486 in epoch 148,   batch loss: 0.42890, batch accuracy: 0.87467
Time: 2018-07-14 22:48:54
TRAINING STATS: batch 72/486 in epoch 148,   batch loss: 0.38688, batch accuracy: 0.88617
Time: 2018-07-14 22:48:58
TRAINING STATS: batch 122/486 in epoch 148,  batch loss: 0.34085, batch accuracy: 0.89867
Time: 2018-07-14 22:49:03
TRAINING STATS: batch 172/486 in epoch 148,  batch loss: 0.39195, batch accuracy: 0.88417
Time: 2018-07-14 22:49:06
TRAINING STATS: batch 222/486 in epoch 148,  batch loss: 0.40363, batch accuracy: 0.88450
Time: 2018-07-14 22:49:10
TRAINING STATS: batch 272/486 in epoch 148,  batch loss: 0.41237, batch accuracy: 0.88050
Time: 2018-07-14 22:49:15
TRAINING STATS: batch 322/486 in epoch 148,  batch loss: 0.37019, batch accuracy: 0.89133
Time: 2018-07-14 22:49:19
TRAINING STATS: batch 372/486 in epoch 148,  batch loss: 0.39477, batch accuracy: 0.88650
Time: 2018-07-14 22:49:22
TRAINING STATS: batch 422/486 in epoch 148,  batch loss: 0.34340, batch accuracy: 0.89617
Time: 2018-07-14 22:49:27
TRAINING STATS: batch 472/486 in epoch 148,  batch loss: 0.44260, batch accuracy: 0.87200
Time: 2018-07-14 22:49:31
TRAINING STATS: batch 36/486 in epoch 149,   batch loss: 0.44389, batch accuracy: 0.87050
Time: 2018-07-14 22:49:34
TRAINING STATS: batch 86/486 in epoch 149,   batch loss: 0.37808, batch accuracy: 0.88850
Time: 2018-07-14 22:49:39
TRAINING STATS: batch 136/486 in epoch 149,  batch loss: 0.41072, batch accuracy: 0.87733
Time: 2018-07-14 22:49:43
TRAINING STATS: batch 186/486 in epoch 149,  batch loss: 0.38470, batch accuracy: 0.88850
Time: 2018-07-14 22:49:47
TRAINING STATS: batch 236/486 in epoch 149,  batch loss: 0.39538, batch accuracy: 0.88100
Time: 2018-07-14 22:49:51
TRAINING STATS: batch 286/486 in epoch 149,  batch loss: 0.38865, batch accuracy: 0.88850
Time: 2018-07-14 22:49:55
TRAINING STATS: batch 336/486 in epoch 149,  batch loss: 0.40515, batch accuracy: 0.87950
Time: 2018-07-14 22:49:59
TRAINING STATS: batch 386/486 in epoch 149,  batch loss: 0.42007, batch accuracy: 0.87783
Time: 2018-07-14 22:50:04
TRAINING STATS: batch 436/486 in epoch 149,  batch loss: 0.38322, batch accuracy: 0.88683
Time: 2018-07-14 22:50:07
TRAINING STATS: batch 0/486 in epoch 150,    batch loss: 0.39745, batch accuracy: 0.88483
Time: 2018-07-14 22:50:11
TRAINING STATS: batch 50/486 in epoch 150,   batch loss: 0.35892, batch accuracy: 0.89583
Time: 2018-07-14 22:50:16
TRAINING STATS: batch 100/486 in epoch 150,  batch loss: 0.38337, batch accuracy: 0.88483
Time: 2018-07-14 22:50:19
TRAINING STATS: batch 150/486 in epoch 150,  batch loss: 0.39079, batch accuracy: 0.88617
Time: 2018-07-14 22:50:23
TRAINING STATS: batch 200/486 in epoch 150,  batch loss: 0.32642, batch accuracy: 0.90583
Time: 2018-07-14 22:50:28
TRAINING STATS: batch 250/486 in epoch 150,  batch loss: 0.42208, batch accuracy: 0.87350
Time: 2018-07-14 22:50:32
TRAINING STATS: batch 300/486 in epoch 150,  batch loss: 0.41003, batch accuracy: 0.88133
Time: 2018-07-14 22:50:35
TRAINING STATS: batch 350/486 in epoch 150,  batch loss: 0.37700, batch accuracy: 0.88633
Time: 2018-07-14 22:50:40
TRAINING STATS: batch 400/486 in epoch 150,  batch loss: 0.35566, batch accuracy: 0.89533
Time: 2018-07-14 22:50:44
TRAINING STATS: batch 450/486 in epoch 150,  batch loss: 0.38418, batch accuracy: 0.88717
Time: 2018-07-14 22:50:48
TRAINING STATS: batch 14/486 in epoch 151,   batch loss: 0.38113, batch accuracy: 0.89317
Time: 2018-07-14 22:50:52
TRAINING STATS: batch 64/486 in epoch 151,   batch loss: 0.45480, batch accuracy: 0.86717
Time: 2018-07-14 22:50:56
TRAINING STATS: batch 114/486 in epoch 151,  batch loss: 0.42210, batch accuracy: 0.87567
Time: 2018-07-14 22:51:00
TRAINING STATS: batch 164/486 in epoch 151,  batch loss: 0.36874, batch accuracy: 0.89100
Time: 2018-07-14 22:51:05
TRAINING STATS: batch 214/486 in epoch 151,  batch loss: 0.37587, batch accuracy: 0.89300
Time: 2018-07-14 22:51:08
TRAINING STATS: batch 264/486 in epoch 151,  batch loss: 0.39079, batch accuracy: 0.88783
Time: 2018-07-14 22:51:12
TRAINING STATS: batch 314/486 in epoch 151,  batch loss: 0.43009, batch accuracy: 0.87517
Time: 2018-07-14 22:51:17
TRAINING STATS: batch 364/486 in epoch 151,  batch loss: 0.41020, batch accuracy: 0.88117
Time: 2018-07-14 22:51:20
TRAINING STATS: batch 414/486 in epoch 151,  batch loss: 0.40239, batch accuracy: 0.88117
Time: 2018-07-14 22:51:24
TRAINING STATS: batch 464/486 in epoch 151,  batch loss: 0.37374, batch accuracy: 0.89067
Time: 2018-07-14 22:51:29
TRAINING STATS: batch 28/486 in epoch 152,   batch loss: 0.37353, batch accuracy: 0.88850
Time: 2018-07-14 22:51:33
TRAINING STATS: batch 78/486 in epoch 152,   batch loss: 0.41299, batch accuracy: 0.87800
Time: 2018-07-14 22:51:36
TRAINING STATS: batch 128/486 in epoch 152,  batch loss: 0.41327, batch accuracy: 0.87883
Time: 2018-07-14 22:51:41
TRAINING STATS: batch 178/486 in epoch 152,  batch loss: 0.39632, batch accuracy: 0.88417
Time: 2018-07-14 22:51:45
TRAINING STATS: batch 228/486 in epoch 152,  batch loss: 0.37748, batch accuracy: 0.89250
Time: 2018-07-14 22:51:49
TRAINING STATS: batch 278/486 in epoch 152,  batch loss: 0.39033, batch accuracy: 0.88750
Time: 2018-07-14 22:51:53
TRAINING STATS: batch 328/486 in epoch 152,  batch loss: 0.38214, batch accuracy: 0.89000
Time: 2018-07-14 22:51:57
TRAINING STATS: batch 378/486 in epoch 152,  batch loss: 0.37877, batch accuracy: 0.89183
Time: 2018-07-14 22:52:01
TRAINING STATS: batch 428/486 in epoch 152,  batch loss: 0.42063, batch accuracy: 0.87633
Time: 2018-07-14 22:52:05
TRAINING STATS: batch 478/486 in epoch 152,  batch loss: 0.35585, batch accuracy: 0.89700
Time: 2018-07-14 22:52:09
TRAINING STATS: batch 42/486 in epoch 153,   batch loss: 0.38759, batch accuracy: 0.89000
Time: 2018-07-14 22:52:13
TRAINING STATS: batch 92/486 in epoch 153,   batch loss: 0.40578, batch accuracy: 0.87967
Time: 2018-07-14 22:52:18
TRAINING STATS: batch 142/486 in epoch 153,  batch loss: 0.36163, batch accuracy: 0.89600
Time: 2018-07-14 22:52:21
TRAINING STATS: batch 192/486 in epoch 153,  batch loss: 0.42609, batch accuracy: 0.87400
Time: 2018-07-14 22:52:25
TRAINING STATS: batch 242/486 in epoch 153,  batch loss: 0.41078, batch accuracy: 0.88000
Time: 2018-07-14 22:52:30
TRAINING STATS: batch 292/486 in epoch 153,  batch loss: 0.40333, batch accuracy: 0.88100
Time: 2018-07-14 22:52:34
TRAINING STATS: batch 342/486 in epoch 153,  batch loss: 0.39307, batch accuracy: 0.88533
Time: 2018-07-14 22:52:37
TRAINING STATS: batch 392/486 in epoch 153,  batch loss: 0.36881, batch accuracy: 0.89350
Time: 2018-07-14 22:52:42
TRAINING STATS: batch 442/486 in epoch 153,  batch loss: 0.35240, batch accuracy: 0.89533
Time: 2018-07-14 22:52:46
TRAINING STATS: batch 6/486 in epoch 154,    batch loss: 0.44762, batch accuracy: 0.87050
Time: 2018-07-14 22:52:49
TRAINING STATS: batch 56/486 in epoch 154,   batch loss: 0.40872, batch accuracy: 0.87733
Time: 2018-07-14 22:52:54
TRAINING STATS: batch 106/486 in epoch 154,  batch loss: 0.42961, batch accuracy: 0.87200
Time: 2018-07-14 22:52:58
TRAINING STATS: batch 156/486 in epoch 154,  batch loss: 0.41019, batch accuracy: 0.87900
Time: 2018-07-14 22:53:02
TRAINING STATS: batch 206/486 in epoch 154,  batch loss: 0.43699, batch accuracy: 0.87167
Time: 2018-07-14 22:53:07
TRAINING STATS: batch 256/486 in epoch 154,  batch loss: 0.36982, batch accuracy: 0.89000
Time: 2018-07-14 22:53:10
TRAINING STATS: batch 306/486 in epoch 154,  batch loss: 0.40854, batch accuracy: 0.88183
Time: 2018-07-14 22:53:14
TRAINING STATS: batch 356/486 in epoch 154,  batch loss: 0.38358, batch accuracy: 0.88667
Time: 2018-07-14 22:53:19
TRAINING STATS: batch 406/486 in epoch 154,  batch loss: 0.39660, batch accuracy: 0.88250
Time: 2018-07-14 22:53:22
TRAINING STATS: batch 456/486 in epoch 154,  batch loss: 0.33712, batch accuracy: 0.90183
Time: 2018-07-14 22:53:26
TRAINING STATS: batch 20/486 in epoch 155,   batch loss: 0.38296, batch accuracy: 0.88833
Time: 2018-07-14 22:53:31
TRAINING STATS: batch 70/486 in epoch 155,   batch loss: 0.31472, batch accuracy: 0.90650
Time: 2018-07-14 22:53:34
TRAINING STATS: batch 120/486 in epoch 155,  batch loss: 0.39614, batch accuracy: 0.88150
Time: 2018-07-14 22:53:38
TRAINING STATS: batch 170/486 in epoch 155,  batch loss: 0.34024, batch accuracy: 0.90183
Time: 2018-07-14 22:53:43
TRAINING STATS: batch 220/486 in epoch 155,  batch loss: 0.33698, batch accuracy: 0.90183
Time: 2018-07-14 22:53:47
TRAINING STATS: batch 270/486 in epoch 155,  batch loss: 0.36205, batch accuracy: 0.89017
Time: 2018-07-14 22:53:50
TRAINING STATS: batch 320/486 in epoch 155,  batch loss: 0.37324, batch accuracy: 0.89267
Time: 2018-07-14 22:53:55
TRAINING STATS: batch 370/486 in epoch 155,  batch loss: 0.40032, batch accuracy: 0.88383
Time: 2018-07-14 22:53:59
TRAINING STATS: batch 420/486 in epoch 155,  batch loss: 0.38752, batch accuracy: 0.88833
Time: 2018-07-14 22:54:03
TRAINING STATS: batch 470/486 in epoch 155,  batch loss: 0.41056, batch accuracy: 0.87800
Time: 2018-07-14 22:54:07
TRAINING STATS: batch 34/486 in epoch 156,   batch loss: 0.40677, batch accuracy: 0.88083
Time: 2018-07-14 22:54:11
TRAINING STATS: batch 84/486 in epoch 156,   batch loss: 0.36776, batch accuracy: 0.89467
Time: 2018-07-14 22:54:15
TRAINING STATS: batch 134/486 in epoch 156,  batch loss: 0.37185, batch accuracy: 0.88950
Time: 2018-07-14 22:54:20
TRAINING STATS: batch 184/486 in epoch 156,  batch loss: 0.40495, batch accuracy: 0.88333
Time: 2018-07-14 22:54:23
TRAINING STATS: batch 234/486 in epoch 156,  batch loss: 0.42321, batch accuracy: 0.87750
Time: 2018-07-14 22:54:27
TRAINING STATS: batch 284/486 in epoch 156,  batch loss: 0.39545, batch accuracy: 0.88433
Time: 2018-07-14 22:54:32
TRAINING STATS: batch 334/486 in epoch 156,  batch loss: 0.37595, batch accuracy: 0.88683
Time: 2018-07-14 22:54:35
TRAINING STATS: batch 384/486 in epoch 156,  batch loss: 0.37312, batch accuracy: 0.89133
Time: 2018-07-14 22:54:39
TRAINING STATS: batch 434/486 in epoch 156,  batch loss: 0.40313, batch accuracy: 0.88217
Time: 2018-07-14 22:54:44
TRAINING STATS: batch 484/486 in epoch 156,  batch loss: 0.40948, batch accuracy: 0.87867
Time: 2018-07-14 22:54:48
TRAINING STATS: batch 48/486 in epoch 157,   batch loss: 0.39515, batch accuracy: 0.88517
Time: 2018-07-14 22:54:51
TRAINING STATS: batch 98/486 in epoch 157,   batch loss: 0.36342, batch accuracy: 0.89567
Time: 2018-07-14 22:54:56
TRAINING STATS: batch 148/486 in epoch 157,  batch loss: 0.37733, batch accuracy: 0.88867
Time: 2018-07-14 22:55:00
TRAINING STATS: batch 198/486 in epoch 157,  batch loss: 0.39127, batch accuracy: 0.88583
Time: 2018-07-14 22:55:03
TRAINING STATS: batch 248/486 in epoch 157,  batch loss: 0.40442, batch accuracy: 0.88433
Time: 2018-07-14 22:55:08
TRAINING STATS: batch 298/486 in epoch 157,  batch loss: 0.37627, batch accuracy: 0.89450
Time: 2018-07-14 22:55:12
TRAINING STATS: batch 348/486 in epoch 157,  batch loss: 0.39169, batch accuracy: 0.88583
Time: 2018-07-14 22:55:16
TRAINING STATS: batch 398/486 in epoch 157,  batch loss: 0.38976, batch accuracy: 0.88383
Time: 2018-07-14 22:55:21
TRAINING STATS: batch 448/486 in epoch 157,  batch loss: 0.41533, batch accuracy: 0.88100
Time: 2018-07-14 22:55:24
TRAINING STATS: batch 12/486 in epoch 158,   batch loss: 0.41192, batch accuracy: 0.87717
Time: 2018-07-14 22:55:28
TRAINING STATS: batch 62/486 in epoch 158,   batch loss: 0.42628, batch accuracy: 0.87400
Time: 2018-07-14 22:55:33
TRAINING STATS: batch 112/486 in epoch 158,  batch loss: 0.39037, batch accuracy: 0.88617
Time: 2018-07-14 22:55:36
TRAINING STATS: batch 162/486 in epoch 158,  batch loss: 0.38234, batch accuracy: 0.88967
Time: 2018-07-14 22:55:40
TRAINING STATS: batch 212/486 in epoch 158,  batch loss: 0.37249, batch accuracy: 0.89000
Time: 2018-07-14 22:55:45
TRAINING STATS: batch 262/486 in epoch 158,  batch loss: 0.40632, batch accuracy: 0.87950
Time: 2018-07-14 22:55:49
TRAINING STATS: batch 312/486 in epoch 158,  batch loss: 0.36446, batch accuracy: 0.89667
Time: 2018-07-14 22:55:52
TRAINING STATS: batch 362/486 in epoch 158,  batch loss: 0.41364, batch accuracy: 0.88383
Time: 2018-07-14 22:55:57
TRAINING STATS: batch 412/486 in epoch 158,  batch loss: 0.34861, batch accuracy: 0.89567
Time: 2018-07-14 22:56:01
TRAINING STATS: batch 462/486 in epoch 158,  batch loss: 0.40192, batch accuracy: 0.88283
Time: 2018-07-14 22:56:04
TRAINING STATS: batch 26/486 in epoch 159,   batch loss: 0.43577, batch accuracy: 0.87350
Time: 2018-07-14 22:56:09
TRAINING STATS: batch 76/486 in epoch 159,   batch loss: 0.41421, batch accuracy: 0.88117
Time: 2018-07-14 22:56:13
TRAINING STATS: batch 126/486 in epoch 159,  batch loss: 0.40179, batch accuracy: 0.87667
Time: 2018-07-14 22:56:17
TRAINING STATS: batch 176/486 in epoch 159,  batch loss: 0.36358, batch accuracy: 0.89483
Time: 2018-07-14 22:56:21
TRAINING STATS: batch 226/486 in epoch 159,  batch loss: 0.36575, batch accuracy: 0.88967
Time: 2018-07-14 22:56:25
TRAINING STATS: batch 276/486 in epoch 159,  batch loss: 0.41284, batch accuracy: 0.88117
Time: 2018-07-14 22:56:29
TRAINING STATS: batch 326/486 in epoch 159,  batch loss: 0.37468, batch accuracy: 0.88983
Time: 2018-07-14 22:56:34
TRAINING STATS: batch 376/486 in epoch 159,  batch loss: 0.44644, batch accuracy: 0.87000
Time: 2018-07-14 22:56:37
TRAINING STATS: batch 426/486 in epoch 159,  batch loss: 0.42704, batch accuracy: 0.87500
Time: 2018-07-14 22:56:41
TRAINING STATS: batch 476/486 in epoch 159,  batch loss: 0.38448, batch accuracy: 0.88683
Time: 2018-07-14 22:56:46
TRAINING STATS: batch 40/486 in epoch 160,   batch loss: 0.39395, batch accuracy: 0.88533
Time: 2018-07-14 22:56:49
TRAINING STATS: batch 90/486 in epoch 160,   batch loss: 0.42206, batch accuracy: 0.88100
Time: 2018-07-14 22:56:53
TRAINING STATS: batch 140/486 in epoch 160,  batch loss: 0.39699, batch accuracy: 0.88317
Time: 2018-07-14 22:56:58
TRAINING STATS: batch 190/486 in epoch 160,  batch loss: 0.38332, batch accuracy: 0.88667
Time: 2018-07-14 22:57:02
TRAINING STATS: batch 240/486 in epoch 160,  batch loss: 0.41219, batch accuracy: 0.88150
Time: 2018-07-14 22:57:05
TRAINING STATS: batch 290/486 in epoch 160,  batch loss: 0.41200, batch accuracy: 0.87867
Time: 2018-07-14 22:57:10
TRAINING STATS: batch 340/486 in epoch 160,  batch loss: 0.39956, batch accuracy: 0.88683
Time: 2018-07-14 22:57:14
TRAINING STATS: batch 390/486 in epoch 160,  batch loss: 0.35223, batch accuracy: 0.89600
Time: 2018-07-14 22:57:18
TRAINING STATS: batch 440/486 in epoch 160,  batch loss: 0.40541, batch accuracy: 0.87800
Time: 2018-07-14 22:57:22
TRAINING STATS: batch 4/486 in epoch 161,    batch loss: 0.37179, batch accuracy: 0.89283
Time: 2018-07-14 22:57:26
TRAINING STATS: batch 54/486 in epoch 161,   batch loss: 0.39613, batch accuracy: 0.88550
Time: 2018-07-14 22:57:30
TRAINING STATS: batch 104/486 in epoch 161,  batch loss: 0.38296, batch accuracy: 0.89067
Time: 2018-07-14 22:57:35
TRAINING STATS: batch 154/486 in epoch 161,  batch loss: 0.35384, batch accuracy: 0.89717
Time: 2018-07-14 22:57:38
TRAINING STATS: batch 204/486 in epoch 161,  batch loss: 0.43015, batch accuracy: 0.87183
Time: 2018-07-14 22:57:42
TRAINING STATS: batch 254/486 in epoch 161,  batch loss: 0.37119, batch accuracy: 0.88983
Time: 2018-07-14 22:57:47
TRAINING STATS: batch 304/486 in epoch 161,  batch loss: 0.38829, batch accuracy: 0.88683
Time: 2018-07-14 22:57:51
TRAINING STATS: batch 354/486 in epoch 161,  batch loss: 0.39373, batch accuracy: 0.88767
Time: 2018-07-14 22:57:54
TRAINING STATS: batch 404/486 in epoch 161,  batch loss: 0.37952, batch accuracy: 0.89083
Time: 2018-07-14 22:57:59
TRAINING STATS: batch 454/486 in epoch 161,  batch loss: 0.34136, batch accuracy: 0.90067
Time: 2018-07-14 22:58:03
TRAINING STATS: batch 18/486 in epoch 162,   batch loss: 0.41497, batch accuracy: 0.87867
Time: 2018-07-14 22:58:06
TRAINING STATS: batch 68/486 in epoch 162,   batch loss: 0.36354, batch accuracy: 0.89300
Time: 2018-07-14 22:58:11
TRAINING STATS: batch 118/486 in epoch 162,  batch loss: 0.38615, batch accuracy: 0.88767
Time: 2018-07-14 22:58:15
TRAINING STATS: batch 168/486 in epoch 162,  batch loss: 0.35128, batch accuracy: 0.89617
Time: 2018-07-14 22:58:18
TRAINING STATS: batch 218/486 in epoch 162,  batch loss: 0.38170, batch accuracy: 0.88833
Time: 2018-07-14 22:58:23
TRAINING STATS: batch 268/486 in epoch 162,  batch loss: 0.39735, batch accuracy: 0.88300
Time: 2018-07-14 22:58:27
TRAINING STATS: batch 318/486 in epoch 162,  batch loss: 0.46797, batch accuracy: 0.86317
Time: 2018-07-14 22:58:31
TRAINING STATS: batch 368/486 in epoch 162,  batch loss: 0.48155, batch accuracy: 0.85833
Time: 2018-07-14 22:58:35
TRAINING STATS: batch 418/486 in epoch 162,  batch loss: 0.43837, batch accuracy: 0.87200
Time: 2018-07-14 22:58:39
TRAINING STATS: batch 468/486 in epoch 162,  batch loss: 0.43097, batch accuracy: 0.87550
Time: 2018-07-14 22:58:43
TRAINING STATS: batch 32/486 in epoch 163,   batch loss: 0.39120, batch accuracy: 0.88800
Time: 2018-07-14 22:58:48
TRAINING STATS: batch 82/486 in epoch 163,   batch loss: 0.43434, batch accuracy: 0.87300
Time: 2018-07-14 22:58:51
TRAINING STATS: batch 132/486 in epoch 163,  batch loss: 0.37980, batch accuracy: 0.89300
Time: 2018-07-14 22:58:55
TRAINING STATS: batch 182/486 in epoch 163,  batch loss: 0.41456, batch accuracy: 0.87650
Time: 2018-07-14 22:59:00
TRAINING STATS: batch 232/486 in epoch 163,  batch loss: 0.40283, batch accuracy: 0.88050
Time: 2018-07-14 22:59:03
TRAINING STATS: batch 282/486 in epoch 163,  batch loss: 0.38356, batch accuracy: 0.88683
Time: 2018-07-14 22:59:07
TRAINING STATS: batch 332/486 in epoch 163,  batch loss: 0.40689, batch accuracy: 0.88050
Time: 2018-07-14 22:59:12
TRAINING STATS: batch 382/486 in epoch 163,  batch loss: 0.40367, batch accuracy: 0.87750
Time: 2018-07-14 22:59:16
TRAINING STATS: batch 432/486 in epoch 163,  batch loss: 0.36441, batch accuracy: 0.89150
Time: 2018-07-14 22:59:19
TRAINING STATS: batch 482/486 in epoch 163,  batch loss: 0.38142, batch accuracy: 0.88750
Time: 2018-07-14 22:59:24
TRAINING STATS: batch 46/486 in epoch 164,   batch loss: 0.39959, batch accuracy: 0.88350
Time: 2018-07-14 22:59:28
TRAINING STATS: batch 96/486 in epoch 164,   batch loss: 0.40982, batch accuracy: 0.88117
Time: 2018-07-14 22:59:32
TRAINING STATS: batch 146/486 in epoch 164,  batch loss: 0.43394, batch accuracy: 0.87700
Time: 2018-07-14 22:59:36
TRAINING STATS: batch 196/486 in epoch 164,  batch loss: 0.44618, batch accuracy: 0.87183
Time: 2018-07-14 22:59:40
TRAINING STATS: batch 246/486 in epoch 164,  batch loss: 0.41980, batch accuracy: 0.87850
Time: 2018-07-14 22:59:44
TRAINING STATS: batch 296/486 in epoch 164,  batch loss: 0.41523, batch accuracy: 0.87833
Time: 2018-07-14 22:59:48
TRAINING STATS: batch 346/486 in epoch 164,  batch loss: 0.38300, batch accuracy: 0.89233
Time: 2018-07-14 22:59:52
TRAINING STATS: batch 396/486 in epoch 164,  batch loss: 0.38316, batch accuracy: 0.88933
Time: 2018-07-14 22:59:56
TRAINING STATS: batch 446/486 in epoch 164,  batch loss: 0.38699, batch accuracy: 0.88800
Time: 2018-07-14 23:00:01
TRAINING STATS: batch 10/486 in epoch 165,   batch loss: 0.41022, batch accuracy: 0.87817
Time: 2018-07-14 23:00:04
TRAINING STATS: batch 60/486 in epoch 165,   batch loss: 0.39749, batch accuracy: 0.88667
Time: 2018-07-14 23:00:08
TRAINING STATS: batch 110/486 in epoch 165,  batch loss: 0.41670, batch accuracy: 0.87617
Time: 2018-07-14 23:00:13
TRAINING STATS: batch 160/486 in epoch 165,  batch loss: 0.36456, batch accuracy: 0.89617
Time: 2018-07-14 23:00:17
TRAINING STATS: batch 210/486 in epoch 165,  batch loss: 0.36811, batch accuracy: 0.89050
Time: 2018-07-14 23:00:20
TRAINING STATS: batch 260/486 in epoch 165,  batch loss: 0.41821, batch accuracy: 0.87767
Time: 2018-07-14 23:00:25
TRAINING STATS: batch 310/486 in epoch 165,  batch loss: 0.39027, batch accuracy: 0.88617
Time: 2018-07-14 23:00:29
TRAINING STATS: batch 360/486 in epoch 165,  batch loss: 0.40662, batch accuracy: 0.88533
Time: 2018-07-14 23:00:33
TRAINING STATS: batch 410/486 in epoch 165,  batch loss: 0.39116, batch accuracy: 0.88433
Time: 2018-07-14 23:00:37
TRAINING STATS: batch 460/486 in epoch 165,  batch loss: 0.45410, batch accuracy: 0.86750
Time: 2018-07-14 23:00:41
TRAINING STATS: batch 24/486 in epoch 166,   batch loss: 0.42442, batch accuracy: 0.87600
Time: 2018-07-14 23:00:45
TRAINING STATS: batch 74/486 in epoch 166,   batch loss: 0.39881, batch accuracy: 0.88367
Time: 2018-07-14 23:00:49
TRAINING STATS: batch 124/486 in epoch 166,  batch loss: 0.39259, batch accuracy: 0.88617
Time: 2018-07-14 23:00:53
TRAINING STATS: batch 174/486 in epoch 166,  batch loss: 0.44544, batch accuracy: 0.87117
Time: 2018-07-14 23:00:57
TRAINING STATS: batch 224/486 in epoch 166,  batch loss: 0.42026, batch accuracy: 0.88000
Time: 2018-07-14 23:01:02
TRAINING STATS: batch 274/486 in epoch 166,  batch loss: 0.41522, batch accuracy: 0.87567
Time: 2018-07-14 23:01:05
TRAINING STATS: batch 324/486 in epoch 166,  batch loss: 0.37031, batch accuracy: 0.89433
Time: 2018-07-14 23:01:09
TRAINING STATS: batch 374/486 in epoch 166,  batch loss: 0.41939, batch accuracy: 0.87583
Time: 2018-07-14 23:01:14
TRAINING STATS: batch 424/486 in epoch 166,  batch loss: 0.37084, batch accuracy: 0.89333
Time: 2018-07-14 23:01:18
TRAINING STATS: batch 474/486 in epoch 166,  batch loss: 0.37424, batch accuracy: 0.89383
Time: 2018-07-14 23:01:21
TRAINING STATS: batch 38/486 in epoch 167,   batch loss: 0.43921, batch accuracy: 0.87267
Time: 2018-07-14 23:01:26
TRAINING STATS: batch 88/486 in epoch 167,   batch loss: 0.39851, batch accuracy: 0.88183
Time: 2018-07-14 23:01:30
TRAINING STATS: batch 138/486 in epoch 167,  batch loss: 0.40056, batch accuracy: 0.88500
Time: 2018-07-14 23:01:33
TRAINING STATS: batch 188/486 in epoch 167,  batch loss: 0.39860, batch accuracy: 0.88517
Time: 2018-07-14 23:01:38
TRAINING STATS: batch 238/486 in epoch 167,  batch loss: 0.38477, batch accuracy: 0.88767
Time: 2018-07-14 23:01:42
TRAINING STATS: batch 288/486 in epoch 167,  batch loss: 0.44795, batch accuracy: 0.86867
Time: 2018-07-14 23:01:46
TRAINING STATS: batch 338/486 in epoch 167,  batch loss: 0.39245, batch accuracy: 0.88233
Time: 2018-07-14 23:01:50
TRAINING STATS: batch 388/486 in epoch 167,  batch loss: 0.40457, batch accuracy: 0.88500
Time: 2018-07-14 23:01:54
TRAINING STATS: batch 438/486 in epoch 167,  batch loss: 0.44650, batch accuracy: 0.87333
Time: 2018-07-14 23:01:58
TRAINING STATS: batch 2/486 in epoch 168,    batch loss: 0.41994, batch accuracy: 0.87783
Time: 2018-07-14 23:02:03
TRAINING STATS: batch 52/486 in epoch 168,   batch loss: 0.42994, batch accuracy: 0.87767
Time: 2018-07-14 23:02:06
TRAINING STATS: batch 102/486 in epoch 168,  batch loss: 0.42079, batch accuracy: 0.87733
Time: 2018-07-14 23:02:10
TRAINING STATS: batch 152/486 in epoch 168,  batch loss: 0.38178, batch accuracy: 0.88617
Time: 2018-07-14 23:02:15
TRAINING STATS: batch 202/486 in epoch 168,  batch loss: 0.41242, batch accuracy: 0.87933
Time: 2018-07-14 23:02:18
TRAINING STATS: batch 252/486 in epoch 168,  batch loss: 0.40525, batch accuracy: 0.88033
Time: 2018-07-14 23:02:22
TRAINING STATS: batch 302/486 in epoch 168,  batch loss: 0.40768, batch accuracy: 0.88117
Time: 2018-07-14 23:02:27
TRAINING STATS: batch 352/486 in epoch 168,  batch loss: 0.37684, batch accuracy: 0.89150
Time: 2018-07-14 23:02:31
TRAINING STATS: batch 402/486 in epoch 168,  batch loss: 0.37055, batch accuracy: 0.89483
Time: 2018-07-14 23:02:34
TRAINING STATS: batch 452/486 in epoch 168,  batch loss: 0.41155, batch accuracy: 0.87683
Time: 2018-07-14 23:02:39
TRAINING STATS: batch 16/486 in epoch 169,   batch loss: 0.37449, batch accuracy: 0.88933
Time: 2018-07-14 23:02:43
TRAINING STATS: batch 66/486 in epoch 169,   batch loss: 0.43988, batch accuracy: 0.87483
Time: 2018-07-14 23:02:46
TRAINING STATS: batch 116/486 in epoch 169,  batch loss: 0.37209, batch accuracy: 0.88867
Time: 2018-07-14 23:02:51
TRAINING STATS: batch 166/486 in epoch 169,  batch loss: 0.35913, batch accuracy: 0.89567
Time: 2018-07-14 23:02:55
TRAINING STATS: batch 216/486 in epoch 169,  batch loss: 0.42440, batch accuracy: 0.88033
Time: 2018-07-14 23:02:59
TRAINING STATS: batch 266/486 in epoch 169,  batch loss: 0.40934, batch accuracy: 0.88400
Time: 2018-07-14 23:03:03
TRAINING STATS: batch 316/486 in epoch 169,  batch loss: 0.39746, batch accuracy: 0.88733
Time: 2018-07-14 23:03:07
TRAINING STATS: batch 366/486 in epoch 169,  batch loss: 0.44363, batch accuracy: 0.86967
Time: 2018-07-14 23:03:11
TRAINING STATS: batch 416/486 in epoch 169,  batch loss: 0.42029, batch accuracy: 0.87850
Time: 2018-07-14 23:03:16
TRAINING STATS: batch 466/486 in epoch 169,  batch loss: 0.36592, batch accuracy: 0.89383
Time: 2018-07-14 23:03:19
TRAINING STATS: batch 30/486 in epoch 170,   batch loss: 0.34071, batch accuracy: 0.90083
Time: 2018-07-14 23:03:23
TRAINING STATS: batch 80/486 in epoch 170,   batch loss: 0.40543, batch accuracy: 0.88300
Time: 2018-07-14 23:03:28
TRAINING STATS: batch 130/486 in epoch 170,  batch loss: 0.43659, batch accuracy: 0.87000
Time: 2018-07-14 23:03:32
TRAINING STATS: batch 180/486 in epoch 170,  batch loss: 0.35846, batch accuracy: 0.89833
Time: 2018-07-14 23:03:35
TRAINING STATS: batch 230/486 in epoch 170,  batch loss: 0.38533, batch accuracy: 0.88833
Time: 2018-07-14 23:03:40
TRAINING STATS: batch 280/486 in epoch 170,  batch loss: 0.38848, batch accuracy: 0.88817
Time: 2018-07-14 23:03:44
TRAINING STATS: batch 330/486 in epoch 170,  batch loss: 0.41563, batch accuracy: 0.88100
Time: 2018-07-14 23:03:47
TRAINING STATS: batch 380/486 in epoch 170,  batch loss: 0.38638, batch accuracy: 0.88450
Time: 2018-07-14 23:03:52
TRAINING STATS: batch 430/486 in epoch 170,  batch loss: 0.39685, batch accuracy: 0.88250
Time: 2018-07-14 23:03:56
TRAINING STATS: batch 480/486 in epoch 170,  batch loss: 0.34553, batch accuracy: 0.89833
Time: 2018-07-14 23:04:00
TRAINING STATS: batch 44/486 in epoch 171,   batch loss: 0.38298, batch accuracy: 0.88833
Time: 2018-07-14 23:04:04
TRAINING STATS: batch 94/486 in epoch 171,   batch loss: 0.40872, batch accuracy: 0.88150
Time: 2018-07-14 23:04:08
TRAINING STATS: batch 144/486 in epoch 171,  batch loss: 0.41881, batch accuracy: 0.87783
Time: 2018-07-14 23:04:12
TRAINING STATS: batch 194/486 in epoch 171,  batch loss: 0.45141, batch accuracy: 0.86867
Time: 2018-07-14 23:04:17
TRAINING STATS: batch 244/486 in epoch 171,  batch loss: 0.38691, batch accuracy: 0.88850
Time: 2018-07-14 23:04:20
TRAINING STATS: batch 294/486 in epoch 171,  batch loss: 0.35336, batch accuracy: 0.89717
Time: 2018-07-14 23:04:24
TRAINING STATS: batch 344/486 in epoch 171,  batch loss: 0.40857, batch accuracy: 0.88383
Time: 2018-07-14 23:04:29
TRAINING STATS: batch 394/486 in epoch 171,  batch loss: 0.39997, batch accuracy: 0.88650
Time: 2018-07-14 23:04:32
TRAINING STATS: batch 444/486 in epoch 171,  batch loss: 0.35387, batch accuracy: 0.89367
Time: 2018-07-14 23:04:36
TRAINING STATS: batch 8/486 in epoch 172,    batch loss: 0.43345, batch accuracy: 0.86817
Time: 2018-07-14 23:04:41
TRAINING STATS: batch 58/486 in epoch 172,   batch loss: 0.42595, batch accuracy: 0.87733
Time: 2018-07-14 23:04:45
TRAINING STATS: batch 108/486 in epoch 172,  batch loss: 0.44325, batch accuracy: 0.87350
Time: 2018-07-14 23:04:48
TRAINING STATS: batch 158/486 in epoch 172,  batch loss: 0.42081, batch accuracy: 0.88067
Time: 2018-07-14 23:04:53
TRAINING STATS: batch 208/486 in epoch 172,  batch loss: 0.43338, batch accuracy: 0.87700
Time: 2018-07-14 23:04:57
TRAINING STATS: batch 258/486 in epoch 172,  batch loss: 0.43065, batch accuracy: 0.87300
Time: 2018-07-14 23:05:00
TRAINING STATS: batch 308/486 in epoch 172,  batch loss: 0.41871, batch accuracy: 0.87717
Time: 2018-07-14 23:05:05
TRAINING STATS: batch 358/486 in epoch 172,  batch loss: 0.42737, batch accuracy: 0.87633
Time: 2018-07-14 23:05:09
TRAINING STATS: batch 408/486 in epoch 172,  batch loss: 0.42033, batch accuracy: 0.87467
Time: 2018-07-14 23:05:13
TRAINING STATS: batch 458/486 in epoch 172,  batch loss: 0.43576, batch accuracy: 0.87533
Time: 2018-07-14 23:05:17
TRAINING STATS: batch 22/486 in epoch 173,   batch loss: 0.42543, batch accuracy: 0.87683
Time: 2018-07-14 23:05:21
TRAINING STATS: batch 72/486 in epoch 173,   batch loss: 0.40893, batch accuracy: 0.88150
Time: 2018-07-14 23:05:25
TRAINING STATS: batch 122/486 in epoch 173,  batch loss: 0.38256, batch accuracy: 0.88817
Time: 2018-07-14 23:05:30
TRAINING STATS: batch 172/486 in epoch 173,  batch loss: 0.40423, batch accuracy: 0.88450
Time: 2018-07-14 23:05:33
TRAINING STATS: batch 222/486 in epoch 173,  batch loss: 0.42158, batch accuracy: 0.88133
Time: 2018-07-14 23:05:37
TRAINING STATS: batch 272/486 in epoch 173,  batch loss: 0.44997, batch accuracy: 0.86633
Time: 2018-07-14 23:05:42
TRAINING STATS: batch 322/486 in epoch 173,  batch loss: 0.39796, batch accuracy: 0.88600
Time: 2018-07-14 23:05:45
TRAINING STATS: batch 372/486 in epoch 173,  batch loss: 0.39719, batch accuracy: 0.88433
Time: 2018-07-14 23:05:49
TRAINING STATS: batch 422/486 in epoch 173,  batch loss: 0.37356, batch accuracy: 0.89283
Time: 2018-07-14 23:05:54
TRAINING STATS: batch 472/486 in epoch 173,  batch loss: 0.45399, batch accuracy: 0.87117
Time: 2018-07-14 23:05:58
TRAINING STATS: batch 36/486 in epoch 174,   batch loss: 0.45953, batch accuracy: 0.86433
Time: 2018-07-14 23:06:01
TRAINING STATS: batch 86/486 in epoch 174,   batch loss: 0.44224, batch accuracy: 0.87050
Time: 2018-07-14 23:06:06
TRAINING STATS: batch 136/486 in epoch 174,  batch loss: 0.48565, batch accuracy: 0.85450
Time: 2018-07-14 23:06:10
TRAINING STATS: batch 186/486 in epoch 174,  batch loss: 0.44287, batch accuracy: 0.87033
Time: 2018-07-14 23:06:14
TRAINING STATS: batch 236/486 in epoch 174,  batch loss: 0.44435, batch accuracy: 0.86950
Time: 2018-07-14 23:06:18
TRAINING STATS: batch 286/486 in epoch 174,  batch loss: 0.45221, batch accuracy: 0.87050
Time: 2018-07-14 23:06:22
TRAINING STATS: batch 336/486 in epoch 174,  batch loss: 0.42104, batch accuracy: 0.87883
Time: 2018-07-14 23:06:26
TRAINING STATS: batch 386/486 in epoch 174,  batch loss: 0.44911, batch accuracy: 0.86800
Time: 2018-07-14 23:06:30
TRAINING STATS: batch 436/486 in epoch 174,  batch loss: 0.40361, batch accuracy: 0.88117
Time: 2018-07-14 23:06:34
TRAINING STATS: batch 0/486 in epoch 175,    batch loss: 0.42716, batch accuracy: 0.87217
Time: 2018-07-14 23:06:38
TRAINING STATS: batch 50/486 in epoch 175,   batch loss: 0.39416, batch accuracy: 0.88750
Time: 2018-07-14 23:06:43
TRAINING STATS: batch 100/486 in epoch 175,  batch loss: 0.45932, batch accuracy: 0.86700
Time: 2018-07-14 23:06:46
TRAINING STATS: batch 150/486 in epoch 175,  batch loss: 0.47647, batch accuracy: 0.85883
Time: 2018-07-14 23:06:50
TRAINING STATS: batch 200/486 in epoch 175,  batch loss: 0.36914, batch accuracy: 0.89350
Time: 2018-07-14 23:06:55
TRAINING STATS: batch 250/486 in epoch 175,  batch loss: 0.42715, batch accuracy: 0.87667
Time: 2018-07-14 23:06:59
TRAINING STATS: batch 300/486 in epoch 175,  batch loss: 0.46327, batch accuracy: 0.86800
Time: 2018-07-14 23:07:02
TRAINING STATS: batch 350/486 in epoch 175,  batch loss: 0.41646, batch accuracy: 0.88200
Time: 2018-07-14 23:07:07
TRAINING STATS: batch 400/486 in epoch 175,  batch loss: 0.39519, batch accuracy: 0.88850
Time: 2018-07-14 23:07:11
TRAINING STATS: batch 450/486 in epoch 175,  batch loss: 0.40520, batch accuracy: 0.87967
Time: 2018-07-14 23:07:14
TRAINING STATS: batch 14/486 in epoch 176,   batch loss: 0.37594, batch accuracy: 0.89367
Time: 2018-07-14 23:07:19
TRAINING STATS: batch 64/486 in epoch 176,   batch loss: 0.47391, batch accuracy: 0.86217
Time: 2018-07-14 23:07:23
TRAINING STATS: batch 114/486 in epoch 176,  batch loss: 0.43120, batch accuracy: 0.87533
Time: 2018-07-14 23:07:27
TRAINING STATS: batch 164/486 in epoch 176,  batch loss: 0.37223, batch accuracy: 0.89167
Time: 2018-07-14 23:07:31
TRAINING STATS: batch 214/486 in epoch 176,  batch loss: 0.40437, batch accuracy: 0.88233
Time: 2018-07-14 23:07:35
TRAINING STATS: batch 264/486 in epoch 176,  batch loss: 0.39994, batch accuracy: 0.88517
Time: 2018-07-14 23:07:39
TRAINING STATS: batch 314/486 in epoch 176,  batch loss: 0.44067, batch accuracy: 0.87400
Time: 2018-07-14 23:07:44
TRAINING STATS: batch 364/486 in epoch 176,  batch loss: 0.41246, batch accuracy: 0.88233
Time: 2018-07-14 23:07:47
TRAINING STATS: batch 414/486 in epoch 176,  batch loss: 0.38485, batch accuracy: 0.89000
Time: 2018-07-14 23:07:51
TRAINING STATS: batch 464/486 in epoch 176,  batch loss: 0.40334, batch accuracy: 0.88467
Time: 2018-07-14 23:07:56
TRAINING STATS: batch 28/486 in epoch 177,   batch loss: 0.38213, batch accuracy: 0.88500
Time: 2018-07-14 23:08:00
TRAINING STATS: batch 78/486 in epoch 177,   batch loss: 0.41025, batch accuracy: 0.88067
Time: 2018-07-14 23:08:03
TRAINING STATS: batch 128/486 in epoch 177,  batch loss: 0.40851, batch accuracy: 0.87750
Time: 2018-07-14 23:08:08
TRAINING STATS: batch 178/486 in epoch 177,  batch loss: 0.34423, batch accuracy: 0.90033
Time: 2018-07-14 23:08:12
TRAINING STATS: batch 228/486 in epoch 177,  batch loss: 0.34699, batch accuracy: 0.89617
Time: 2018-07-14 23:08:15
TRAINING STATS: batch 278/486 in epoch 177,  batch loss: 0.37093, batch accuracy: 0.88983
Time: 2018-07-14 23:08:20
TRAINING STATS: batch 328/486 in epoch 177,  batch loss: 0.39373, batch accuracy: 0.88267
Time: 2018-07-14 23:08:24
TRAINING STATS: batch 378/486 in epoch 177,  batch loss: 0.36564, batch accuracy: 0.89317
Time: 2018-07-14 23:08:28
TRAINING STATS: batch 428/486 in epoch 177,  batch loss: 0.41978, batch accuracy: 0.87933
Time: 2018-07-14 23:08:32
TRAINING STATS: batch 478/486 in epoch 177,  batch loss: 0.38586, batch accuracy: 0.88683
Time: 2018-07-14 23:08:36
TRAINING STATS: batch 42/486 in epoch 178,   batch loss: 0.39946, batch accuracy: 0.88283
Time: 2018-07-14 23:08:40
TRAINING STATS: batch 92/486 in epoch 178,   batch loss: 0.41058, batch accuracy: 0.87800
Time: 2018-07-14 23:08:45
TRAINING STATS: batch 142/486 in epoch 178,  batch loss: 0.35377, batch accuracy: 0.89533
Time: 2018-07-14 23:08:48
TRAINING STATS: batch 192/486 in epoch 178,  batch loss: 0.38956, batch accuracy: 0.89017
Time: 2018-07-14 23:08:52
TRAINING STATS: batch 242/486 in epoch 178,  batch loss: 0.39446, batch accuracy: 0.88850
Time: 2018-07-14 23:08:57
TRAINING STATS: batch 292/486 in epoch 178,  batch loss: 0.46499, batch accuracy: 0.86767
Time: 2018-07-14 23:09:00
TRAINING STATS: batch 342/486 in epoch 178,  batch loss: 0.44274, batch accuracy: 0.87450
Time: 2018-07-14 23:09:04
TRAINING STATS: batch 392/486 in epoch 178,  batch loss: 0.41630, batch accuracy: 0.87817
Time: 2018-07-14 23:09:09
TRAINING STATS: batch 442/486 in epoch 178,  batch loss: 0.37437, batch accuracy: 0.89400
Time: 2018-07-14 23:09:13
TRAINING STATS: batch 6/486 in epoch 179,    batch loss: 0.46006, batch accuracy: 0.86950
Time: 2018-07-14 23:09:16
TRAINING STATS: batch 56/486 in epoch 179,   batch loss: 0.42243, batch accuracy: 0.87800
Time: 2018-07-14 23:09:21
TRAINING STATS: batch 106/486 in epoch 179,  batch loss: 0.42842, batch accuracy: 0.87767
Time: 2018-07-14 23:09:25
TRAINING STATS: batch 156/486 in epoch 179,  batch loss: 0.39861, batch accuracy: 0.88567
Time: 2018-07-14 23:09:29
TRAINING STATS: batch 206/486 in epoch 179,  batch loss: 0.43947, batch accuracy: 0.87383
Time: 2018-07-14 23:09:33
TRAINING STATS: batch 256/486 in epoch 179,  batch loss: 0.39778, batch accuracy: 0.88250
Time: 2018-07-14 23:09:37
TRAINING STATS: batch 306/486 in epoch 179,  batch loss: 0.41087, batch accuracy: 0.88067
Time: 2018-07-14 23:09:41
TRAINING STATS: batch 356/486 in epoch 179,  batch loss: 0.42488, batch accuracy: 0.87717
Time: 2018-07-14 23:09:45
TRAINING STATS: batch 406/486 in epoch 179,  batch loss: 0.44994, batch accuracy: 0.86700
Time: 2018-07-14 23:09:49
TRAINING STATS: batch 456/486 in epoch 179,  batch loss: 0.38247, batch accuracy: 0.89267
Time: 2018-07-14 23:09:53
TRAINING STATS: batch 20/486 in epoch 180,   batch loss: 0.42756, batch accuracy: 0.87217
Time: 2018-07-14 23:09:58
TRAINING STATS: batch 70/486 in epoch 180,   batch loss: 0.35711, batch accuracy: 0.89900
Time: 2018-07-14 23:10:01
TRAINING STATS: batch 120/486 in epoch 180,  batch loss: 0.42870, batch accuracy: 0.87317
Time: 2018-07-14 23:10:05
TRAINING STATS: batch 170/486 in epoch 180,  batch loss: 0.35966, batch accuracy: 0.89617
Time: 2018-07-14 23:10:10
TRAINING STATS: batch 220/486 in epoch 180,  batch loss: 0.38793, batch accuracy: 0.88767
Time: 2018-07-14 23:10:14
TRAINING STATS: batch 270/486 in epoch 180,  batch loss: 0.37677, batch accuracy: 0.89433
Time: 2018-07-14 23:10:17
TRAINING STATS: batch 320/486 in epoch 180,  batch loss: 0.38845, batch accuracy: 0.88700
Time: 2018-07-14 23:10:22
TRAINING STATS: batch 370/486 in epoch 180,  batch loss: 0.38444, batch accuracy: 0.88717
Time: 2018-07-14 23:10:26
TRAINING STATS: batch 420/486 in epoch 180,  batch loss: 0.40396, batch accuracy: 0.88450
Time: 2018-07-14 23:10:29
TRAINING STATS: batch 470/486 in epoch 180,  batch loss: 0.44325, batch accuracy: 0.86767
Time: 2018-07-14 23:10:34
TRAINING STATS: batch 34/486 in epoch 181,   batch loss: 0.41068, batch accuracy: 0.87883
Time: 2018-07-14 23:10:38
TRAINING STATS: batch 84/486 in epoch 181,   batch loss: 0.37720, batch accuracy: 0.89017
Time: 2018-07-14 23:10:42
TRAINING STATS: batch 134/486 in epoch 181,  batch loss: 0.40053, batch accuracy: 0.88567
Time: 2018-07-14 23:10:46
TRAINING STATS: batch 184/486 in epoch 181,  batch loss: 0.39690, batch accuracy: 0.88533
Time: 2018-07-14 23:10:50
TRAINING STATS: batch 234/486 in epoch 181,  batch loss: 0.44055, batch accuracy: 0.86850
Time: 2018-07-14 23:10:54
TRAINING STATS: batch 284/486 in epoch 181,  batch loss: 0.41875, batch accuracy: 0.87983
Time: 2018-07-14 23:10:59
TRAINING STATS: batch 334/486 in epoch 181,  batch loss: 0.38147, batch accuracy: 0.88833
Time: 2018-07-14 23:11:02
TRAINING STATS: batch 384/486 in epoch 181,  batch loss: 0.39972, batch accuracy: 0.88200
Time: 2018-07-14 23:11:06
TRAINING STATS: batch 434/486 in epoch 181,  batch loss: 0.43098, batch accuracy: 0.87500
Time: 2018-07-14 23:11:11
TRAINING STATS: batch 484/486 in epoch 181,  batch loss: 0.38485, batch accuracy: 0.88800
Time: 2018-07-14 23:11:14
TRAINING STATS: batch 48/486 in epoch 182,   batch loss: 0.42393, batch accuracy: 0.87817
Time: 2018-07-14 23:11:18
TRAINING STATS: batch 98/486 in epoch 182,   batch loss: 0.38557, batch accuracy: 0.88700
Time: 2018-07-14 23:11:23
TRAINING STATS: batch 148/486 in epoch 182,  batch loss: 0.42473, batch accuracy: 0.87600
Time: 2018-07-14 23:11:27
TRAINING STATS: batch 198/486 in epoch 182,  batch loss: 0.40018, batch accuracy: 0.88217
Time: 2018-07-14 23:11:30
TRAINING STATS: batch 248/486 in epoch 182,  batch loss: 0.43319, batch accuracy: 0.87317
Time: 2018-07-14 23:11:35
TRAINING STATS: batch 298/486 in epoch 182,  batch loss: 0.41596, batch accuracy: 0.87917
Time: 2018-07-14 23:11:39
TRAINING STATS: batch 348/486 in epoch 182,  batch loss: 0.40699, batch accuracy: 0.88117
Time: 2018-07-14 23:11:42
TRAINING STATS: batch 398/486 in epoch 182,  batch loss: 0.41820, batch accuracy: 0.87667
Time: 2018-07-14 23:11:47
TRAINING STATS: batch 448/486 in epoch 182,  batch loss: 0.43046, batch accuracy: 0.87583
Time: 2018-07-14 23:11:51
TRAINING STATS: batch 12/486 in epoch 183,   batch loss: 0.38333, batch accuracy: 0.89017
Time: 2018-07-14 23:11:55
TRAINING STATS: batch 62/486 in epoch 183,   batch loss: 0.40695, batch accuracy: 0.87717
Time: 2018-07-14 23:11:59
TRAINING STATS: batch 112/486 in epoch 183,  batch loss: 0.39288, batch accuracy: 0.88750
Time: 2018-07-14 23:12:03
TRAINING STATS: batch 162/486 in epoch 183,  batch loss: 0.41516, batch accuracy: 0.87950
Time: 2018-07-14 23:12:07
TRAINING STATS: batch 212/486 in epoch 183,  batch loss: 0.38128, batch accuracy: 0.88750
Time: 2018-07-14 23:12:12
TRAINING STATS: batch 262/486 in epoch 183,  batch loss: 0.42331, batch accuracy: 0.87833
Time: 2018-07-14 23:12:15
TRAINING STATS: batch 312/486 in epoch 183,  batch loss: 0.39348, batch accuracy: 0.88900
Time: 2018-07-14 23:12:19
TRAINING STATS: batch 362/486 in epoch 183,  batch loss: 0.41976, batch accuracy: 0.87950
Time: 2018-07-14 23:12:24
TRAINING STATS: batch 412/486 in epoch 183,  batch loss: 0.36019, batch accuracy: 0.89550
Time: 2018-07-14 23:12:28
TRAINING STATS: batch 462/486 in epoch 183,  batch loss: 0.39795, batch accuracy: 0.88450
Time: 2018-07-14 23:12:31
TRAINING STATS: batch 26/486 in epoch 184,   batch loss: 0.44234, batch accuracy: 0.87250
Time: 2018-07-14 23:12:36
TRAINING STATS: batch 76/486 in epoch 184,   batch loss: 0.44944, batch accuracy: 0.87217
Time: 2018-07-14 23:12:40
TRAINING STATS: batch 126/486 in epoch 184,  batch loss: 0.42023, batch accuracy: 0.87750
Time: 2018-07-14 23:12:43
TRAINING STATS: batch 176/486 in epoch 184,  batch loss: 0.40132, batch accuracy: 0.88367
Time: 2018-07-14 23:12:48
TRAINING STATS: batch 226/486 in epoch 184,  batch loss: 0.42474, batch accuracy: 0.87683
Time: 2018-07-14 23:12:52
TRAINING STATS: batch 276/486 in epoch 184,  batch loss: 0.46192, batch accuracy: 0.86683
Time: 2018-07-14 23:12:56
TRAINING STATS: batch 326/486 in epoch 184,  batch loss: 0.39129, batch accuracy: 0.88500
Time: 2018-07-14 23:13:00
TRAINING STATS: batch 376/486 in epoch 184,  batch loss: 0.42134, batch accuracy: 0.87917
Time: 2018-07-14 23:13:04
TRAINING STATS: batch 426/486 in epoch 184,  batch loss: 0.40558, batch accuracy: 0.88050
Time: 2018-07-14 23:13:08
TRAINING STATS: batch 476/486 in epoch 184,  batch loss: 0.37773, batch accuracy: 0.88583
Time: 2018-07-14 23:13:13
TRAINING STATS: batch 40/486 in epoch 185,   batch loss: 0.37669, batch accuracy: 0.89450
Time: 2018-07-14 23:13:16
TRAINING STATS: batch 90/486 in epoch 185,   batch loss: 0.39874, batch accuracy: 0.88550
Time: 2018-07-14 23:13:20
TRAINING STATS: batch 140/486 in epoch 185,  batch loss: 0.39438, batch accuracy: 0.88883
Time: 2018-07-14 23:13:25
TRAINING STATS: batch 190/486 in epoch 185,  batch loss: 0.43511, batch accuracy: 0.87200
Time: 2018-07-14 23:13:29
TRAINING STATS: batch 240/486 in epoch 185,  batch loss: 0.41375, batch accuracy: 0.87950
Time: 2018-07-14 23:13:32
TRAINING STATS: batch 290/486 in epoch 185,  batch loss: 0.46476, batch accuracy: 0.86567
Time: 2018-07-14 23:13:37
TRAINING STATS: batch 340/486 in epoch 185,  batch loss: 0.44723, batch accuracy: 0.86583
Time: 2018-07-14 23:13:41
TRAINING STATS: batch 390/486 in epoch 185,  batch loss: 0.41654, batch accuracy: 0.87667
Time: 2018-07-14 23:13:44
TRAINING STATS: batch 440/486 in epoch 185,  batch loss: 0.45408, batch accuracy: 0.86583
Time: 2018-07-14 23:13:49
TRAINING STATS: batch 4/486 in epoch 186,    batch loss: 0.41858, batch accuracy: 0.88033
Time: 2018-07-14 23:13:53
TRAINING STATS: batch 54/486 in epoch 186,   batch loss: 0.45051, batch accuracy: 0.86817
Time: 2018-07-14 23:13:57
TRAINING STATS: batch 104/486 in epoch 186,  batch loss: 0.41208, batch accuracy: 0.88100
Time: 2018-07-14 23:14:01
TRAINING STATS: batch 154/486 in epoch 186,  batch loss: 0.35164, batch accuracy: 0.89767
Time: 2018-07-14 23:14:05
TRAINING STATS: batch 204/486 in epoch 186,  batch loss: 0.46854, batch accuracy: 0.86117
Time: 2018-07-14 23:14:09
TRAINING STATS: batch 254/486 in epoch 186,  batch loss: 0.40651, batch accuracy: 0.88017
Time: 2018-07-14 23:14:14
TRAINING STATS: batch 304/486 in epoch 186,  batch loss: 0.42671, batch accuracy: 0.87333
Time: 2018-07-14 23:14:17
TRAINING STATS: batch 354/486 in epoch 186,  batch loss: 0.40790, batch accuracy: 0.88083
Time: 2018-07-14 23:14:21
TRAINING STATS: batch 404/486 in epoch 186,  batch loss: 0.42573, batch accuracy: 0.87767
Time: 2018-07-14 23:14:26
TRAINING STATS: batch 454/486 in epoch 186,  batch loss: 0.36255, batch accuracy: 0.89450
Time: 2018-07-14 23:14:29
TRAINING STATS: batch 18/486 in epoch 187,   batch loss: 0.42210, batch accuracy: 0.87867
Time: 2018-07-14 23:14:33
TRAINING STATS: batch 68/486 in epoch 187,   batch loss: 0.36968, batch accuracy: 0.89217
Time: 2018-07-14 23:14:38
TRAINING STATS: batch 118/486 in epoch 187,  batch loss: 0.37772, batch accuracy: 0.89100
Time: 2018-07-14 23:14:42
TRAINING STATS: batch 168/486 in epoch 187,  batch loss: 0.35481, batch accuracy: 0.89917
Time: 2018-07-14 23:14:45
TRAINING STATS: batch 218/486 in epoch 187,  batch loss: 0.39109, batch accuracy: 0.88550
Time: 2018-07-14 23:14:50
TRAINING STATS: batch 268/486 in epoch 187,  batch loss: 0.39179, batch accuracy: 0.88517
Time: 2018-07-14 23:14:54
TRAINING STATS: batch 318/486 in epoch 187,  batch loss: 0.43601, batch accuracy: 0.87283
Time: 2018-07-14 23:14:58
TRAINING STATS: batch 368/486 in epoch 187,  batch loss: 0.42562, batch accuracy: 0.87850
Time: 2018-07-14 23:15:02
TRAINING STATS: batch 418/486 in epoch 187,  batch loss: 0.38905, batch accuracy: 0.88433
Time: 2018-07-14 23:15:06
TRAINING STATS: batch 468/486 in epoch 187,  batch loss: 0.42508, batch accuracy: 0.87633
Time: 2018-07-14 23:15:10
TRAINING STATS: batch 32/486 in epoch 188,   batch loss: 0.42837, batch accuracy: 0.87617
Time: 2018-07-14 23:15:14
TRAINING STATS: batch 82/486 in epoch 188,   batch loss: 0.40491, batch accuracy: 0.87933
Time: 2018-07-14 23:15:18
TRAINING STATS: batch 132/486 in epoch 188,  batch loss: 0.39523, batch accuracy: 0.88417
Time: 2018-07-14 23:15:22
TRAINING STATS: batch 182/486 in epoch 188,  batch loss: 0.42615, batch accuracy: 0.87367
Time: 2018-07-14 23:15:27
TRAINING STATS: batch 232/486 in epoch 188,  batch loss: 0.43297, batch accuracy: 0.87700
Time: 2018-07-14 23:15:30
TRAINING STATS: batch 282/486 in epoch 188,  batch loss: 0.37187, batch accuracy: 0.88867
Time: 2018-07-14 23:15:34
TRAINING STATS: batch 332/486 in epoch 188,  batch loss: 0.43276, batch accuracy: 0.87500
Time: 2018-07-14 23:15:39
TRAINING STATS: batch 382/486 in epoch 188,  batch loss: 0.39719, batch accuracy: 0.88467
Time: 2018-07-14 23:15:43
TRAINING STATS: batch 432/486 in epoch 188,  batch loss: 0.38201, batch accuracy: 0.89083
Time: 2018-07-14 23:15:46
TRAINING STATS: batch 482/486 in epoch 188,  batch loss: 0.35630, batch accuracy: 0.89533
Time: 2018-07-14 23:15:51
TRAINING STATS: batch 46/486 in epoch 189,   batch loss: 0.38860, batch accuracy: 0.88283
Time: 2018-07-14 23:15:55
TRAINING STATS: batch 96/486 in epoch 189,   batch loss: 0.38551, batch accuracy: 0.88733
Time: 2018-07-14 23:15:58
TRAINING STATS: batch 146/486 in epoch 189,  batch loss: 0.39195, batch accuracy: 0.89200
Time: 2018-07-14 23:16:03
TRAINING STATS: batch 196/486 in epoch 189,  batch loss: 0.42673, batch accuracy: 0.87633
Time: 2018-07-14 23:16:07
TRAINING STATS: batch 246/486 in epoch 189,  batch loss: 0.37354, batch accuracy: 0.89417
Time: 2018-07-14 23:16:11
TRAINING STATS: batch 296/486 in epoch 189,  batch loss: 0.39614, batch accuracy: 0.88500
Time: 2018-07-14 23:16:15
TRAINING STATS: batch 346/486 in epoch 189,  batch loss: 0.36335, batch accuracy: 0.89367
Time: 2018-07-14 23:16:19
TRAINING STATS: batch 396/486 in epoch 189,  batch loss: 0.40249, batch accuracy: 0.87950
Time: 2018-07-14 23:16:23
TRAINING STATS: batch 446/486 in epoch 189,  batch loss: 0.38772, batch accuracy: 0.88950
Time: 2018-07-14 23:16:28
TRAINING STATS: batch 10/486 in epoch 190,   batch loss: 0.38592, batch accuracy: 0.88667
Time: 2018-07-14 23:16:31
TRAINING STATS: batch 60/486 in epoch 190,   batch loss: 0.38161, batch accuracy: 0.88883
Time: 2018-07-14 23:16:35
TRAINING STATS: batch 110/486 in epoch 190,  batch loss: 0.41753, batch accuracy: 0.87567
Time: 2018-07-14 23:16:40
TRAINING STATS: batch 160/486 in epoch 190,  batch loss: 0.35245, batch accuracy: 0.89433
Time: 2018-07-14 23:16:43
TRAINING STATS: batch 210/486 in epoch 190,  batch loss: 0.34380, batch accuracy: 0.89900
Time: 2018-07-14 23:16:47
TRAINING STATS: batch 260/486 in epoch 190,  batch loss: 0.39767, batch accuracy: 0.88450
Time: 2018-07-14 23:16:52
TRAINING STATS: batch 310/486 in epoch 190,  batch loss: 0.36708, batch accuracy: 0.89400
Time: 2018-07-14 23:16:56
TRAINING STATS: batch 360/486 in epoch 190,  batch loss: 0.39194, batch accuracy: 0.89033
Time: 2018-07-14 23:16:59
TRAINING STATS: batch 410/486 in epoch 190,  batch loss: 0.36480, batch accuracy: 0.89617
Time: 2018-07-14 23:17:04
TRAINING STATS: batch 460/486 in epoch 190,  batch loss: 0.44253, batch accuracy: 0.86933
Time: 2018-07-14 23:17:08
TRAINING STATS: batch 24/486 in epoch 191,   batch loss: 0.38465, batch accuracy: 0.88633
Time: 2018-07-14 23:17:12
TRAINING STATS: batch 74/486 in epoch 191,   batch loss: 0.43777, batch accuracy: 0.87150
Time: 2018-07-14 23:17:16
TRAINING STATS: batch 124/486 in epoch 191,  batch loss: 0.41915, batch accuracy: 0.87683
Time: 2018-07-14 23:17:20
TRAINING STATS: batch 174/486 in epoch 191,  batch loss: 0.42054, batch accuracy: 0.87767
Time: 2018-07-14 23:17:24
TRAINING STATS: batch 224/486 in epoch 191,  batch loss: 0.43054, batch accuracy: 0.87683
Time: 2018-07-14 23:17:29
TRAINING STATS: batch 274/486 in epoch 191,  batch loss: 0.42437, batch accuracy: 0.87700
Time: 2018-07-14 23:17:32
TRAINING STATS: batch 324/486 in epoch 191,  batch loss: 0.37118, batch accuracy: 0.89567
Time: 2018-07-14 23:17:36
TRAINING STATS: batch 374/486 in epoch 191,  batch loss: 0.44386, batch accuracy: 0.87450
Time: 2018-07-14 23:17:41
TRAINING STATS: batch 424/486 in epoch 191,  batch loss: 0.39530, batch accuracy: 0.88617
Time: 2018-07-14 23:17:44
TRAINING STATS: batch 474/486 in epoch 191,  batch loss: 0.39687, batch accuracy: 0.88667
Time: 2018-07-14 23:17:48
TRAINING STATS: batch 38/486 in epoch 192,   batch loss: 0.44114, batch accuracy: 0.87133
Time: 2018-07-14 23:17:53
TRAINING STATS: batch 88/486 in epoch 192,   batch loss: 0.38770, batch accuracy: 0.88583
Time: 2018-07-14 23:17:57
TRAINING STATS: batch 138/486 in epoch 192,  batch loss: 0.42089, batch accuracy: 0.88133
Time: 2018-07-14 23:18:00
TRAINING STATS: batch 188/486 in epoch 192,  batch loss: 0.40662, batch accuracy: 0.88133
Time: 2018-07-14 23:18:05
TRAINING STATS: batch 238/486 in epoch 192,  batch loss: 0.40840, batch accuracy: 0.88367
Time: 2018-07-14 23:18:09
TRAINING STATS: batch 288/486 in epoch 192,  batch loss: 0.42952, batch accuracy: 0.87450
Time: 2018-07-14 23:18:13
TRAINING STATS: batch 338/486 in epoch 192,  batch loss: 0.47766, batch accuracy: 0.85717
Time: 2018-07-14 23:18:17
TRAINING STATS: batch 388/486 in epoch 192,  batch loss: 0.45119, batch accuracy: 0.86850
Time: 2018-07-14 23:18:21
TRAINING STATS: batch 438/486 in epoch 192,  batch loss: 0.45851, batch accuracy: 0.87000
Time: 2018-07-14 23:18:25
TRAINING STATS: batch 2/486 in epoch 193,    batch loss: 0.44375, batch accuracy: 0.87217
Time: 2018-07-14 23:18:29
TRAINING STATS: batch 52/486 in epoch 193,   batch loss: 0.44338, batch accuracy: 0.87383
Time: 2018-07-14 23:18:33
TRAINING STATS: batch 102/486 in epoch 193,  batch loss: 0.42585, batch accuracy: 0.87750
Time: 2018-07-14 23:18:37
TRAINING STATS: batch 152/486 in epoch 193,  batch loss: 0.40704, batch accuracy: 0.87683
Time: 2018-07-14 23:18:42
TRAINING STATS: batch 202/486 in epoch 193,  batch loss: 0.45304, batch accuracy: 0.86817
Time: 2018-07-14 23:18:45
TRAINING STATS: batch 252/486 in epoch 193,  batch loss: 0.44525, batch accuracy: 0.87167
Time: 2018-07-14 23:18:49
TRAINING STATS: batch 302/486 in epoch 193,  batch loss: 0.43899, batch accuracy: 0.86900
Time: 2018-07-14 23:18:54
TRAINING STATS: batch 352/486 in epoch 193,  batch loss: 0.42582, batch accuracy: 0.87967
Time: 2018-07-14 23:18:58
TRAINING STATS: batch 402/486 in epoch 193,  batch loss: 0.38958, batch accuracy: 0.88533
Time: 2018-07-14 23:19:01
TRAINING STATS: batch 452/486 in epoch 193,  batch loss: 0.45284, batch accuracy: 0.86483
Time: 2018-07-14 23:19:06
TRAINING STATS: batch 16/486 in epoch 194,   batch loss: 0.39132, batch accuracy: 0.88550
Time: 2018-07-14 23:19:10
TRAINING STATS: batch 66/486 in epoch 194,   batch loss: 0.42800, batch accuracy: 0.87600
Time: 2018-07-14 23:19:13
TRAINING STATS: batch 116/486 in epoch 194,  batch loss: 0.41241, batch accuracy: 0.88300
Time: 2018-07-14 23:19:18
TRAINING STATS: batch 166/486 in epoch 194,  batch loss: 0.35045, batch accuracy: 0.89950
Time: 2018-07-14 23:19:22
TRAINING STATS: batch 216/486 in epoch 194,  batch loss: 0.44125, batch accuracy: 0.87317
Time: 2018-07-14 23:19:26
TRAINING STATS: batch 266/486 in epoch 194,  batch loss: 0.42587, batch accuracy: 0.87700
Time: 2018-07-14 23:19:30
TRAINING STATS: batch 316/486 in epoch 194,  batch loss: 0.41177, batch accuracy: 0.87917
Time: 2018-07-14 23:19:34
TRAINING STATS: batch 366/486 in epoch 194,  batch loss: 0.43573, batch accuracy: 0.87167
Time: 2018-07-14 23:19:38
TRAINING STATS: batch 416/486 in epoch 194,  batch loss: 0.45134, batch accuracy: 0.86567
Time: 2018-07-14 23:19:43
TRAINING STATS: batch 466/486 in epoch 194,  batch loss: 0.36792, batch accuracy: 0.89083
Time: 2018-07-14 23:19:46
TRAINING STATS: batch 30/486 in epoch 195,   batch loss: 0.38747, batch accuracy: 0.89217
Time: 2018-07-14 23:19:50
TRAINING STATS: batch 80/486 in epoch 195,   batch loss: 0.43898, batch accuracy: 0.87483
Time: 2018-07-14 23:19:55
TRAINING STATS: batch 130/486 in epoch 195,  batch loss: 0.44837, batch accuracy: 0.86717
Time: 2018-07-14 23:19:58
TRAINING STATS: batch 180/486 in epoch 195,  batch loss: 0.39859, batch accuracy: 0.88200
Time: 2018-07-14 23:20:02
TRAINING STATS: batch 230/486 in epoch 195,  batch loss: 0.42919, batch accuracy: 0.87850
Time: 2018-07-14 23:20:07
TRAINING STATS: batch 280/486 in epoch 195,  batch loss: 0.40841, batch accuracy: 0.88283
Time: 2018-07-14 23:20:11
TRAINING STATS: batch 330/486 in epoch 195,  batch loss: 0.44962, batch accuracy: 0.86883
Time: 2018-07-14 23:20:14
TRAINING STATS: batch 380/486 in epoch 195,  batch loss: 0.38834, batch accuracy: 0.89017
Time: 2018-07-14 23:20:19
TRAINING STATS: batch 430/486 in epoch 195,  batch loss: 0.42106, batch accuracy: 0.87783
Time: 2018-07-14 23:20:23
TRAINING STATS: batch 480/486 in epoch 195,  batch loss: 0.41369, batch accuracy: 0.87817
Time: 2018-07-14 23:20:27
TRAINING STATS: batch 44/486 in epoch 196,   batch loss: 0.42314, batch accuracy: 0.87917
Time: 2018-07-14 23:20:31
TRAINING STATS: batch 94/486 in epoch 196,   batch loss: 0.43227, batch accuracy: 0.87017
Time: 2018-07-14 23:20:35
TRAINING STATS: batch 144/486 in epoch 196,  batch loss: 0.44643, batch accuracy: 0.86850
Time: 2018-07-14 23:20:39
TRAINING STATS: batch 194/486 in epoch 196,  batch loss: 0.48576, batch accuracy: 0.86033
Time: 2018-07-14 23:20:43
TRAINING STATS: batch 244/486 in epoch 196,  batch loss: 0.42200, batch accuracy: 0.87783
Time: 2018-07-14 23:20:47
TRAINING STATS: batch 294/486 in epoch 196,  batch loss: 0.41747, batch accuracy: 0.87733
Time: 2018-07-14 23:20:51
TRAINING STATS: batch 344/486 in epoch 196,  batch loss: 0.44172, batch accuracy: 0.87183
Time: 2018-07-14 23:20:56
TRAINING STATS: batch 394/486 in epoch 196,  batch loss: 0.42566, batch accuracy: 0.87800
Time: 2018-07-14 23:20:59
TRAINING STATS: batch 444/486 in epoch 196,  batch loss: 0.37310, batch accuracy: 0.89283
Time: 2018-07-14 23:21:03
TRAINING STATS: batch 8/486 in epoch 197,    batch loss: 0.42646, batch accuracy: 0.87483
Time: 2018-07-14 23:21:08
TRAINING STATS: batch 58/486 in epoch 197,   batch loss: 0.49531, batch accuracy: 0.85600
Time: 2018-07-14 23:21:12
TRAINING STATS: batch 108/486 in epoch 197,  batch loss: 0.49917, batch accuracy: 0.85300
Time: 2018-07-14 23:21:15
TRAINING STATS: batch 158/486 in epoch 197,  batch loss: 0.48249, batch accuracy: 0.85667
Time: 2018-07-14 23:21:20
TRAINING STATS: batch 208/486 in epoch 197,  batch loss: 0.46350, batch accuracy: 0.86617
Time: 2018-07-14 23:21:24
TRAINING STATS: batch 258/486 in epoch 197,  batch loss: 0.47012, batch accuracy: 0.86150
Time: 2018-07-14 23:21:27
TRAINING STATS: batch 308/486 in epoch 197,  batch loss: 0.45001, batch accuracy: 0.86867
Time: 2018-07-14 23:21:32
TRAINING STATS: batch 358/486 in epoch 197,  batch loss: 0.50465, batch accuracy: 0.85267
Time: 2018-07-14 23:21:36
TRAINING STATS: batch 408/486 in epoch 197,  batch loss: 0.50168, batch accuracy: 0.85100
Time: 2018-07-14 23:21:40
TRAINING STATS: batch 458/486 in epoch 197,  batch loss: 0.47745, batch accuracy: 0.86233
Time: 2018-07-14 23:21:44
TRAINING STATS: batch 22/486 in epoch 198,   batch loss: 0.48352, batch accuracy: 0.86067
Time: 2018-07-14 23:21:48
TRAINING STATS: batch 72/486 in epoch 198,   batch loss: 0.45741, batch accuracy: 0.86867
Time: 2018-07-14 23:21:52
TRAINING STATS: batch 122/486 in epoch 198,  batch loss: 0.40894, batch accuracy: 0.88233
Time: 2018-07-14 23:21:57
TRAINING STATS: batch 172/486 in epoch 198,  batch loss: 0.45362, batch accuracy: 0.86883
Time: 2018-07-14 23:22:00
TRAINING STATS: batch 222/486 in epoch 198,  batch loss: 0.47850, batch accuracy: 0.86267
Time: 2018-07-14 23:22:04
TRAINING STATS: batch 272/486 in epoch 198,  batch loss: 0.48920, batch accuracy: 0.85683
Time: 2018-07-14 23:22:09
TRAINING STATS: batch 322/486 in epoch 198,  batch loss: 0.44358, batch accuracy: 0.87283
Time: 2018-07-14 23:22:13
TRAINING STATS: batch 372/486 in epoch 198,  batch loss: 0.45463, batch accuracy: 0.86700
Time: 2018-07-14 23:22:16
TRAINING STATS: batch 422/486 in epoch 198,  batch loss: 0.42589, batch accuracy: 0.87467
Time: 2018-07-14 23:22:21
TRAINING STATS: batch 472/486 in epoch 198,  batch loss: 0.48540, batch accuracy: 0.85817
Time: 2018-07-14 23:22:25
TRAINING STATS: batch 36/486 in epoch 199,   batch loss: 0.51761, batch accuracy: 0.84817
Time: 2018-07-14 23:22:28
TRAINING STATS: batch 86/486 in epoch 199,   batch loss: 0.43674, batch accuracy: 0.87183
Time: 2018-07-14 23:22:33
TRAINING STATS: batch 136/486 in epoch 199,  batch loss: 0.47247, batch accuracy: 0.85717
Time: 2018-07-14 23:22:37
TRAINING STATS: batch 186/486 in epoch 199,  batch loss: 0.45521, batch accuracy: 0.86733
Time: 2018-07-14 23:22:41
TRAINING STATS: batch 236/486 in epoch 199,  batch loss: 0.46807, batch accuracy: 0.86050
Time: 2018-07-14 23:22:45
TRAINING STATS: batch 286/486 in epoch 199,  batch loss: 0.46191, batch accuracy: 0.86667
Time: 2018-07-14 23:22:49
TRAINING STATS: batch 336/486 in epoch 199,  batch loss: 0.45147, batch accuracy: 0.87400
Time: 2018-07-14 23:22:53
TRAINING STATS: batch 386/486 in epoch 199,  batch loss: 0.47500, batch accuracy: 0.85750
Time: 2018-07-14 23:22:58
TRAINING STATS: batch 436/486 in epoch 199,  batch loss: 0.45974, batch accuracy: 0.86400
Time: 2018-07-14 23:23:01
TRAINING STATS: batch 0/486 in epoch 200,    batch loss: 0.48979, batch accuracy: 0.85667
Time: 2018-07-14 23:23:05
TRAINING STATS: batch 50/486 in epoch 200,   batch loss: 0.43640, batch accuracy: 0.87283
Time: 2018-07-14 23:23:10
TRAINING STATS: batch 100/486 in epoch 200,  batch loss: 0.50057, batch accuracy: 0.85283
Time: 2018-07-14 23:23:13
TRAINING STATS: batch 150/486 in epoch 200,  batch loss: 0.53560, batch accuracy: 0.84433
Time: 2018-07-14 23:23:17
TRAINING STATS: batch 200/486 in epoch 200,  batch loss: 0.46812, batch accuracy: 0.86600
Time: 2018-07-14 23:23:22
TRAINING STATS: batch 250/486 in epoch 200,  batch loss: 0.53351, batch accuracy: 0.84467
Time: 2018-07-14 23:23:26
TRAINING STATS: batch 300/486 in epoch 200,  batch loss: 0.50535, batch accuracy: 0.85683
Time: 2018-07-14 23:23:29
TRAINING STATS: batch 350/486 in epoch 200,  batch loss: 0.49497, batch accuracy: 0.85483
Time: 2018-07-14 23:23:34
TRAINING STATS: batch 400/486 in epoch 200,  batch loss: 0.47079, batch accuracy: 0.86667
Time: 2018-07-14 23:23:38
TRAINING STATS: batch 450/486 in epoch 200,  batch loss: 2.24653, batch accuracy: 0.39333
Time: 2018-07-14 23:23:42
TRAINING STATS: batch 14/486 in epoch 201,   batch loss: 1.99389, batch accuracy: 0.45900
Time: 2018-07-14 23:23:46
TRAINING STATS: batch 64/486 in epoch 201,   batch loss: 2.06678, batch accuracy: 0.43600
Time: 2018-07-14 23:23:50
TRAINING STATS: batch 114/486 in epoch 201,  batch loss: 1.94450, batch accuracy: 0.46217
Time: 2018-07-14 23:23:54
TRAINING STATS: batch 164/486 in epoch 201,  batch loss: 1.80238, batch accuracy: 0.50650
Time: 2018-07-14 23:23:58
TRAINING STATS: batch 214/486 in epoch 201,  batch loss: 1.87212, batch accuracy: 0.49217
Time: 2018-07-14 23:24:02
TRAINING STATS: batch 264/486 in epoch 201,  batch loss: 1.90488, batch accuracy: 0.47083
Time: 2018-07-14 23:24:06
TRAINING STATS: batch 314/486 in epoch 201,  batch loss: 1.93542, batch accuracy: 0.46017
Time: 2018-07-14 23:24:11
TRAINING STATS: batch 364/486 in epoch 201,  batch loss: 1.92382, batch accuracy: 0.47917
Time: 2018-07-14 23:24:14
TRAINING STATS: batch 414/486 in epoch 201,  batch loss: 1.76863, batch accuracy: 0.51683
Time: 2018-07-14 23:24:18
TRAINING STATS: batch 464/486 in epoch 201,  batch loss: 1.75550, batch accuracy: 0.52200
Time: 2018-07-14 23:24:23
TRAINING STATS: batch 28/486 in epoch 202,   batch loss: 1.69209, batch accuracy: 0.54050
Time: 2018-07-14 23:24:27
TRAINING STATS: batch 78/486 in epoch 202,   batch loss: 1.76644, batch accuracy: 0.52217
Time: 2018-07-14 23:24:30
TRAINING STATS: batch 128/486 in epoch 202,  batch loss: 1.73394, batch accuracy: 0.52283
Time: 2018-07-14 23:24:35
TRAINING STATS: batch 178/486 in epoch 202,  batch loss: 1.64925, batch accuracy: 0.54733
Time: 2018-07-14 23:24:39
TRAINING STATS: batch 228/486 in epoch 202,  batch loss: 1.68415, batch accuracy: 0.53850
Time: 2018-07-14 23:24:42
TRAINING STATS: batch 278/486 in epoch 202,  batch loss: 1.66592, batch accuracy: 0.54450
Time: 2018-07-14 23:24:47
TRAINING STATS: batch 328/486 in epoch 202,  batch loss: 1.69285, batch accuracy: 0.53400
Time: 2018-07-14 23:24:51
TRAINING STATS: batch 378/486 in epoch 202,  batch loss: 1.68969, batch accuracy: 0.53900
Time: 2018-07-14 23:24:55
TRAINING STATS: batch 428/486 in epoch 202,  batch loss: 1.76122, batch accuracy: 0.51867
Time: 2018-07-14 23:24:59
TRAINING STATS: batch 478/486 in epoch 202,  batch loss: 1.73070, batch accuracy: 0.52400
Time: 2018-07-14 23:25:03
TRAINING STATS: batch 42/486 in epoch 203,   batch loss: 1.59761, batch accuracy: 0.56350
Time: 2018-07-14 23:25:07
TRAINING STATS: batch 92/486 in epoch 203,   batch loss: 1.68719, batch accuracy: 0.53683
Time: 2018-07-14 23:25:11
TRAINING STATS: batch 142/486 in epoch 203,  batch loss: 1.64341, batch accuracy: 0.55450
Time: 2018-07-14 23:25:15
TRAINING STATS: batch 192/486 in epoch 203,  batch loss: 1.66091, batch accuracy: 0.54317
Time: 2018-07-14 23:25:19
TRAINING STATS: batch 242/486 in epoch 203,  batch loss: 1.62683, batch accuracy: 0.55633
Time: 2018-07-14 23:25:24
TRAINING STATS: batch 292/486 in epoch 203,  batch loss: 1.61258, batch accuracy: 0.55700
Time: 2018-07-14 23:25:27
TRAINING STATS: batch 342/486 in epoch 203,  batch loss: 1.62691, batch accuracy: 0.55600
Time: 2018-07-14 23:25:31
TRAINING STATS: batch 392/486 in epoch 203,  batch loss: 1.55238, batch accuracy: 0.57133
Time: 2018-07-14 23:25:36
TRAINING STATS: batch 442/486 in epoch 203,  batch loss: 1.54783, batch accuracy: 0.57300
Time: 2018-07-14 23:25:39
TRAINING STATS: batch 6/486 in epoch 204,    batch loss: 1.68991, batch accuracy: 0.53750
Time: 2018-07-14 23:25:43
TRAINING STATS: batch 56/486 in epoch 204,   batch loss: 1.60573, batch accuracy: 0.56050
Time: 2018-07-14 23:25:48
TRAINING STATS: batch 106/486 in epoch 204,  batch loss: 1.71025, batch accuracy: 0.52850
Time: 2018-07-14 23:25:52
TRAINING STATS: batch 156/486 in epoch 204,  batch loss: 1.67510, batch accuracy: 0.54250
Time: 2018-07-14 23:25:55
TRAINING STATS: batch 206/486 in epoch 204,  batch loss: 1.71094, batch accuracy: 0.53433
Time: 2018-07-14 23:26:00
TRAINING STATS: batch 256/486 in epoch 204,  batch loss: 1.56021, batch accuracy: 0.56900
Time: 2018-07-14 23:26:04
TRAINING STATS: batch 306/486 in epoch 204,  batch loss: 1.63602, batch accuracy: 0.55300
Time: 2018-07-14 23:26:07
TRAINING STATS: batch 356/486 in epoch 204,  batch loss: 1.67041, batch accuracy: 0.53617
Time: 2018-07-14 23:26:12
TRAINING STATS: batch 406/486 in epoch 204,  batch loss: 1.68932, batch accuracy: 0.53400
Time: 2018-07-14 23:26:16
TRAINING STATS: batch 456/486 in epoch 204,  batch loss: 1.46217, batch accuracy: 0.60617
Time: 2018-07-14 23:26:20
TRAINING STATS: batch 20/486 in epoch 205,   batch loss: 1.59497, batch accuracy: 0.57050
Time: 2018-07-14 23:26:24
TRAINING STATS: batch 70/486 in epoch 205,   batch loss: 1.46241, batch accuracy: 0.59967
Time: 2018-07-14 23:26:28
TRAINING STATS: batch 120/486 in epoch 205,  batch loss: 1.54257, batch accuracy: 0.57117
Time: 2018-07-14 23:26:32
TRAINING STATS: batch 170/486 in epoch 205,  batch loss: 1.58654, batch accuracy: 0.56367
Time: 2018-07-14 23:26:37
TRAINING STATS: batch 220/486 in epoch 205,  batch loss: 1.49805, batch accuracy: 0.59083
Time: 2018-07-14 23:26:40
TRAINING STATS: batch 270/486 in epoch 205,  batch loss: 1.57483, batch accuracy: 0.55967
Time: 2018-07-14 23:26:44
TRAINING STATS: batch 320/486 in epoch 205,  batch loss: 1.51886, batch accuracy: 0.58200
Time: 2018-07-14 23:26:49
TRAINING STATS: batch 370/486 in epoch 205,  batch loss: 1.56311, batch accuracy: 0.56933
Time: 2018-07-14 23:26:52
TRAINING STATS: batch 420/486 in epoch 205,  batch loss: 1.60181, batch accuracy: 0.56600
Time: 2018-07-14 23:26:56
TRAINING STATS: batch 470/486 in epoch 205,  batch loss: 1.64906, batch accuracy: 0.54617
Time: 2018-07-14 23:27:01
TRAINING STATS: batch 34/486 in epoch 206,   batch loss: 1.58572, batch accuracy: 0.57150
Time: 2018-07-14 23:27:05
TRAINING STATS: batch 84/486 in epoch 206,   batch loss: 1.57756, batch accuracy: 0.56850
Time: 2018-07-14 23:27:08
TRAINING STATS: batch 134/486 in epoch 206,  batch loss: 1.53899, batch accuracy: 0.59000
Time: 2018-07-14 23:27:13
TRAINING STATS: batch 184/486 in epoch 206,  batch loss: 1.53348, batch accuracy: 0.58067
Time: 2018-07-14 23:27:17
TRAINING STATS: batch 234/486 in epoch 206,  batch loss: 1.65202, batch accuracy: 0.54583
Time: 2018-07-14 23:27:20
TRAINING STATS: batch 284/486 in epoch 206,  batch loss: 1.58696, batch accuracy: 0.56250
Time: 2018-07-14 23:27:25
TRAINING STATS: batch 334/486 in epoch 206,  batch loss: 1.51177, batch accuracy: 0.58750
Time: 2018-07-14 23:27:29
TRAINING STATS: batch 384/486 in epoch 206,  batch loss: 1.50973, batch accuracy: 0.59367
Time: 2018-07-14 23:27:33
TRAINING STATS: batch 434/486 in epoch 206,  batch loss: 1.60234, batch accuracy: 0.55833
Time: 2018-07-14 23:27:37
TRAINING STATS: batch 484/486 in epoch 206,  batch loss: 1.55195, batch accuracy: 0.57333
Time: 2018-07-14 23:27:41
TRAINING STATS: batch 48/486 in epoch 207,   batch loss: 1.53753, batch accuracy: 0.57700
Time: 2018-07-14 23:27:45
TRAINING STATS: batch 98/486 in epoch 207,   batch loss: 1.48875, batch accuracy: 0.59583
Time: 2018-07-14 23:27:50
TRAINING STATS: batch 148/486 in epoch 207,  batch loss: 1.55226, batch accuracy: 0.58000
Time: 2018-07-14 23:27:53
TRAINING STATS: batch 198/486 in epoch 207,  batch loss: 1.52945, batch accuracy: 0.58850
Time: 2018-07-14 23:27:57
TRAINING STATS: batch 248/486 in epoch 207,  batch loss: 1.55390, batch accuracy: 0.58000
Time: 2018-07-14 23:28:02
TRAINING STATS: batch 298/486 in epoch 207,  batch loss: 1.56077, batch accuracy: 0.58383
Time: 2018-07-14 23:28:05
TRAINING STATS: batch 348/486 in epoch 207,  batch loss: 1.56196, batch accuracy: 0.57833
Time: 2018-07-14 23:28:09
TRAINING STATS: batch 398/486 in epoch 207,  batch loss: 1.53618, batch accuracy: 0.58633
Time: 2018-07-14 23:28:14
TRAINING STATS: batch 448/486 in epoch 207,  batch loss: 1.56244, batch accuracy: 0.57650
Time: 2018-07-14 23:28:18
TRAINING STATS: batch 12/486 in epoch 208,   batch loss: 1.55221, batch accuracy: 0.57417
Time: 2018-07-14 23:28:21
TRAINING STATS: batch 62/486 in epoch 208,   batch loss: 1.60846, batch accuracy: 0.56033
Time: 2018-07-14 23:28:26
TRAINING STATS: batch 112/486 in epoch 208,  batch loss: 1.54943, batch accuracy: 0.57850
Time: 2018-07-14 23:28:30
TRAINING STATS: batch 162/486 in epoch 208,  batch loss: 1.51024, batch accuracy: 0.58933
Time: 2018-07-14 23:28:33
TRAINING STATS: batch 212/486 in epoch 208,  batch loss: 1.43013, batch accuracy: 0.61050
Time: 2018-07-14 23:28:38
TRAINING STATS: batch 262/486 in epoch 208,  batch loss: 1.56645, batch accuracy: 0.57233
Time: 2018-07-14 23:28:42
TRAINING STATS: batch 312/486 in epoch 208,  batch loss: 1.50843, batch accuracy: 0.59250
Time: 2018-07-14 23:28:46
TRAINING STATS: batch 362/486 in epoch 208,  batch loss: 1.49762, batch accuracy: 0.59283
Time: 2018-07-14 23:28:50
TRAINING STATS: batch 412/486 in epoch 208,  batch loss: 1.43104, batch accuracy: 0.60983
Time: 2018-07-14 23:28:54
TRAINING STATS: batch 462/486 in epoch 208,  batch loss: 1.49754, batch accuracy: 0.59167
Time: 2018-07-14 23:28:58
TRAINING STATS: batch 26/486 in epoch 209,   batch loss: 1.54883, batch accuracy: 0.57600
Time: 2018-07-14 23:29:02
TRAINING STATS: batch 76/486 in epoch 209,   batch loss: 1.56950, batch accuracy: 0.57267
Time: 2018-07-14 23:29:06
TRAINING STATS: batch 126/486 in epoch 209,  batch loss: 1.60895, batch accuracy: 0.55883
Time: 2018-07-14 23:29:10
TRAINING STATS: batch 176/486 in epoch 209,  batch loss: 1.46444, batch accuracy: 0.60050
Time: 2018-07-14 23:29:15
TRAINING STATS: batch 226/486 in epoch 209,  batch loss: 1.51098, batch accuracy: 0.58117
Time: 2018-07-14 23:29:18
TRAINING STATS: batch 276/486 in epoch 209,  batch loss: 1.48890, batch accuracy: 0.59533
Time: 2018-07-14 23:29:22
TRAINING STATS: batch 326/486 in epoch 209,  batch loss: 1.52573, batch accuracy: 0.58633
Time: 2018-07-14 23:29:27
TRAINING STATS: batch 376/486 in epoch 209,  batch loss: 1.57116, batch accuracy: 0.57267
Time: 2018-07-14 23:29:30
TRAINING STATS: batch 426/486 in epoch 209,  batch loss: 1.51309, batch accuracy: 0.58617
Time: 2018-07-14 23:29:34
TRAINING STATS: batch 476/486 in epoch 209,  batch loss: 1.50068, batch accuracy: 0.59300
Time: 2018-07-14 23:29:39
TRAINING STATS: batch 40/486 in epoch 210,   batch loss: 1.47232, batch accuracy: 0.60467
Time: 2018-07-14 23:29:43
TRAINING STATS: batch 90/486 in epoch 210,   batch loss: 1.55133, batch accuracy: 0.57717
Time: 2018-07-14 23:29:46
TRAINING STATS: batch 140/486 in epoch 210,  batch loss: 1.41841, batch accuracy: 0.61767
Time: 2018-07-14 23:29:51
TRAINING STATS: batch 190/486 in epoch 210,  batch loss: 1.47497, batch accuracy: 0.60733
Time: 2018-07-14 23:29:55
TRAINING STATS: batch 240/486 in epoch 210,  batch loss: 1.43650, batch accuracy: 0.60617
Time: 2018-07-14 23:29:58
TRAINING STATS: batch 290/486 in epoch 210,  batch loss: 1.54650, batch accuracy: 0.57817
Time: 2018-07-14 23:30:03
TRAINING STATS: batch 340/486 in epoch 210,  batch loss: 1.54351, batch accuracy: 0.57417
Time: 2018-07-14 23:30:07
TRAINING STATS: batch 390/486 in epoch 210,  batch loss: 1.40329, batch accuracy: 0.62067
Time: 2018-07-14 23:30:11
TRAINING STATS: batch 440/486 in epoch 210,  batch loss: 1.49516, batch accuracy: 0.59150
Time: 2018-07-14 23:30:15
TRAINING STATS: batch 4/486 in epoch 211,    batch loss: 1.42621, batch accuracy: 0.61617
Time: 2018-07-14 23:30:19
TRAINING STATS: batch 54/486 in epoch 211,   batch loss: 1.46767, batch accuracy: 0.60167
Time: 2018-07-14 23:30:23
TRAINING STATS: batch 104/486 in epoch 211,  batch loss: 1.48511, batch accuracy: 0.59567
Time: 2018-07-14 23:30:28
TRAINING STATS: batch 154/486 in epoch 211,  batch loss: 1.43799, batch accuracy: 0.60900
Time: 2018-07-14 23:30:31
TRAINING STATS: batch 204/486 in epoch 211,  batch loss: 1.58259, batch accuracy: 0.57083
Time: 2018-07-14 23:30:35
TRAINING STATS: batch 254/486 in epoch 211,  batch loss: 1.37296, batch accuracy: 0.62500
Time: 2018-07-14 23:30:40
TRAINING STATS: batch 304/486 in epoch 211,  batch loss: 1.43565, batch accuracy: 0.60967
Time: 2018-07-14 23:30:43
TRAINING STATS: batch 354/486 in epoch 211,  batch loss: 1.46056, batch accuracy: 0.60133
Time: 2018-07-14 23:30:47
TRAINING STATS: batch 404/486 in epoch 211,  batch loss: 1.43090, batch accuracy: 0.60850
Time: 2018-07-14 23:30:52
TRAINING STATS: batch 454/486 in epoch 211,  batch loss: 1.29481, batch accuracy: 0.64133
Time: 2018-07-14 23:30:55
TRAINING STATS: batch 18/486 in epoch 212,   batch loss: 1.46707, batch accuracy: 0.59167
Time: 2018-07-14 23:30:59
TRAINING STATS: batch 68/486 in epoch 212,   batch loss: 1.33022, batch accuracy: 0.64333
Time: 2018-07-14 23:31:04
TRAINING STATS: batch 118/486 in epoch 212,  batch loss: 1.50071, batch accuracy: 0.59417
Time: 2018-07-14 23:31:08
TRAINING STATS: batch 168/486 in epoch 212,  batch loss: 1.47513, batch accuracy: 0.60267
Time: 2018-07-14 23:31:11
TRAINING STATS: batch 218/486 in epoch 212,  batch loss: 1.49233, batch accuracy: 0.59133
Time: 2018-07-14 23:31:16
TRAINING STATS: batch 268/486 in epoch 212,  batch loss: 1.54797, batch accuracy: 0.57017
Time: 2018-07-14 23:31:20
TRAINING STATS: batch 318/486 in epoch 212,  batch loss: 1.54997, batch accuracy: 0.57083
Time: 2018-07-14 23:31:23
TRAINING STATS: batch 368/486 in epoch 212,  batch loss: 1.51693, batch accuracy: 0.57467
Time: 2018-07-14 23:31:28
TRAINING STATS: batch 418/486 in epoch 212,  batch loss: 1.53213, batch accuracy: 0.58200
Time: 2018-07-14 23:31:32
TRAINING STATS: batch 468/486 in epoch 212,  batch loss: 1.47239, batch accuracy: 0.59700
Time: 2018-07-14 23:31:36
TRAINING STATS: batch 32/486 in epoch 213,   batch loss: 1.41377, batch accuracy: 0.61667
Time: 2018-07-14 23:31:40
TRAINING STATS: batch 82/486 in epoch 213,   batch loss: 1.52892, batch accuracy: 0.58200
Time: 2018-07-14 23:31:44
TRAINING STATS: batch 132/486 in epoch 213,  batch loss: 1.54520, batch accuracy: 0.58567
Time: 2018-07-14 23:31:48
TRAINING STATS: batch 182/486 in epoch 213,  batch loss: 1.57428, batch accuracy: 0.57717
Time: 2018-07-14 23:31:53
TRAINING STATS: batch 232/486 in epoch 213,  batch loss: 1.54968, batch accuracy: 0.57517
Time: 2018-07-14 23:31:56
TRAINING STATS: batch 282/486 in epoch 213,  batch loss: 1.46645, batch accuracy: 0.59467
Time: 2018-07-14 23:32:00
TRAINING STATS: batch 332/486 in epoch 213,  batch loss: 1.55512, batch accuracy: 0.58117
Time: 2018-07-14 23:32:05
TRAINING STATS: batch 382/486 in epoch 213,  batch loss: 1.52389, batch accuracy: 0.58067
Time: 2018-07-14 23:32:08
TRAINING STATS: batch 432/486 in epoch 213,  batch loss: 1.43033, batch accuracy: 0.60983
Time: 2018-07-14 23:32:12
TRAINING STATS: batch 482/486 in epoch 213,  batch loss: 1.45202, batch accuracy: 0.61100
Time: 2018-07-14 23:32:17
TRAINING STATS: batch 46/486 in epoch 214,   batch loss: 1.45753, batch accuracy: 0.60300
Time: 2018-07-14 23:32:21
TRAINING STATS: batch 96/486 in epoch 214,   batch loss: 1.55618, batch accuracy: 0.57900
Time: 2018-07-14 23:32:24
TRAINING STATS: batch 146/486 in epoch 214,  batch loss: 1.58266, batch accuracy: 0.56800
Time: 2018-07-14 23:32:29
TRAINING STATS: batch 196/486 in epoch 214,  batch loss: 1.51947, batch accuracy: 0.58617
Time: 2018-07-14 23:32:33
TRAINING STATS: batch 246/486 in epoch 214,  batch loss: 1.47773, batch accuracy: 0.60267
Time: 2018-07-14 23:32:36
TRAINING STATS: batch 296/486 in epoch 214,  batch loss: 1.45356, batch accuracy: 0.60483
Time: 2018-07-14 23:32:41
TRAINING STATS: batch 346/486 in epoch 214,  batch loss: 1.35727, batch accuracy: 0.63483
Time: 2018-07-14 23:32:45
TRAINING STATS: batch 396/486 in epoch 214,  batch loss: 1.40149, batch accuracy: 0.62133
Time: 2018-07-14 23:32:48
TRAINING STATS: batch 446/486 in epoch 214,  batch loss: 1.46433, batch accuracy: 0.60700
Time: 2018-07-14 23:32:53
TRAINING STATS: batch 10/486 in epoch 215,   batch loss: 1.43888, batch accuracy: 0.60717
Time: 2018-07-14 23:32:57
TRAINING STATS: batch 60/486 in epoch 215,   batch loss: 1.46048, batch accuracy: 0.60650
Time: 2018-07-14 23:33:01
TRAINING STATS: batch 110/486 in epoch 215,  batch loss: 1.54907, batch accuracy: 0.57650
Time: 2018-07-14 23:33:05
TRAINING STATS: batch 160/486 in epoch 215,  batch loss: 1.45389, batch accuracy: 0.60733
Time: 2018-07-14 23:33:09
TRAINING STATS: batch 210/486 in epoch 215,  batch loss: 1.37522, batch accuracy: 0.63350
Time: 2018-07-14 23:33:13
TRAINING STATS: batch 260/486 in epoch 215,  batch loss: 1.47505, batch accuracy: 0.59317
Time: 2018-07-14 23:33:18
TRAINING STATS: batch 310/486 in epoch 215,  batch loss: 1.43315, batch accuracy: 0.62167
Time: 2018-07-14 23:33:21
TRAINING STATS: batch 360/486 in epoch 215,  batch loss: 1.47875, batch accuracy: 0.59833
Time: 2018-07-14 23:33:25
TRAINING STATS: batch 410/486 in epoch 215,  batch loss: 1.36352, batch accuracy: 0.62883
Time: 2018-07-14 23:33:30
TRAINING STATS: batch 460/486 in epoch 215,  batch loss: 1.56311, batch accuracy: 0.56567
Time: 2018-07-14 23:33:33
TRAINING STATS: batch 24/486 in epoch 216,   batch loss: 1.59875, batch accuracy: 0.55967
Time: 2018-07-14 23:33:37
TRAINING STATS: batch 74/486 in epoch 216,   batch loss: 1.52342, batch accuracy: 0.58517
Time: 2018-07-14 23:33:42
TRAINING STATS: batch 124/486 in epoch 216,  batch loss: 1.46724, batch accuracy: 0.60083
Time: 2018-07-14 23:33:46
TRAINING STATS: batch 174/486 in epoch 216,  batch loss: 1.55028, batch accuracy: 0.58150
Time: 2018-07-14 23:33:49
TRAINING STATS: batch 224/486 in epoch 216,  batch loss: 1.55260, batch accuracy: 0.57300
Time: 2018-07-14 23:33:54
TRAINING STATS: batch 274/486 in epoch 216,  batch loss: 1.43092, batch accuracy: 0.60967
Time: 2018-07-14 23:33:58
TRAINING STATS: batch 324/486 in epoch 216,  batch loss: 1.46895, batch accuracy: 0.60133
Time: 2018-07-14 23:34:01
TRAINING STATS: batch 374/486 in epoch 216,  batch loss: 1.49192, batch accuracy: 0.59817
Time: 2018-07-14 23:34:06
TRAINING STATS: batch 424/486 in epoch 216,  batch loss: 1.37649, batch accuracy: 0.62467
Time: 2018-07-14 23:34:10
TRAINING STATS: batch 474/486 in epoch 216,  batch loss: 1.46808, batch accuracy: 0.60050
Time: 2018-07-14 23:34:14
TRAINING STATS: batch 38/486 in epoch 217,   batch loss: 1.47761, batch accuracy: 0.60767
Time: 2018-07-14 23:34:18
TRAINING STATS: batch 88/486 in epoch 217,   batch loss: 1.46564, batch accuracy: 0.60250
Time: 2018-07-14 23:34:22
TRAINING STATS: batch 138/486 in epoch 217,  batch loss: 1.48808, batch accuracy: 0.59350
Time: 2018-07-14 23:34:26
TRAINING STATS: batch 188/486 in epoch 217,  batch loss: 1.39163, batch accuracy: 0.62133
Time: 2018-07-14 23:34:31
TRAINING STATS: batch 238/486 in epoch 217,  batch loss: 1.41786, batch accuracy: 0.61817
Time: 2018-07-14 23:34:34
TRAINING STATS: batch 288/486 in epoch 217,  batch loss: 1.49246, batch accuracy: 0.58367
Time: 2018-07-14 23:34:38
TRAINING STATS: batch 338/486 in epoch 217,  batch loss: 1.43325, batch accuracy: 0.60967
Time: 2018-07-14 23:34:43
TRAINING STATS: batch 388/486 in epoch 217,  batch loss: 1.41299, batch accuracy: 0.61567
Time: 2018-07-14 23:34:46
TRAINING STATS: batch 438/486 in epoch 217,  batch loss: 1.48586, batch accuracy: 0.59750
Time: 2018-07-14 23:34:50
TRAINING STATS: batch 2/486 in epoch 218,    batch loss: 1.53336, batch accuracy: 0.58550
Time: 2018-07-14 23:34:55
TRAINING STATS: batch 52/486 in epoch 218,   batch loss: 1.57585, batch accuracy: 0.56633
Time: 2018-07-14 23:34:59
TRAINING STATS: batch 102/486 in epoch 218,  batch loss: 1.51552, batch accuracy: 0.59200
Time: 2018-07-14 23:35:02
TRAINING STATS: batch 152/486 in epoch 218,  batch loss: 1.44304, batch accuracy: 0.60583
Time: 2018-07-14 23:35:07
TRAINING STATS: batch 202/486 in epoch 218,  batch loss: 1.47278, batch accuracy: 0.59800
Time: 2018-07-14 23:35:11
TRAINING STATS: batch 252/486 in epoch 218,  batch loss: 1.43146, batch accuracy: 0.60417
Time: 2018-07-14 23:35:14
TRAINING STATS: batch 302/486 in epoch 218,  batch loss: 1.40946, batch accuracy: 0.60833
Time: 2018-07-14 23:35:19
TRAINING STATS: batch 352/486 in epoch 218,  batch loss: 1.42063, batch accuracy: 0.61617
Time: 2018-07-14 23:35:23
TRAINING STATS: batch 402/486 in epoch 218,  batch loss: 1.30964, batch accuracy: 0.64417
Time: 2018-07-14 23:35:27
TRAINING STATS: batch 452/486 in epoch 218,  batch loss: 1.39670, batch accuracy: 0.61600
Time: 2018-07-14 23:35:31
TRAINING STATS: batch 16/486 in epoch 219,   batch loss: 1.41909, batch accuracy: 0.61867
Time: 2018-07-14 23:35:35
TRAINING STATS: batch 66/486 in epoch 219,   batch loss: 1.41447, batch accuracy: 0.61633
Time: 2018-07-14 23:35:39
TRAINING STATS: batch 116/486 in epoch 219,  batch loss: 1.41434, batch accuracy: 0.61067
Time: 2018-07-14 23:35:44
TRAINING STATS: batch 166/486 in epoch 219,  batch loss: 1.46781, batch accuracy: 0.60967
Time: 2018-07-14 23:35:47
TRAINING STATS: batch 216/486 in epoch 219,  batch loss: 1.54930, batch accuracy: 0.58000
Time: 2018-07-14 23:35:51
TRAINING STATS: batch 266/486 in epoch 219,  batch loss: 1.50159, batch accuracy: 0.58917
Time: 2018-07-14 23:35:56
TRAINING STATS: batch 316/486 in epoch 219,  batch loss: 1.49032, batch accuracy: 0.58900
Time: 2018-07-14 23:35:59
TRAINING STATS: batch 366/486 in epoch 219,  batch loss: 1.58526, batch accuracy: 0.57400
Time: 2018-07-14 23:36:03
TRAINING STATS: batch 416/486 in epoch 219,  batch loss: 1.52512, batch accuracy: 0.58600
Time: 2018-07-14 23:36:08
TRAINING STATS: batch 466/486 in epoch 219,  batch loss: 1.33926, batch accuracy: 0.63717
Time: 2018-07-14 23:36:11
TRAINING STATS: batch 30/486 in epoch 220,   batch loss: 1.33492, batch accuracy: 0.64067
Time: 2018-07-14 23:36:15
TRAINING STATS: batch 80/486 in epoch 220,   batch loss: 1.45678, batch accuracy: 0.60133
Time: 2018-07-14 23:36:20
TRAINING STATS: batch 130/486 in epoch 220,  batch loss: 1.44208, batch accuracy: 0.60933
Time: 2018-07-14 23:36:24
TRAINING STATS: batch 180/486 in epoch 220,  batch loss: 1.47752, batch accuracy: 0.60300
Time: 2018-07-14 23:36:27
TRAINING STATS: batch 230/486 in epoch 220,  batch loss: 1.43757, batch accuracy: 0.60683
Time: 2018-07-14 23:36:32
TRAINING STATS: batch 280/486 in epoch 220,  batch loss: 1.39646, batch accuracy: 0.61517
Time: 2018-07-14 23:36:36
TRAINING STATS: batch 330/486 in epoch 220,  batch loss: 1.40113, batch accuracy: 0.61883
Time: 2018-07-14 23:36:40
TRAINING STATS: batch 380/486 in epoch 220,  batch loss: 1.34605, batch accuracy: 0.63667
Time: 2018-07-14 23:36:44
TRAINING STATS: batch 430/486 in epoch 220,  batch loss: 1.32331, batch accuracy: 0.64050
Time: 2018-07-14 23:36:48
TRAINING STATS: batch 480/486 in epoch 220,  batch loss: 1.39644, batch accuracy: 0.62433
Time: 2018-07-14 23:36:52
TRAINING STATS: batch 44/486 in epoch 221,   batch loss: 1.35531, batch accuracy: 0.62750
Time: 2018-07-14 23:36:56
TRAINING STATS: batch 94/486 in epoch 221,   batch loss: 1.46713, batch accuracy: 0.60667
Time: 2018-07-14 23:37:00
TRAINING STATS: batch 144/486 in epoch 221,  batch loss: 1.51408, batch accuracy: 0.58650
Time: 2018-07-14 23:37:04
TRAINING STATS: batch 194/486 in epoch 221,  batch loss: 1.54114, batch accuracy: 0.58017
Time: 2018-07-14 23:37:09
TRAINING STATS: batch 244/486 in epoch 221,  batch loss: 1.41398, batch accuracy: 0.61517
Time: 2018-07-14 23:37:12
TRAINING STATS: batch 294/486 in epoch 221,  batch loss: 1.33582, batch accuracy: 0.62817
Time: 2018-07-14 23:37:16
TRAINING STATS: batch 344/486 in epoch 221,  batch loss: 1.37777, batch accuracy: 0.62333
Time: 2018-07-14 23:37:21
TRAINING STATS: batch 394/486 in epoch 221,  batch loss: 1.32943, batch accuracy: 0.64300
Time: 2018-07-14 23:37:25
TRAINING STATS: batch 444/486 in epoch 221,  batch loss: 1.32300, batch accuracy: 0.64033
Time: 2018-07-14 23:37:28
TRAINING STATS: batch 8/486 in epoch 222,    batch loss: 1.43415, batch accuracy: 0.61300
Time: 2018-07-14 23:37:33
TRAINING STATS: batch 58/486 in epoch 222,   batch loss: 1.38905, batch accuracy: 0.62217
Time: 2018-07-14 23:37:37
TRAINING STATS: batch 108/486 in epoch 222,  batch loss: 1.51000, batch accuracy: 0.59467
Time: 2018-07-14 23:37:40
TRAINING STATS: batch 158/486 in epoch 222,  batch loss: 1.46530, batch accuracy: 0.60950
Time: 2018-07-14 23:37:45
TRAINING STATS: batch 208/486 in epoch 222,  batch loss: 1.43492, batch accuracy: 0.61233
Time: 2018-07-14 23:37:49
TRAINING STATS: batch 258/486 in epoch 222,  batch loss: 1.46738, batch accuracy: 0.60367
Time: 2018-07-14 23:37:52
TRAINING STATS: batch 308/486 in epoch 222,  batch loss: 1.57088, batch accuracy: 0.57867
Time: 2018-07-14 23:37:57
TRAINING STATS: batch 358/486 in epoch 222,  batch loss: 1.57591, batch accuracy: 0.56200
Time: 2018-07-14 23:38:01
TRAINING STATS: batch 408/486 in epoch 222,  batch loss: 1.59805, batch accuracy: 0.56517
Time: 2018-07-14 23:38:05
TRAINING STATS: batch 458/486 in epoch 222,  batch loss: 1.56575, batch accuracy: 0.57483
Time: 2018-07-14 23:38:09
TRAINING STATS: batch 22/486 in epoch 223,   batch loss: 1.52251, batch accuracy: 0.58633
Time: 2018-07-14 23:38:13
TRAINING STATS: batch 72/486 in epoch 223,   batch loss: 1.49987, batch accuracy: 0.58950
Time: 2018-07-14 23:38:17
TRAINING STATS: batch 122/486 in epoch 223,  batch loss: 1.39191, batch accuracy: 0.62550
Time: 2018-07-14 23:38:21
TRAINING STATS: batch 172/486 in epoch 223,  batch loss: 1.54093, batch accuracy: 0.57867
Time: 2018-07-14 23:38:25
TRAINING STATS: batch 222/486 in epoch 223,  batch loss: 1.46074, batch accuracy: 0.59583
Time: 2018-07-14 23:38:29
TRAINING STATS: batch 272/486 in epoch 223,  batch loss: 1.46517, batch accuracy: 0.59500
Time: 2018-07-14 23:38:34
TRAINING STATS: batch 322/486 in epoch 223,  batch loss: 1.47049, batch accuracy: 0.60683
Time: 2018-07-14 23:38:37
TRAINING STATS: batch 372/486 in epoch 223,  batch loss: 1.43918, batch accuracy: 0.61017
Time: 2018-07-14 23:38:41
TRAINING STATS: batch 422/486 in epoch 223,  batch loss: 1.56868, batch accuracy: 0.57300
Time: 2018-07-14 23:38:46
TRAINING STATS: batch 472/486 in epoch 223,  batch loss: 1.67491, batch accuracy: 0.54317
Time: 2018-07-14 23:38:49
TRAINING STATS: batch 36/486 in epoch 224,   batch loss: 2.19897, batch accuracy: 0.40783
Time: 2018-07-14 23:38:53
TRAINING STATS: batch 86/486 in epoch 224,   batch loss: 1.88900, batch accuracy: 0.49300
Time: 2018-07-14 23:38:58
TRAINING STATS: batch 136/486 in epoch 224,  batch loss: 1.76009, batch accuracy: 0.52550
Time: 2018-07-14 23:39:01
TRAINING STATS: batch 186/486 in epoch 224,  batch loss: 1.63425, batch accuracy: 0.55150
Time: 2018-07-14 23:39:05
TRAINING STATS: batch 236/486 in epoch 224,  batch loss: 1.65704, batch accuracy: 0.54267
Time: 2018-07-14 23:39:10
TRAINING STATS: batch 286/486 in epoch 224,  batch loss: 1.56880, batch accuracy: 0.56950
Time: 2018-07-14 23:39:14
TRAINING STATS: batch 336/486 in epoch 224,  batch loss: 1.47143, batch accuracy: 0.59583
Time: 2018-07-14 23:39:17
TRAINING STATS: batch 386/486 in epoch 224,  batch loss: 1.61916, batch accuracy: 0.55317
Time: 2018-07-14 23:39:22
TRAINING STATS: batch 436/486 in epoch 224,  batch loss: 1.98125, batch accuracy: 0.46633
Time: 2018-07-14 23:39:26
TRAINING STATS: batch 0/486 in epoch 225,    batch loss: 1.85908, batch accuracy: 0.49283
Time: 2018-07-14 23:39:29
TRAINING STATS: batch 50/486 in epoch 225,   batch loss: 1.66514, batch accuracy: 0.55033
Time: 2018-07-14 23:39:34
TRAINING STATS: batch 100/486 in epoch 225,  batch loss: 1.64042, batch accuracy: 0.56067
Time: 2018-07-14 23:39:38
TRAINING STATS: batch 150/486 in epoch 225,  batch loss: 1.51128, batch accuracy: 0.59117
Time: 2018-07-14 23:39:42
TRAINING STATS: batch 200/486 in epoch 225,  batch loss: 1.37544, batch accuracy: 0.63317
Time: 2018-07-14 23:39:46
TRAINING STATS: batch 250/486 in epoch 225,  batch loss: 1.60742, batch accuracy: 0.56117
Time: 2018-07-14 23:39:50
TRAINING STATS: batch 300/486 in epoch 225,  batch loss: 1.55969, batch accuracy: 0.57017
Time: 2018-07-14 23:39:54
TRAINING STATS: batch 350/486 in epoch 225,  batch loss: 1.48563, batch accuracy: 0.59650
Time: 2018-07-14 23:39:59
TRAINING STATS: batch 400/486 in epoch 225,  batch loss: 1.36510, batch accuracy: 0.63400
Time: 2018-07-14 23:40:02
TRAINING STATS: batch 450/486 in epoch 225,  batch loss: 1.53639, batch accuracy: 0.57717
Time: 2018-07-14 23:40:06
TRAINING STATS: batch 14/486 in epoch 226,   batch loss: 1.38551, batch accuracy: 0.62333
Time: 2018-07-14 23:40:11
TRAINING STATS: batch 64/486 in epoch 226,   batch loss: 1.58562, batch accuracy: 0.56633
Time: 2018-07-14 23:40:14
TRAINING STATS: batch 114/486 in epoch 226,  batch loss: 1.49987, batch accuracy: 0.59050
Time: 2018-07-14 23:40:18
TRAINING STATS: batch 164/486 in epoch 226,  batch loss: 1.40255, batch accuracy: 0.62033
Time: 2018-07-14 23:40:23
TRAINING STATS: batch 214/486 in epoch 226,  batch loss: 1.43345, batch accuracy: 0.61267
Time: 2018-07-14 23:40:27
TRAINING STATS: batch 264/486 in epoch 226,  batch loss: 1.46510, batch accuracy: 0.60383
Time: 2018-07-14 23:40:30
TRAINING STATS: batch 314/486 in epoch 226,  batch loss: 1.52787, batch accuracy: 0.57633
Time: 2018-07-14 23:40:35
TRAINING STATS: batch 364/486 in epoch 226,  batch loss: 1.40350, batch accuracy: 0.61700
Time: 2018-07-14 23:40:39
TRAINING STATS: batch 414/486 in epoch 226,  batch loss: 1.36067, batch accuracy: 0.62650
Time: 2018-07-14 23:40:42
TRAINING STATS: batch 464/486 in epoch 226,  batch loss: 1.59434, batch accuracy: 0.57267
Time: 2018-07-14 23:40:47
TRAINING STATS: batch 28/486 in epoch 227,   batch loss: 1.64992, batch accuracy: 0.54867
Time: 2018-07-14 23:40:51
TRAINING STATS: batch 78/486 in epoch 227,   batch loss: 1.59546, batch accuracy: 0.57017
Time: 2018-07-14 23:40:54
TRAINING STATS: batch 128/486 in epoch 227,  batch loss: 1.53771, batch accuracy: 0.57567
Time: 2018-07-14 23:40:59
TRAINING STATS: batch 178/486 in epoch 227,  batch loss: 1.37151, batch accuracy: 0.62317
Time: 2018-07-14 23:41:03
TRAINING STATS: batch 228/486 in epoch 227,  batch loss: 1.37882, batch accuracy: 0.63417
Time: 2018-07-14 23:41:07
TRAINING STATS: batch 278/486 in epoch 227,  batch loss: 1.38289, batch accuracy: 0.62850
Time: 2018-07-14 23:41:11
TRAINING STATS: batch 328/486 in epoch 227,  batch loss: 1.43054, batch accuracy: 0.60833
Time: 2018-07-14 23:41:15
TRAINING STATS: batch 378/486 in epoch 227,  batch loss: 1.47486, batch accuracy: 0.59583
Time: 2018-07-14 23:41:19
TRAINING STATS: batch 428/486 in epoch 227,  batch loss: 1.52996, batch accuracy: 0.58383
Time: 2018-07-14 23:41:24
TRAINING STATS: batch 478/486 in epoch 227,  batch loss: 1.53287, batch accuracy: 0.58033
Time: 2018-07-14 23:41:27
TRAINING STATS: batch 42/486 in epoch 228,   batch loss: 1.36515, batch accuracy: 0.62650
Time: 2018-07-14 23:41:31
TRAINING STATS: batch 92/486 in epoch 228,   batch loss: 1.49513, batch accuracy: 0.60167
Time: 2018-07-14 23:41:36
TRAINING STATS: batch 142/486 in epoch 228,  batch loss: 1.42482, batch accuracy: 0.61533
Time: 2018-07-14 23:41:39
TRAINING STATS: batch 192/486 in epoch 228,  batch loss: 1.44633, batch accuracy: 0.60750
Time: 2018-07-14 23:41:43
TRAINING STATS: batch 242/486 in epoch 228,  batch loss: 1.39629, batch accuracy: 0.61733
Time: 2018-07-14 23:41:48
TRAINING STATS: batch 292/486 in epoch 228,  batch loss: 1.40011, batch accuracy: 0.62050
Time: 2018-07-14 23:41:52
TRAINING STATS: batch 342/486 in epoch 228,  batch loss: 1.41690, batch accuracy: 0.61917
Time: 2018-07-14 23:41:55
TRAINING STATS: batch 392/486 in epoch 228,  batch loss: 1.34708, batch accuracy: 0.63233
Time: 2018-07-14 23:42:00
TRAINING STATS: batch 442/486 in epoch 228,  batch loss: 1.30544, batch accuracy: 0.63617
Time: 2018-07-14 23:42:04
TRAINING STATS: batch 6/486 in epoch 229,    batch loss: 1.46857, batch accuracy: 0.59617
Time: 2018-07-14 23:42:07
TRAINING STATS: batch 56/486 in epoch 229,   batch loss: 1.39476, batch accuracy: 0.61633
Time: 2018-07-14 23:42:12
TRAINING STATS: batch 106/486 in epoch 229,  batch loss: 1.47233, batch accuracy: 0.59867
Time: 2018-07-14 23:42:16
TRAINING STATS: batch 156/486 in epoch 229,  batch loss: 1.45639, batch accuracy: 0.60483
Time: 2018-07-14 23:42:19
TRAINING STATS: batch 206/486 in epoch 229,  batch loss: 1.53691, batch accuracy: 0.58033
Time: 2018-07-14 23:42:24
TRAINING STATS: batch 256/486 in epoch 229,  batch loss: 1.36908, batch accuracy: 0.62900
Time: 2018-07-14 23:42:28
TRAINING STATS: batch 306/486 in epoch 229,  batch loss: 1.42387, batch accuracy: 0.61567
Time: 2018-07-14 23:42:32
TRAINING STATS: batch 356/486 in epoch 229,  batch loss: 1.44236, batch accuracy: 0.60500
Time: 2018-07-14 23:42:36
TRAINING STATS: batch 406/486 in epoch 229,  batch loss: 1.45193, batch accuracy: 0.60200
Time: 2018-07-14 23:42:40
TRAINING STATS: batch 456/486 in epoch 229,  batch loss: 1.26106, batch accuracy: 0.65800
Time: 2018-07-14 23:42:44
TRAINING STATS: batch 20/486 in epoch 230,   batch loss: 1.38607, batch accuracy: 0.62533
Time: 2018-07-14 23:42:49
TRAINING STATS: batch 70/486 in epoch 230,   batch loss: 1.30987, batch accuracy: 0.64750
Time: 2018-07-14 23:42:52
TRAINING STATS: batch 120/486 in epoch 230,  batch loss: 1.36652, batch accuracy: 0.63067
Time: 2018-07-14 23:42:56
TRAINING STATS: batch 170/486 in epoch 230,  batch loss: 1.39135, batch accuracy: 0.61583
Time: 2018-07-14 23:43:01
TRAINING STATS: batch 220/486 in epoch 230,  batch loss: 1.35682, batch accuracy: 0.63400
Time: 2018-07-14 23:43:04
TRAINING STATS: batch 270/486 in epoch 230,  batch loss: 1.46136, batch accuracy: 0.59650
Time: 2018-07-14 23:43:08
TRAINING STATS: batch 320/486 in epoch 230,  batch loss: 1.41346, batch accuracy: 0.61633
Time: 2018-07-14 23:43:13
TRAINING STATS: batch 370/486 in epoch 230,  batch loss: 1.39397, batch accuracy: 0.61900
Time: 2018-07-14 23:43:17
TRAINING STATS: batch 420/486 in epoch 230,  batch loss: 1.48000, batch accuracy: 0.59167
Time: 2018-07-14 23:43:20
TRAINING STATS: batch 470/486 in epoch 230,  batch loss: 1.54951, batch accuracy: 0.57150
Time: 2018-07-14 23:43:25
TRAINING STATS: batch 34/486 in epoch 231,   batch loss: 1.49510, batch accuracy: 0.59417
Time: 2018-07-14 23:43:29
TRAINING STATS: batch 84/486 in epoch 231,   batch loss: 1.43237, batch accuracy: 0.60767
Time: 2018-07-14 23:43:32
TRAINING STATS: batch 134/486 in epoch 231,  batch loss: 1.39947, batch accuracy: 0.62367
Time: 2018-07-14 23:43:37
TRAINING STATS: batch 184/486 in epoch 231,  batch loss: 1.41593, batch accuracy: 0.61667
Time: 2018-07-14 23:43:41
TRAINING STATS: batch 234/486 in epoch 231,  batch loss: 1.49879, batch accuracy: 0.58867
Time: 2018-07-14 23:43:44
TRAINING STATS: batch 284/486 in epoch 231,  batch loss: 1.45154, batch accuracy: 0.60217
Time: 2018-07-14 23:43:49
TRAINING STATS: batch 334/486 in epoch 231,  batch loss: 1.34486, batch accuracy: 0.63400
Time: 2018-07-14 23:43:53
TRAINING STATS: batch 384/486 in epoch 231,  batch loss: 1.40098, batch accuracy: 0.62183
Time: 2018-07-14 23:43:57
TRAINING STATS: batch 434/486 in epoch 231,  batch loss: 1.64405, batch accuracy: 0.55233
Time: 2018-07-14 23:44:01
TRAINING STATS: batch 484/486 in epoch 231,  batch loss: 1.59390, batch accuracy: 0.57000
Time: 2018-07-14 23:44:05
TRAINING STATS: batch 48/486 in epoch 232,   batch loss: 1.55322, batch accuracy: 0.57583
Time: 2018-07-14 23:44:09
TRAINING STATS: batch 98/486 in epoch 232,   batch loss: 1.53290, batch accuracy: 0.59083
Time: 2018-07-14 23:44:14
TRAINING STATS: batch 148/486 in epoch 232,  batch loss: 2.47484, batch accuracy: 0.31300
Time: 2018-07-14 23:44:17
TRAINING STATS: batch 198/486 in epoch 232,  batch loss: 2.02806, batch accuracy: 0.45783
Time: 2018-07-14 23:44:21
TRAINING STATS: batch 248/486 in epoch 232,  batch loss: 1.84932, batch accuracy: 0.50250
Time: 2018-07-14 23:44:26
TRAINING STATS: batch 298/486 in epoch 232,  batch loss: 1.71832, batch accuracy: 0.53433
Time: 2018-07-14 23:44:30
TRAINING STATS: batch 348/486 in epoch 232,  batch loss: 1.65523, batch accuracy: 0.55533
Time: 2018-07-14 23:44:33
TRAINING STATS: batch 398/486 in epoch 232,  batch loss: 1.61602, batch accuracy: 0.55917
Time: 2018-07-14 23:44:38
TRAINING STATS: batch 448/486 in epoch 232,  batch loss: 1.61988, batch accuracy: 0.56300
Time: 2018-07-14 23:44:42
TRAINING STATS: batch 12/486 in epoch 233,   batch loss: 1.70580, batch accuracy: 0.52667
Time: 2018-07-14 23:44:45
TRAINING STATS: batch 62/486 in epoch 233,   batch loss: 1.68584, batch accuracy: 0.53533
Time: 2018-07-14 23:44:50
TRAINING STATS: batch 112/486 in epoch 233,  batch loss: 1.82049, batch accuracy: 0.51067
Time: 2018-07-14 23:44:54
TRAINING STATS: batch 162/486 in epoch 233,  batch loss: 1.80435, batch accuracy: 0.50867
Time: 2018-07-14 23:44:57
TRAINING STATS: batch 212/486 in epoch 233,  batch loss: 1.52545, batch accuracy: 0.58633
Time: 2018-07-14 23:45:02
TRAINING STATS: batch 262/486 in epoch 233,  batch loss: 1.61191, batch accuracy: 0.56383
Time: 2018-07-14 23:45:06
TRAINING STATS: batch 312/486 in epoch 233,  batch loss: 1.52584, batch accuracy: 0.58500
Time: 2018-07-14 23:45:10
TRAINING STATS: batch 362/486 in epoch 233,  batch loss: 1.54756, batch accuracy: 0.58233
Time: 2018-07-14 23:45:14
TRAINING STATS: batch 412/486 in epoch 233,  batch loss: 1.50887, batch accuracy: 0.59433
Time: 2018-07-14 23:45:18
TRAINING STATS: batch 462/486 in epoch 233,  batch loss: 1.55604, batch accuracy: 0.57367
Time: 2018-07-14 23:45:22
TRAINING STATS: batch 26/486 in epoch 234,   batch loss: 1.56784, batch accuracy: 0.56883
Time: 2018-07-14 23:45:26
TRAINING STATS: batch 76/486 in epoch 234,   batch loss: 1.58042, batch accuracy: 0.57050
Time: 2018-07-14 23:45:30
TRAINING STATS: batch 126/486 in epoch 234,  batch loss: 1.58750, batch accuracy: 0.56933
Time: 2018-07-14 23:45:34
TRAINING STATS: batch 176/486 in epoch 234,  batch loss: 1.43039, batch accuracy: 0.61283
Time: 2018-07-14 23:45:39
TRAINING STATS: batch 226/486 in epoch 234,  batch loss: 1.53489, batch accuracy: 0.58617
Time: 2018-07-14 23:45:42
TRAINING STATS: batch 276/486 in epoch 234,  batch loss: 1.51726, batch accuracy: 0.58383
Time: 2018-07-14 23:45:46
TRAINING STATS: batch 326/486 in epoch 234,  batch loss: 1.53175, batch accuracy: 0.58367
Time: 2018-07-14 23:45:51
TRAINING STATS: batch 376/486 in epoch 234,  batch loss: 1.64745, batch accuracy: 0.55100
Time: 2018-07-14 23:45:54
TRAINING STATS: batch 426/486 in epoch 234,  batch loss: 1.53823, batch accuracy: 0.57650
Time: 2018-07-14 23:45:58
TRAINING STATS: batch 476/486 in epoch 234,  batch loss: 1.51401, batch accuracy: 0.58483
Time: 2018-07-14 23:46:03
TRAINING STATS: batch 40/486 in epoch 235,   batch loss: 1.54421, batch accuracy: 0.58383
Time: 2018-07-14 23:46:07
TRAINING STATS: batch 90/486 in epoch 235,   batch loss: 1.59792, batch accuracy: 0.56567
Time: 2018-07-14 23:46:10
TRAINING STATS: batch 140/486 in epoch 235,  batch loss: 1.46316, batch accuracy: 0.59983
Time: 2018-07-14 23:46:15
TRAINING STATS: batch 190/486 in epoch 235,  batch loss: 1.62695, batch accuracy: 0.55983
Time: 2018-07-14 23:46:19
TRAINING STATS: batch 240/486 in epoch 235,  batch loss: 1.59047, batch accuracy: 0.56167
Time: 2018-07-14 23:46:22
TRAINING STATS: batch 290/486 in epoch 235,  batch loss: 1.65469, batch accuracy: 0.54767
Time: 2018-07-14 23:46:27
TRAINING STATS: batch 340/486 in epoch 235,  batch loss: 1.60545, batch accuracy: 0.56000
Time: 2018-07-14 23:46:31
TRAINING STATS: batch 390/486 in epoch 235,  batch loss: 1.44577, batch accuracy: 0.60833
Time: 2018-07-14 23:46:35
TRAINING STATS: batch 440/486 in epoch 235,  batch loss: 1.51397, batch accuracy: 0.58300
Time: 2018-07-14 23:46:39
TRAINING STATS: batch 4/486 in epoch 236,    batch loss: 1.46875, batch accuracy: 0.60567
Time: 2018-07-14 23:46:43
TRAINING STATS: batch 54/486 in epoch 236,   batch loss: 1.51018, batch accuracy: 0.58833
Time: 2018-07-14 23:46:47
TRAINING STATS: batch 104/486 in epoch 236,  batch loss: 1.47451, batch accuracy: 0.60317
Time: 2018-07-14 23:46:51
TRAINING STATS: batch 154/486 in epoch 236,  batch loss: 1.44075, batch accuracy: 0.61183
Time: 2018-07-14 23:46:55
TRAINING STATS: batch 204/486 in epoch 236,  batch loss: 1.56999, batch accuracy: 0.57900
Time: 2018-07-14 23:46:59
TRAINING STATS: batch 254/486 in epoch 236,  batch loss: 1.38746, batch accuracy: 0.61900
Time: 2018-07-14 23:47:04
TRAINING STATS: batch 304/486 in epoch 236,  batch loss: 1.40593, batch accuracy: 0.62067
Time: 2018-07-14 23:47:07
TRAINING STATS: batch 354/486 in epoch 236,  batch loss: 1.46383, batch accuracy: 0.60383
Time: 2018-07-14 23:47:11
TRAINING STATS: batch 404/486 in epoch 236,  batch loss: 1.43022, batch accuracy: 0.61283
Time: 2018-07-14 23:47:16
TRAINING STATS: batch 454/486 in epoch 236,  batch loss: 1.26755, batch accuracy: 0.65500
Time: 2018-07-14 23:47:20
TRAINING STATS: batch 18/486 in epoch 237,   batch loss: 1.46059, batch accuracy: 0.60567
Time: 2018-07-14 23:47:23
TRAINING STATS: batch 68/486 in epoch 237,   batch loss: 1.27005, batch accuracy: 0.65217
Time: 2018-07-14 23:47:28
TRAINING STATS: batch 118/486 in epoch 237,  batch loss: 1.45404, batch accuracy: 0.60733
Time: 2018-07-14 23:47:32
TRAINING STATS: batch 168/486 in epoch 237,  batch loss: 1.36400, batch accuracy: 0.63517
Time: 2018-07-14 23:47:35
TRAINING STATS: batch 218/486 in epoch 237,  batch loss: 1.42708, batch accuracy: 0.61350
Time: 2018-07-14 23:47:40
TRAINING STATS: batch 268/486 in epoch 237,  batch loss: 1.41747, batch accuracy: 0.61567
Time: 2018-07-14 23:47:44
TRAINING STATS: batch 318/486 in epoch 237,  batch loss: 1.44747, batch accuracy: 0.59867
Time: 2018-07-14 23:47:48
TRAINING STATS: batch 368/486 in epoch 237,  batch loss: 1.44766, batch accuracy: 0.60183
Time: 2018-07-14 23:47:52
TRAINING STATS: batch 418/486 in epoch 237,  batch loss: 1.49416, batch accuracy: 0.59317
Time: 2018-07-14 23:47:56
TRAINING STATS: batch 468/486 in epoch 237,  batch loss: 2.68337, batch accuracy: 0.22717
Time: 2018-07-14 23:48:00
TRAINING STATS: batch 32/486 in epoch 238,   batch loss: 2.81219, batch accuracy: 0.17917
Time: 2018-07-14 23:48:04
TRAINING STATS: batch 82/486 in epoch 238,   batch loss: 2.88898, batch accuracy: 0.15733
Time: 2018-07-14 23:48:08
TRAINING STATS: batch 132/486 in epoch 238,  batch loss: 2.79178, batch accuracy: 0.18417
Time: 2018-07-14 23:48:12
TRAINING STATS: batch 182/486 in epoch 238,  batch loss: 2.77421, batch accuracy: 0.19267
Time: 2018-07-14 23:48:16
TRAINING STATS: batch 232/486 in epoch 238,  batch loss: 2.71500, batch accuracy: 0.21183
Time: 2018-07-14 23:48:20
TRAINING STATS: batch 282/486 in epoch 238,  batch loss: 2.64489, batch accuracy: 0.23600
Time: 2018-07-14 23:48:24
TRAINING STATS: batch 332/486 in epoch 238,  batch loss: 2.65060, batch accuracy: 0.24000
Time: 2018-07-14 23:48:29
TRAINING STATS: batch 382/486 in epoch 238,  batch loss: 2.64469, batch accuracy: 0.23917
Time: 2018-07-14 23:48:32
TRAINING STATS: batch 432/486 in epoch 238,  batch loss: 2.58798, batch accuracy: 0.24217
Time: 2018-07-14 23:48:36
TRAINING STATS: batch 482/486 in epoch 238,  batch loss: 2.60703, batch accuracy: 0.24667
Time: 2018-07-14 23:48:41
TRAINING STATS: batch 46/486 in epoch 239,   batch loss: 2.56744, batch accuracy: 0.24933
Time: 2018-07-14 23:48:44
TRAINING STATS: batch 96/486 in epoch 239,   batch loss: 2.57722, batch accuracy: 0.24733
Time: 2018-07-14 23:48:48
TRAINING STATS: batch 146/486 in epoch 239,  batch loss: 2.56998, batch accuracy: 0.25733
Time: 2018-07-14 23:48:53
TRAINING STATS: batch 196/486 in epoch 239,  batch loss: 2.55487, batch accuracy: 0.25233
Time: 2018-07-14 23:48:57
TRAINING STATS: batch 246/486 in epoch 239,  batch loss: 2.52328, batch accuracy: 0.25067
Time: 2018-07-14 23:49:00
TRAINING STATS: batch 296/486 in epoch 239,  batch loss: 2.50403, batch accuracy: 0.25833
Time: 2018-07-14 23:49:05
TRAINING STATS: batch 346/486 in epoch 239,  batch loss: 2.48513, batch accuracy: 0.26400
Time: 2018-07-14 23:49:09
TRAINING STATS: batch 396/486 in epoch 239,  batch loss: 2.48411, batch accuracy: 0.27200
Time: 2018-07-14 23:49:12
TRAINING STATS: batch 446/486 in epoch 239,  batch loss: 2.49245, batch accuracy: 0.27383
Time: 2018-07-14 23:49:17
TRAINING STATS: batch 10/486 in epoch 240,   batch loss: 2.49679, batch accuracy: 0.27883
Time: 2018-07-14 23:49:21
TRAINING STATS: batch 60/486 in epoch 240,   batch loss: 2.43537, batch accuracy: 0.27983
Time: 2018-07-14 23:49:24
TRAINING STATS: batch 110/486 in epoch 240,  batch loss: 2.65515, batch accuracy: 0.21633
Time: 2018-07-14 23:49:29
TRAINING STATS: batch 160/486 in epoch 240,  batch loss: 2.54099, batch accuracy: 0.23450
Time: 2018-07-14 23:49:33
TRAINING STATS: batch 210/486 in epoch 240,  batch loss: 2.46641, batch accuracy: 0.27183
Time: 2018-07-14 23:49:37
TRAINING STATS: batch 260/486 in epoch 240,  batch loss: 2.44687, batch accuracy: 0.29150
Time: 2018-07-14 23:49:41
TRAINING STATS: batch 310/486 in epoch 240,  batch loss: 2.38888, batch accuracy: 0.33783
Time: 2018-07-14 23:49:45
TRAINING STATS: batch 360/486 in epoch 240,  batch loss: 2.34634, batch accuracy: 0.36867
Time: 2018-07-14 23:49:49
TRAINING STATS: batch 410/486 in epoch 240,  batch loss: 2.25851, batch accuracy: 0.40117
Time: 2018-07-14 23:49:54
TRAINING STATS: batch 460/486 in epoch 240,  batch loss: 2.34886, batch accuracy: 0.36117
Time: 2018-07-14 23:49:57
TRAINING STATS: batch 24/486 in epoch 241,   batch loss: 2.27842, batch accuracy: 0.39200
Time: 2018-07-14 23:50:01
TRAINING STATS: batch 74/486 in epoch 241,   batch loss: 2.23201, batch accuracy: 0.40817
Time: 2018-07-14 23:50:06
TRAINING STATS: batch 124/486 in epoch 241,  batch loss: 2.20345, batch accuracy: 0.41850
Time: 2018-07-14 23:50:09
TRAINING STATS: batch 174/486 in epoch 241,  batch loss: 2.19708, batch accuracy: 0.41750
Time: 2018-07-14 23:50:13
TRAINING STATS: batch 224/486 in epoch 241,  batch loss: 2.17681, batch accuracy: 0.42750
Time: 2018-07-14 23:50:18
TRAINING STATS: batch 274/486 in epoch 241,  batch loss: 2.13530, batch accuracy: 0.43333
Time: 2018-07-14 23:50:21
TRAINING STATS: batch 324/486 in epoch 241,  batch loss: 2.15425, batch accuracy: 0.42600
Time: 2018-07-14 23:50:25
TRAINING STATS: batch 374/486 in epoch 241,  batch loss: 2.10259, batch accuracy: 0.44300
Time: 2018-07-14 23:50:30
TRAINING STATS: batch 424/486 in epoch 241,  batch loss: 2.01133, batch accuracy: 0.46233
Time: 2018-07-14 23:50:34
TRAINING STATS: batch 474/486 in epoch 241,  batch loss: 2.02721, batch accuracy: 0.45433
Time: 2018-07-14 23:50:37
TRAINING STATS: batch 38/486 in epoch 242,   batch loss: 2.00872, batch accuracy: 0.46300
Time: 2018-07-14 23:50:42
TRAINING STATS: batch 88/486 in epoch 242,   batch loss: 2.07669, batch accuracy: 0.43217
Time: 2018-07-14 23:50:46
TRAINING STATS: batch 138/486 in epoch 242,  batch loss: 2.04125, batch accuracy: 0.45367
Time: 2018-07-14 23:50:50
TRAINING STATS: batch 188/486 in epoch 242,  batch loss: 2.04134, batch accuracy: 0.44600
Time: 2018-07-14 23:50:54
TRAINING STATS: batch 238/486 in epoch 242,  batch loss: 2.09280, batch accuracy: 0.43650
Time: 2018-07-14 23:50:58
TRAINING STATS: batch 288/486 in epoch 242,  batch loss: 2.14402, batch accuracy: 0.41483
Time: 2018-07-14 23:51:02
TRAINING STATS: batch 338/486 in epoch 242,  batch loss: 2.10439, batch accuracy: 0.42983
Time: 2018-07-14 23:51:06
TRAINING STATS: batch 388/486 in epoch 242,  batch loss: 2.04000, batch accuracy: 0.45000
Time: 2018-07-14 23:51:10
TRAINING STATS: batch 438/486 in epoch 242,  batch loss: 2.06430, batch accuracy: 0.45050
Time: 2018-07-14 23:51:14
TRAINING STATS: batch 2/486 in epoch 243,    batch loss: 1.97167, batch accuracy: 0.47567
Time: 2018-07-14 23:51:19
TRAINING STATS: batch 52/486 in epoch 243,   batch loss: 1.96124, batch accuracy: 0.47150
Time: 2018-07-14 23:51:22
TRAINING STATS: batch 102/486 in epoch 243,  batch loss: 1.92787, batch accuracy: 0.48550
Time: 2018-07-14 23:51:26
TRAINING STATS: batch 152/486 in epoch 243,  batch loss: 1.80983, batch accuracy: 0.51417
Time: 2018-07-14 23:51:31
TRAINING STATS: batch 202/486 in epoch 243,  batch loss: 1.83110, batch accuracy: 0.51167
Time: 2018-07-14 23:51:34
TRAINING STATS: batch 252/486 in epoch 243,  batch loss: 1.74987, batch accuracy: 0.52217
Time: 2018-07-14 23:51:38
TRAINING STATS: batch 302/486 in epoch 243,  batch loss: 1.78992, batch accuracy: 0.51150
Time: 2018-07-14 23:51:43
TRAINING STATS: batch 352/486 in epoch 243,  batch loss: 2.05348, batch accuracy: 0.44567
Time: 2018-07-14 23:51:46
TRAINING STATS: batch 402/486 in epoch 243,  batch loss: 1.97457, batch accuracy: 0.46850
Time: 2018-07-14 23:51:50
TRAINING STATS: batch 452/486 in epoch 243,  batch loss: 1.98922, batch accuracy: 0.45833
Time: 2018-07-14 23:51:55
TRAINING STATS: batch 16/486 in epoch 244,   batch loss: 1.88337, batch accuracy: 0.49467
Time: 2018-07-14 23:51:59
TRAINING STATS: batch 66/486 in epoch 244,   batch loss: 1.84305, batch accuracy: 0.50283
Time: 2018-07-14 23:52:02
TRAINING STATS: batch 116/486 in epoch 244,  batch loss: 1.78184, batch accuracy: 0.51767
Time: 2018-07-14 23:52:07
TRAINING STATS: batch 166/486 in epoch 244,  batch loss: 1.71554, batch accuracy: 0.53683
Time: 2018-07-14 23:52:11
TRAINING STATS: batch 216/486 in epoch 244,  batch loss: 1.90184, batch accuracy: 0.48500
Time: 2018-07-14 23:52:14
TRAINING STATS: batch 266/486 in epoch 244,  batch loss: 1.87776, batch accuracy: 0.49467
Time: 2018-07-14 23:52:19
TRAINING STATS: batch 316/486 in epoch 244,  batch loss: 1.78637, batch accuracy: 0.51367
Time: 2018-07-14 23:52:23
TRAINING STATS: batch 366/486 in epoch 244,  batch loss: 1.85733, batch accuracy: 0.49233
Time: 2018-07-14 23:52:27
TRAINING STATS: batch 416/486 in epoch 244,  batch loss: 1.86247, batch accuracy: 0.49300
Time: 2018-07-14 23:52:31
TRAINING STATS: batch 466/486 in epoch 244,  batch loss: 1.63445, batch accuracy: 0.55767
Time: 2018-07-14 23:52:35
TRAINING STATS: batch 30/486 in epoch 245,   batch loss: 1.63259, batch accuracy: 0.55700
Time: 2018-07-14 23:52:39
TRAINING STATS: batch 80/486 in epoch 245,   batch loss: 1.74116, batch accuracy: 0.52167
Time: 2018-07-14 23:52:44
TRAINING STATS: batch 130/486 in epoch 245,  batch loss: 1.71302, batch accuracy: 0.53717
Time: 2018-07-14 23:52:47
TRAINING STATS: batch 180/486 in epoch 245,  batch loss: 1.77867, batch accuracy: 0.50900
Time: 2018-07-14 23:52:51
TRAINING STATS: batch 230/486 in epoch 245,  batch loss: 1.73640, batch accuracy: 0.52267
Time: 2018-07-14 23:52:56
TRAINING STATS: batch 280/486 in epoch 245,  batch loss: 1.79512, batch accuracy: 0.50367
Time: 2018-07-14 23:52:59
TRAINING STATS: batch 330/486 in epoch 245,  batch loss: 1.87884, batch accuracy: 0.48900
Time: 2018-07-14 23:53:03
TRAINING STATS: batch 380/486 in epoch 245,  batch loss: 1.75998, batch accuracy: 0.52567
Time: 2018-07-14 23:53:08
TRAINING STATS: batch 430/486 in epoch 245,  batch loss: 1.63483, batch accuracy: 0.55500
Time: 2018-07-14 23:53:11
TRAINING STATS: batch 480/486 in epoch 245,  batch loss: 1.77430, batch accuracy: 0.52000
Time: 2018-07-14 23:53:15
TRAINING STATS: batch 44/486 in epoch 246,   batch loss: 1.64122, batch accuracy: 0.55233
Time: 2018-07-14 23:53:20
TRAINING STATS: batch 94/486 in epoch 246,   batch loss: 1.75638, batch accuracy: 0.52817
Time: 2018-07-14 23:53:24
TRAINING STATS: batch 144/486 in epoch 246,  batch loss: 1.78929, batch accuracy: 0.50450
Time: 2018-07-14 23:53:27
TRAINING STATS: batch 194/486 in epoch 246,  batch loss: 1.84117, batch accuracy: 0.49150
Time: 2018-07-14 23:53:32
TRAINING STATS: batch 244/486 in epoch 246,  batch loss: 1.67413, batch accuracy: 0.54300
Time: 2018-07-14 23:53:36
TRAINING STATS: batch 294/486 in epoch 246,  batch loss: 1.61303, batch accuracy: 0.55767
Time: 2018-07-14 23:53:39
TRAINING STATS: batch 344/486 in epoch 246,  batch loss: 1.66029, batch accuracy: 0.54467
Time: 2018-07-14 23:53:44
TRAINING STATS: batch 394/486 in epoch 246,  batch loss: 1.78510, batch accuracy: 0.52667
Time: 2018-07-14 23:53:48
TRAINING STATS: batch 444/486 in epoch 246,  batch loss: 1.75638, batch accuracy: 0.53300
Time: 2018-07-14 23:53:51
TRAINING STATS: batch 8/486 in epoch 247,    batch loss: 1.88161, batch accuracy: 0.49600
Time: 2018-07-14 23:53:56
TRAINING STATS: batch 58/486 in epoch 247,   batch loss: 1.74488, batch accuracy: 0.53183
Time: 2018-07-14 23:54:00
TRAINING STATS: batch 108/486 in epoch 247,  batch loss: 1.81171, batch accuracy: 0.51983
Time: 2018-07-14 23:54:04
TRAINING STATS: batch 158/486 in epoch 247,  batch loss: 1.74625, batch accuracy: 0.52667
Time: 2018-07-14 23:54:08
TRAINING STATS: batch 208/486 in epoch 247,  batch loss: 1.71634, batch accuracy: 0.52850
Time: 2018-07-14 23:54:12
TRAINING STATS: batch 258/486 in epoch 247,  batch loss: 1.62787, batch accuracy: 0.55467
Time: 2018-07-14 23:54:16
TRAINING STATS: batch 308/486 in epoch 247,  batch loss: 1.69060, batch accuracy: 0.54333
Time: 2018-07-14 23:54:20
TRAINING STATS: batch 358/486 in epoch 247,  batch loss: 1.74439, batch accuracy: 0.52067
Time: 2018-07-14 23:54:24
TRAINING STATS: batch 408/486 in epoch 247,  batch loss: 1.85334, batch accuracy: 0.49417
Time: 2018-07-14 23:54:28
TRAINING STATS: batch 458/486 in epoch 247,  batch loss: 1.74481, batch accuracy: 0.52800
Time: 2018-07-14 23:54:33
TRAINING STATS: batch 22/486 in epoch 248,   batch loss: 1.79576, batch accuracy: 0.51283
Time: 2018-07-14 23:54:36
TRAINING STATS: batch 72/486 in epoch 248,   batch loss: 1.78303, batch accuracy: 0.51050
Time: 2018-07-14 23:54:40
TRAINING STATS: batch 122/486 in epoch 248,  batch loss: 1.64002, batch accuracy: 0.55400
Time: 2018-07-14 23:54:45
TRAINING STATS: batch 172/486 in epoch 248,  batch loss: 2.36058, batch accuracy: 0.33550
Time: 2018-07-14 23:54:48
TRAINING STATS: batch 222/486 in epoch 248,  batch loss: 2.00945, batch accuracy: 0.46333
Time: 2018-07-14 23:54:52
TRAINING STATS: batch 272/486 in epoch 248,  batch loss: 2.03909, batch accuracy: 0.44700
Time: 2018-07-14 23:54:57
TRAINING STATS: batch 322/486 in epoch 248,  batch loss: 1.96563, batch accuracy: 0.46867
Time: 2018-07-14 23:55:00
TRAINING STATS: batch 372/486 in epoch 248,  batch loss: 1.83730, batch accuracy: 0.50783
Time: 2018-07-14 23:55:04
TRAINING STATS: batch 422/486 in epoch 248,  batch loss: 1.74588, batch accuracy: 0.52950
Time: 2018-07-14 23:55:09
TRAINING STATS: batch 472/486 in epoch 248,  batch loss: 1.79422, batch accuracy: 0.50767
Time: 2018-07-14 23:55:13
TRAINING STATS: batch 36/486 in epoch 249,   batch loss: 1.78105, batch accuracy: 0.51967
Time: 2018-07-14 23:55:16
TRAINING STATS: batch 86/486 in epoch 249,   batch loss: 1.69800, batch accuracy: 0.54000
Time: 2018-07-14 23:55:21
TRAINING STATS: batch 136/486 in epoch 249,  batch loss: 1.75030, batch accuracy: 0.52383
Time: 2018-07-14 23:55:25
TRAINING STATS: batch 186/486 in epoch 249,  batch loss: 1.69726, batch accuracy: 0.54150
Time: 2018-07-14 23:55:28
TRAINING STATS: batch 236/486 in epoch 249,  batch loss: 1.76002, batch accuracy: 0.52217
Time: 2018-07-14 23:55:33
TRAINING STATS: batch 286/486 in epoch 249,  batch loss: 1.73728, batch accuracy: 0.52500
Time: 2018-07-14 23:55:37
TRAINING STATS: batch 336/486 in epoch 249,  batch loss: 1.65552, batch accuracy: 0.54450
Time: 2018-07-14 23:55:40
TRAINING STATS: batch 386/486 in epoch 249,  batch loss: 1.70669, batch accuracy: 0.54050
Time: 2018-07-14 23:55:45
TRAINING STATS: batch 436/486 in epoch 249,  batch loss: 1.64600, batch accuracy: 0.55933
Time: 2018-07-14 23:55:49
TRAINING STATS: batch 0/486 in epoch 250,    batch loss: 1.62668, batch accuracy: 0.55750
Time: 2018-07-14 23:55:53
TRAINING STATS: batch 50/486 in epoch 250,   batch loss: 1.71003, batch accuracy: 0.54500
Time: 2018-07-14 23:55:57
TRAINING STATS: batch 100/486 in epoch 250,  batch loss: 1.69908, batch accuracy: 0.54133
Time: 2018-07-14 23:56:01
TRAINING STATS: batch 150/486 in epoch 250,  batch loss: 1.69258, batch accuracy: 0.54300
Time: 2018-07-14 23:56:05
TRAINING STATS: batch 200/486 in epoch 250,  batch loss: 1.53686, batch accuracy: 0.59083
Time: 2018-07-14 23:56:09
TRAINING STATS: batch 250/486 in epoch 250,  batch loss: 1.70144, batch accuracy: 0.53550
Time: 2018-07-14 23:56:13
TRAINING STATS: batch 300/486 in epoch 250,  batch loss: 1.67086, batch accuracy: 0.53767
Time: 2018-07-14 23:56:17
TRAINING STATS: batch 350/486 in epoch 250,  batch loss: 1.70179, batch accuracy: 0.54333
Time: 2018-07-14 23:56:21
TRAINING STATS: batch 400/486 in epoch 250,  batch loss: 1.51328, batch accuracy: 0.59067
Time: 2018-07-14 23:56:25
TRAINING STATS: batch 450/486 in epoch 250,  batch loss: 1.72417, batch accuracy: 0.52133
Time: 2018-07-14 23:56:29
TRAINING STATS: batch 14/486 in epoch 251,   batch loss: 1.58749, batch accuracy: 0.56783
Time: 2018-07-14 23:56:34
TRAINING STATS: batch 64/486 in epoch 251,   batch loss: 1.76174, batch accuracy: 0.51883
Time: 2018-07-14 23:56:37
TRAINING STATS: batch 114/486 in epoch 251,  batch loss: 1.65912, batch accuracy: 0.54183
Time: 2018-07-14 23:56:41
TRAINING STATS: batch 164/486 in epoch 251,  batch loss: 1.56127, batch accuracy: 0.57600
Time: 2018-07-14 23:56:46
TRAINING STATS: batch 214/486 in epoch 251,  batch loss: 1.63379, batch accuracy: 0.56150
Time: 2018-07-14 23:56:49
TRAINING STATS: batch 264/486 in epoch 251,  batch loss: 1.64856, batch accuracy: 0.55050
Time: 2018-07-14 23:56:53
TRAINING STATS: batch 314/486 in epoch 251,  batch loss: 1.71577, batch accuracy: 0.53250
Time: 2018-07-14 23:56:58
TRAINING STATS: batch 364/486 in epoch 251,  batch loss: 1.60045, batch accuracy: 0.56517
Time: 2018-07-14 23:57:01
TRAINING STATS: batch 414/486 in epoch 251,  batch loss: 1.57117, batch accuracy: 0.56867
Time: 2018-07-14 23:57:05
TRAINING STATS: batch 464/486 in epoch 251,  batch loss: 1.62887, batch accuracy: 0.55333
Time: 2018-07-14 23:57:10
TRAINING STATS: batch 28/486 in epoch 252,   batch loss: 1.77010, batch accuracy: 0.50983
Time: 2018-07-14 23:57:14
TRAINING STATS: batch 78/486 in epoch 252,   batch loss: 1.70263, batch accuracy: 0.54700
Time: 2018-07-14 23:57:17
TRAINING STATS: batch 128/486 in epoch 252,  batch loss: 1.76492, batch accuracy: 0.51550
Time: 2018-07-14 23:57:22
TRAINING STATS: batch 178/486 in epoch 252,  batch loss: 1.65415, batch accuracy: 0.55000
Time: 2018-07-14 23:57:26
TRAINING STATS: batch 228/486 in epoch 252,  batch loss: 1.70568, batch accuracy: 0.53533
Time: 2018-07-14 23:57:30
TRAINING STATS: batch 278/486 in epoch 252,  batch loss: 1.56969, batch accuracy: 0.57433
Time: 2018-07-14 23:57:34
TRAINING STATS: batch 328/486 in epoch 252,  batch loss: 1.63605, batch accuracy: 0.55600
Time: 2018-07-14 23:57:38
TRAINING STATS: batch 378/486 in epoch 252,  batch loss: 1.66072, batch accuracy: 0.55283
Time: 2018-07-14 23:57:42
TRAINING STATS: batch 428/486 in epoch 252,  batch loss: 1.68080, batch accuracy: 0.54433
Time: 2018-07-14 23:57:46
TRAINING STATS: batch 478/486 in epoch 252,  batch loss: 1.66532, batch accuracy: 0.55217
Time: 2018-07-14 23:57:50
TRAINING STATS: batch 42/486 in epoch 253,   batch loss: 1.52507, batch accuracy: 0.58083
Time: 2018-07-14 23:57:54
TRAINING STATS: batch 92/486 in epoch 253,   batch loss: 1.66345, batch accuracy: 0.54900
Time: 2018-07-14 23:57:59
TRAINING STATS: batch 142/486 in epoch 253,  batch loss: 1.62521, batch accuracy: 0.56017
Time: 2018-07-14 23:58:02
TRAINING STATS: batch 192/486 in epoch 253,  batch loss: 1.75687, batch accuracy: 0.51850
Time: 2018-07-14 23:58:06
TRAINING STATS: batch 242/486 in epoch 253,  batch loss: 1.89086, batch accuracy: 0.49350
Time: 2018-07-14 23:58:11
TRAINING STATS: batch 292/486 in epoch 253,  batch loss: 2.57632, batch accuracy: 0.26700
Time: 2018-07-14 23:58:14
TRAINING STATS: batch 342/486 in epoch 253,  batch loss: 2.16225, batch accuracy: 0.41133
Time: 2018-07-14 23:58:18
TRAINING STATS: batch 392/486 in epoch 253,  batch loss: 1.93161, batch accuracy: 0.49150
Time: 2018-07-14 23:58:23
TRAINING STATS: batch 442/486 in epoch 253,  batch loss: 1.86140, batch accuracy: 0.50833
Time: 2018-07-14 23:58:26
TRAINING STATS: batch 6/486 in epoch 254,    batch loss: 1.96506, batch accuracy: 0.47667
Time: 2018-07-14 23:58:30
TRAINING STATS: batch 56/486 in epoch 254,   batch loss: 1.88065, batch accuracy: 0.49933
Time: 2018-07-14 23:58:35
TRAINING STATS: batch 106/486 in epoch 254,  batch loss: 1.81653, batch accuracy: 0.50650
Time: 2018-07-14 23:58:39
TRAINING STATS: batch 156/486 in epoch 254,  batch loss: 1.73305, batch accuracy: 0.52467
Time: 2018-07-14 23:58:42
TRAINING STATS: batch 206/486 in epoch 254,  batch loss: 1.82839, batch accuracy: 0.50300
Time: 2018-07-14 23:58:47
TRAINING STATS: batch 256/486 in epoch 254,  batch loss: 1.65439, batch accuracy: 0.54750
Time: 2018-07-14 23:58:51
TRAINING STATS: batch 306/486 in epoch 254,  batch loss: 1.73781, batch accuracy: 0.53450
Time: 2018-07-14 23:58:54
TRAINING STATS: batch 356/486 in epoch 254,  batch loss: 1.73939, batch accuracy: 0.52717
Time: 2018-07-14 23:58:59
TRAINING STATS: batch 406/486 in epoch 254,  batch loss: 1.78182, batch accuracy: 0.51317
Time: 2018-07-14 23:59:03
TRAINING STATS: batch 456/486 in epoch 254,  batch loss: 1.55273, batch accuracy: 0.58300
Time: 2018-07-14 23:59:07
TRAINING STATS: batch 20/486 in epoch 255,   batch loss: 1.63967, batch accuracy: 0.55167
Time: 2018-07-14 23:59:11
TRAINING STATS: batch 70/486 in epoch 255,   batch loss: 1.52547, batch accuracy: 0.58417
Time: 2018-07-14 23:59:15
TRAINING STATS: batch 120/486 in epoch 255,  batch loss: 1.58647, batch accuracy: 0.56217
Time: 2018-07-14 23:59:19
TRAINING STATS: batch 170/486 in epoch 255,  batch loss: 1.61112, batch accuracy: 0.55900
Time: 2018-07-14 23:59:24
TRAINING STATS: batch 220/486 in epoch 255,  batch loss: 1.52060, batch accuracy: 0.58867
Time: 2018-07-14 23:59:27
TRAINING STATS: batch 270/486 in epoch 255,  batch loss: 1.60108, batch accuracy: 0.55167
Time: 2018-07-14 23:59:31
TRAINING STATS: batch 320/486 in epoch 255,  batch loss: 1.53138, batch accuracy: 0.57600
Time: 2018-07-14 23:59:36
TRAINING STATS: batch 370/486 in epoch 255,  batch loss: 1.57622, batch accuracy: 0.56583
Time: 2018-07-14 23:59:39
TRAINING STATS: batch 420/486 in epoch 255,  batch loss: 1.63676, batch accuracy: 0.55083
Time: 2018-07-14 23:59:43
TRAINING STATS: batch 470/486 in epoch 255,  batch loss: 1.69505, batch accuracy: 0.53200
Time: 2018-07-14 23:59:48
TRAINING STATS: batch 34/486 in epoch 256,   batch loss: 1.61978, batch accuracy: 0.55450
Time: 2018-07-14 23:59:51
TRAINING STATS: batch 84/486 in epoch 256,   batch loss: 1.58415, batch accuracy: 0.56083
Time: 2018-07-14 23:59:55
TRAINING STATS: batch 134/486 in epoch 256,  batch loss: 1.58060, batch accuracy: 0.57367
Time: 2018-07-15 00:00:00
TRAINING STATS: batch 184/486 in epoch 256,  batch loss: 1.59646, batch accuracy: 0.55650
Time: 2018-07-15 00:00:04
TRAINING STATS: batch 234/486 in epoch 256,  batch loss: 1.66436, batch accuracy: 0.53933
Time: 2018-07-15 00:00:07
TRAINING STATS: batch 284/486 in epoch 256,  batch loss: 1.66759, batch accuracy: 0.54800
Time: 2018-07-15 00:00:12
TRAINING STATS: batch 334/486 in epoch 256,  batch loss: 1.57217, batch accuracy: 0.57633
Time: 2018-07-15 00:00:16
TRAINING STATS: batch 384/486 in epoch 256,  batch loss: 1.59191, batch accuracy: 0.56783
Time: 2018-07-15 00:00:19
TRAINING STATS: batch 434/486 in epoch 256,  batch loss: 1.69607, batch accuracy: 0.54233
Time: 2018-07-15 00:00:24
TRAINING STATS: batch 484/486 in epoch 256,  batch loss: 1.68832, batch accuracy: 0.53300
Time: 2018-07-15 00:00:28
TRAINING STATS: batch 48/486 in epoch 257,   batch loss: 1.71728, batch accuracy: 0.51733
Time: 2018-07-15 00:00:31
TRAINING STATS: batch 98/486 in epoch 257,   batch loss: 1.71466, batch accuracy: 0.52800
Time: 2018-07-15 00:00:36
TRAINING STATS: batch 148/486 in epoch 257,  batch loss: 1.69470, batch accuracy: 0.55133
Time: 2018-07-15 00:00:40
TRAINING STATS: batch 198/486 in epoch 257,  batch loss: 1.69622, batch accuracy: 0.53667
Time: 2018-07-15 00:00:44
TRAINING STATS: batch 248/486 in epoch 257,  batch loss: 1.78609, batch accuracy: 0.51400
Time: 2018-07-15 00:00:48
TRAINING STATS: batch 298/486 in epoch 257,  batch loss: 1.81892, batch accuracy: 0.50850
Time: 2018-07-15 00:00:52
TRAINING STATS: batch 348/486 in epoch 257,  batch loss: 1.80402, batch accuracy: 0.52750
Time: 2018-07-15 00:00:56
TRAINING STATS: batch 398/486 in epoch 257,  batch loss: 1.95207, batch accuracy: 0.46533
Time: 2018-07-15 00:01:01
TRAINING STATS: batch 448/486 in epoch 257,  batch loss: 2.51147, batch accuracy: 0.29400
Time: 2018-07-15 00:01:04
TRAINING STATS: batch 12/486 in epoch 258,   batch loss: 2.39993, batch accuracy: 0.33050
Time: 2018-07-15 00:01:08
TRAINING STATS: batch 62/486 in epoch 258,   batch loss: 2.62285, batch accuracy: 0.26283
Time: 2018-07-15 00:01:13
TRAINING STATS: batch 112/486 in epoch 258,  batch loss: 2.52372, batch accuracy: 0.28200
Time: 2018-07-15 00:01:16
TRAINING STATS: batch 162/486 in epoch 258,  batch loss: 2.28269, batch accuracy: 0.38433
Time: 2018-07-15 00:01:20
TRAINING STATS: batch 212/486 in epoch 258,  batch loss: 1.94709, batch accuracy: 0.48583
Time: 2018-07-15 00:01:25
TRAINING STATS: batch 262/486 in epoch 258,  batch loss: 1.92760, batch accuracy: 0.47900
Time: 2018-07-15 00:01:28
TRAINING STATS: batch 312/486 in epoch 258,  batch loss: 1.85552, batch accuracy: 0.49733
Time: 2018-07-15 00:01:32
TRAINING STATS: batch 362/486 in epoch 258,  batch loss: 1.77606, batch accuracy: 0.51750
Time: 2018-07-15 00:01:37
TRAINING STATS: batch 412/486 in epoch 258,  batch loss: 1.71334, batch accuracy: 0.54367
Time: 2018-07-15 00:01:41
TRAINING STATS: batch 462/486 in epoch 258,  batch loss: 1.74561, batch accuracy: 0.53083
Time: 2018-07-15 00:01:44
TRAINING STATS: batch 26/486 in epoch 259,   batch loss: 1.88132, batch accuracy: 0.48217
Time: 2018-07-15 00:01:49
TRAINING STATS: batch 76/486 in epoch 259,   batch loss: 1.83087, batch accuracy: 0.50283
Time: 2018-07-15 00:01:53
TRAINING STATS: batch 126/486 in epoch 259,  batch loss: 1.72758, batch accuracy: 0.53283
Time: 2018-07-15 00:01:56
TRAINING STATS: batch 176/486 in epoch 259,  batch loss: 1.60074, batch accuracy: 0.56133
Time: 2018-07-15 00:02:01
TRAINING STATS: batch 226/486 in epoch 259,  batch loss: 1.65853, batch accuracy: 0.55667
Time: 2018-07-15 00:02:05
TRAINING STATS: batch 276/486 in epoch 259,  batch loss: 1.63361, batch accuracy: 0.55950
Time: 2018-07-15 00:02:09
TRAINING STATS: batch 326/486 in epoch 259,  batch loss: 1.66813, batch accuracy: 0.54217
Time: 2018-07-15 00:02:13
TRAINING STATS: batch 376/486 in epoch 259,  batch loss: 2.00922, batch accuracy: 0.45550
Time: 2018-07-15 00:02:17
TRAINING STATS: batch 426/486 in epoch 259,  batch loss: 1.83039, batch accuracy: 0.50567
Time: 2018-07-15 00:02:21
TRAINING STATS: batch 476/486 in epoch 259,  batch loss: 1.74484, batch accuracy: 0.53100
Time: 2018-07-15 00:02:26
TRAINING STATS: batch 40/486 in epoch 260,   batch loss: 1.64896, batch accuracy: 0.55000
Time: 2018-07-15 00:02:29
TRAINING STATS: batch 90/486 in epoch 260,   batch loss: 1.70763, batch accuracy: 0.52983
Time: 2018-07-15 00:02:33
TRAINING STATS: batch 140/486 in epoch 260,  batch loss: 1.56168, batch accuracy: 0.57033
Time: 2018-07-15 00:02:38
TRAINING STATS: batch 190/486 in epoch 260,  batch loss: 1.64383, batch accuracy: 0.55000
Time: 2018-07-15 00:02:41
TRAINING STATS: batch 240/486 in epoch 260,  batch loss: 1.60155, batch accuracy: 0.56033
Time: 2018-07-15 00:02:45
TRAINING STATS: batch 290/486 in epoch 260,  batch loss: 1.64030, batch accuracy: 0.55150
Time: 2018-07-15 00:02:50
TRAINING STATS: batch 340/486 in epoch 260,  batch loss: 1.68363, batch accuracy: 0.53550
Time: 2018-07-15 00:02:53
TRAINING STATS: batch 390/486 in epoch 260,  batch loss: 1.50692, batch accuracy: 0.58967
Time: 2018-07-15 00:02:57
TRAINING STATS: batch 440/486 in epoch 260,  batch loss: 1.59152, batch accuracy: 0.56667
Time: 2018-07-15 00:03:02
TRAINING STATS: batch 4/486 in epoch 261,    batch loss: 1.54205, batch accuracy: 0.58517
Time: 2018-07-15 00:03:05
TRAINING STATS: batch 54/486 in epoch 261,   batch loss: 1.59394, batch accuracy: 0.56250
Time: 2018-07-15 00:03:09
TRAINING STATS: batch 104/486 in epoch 261,  batch loss: 1.63214, batch accuracy: 0.56117
Time: 2018-07-15 00:03:14
TRAINING STATS: batch 154/486 in epoch 261,  batch loss: 1.56651, batch accuracy: 0.57483
Time: 2018-07-15 00:03:18
TRAINING STATS: batch 204/486 in epoch 261,  batch loss: 1.65000, batch accuracy: 0.55467
Time: 2018-07-15 00:03:21
TRAINING STATS: batch 254/486 in epoch 261,  batch loss: 1.58133, batch accuracy: 0.56883
Time: 2018-07-15 00:03:26
TRAINING STATS: batch 304/486 in epoch 261,  batch loss: 1.55790, batch accuracy: 0.57850
Time: 2018-07-15 00:03:30
TRAINING STATS: batch 354/486 in epoch 261,  batch loss: 1.59214, batch accuracy: 0.56367
Time: 2018-07-15 00:03:33
TRAINING STATS: batch 404/486 in epoch 261,  batch loss: 1.63141, batch accuracy: 0.55550
Time: 2018-07-15 00:03:38
TRAINING STATS: batch 454/486 in epoch 261,  batch loss: 1.47786, batch accuracy: 0.59517
Time: 2018-07-15 00:03:42
TRAINING STATS: batch 18/486 in epoch 262,   batch loss: 1.66555, batch accuracy: 0.55000
Time: 2018-07-15 00:03:46
TRAINING STATS: batch 68/486 in epoch 262,   batch loss: 1.48324, batch accuracy: 0.60117
Time: 2018-07-15 00:03:50
TRAINING STATS: batch 118/486 in epoch 262,  batch loss: 1.59306, batch accuracy: 0.56567
Time: 2018-07-15 00:03:54
TRAINING STATS: batch 168/486 in epoch 262,  batch loss: 1.50401, batch accuracy: 0.59083
Time: 2018-07-15 00:03:58
TRAINING STATS: batch 218/486 in epoch 262,  batch loss: 1.53221, batch accuracy: 0.58467
Time: 2018-07-15 00:04:02
TRAINING STATS: batch 268/486 in epoch 262,  batch loss: 1.55781, batch accuracy: 0.58050
Time: 2018-07-15 00:04:06
TRAINING STATS: batch 318/486 in epoch 262,  batch loss: 1.57062, batch accuracy: 0.56367
Time: 2018-07-15 00:04:10
TRAINING STATS: batch 368/486 in epoch 262,  batch loss: 1.57901, batch accuracy: 0.57200
Time: 2018-07-15 00:04:14
TRAINING STATS: batch 418/486 in epoch 262,  batch loss: 1.63892, batch accuracy: 0.55000
Time: 2018-07-15 00:04:18
TRAINING STATS: batch 468/486 in epoch 262,  batch loss: 1.55729, batch accuracy: 0.57250
Time: 2018-07-15 00:04:22
TRAINING STATS: batch 32/486 in epoch 263,   batch loss: 1.51022, batch accuracy: 0.58650
Time: 2018-07-15 00:04:27
TRAINING STATS: batch 82/486 in epoch 263,   batch loss: 1.60715, batch accuracy: 0.55100
Time: 2018-07-15 00:04:30
TRAINING STATS: batch 132/486 in epoch 263,  batch loss: 1.54765, batch accuracy: 0.57983
Time: 2018-07-15 00:04:34
TRAINING STATS: batch 182/486 in epoch 263,  batch loss: 1.63085, batch accuracy: 0.55333
Time: 2018-07-15 00:04:39
TRAINING STATS: batch 232/486 in epoch 263,  batch loss: 1.61292, batch accuracy: 0.56000
Time: 2018-07-15 00:04:42
TRAINING STATS: batch 282/486 in epoch 263,  batch loss: 1.49241, batch accuracy: 0.59367
Time: 2018-07-15 00:04:46
TRAINING STATS: batch 332/486 in epoch 263,  batch loss: 1.60070, batch accuracy: 0.56683
Time: 2018-07-15 00:04:51
TRAINING STATS: batch 382/486 in epoch 263,  batch loss: 1.61334, batch accuracy: 0.55517
Time: 2018-07-15 00:04:54
TRAINING STATS: batch 432/486 in epoch 263,  batch loss: 1.51119, batch accuracy: 0.58900
Time: 2018-07-15 00:04:58
TRAINING STATS: batch 482/486 in epoch 263,  batch loss: 1.55965, batch accuracy: 0.57683
Time: 2018-07-15 00:05:03
TRAINING STATS: batch 46/486 in epoch 264,   batch loss: 1.55234, batch accuracy: 0.57950
Time: 2018-07-15 00:05:07
TRAINING STATS: batch 96/486 in epoch 264,   batch loss: 1.61897, batch accuracy: 0.55933
Time: 2018-07-15 00:05:10
TRAINING STATS: batch 146/486 in epoch 264,  batch loss: 1.61245, batch accuracy: 0.55817
Time: 2018-07-15 00:05:15
TRAINING STATS: batch 196/486 in epoch 264,  batch loss: 1.64434, batch accuracy: 0.55133
Time: 2018-07-15 00:05:19
TRAINING STATS: batch 246/486 in epoch 264,  batch loss: 1.93472, batch accuracy: 0.46283
Time: 2018-07-15 00:05:23
TRAINING STATS: batch 296/486 in epoch 264,  batch loss: 1.73645, batch accuracy: 0.52783
Time: 2018-07-15 00:05:27
TRAINING STATS: batch 346/486 in epoch 264,  batch loss: 1.56808, batch accuracy: 0.58000
Time: 2018-07-15 00:05:31
TRAINING STATS: batch 396/486 in epoch 264,  batch loss: 1.64102, batch accuracy: 0.55250
Time: 2018-07-15 00:05:35
TRAINING STATS: batch 446/486 in epoch 264,  batch loss: 1.91326, batch accuracy: 0.47367
Time: 2018-07-15 00:05:39
TRAINING STATS: batch 10/486 in epoch 265,   batch loss: 1.97535, batch accuracy: 0.46200
Time: 2018-07-15 00:05:43
TRAINING STATS: batch 60/486 in epoch 265,   batch loss: 1.69392, batch accuracy: 0.54467
Time: 2018-07-15 00:05:47
TRAINING STATS: batch 110/486 in epoch 265,  batch loss: 1.69317, batch accuracy: 0.53967
Time: 2018-07-15 00:05:51
TRAINING STATS: batch 160/486 in epoch 265,  batch loss: 1.61357, batch accuracy: 0.55983
Time: 2018-07-15 00:05:55
TRAINING STATS: batch 210/486 in epoch 265,  batch loss: 1.53269, batch accuracy: 0.58117
Time: 2018-07-15 00:05:59
TRAINING STATS: batch 260/486 in epoch 265,  batch loss: 1.62848, batch accuracy: 0.55333
Time: 2018-07-15 00:06:04
TRAINING STATS: batch 310/486 in epoch 265,  batch loss: 1.56561, batch accuracy: 0.57200
Time: 2018-07-15 00:06:07
TRAINING STATS: batch 360/486 in epoch 265,  batch loss: 1.60369, batch accuracy: 0.55817
Time: 2018-07-15 00:06:11
TRAINING STATS: batch 410/486 in epoch 265,  batch loss: 1.51045, batch accuracy: 0.58900
Time: 2018-07-15 00:06:16
TRAINING STATS: batch 460/486 in epoch 265,  batch loss: 1.68487, batch accuracy: 0.53100
Time: 2018-07-15 00:06:19
TRAINING STATS: batch 24/486 in epoch 266,   batch loss: 1.65531, batch accuracy: 0.55267
Time: 2018-07-15 00:06:23
TRAINING STATS: batch 74/486 in epoch 266,   batch loss: 1.60366, batch accuracy: 0.55483
Time: 2018-07-15 00:06:28
TRAINING STATS: batch 124/486 in epoch 266,  batch loss: 1.60864, batch accuracy: 0.56567
Time: 2018-07-15 00:06:31
TRAINING STATS: batch 174/486 in epoch 266,  batch loss: 1.62551, batch accuracy: 0.55567
Time: 2018-07-15 00:06:35
TRAINING STATS: batch 224/486 in epoch 266,  batch loss: 1.59640, batch accuracy: 0.56250
Time: 2018-07-15 00:06:40
TRAINING STATS: batch 274/486 in epoch 266,  batch loss: 1.53625, batch accuracy: 0.58067
Time: 2018-07-15 00:06:44
TRAINING STATS: batch 324/486 in epoch 266,  batch loss: 1.57541, batch accuracy: 0.57683
Time: 2018-07-15 00:06:47
TRAINING STATS: batch 374/486 in epoch 266,  batch loss: 1.58459, batch accuracy: 0.57300
Time: 2018-07-15 00:06:52
TRAINING STATS: batch 424/486 in epoch 266,  batch loss: 1.49720, batch accuracy: 0.59167
Time: 2018-07-15 00:06:56
TRAINING STATS: batch 474/486 in epoch 266,  batch loss: 1.55213, batch accuracy: 0.57850
Time: 2018-07-15 00:06:59
TRAINING STATS: batch 38/486 in epoch 267,   batch loss: 1.55775, batch accuracy: 0.57867
Time: 2018-07-15 00:07:04
TRAINING STATS: batch 88/486 in epoch 267,   batch loss: 1.56176, batch accuracy: 0.57517
Time: 2018-07-15 00:07:08
TRAINING STATS: batch 138/486 in epoch 267,  batch loss: 1.56869, batch accuracy: 0.56900
Time: 2018-07-15 00:07:11
TRAINING STATS: batch 188/486 in epoch 267,  batch loss: 1.47364, batch accuracy: 0.59983
Time: 2018-07-15 00:07:16
TRAINING STATS: batch 238/486 in epoch 267,  batch loss: 1.50530, batch accuracy: 0.59000
Time: 2018-07-15 00:07:20
TRAINING STATS: batch 288/486 in epoch 267,  batch loss: 1.56201, batch accuracy: 0.56333
Time: 2018-07-15 00:07:24
TRAINING STATS: batch 338/486 in epoch 267,  batch loss: 1.51704, batch accuracy: 0.58117
Time: 2018-07-15 00:07:28
TRAINING STATS: batch 388/486 in epoch 267,  batch loss: 1.48353, batch accuracy: 0.60067
Time: 2018-07-15 00:07:32
TRAINING STATS: batch 438/486 in epoch 267,  batch loss: 1.53987, batch accuracy: 0.57700
Time: 2018-07-15 00:07:36
TRAINING STATS: batch 2/486 in epoch 268,    batch loss: 1.51530, batch accuracy: 0.58700
Time: 2018-07-15 00:07:40
TRAINING STATS: batch 52/486 in epoch 268,   batch loss: 1.61256, batch accuracy: 0.55317
Time: 2018-07-15 00:07:44
TRAINING STATS: batch 102/486 in epoch 268,  batch loss: 2.55802, batch accuracy: 0.27200
Time: 2018-07-15 00:07:48
TRAINING STATS: batch 152/486 in epoch 268,  batch loss: 2.15525, batch accuracy: 0.40700
Time: 2018-07-15 00:07:52
TRAINING STATS: batch 202/486 in epoch 268,  batch loss: 1.99773, batch accuracy: 0.46850
Time: 2018-07-15 00:07:56
TRAINING STATS: batch 252/486 in epoch 268,  batch loss: 1.81314, batch accuracy: 0.51517
Time: 2018-07-15 00:08:00
TRAINING STATS: batch 302/486 in epoch 268,  batch loss: 1.83639, batch accuracy: 0.50817
Time: 2018-07-15 00:08:05
TRAINING STATS: batch 352/486 in epoch 268,  batch loss: 1.75168, batch accuracy: 0.52817
Time: 2018-07-15 00:08:08
TRAINING STATS: batch 402/486 in epoch 268,  batch loss: 1.54494, batch accuracy: 0.58617
Time: 2018-07-15 00:08:12
TRAINING STATS: batch 452/486 in epoch 268,  batch loss: 1.63375, batch accuracy: 0.54150
Time: 2018-07-15 00:08:17
TRAINING STATS: batch 16/486 in epoch 269,   batch loss: 1.59697, batch accuracy: 0.57633
Time: 2018-07-15 00:08:20
TRAINING STATS: batch 66/486 in epoch 269,   batch loss: 1.60512, batch accuracy: 0.57050
Time: 2018-07-15 00:08:24
TRAINING STATS: batch 116/486 in epoch 269,  batch loss: 1.61731, batch accuracy: 0.56233
Time: 2018-07-15 00:08:29
TRAINING STATS: batch 166/486 in epoch 269,  batch loss: 1.50774, batch accuracy: 0.59483
Time: 2018-07-15 00:08:32
TRAINING STATS: batch 216/486 in epoch 269,  batch loss: 1.59210, batch accuracy: 0.57183
Time: 2018-07-15 00:08:36
TRAINING STATS: batch 266/486 in epoch 269,  batch loss: 1.57165, batch accuracy: 0.56883
Time: 2018-07-15 00:08:41
TRAINING STATS: batch 316/486 in epoch 269,  batch loss: 1.54752, batch accuracy: 0.57717
Time: 2018-07-15 00:08:45
TRAINING STATS: batch 366/486 in epoch 269,  batch loss: 1.60960, batch accuracy: 0.56717
Time: 2018-07-15 00:08:48
TRAINING STATS: batch 416/486 in epoch 269,  batch loss: 1.58998, batch accuracy: 0.56850
Time: 2018-07-15 00:08:53
TRAINING STATS: batch 466/486 in epoch 269,  batch loss: 1.43298, batch accuracy: 0.61633
Time: 2018-07-15 00:08:57
TRAINING STATS: batch 30/486 in epoch 270,   batch loss: 1.43216, batch accuracy: 0.61333
Time: 2018-07-15 00:09:00
TRAINING STATS: batch 80/486 in epoch 270,   batch loss: 1.52994, batch accuracy: 0.58133
Time: 2018-07-15 00:09:05
TRAINING STATS: batch 130/486 in epoch 270,  batch loss: 1.52047, batch accuracy: 0.59167
Time: 2018-07-15 00:09:09
TRAINING STATS: batch 180/486 in epoch 270,  batch loss: 1.57940, batch accuracy: 0.57450
Time: 2018-07-15 00:09:12
TRAINING STATS: batch 230/486 in epoch 270,  batch loss: 1.55616, batch accuracy: 0.56800
Time: 2018-07-15 00:09:17
TRAINING STATS: batch 280/486 in epoch 270,  batch loss: 1.49055, batch accuracy: 0.59317
Time: 2018-07-15 00:09:21
TRAINING STATS: batch 330/486 in epoch 270,  batch loss: 1.50582, batch accuracy: 0.59350
Time: 2018-07-15 00:09:24
TRAINING STATS: batch 380/486 in epoch 270,  batch loss: 1.47213, batch accuracy: 0.60250
Time: 2018-07-15 00:09:29
TRAINING STATS: batch 430/486 in epoch 270,  batch loss: 1.44584, batch accuracy: 0.61033
Time: 2018-07-15 00:09:33
TRAINING STATS: batch 480/486 in epoch 270,  batch loss: 1.53963, batch accuracy: 0.58233
Time: 2018-07-15 00:09:37
TRAINING STATS: batch 44/486 in epoch 271,   batch loss: 1.48412, batch accuracy: 0.59567
Time: 2018-07-15 00:09:41
TRAINING STATS: batch 94/486 in epoch 271,   batch loss: 1.57094, batch accuracy: 0.57533
Time: 2018-07-15 00:09:45
TRAINING STATS: batch 144/486 in epoch 271,  batch loss: 1.61908, batch accuracy: 0.55850
Time: 2018-07-15 00:09:49
TRAINING STATS: batch 194/486 in epoch 271,  batch loss: 1.65836, batch accuracy: 0.55000
Time: 2018-07-15 00:09:53
TRAINING STATS: batch 244/486 in epoch 271,  batch loss: 1.51208, batch accuracy: 0.58933
Time: 2018-07-15 00:09:57
TRAINING STATS: batch 294/486 in epoch 271,  batch loss: 1.43621, batch accuracy: 0.61017
Time: 2018-07-15 00:10:01
TRAINING STATS: batch 344/486 in epoch 271,  batch loss: 1.50347, batch accuracy: 0.59033
Time: 2018-07-15 00:10:06
TRAINING STATS: batch 394/486 in epoch 271,  batch loss: 1.48763, batch accuracy: 0.60467
Time: 2018-07-15 00:10:09
TRAINING STATS: batch 444/486 in epoch 271,  batch loss: 1.48913, batch accuracy: 0.59517
Time: 2018-07-15 00:10:13
TRAINING STATS: batch 8/486 in epoch 272,    batch loss: 1.51621, batch accuracy: 0.58683
Time: 2018-07-15 00:10:18
TRAINING STATS: batch 58/486 in epoch 272,   batch loss: 1.50096, batch accuracy: 0.59533
Time: 2018-07-15 00:10:21
TRAINING STATS: batch 108/486 in epoch 272,  batch loss: 1.61461, batch accuracy: 0.56450
Time: 2018-07-15 00:10:25
TRAINING STATS: batch 158/486 in epoch 272,  batch loss: 1.58450, batch accuracy: 0.56700
Time: 2018-07-15 00:10:30
TRAINING STATS: batch 208/486 in epoch 272,  batch loss: 1.53322, batch accuracy: 0.58250
Time: 2018-07-15 00:10:33
TRAINING STATS: batch 258/486 in epoch 272,  batch loss: 1.46023, batch accuracy: 0.60350
Time: 2018-07-15 00:10:37
TRAINING STATS: batch 308/486 in epoch 272,  batch loss: 1.50760, batch accuracy: 0.58417
Time: 2018-07-15 00:10:42
TRAINING STATS: batch 358/486 in epoch 272,  batch loss: 1.55448, batch accuracy: 0.57283
Time: 2018-07-15 00:10:46
TRAINING STATS: batch 408/486 in epoch 272,  batch loss: 1.53913, batch accuracy: 0.57400
Time: 2018-07-15 00:10:49
TRAINING STATS: batch 458/486 in epoch 272,  batch loss: 1.52210, batch accuracy: 0.58367
Time: 2018-07-15 00:10:54
TRAINING STATS: batch 22/486 in epoch 273,   batch loss: 1.55408, batch accuracy: 0.57917
Time: 2018-07-15 00:10:58
TRAINING STATS: batch 72/486 in epoch 273,   batch loss: 1.53349, batch accuracy: 0.57717
Time: 2018-07-15 00:11:01
TRAINING STATS: batch 122/486 in epoch 273,  batch loss: 1.46795, batch accuracy: 0.60250
Time: 2018-07-15 00:11:06
TRAINING STATS: batch 172/486 in epoch 273,  batch loss: 1.59305, batch accuracy: 0.56567
Time: 2018-07-15 00:11:10
TRAINING STATS: batch 222/486 in epoch 273,  batch loss: 1.50263, batch accuracy: 0.58117
Time: 2018-07-15 00:11:13
TRAINING STATS: batch 272/486 in epoch 273,  batch loss: 1.51238, batch accuracy: 0.58200
Time: 2018-07-15 00:11:18
TRAINING STATS: batch 322/486 in epoch 273,  batch loss: 1.52578, batch accuracy: 0.58400
Time: 2018-07-15 00:11:22
TRAINING STATS: batch 372/486 in epoch 273,  batch loss: 1.47376, batch accuracy: 0.59883
Time: 2018-07-15 00:11:26
TRAINING STATS: batch 422/486 in epoch 273,  batch loss: 1.49150, batch accuracy: 0.59617
Time: 2018-07-15 00:11:30
TRAINING STATS: batch 472/486 in epoch 273,  batch loss: 1.55925, batch accuracy: 0.57750
Time: 2018-07-15 00:11:34
TRAINING STATS: batch 36/486 in epoch 274,   batch loss: 1.74978, batch accuracy: 0.52333
Time: 2018-07-15 00:11:38
TRAINING STATS: batch 86/486 in epoch 274,   batch loss: 2.18859, batch accuracy: 0.39083
Time: 2018-07-15 00:11:42
TRAINING STATS: batch 136/486 in epoch 274,  batch loss: 1.86838, batch accuracy: 0.49433
Time: 2018-07-15 00:11:46
TRAINING STATS: batch 186/486 in epoch 274,  batch loss: 1.67691, batch accuracy: 0.54967
Time: 2018-07-15 00:11:50
TRAINING STATS: batch 236/486 in epoch 274,  batch loss: 1.62225, batch accuracy: 0.54967
Time: 2018-07-15 00:11:54
TRAINING STATS: batch 286/486 in epoch 274,  batch loss: 1.67314, batch accuracy: 0.54883
Time: 2018-07-15 00:11:58
TRAINING STATS: batch 336/486 in epoch 274,  batch loss: 1.59143, batch accuracy: 0.56917
Time: 2018-07-15 00:12:02
TRAINING STATS: batch 386/486 in epoch 274,  batch loss: 1.62494, batch accuracy: 0.54833
Time: 2018-07-15 00:12:07
TRAINING STATS: batch 436/486 in epoch 274,  batch loss: 1.55349, batch accuracy: 0.57767
Time: 2018-07-15 00:12:10
TRAINING STATS: batch 0/486 in epoch 275,    batch loss: 1.54592, batch accuracy: 0.58133
Time: 2018-07-15 00:12:14
TRAINING STATS: batch 50/486 in epoch 275,   batch loss: 1.56069, batch accuracy: 0.57733
Time: 2018-07-15 00:12:19
TRAINING STATS: batch 100/486 in epoch 275,  batch loss: 1.60805, batch accuracy: 0.56783
Time: 2018-07-15 00:12:22
TRAINING STATS: batch 150/486 in epoch 275,  batch loss: 1.65238, batch accuracy: 0.55517
Time: 2018-07-15 00:12:26
TRAINING STATS: batch 200/486 in epoch 275,  batch loss: 2.91687, batch accuracy: 0.15333
Time: 2018-07-15 00:12:31
TRAINING STATS: batch 250/486 in epoch 275,  batch loss: 2.54122, batch accuracy: 0.26083
Time: 2018-07-15 00:12:35
TRAINING STATS: batch 300/486 in epoch 275,  batch loss: 2.26624, batch accuracy: 0.34583
Time: 2018-07-15 00:12:38
TRAINING STATS: batch 350/486 in epoch 275,  batch loss: 2.11951, batch accuracy: 0.41183
Time: 2018-07-15 00:12:43
TRAINING STATS: batch 400/486 in epoch 275,  batch loss: 1.91557, batch accuracy: 0.48467
Time: 2018-07-15 00:12:47
TRAINING STATS: batch 450/486 in epoch 275,  batch loss: 2.00885, batch accuracy: 0.45033
Time: 2018-07-15 00:12:50
TRAINING STATS: batch 14/486 in epoch 276,   batch loss: 1.83231, batch accuracy: 0.51550
Time: 2018-07-15 00:12:55
TRAINING STATS: batch 64/486 in epoch 276,   batch loss: 2.01044, batch accuracy: 0.45700
Time: 2018-07-15 00:12:59
TRAINING STATS: batch 114/486 in epoch 276,  batch loss: 1.89729, batch accuracy: 0.49367
Time: 2018-07-15 00:13:03
TRAINING STATS: batch 164/486 in epoch 276,  batch loss: 1.98089, batch accuracy: 0.45083
Time: 2018-07-15 00:13:07
TRAINING STATS: batch 214/486 in epoch 276,  batch loss: 1.84462, batch accuracy: 0.50500
Time: 2018-07-15 00:13:11
TRAINING STATS: batch 264/486 in epoch 276,  batch loss: 1.82051, batch accuracy: 0.50050
Time: 2018-07-15 00:13:15
TRAINING STATS: batch 314/486 in epoch 276,  batch loss: 1.85023, batch accuracy: 0.48500
Time: 2018-07-15 00:13:19
TRAINING STATS: batch 364/486 in epoch 276,  batch loss: 1.75090, batch accuracy: 0.52483
Time: 2018-07-15 00:13:23
TRAINING STATS: batch 414/486 in epoch 276,  batch loss: 1.68702, batch accuracy: 0.53933
Time: 2018-07-15 00:13:27
TRAINING STATS: batch 464/486 in epoch 276,  batch loss: 1.71055, batch accuracy: 0.54000
Time: 2018-07-15 00:13:32
TRAINING STATS: batch 28/486 in epoch 277,   batch loss: 1.67220, batch accuracy: 0.54533
Time: 2018-07-15 00:13:35
TRAINING STATS: batch 78/486 in epoch 277,   batch loss: 1.71506, batch accuracy: 0.53250
Time: 2018-07-15 00:13:39
TRAINING STATS: batch 128/486 in epoch 277,  batch loss: 1.67831, batch accuracy: 0.53667
Time: 2018-07-15 00:13:44
TRAINING STATS: batch 178/486 in epoch 277,  batch loss: 1.61302, batch accuracy: 0.55133
Time: 2018-07-15 00:13:47
TRAINING STATS: batch 228/486 in epoch 277,  batch loss: 1.77495, batch accuracy: 0.51100
Time: 2018-07-15 00:13:51
TRAINING STATS: batch 278/486 in epoch 277,  batch loss: 1.64290, batch accuracy: 0.55350
Time: 2018-07-15 00:13:56
TRAINING STATS: batch 328/486 in epoch 277,  batch loss: 1.66925, batch accuracy: 0.54500
Time: 2018-07-15 00:13:59
TRAINING STATS: batch 378/486 in epoch 277,  batch loss: 1.66013, batch accuracy: 0.54433
Time: 2018-07-15 00:14:03
TRAINING STATS: batch 428/486 in epoch 277,  batch loss: 1.72249, batch accuracy: 0.52367
Time: 2018-07-15 00:14:08
TRAINING STATS: batch 478/486 in epoch 277,  batch loss: 1.71053, batch accuracy: 0.53733
Time: 2018-07-15 00:14:12
TRAINING STATS: batch 42/486 in epoch 278,   batch loss: 1.66994, batch accuracy: 0.54567
Time: 2018-07-15 00:14:15
TRAINING STATS: batch 92/486 in epoch 278,   batch loss: 1.89540, batch accuracy: 0.47533
Time: 2018-07-15 00:14:20
TRAINING STATS: batch 142/486 in epoch 278,  batch loss: 1.76223, batch accuracy: 0.52433
Time: 2018-07-15 00:14:24
TRAINING STATS: batch 192/486 in epoch 278,  batch loss: 1.69683, batch accuracy: 0.53733
Time: 2018-07-15 00:14:27
TRAINING STATS: batch 242/486 in epoch 278,  batch loss: 1.67219, batch accuracy: 0.54033
Time: 2018-07-15 00:14:32
TRAINING STATS: batch 292/486 in epoch 278,  batch loss: 1.68810, batch accuracy: 0.53800
Time: 2018-07-15 00:14:36
TRAINING STATS: batch 342/486 in epoch 278,  batch loss: 1.68635, batch accuracy: 0.53567
Time: 2018-07-15 00:14:39
TRAINING STATS: batch 392/486 in epoch 278,  batch loss: 1.61451, batch accuracy: 0.55517
Time: 2018-07-15 00:14:44
TRAINING STATS: batch 442/486 in epoch 278,  batch loss: 1.64732, batch accuracy: 0.54900
Time: 2018-07-15 00:14:48
TRAINING STATS: batch 6/486 in epoch 279,    batch loss: 1.71268, batch accuracy: 0.54333
Time: 2018-07-15 00:14:52
TRAINING STATS: batch 56/486 in epoch 279,   batch loss: 1.62320, batch accuracy: 0.54950
Time: 2018-07-15 00:14:56
TRAINING STATS: batch 106/486 in epoch 279,  batch loss: 1.73278, batch accuracy: 0.53267
Time: 2018-07-15 00:15:00
TRAINING STATS: batch 156/486 in epoch 279,  batch loss: 1.79543, batch accuracy: 0.50400
Time: 2018-07-15 00:15:04
TRAINING STATS: batch 206/486 in epoch 279,  batch loss: 1.98394, batch accuracy: 0.45967
Time: 2018-07-15 00:15:08
TRAINING STATS: batch 256/486 in epoch 279,  batch loss: 1.82838, batch accuracy: 0.50650
Time: 2018-07-15 00:15:12
TRAINING STATS: batch 306/486 in epoch 279,  batch loss: 1.82167, batch accuracy: 0.50183
Time: 2018-07-15 00:15:16
TRAINING STATS: batch 356/486 in epoch 279,  batch loss: 1.78656, batch accuracy: 0.51933
Time: 2018-07-15 00:15:20
TRAINING STATS: batch 406/486 in epoch 279,  batch loss: 1.76960, batch accuracy: 0.51650
Time: 2018-07-15 00:15:24
TRAINING STATS: batch 456/486 in epoch 279,  batch loss: 1.53882, batch accuracy: 0.58583
Time: 2018-07-15 00:15:28
TRAINING STATS: batch 20/486 in epoch 280,   batch loss: 1.65452, batch accuracy: 0.54683
Time: 2018-07-15 00:15:33
TRAINING STATS: batch 70/486 in epoch 280,   batch loss: 1.62414, batch accuracy: 0.56467
Time: 2018-07-15 00:15:36
TRAINING STATS: batch 120/486 in epoch 280,  batch loss: 1.86104, batch accuracy: 0.50717
Time: 2018-07-15 00:15:40
TRAINING STATS: batch 170/486 in epoch 280,  batch loss: 1.87999, batch accuracy: 0.49433
Time: 2018-07-15 00:15:45
TRAINING STATS: batch 220/486 in epoch 280,  batch loss: 2.66289, batch accuracy: 0.21867
Time: 2018-07-15 00:15:48
TRAINING STATS: batch 270/486 in epoch 280,  batch loss: 2.57372, batch accuracy: 0.25867
Time: 2018-07-15 00:15:52
TRAINING STATS: batch 320/486 in epoch 280,  batch loss: 2.44757, batch accuracy: 0.30967
Time: 2018-07-15 00:15:57
TRAINING STATS: batch 370/486 in epoch 280,  batch loss: 2.42527, batch accuracy: 0.31650
Time: 2018-07-15 00:16:00
TRAINING STATS: batch 420/486 in epoch 280,  batch loss: 2.40270, batch accuracy: 0.33833
Time: 2018-07-15 00:16:04
TRAINING STATS: batch 470/486 in epoch 280,  batch loss: 2.38785, batch accuracy: 0.34100
Time: 2018-07-15 00:16:09
TRAINING STATS: batch 34/486 in epoch 281,   batch loss: 2.39238, batch accuracy: 0.33700
Time: 2018-07-15 00:16:13
TRAINING STATS: batch 84/486 in epoch 281,   batch loss: 2.32583, batch accuracy: 0.35400
Time: 2018-07-15 00:16:16
TRAINING STATS: batch 134/486 in epoch 281,  batch loss: 2.30541, batch accuracy: 0.37783
Time: 2018-07-15 00:16:21
TRAINING STATS: batch 184/486 in epoch 281,  batch loss: 2.30068, batch accuracy: 0.37267
Time: 2018-07-15 00:16:25
TRAINING STATS: batch 234/486 in epoch 281,  batch loss: 2.45480, batch accuracy: 0.29567
Time: 2018-07-15 00:16:28
TRAINING STATS: batch 284/486 in epoch 281,  batch loss: 2.36265, batch accuracy: 0.35300
Time: 2018-07-15 00:16:33
TRAINING STATS: batch 334/486 in epoch 281,  batch loss: 2.27087, batch accuracy: 0.36967
Time: 2018-07-15 00:16:37
TRAINING STATS: batch 384/486 in epoch 281,  batch loss: 2.25077, batch accuracy: 0.39583
Time: 2018-07-15 00:16:41
TRAINING STATS: batch 434/486 in epoch 281,  batch loss: 2.29530, batch accuracy: 0.37617
Time: 2018-07-15 00:16:45
TRAINING STATS: batch 484/486 in epoch 281,  batch loss: 2.35696, batch accuracy: 0.34150
Time: 2018-07-15 00:16:49
TRAINING STATS: batch 48/486 in epoch 282,   batch loss: 2.27425, batch accuracy: 0.38267
Time: 2018-07-15 00:16:53
TRAINING STATS: batch 98/486 in epoch 282,   batch loss: 2.18575, batch accuracy: 0.42600
Time: 2018-07-15 00:16:57
TRAINING STATS: batch 148/486 in epoch 282,  batch loss: 2.25235, batch accuracy: 0.41167
Time: 2018-07-15 00:17:01
TRAINING STATS: batch 198/486 in epoch 282,  batch loss: 2.27163, batch accuracy: 0.39017
Time: 2018-07-15 00:17:05
TRAINING STATS: batch 248/486 in epoch 282,  batch loss: 2.21470, batch accuracy: 0.40517
Time: 2018-07-15 00:17:10
TRAINING STATS: batch 298/486 in epoch 282,  batch loss: 2.16612, batch accuracy: 0.41583
Time: 2018-07-15 00:17:13
TRAINING STATS: batch 348/486 in epoch 282,  batch loss: 2.19091, batch accuracy: 0.42100
Time: 2018-07-15 00:17:17
TRAINING STATS: batch 398/486 in epoch 282,  batch loss: 2.24365, batch accuracy: 0.38733
Time: 2018-07-15 00:17:22
TRAINING STATS: batch 448/486 in epoch 282,  batch loss: 2.15312, batch accuracy: 0.42750
Time: 2018-07-15 00:17:25
TRAINING STATS: batch 12/486 in epoch 283,   batch loss: 2.19389, batch accuracy: 0.40517
Time: 2018-07-15 00:17:29
TRAINING STATS: batch 62/486 in epoch 283,   batch loss: 2.23636, batch accuracy: 0.40450
Time: 2018-07-15 00:17:34
TRAINING STATS: batch 112/486 in epoch 283,  batch loss: 2.13283, batch accuracy: 0.43200
Time: 2018-07-15 00:17:37
TRAINING STATS: batch 162/486 in epoch 283,  batch loss: 2.15104, batch accuracy: 0.42817
Time: 2018-07-15 00:17:41
TRAINING STATS: batch 212/486 in epoch 283,  batch loss: 2.22212, batch accuracy: 0.38667
Time: 2018-07-15 00:17:46
TRAINING STATS: batch 262/486 in epoch 283,  batch loss: 2.21420, batch accuracy: 0.40750
Time: 2018-07-15 00:17:49
TRAINING STATS: batch 312/486 in epoch 283,  batch loss: 2.18432, batch accuracy: 0.42550
Time: 2018-07-15 00:17:53
TRAINING STATS: batch 362/486 in epoch 283,  batch loss: 2.13923, batch accuracy: 0.44133
Time: 2018-07-15 00:17:58
TRAINING STATS: batch 412/486 in epoch 283,  batch loss: 2.11459, batch accuracy: 0.44017
Time: 2018-07-15 00:18:02
TRAINING STATS: batch 462/486 in epoch 283,  batch loss: 2.18165, batch accuracy: 0.40483
Time: 2018-07-15 00:18:05
TRAINING STATS: batch 26/486 in epoch 284,   batch loss: 2.23161, batch accuracy: 0.40367
Time: 2018-07-15 00:18:10
TRAINING STATS: batch 76/486 in epoch 284,   batch loss: 2.17430, batch accuracy: 0.41683
Time: 2018-07-15 00:18:14
TRAINING STATS: batch 126/486 in epoch 284,  batch loss: 2.14646, batch accuracy: 0.42150
Time: 2018-07-15 00:18:18
TRAINING STATS: batch 176/486 in epoch 284,  batch loss: 2.22258, batch accuracy: 0.39683
Time: 2018-07-15 00:18:22
TRAINING STATS: batch 226/486 in epoch 284,  batch loss: 2.37488, batch accuracy: 0.34567
Time: 2018-07-15 00:18:26
TRAINING STATS: batch 276/486 in epoch 284,  batch loss: 2.25319, batch accuracy: 0.40250
Time: 2018-07-15 00:18:29
TRAINING STATS: batch 326/486 in epoch 284,  batch loss: 2.27350, batch accuracy: 0.37717
Time: 2018-07-15 00:18:34
TRAINING STATS: batch 376/486 in epoch 284,  batch loss: 2.21381, batch accuracy: 0.41767
Time: 2018-07-15 00:18:38
TRAINING STATS: batch 426/486 in epoch 284,  batch loss: 2.15086, batch accuracy: 0.42067
Time: 2018-07-15 00:18:42
TRAINING STATS: batch 476/486 in epoch 284,  batch loss: 2.09438, batch accuracy: 0.45717
Time: 2018-07-15 00:18:46
TRAINING STATS: batch 40/486 in epoch 285,   batch loss: 2.09148, batch accuracy: 0.44283
Time: 2018-07-15 00:18:50
TRAINING STATS: batch 90/486 in epoch 285,   batch loss: 2.13998, batch accuracy: 0.43367
Time: 2018-07-15 00:18:54
TRAINING STATS: batch 140/486 in epoch 285,  batch loss: 2.01878, batch accuracy: 0.46917
Time: 2018-07-15 00:18:58
TRAINING STATS: batch 190/486 in epoch 285,  batch loss: 2.06292, batch accuracy: 0.45650
Time: 2018-07-15 00:19:02
TRAINING STATS: batch 240/486 in epoch 285,  batch loss: 2.05626, batch accuracy: 0.45300
Time: 2018-07-15 00:19:06
TRAINING STATS: batch 290/486 in epoch 285,  batch loss: 2.06947, batch accuracy: 0.44417
Time: 2018-07-15 00:19:11
TRAINING STATS: batch 340/486 in epoch 285,  batch loss: 2.12449, batch accuracy: 0.42800
Time: 2018-07-15 00:19:14
TRAINING STATS: batch 390/486 in epoch 285,  batch loss: 1.99731, batch accuracy: 0.47050
Time: 2018-07-15 00:19:18
TRAINING STATS: batch 440/486 in epoch 285,  batch loss: 2.11805, batch accuracy: 0.43100
Time: 2018-07-15 00:19:23
TRAINING STATS: batch 4/486 in epoch 286,    batch loss: 2.05121, batch accuracy: 0.45667
Time: 2018-07-15 00:19:26
TRAINING STATS: batch 54/486 in epoch 286,   batch loss: 2.04265, batch accuracy: 0.45250
Time: 2018-07-15 00:19:30
TRAINING STATS: batch 104/486 in epoch 286,  batch loss: 2.08131, batch accuracy: 0.44200
Time: 2018-07-15 00:19:35
TRAINING STATS: batch 154/486 in epoch 286,  batch loss: 2.06077, batch accuracy: 0.45233
Time: 2018-07-15 00:19:38
TRAINING STATS: batch 204/486 in epoch 286,  batch loss: 2.08989, batch accuracy: 0.44517
Time: 2018-07-15 00:19:42
TRAINING STATS: batch 254/486 in epoch 286,  batch loss: 2.03750, batch accuracy: 0.45317
Time: 2018-07-15 00:19:47
TRAINING STATS: batch 304/486 in epoch 286,  batch loss: 2.16347, batch accuracy: 0.43750
Time: 2018-07-15 00:19:50
TRAINING STATS: batch 354/486 in epoch 286,  batch loss: 2.13166, batch accuracy: 0.42667
Time: 2018-07-15 00:19:54
TRAINING STATS: batch 404/486 in epoch 286,  batch loss: 2.08602, batch accuracy: 0.44100
Time: 2018-07-15 00:19:59
TRAINING STATS: batch 454/486 in epoch 286,  batch loss: 2.01137, batch accuracy: 0.46700
Time: 2018-07-15 00:20:02
TRAINING STATS: batch 18/486 in epoch 287,   batch loss: 2.06585, batch accuracy: 0.44733
Time: 2018-07-15 00:20:06
TRAINING STATS: batch 68/486 in epoch 287,   batch loss: 1.88369, batch accuracy: 0.49833
Time: 2018-07-15 00:20:11
TRAINING STATS: batch 118/486 in epoch 287,  batch loss: 1.96245, batch accuracy: 0.47350
Time: 2018-07-15 00:20:15
TRAINING STATS: batch 168/486 in epoch 287,  batch loss: 1.88240, batch accuracy: 0.49733
Time: 2018-07-15 00:20:18
TRAINING STATS: batch 218/486 in epoch 287,  batch loss: 1.95658, batch accuracy: 0.46933
Time: 2018-07-15 00:20:23
TRAINING STATS: batch 268/486 in epoch 287,  batch loss: 1.92238, batch accuracy: 0.48583
Time: 2018-07-15 00:20:27
TRAINING STATS: batch 318/486 in epoch 287,  batch loss: 2.12703, batch accuracy: 0.42083
Time: 2018-07-15 00:20:30
TRAINING STATS: batch 368/486 in epoch 287,  batch loss: 1.99579, batch accuracy: 0.45483
Time: 2018-07-15 00:20:35
TRAINING STATS: batch 418/486 in epoch 287,  batch loss: 2.06903, batch accuracy: 0.44150
Time: 2018-07-15 00:20:39
TRAINING STATS: batch 468/486 in epoch 287,  batch loss: 1.98843, batch accuracy: 0.46333
Time: 2018-07-15 00:20:42
TRAINING STATS: batch 32/486 in epoch 288,   batch loss: 1.94045, batch accuracy: 0.47150
Time: 2018-07-15 00:20:47
TRAINING STATS: batch 82/486 in epoch 288,   batch loss: 1.96466, batch accuracy: 0.46533
Time: 2018-07-15 00:20:51
TRAINING STATS: batch 132/486 in epoch 288,  batch loss: 1.94295, batch accuracy: 0.48083
Time: 2018-07-15 00:20:55
TRAINING STATS: batch 182/486 in epoch 288,  batch loss: 1.99968, batch accuracy: 0.45917
Time: 2018-07-15 00:20:59
TRAINING STATS: batch 232/486 in epoch 288,  batch loss: 1.90507, batch accuracy: 0.49267
Time: 2018-07-15 00:21:03
TRAINING STATS: batch 282/486 in epoch 288,  batch loss: 1.83171, batch accuracy: 0.49283
Time: 2018-07-15 00:21:07
TRAINING STATS: batch 332/486 in epoch 288,  batch loss: 1.89303, batch accuracy: 0.48467
Time: 2018-07-15 00:21:11
TRAINING STATS: batch 382/486 in epoch 288,  batch loss: 1.84005, batch accuracy: 0.49583
Time: 2018-07-15 00:21:15
TRAINING STATS: batch 432/486 in epoch 288,  batch loss: 1.76690, batch accuracy: 0.51317
Time: 2018-07-15 00:21:19
TRAINING STATS: batch 482/486 in epoch 288,  batch loss: 1.82055, batch accuracy: 0.49933
Time: 2018-07-15 00:21:23
TRAINING STATS: batch 46/486 in epoch 289,   batch loss: 1.77552, batch accuracy: 0.52183
Time: 2018-07-15 00:21:27
TRAINING STATS: batch 96/486 in epoch 289,   batch loss: 1.81340, batch accuracy: 0.50550
Time: 2018-07-15 00:21:31
TRAINING STATS: batch 146/486 in epoch 289,  batch loss: 1.87428, batch accuracy: 0.48617
Time: 2018-07-15 00:21:36
TRAINING STATS: batch 196/486 in epoch 289,  batch loss: 1.82509, batch accuracy: 0.49750
Time: 2018-07-15 00:21:39
TRAINING STATS: batch 246/486 in epoch 289,  batch loss: 1.75733, batch accuracy: 0.51783
Time: 2018-07-15 00:21:43
TRAINING STATS: batch 296/486 in epoch 289,  batch loss: 1.73461, batch accuracy: 0.52367
Time: 2018-07-15 00:21:48
TRAINING STATS: batch 346/486 in epoch 289,  batch loss: 1.71848, batch accuracy: 0.53367
Time: 2018-07-15 00:21:51
TRAINING STATS: batch 396/486 in epoch 289,  batch loss: 1.73007, batch accuracy: 0.53083
Time: 2018-07-15 00:21:55
TRAINING STATS: batch 446/486 in epoch 289,  batch loss: 1.80295, batch accuracy: 0.50267
Time: 2018-07-15 00:22:00
TRAINING STATS: batch 10/486 in epoch 290,   batch loss: 1.80138, batch accuracy: 0.50217
Time: 2018-07-15 00:22:03
TRAINING STATS: batch 60/486 in epoch 290,   batch loss: 1.78822, batch accuracy: 0.51100
Time: 2018-07-15 00:22:07
TRAINING STATS: batch 110/486 in epoch 290,  batch loss: 1.79413, batch accuracy: 0.51000
Time: 2018-07-15 00:22:12
TRAINING STATS: batch 160/486 in epoch 290,  batch loss: 1.71823, batch accuracy: 0.52483
Time: 2018-07-15 00:22:16
TRAINING STATS: batch 210/486 in epoch 290,  batch loss: 1.73243, batch accuracy: 0.51633
Time: 2018-07-15 00:22:19
TRAINING STATS: batch 260/486 in epoch 290,  batch loss: 1.79988, batch accuracy: 0.50283
Time: 2018-07-15 00:22:24
TRAINING STATS: batch 310/486 in epoch 290,  batch loss: 1.78004, batch accuracy: 0.50650
Time: 2018-07-15 00:22:28
TRAINING STATS: batch 360/486 in epoch 290,  batch loss: 1.79596, batch accuracy: 0.50300
Time: 2018-07-15 00:22:31
TRAINING STATS: batch 410/486 in epoch 290,  batch loss: 1.68274, batch accuracy: 0.54550
Time: 2018-07-15 00:22:36
TRAINING STATS: batch 460/486 in epoch 290,  batch loss: 1.85735, batch accuracy: 0.48850
Time: 2018-07-15 00:22:40
TRAINING STATS: batch 24/486 in epoch 291,   batch loss: 1.80102, batch accuracy: 0.50967
Time: 2018-07-15 00:22:43
TRAINING STATS: batch 74/486 in epoch 291,   batch loss: 1.77769, batch accuracy: 0.51850
Time: 2018-07-15 00:22:48
TRAINING STATS: batch 124/486 in epoch 291,  batch loss: 1.80266, batch accuracy: 0.50733
Time: 2018-07-15 00:22:52
TRAINING STATS: batch 174/486 in epoch 291,  batch loss: 1.82397, batch accuracy: 0.49767
Time: 2018-07-15 00:22:55
TRAINING STATS: batch 224/486 in epoch 291,  batch loss: 1.81564, batch accuracy: 0.50367
Time: 2018-07-15 00:23:00
TRAINING STATS: batch 274/486 in epoch 291,  batch loss: 1.75657, batch accuracy: 0.51067
Time: 2018-07-15 00:23:04
TRAINING STATS: batch 324/486 in epoch 291,  batch loss: 1.83529, batch accuracy: 0.49367
Time: 2018-07-15 00:23:08
TRAINING STATS: batch 374/486 in epoch 291,  batch loss: 2.68373, batch accuracy: 0.23450
Time: 2018-07-15 00:23:12
TRAINING STATS: batch 424/486 in epoch 291,  batch loss: 2.41475, batch accuracy: 0.30167
Time: 2018-07-15 00:23:16
TRAINING STATS: batch 474/486 in epoch 291,  batch loss: 2.37289, batch accuracy: 0.31400
Time: 2018-07-15 00:23:20
TRAINING STATS: batch 38/486 in epoch 292,   batch loss: 2.33564, batch accuracy: 0.34233
Time: 2018-07-15 00:23:24
TRAINING STATS: batch 88/486 in epoch 292,   batch loss: 2.30729, batch accuracy: 0.34667
Time: 2018-07-15 00:23:28
TRAINING STATS: batch 138/486 in epoch 292,  batch loss: 2.30069, batch accuracy: 0.35217
Time: 2018-07-15 00:23:32
TRAINING STATS: batch 188/486 in epoch 292,  batch loss: 2.22111, batch accuracy: 0.38450
Time: 2018-07-15 00:23:37
TRAINING STATS: batch 238/486 in epoch 292,  batch loss: 2.17089, batch accuracy: 0.40683
Time: 2018-07-15 00:23:40
TRAINING STATS: batch 288/486 in epoch 292,  batch loss: 2.11450, batch accuracy: 0.42983
Time: 2018-07-15 00:23:44
TRAINING STATS: batch 338/486 in epoch 292,  batch loss: 2.00650, batch accuracy: 0.46500
Time: 2018-07-15 00:23:49
TRAINING STATS: batch 388/486 in epoch 292,  batch loss: 1.91960, batch accuracy: 0.49300
Time: 2018-07-15 00:23:52
TRAINING STATS: batch 438/486 in epoch 292,  batch loss: 1.93298, batch accuracy: 0.48000
Time: 2018-07-15 00:23:56
TRAINING STATS: batch 2/486 in epoch 293,    batch loss: 1.92907, batch accuracy: 0.48283
Time: 2018-07-15 00:24:01
TRAINING STATS: batch 52/486 in epoch 293,   batch loss: 1.97336, batch accuracy: 0.46317
Time: 2018-07-15 00:24:04
TRAINING STATS: batch 102/486 in epoch 293,  batch loss: 1.95725, batch accuracy: 0.46417
Time: 2018-07-15 00:24:08
TRAINING STATS: batch 152/486 in epoch 293,  batch loss: 1.81404, batch accuracy: 0.51100
Time: 2018-07-15 00:24:13
TRAINING STATS: batch 202/486 in epoch 293,  batch loss: 1.86360, batch accuracy: 0.49133
Time: 2018-07-15 00:24:16
TRAINING STATS: batch 252/486 in epoch 293,  batch loss: 1.80643, batch accuracy: 0.50483
Time: 2018-07-15 00:24:20
TRAINING STATS: batch 302/486 in epoch 293,  batch loss: 1.81922, batch accuracy: 0.49617
Time: 2018-07-15 00:24:25
TRAINING STATS: batch 352/486 in epoch 293,  batch loss: 1.85606, batch accuracy: 0.49067
Time: 2018-07-15 00:24:29
TRAINING STATS: batch 402/486 in epoch 293,  batch loss: 1.76976, batch accuracy: 0.52633
Time: 2018-07-15 00:24:32
TRAINING STATS: batch 452/486 in epoch 293,  batch loss: 1.84009, batch accuracy: 0.49750
Time: 2018-07-15 00:24:37
TRAINING STATS: batch 16/486 in epoch 294,   batch loss: 2.31920, batch accuracy: 0.35283
Time: 2018-07-15 00:24:41
TRAINING STATS: batch 66/486 in epoch 294,   batch loss: 1.94784, batch accuracy: 0.47967
Time: 2018-07-15 00:24:44
TRAINING STATS: batch 116/486 in epoch 294,  batch loss: 1.87033, batch accuracy: 0.50083
Time: 2018-07-15 00:24:49
TRAINING STATS: batch 166/486 in epoch 294,  batch loss: 1.78704, batch accuracy: 0.51933
Time: 2018-07-15 00:24:53
TRAINING STATS: batch 216/486 in epoch 294,  batch loss: 1.87835, batch accuracy: 0.49250
Time: 2018-07-15 00:24:56
TRAINING STATS: batch 266/486 in epoch 294,  batch loss: 1.87750, batch accuracy: 0.49150
Time: 2018-07-15 00:25:01
TRAINING STATS: batch 316/486 in epoch 294,  batch loss: 1.81815, batch accuracy: 0.50450
Time: 2018-07-15 00:25:05
TRAINING STATS: batch 366/486 in epoch 294,  batch loss: 1.88512, batch accuracy: 0.49667
Time: 2018-07-15 00:25:08
TRAINING STATS: batch 416/486 in epoch 294,  batch loss: 1.86932, batch accuracy: 0.48750
Time: 2018-07-15 00:25:13
TRAINING STATS: batch 466/486 in epoch 294,  batch loss: 1.72516, batch accuracy: 0.53700
Time: 2018-07-15 00:25:17
TRAINING STATS: batch 30/486 in epoch 295,   batch loss: 1.71533, batch accuracy: 0.52933
Time: 2018-07-15 00:25:21
TRAINING STATS: batch 80/486 in epoch 295,   batch loss: 1.81082, batch accuracy: 0.50867
Time: 2018-07-15 00:25:25
TRAINING STATS: batch 130/486 in epoch 295,  batch loss: 1.76700, batch accuracy: 0.52050
Time: 2018-07-15 00:25:29
TRAINING STATS: batch 180/486 in epoch 295,  batch loss: 1.82473, batch accuracy: 0.49633
Time: 2018-07-15 00:25:33
TRAINING STATS: batch 230/486 in epoch 295,  batch loss: 1.80959, batch accuracy: 0.49283
Time: 2018-07-15 00:25:37
TRAINING STATS: batch 280/486 in epoch 295,  batch loss: 1.75918, batch accuracy: 0.51483
Time: 2018-07-15 00:25:41
TRAINING STATS: batch 330/486 in epoch 295,  batch loss: 1.77302, batch accuracy: 0.51217
Time: 2018-07-15 00:25:45
TRAINING STATS: batch 380/486 in epoch 295,  batch loss: 1.76924, batch accuracy: 0.51350
Time: 2018-07-15 00:25:50
TRAINING STATS: batch 430/486 in epoch 295,  batch loss: 1.70525, batch accuracy: 0.53483
Time: 2018-07-15 00:25:53
TRAINING STATS: batch 480/486 in epoch 295,  batch loss: 1.82634, batch accuracy: 0.50117
Time: 2018-07-15 00:25:57
TRAINING STATS: batch 44/486 in epoch 296,   batch loss: 2.02218, batch accuracy: 0.44200
Time: 2018-07-15 00:26:02
TRAINING STATS: batch 94/486 in epoch 296,   batch loss: 2.41288, batch accuracy: 0.32300
Time: 2018-07-15 00:26:05
TRAINING STATS: batch 144/486 in epoch 296,  batch loss: 2.28433, batch accuracy: 0.35817
Time: 2018-07-15 00:26:09
TRAINING STATS: batch 194/486 in epoch 296,  batch loss: 2.12092, batch accuracy: 0.42633
Time: 2018-07-15 00:26:14
TRAINING STATS: batch 244/486 in epoch 296,  batch loss: 1.93689, batch accuracy: 0.48383
Time: 2018-07-15 00:26:17
TRAINING STATS: batch 294/486 in epoch 296,  batch loss: 1.80161, batch accuracy: 0.51683
Time: 2018-07-15 00:26:21
TRAINING STATS: batch 344/486 in epoch 296,  batch loss: 1.88021, batch accuracy: 0.49633
Time: 2018-07-15 00:26:26
TRAINING STATS: batch 394/486 in epoch 296,  batch loss: 1.83215, batch accuracy: 0.50483
Time: 2018-07-15 00:26:29
TRAINING STATS: batch 444/486 in epoch 296,  batch loss: 1.78062, batch accuracy: 0.51617
Time: 2018-07-15 00:26:33
TRAINING STATS: batch 8/486 in epoch 297,    batch loss: 2.06843, batch accuracy: 0.43717
Time: 2018-07-15 00:26:38
TRAINING STATS: batch 58/486 in epoch 297,   batch loss: 1.95705, batch accuracy: 0.47717
Time: 2018-07-15 00:26:41
TRAINING STATS: batch 108/486 in epoch 297,  batch loss: 1.96133, batch accuracy: 0.46967
Time: 2018-07-15 00:26:45
TRAINING STATS: batch 158/486 in epoch 297,  batch loss: 1.93503, batch accuracy: 0.47400
Time: 2018-07-15 00:26:50
TRAINING STATS: batch 208/486 in epoch 297,  batch loss: 1.85291, batch accuracy: 0.50017
Time: 2018-07-15 00:26:54
TRAINING STATS: batch 258/486 in epoch 297,  batch loss: 1.79904, batch accuracy: 0.50683
Time: 2018-07-15 00:26:57
TRAINING STATS: batch 308/486 in epoch 297,  batch loss: 1.85252, batch accuracy: 0.49133
Time: 2018-07-15 00:27:02
TRAINING STATS: batch 358/486 in epoch 297,  batch loss: 1.83844, batch accuracy: 0.49067
Time: 2018-07-15 00:27:06
TRAINING STATS: batch 408/486 in epoch 297,  batch loss: 2.11498, batch accuracy: 0.41483
Time: 2018-07-15 00:27:09
TRAINING STATS: batch 458/486 in epoch 297,  batch loss: 2.06908, batch accuracy: 0.45050
Time: 2018-07-15 00:27:14
TRAINING STATS: batch 22/486 in epoch 298,   batch loss: 2.61138, batch accuracy: 0.24667
Time: 2018-07-15 00:27:18
TRAINING STATS: batch 72/486 in epoch 298,   batch loss: 2.26074, batch accuracy: 0.40517
Time: 2018-07-15 00:27:21
TRAINING STATS: batch 122/486 in epoch 298,  batch loss: 2.18628, batch accuracy: 0.43200
Time: 2018-07-15 00:27:26
TRAINING STATS: batch 172/486 in epoch 298,  batch loss: 2.27455, batch accuracy: 0.40417
Time: 2018-07-15 00:27:30
TRAINING STATS: batch 222/486 in epoch 298,  batch loss: 2.20784, batch accuracy: 0.41100
Time: 2018-07-15 00:27:34
TRAINING STATS: batch 272/486 in epoch 298,  batch loss: 2.19984, batch accuracy: 0.41383
Time: 2018-07-15 00:27:38
TRAINING STATS: batch 322/486 in epoch 298,  batch loss: 2.17316, batch accuracy: 0.41283
Time: 2018-07-15 00:27:42
TRAINING STATS: batch 372/486 in epoch 298,  batch loss: 2.09268, batch accuracy: 0.45333
Time: 2018-07-15 00:27:46
TRAINING STATS: batch 422/486 in epoch 298,  batch loss: 2.19395, batch accuracy: 0.40833
Time: 2018-07-15 00:27:50
TRAINING STATS: batch 472/486 in epoch 298,  batch loss: 2.16788, batch accuracy: 0.41633
Time: 2018-07-15 00:27:54
TRAINING STATS: batch 36/486 in epoch 299,   batch loss: 2.10273, batch accuracy: 0.44383
Time: 2018-07-15 00:27:58
TRAINING STATS: batch 86/486 in epoch 299,   batch loss: 2.04022, batch accuracy: 0.46450
Time: 2018-07-15 00:28:02
TRAINING STATS: batch 136/486 in epoch 299,  batch loss: 2.09460, batch accuracy: 0.43983
Time: 2018-07-15 00:28:06
TRAINING STATS: batch 186/486 in epoch 299,  batch loss: 2.07068, batch accuracy: 0.45083
Time: 2018-07-15 00:28:10
TRAINING STATS: batch 236/486 in epoch 299,  batch loss: 2.09357, batch accuracy: 0.43500
Time: 2018-07-15 00:28:15
TRAINING STATS: batch 286/486 in epoch 299,  batch loss: 2.04187, batch accuracy: 0.46150
Time: 2018-07-15 00:28:18
TRAINING STATS: batch 336/486 in epoch 299,  batch loss: 1.99633, batch accuracy: 0.46483
Time: 2018-07-15 00:28:22
TRAINING STATS: batch 386/486 in epoch 299,  batch loss: 2.03813, batch accuracy: 0.45300
Time: 2018-07-15 00:28:27
TRAINING STATS: batch 436/486 in epoch 299,  batch loss: 2.16521, batch accuracy: 0.42083
Time: 2018-07-15 00:28:30
TRAINING STATS: batch 0/486 in epoch 300,    batch loss: 2.24793, batch accuracy: 0.40483
Time: 2018-07-15 00:28:34
TRAINING STATS: batch 50/486 in epoch 300,   batch loss: 2.08236, batch accuracy: 0.44883
Time: 2018-07-15 00:28:39
TRAINING STATS: batch 100/486 in epoch 300,  batch loss: 2.14100, batch accuracy: 0.44167
Time: 2018-07-15 00:28:42
TRAINING STATS: batch 150/486 in epoch 300,  batch loss: 2.06671, batch accuracy: 0.46850
Time: 2018-07-15 00:28:46
TRAINING STATS: batch 200/486 in epoch 300,  batch loss: 2.04687, batch accuracy: 0.45783
Time: 2018-07-15 00:28:51
TRAINING STATS: batch 250/486 in epoch 300,  batch loss: 2.18031, batch accuracy: 0.40067
Time: 2018-07-15 00:28:54
TRAINING STATS: batch 300/486 in epoch 300,  batch loss: 2.23490, batch accuracy: 0.39617
Time: 2018-07-15 00:28:58
TRAINING STATS: batch 350/486 in epoch 300,  batch loss: 2.07979, batch accuracy: 0.45517
Time: 2018-07-15 00:29:03
TRAINING STATS: batch 400/486 in epoch 300,  batch loss: 1.93636, batch accuracy: 0.49200
Time: 2018-07-15 00:29:06
TRAINING STATS: batch 450/486 in epoch 300,  batch loss: 2.07889, batch accuracy: 0.43833
Time: 2018-07-15 00:29:10
TRAINING STATS: batch 14/486 in epoch 301,   batch loss: 1.98113, batch accuracy: 0.47250
Time: 2018-07-15 00:29:15
TRAINING STATS: batch 64/486 in epoch 301,   batch loss: 2.16304, batch accuracy: 0.42283
Time: 2018-07-15 00:29:18
TRAINING STATS: batch 114/486 in epoch 301,  batch loss: 2.13180, batch accuracy: 0.42183
Time: 2018-07-15 00:29:22
TRAINING STATS: batch 164/486 in epoch 301,  batch loss: 2.21829, batch accuracy: 0.40450
Time: 2018-07-15 00:29:27
TRAINING STATS: batch 214/486 in epoch 301,  batch loss: 2.08170, batch accuracy: 0.46167
Time: 2018-07-15 00:29:30
TRAINING STATS: batch 264/486 in epoch 301,  batch loss: 2.10503, batch accuracy: 0.43667
Time: 2018-07-15 00:29:34
TRAINING STATS: batch 314/486 in epoch 301,  batch loss: 2.08846, batch accuracy: 0.43183
Time: 2018-07-15 00:29:39
TRAINING STATS: batch 364/486 in epoch 301,  batch loss: 1.98666, batch accuracy: 0.47400
Time: 2018-07-15 00:29:43
TRAINING STATS: batch 414/486 in epoch 301,  batch loss: 1.94455, batch accuracy: 0.47717
Time: 2018-07-15 00:29:46
TRAINING STATS: batch 464/486 in epoch 301,  batch loss: 1.95481, batch accuracy: 0.47317
Time: 2018-07-15 00:29:51
TRAINING STATS: batch 28/486 in epoch 302,   batch loss: 1.99705, batch accuracy: 0.46500
Time: 2018-07-15 00:29:55
TRAINING STATS: batch 78/486 in epoch 302,   batch loss: 2.01004, batch accuracy: 0.46417
Time: 2018-07-15 00:29:58
TRAINING STATS: batch 128/486 in epoch 302,  batch loss: 2.16623, batch accuracy: 0.41283
Time: 2018-07-15 00:30:03
TRAINING STATS: batch 178/486 in epoch 302,  batch loss: 1.95316, batch accuracy: 0.48733
Time: 2018-07-15 00:30:07
TRAINING STATS: batch 228/486 in epoch 302,  batch loss: 1.95097, batch accuracy: 0.47517
Time: 2018-07-15 00:30:10
TRAINING STATS: batch 278/486 in epoch 302,  batch loss: 2.05851, batch accuracy: 0.45767
Time: 2018-07-15 00:30:15
TRAINING STATS: batch 328/486 in epoch 302,  batch loss: 2.03767, batch accuracy: 0.45417
Time: 2018-07-15 00:30:19
TRAINING STATS: batch 378/486 in epoch 302,  batch loss: 2.11374, batch accuracy: 0.43533
Time: 2018-07-15 00:30:22
TRAINING STATS: batch 428/486 in epoch 302,  batch loss: 2.15087, batch accuracy: 0.42400
Time: 2018-07-15 00:30:27
TRAINING STATS: batch 478/486 in epoch 302,  batch loss: 2.00344, batch accuracy: 0.47567
Time: 2018-07-15 00:30:31
TRAINING STATS: batch 42/486 in epoch 303,   batch loss: 1.89778, batch accuracy: 0.49750
Time: 2018-07-15 00:30:35
TRAINING STATS: batch 92/486 in epoch 303,   batch loss: 2.01525, batch accuracy: 0.46817
Time: 2018-07-15 00:30:39
TRAINING STATS: batch 142/486 in epoch 303,  batch loss: 2.85622, batch accuracy: 0.16950
Time: 2018-07-15 00:30:43
TRAINING STATS: batch 192/486 in epoch 303,  batch loss: 2.60293, batch accuracy: 0.24833
Time: 2018-07-15 00:30:47
TRAINING STATS: batch 242/486 in epoch 303,  batch loss: 2.49157, batch accuracy: 0.26067
Time: 2018-07-15 00:30:51
TRAINING STATS: batch 292/486 in epoch 303,  batch loss: 2.36826, batch accuracy: 0.33500
Time: 2018-07-15 00:30:55
TRAINING STATS: batch 342/486 in epoch 303,  batch loss: 2.24284, batch accuracy: 0.38883
Time: 2018-07-15 00:30:59
TRAINING STATS: batch 392/486 in epoch 303,  batch loss: 2.14709, batch accuracy: 0.42500
Time: 2018-07-15 00:31:03
TRAINING STATS: batch 442/486 in epoch 303,  batch loss: 2.14354, batch accuracy: 0.44233
Time: 2018-07-15 00:31:07
TRAINING STATS: batch 6/486 in epoch 304,    batch loss: 2.14814, batch accuracy: 0.43517
Time: 2018-07-15 00:31:11
TRAINING STATS: batch 56/486 in epoch 304,   batch loss: 2.08942, batch accuracy: 0.45317
Time: 2018-07-15 00:31:15
TRAINING STATS: batch 106/486 in epoch 304,  batch loss: 2.15856, batch accuracy: 0.42500
Time: 2018-07-15 00:31:19
TRAINING STATS: batch 156/486 in epoch 304,  batch loss: 2.17209, batch accuracy: 0.42017
Time: 2018-07-15 00:31:23
TRAINING STATS: batch 206/486 in epoch 304,  batch loss: 2.14358, batch accuracy: 0.42817
Time: 2018-07-15 00:31:28
TRAINING STATS: batch 256/486 in epoch 304,  batch loss: 2.07408, batch accuracy: 0.44283
Time: 2018-07-15 00:31:31
TRAINING STATS: batch 306/486 in epoch 304,  batch loss: 2.04353, batch accuracy: 0.45950
Time: 2018-07-15 00:31:35
TRAINING STATS: batch 356/486 in epoch 304,  batch loss: 2.03105, batch accuracy: 0.46083
Time: 2018-07-15 00:31:40
TRAINING STATS: batch 406/486 in epoch 304,  batch loss: 2.08172, batch accuracy: 0.43733
Time: 2018-07-15 00:31:43
TRAINING STATS: batch 456/486 in epoch 304,  batch loss: 1.90053, batch accuracy: 0.49583
Time: 2018-07-15 00:31:47
TRAINING STATS: batch 20/486 in epoch 305,   batch loss: 2.04877, batch accuracy: 0.45483
Time: 2018-07-15 00:31:52
TRAINING STATS: batch 70/486 in epoch 305,   batch loss: 1.90578, batch accuracy: 0.50050
Time: 2018-07-15 00:31:55
TRAINING STATS: batch 120/486 in epoch 305,  batch loss: 1.95025, batch accuracy: 0.48150
Time: 2018-07-15 00:31:59
TRAINING STATS: batch 170/486 in epoch 305,  batch loss: 1.94641, batch accuracy: 0.48800
Time: 2018-07-15 00:32:04
TRAINING STATS: batch 220/486 in epoch 305,  batch loss: 1.86093, batch accuracy: 0.50500
Time: 2018-07-15 00:32:07
TRAINING STATS: batch 270/486 in epoch 305,  batch loss: 1.92609, batch accuracy: 0.47233
Time: 2018-07-15 00:32:11
TRAINING STATS: batch 320/486 in epoch 305,  batch loss: 1.86625, batch accuracy: 0.49167
Time: 2018-07-15 00:32:16
TRAINING STATS: batch 370/486 in epoch 305,  batch loss: 2.14171, batch accuracy: 0.42967
Time: 2018-07-15 00:32:20
TRAINING STATS: batch 420/486 in epoch 305,  batch loss: 2.01207, batch accuracy: 0.46283
Time: 2018-07-15 00:32:23
TRAINING STATS: batch 470/486 in epoch 305,  batch loss: 2.01749, batch accuracy: 0.45267
Time: 2018-07-15 00:32:28
TRAINING STATS: batch 34/486 in epoch 306,   batch loss: 1.93673, batch accuracy: 0.48050
Time: 2018-07-15 00:32:31
TRAINING STATS: batch 84/486 in epoch 306,   batch loss: 1.89663, batch accuracy: 0.48533
Time: 2018-07-15 00:32:35
TRAINING STATS: batch 134/486 in epoch 306,  batch loss: 1.89310, batch accuracy: 0.49500
Time: 2018-07-15 00:32:40
TRAINING STATS: batch 184/486 in epoch 306,  batch loss: 1.90450, batch accuracy: 0.48150
Time: 2018-07-15 00:32:44
TRAINING STATS: batch 234/486 in epoch 306,  batch loss: 1.92552, batch accuracy: 0.48483
Time: 2018-07-15 00:32:47
TRAINING STATS: batch 284/486 in epoch 306,  batch loss: 1.91436, batch accuracy: 0.48817
Time: 2018-07-15 00:32:52
TRAINING STATS: batch 334/486 in epoch 306,  batch loss: 1.97264, batch accuracy: 0.47583
Time: 2018-07-15 00:32:56
TRAINING STATS: batch 384/486 in epoch 306,  batch loss: 1.85319, batch accuracy: 0.50150
Time: 2018-07-15 00:32:59
TRAINING STATS: batch 434/486 in epoch 306,  batch loss: 1.95897, batch accuracy: 0.46633
Time: 2018-07-15 00:33:04
TRAINING STATS: batch 484/486 in epoch 306,  batch loss: 1.87842, batch accuracy: 0.48517
Time: 2018-07-15 00:33:08
TRAINING STATS: batch 48/486 in epoch 307,   batch loss: 1.84802, batch accuracy: 0.49667
Time: 2018-07-15 00:33:11
TRAINING STATS: batch 98/486 in epoch 307,   batch loss: 1.85438, batch accuracy: 0.50000
Time: 2018-07-15 00:33:16
TRAINING STATS: batch 148/486 in epoch 307,  batch loss: 1.93958, batch accuracy: 0.47850
Time: 2018-07-15 00:33:20
TRAINING STATS: batch 198/486 in epoch 307,  batch loss: 2.10764, batch accuracy: 0.42400
Time: 2018-07-15 00:33:23
TRAINING STATS: batch 248/486 in epoch 307,  batch loss: 1.97437, batch accuracy: 0.47350
Time: 2018-07-15 00:33:28
TRAINING STATS: batch 298/486 in epoch 307,  batch loss: 1.91638, batch accuracy: 0.48467
Time: 2018-07-15 00:33:32
TRAINING STATS: batch 348/486 in epoch 307,  batch loss: 1.91624, batch accuracy: 0.48183
Time: 2018-07-15 00:33:36
TRAINING STATS: batch 398/486 in epoch 307,  batch loss: 1.91982, batch accuracy: 0.48017
Time: 2018-07-15 00:33:40
TRAINING STATS: batch 448/486 in epoch 307,  batch loss: 1.88880, batch accuracy: 0.49183
Time: 2018-07-15 00:33:44
TRAINING STATS: batch 12/486 in epoch 308,   batch loss: 1.90571, batch accuracy: 0.47683
Time: 2018-07-15 00:33:48
TRAINING STATS: batch 62/486 in epoch 308,   batch loss: 1.93467, batch accuracy: 0.47867
Time: 2018-07-15 00:33:52
TRAINING STATS: batch 112/486 in epoch 308,  batch loss: 1.85358, batch accuracy: 0.49633
Time: 2018-07-15 00:33:56
TRAINING STATS: batch 162/486 in epoch 308,  batch loss: 1.86265, batch accuracy: 0.50150
Time: 2018-07-15 00:34:00
TRAINING STATS: batch 212/486 in epoch 308,  batch loss: 1.76887, batch accuracy: 0.52417
Time: 2018-07-15 00:34:04
TRAINING STATS: batch 262/486 in epoch 308,  batch loss: 1.91726, batch accuracy: 0.48200
Time: 2018-07-15 00:34:08
TRAINING STATS: batch 312/486 in epoch 308,  batch loss: 1.99166, batch accuracy: 0.46467
Time: 2018-07-15 00:34:12
TRAINING STATS: batch 362/486 in epoch 308,  batch loss: 1.93888, batch accuracy: 0.48317
Time: 2018-07-15 00:34:16
TRAINING STATS: batch 412/486 in epoch 308,  batch loss: 1.82117, batch accuracy: 0.51583
Time: 2018-07-15 00:34:20
TRAINING STATS: batch 462/486 in epoch 308,  batch loss: 1.88271, batch accuracy: 0.49317
Time: 2018-07-15 00:34:24
TRAINING STATS: batch 26/486 in epoch 309,   batch loss: 1.88051, batch accuracy: 0.49717
Time: 2018-07-15 00:34:28
TRAINING STATS: batch 76/486 in epoch 309,   batch loss: 1.91081, batch accuracy: 0.48683
Time: 2018-07-15 00:34:32
TRAINING STATS: batch 126/486 in epoch 309,  batch loss: 1.88738, batch accuracy: 0.48333
Time: 2018-07-15 00:34:36
TRAINING STATS: batch 176/486 in epoch 309,  batch loss: 1.75242, batch accuracy: 0.52817
Time: 2018-07-15 00:34:41
TRAINING STATS: batch 226/486 in epoch 309,  batch loss: 1.81076, batch accuracy: 0.51017
Time: 2018-07-15 00:34:44
TRAINING STATS: batch 276/486 in epoch 309,  batch loss: 1.99423, batch accuracy: 0.45783
Time: 2018-07-15 00:34:48
TRAINING STATS: batch 326/486 in epoch 309,  batch loss: 1.94364, batch accuracy: 0.47117
Time: 2018-07-15 00:34:53
TRAINING STATS: batch 376/486 in epoch 309,  batch loss: 1.89934, batch accuracy: 0.49350
Time: 2018-07-15 00:34:56
TRAINING STATS: batch 426/486 in epoch 309,  batch loss: 1.85770, batch accuracy: 0.49300
Time: 2018-07-15 00:35:00
TRAINING STATS: batch 476/486 in epoch 309,  batch loss: 1.80235, batch accuracy: 0.51433
Time: 2018-07-15 00:35:05
TRAINING STATS: batch 40/486 in epoch 310,   batch loss: 1.79065, batch accuracy: 0.51967
Time: 2018-07-15 00:35:08
TRAINING STATS: batch 90/486 in epoch 310,   batch loss: 1.88722, batch accuracy: 0.49417
Time: 2018-07-15 00:35:12
TRAINING STATS: batch 140/486 in epoch 310,  batch loss: 1.88653, batch accuracy: 0.48750
Time: 2018-07-15 00:35:17
TRAINING STATS: batch 190/486 in epoch 310,  batch loss: 1.81700, batch accuracy: 0.51400
Time: 2018-07-15 00:35:20
TRAINING STATS: batch 240/486 in epoch 310,  batch loss: 2.00922, batch accuracy: 0.45933
Time: 2018-07-15 00:35:24
TRAINING STATS: batch 290/486 in epoch 310,  batch loss: 1.96918, batch accuracy: 0.46250
Time: 2018-07-15 00:35:29
TRAINING STATS: batch 340/486 in epoch 310,  batch loss: 1.97126, batch accuracy: 0.46450
Time: 2018-07-15 00:35:32
TRAINING STATS: batch 390/486 in epoch 310,  batch loss: 2.73715, batch accuracy: 0.19917
Time: 2018-07-15 00:35:36
TRAINING STATS: batch 440/486 in epoch 310,  batch loss: 2.48790, batch accuracy: 0.28467
Time: 2018-07-15 00:35:41
TRAINING STATS: batch 4/486 in epoch 311,    batch loss: 2.36784, batch accuracy: 0.34150
Time: 2018-07-15 00:35:45
TRAINING STATS: batch 54/486 in epoch 311,   batch loss: 2.34416, batch accuracy: 0.34250
Time: 2018-07-15 00:35:48
TRAINING STATS: batch 104/486 in epoch 311,  batch loss: 2.33560, batch accuracy: 0.34467
Time: 2018-07-15 00:35:53
TRAINING STATS: batch 154/486 in epoch 311,  batch loss: 2.29487, batch accuracy: 0.35200
Time: 2018-07-15 00:35:57
TRAINING STATS: batch 204/486 in epoch 311,  batch loss: 2.30967, batch accuracy: 0.35267
Time: 2018-07-15 00:36:00
TRAINING STATS: batch 254/486 in epoch 311,  batch loss: 2.19745, batch accuracy: 0.38417
Time: 2018-07-15 00:36:05
TRAINING STATS: batch 304/486 in epoch 311,  batch loss: 2.22019, batch accuracy: 0.39033
Time: 2018-07-15 00:36:09
TRAINING STATS: batch 354/486 in epoch 311,  batch loss: 2.20150, batch accuracy: 0.39700
Time: 2018-07-15 00:36:12
TRAINING STATS: batch 404/486 in epoch 311,  batch loss: 2.16668, batch accuracy: 0.40567
Time: 2018-07-15 00:36:17
TRAINING STATS: batch 454/486 in epoch 311,  batch loss: 2.05351, batch accuracy: 0.43733
Time: 2018-07-15 00:36:21
TRAINING STATS: batch 18/486 in epoch 312,   batch loss: 2.14488, batch accuracy: 0.41617
Time: 2018-07-15 00:36:25
TRAINING STATS: batch 68/486 in epoch 312,   batch loss: 2.02896, batch accuracy: 0.45767
Time: 2018-07-15 00:36:29
TRAINING STATS: batch 118/486 in epoch 312,  batch loss: 2.09173, batch accuracy: 0.43950
Time: 2018-07-15 00:36:33
TRAINING STATS: batch 168/486 in epoch 312,  batch loss: 2.03355, batch accuracy: 0.46233
Time: 2018-07-15 00:36:37
TRAINING STATS: batch 218/486 in epoch 312,  batch loss: 2.04212, batch accuracy: 0.45717
Time: 2018-07-15 00:36:41
TRAINING STATS: batch 268/486 in epoch 312,  batch loss: 1.98859, batch accuracy: 0.46833
Time: 2018-07-15 00:36:45
TRAINING STATS: batch 318/486 in epoch 312,  batch loss: 2.04509, batch accuracy: 0.44467
Time: 2018-07-15 00:36:49
TRAINING STATS: batch 368/486 in epoch 312,  batch loss: 2.08890, batch accuracy: 0.44250
Time: 2018-07-15 00:36:53
TRAINING STATS: batch 418/486 in epoch 312,  batch loss: 2.06412, batch accuracy: 0.44700
Time: 2018-07-15 00:36:57
TRAINING STATS: batch 468/486 in epoch 312,  batch loss: 2.00859, batch accuracy: 0.47433
Time: 2018-07-15 00:37:01
TRAINING STATS: batch 32/486 in epoch 313,   batch loss: 1.96430, batch accuracy: 0.47067
Time: 2018-07-15 00:37:05
TRAINING STATS: batch 82/486 in epoch 313,   batch loss: 2.03146, batch accuracy: 0.45983
Time: 2018-07-15 00:37:09
TRAINING STATS: batch 132/486 in epoch 313,  batch loss: 1.97430, batch accuracy: 0.47883
Time: 2018-07-15 00:37:13
TRAINING STATS: batch 182/486 in epoch 313,  batch loss: 2.02207, batch accuracy: 0.45617
Time: 2018-07-15 00:37:17
TRAINING STATS: batch 232/486 in epoch 313,  batch loss: 2.12430, batch accuracy: 0.44067
Time: 2018-07-15 00:37:21
TRAINING STATS: batch 282/486 in epoch 313,  batch loss: 2.03316, batch accuracy: 0.46417
Time: 2018-07-15 00:37:25
TRAINING STATS: batch 332/486 in epoch 313,  batch loss: 2.27520, batch accuracy: 0.36717
Time: 2018-07-15 00:37:29
TRAINING STATS: batch 382/486 in epoch 313,  batch loss: 2.11499, batch accuracy: 0.43683
Time: 2018-07-15 00:37:33
TRAINING STATS: batch 432/486 in epoch 313,  batch loss: 2.07844, batch accuracy: 0.44650
Time: 2018-07-15 00:37:37
TRAINING STATS: batch 482/486 in epoch 313,  batch loss: 2.06054, batch accuracy: 0.45217
Time: 2018-07-15 00:37:42
TRAINING STATS: batch 46/486 in epoch 314,   batch loss: 2.04467, batch accuracy: 0.45917
Time: 2018-07-15 00:37:45
TRAINING STATS: batch 96/486 in epoch 314,   batch loss: 2.09876, batch accuracy: 0.44133
Time: 2018-07-15 00:37:49
TRAINING STATS: batch 146/486 in epoch 314,  batch loss: 2.07826, batch accuracy: 0.45433
Time: 2018-07-15 00:37:54
TRAINING STATS: batch 196/486 in epoch 314,  batch loss: 2.08815, batch accuracy: 0.44383
Time: 2018-07-15 00:37:57
TRAINING STATS: batch 246/486 in epoch 314,  batch loss: 2.00143, batch accuracy: 0.47050
Time: 2018-07-15 00:38:01
TRAINING STATS: batch 296/486 in epoch 314,  batch loss: 1.98533, batch accuracy: 0.47733
Time: 2018-07-15 00:38:06
TRAINING STATS: batch 346/486 in epoch 314,  batch loss: 1.95059, batch accuracy: 0.48383
Time: 2018-07-15 00:38:09
TRAINING STATS: batch 396/486 in epoch 314,  batch loss: 1.95407, batch accuracy: 0.48150
Time: 2018-07-15 00:38:13
TRAINING STATS: batch 446/486 in epoch 314,  batch loss: 1.96372, batch accuracy: 0.47550
Time: 2018-07-15 00:38:18
TRAINING STATS: batch 10/486 in epoch 315,   batch loss: 1.98602, batch accuracy: 0.46533
Time: 2018-07-15 00:38:21
TRAINING STATS: batch 60/486 in epoch 315,   batch loss: 1.93395, batch accuracy: 0.48717
Time: 2018-07-15 00:38:25
TRAINING STATS: batch 110/486 in epoch 315,  batch loss: 1.95874, batch accuracy: 0.48483
Time: 2018-07-15 00:38:30
TRAINING STATS: batch 160/486 in epoch 315,  batch loss: 1.89450, batch accuracy: 0.50183
Time: 2018-07-15 00:38:33
TRAINING STATS: batch 210/486 in epoch 315,  batch loss: 1.85796, batch accuracy: 0.50700
Time: 2018-07-15 00:38:37
TRAINING STATS: batch 260/486 in epoch 315,  batch loss: 1.93538, batch accuracy: 0.48150
Time: 2018-07-15 00:38:42
TRAINING STATS: batch 310/486 in epoch 315,  batch loss: 1.91023, batch accuracy: 0.48217
Time: 2018-07-15 00:38:45
TRAINING STATS: batch 360/486 in epoch 315,  batch loss: 1.92052, batch accuracy: 0.48883
Time: 2018-07-15 00:38:49
TRAINING STATS: batch 410/486 in epoch 315,  batch loss: 1.87197, batch accuracy: 0.50717
Time: 2018-07-15 00:38:54
TRAINING STATS: batch 460/486 in epoch 315,  batch loss: 2.01123, batch accuracy: 0.45883
Time: 2018-07-15 00:38:58
TRAINING STATS: batch 24/486 in epoch 316,   batch loss: 1.95372, batch accuracy: 0.47950
Time: 2018-07-15 00:39:01
TRAINING STATS: batch 74/486 in epoch 316,   batch loss: 1.95237, batch accuracy: 0.46550
Time: 2018-07-15 00:39:06
TRAINING STATS: batch 124/486 in epoch 316,  batch loss: 2.07015, batch accuracy: 0.45300
Time: 2018-07-15 00:39:10
TRAINING STATS: batch 174/486 in epoch 316,  batch loss: 1.97182, batch accuracy: 0.47700
Time: 2018-07-15 00:39:13
TRAINING STATS: batch 224/486 in epoch 316,  batch loss: 1.92626, batch accuracy: 0.48433
Time: 2018-07-15 00:39:18
TRAINING STATS: batch 274/486 in epoch 316,  batch loss: 1.89607, batch accuracy: 0.49217
Time: 2018-07-15 00:39:22
TRAINING STATS: batch 324/486 in epoch 316,  batch loss: 1.91831, batch accuracy: 0.49033
Time: 2018-07-15 00:39:25
TRAINING STATS: batch 374/486 in epoch 316,  batch loss: 1.92238, batch accuracy: 0.49617
Time: 2018-07-15 00:39:30
TRAINING STATS: batch 424/486 in epoch 316,  batch loss: 1.83712, batch accuracy: 0.50967
Time: 2018-07-15 00:39:34
TRAINING STATS: batch 474/486 in epoch 316,  batch loss: 1.98363, batch accuracy: 0.46517
Time: 2018-07-15 00:39:38
TRAINING STATS: batch 38/486 in epoch 317,   batch loss: 1.90531, batch accuracy: 0.50283
Time: 2018-07-15 00:39:42
TRAINING STATS: batch 88/486 in epoch 317,   batch loss: 1.90941, batch accuracy: 0.48217
Time: 2018-07-15 00:39:46
TRAINING STATS: batch 138/486 in epoch 317,  batch loss: 1.94674, batch accuracy: 0.48750
Time: 2018-07-15 00:39:50
TRAINING STATS: batch 188/486 in epoch 317,  batch loss: 1.82761, batch accuracy: 0.51683
Time: 2018-07-15 00:39:54
TRAINING STATS: batch 238/486 in epoch 317,  batch loss: 1.85464, batch accuracy: 0.50967
Time: 2018-07-15 00:39:58
TRAINING STATS: batch 288/486 in epoch 317,  batch loss: 1.87076, batch accuracy: 0.49033
Time: 2018-07-15 00:40:02
TRAINING STATS: batch 338/486 in epoch 317,  batch loss: 2.00540, batch accuracy: 0.46067
Time: 2018-07-15 00:40:06
TRAINING STATS: batch 388/486 in epoch 317,  batch loss: 1.88533, batch accuracy: 0.49467
Time: 2018-07-15 00:40:10
TRAINING STATS: batch 438/486 in epoch 317,  batch loss: 1.88398, batch accuracy: 0.50633
Time: 2018-07-15 00:40:14
TRAINING STATS: batch 2/486 in epoch 318,    batch loss: 1.87217, batch accuracy: 0.49867
Time: 2018-07-15 00:40:19
TRAINING STATS: batch 52/486 in epoch 318,   batch loss: 1.93157, batch accuracy: 0.47817
Time: 2018-07-15 00:40:22
TRAINING STATS: batch 102/486 in epoch 318,  batch loss: 1.88802, batch accuracy: 0.49217
Time: 2018-07-15 00:40:26
TRAINING STATS: batch 152/486 in epoch 318,  batch loss: 1.80755, batch accuracy: 0.50833
Time: 2018-07-15 00:40:31
TRAINING STATS: batch 202/486 in epoch 318,  batch loss: 1.86059, batch accuracy: 0.50217
Time: 2018-07-15 00:40:34
TRAINING STATS: batch 252/486 in epoch 318,  batch loss: 1.81263, batch accuracy: 0.51283
Time: 2018-07-15 00:40:38
TRAINING STATS: batch 302/486 in epoch 318,  batch loss: 2.01052, batch accuracy: 0.45867
Time: 2018-07-15 00:40:43
TRAINING STATS: batch 352/486 in epoch 318,  batch loss: 1.85946, batch accuracy: 0.51033
Time: 2018-07-15 00:40:46
TRAINING STATS: batch 402/486 in epoch 318,  batch loss: 1.70450, batch accuracy: 0.55450
Time: 2018-07-15 00:40:50
TRAINING STATS: batch 452/486 in epoch 318,  batch loss: 1.81773, batch accuracy: 0.50667
Time: 2018-07-15 00:40:55
TRAINING STATS: batch 16/486 in epoch 319,   batch loss: 1.78771, batch accuracy: 0.51650
Time: 2018-07-15 00:40:58
TRAINING STATS: batch 66/486 in epoch 319,   batch loss: 1.80632, batch accuracy: 0.51067
Time: 2018-07-15 00:41:02
TRAINING STATS: batch 116/486 in epoch 319,  batch loss: 1.78160, batch accuracy: 0.52583
Time: 2018-07-15 00:41:07
TRAINING STATS: batch 166/486 in epoch 319,  batch loss: 1.73665, batch accuracy: 0.54500
Time: 2018-07-15 00:41:10
TRAINING STATS: batch 216/486 in epoch 319,  batch loss: 1.81288, batch accuracy: 0.51283
Time: 2018-07-15 00:41:14
TRAINING STATS: batch 266/486 in epoch 319,  batch loss: 1.81641, batch accuracy: 0.51867
Time: 2018-07-15 00:41:19
TRAINING STATS: batch 316/486 in epoch 319,  batch loss: 1.78358, batch accuracy: 0.51533
Time: 2018-07-15 00:41:22
TRAINING STATS: batch 366/486 in epoch 319,  batch loss: 1.86546, batch accuracy: 0.49800
Time: 2018-07-15 00:41:26
TRAINING STATS: batch 416/486 in epoch 319,  batch loss: 1.93153, batch accuracy: 0.48583
Time: 2018-07-15 00:41:31
TRAINING STATS: batch 466/486 in epoch 319,  batch loss: 1.71379, batch accuracy: 0.55083
Time: 2018-07-15 00:41:34
TRAINING STATS: batch 30/486 in epoch 320,   batch loss: 1.75253, batch accuracy: 0.53750
Time: 2018-07-15 00:41:38
TRAINING STATS: batch 80/486 in epoch 320,   batch loss: 1.84989, batch accuracy: 0.51083
Time: 2018-07-15 00:41:43
TRAINING STATS: batch 130/486 in epoch 320,  batch loss: 1.85310, batch accuracy: 0.50983
Time: 2018-07-15 00:41:47
TRAINING STATS: batch 180/486 in epoch 320,  batch loss: 1.85421, batch accuracy: 0.50683
Time: 2018-07-15 00:41:50
TRAINING STATS: batch 230/486 in epoch 320,  batch loss: 1.85762, batch accuracy: 0.49650
Time: 2018-07-15 00:41:55
TRAINING STATS: batch 280/486 in epoch 320,  batch loss: 2.16809, batch accuracy: 0.40833
Time: 2018-07-15 00:41:59
TRAINING STATS: batch 330/486 in epoch 320,  batch loss: 2.34537, batch accuracy: 0.32467
Time: 2018-07-15 00:42:02
TRAINING STATS: batch 380/486 in epoch 320,  batch loss: 2.17267, batch accuracy: 0.41483
Time: 2018-07-15 00:42:07
TRAINING STATS: batch 430/486 in epoch 320,  batch loss: 2.08344, batch accuracy: 0.44767
Time: 2018-07-15 00:42:11
TRAINING STATS: batch 480/486 in epoch 320,  batch loss: 2.11727, batch accuracy: 0.43533
Time: 2018-07-15 00:42:14
TRAINING STATS: batch 44/486 in epoch 321,   batch loss: 2.04641, batch accuracy: 0.45083
Time: 2018-07-15 00:42:19
TRAINING STATS: batch 94/486 in epoch 321,   batch loss: 2.06678, batch accuracy: 0.45417
Time: 2018-07-15 00:42:23
TRAINING STATS: batch 144/486 in epoch 321,  batch loss: 2.06616, batch accuracy: 0.44733
Time: 2018-07-15 00:42:27
TRAINING STATS: batch 194/486 in epoch 321,  batch loss: 2.08216, batch accuracy: 0.43383
Time: 2018-07-15 00:42:31
TRAINING STATS: batch 244/486 in epoch 321,  batch loss: 1.96524, batch accuracy: 0.48350
Time: 2018-07-15 00:42:35
TRAINING STATS: batch 294/486 in epoch 321,  batch loss: 1.90345, batch accuracy: 0.50067
Time: 2018-07-15 00:42:39
TRAINING STATS: batch 344/486 in epoch 321,  batch loss: 1.93535, batch accuracy: 0.49433
Time: 2018-07-15 00:42:43
TRAINING STATS: batch 394/486 in epoch 321,  batch loss: 1.90876, batch accuracy: 0.50233
Time: 2018-07-15 00:42:47
TRAINING STATS: batch 444/486 in epoch 321,  batch loss: 1.85809, batch accuracy: 0.51250
Time: 2018-07-15 00:42:51
TRAINING STATS: batch 8/486 in epoch 322,    batch loss: 1.88453, batch accuracy: 0.50433
Time: 2018-07-15 00:42:55
TRAINING STATS: batch 58/486 in epoch 322,   batch loss: 1.86913, batch accuracy: 0.51383
Time: 2018-07-15 00:42:59
TRAINING STATS: batch 108/486 in epoch 322,  batch loss: 1.96787, batch accuracy: 0.47850
Time: 2018-07-15 00:43:03
TRAINING STATS: batch 158/486 in epoch 322,  batch loss: 1.94574, batch accuracy: 0.48067
Time: 2018-07-15 00:43:08
TRAINING STATS: batch 208/486 in epoch 322,  batch loss: 1.93689, batch accuracy: 0.48433
Time: 2018-07-15 00:43:11
TRAINING STATS: batch 258/486 in epoch 322,  batch loss: 1.84419, batch accuracy: 0.51217
Time: 2018-07-15 00:43:15
TRAINING STATS: batch 308/486 in epoch 322,  batch loss: 1.89105, batch accuracy: 0.50133
Time: 2018-07-15 00:43:20
TRAINING STATS: batch 358/486 in epoch 322,  batch loss: 1.90668, batch accuracy: 0.49533
Time: 2018-07-15 00:43:23
TRAINING STATS: batch 408/486 in epoch 322,  batch loss: 1.91142, batch accuracy: 0.48483
Time: 2018-07-15 00:43:27
TRAINING STATS: batch 458/486 in epoch 322,  batch loss: 1.88816, batch accuracy: 0.50550
Time: 2018-07-15 00:43:32
TRAINING STATS: batch 22/486 in epoch 323,   batch loss: 1.91454, batch accuracy: 0.50517
Time: 2018-07-15 00:43:35
TRAINING STATS: batch 72/486 in epoch 323,   batch loss: 1.89116, batch accuracy: 0.50150
Time: 2018-07-15 00:43:39
TRAINING STATS: batch 122/486 in epoch 323,  batch loss: 1.82114, batch accuracy: 0.53250
Time: 2018-07-15 00:43:44
TRAINING STATS: batch 172/486 in epoch 323,  batch loss: 1.91781, batch accuracy: 0.49400
Time: 2018-07-15 00:43:48
TRAINING STATS: batch 222/486 in epoch 323,  batch loss: 1.92927, batch accuracy: 0.48617
Time: 2018-07-15 00:43:51
TRAINING STATS: batch 272/486 in epoch 323,  batch loss: 1.90253, batch accuracy: 0.48533
Time: 2018-07-15 00:43:56
TRAINING STATS: batch 322/486 in epoch 323,  batch loss: 1.84738, batch accuracy: 0.51067
Time: 2018-07-15 00:43:59
TRAINING STATS: batch 372/486 in epoch 323,  batch loss: 1.80173, batch accuracy: 0.52367
Time: 2018-07-15 00:44:03
TRAINING STATS: batch 422/486 in epoch 323,  batch loss: 1.83492, batch accuracy: 0.51450
Time: 2018-07-15 00:44:08
TRAINING STATS: batch 472/486 in epoch 323,  batch loss: 1.92725, batch accuracy: 0.47800
Time: 2018-07-15 00:44:12
TRAINING STATS: batch 36/486 in epoch 324,   batch loss: 1.89445, batch accuracy: 0.49900
Time: 2018-07-15 00:44:15
TRAINING STATS: batch 86/486 in epoch 324,   batch loss: 1.86908, batch accuracy: 0.51183
Time: 2018-07-15 00:44:20
TRAINING STATS: batch 136/486 in epoch 324,  batch loss: 1.90467, batch accuracy: 0.48817
Time: 2018-07-15 00:44:24
TRAINING STATS: batch 186/486 in epoch 324,  batch loss: 1.85893, batch accuracy: 0.50267
Time: 2018-07-15 00:44:27
TRAINING STATS: batch 236/486 in epoch 324,  batch loss: 1.89465, batch accuracy: 0.49150
Time: 2018-07-15 00:44:32
TRAINING STATS: batch 286/486 in epoch 324,  batch loss: 1.87024, batch accuracy: 0.50050
Time: 2018-07-15 00:44:36
TRAINING STATS: batch 336/486 in epoch 324,  batch loss: 1.82695, batch accuracy: 0.51150
Time: 2018-07-15 00:44:39
TRAINING STATS: batch 386/486 in epoch 324,  batch loss: 1.86605, batch accuracy: 0.50033
Time: 2018-07-15 00:44:44
TRAINING STATS: batch 436/486 in epoch 324,  batch loss: 1.84737, batch accuracy: 0.50733
Time: 2018-07-15 00:44:48
TRAINING STATS: batch 0/486 in epoch 325,    batch loss: 1.81699, batch accuracy: 0.51783
Time: 2018-07-15 00:44:51
TRAINING STATS: batch 50/486 in epoch 325,   batch loss: 1.77777, batch accuracy: 0.53317
Time: 2018-07-15 00:44:56
TRAINING STATS: batch 100/486 in epoch 325,  batch loss: 1.83276, batch accuracy: 0.51500
Time: 2018-07-15 00:45:00
TRAINING STATS: batch 150/486 in epoch 325,  batch loss: 1.78752, batch accuracy: 0.53383
Time: 2018-07-15 00:45:03
TRAINING STATS: batch 200/486 in epoch 325,  batch loss: 1.70799, batch accuracy: 0.54700
Time: 2018-07-15 00:45:08
TRAINING STATS: batch 250/486 in epoch 325,  batch loss: 1.89311, batch accuracy: 0.49217
Time: 2018-07-15 00:45:12
TRAINING STATS: batch 300/486 in epoch 325,  batch loss: 1.85665, batch accuracy: 0.49917
Time: 2018-07-15 00:45:16
TRAINING STATS: batch 350/486 in epoch 325,  batch loss: 1.83435, batch accuracy: 0.51950
Time: 2018-07-15 00:45:20
TRAINING STATS: batch 400/486 in epoch 325,  batch loss: 1.71570, batch accuracy: 0.55133
Time: 2018-07-15 00:45:24
TRAINING STATS: batch 450/486 in epoch 325,  batch loss: 1.85871, batch accuracy: 0.49150
Time: 2018-07-15 00:45:28
TRAINING STATS: batch 14/486 in epoch 326,   batch loss: 1.72859, batch accuracy: 0.54000
Time: 2018-07-15 00:45:32
TRAINING STATS: batch 64/486 in epoch 326,   batch loss: 1.89929, batch accuracy: 0.49133
Time: 2018-07-15 00:45:36
TRAINING STATS: batch 114/486 in epoch 326,  batch loss: 1.84232, batch accuracy: 0.50767
Time: 2018-07-15 00:45:40
TRAINING STATS: batch 164/486 in epoch 326,  batch loss: 1.74209, batch accuracy: 0.54367
Time: 2018-07-15 00:45:44
TRAINING STATS: batch 214/486 in epoch 326,  batch loss: 1.79804, batch accuracy: 0.52150
Time: 2018-07-15 00:45:48
TRAINING STATS: batch 264/486 in epoch 326,  batch loss: 1.88063, batch accuracy: 0.49667
Time: 2018-07-15 00:45:52
TRAINING STATS: batch 314/486 in epoch 326,  batch loss: 1.88144, batch accuracy: 0.49567
Time: 2018-07-15 00:45:56
TRAINING STATS: batch 364/486 in epoch 326,  batch loss: 1.79290, batch accuracy: 0.53000
Time: 2018-07-15 00:46:00
TRAINING STATS: batch 414/486 in epoch 326,  batch loss: 1.73422, batch accuracy: 0.53750
Time: 2018-07-15 00:46:04
TRAINING STATS: batch 464/486 in epoch 326,  batch loss: 1.78741, batch accuracy: 0.52067
Time: 2018-07-15 00:46:08
TRAINING STATS: batch 28/486 in epoch 327,   batch loss: 1.72771, batch accuracy: 0.54433
Time: 2018-07-15 00:46:12
TRAINING STATS: batch 78/486 in epoch 327,   batch loss: 1.79713, batch accuracy: 0.52133
Time: 2018-07-15 00:46:16
TRAINING STATS: batch 128/486 in epoch 327,  batch loss: 1.76147, batch accuracy: 0.52850
Time: 2018-07-15 00:46:21
TRAINING STATS: batch 178/486 in epoch 327,  batch loss: 1.69417, batch accuracy: 0.54950
Time: 2018-07-15 00:46:24
TRAINING STATS: batch 228/486 in epoch 327,  batch loss: 1.73983, batch accuracy: 0.54050
Time: 2018-07-15 00:46:28
TRAINING STATS: batch 278/486 in epoch 327,  batch loss: 1.72741, batch accuracy: 0.53850
Time: 2018-07-15 00:46:33
TRAINING STATS: batch 328/486 in epoch 327,  batch loss: 1.79984, batch accuracy: 0.52617
Time: 2018-07-15 00:46:36
TRAINING STATS: batch 378/486 in epoch 327,  batch loss: 1.91462, batch accuracy: 0.49983
Time: 2018-07-15 00:46:40
TRAINING STATS: batch 428/486 in epoch 327,  batch loss: 1.88646, batch accuracy: 0.50550
Time: 2018-07-15 00:46:45
TRAINING STATS: batch 478/486 in epoch 327,  batch loss: 1.83577, batch accuracy: 0.51750
Time: 2018-07-15 00:46:48
TRAINING STATS: batch 42/486 in epoch 328,   batch loss: 1.73250, batch accuracy: 0.54667
Time: 2018-07-15 00:46:52
TRAINING STATS: batch 92/486 in epoch 328,   batch loss: 1.82993, batch accuracy: 0.51667
Time: 2018-07-15 00:46:57
TRAINING STATS: batch 142/486 in epoch 328,  batch loss: 1.75995, batch accuracy: 0.53550
Time: 2018-07-15 00:47:00
TRAINING STATS: batch 192/486 in epoch 328,  batch loss: 1.78567, batch accuracy: 0.53083
Time: 2018-07-15 00:47:04
TRAINING STATS: batch 242/486 in epoch 328,  batch loss: 1.76226, batch accuracy: 0.53333
Time: 2018-07-15 00:47:09
TRAINING STATS: batch 292/486 in epoch 328,  batch loss: 1.77664, batch accuracy: 0.52983
Time: 2018-07-15 00:47:12
TRAINING STATS: batch 342/486 in epoch 328,  batch loss: 1.75922, batch accuracy: 0.53317
Time: 2018-07-15 00:47:16
TRAINING STATS: batch 392/486 in epoch 328,  batch loss: 1.69310, batch accuracy: 0.55133
Time: 2018-07-15 00:47:21
TRAINING STATS: batch 442/486 in epoch 328,  batch loss: 1.89028, batch accuracy: 0.50317
Time: 2018-07-15 00:47:24
TRAINING STATS: batch 6/486 in epoch 329,    batch loss: 1.90626, batch accuracy: 0.49617
Time: 2018-07-15 00:47:28
TRAINING STATS: batch 56/486 in epoch 329,   batch loss: 1.90184, batch accuracy: 0.48967
Time: 2018-07-15 00:47:33
TRAINING STATS: batch 106/486 in epoch 329,  batch loss: 1.91030, batch accuracy: 0.48733
Time: 2018-07-15 00:47:36
TRAINING STATS: batch 156/486 in epoch 329,  batch loss: 1.87335, batch accuracy: 0.50233
Time: 2018-07-15 00:47:40
TRAINING STATS: batch 206/486 in epoch 329,  batch loss: 1.91500, batch accuracy: 0.49417
Time: 2018-07-15 00:47:45
TRAINING STATS: batch 256/486 in epoch 329,  batch loss: 1.77293, batch accuracy: 0.53567
Time: 2018-07-15 00:47:48
TRAINING STATS: batch 306/486 in epoch 329,  batch loss: 1.81427, batch accuracy: 0.52217
Time: 2018-07-15 00:47:52
TRAINING STATS: batch 356/486 in epoch 329,  batch loss: 1.84972, batch accuracy: 0.50933
Time: 2018-07-15 00:47:57
TRAINING STATS: batch 406/486 in epoch 329,  batch loss: 1.86827, batch accuracy: 0.49633
Time: 2018-07-15 00:48:00
TRAINING STATS: batch 456/486 in epoch 329,  batch loss: 1.69861, batch accuracy: 0.55700
Time: 2018-07-15 00:48:04
TRAINING STATS: batch 20/486 in epoch 330,   batch loss: 1.80661, batch accuracy: 0.52033
Time: 2018-07-15 00:48:09
TRAINING STATS: batch 70/486 in epoch 330,   batch loss: 1.72800, batch accuracy: 0.54917
Time: 2018-07-15 00:48:12
TRAINING STATS: batch 120/486 in epoch 330,  batch loss: 1.82083, batch accuracy: 0.51600
Time: 2018-07-15 00:48:16
TRAINING STATS: batch 170/486 in epoch 330,  batch loss: 2.27270, batch accuracy: 0.37617
Time: 2018-07-15 00:48:21
TRAINING STATS: batch 220/486 in epoch 330,  batch loss: 2.22490, batch accuracy: 0.38583
Time: 2018-07-15 00:48:25
TRAINING STATS: batch 270/486 in epoch 330,  batch loss: 2.16927, batch accuracy: 0.39417
Time: 2018-07-15 00:48:28
TRAINING STATS: batch 320/486 in epoch 330,  batch loss: 2.08661, batch accuracy: 0.43300
Time: 2018-07-15 00:48:33
TRAINING STATS: batch 370/486 in epoch 330,  batch loss: 2.11402, batch accuracy: 0.43383
Time: 2018-07-15 00:48:37
TRAINING STATS: batch 420/486 in epoch 330,  batch loss: 2.12165, batch accuracy: 0.43633
Time: 2018-07-15 00:48:40
TRAINING STATS: batch 470/486 in epoch 330,  batch loss: 2.15564, batch accuracy: 0.43083
Time: 2018-07-15 00:48:45
TRAINING STATS: batch 34/486 in epoch 331,   batch loss: 2.10715, batch accuracy: 0.43317
Time: 2018-07-15 00:48:49
TRAINING STATS: batch 84/486 in epoch 331,   batch loss: 2.08316, batch accuracy: 0.45717
Time: 2018-07-15 00:48:52
TRAINING STATS: batch 134/486 in epoch 331,  batch loss: 2.09866, batch accuracy: 0.45050
Time: 2018-07-15 00:48:57
TRAINING STATS: batch 184/486 in epoch 331,  batch loss: 2.13795, batch accuracy: 0.42617
Time: 2018-07-15 00:49:01
TRAINING STATS: batch 234/486 in epoch 331,  batch loss: 2.11044, batch accuracy: 0.44250
Time: 2018-07-15 00:49:04
TRAINING STATS: batch 284/486 in epoch 331,  batch loss: 2.06260, batch accuracy: 0.45750
Time: 2018-07-15 00:49:09
TRAINING STATS: batch 334/486 in epoch 331,  batch loss: 2.02005, batch accuracy: 0.46067
Time: 2018-07-15 00:49:13
TRAINING STATS: batch 384/486 in epoch 331,  batch loss: 1.94434, batch accuracy: 0.49867
Time: 2018-07-15 00:49:16
TRAINING STATS: batch 434/486 in epoch 331,  batch loss: 2.00005, batch accuracy: 0.46567
Time: 2018-07-15 00:49:21
TRAINING STATS: batch 484/486 in epoch 331,  batch loss: 1.96733, batch accuracy: 0.48483
Time: 2018-07-15 00:49:25
TRAINING STATS: batch 48/486 in epoch 332,   batch loss: 1.89850, batch accuracy: 0.49567
Time: 2018-07-15 00:49:28
TRAINING STATS: batch 98/486 in epoch 332,   batch loss: 1.86377, batch accuracy: 0.51583
Time: 2018-07-15 00:49:33
TRAINING STATS: batch 148/486 in epoch 332,  batch loss: 2.00286, batch accuracy: 0.47317
Time: 2018-07-15 00:49:37
TRAINING STATS: batch 198/486 in epoch 332,  batch loss: 1.87257, batch accuracy: 0.51133
Time: 2018-07-15 00:49:40
TRAINING STATS: batch 248/486 in epoch 332,  batch loss: 1.90014, batch accuracy: 0.50717
Time: 2018-07-15 00:49:45
TRAINING STATS: batch 298/486 in epoch 332,  batch loss: 1.87943, batch accuracy: 0.50000
Time: 2018-07-15 00:49:49
TRAINING STATS: batch 348/486 in epoch 332,  batch loss: 1.87123, batch accuracy: 0.51350
Time: 2018-07-15 00:49:53
TRAINING STATS: batch 398/486 in epoch 332,  batch loss: 1.85724, batch accuracy: 0.51217
Time: 2018-07-15 00:49:57
TRAINING STATS: batch 448/486 in epoch 332,  batch loss: 1.85155, batch accuracy: 0.51850
Time: 2018-07-15 00:50:01
TRAINING STATS: batch 12/486 in epoch 333,   batch loss: 1.89284, batch accuracy: 0.48583
Time: 2018-07-15 00:50:05
TRAINING STATS: batch 62/486 in epoch 333,   batch loss: 1.91057, batch accuracy: 0.49533
Time: 2018-07-15 00:50:09
TRAINING STATS: batch 112/486 in epoch 333,  batch loss: 1.82863, batch accuracy: 0.52067
Time: 2018-07-15 00:50:13
TRAINING STATS: batch 162/486 in epoch 333,  batch loss: 1.85057, batch accuracy: 0.51750
Time: 2018-07-15 00:50:17
TRAINING STATS: batch 212/486 in epoch 333,  batch loss: 1.75260, batch accuracy: 0.55050
Time: 2018-07-15 00:50:21
TRAINING STATS: batch 262/486 in epoch 333,  batch loss: 1.88643, batch accuracy: 0.50200
Time: 2018-07-15 00:50:25
TRAINING STATS: batch 312/486 in epoch 333,  batch loss: 1.83945, batch accuracy: 0.51583
Time: 2018-07-15 00:50:29
TRAINING STATS: batch 362/486 in epoch 333,  batch loss: 1.83615, batch accuracy: 0.51500
Time: 2018-07-15 00:50:33
TRAINING STATS: batch 412/486 in epoch 333,  batch loss: 1.79421, batch accuracy: 0.53550
Time: 2018-07-15 00:50:37
TRAINING STATS: batch 462/486 in epoch 333,  batch loss: 1.84130, batch accuracy: 0.50667
Time: 2018-07-15 00:50:41
TRAINING STATS: batch 26/486 in epoch 334,   batch loss: 1.84337, batch accuracy: 0.51383
Time: 2018-07-15 00:50:45
TRAINING STATS: batch 76/486 in epoch 334,   batch loss: 1.88965, batch accuracy: 0.49967
Time: 2018-07-15 00:50:49
TRAINING STATS: batch 126/486 in epoch 334,  batch loss: 1.85583, batch accuracy: 0.50883
Time: 2018-07-15 00:50:53
TRAINING STATS: batch 176/486 in epoch 334,  batch loss: 1.76973, batch accuracy: 0.53483
Time: 2018-07-15 00:50:57
TRAINING STATS: batch 226/486 in epoch 334,  batch loss: 1.80021, batch accuracy: 0.52550
Time: 2018-07-15 00:51:01
TRAINING STATS: batch 276/486 in epoch 334,  batch loss: 1.80571, batch accuracy: 0.52700
Time: 2018-07-15 00:51:05
TRAINING STATS: batch 326/486 in epoch 334,  batch loss: 1.85360, batch accuracy: 0.50683
Time: 2018-07-15 00:51:10
TRAINING STATS: batch 376/486 in epoch 334,  batch loss: 1.83326, batch accuracy: 0.51567
Time: 2018-07-15 00:51:13
TRAINING STATS: batch 426/486 in epoch 334,  batch loss: 1.89522, batch accuracy: 0.49033
Time: 2018-07-15 00:51:17
TRAINING STATS: batch 476/486 in epoch 334,  batch loss: 1.77240, batch accuracy: 0.54533
Time: 2018-07-15 00:51:22
TRAINING STATS: batch 40/486 in epoch 335,   batch loss: 1.77094, batch accuracy: 0.53300
Time: 2018-07-15 00:51:25
TRAINING STATS: batch 90/486 in epoch 335,   batch loss: 1.86257, batch accuracy: 0.50683
Time: 2018-07-15 00:51:29
TRAINING STATS: batch 140/486 in epoch 335,  batch loss: 1.76311, batch accuracy: 0.54483
Time: 2018-07-15 00:51:34
TRAINING STATS: batch 190/486 in epoch 335,  batch loss: 1.82761, batch accuracy: 0.52350
Time: 2018-07-15 00:51:37
TRAINING STATS: batch 240/486 in epoch 335,  batch loss: 1.79409, batch accuracy: 0.53000
Time: 2018-07-15 00:51:41
TRAINING STATS: batch 290/486 in epoch 335,  batch loss: 1.82832, batch accuracy: 0.51417
Time: 2018-07-15 00:51:46
TRAINING STATS: batch 340/486 in epoch 335,  batch loss: 1.87989, batch accuracy: 0.50750
Time: 2018-07-15 00:51:49
TRAINING STATS: batch 390/486 in epoch 335,  batch loss: 1.74553, batch accuracy: 0.54217
Time: 2018-07-15 00:51:53
TRAINING STATS: batch 440/486 in epoch 335,  batch loss: 1.79176, batch accuracy: 0.52583
Time: 2018-07-15 00:51:58
TRAINING STATS: batch 4/486 in epoch 336,    batch loss: 1.75908, batch accuracy: 0.54683
Time: 2018-07-15 00:52:01
TRAINING STATS: batch 54/486 in epoch 336,   batch loss: 1.83599, batch accuracy: 0.51417
Time: 2018-07-15 00:52:05
TRAINING STATS: batch 104/486 in epoch 336,  batch loss: 1.83253, batch accuracy: 0.51283
Time: 2018-07-15 00:52:10
TRAINING STATS: batch 154/486 in epoch 336,  batch loss: 1.80132, batch accuracy: 0.53350
Time: 2018-07-15 00:52:13
TRAINING STATS: batch 204/486 in epoch 336,  batch loss: 1.85970, batch accuracy: 0.51517
Time: 2018-07-15 00:52:17
TRAINING STATS: batch 254/486 in epoch 336,  batch loss: 1.73862, batch accuracy: 0.54300
Time: 2018-07-15 00:52:22
TRAINING STATS: batch 304/486 in epoch 336,  batch loss: 1.76704, batch accuracy: 0.54100
Time: 2018-07-15 00:52:26
TRAINING STATS: batch 354/486 in epoch 336,  batch loss: 1.83042, batch accuracy: 0.51233
Time: 2018-07-15 00:52:29
TRAINING STATS: batch 404/486 in epoch 336,  batch loss: 1.76589, batch accuracy: 0.53650
Time: 2018-07-15 00:52:34
TRAINING STATS: batch 454/486 in epoch 336,  batch loss: 1.67032, batch accuracy: 0.56583
Time: 2018-07-15 00:52:38
TRAINING STATS: batch 18/486 in epoch 337,   batch loss: 2.06286, batch accuracy: 0.43917
Time: 2018-07-15 00:52:41
TRAINING STATS: batch 68/486 in epoch 337,   batch loss: 1.71018, batch accuracy: 0.54917
Time: 2018-07-15 00:52:46
TRAINING STATS: batch 118/486 in epoch 337,  batch loss: 1.81616, batch accuracy: 0.52650
Time: 2018-07-15 00:52:50
TRAINING STATS: batch 168/486 in epoch 337,  batch loss: 1.74135, batch accuracy: 0.54650
Time: 2018-07-15 00:52:53
TRAINING STATS: batch 218/486 in epoch 337,  batch loss: 1.76832, batch accuracy: 0.53450
Time: 2018-07-15 00:52:58
TRAINING STATS: batch 268/486 in epoch 337,  batch loss: 1.77912, batch accuracy: 0.51933
Time: 2018-07-15 00:53:02
TRAINING STATS: batch 318/486 in epoch 337,  batch loss: 1.78054, batch accuracy: 0.52450
Time: 2018-07-15 00:53:05
TRAINING STATS: batch 368/486 in epoch 337,  batch loss: 1.82213, batch accuracy: 0.52367
Time: 2018-07-15 00:53:10
TRAINING STATS: batch 418/486 in epoch 337,  batch loss: 1.86097, batch accuracy: 0.50450
Time: 2018-07-15 00:53:14
TRAINING STATS: batch 468/486 in epoch 337,  batch loss: 1.78894, batch accuracy: 0.52517
Time: 2018-07-15 00:53:17
TRAINING STATS: batch 32/486 in epoch 338,   batch loss: 1.75868, batch accuracy: 0.53383
Time: 2018-07-15 00:53:22
TRAINING STATS: batch 82/486 in epoch 338,   batch loss: 1.86661, batch accuracy: 0.50567
Time: 2018-07-15 00:53:26
TRAINING STATS: batch 132/486 in epoch 338,  batch loss: 1.78326, batch accuracy: 0.53983
Time: 2018-07-15 00:53:29
TRAINING STATS: batch 182/486 in epoch 338,  batch loss: 1.85451, batch accuracy: 0.50700
Time: 2018-07-15 00:53:34
TRAINING STATS: batch 232/486 in epoch 338,  batch loss: 1.95433, batch accuracy: 0.47550
Time: 2018-07-15 00:53:38
TRAINING STATS: batch 282/486 in epoch 338,  batch loss: 1.76342, batch accuracy: 0.53450
Time: 2018-07-15 00:53:41
TRAINING STATS: batch 332/486 in epoch 338,  batch loss: 1.83488, batch accuracy: 0.51800
Time: 2018-07-15 00:53:46
TRAINING STATS: batch 382/486 in epoch 338,  batch loss: 1.85929, batch accuracy: 0.50733
Time: 2018-07-15 00:53:50
TRAINING STATS: batch 432/486 in epoch 338,  batch loss: 1.74594, batch accuracy: 0.53583
Time: 2018-07-15 00:53:54
TRAINING STATS: batch 482/486 in epoch 338,  batch loss: 1.77875, batch accuracy: 0.52867
Time: 2018-07-15 00:53:58
TRAINING STATS: batch 46/486 in epoch 339,   batch loss: 1.76225, batch accuracy: 0.54467
Time: 2018-07-15 00:54:02
TRAINING STATS: batch 96/486 in epoch 339,   batch loss: 1.83033, batch accuracy: 0.51867
Time: 2018-07-15 00:54:05
TRAINING STATS: batch 146/486 in epoch 339,  batch loss: 1.84049, batch accuracy: 0.51717
Time: 2018-07-15 00:54:10
TRAINING STATS: batch 196/486 in epoch 339,  batch loss: 1.83484, batch accuracy: 0.50933
Time: 2018-07-15 00:54:14
TRAINING STATS: batch 246/486 in epoch 339,  batch loss: 1.75183, batch accuracy: 0.54117
Time: 2018-07-15 00:54:18
TRAINING STATS: batch 296/486 in epoch 339,  batch loss: 1.75042, batch accuracy: 0.53433
Time: 2018-07-15 00:54:22
TRAINING STATS: batch 346/486 in epoch 339,  batch loss: 1.77828, batch accuracy: 0.52967
Time: 2018-07-15 00:54:26
TRAINING STATS: batch 396/486 in epoch 339,  batch loss: 1.78500, batch accuracy: 0.52417
Time: 2018-07-15 00:54:30
TRAINING STATS: batch 446/486 in epoch 339,  batch loss: 1.82175, batch accuracy: 0.51617
Time: 2018-07-15 00:54:34
TRAINING STATS: batch 10/486 in epoch 340,   batch loss: 1.81003, batch accuracy: 0.52183
Time: 2018-07-15 00:54:38
TRAINING STATS: batch 60/486 in epoch 340,   batch loss: 1.76356, batch accuracy: 0.53950
Time: 2018-07-15 00:54:42
TRAINING STATS: batch 110/486 in epoch 340,  batch loss: 1.82443, batch accuracy: 0.51483
Time: 2018-07-15 00:54:46
TRAINING STATS: batch 160/486 in epoch 340,  batch loss: 1.75244, batch accuracy: 0.54017
Time: 2018-07-15 00:54:50
TRAINING STATS: batch 210/486 in epoch 340,  batch loss: 1.74443, batch accuracy: 0.53767
Time: 2018-07-15 00:54:54
TRAINING STATS: batch 260/486 in epoch 340,  batch loss: 1.79765, batch accuracy: 0.52050
Time: 2018-07-15 00:54:58
TRAINING STATS: batch 310/486 in epoch 340,  batch loss: 1.77775, batch accuracy: 0.53067
Time: 2018-07-15 00:55:02
TRAINING STATS: batch 360/486 in epoch 340,  batch loss: 1.84729, batch accuracy: 0.51117
Time: 2018-07-15 00:55:06
TRAINING STATS: batch 410/486 in epoch 340,  batch loss: 2.64133, batch accuracy: 0.24650
Time: 2018-07-15 00:55:10
TRAINING STATS: batch 460/486 in epoch 340,  batch loss: 2.32076, batch accuracy: 0.34950
Time: 2018-07-15 00:55:14
TRAINING STATS: batch 24/486 in epoch 341,   batch loss: 2.21364, batch accuracy: 0.39250
Time: 2018-07-15 00:55:18
TRAINING STATS: batch 74/486 in epoch 341,   batch loss: 2.26217, batch accuracy: 0.37317
Time: 2018-07-15 00:55:22
TRAINING STATS: batch 124/486 in epoch 341,  batch loss: 2.17179, batch accuracy: 0.40833
Time: 2018-07-15 00:55:26
TRAINING STATS: batch 174/486 in epoch 341,  batch loss: 2.11537, batch accuracy: 0.42483
Time: 2018-07-15 00:55:30
TRAINING STATS: batch 224/486 in epoch 341,  batch loss: 2.06721, batch accuracy: 0.43933
Time: 2018-07-15 00:55:34
TRAINING STATS: batch 274/486 in epoch 341,  batch loss: 1.99771, batch accuracy: 0.46117
Time: 2018-07-15 00:55:38
TRAINING STATS: batch 324/486 in epoch 341,  batch loss: 2.03226, batch accuracy: 0.44817
Time: 2018-07-15 00:55:42
TRAINING STATS: batch 374/486 in epoch 341,  batch loss: 2.02548, batch accuracy: 0.45700
Time: 2018-07-15 00:55:47
TRAINING STATS: batch 424/486 in epoch 341,  batch loss: 1.94410, batch accuracy: 0.47783
Time: 2018-07-15 00:55:50
TRAINING STATS: batch 474/486 in epoch 341,  batch loss: 1.99556, batch accuracy: 0.44967
Time: 2018-07-15 00:55:54
TRAINING STATS: batch 38/486 in epoch 342,   batch loss: 1.99965, batch accuracy: 0.46283
Time: 2018-07-15 00:55:59
TRAINING STATS: batch 88/486 in epoch 342,   batch loss: 2.03011, batch accuracy: 0.44550
Time: 2018-07-15 00:56:02
TRAINING STATS: batch 138/486 in epoch 342,  batch loss: 1.98246, batch accuracy: 0.46717
Time: 2018-07-15 00:56:06
TRAINING STATS: batch 188/486 in epoch 342,  batch loss: 1.90331, batch accuracy: 0.49583
Time: 2018-07-15 00:56:11
TRAINING STATS: batch 238/486 in epoch 342,  batch loss: 1.94672, batch accuracy: 0.48383
Time: 2018-07-15 00:56:14
TRAINING STATS: batch 288/486 in epoch 342,  batch loss: 1.97587, batch accuracy: 0.46333
Time: 2018-07-15 00:56:18
TRAINING STATS: batch 338/486 in epoch 342,  batch loss: 1.98824, batch accuracy: 0.45983
Time: 2018-07-15 00:56:23
TRAINING STATS: batch 388/486 in epoch 342,  batch loss: 1.90662, batch accuracy: 0.48333
Time: 2018-07-15 00:56:26
TRAINING STATS: batch 438/486 in epoch 342,  batch loss: 1.94987, batch accuracy: 0.48050
Time: 2018-07-15 00:56:30
TRAINING STATS: batch 2/486 in epoch 343,    batch loss: 1.94430, batch accuracy: 0.48333
Time: 2018-07-15 00:56:35
TRAINING STATS: batch 52/486 in epoch 343,   batch loss: 1.98861, batch accuracy: 0.46083
Time: 2018-07-15 00:56:38
TRAINING STATS: batch 102/486 in epoch 343,  batch loss: 1.94267, batch accuracy: 0.47700
Time: 2018-07-15 00:56:42
TRAINING STATS: batch 152/486 in epoch 343,  batch loss: 1.88818, batch accuracy: 0.50033
Time: 2018-07-15 00:56:47
TRAINING STATS: batch 202/486 in epoch 343,  batch loss: 1.93580, batch accuracy: 0.47733
Time: 2018-07-15 00:56:50
TRAINING STATS: batch 252/486 in epoch 343,  batch loss: 1.87967, batch accuracy: 0.49733
Time: 2018-07-15 00:56:54
TRAINING STATS: batch 302/486 in epoch 343,  batch loss: 1.89240, batch accuracy: 0.48883
Time: 2018-07-15 00:56:59
TRAINING STATS: batch 352/486 in epoch 343,  batch loss: 1.89636, batch accuracy: 0.50033
Time: 2018-07-15 00:57:03
TRAINING STATS: batch 402/486 in epoch 343,  batch loss: 1.82060, batch accuracy: 0.52500
Time: 2018-07-15 00:57:06
TRAINING STATS: batch 452/486 in epoch 343,  batch loss: 1.89476, batch accuracy: 0.49533
Time: 2018-07-15 00:57:11
TRAINING STATS: batch 16/486 in epoch 344,   batch loss: 1.85647, batch accuracy: 0.51683
Time: 2018-07-15 00:57:15
TRAINING STATS: batch 66/486 in epoch 344,   batch loss: 1.91688, batch accuracy: 0.49850
Time: 2018-07-15 00:57:18
TRAINING STATS: batch 116/486 in epoch 344,  batch loss: 1.86093, batch accuracy: 0.51567
Time: 2018-07-15 00:57:23
TRAINING STATS: batch 166/486 in epoch 344,  batch loss: 1.81343, batch accuracy: 0.52867
Time: 2018-07-15 00:57:27
TRAINING STATS: batch 216/486 in epoch 344,  batch loss: 1.90686, batch accuracy: 0.50117
Time: 2018-07-15 00:57:30
TRAINING STATS: batch 266/486 in epoch 344,  batch loss: 1.87012, batch accuracy: 0.50567
Time: 2018-07-15 00:57:35
TRAINING STATS: batch 316/486 in epoch 344,  batch loss: 1.87671, batch accuracy: 0.50383
Time: 2018-07-15 00:57:39
TRAINING STATS: batch 366/486 in epoch 344,  batch loss: 1.96908, batch accuracy: 0.48150
Time: 2018-07-15 00:57:42
TRAINING STATS: batch 416/486 in epoch 344,  batch loss: 1.93025, batch accuracy: 0.48167
Time: 2018-07-15 00:57:47
TRAINING STATS: batch 466/486 in epoch 344,  batch loss: 1.91223, batch accuracy: 0.48750
Time: 2018-07-15 00:57:51
TRAINING STATS: batch 30/486 in epoch 345,   batch loss: 1.86144, batch accuracy: 0.51033
Time: 2018-07-15 00:57:54
TRAINING STATS: batch 80/486 in epoch 345,   batch loss: 1.95473, batch accuracy: 0.48100
Time: 2018-07-15 00:57:59
TRAINING STATS: batch 130/486 in epoch 345,  batch loss: 1.93397, batch accuracy: 0.49117
Time: 2018-07-15 00:58:03
TRAINING STATS: batch 180/486 in epoch 345,  batch loss: 1.96676, batch accuracy: 0.49217
Time: 2018-07-15 00:58:06
TRAINING STATS: batch 230/486 in epoch 345,  batch loss: 1.94762, batch accuracy: 0.48217
Time: 2018-07-15 00:58:11
TRAINING STATS: batch 280/486 in epoch 345,  batch loss: 1.89000, batch accuracy: 0.50767
Time: 2018-07-15 00:58:15
TRAINING STATS: batch 330/486 in epoch 345,  batch loss: 1.91300, batch accuracy: 0.49350
Time: 2018-07-15 00:58:19
TRAINING STATS: batch 380/486 in epoch 345,  batch loss: 1.90011, batch accuracy: 0.49400
Time: 2018-07-15 00:58:23
TRAINING STATS: batch 430/486 in epoch 345,  batch loss: 1.83917, batch accuracy: 0.51600
Time: 2018-07-15 00:58:27
TRAINING STATS: batch 480/486 in epoch 345,  batch loss: 1.88449, batch accuracy: 0.49933
Time: 2018-07-15 00:58:31
TRAINING STATS: batch 44/486 in epoch 346,   batch loss: 1.82955, batch accuracy: 0.52350
Time: 2018-07-15 00:58:35
TRAINING STATS: batch 94/486 in epoch 346,   batch loss: 1.90561, batch accuracy: 0.50633
Time: 2018-07-15 00:58:39
TRAINING STATS: batch 144/486 in epoch 346,  batch loss: 1.92378, batch accuracy: 0.48683
Time: 2018-07-15 00:58:42
TRAINING STATS: batch 194/486 in epoch 346,  batch loss: 1.95105, batch accuracy: 0.47933
Time: 2018-07-15 00:58:47
TRAINING STATS: batch 244/486 in epoch 346,  batch loss: 1.84178, batch accuracy: 0.50683
Time: 2018-07-15 00:58:51
TRAINING STATS: batch 294/486 in epoch 346,  batch loss: 1.80684, batch accuracy: 0.51500
Time: 2018-07-15 00:58:54
TRAINING STATS: batch 344/486 in epoch 346,  batch loss: 1.83788, batch accuracy: 0.51617
Time: 2018-07-15 00:58:59
TRAINING STATS: batch 394/486 in epoch 346,  batch loss: 1.83223, batch accuracy: 0.51917
Time: 2018-07-15 00:59:03
TRAINING STATS: batch 444/486 in epoch 346,  batch loss: 1.81008, batch accuracy: 0.53067
Time: 2018-07-15 00:59:07
TRAINING STATS: batch 8/486 in epoch 347,    batch loss: 1.88061, batch accuracy: 0.50200
Time: 2018-07-15 00:59:11
TRAINING STATS: batch 58/486 in epoch 347,   batch loss: 1.84079, batch accuracy: 0.52667
Time: 2018-07-15 00:59:15
TRAINING STATS: batch 108/486 in epoch 347,  batch loss: 1.99984, batch accuracy: 0.47367
Time: 2018-07-15 00:59:19
TRAINING STATS: batch 158/486 in epoch 347,  batch loss: 1.91082, batch accuracy: 0.49283
Time: 2018-07-15 00:59:23
TRAINING STATS: batch 208/486 in epoch 347,  batch loss: 1.86023, batch accuracy: 0.50617
Time: 2018-07-15 00:59:27
TRAINING STATS: batch 258/486 in epoch 347,  batch loss: 1.87893, batch accuracy: 0.50650
Time: 2018-07-15 00:59:31
TRAINING STATS: batch 308/486 in epoch 347,  batch loss: 1.88906, batch accuracy: 0.50333
Time: 2018-07-15 00:59:35
TRAINING STATS: batch 358/486 in epoch 347,  batch loss: 1.92610, batch accuracy: 0.49083
Time: 2018-07-15 00:59:39
TRAINING STATS: batch 408/486 in epoch 347,  batch loss: 1.90549, batch accuracy: 0.49283
Time: 2018-07-15 00:59:43
TRAINING STATS: batch 458/486 in epoch 347,  batch loss: 1.92928, batch accuracy: 0.49833
Time: 2018-07-15 00:59:47
TRAINING STATS: batch 22/486 in epoch 348,   batch loss: 1.97646, batch accuracy: 0.46867
Time: 2018-07-15 00:59:51
TRAINING STATS: batch 72/486 in epoch 348,   batch loss: 1.92278, batch accuracy: 0.49317
Time: 2018-07-15 00:59:55
TRAINING STATS: batch 122/486 in epoch 348,  batch loss: 1.85230, batch accuracy: 0.51783
Time: 2018-07-15 00:59:59
TRAINING STATS: batch 172/486 in epoch 348,  batch loss: 2.16501, batch accuracy: 0.42150
Time: 2018-07-15 01:00:03
TRAINING STATS: batch 222/486 in epoch 348,  batch loss: 1.98863, batch accuracy: 0.46950
Time: 2018-07-15 01:00:07
TRAINING STATS: batch 272/486 in epoch 348,  batch loss: 2.01629, batch accuracy: 0.46183
Time: 2018-07-15 01:00:11
TRAINING STATS: batch 322/486 in epoch 348,  batch loss: 1.98670, batch accuracy: 0.47983
Time: 2018-07-15 01:00:15
TRAINING STATS: batch 372/486 in epoch 348,  batch loss: 1.94614, batch accuracy: 0.48150
Time: 2018-07-15 01:00:19
TRAINING STATS: batch 422/486 in epoch 348,  batch loss: 1.95482, batch accuracy: 0.48533
Time: 2018-07-15 01:00:24
TRAINING STATS: batch 472/486 in epoch 348,  batch loss: 2.02220, batch accuracy: 0.45950
Time: 2018-07-15 01:00:27
TRAINING STATS: batch 36/486 in epoch 349,   batch loss: 2.02209, batch accuracy: 0.46950
Time: 2018-07-15 01:00:31
TRAINING STATS: batch 86/486 in epoch 349,   batch loss: 1.96072, batch accuracy: 0.48683
Time: 2018-07-15 01:00:36
TRAINING STATS: batch 136/486 in epoch 349,  batch loss: 1.99246, batch accuracy: 0.47350
Time: 2018-07-15 01:00:39
TRAINING STATS: batch 186/486 in epoch 349,  batch loss: 1.95606, batch accuracy: 0.49167
Time: 2018-07-15 01:00:43
TRAINING STATS: batch 236/486 in epoch 349,  batch loss: 1.95953, batch accuracy: 0.48450
Time: 2018-07-15 01:00:48
TRAINING STATS: batch 286/486 in epoch 349,  batch loss: 1.96945, batch accuracy: 0.48267
Time: 2018-07-15 01:00:51
TRAINING STATS: batch 336/486 in epoch 349,  batch loss: 1.93515, batch accuracy: 0.48867
Time: 2018-07-15 01:00:55
TRAINING STATS: batch 386/486 in epoch 349,  batch loss: 1.95829, batch accuracy: 0.48133
Time: 2018-07-15 01:01:00
TRAINING STATS: batch 436/486 in epoch 349,  batch loss: 1.96064, batch accuracy: 0.48900
Time: 2018-07-15 01:01:03
TRAINING STATS: batch 0/486 in epoch 350,    batch loss: 1.98383, batch accuracy: 0.47000
Time: 2018-07-15 01:01:07
TRAINING STATS: batch 50/486 in epoch 350,   batch loss: 1.88031, batch accuracy: 0.51583
Time: 2018-07-15 01:01:12
TRAINING STATS: batch 100/486 in epoch 350,  batch loss: 1.97044, batch accuracy: 0.48967
Time: 2018-07-15 01:01:15
TRAINING STATS: batch 150/486 in epoch 350,  batch loss: 1.90589, batch accuracy: 0.50717
Time: 2018-07-15 01:01:19
TRAINING STATS: batch 200/486 in epoch 350,  batch loss: 1.83295, batch accuracy: 0.51950
Time: 2018-07-15 01:01:24
TRAINING STATS: batch 250/486 in epoch 350,  batch loss: 1.96446, batch accuracy: 0.48167
Time: 2018-07-15 01:01:27
TRAINING STATS: batch 300/486 in epoch 350,  batch loss: 1.93925, batch accuracy: 0.48133
Time: 2018-07-15 01:01:31
TRAINING STATS: batch 350/486 in epoch 350,  batch loss: 1.93296, batch accuracy: 0.50350
Time: 2018-07-15 01:01:36
TRAINING STATS: batch 400/486 in epoch 350,  batch loss: 1.81609, batch accuracy: 0.53267
Time: 2018-07-15 01:01:39
TRAINING STATS: batch 450/486 in epoch 350,  batch loss: 1.96477, batch accuracy: 0.48133
Time: 2018-07-15 01:01:43
TRAINING STATS: batch 14/486 in epoch 351,   batch loss: 1.83936, batch accuracy: 0.52417
Time: 2018-07-15 01:01:48
TRAINING STATS: batch 64/486 in epoch 351,   batch loss: 2.00401, batch accuracy: 0.46783
Time: 2018-07-15 01:01:51
TRAINING STATS: batch 114/486 in epoch 351,  batch loss: 1.92867, batch accuracy: 0.49050
Time: 2018-07-15 01:01:55
TRAINING STATS: batch 164/486 in epoch 351,  batch loss: 1.85716, batch accuracy: 0.51683
Time: 2018-07-15 01:02:00
TRAINING STATS: batch 214/486 in epoch 351,  batch loss: 1.92353, batch accuracy: 0.49950
Time: 2018-07-15 01:02:03
TRAINING STATS: batch 264/486 in epoch 351,  batch loss: 1.94908, batch accuracy: 0.48250
Time: 2018-07-15 01:02:07
TRAINING STATS: batch 314/486 in epoch 351,  batch loss: 1.94496, batch accuracy: 0.48433
Time: 2018-07-15 01:02:12
TRAINING STATS: batch 364/486 in epoch 351,  batch loss: 1.90071, batch accuracy: 0.50567
Time: 2018-07-15 01:02:15
TRAINING STATS: batch 414/486 in epoch 351,  batch loss: 1.87309, batch accuracy: 0.50317
Time: 2018-07-15 01:02:19
TRAINING STATS: batch 464/486 in epoch 351,  batch loss: 1.86559, batch accuracy: 0.49833
Time: 2018-07-15 01:02:24
TRAINING STATS: batch 28/486 in epoch 352,   batch loss: 1.85021, batch accuracy: 0.51600
Time: 2018-07-15 01:02:27
TRAINING STATS: batch 78/486 in epoch 352,   batch loss: 1.94401, batch accuracy: 0.49017
Time: 2018-07-15 01:02:31
TRAINING STATS: batch 128/486 in epoch 352,  batch loss: 1.87664, batch accuracy: 0.50150
Time: 2018-07-15 01:02:36
TRAINING STATS: batch 178/486 in epoch 352,  batch loss: 1.82230, batch accuracy: 0.51950
Time: 2018-07-15 01:02:40
TRAINING STATS: batch 228/486 in epoch 352,  batch loss: 1.91069, batch accuracy: 0.50017
Time: 2018-07-15 01:02:43
TRAINING STATS: batch 278/486 in epoch 352,  batch loss: 1.92519, batch accuracy: 0.49600
Time: 2018-07-15 01:02:48
TRAINING STATS: batch 328/486 in epoch 352,  batch loss: 1.88458, batch accuracy: 0.50550
Time: 2018-07-15 01:02:52
TRAINING STATS: batch 378/486 in epoch 352,  batch loss: 1.92070, batch accuracy: 0.49200
Time: 2018-07-15 01:02:55
TRAINING STATS: batch 428/486 in epoch 352,  batch loss: 1.99022, batch accuracy: 0.46517
Time: 2018-07-15 01:03:00
TRAINING STATS: batch 478/486 in epoch 352,  batch loss: 1.91340, batch accuracy: 0.49400
Time: 2018-07-15 01:03:04
TRAINING STATS: batch 42/486 in epoch 353,   batch loss: 1.78968, batch accuracy: 0.53517
Time: 2018-07-15 01:03:07
TRAINING STATS: batch 92/486 in epoch 353,   batch loss: 1.85581, batch accuracy: 0.51200
Time: 2018-07-15 01:03:12
TRAINING STATS: batch 142/486 in epoch 353,  batch loss: 1.81916, batch accuracy: 0.52483
Time: 2018-07-15 01:03:16
TRAINING STATS: batch 192/486 in epoch 353,  batch loss: 1.84353, batch accuracy: 0.51900
Time: 2018-07-15 01:03:19
TRAINING STATS: batch 242/486 in epoch 353,  batch loss: 1.82500, batch accuracy: 0.51733
Time: 2018-07-15 01:03:24
TRAINING STATS: batch 292/486 in epoch 353,  batch loss: 1.83798, batch accuracy: 0.51517
Time: 2018-07-15 01:03:28
TRAINING STATS: batch 342/486 in epoch 353,  batch loss: 1.81733, batch accuracy: 0.52450
Time: 2018-07-15 01:03:31
TRAINING STATS: batch 392/486 in epoch 353,  batch loss: 1.88525, batch accuracy: 0.49700
Time: 2018-07-15 01:03:36
TRAINING STATS: batch 442/486 in epoch 353,  batch loss: 1.76953, batch accuracy: 0.53533
Time: 2018-07-15 01:03:40
TRAINING STATS: batch 6/486 in epoch 354,    batch loss: 1.86614, batch accuracy: 0.51217
Time: 2018-07-15 01:03:43
TRAINING STATS: batch 56/486 in epoch 354,   batch loss: 1.81613, batch accuracy: 0.52483
Time: 2018-07-15 01:03:48
TRAINING STATS: batch 106/486 in epoch 354,  batch loss: 1.90662, batch accuracy: 0.49483
Time: 2018-07-15 01:03:52
TRAINING STATS: batch 156/486 in epoch 354,  batch loss: 1.85587, batch accuracy: 0.51067
Time: 2018-07-15 01:03:55
TRAINING STATS: batch 206/486 in epoch 354,  batch loss: 1.89819, batch accuracy: 0.49717
Time: 2018-07-15 01:04:00
TRAINING STATS: batch 256/486 in epoch 354,  batch loss: 1.78261, batch accuracy: 0.53150
Time: 2018-07-15 01:04:04
TRAINING STATS: batch 306/486 in epoch 354,  batch loss: 1.83496, batch accuracy: 0.50833
Time: 2018-07-15 01:04:08
TRAINING STATS: batch 356/486 in epoch 354,  batch loss: 1.87089, batch accuracy: 0.49833
Time: 2018-07-15 01:04:12
TRAINING STATS: batch 406/486 in epoch 354,  batch loss: 1.91354, batch accuracy: 0.48800
Time: 2018-07-15 01:04:16
TRAINING STATS: batch 456/486 in epoch 354,  batch loss: 1.72487, batch accuracy: 0.55067
Time: 2018-07-15 01:04:20
TRAINING STATS: batch 20/486 in epoch 355,   batch loss: 1.82471, batch accuracy: 0.51500
Time: 2018-07-15 01:04:24
TRAINING STATS: batch 70/486 in epoch 355,   batch loss: 1.76499, batch accuracy: 0.53967
Time: 2018-07-15 01:04:28
TRAINING STATS: batch 120/486 in epoch 355,  batch loss: 1.78360, batch accuracy: 0.52650
Time: 2018-07-15 01:04:32
TRAINING STATS: batch 170/486 in epoch 355,  batch loss: 1.80363, batch accuracy: 0.52350
Time: 2018-07-15 01:04:36
TRAINING STATS: batch 220/486 in epoch 355,  batch loss: 1.77628, batch accuracy: 0.52967
Time: 2018-07-15 01:04:40
TRAINING STATS: batch 270/486 in epoch 355,  batch loss: 1.85362, batch accuracy: 0.49700
Time: 2018-07-15 01:04:44
TRAINING STATS: batch 320/486 in epoch 355,  batch loss: 1.79914, batch accuracy: 0.51933
Time: 2018-07-15 01:04:48
TRAINING STATS: batch 370/486 in epoch 355,  batch loss: 1.85453, batch accuracy: 0.50467
Time: 2018-07-15 01:04:52
TRAINING STATS: batch 420/486 in epoch 355,  batch loss: 1.87267, batch accuracy: 0.50367
Time: 2018-07-15 01:04:56
TRAINING STATS: batch 470/486 in epoch 355,  batch loss: 1.92347, batch accuracy: 0.49117
Time: 2018-07-15 01:05:00
TRAINING STATS: batch 34/486 in epoch 356,   batch loss: 1.85740, batch accuracy: 0.51100
Time: 2018-07-15 01:05:04
TRAINING STATS: batch 84/486 in epoch 356,   batch loss: 1.83266, batch accuracy: 0.51150
Time: 2018-07-15 01:05:08
TRAINING STATS: batch 134/486 in epoch 356,  batch loss: 1.89510, batch accuracy: 0.50350
Time: 2018-07-15 01:05:13
TRAINING STATS: batch 184/486 in epoch 356,  batch loss: 1.82689, batch accuracy: 0.52067
Time: 2018-07-15 01:05:16
TRAINING STATS: batch 234/486 in epoch 356,  batch loss: 1.91113, batch accuracy: 0.49283
Time: 2018-07-15 01:05:20
TRAINING STATS: batch 284/486 in epoch 356,  batch loss: 1.86145, batch accuracy: 0.50800
Time: 2018-07-15 01:05:25
TRAINING STATS: batch 334/486 in epoch 356,  batch loss: 1.82492, batch accuracy: 0.51717
Time: 2018-07-15 01:05:28
TRAINING STATS: batch 384/486 in epoch 356,  batch loss: 1.80402, batch accuracy: 0.52700
Time: 2018-07-15 01:05:32
TRAINING STATS: batch 434/486 in epoch 356,  batch loss: 1.89784, batch accuracy: 0.49100
Time: 2018-07-15 01:05:37
TRAINING STATS: batch 484/486 in epoch 356,  batch loss: 1.83441, batch accuracy: 0.50717
Time: 2018-07-15 01:05:40
TRAINING STATS: batch 48/486 in epoch 357,   batch loss: 1.82862, batch accuracy: 0.51550
Time: 2018-07-15 01:05:44
TRAINING STATS: batch 98/486 in epoch 357,   batch loss: 1.79404, batch accuracy: 0.53083
Time: 2018-07-15 01:05:49
TRAINING STATS: batch 148/486 in epoch 357,  batch loss: 1.85900, batch accuracy: 0.51200
Time: 2018-07-15 01:05:52
TRAINING STATS: batch 198/486 in epoch 357,  batch loss: 1.80651, batch accuracy: 0.52100
Time: 2018-07-15 01:05:56
TRAINING STATS: batch 248/486 in epoch 357,  batch loss: 1.84937, batch accuracy: 0.51067
Time: 2018-07-15 01:06:01
TRAINING STATS: batch 298/486 in epoch 357,  batch loss: 1.84309, batch accuracy: 0.50450
Time: 2018-07-15 01:06:04
TRAINING STATS: batch 348/486 in epoch 357,  batch loss: 1.92970, batch accuracy: 0.48950
Time: 2018-07-15 01:06:08
TRAINING STATS: batch 398/486 in epoch 357,  batch loss: 1.82221, batch accuracy: 0.52150
Time: 2018-07-15 01:06:13
TRAINING STATS: batch 448/486 in epoch 357,  batch loss: 1.80610, batch accuracy: 0.52017
Time: 2018-07-15 01:06:16
TRAINING STATS: batch 12/486 in epoch 358,   batch loss: 1.83199, batch accuracy: 0.50233
Time: 2018-07-15 01:06:20
TRAINING STATS: batch 62/486 in epoch 358,   batch loss: 1.89755, batch accuracy: 0.48933
Time: 2018-07-15 01:06:25
TRAINING STATS: batch 112/486 in epoch 358,  batch loss: 1.81466, batch accuracy: 0.51233
Time: 2018-07-15 01:06:28
TRAINING STATS: batch 162/486 in epoch 358,  batch loss: 1.81644, batch accuracy: 0.52750
Time: 2018-07-15 01:06:32
TRAINING STATS: batch 212/486 in epoch 358,  batch loss: 1.73578, batch accuracy: 0.54500
Time: 2018-07-15 01:06:37
TRAINING STATS: batch 262/486 in epoch 358,  batch loss: 1.86735, batch accuracy: 0.50167
Time: 2018-07-15 01:06:40
TRAINING STATS: batch 312/486 in epoch 358,  batch loss: 1.84772, batch accuracy: 0.51150
Time: 2018-07-15 01:06:44
TRAINING STATS: batch 362/486 in epoch 358,  batch loss: 1.81974, batch accuracy: 0.52083
Time: 2018-07-15 01:06:49
TRAINING STATS: batch 412/486 in epoch 358,  batch loss: 2.01186, batch accuracy: 0.47133
Time: 2018-07-15 01:06:52
TRAINING STATS: batch 462/486 in epoch 358,  batch loss: 1.91471, batch accuracy: 0.49650
Time: 2018-07-15 01:06:56
TRAINING STATS: batch 26/486 in epoch 359,   batch loss: 2.04504, batch accuracy: 0.46683
Time: 2018-07-15 01:07:01
TRAINING STATS: batch 76/486 in epoch 359,   batch loss: 1.94911, batch accuracy: 0.48750
Time: 2018-07-15 01:07:05
TRAINING STATS: batch 126/486 in epoch 359,  batch loss: 1.88178, batch accuracy: 0.50033
Time: 2018-07-15 01:07:08
TRAINING STATS: batch 176/486 in epoch 359,  batch loss: 1.75988, batch accuracy: 0.53517
Time: 2018-07-15 01:07:13
TRAINING STATS: batch 226/486 in epoch 359,  batch loss: 1.80491, batch accuracy: 0.52050
Time: 2018-07-15 01:07:17
TRAINING STATS: batch 276/486 in epoch 359,  batch loss: 1.79925, batch accuracy: 0.52017
Time: 2018-07-15 01:07:20
TRAINING STATS: batch 326/486 in epoch 359,  batch loss: 1.84728, batch accuracy: 0.50383
Time: 2018-07-15 01:07:25
TRAINING STATS: batch 376/486 in epoch 359,  batch loss: 1.82499, batch accuracy: 0.51733
Time: 2018-07-15 01:07:29
TRAINING STATS: batch 426/486 in epoch 359,  batch loss: 1.80688, batch accuracy: 0.51233
Time: 2018-07-15 01:07:32
TRAINING STATS: batch 476/486 in epoch 359,  batch loss: 1.77054, batch accuracy: 0.54067
Time: 2018-07-15 01:07:37
TRAINING STATS: batch 40/486 in epoch 360,   batch loss: 1.77212, batch accuracy: 0.53350
Time: 2018-07-15 01:07:41
TRAINING STATS: batch 90/486 in epoch 360,   batch loss: 1.84536, batch accuracy: 0.51083
Time: 2018-07-15 01:07:44
TRAINING STATS: batch 140/486 in epoch 360,  batch loss: 1.74132, batch accuracy: 0.53717
Time: 2018-07-15 01:07:49
TRAINING STATS: batch 190/486 in epoch 360,  batch loss: 1.80660, batch accuracy: 0.51733
Time: 2018-07-15 01:07:53
TRAINING STATS: batch 240/486 in epoch 360,  batch loss: 1.77188, batch accuracy: 0.53550
Time: 2018-07-15 01:07:56
TRAINING STATS: batch 290/486 in epoch 360,  batch loss: 1.86957, batch accuracy: 0.48800
Time: 2018-07-15 01:08:01
TRAINING STATS: batch 340/486 in epoch 360,  batch loss: 1.88443, batch accuracy: 0.49650
Time: 2018-07-15 01:08:05
TRAINING STATS: batch 390/486 in epoch 360,  batch loss: 1.74407, batch accuracy: 0.53633
Time: 2018-07-15 01:08:08
TRAINING STATS: batch 440/486 in epoch 360,  batch loss: 1.81253, batch accuracy: 0.51867
Time: 2018-07-15 01:08:13
TRAINING STATS: batch 4/486 in epoch 361,    batch loss: 1.77465, batch accuracy: 0.53933
Time: 2018-07-15 01:08:17
TRAINING STATS: batch 54/486 in epoch 361,   batch loss: 2.74215, batch accuracy: 0.19850
Time: 2018-07-15 01:08:20
TRAINING STATS: batch 104/486 in epoch 361,  batch loss: 2.14211, batch accuracy: 0.43467
Time: 2018-07-15 01:08:25
TRAINING STATS: batch 154/486 in epoch 361,  batch loss: 2.04174, batch accuracy: 0.47200
Time: 2018-07-15 01:08:29
TRAINING STATS: batch 204/486 in epoch 361,  batch loss: 2.11310, batch accuracy: 0.44567
Time: 2018-07-15 01:08:33
TRAINING STATS: batch 254/486 in epoch 361,  batch loss: 1.93835, batch accuracy: 0.48150
Time: 2018-07-15 01:08:37
TRAINING STATS: batch 304/486 in epoch 361,  batch loss: 1.95769, batch accuracy: 0.47933
Time: 2018-07-15 01:08:41
TRAINING STATS: batch 354/486 in epoch 361,  batch loss: 1.96667, batch accuracy: 0.48167
Time: 2018-07-15 01:08:45
TRAINING STATS: batch 404/486 in epoch 361,  batch loss: 1.96272, batch accuracy: 0.47850
Time: 2018-07-15 01:08:49
TRAINING STATS: batch 454/486 in epoch 361,  batch loss: 1.81173, batch accuracy: 0.53183
Time: 2018-07-15 01:08:53
TRAINING STATS: batch 18/486 in epoch 362,   batch loss: 1.98577, batch accuracy: 0.47383
Time: 2018-07-15 01:08:57
TRAINING STATS: batch 68/486 in epoch 362,   batch loss: 1.79244, batch accuracy: 0.53217
Time: 2018-07-15 01:09:01
TRAINING STATS: batch 118/486 in epoch 362,  batch loss: 1.90988, batch accuracy: 0.50167
Time: 2018-07-15 01:09:05
TRAINING STATS: batch 168/486 in epoch 362,  batch loss: 1.82373, batch accuracy: 0.51983
Time: 2018-07-15 01:09:09
TRAINING STATS: batch 218/486 in epoch 362,  batch loss: 1.85071, batch accuracy: 0.50583
Time: 2018-07-15 01:09:13
TRAINING STATS: batch 268/486 in epoch 362,  batch loss: 1.79458, batch accuracy: 0.52550
Time: 2018-07-15 01:09:17
TRAINING STATS: batch 318/486 in epoch 362,  batch loss: 1.82779, batch accuracy: 0.51450
Time: 2018-07-15 01:09:21
TRAINING STATS: batch 368/486 in epoch 362,  batch loss: 1.86343, batch accuracy: 0.50333
Time: 2018-07-15 01:09:25
TRAINING STATS: batch 418/486 in epoch 362,  batch loss: 1.88807, batch accuracy: 0.49067
Time: 2018-07-15 01:09:29
TRAINING STATS: batch 468/486 in epoch 362,  batch loss: 1.86225, batch accuracy: 0.50733
Time: 2018-07-15 01:09:33
TRAINING STATS: batch 32/486 in epoch 363,   batch loss: 1.79243, batch accuracy: 0.52033
Time: 2018-07-15 01:09:37
TRAINING STATS: batch 82/486 in epoch 363,   batch loss: 1.87978, batch accuracy: 0.48700
Time: 2018-07-15 01:09:41
TRAINING STATS: batch 132/486 in epoch 363,  batch loss: 1.79715, batch accuracy: 0.52583
Time: 2018-07-15 01:09:45
TRAINING STATS: batch 182/486 in epoch 363,  batch loss: 1.86458, batch accuracy: 0.50400
Time: 2018-07-15 01:09:50
TRAINING STATS: batch 232/486 in epoch 363,  batch loss: 1.84446, batch accuracy: 0.50783
Time: 2018-07-15 01:09:53
TRAINING STATS: batch 282/486 in epoch 363,  batch loss: 1.77068, batch accuracy: 0.52483
Time: 2018-07-15 01:09:57
TRAINING STATS: batch 332/486 in epoch 363,  batch loss: 1.85506, batch accuracy: 0.50667
Time: 2018-07-15 01:10:02
TRAINING STATS: batch 382/486 in epoch 363,  batch loss: 1.84920, batch accuracy: 0.50683
Time: 2018-07-15 01:10:05
TRAINING STATS: batch 432/486 in epoch 363,  batch loss: 1.76082, batch accuracy: 0.53300
Time: 2018-07-15 01:10:09
TRAINING STATS: batch 482/486 in epoch 363,  batch loss: 1.80727, batch accuracy: 0.51517
Time: 2018-07-15 01:10:14
TRAINING STATS: batch 46/486 in epoch 364,   batch loss: 1.78994, batch accuracy: 0.52383
Time: 2018-07-15 01:10:17
TRAINING STATS: batch 96/486 in epoch 364,   batch loss: 1.84413, batch accuracy: 0.51267
Time: 2018-07-15 01:10:21
TRAINING STATS: batch 146/486 in epoch 364,  batch loss: 1.86453, batch accuracy: 0.51050
Time: 2018-07-15 01:10:26
TRAINING STATS: batch 196/486 in epoch 364,  batch loss: 1.85131, batch accuracy: 0.50583
Time: 2018-07-15 01:10:29
TRAINING STATS: batch 246/486 in epoch 364,  batch loss: 1.78046, batch accuracy: 0.52650
Time: 2018-07-15 01:10:33
TRAINING STATS: batch 296/486 in epoch 364,  batch loss: 1.76900, batch accuracy: 0.53333
Time: 2018-07-15 01:10:38
TRAINING STATS: batch 346/486 in epoch 364,  batch loss: 1.72735, batch accuracy: 0.54517
Time: 2018-07-15 01:10:41
TRAINING STATS: batch 396/486 in epoch 364,  batch loss: 1.77506, batch accuracy: 0.53567
Time: 2018-07-15 01:10:45
TRAINING STATS: batch 446/486 in epoch 364,  batch loss: 1.85272, batch accuracy: 0.50083
Time: 2018-07-15 01:10:50
TRAINING STATS: batch 10/486 in epoch 365,   batch loss: 1.95573, batch accuracy: 0.47350
Time: 2018-07-15 01:10:53
TRAINING STATS: batch 60/486 in epoch 365,   batch loss: 1.86309, batch accuracy: 0.50000
Time: 2018-07-15 01:10:57
TRAINING STATS: batch 110/486 in epoch 365,  batch loss: 1.89838, batch accuracy: 0.49983
Time: 2018-07-15 01:11:02
TRAINING STATS: batch 160/486 in epoch 365,  batch loss: 1.79665, batch accuracy: 0.52333
Time: 2018-07-15 01:11:06
TRAINING STATS: batch 210/486 in epoch 365,  batch loss: 1.78791, batch accuracy: 0.51450
Time: 2018-07-15 01:11:09
TRAINING STATS: batch 260/486 in epoch 365,  batch loss: 1.87473, batch accuracy: 0.49983
Time: 2018-07-15 01:11:14
TRAINING STATS: batch 310/486 in epoch 365,  batch loss: 1.90309, batch accuracy: 0.48700
Time: 2018-07-15 01:11:17
TRAINING STATS: batch 360/486 in epoch 365,  batch loss: 1.86239, batch accuracy: 0.50667
Time: 2018-07-15 01:11:21
TRAINING STATS: batch 410/486 in epoch 365,  batch loss: 1.82015, batch accuracy: 0.51217
Time: 2018-07-15 01:11:26
TRAINING STATS: batch 460/486 in epoch 365,  batch loss: 1.93001, batch accuracy: 0.47800
Time: 2018-07-15 01:11:29
TRAINING STATS: batch 24/486 in epoch 366,   batch loss: 1.90215, batch accuracy: 0.49783
Time: 2018-07-15 01:11:33
TRAINING STATS: batch 74/486 in epoch 366,   batch loss: 1.84754, batch accuracy: 0.50900
Time: 2018-07-15 01:11:38
TRAINING STATS: batch 124/486 in epoch 366,  batch loss: 1.84378, batch accuracy: 0.51600
Time: 2018-07-15 01:11:42
TRAINING STATS: batch 174/486 in epoch 366,  batch loss: 1.88274, batch accuracy: 0.50267
Time: 2018-07-15 01:11:45
TRAINING STATS: batch 224/486 in epoch 366,  batch loss: 2.33793, batch accuracy: 0.33867
Time: 2018-07-15 01:11:50
TRAINING STATS: batch 274/486 in epoch 366,  batch loss: 1.93735, batch accuracy: 0.48650
Time: 2018-07-15 01:11:54
TRAINING STATS: batch 324/486 in epoch 366,  batch loss: 1.90144, batch accuracy: 0.49433
Time: 2018-07-15 01:11:57
TRAINING STATS: batch 374/486 in epoch 366,  batch loss: 1.86566, batch accuracy: 0.51300
Time: 2018-07-15 01:12:02
TRAINING STATS: batch 424/486 in epoch 366,  batch loss: 1.77541, batch accuracy: 0.52700
Time: 2018-07-15 01:12:06
TRAINING STATS: batch 474/486 in epoch 366,  batch loss: 1.84035, batch accuracy: 0.49783
Time: 2018-07-15 01:12:09
TRAINING STATS: batch 38/486 in epoch 367,   batch loss: 1.85831, batch accuracy: 0.50667
Time: 2018-07-15 01:12:14
TRAINING STATS: batch 88/486 in epoch 367,   batch loss: 1.87169, batch accuracy: 0.49900
Time: 2018-07-15 01:12:18
TRAINING STATS: batch 138/486 in epoch 367,  batch loss: 1.85087, batch accuracy: 0.50333
Time: 2018-07-15 01:12:21
TRAINING STATS: batch 188/486 in epoch 367,  batch loss: 1.78299, batch accuracy: 0.52917
Time: 2018-07-15 01:12:26
TRAINING STATS: batch 238/486 in epoch 367,  batch loss: 1.82136, batch accuracy: 0.51217
Time: 2018-07-15 01:12:30
TRAINING STATS: batch 288/486 in epoch 367,  batch loss: 1.84487, batch accuracy: 0.50933
Time: 2018-07-15 01:12:34
TRAINING STATS: batch 338/486 in epoch 367,  batch loss: 1.83387, batch accuracy: 0.51167
Time: 2018-07-15 01:12:38
TRAINING STATS: batch 388/486 in epoch 367,  batch loss: 1.79220, batch accuracy: 0.51833
Time: 2018-07-15 01:12:42
TRAINING STATS: batch 438/486 in epoch 367,  batch loss: 1.83038, batch accuracy: 0.51133
Time: 2018-07-15 01:12:45
TRAINING STATS: batch 2/486 in epoch 368,    batch loss: 1.84100, batch accuracy: 0.49400
Time: 2018-07-15 01:12:50
TRAINING STATS: batch 52/486 in epoch 368,   batch loss: 1.94870, batch accuracy: 0.46167
Time: 2018-07-15 01:12:54
TRAINING STATS: batch 102/486 in epoch 368,  batch loss: 1.84772, batch accuracy: 0.50800
Time: 2018-07-15 01:12:58
TRAINING STATS: batch 152/486 in epoch 368,  batch loss: 1.78864, batch accuracy: 0.52700
Time: 2018-07-15 01:13:02
TRAINING STATS: batch 202/486 in epoch 368,  batch loss: 1.82923, batch accuracy: 0.51500
Time: 2018-07-15 01:13:06
TRAINING STATS: batch 252/486 in epoch 368,  batch loss: 1.78116, batch accuracy: 0.52200
Time: 2018-07-15 01:13:10
TRAINING STATS: batch 302/486 in epoch 368,  batch loss: 1.77668, batch accuracy: 0.52250
Time: 2018-07-15 01:13:14
TRAINING STATS: batch 352/486 in epoch 368,  batch loss: 1.79972, batch accuracy: 0.52183
Time: 2018-07-15 01:13:18
TRAINING STATS: batch 402/486 in epoch 368,  batch loss: 1.69970, batch accuracy: 0.55550
Time: 2018-07-15 01:13:22
TRAINING STATS: batch 452/486 in epoch 368,  batch loss: 1.80450, batch accuracy: 0.51667
Time: 2018-07-15 01:13:26
TRAINING STATS: batch 16/486 in epoch 369,   batch loss: 1.80241, batch accuracy: 0.52600
Time: 2018-07-15 01:13:30
TRAINING STATS: batch 66/486 in epoch 369,   batch loss: 1.81935, batch accuracy: 0.52367
Time: 2018-07-15 01:13:34
TRAINING STATS: batch 116/486 in epoch 369,  batch loss: 1.78049, batch accuracy: 0.52633
Time: 2018-07-15 01:13:38
TRAINING STATS: batch 166/486 in epoch 369,  batch loss: 1.75151, batch accuracy: 0.53517
Time: 2018-07-15 01:13:42
TRAINING STATS: batch 216/486 in epoch 369,  batch loss: 1.82340, batch accuracy: 0.51683
Time: 2018-07-15 01:13:46
TRAINING STATS: batch 266/486 in epoch 369,  batch loss: 1.85227, batch accuracy: 0.49817
Time: 2018-07-15 01:13:50
TRAINING STATS: batch 316/486 in epoch 369,  batch loss: 1.81540, batch accuracy: 0.51133
Time: 2018-07-15 01:13:54
TRAINING STATS: batch 366/486 in epoch 369,  batch loss: 1.90151, batch accuracy: 0.49350
Time: 2018-07-15 01:13:58
TRAINING STATS: batch 416/486 in epoch 369,  batch loss: 1.85775, batch accuracy: 0.49883
Time: 2018-07-15 01:14:03
TRAINING STATS: batch 466/486 in epoch 369,  batch loss: 1.69536, batch accuracy: 0.55167
Time: 2018-07-15 01:14:06
TRAINING STATS: batch 30/486 in epoch 370,   batch loss: 1.78246, batch accuracy: 0.51783
Time: 2018-07-15 01:14:10
TRAINING STATS: batch 80/486 in epoch 370,   batch loss: 1.83862, batch accuracy: 0.49817
Time: 2018-07-15 01:14:15
TRAINING STATS: batch 130/486 in epoch 370,  batch loss: 1.79899, batch accuracy: 0.52733
Time: 2018-07-15 01:14:18
TRAINING STATS: batch 180/486 in epoch 370,  batch loss: 1.84330, batch accuracy: 0.51100
Time: 2018-07-15 01:14:22
TRAINING STATS: batch 230/486 in epoch 370,  batch loss: 1.83182, batch accuracy: 0.49550
Time: 2018-07-15 01:14:27
TRAINING STATS: batch 280/486 in epoch 370,  batch loss: 1.80966, batch accuracy: 0.51617
Time: 2018-07-15 01:14:30
TRAINING STATS: batch 330/486 in epoch 370,  batch loss: 1.81398, batch accuracy: 0.50500
Time: 2018-07-15 01:14:34
TRAINING STATS: batch 380/486 in epoch 370,  batch loss: 1.78339, batch accuracy: 0.52467
Time: 2018-07-15 01:14:39
TRAINING STATS: batch 430/486 in epoch 370,  batch loss: 1.77513, batch accuracy: 0.53167
Time: 2018-07-15 01:14:42
TRAINING STATS: batch 480/486 in epoch 370,  batch loss: 1.87872, batch accuracy: 0.50067
Time: 2018-07-15 01:14:46
TRAINING STATS: batch 44/486 in epoch 371,   batch loss: 1.75902, batch accuracy: 0.52850
Time: 2018-07-15 01:14:51
TRAINING STATS: batch 94/486 in epoch 371,   batch loss: 1.84309, batch accuracy: 0.51233
Time: 2018-07-15 01:14:54
TRAINING STATS: batch 144/486 in epoch 371,  batch loss: 1.88750, batch accuracy: 0.49383
Time: 2018-07-15 01:14:58
TRAINING STATS: batch 194/486 in epoch 371,  batch loss: 1.88243, batch accuracy: 0.49083
Time: 2018-07-15 01:15:03
TRAINING STATS: batch 244/486 in epoch 371,  batch loss: 1.79105, batch accuracy: 0.52217
Time: 2018-07-15 01:15:06
TRAINING STATS: batch 294/486 in epoch 371,  batch loss: 1.79981, batch accuracy: 0.51083
Time: 2018-07-15 01:15:10
TRAINING STATS: batch 344/486 in epoch 371,  batch loss: 1.79300, batch accuracy: 0.52383
Time: 2018-07-15 01:15:15
TRAINING STATS: batch 394/486 in epoch 371,  batch loss: 1.83188, batch accuracy: 0.51250
Time: 2018-07-15 01:15:19
TRAINING STATS: batch 444/486 in epoch 371,  batch loss: 1.75441, batch accuracy: 0.54183
Time: 2018-07-15 01:15:22
TRAINING STATS: batch 8/486 in epoch 372,    batch loss: 1.80299, batch accuracy: 0.51317
Time: 2018-07-15 01:15:27
TRAINING STATS: batch 58/486 in epoch 372,   batch loss: 1.80323, batch accuracy: 0.52433
Time: 2018-07-15 01:15:31
TRAINING STATS: batch 108/486 in epoch 372,  batch loss: 1.85396, batch accuracy: 0.51400
Time: 2018-07-15 01:15:34
TRAINING STATS: batch 158/486 in epoch 372,  batch loss: 1.91704, batch accuracy: 0.48950
Time: 2018-07-15 01:15:39
TRAINING STATS: batch 208/486 in epoch 372,  batch loss: 1.89196, batch accuracy: 0.50000
Time: 2018-07-15 01:15:43
TRAINING STATS: batch 258/486 in epoch 372,  batch loss: 1.78771, batch accuracy: 0.53167
Time: 2018-07-15 01:15:46
TRAINING STATS: batch 308/486 in epoch 372,  batch loss: 1.82792, batch accuracy: 0.51650
Time: 2018-07-15 01:15:51
TRAINING STATS: batch 358/486 in epoch 372,  batch loss: 1.83635, batch accuracy: 0.51167
Time: 2018-07-15 01:15:55
TRAINING STATS: batch 408/486 in epoch 372,  batch loss: 1.85922, batch accuracy: 0.50050
Time: 2018-07-15 01:15:58
TRAINING STATS: batch 458/486 in epoch 372,  batch loss: 1.83292, batch accuracy: 0.51533
Time: 2018-07-15 01:16:03
TRAINING STATS: batch 22/486 in epoch 373,   batch loss: 1.84407, batch accuracy: 0.50533
Time: 2018-07-15 01:16:07
TRAINING STATS: batch 72/486 in epoch 373,   batch loss: 1.82539, batch accuracy: 0.51667
Time: 2018-07-15 01:16:10
TRAINING STATS: batch 122/486 in epoch 373,  batch loss: 1.74529, batch accuracy: 0.54300
Time: 2018-07-15 01:16:15
TRAINING STATS: batch 172/486 in epoch 373,  batch loss: 1.85474, batch accuracy: 0.50183
Time: 2018-07-15 01:16:19
TRAINING STATS: batch 222/486 in epoch 373,  batch loss: 1.78609, batch accuracy: 0.51967
Time: 2018-07-15 01:16:22
TRAINING STATS: batch 272/486 in epoch 373,  batch loss: 1.83285, batch accuracy: 0.50683
Time: 2018-07-15 01:16:27
TRAINING STATS: batch 322/486 in epoch 373,  batch loss: 1.83597, batch accuracy: 0.50683
Time: 2018-07-15 01:16:31
TRAINING STATS: batch 372/486 in epoch 373,  batch loss: 1.75930, batch accuracy: 0.53517
Time: 2018-07-15 01:16:34
TRAINING STATS: batch 422/486 in epoch 373,  batch loss: 1.80671, batch accuracy: 0.51217
Time: 2018-07-15 01:16:39
TRAINING STATS: batch 472/486 in epoch 373,  batch loss: 1.85398, batch accuracy: 0.50467
Time: 2018-07-15 01:16:43
TRAINING STATS: batch 36/486 in epoch 374,   batch loss: 1.85221, batch accuracy: 0.50817
Time: 2018-07-15 01:16:46
TRAINING STATS: batch 86/486 in epoch 374,   batch loss: 1.78807, batch accuracy: 0.52950
Time: 2018-07-15 01:16:51
TRAINING STATS: batch 136/486 in epoch 374,  batch loss: 1.84927, batch accuracy: 0.50817
Time: 2018-07-15 01:16:55
TRAINING STATS: batch 186/486 in epoch 374,  batch loss: 1.83790, batch accuracy: 0.50167
Time: 2018-07-15 01:16:58
TRAINING STATS: batch 236/486 in epoch 374,  batch loss: 1.95507, batch accuracy: 0.47300
Time: 2018-07-15 01:17:03
TRAINING STATS: batch 286/486 in epoch 374,  batch loss: 1.87096, batch accuracy: 0.50700
Time: 2018-07-15 01:17:07
TRAINING STATS: batch 336/486 in epoch 374,  batch loss: 1.81651, batch accuracy: 0.51917
Time: 2018-07-15 01:17:11
TRAINING STATS: batch 386/486 in epoch 374,  batch loss: 1.83446, batch accuracy: 0.50633
Time: 2018-07-15 01:17:15
TRAINING STATS: batch 436/486 in epoch 374,  batch loss: 1.82099, batch accuracy: 0.51617
Time: 2018-07-15 01:17:19
TRAINING STATS: batch 0/486 in epoch 375,    batch loss: 1.80005, batch accuracy: 0.51400
Time: 2018-07-15 01:17:23
TRAINING STATS: batch 50/486 in epoch 375,   batch loss: 1.76055, batch accuracy: 0.53833
Time: 2018-07-15 01:17:27
TRAINING STATS: batch 100/486 in epoch 375,  batch loss: 1.84470, batch accuracy: 0.50517
Time: 2018-07-15 01:17:31
TRAINING STATS: batch 150/486 in epoch 375,  batch loss: 1.77036, batch accuracy: 0.53283
Time: 2018-07-15 01:17:35
TRAINING STATS: batch 200/486 in epoch 375,  batch loss: 1.70979, batch accuracy: 0.55100
Time: 2018-07-15 01:17:39
TRAINING STATS: batch 250/486 in epoch 375,  batch loss: 1.87382, batch accuracy: 0.49283
Time: 2018-07-15 01:17:43
TRAINING STATS: batch 300/486 in epoch 375,  batch loss: 1.83337, batch accuracy: 0.50867
Time: 2018-07-15 01:17:47
TRAINING STATS: batch 350/486 in epoch 375,  batch loss: 1.80348, batch accuracy: 0.53250
Time: 2018-07-15 01:17:51
TRAINING STATS: batch 400/486 in epoch 375,  batch loss: 1.69272, batch accuracy: 0.54800
Time: 2018-07-15 01:17:55
TRAINING STATS: batch 450/486 in epoch 375,  batch loss: 1.84495, batch accuracy: 0.50367
Time: 2018-07-15 01:17:59
TRAINING STATS: batch 14/486 in epoch 376,   batch loss: 1.73593, batch accuracy: 0.54533
Time: 2018-07-15 01:18:03
TRAINING STATS: batch 64/486 in epoch 376,   batch loss: 1.88221, batch accuracy: 0.49517
Time: 2018-07-15 01:18:07
TRAINING STATS: batch 114/486 in epoch 376,  batch loss: 1.88559, batch accuracy: 0.48783
Time: 2018-07-15 01:18:11
TRAINING STATS: batch 164/486 in epoch 376,  batch loss: 1.73733, batch accuracy: 0.54317
Time: 2018-07-15 01:18:15
TRAINING STATS: batch 214/486 in epoch 376,  batch loss: 1.79702, batch accuracy: 0.52400
Time: 2018-07-15 01:18:19
TRAINING STATS: batch 264/486 in epoch 376,  batch loss: 1.82815, batch accuracy: 0.50417
Time: 2018-07-15 01:18:23
TRAINING STATS: batch 314/486 in epoch 376,  batch loss: 1.83542, batch accuracy: 0.50000
Time: 2018-07-15 01:18:28
TRAINING STATS: batch 364/486 in epoch 376,  batch loss: 1.78871, batch accuracy: 0.52233
Time: 2018-07-15 01:18:31
TRAINING STATS: batch 414/486 in epoch 376,  batch loss: 1.74363, batch accuracy: 0.53150
Time: 2018-07-15 01:18:35
TRAINING STATS: batch 464/486 in epoch 376,  batch loss: 1.75783, batch accuracy: 0.53283
Time: 2018-07-15 01:18:39
TRAINING STATS: batch 28/486 in epoch 377,   batch loss: 1.71270, batch accuracy: 0.54283
Time: 2018-07-15 01:18:43
TRAINING STATS: batch 78/486 in epoch 377,   batch loss: 1.77867, batch accuracy: 0.53283
Time: 2018-07-15 01:18:47
TRAINING STATS: batch 128/486 in epoch 377,  batch loss: 1.77291, batch accuracy: 0.51867
Time: 2018-07-15 01:18:51
TRAINING STATS: batch 178/486 in epoch 377,  batch loss: 1.70642, batch accuracy: 0.54350
Time: 2018-07-15 01:18:55
TRAINING STATS: batch 228/486 in epoch 377,  batch loss: 1.74665, batch accuracy: 0.52250
Time: 2018-07-15 01:18:59
TRAINING STATS: batch 278/486 in epoch 377,  batch loss: 1.71997, batch accuracy: 0.54200
Time: 2018-07-15 01:19:04
TRAINING STATS: batch 328/486 in epoch 377,  batch loss: 1.74596, batch accuracy: 0.53783
Time: 2018-07-15 01:19:07
TRAINING STATS: batch 378/486 in epoch 377,  batch loss: 1.78769, batch accuracy: 0.52617
Time: 2018-07-15 01:19:11
TRAINING STATS: batch 428/486 in epoch 377,  batch loss: 1.81409, batch accuracy: 0.51317
Time: 2018-07-15 01:19:16
TRAINING STATS: batch 478/486 in epoch 377,  batch loss: 1.80497, batch accuracy: 0.51867
Time: 2018-07-15 01:19:19
TRAINING STATS: batch 42/486 in epoch 378,   batch loss: 1.72772, batch accuracy: 0.54300
Time: 2018-07-15 01:19:23
TRAINING STATS: batch 92/486 in epoch 378,   batch loss: 1.80725, batch accuracy: 0.51683
Time: 2018-07-15 01:19:28
TRAINING STATS: batch 142/486 in epoch 378,  batch loss: 1.77800, batch accuracy: 0.52350
Time: 2018-07-15 01:19:31
TRAINING STATS: batch 192/486 in epoch 378,  batch loss: 1.77692, batch accuracy: 0.53183
Time: 2018-07-15 01:19:35
TRAINING STATS: batch 242/486 in epoch 378,  batch loss: 1.77673, batch accuracy: 0.51933
Time: 2018-07-15 01:19:40
TRAINING STATS: batch 292/486 in epoch 378,  batch loss: 1.77260, batch accuracy: 0.53033
Time: 2018-07-15 01:19:43
TRAINING STATS: batch 342/486 in epoch 378,  batch loss: 1.74931, batch accuracy: 0.53500
Time: 2018-07-15 01:19:47
TRAINING STATS: batch 392/486 in epoch 378,  batch loss: 1.71091, batch accuracy: 0.54717
Time: 2018-07-15 01:19:52
TRAINING STATS: batch 442/486 in epoch 378,  batch loss: 1.70359, batch accuracy: 0.54833
Time: 2018-07-15 01:19:55
TRAINING STATS: batch 6/486 in epoch 379,    batch loss: 1.82512, batch accuracy: 0.51167
Time: 2018-07-15 01:19:59
TRAINING STATS: batch 56/486 in epoch 379,   batch loss: 1.78967, batch accuracy: 0.52050
Time: 2018-07-15 01:20:04
TRAINING STATS: batch 106/486 in epoch 379,  batch loss: 1.83651, batch accuracy: 0.50883
Time: 2018-07-15 01:20:08
TRAINING STATS: batch 156/486 in epoch 379,  batch loss: 1.82274, batch accuracy: 0.51400
Time: 2018-07-15 01:20:11
TRAINING STATS: batch 206/486 in epoch 379,  batch loss: 1.85092, batch accuracy: 0.50667
Time: 2018-07-15 01:20:16
TRAINING STATS: batch 256/486 in epoch 379,  batch loss: 1.72604, batch accuracy: 0.53850
Time: 2018-07-15 01:20:20
TRAINING STATS: batch 306/486 in epoch 379,  batch loss: 1.79073, batch accuracy: 0.51800
Time: 2018-07-15 01:20:23
TRAINING STATS: batch 356/486 in epoch 379,  batch loss: 1.82595, batch accuracy: 0.50767
Time: 2018-07-15 01:20:28
TRAINING STATS: batch 406/486 in epoch 379,  batch loss: 1.85182, batch accuracy: 0.50283
Time: 2018-07-15 01:20:32
TRAINING STATS: batch 456/486 in epoch 379,  batch loss: 1.66675, batch accuracy: 0.56117
Time: 2018-07-15 01:20:35
TRAINING STATS: batch 20/486 in epoch 380,   batch loss: 1.77096, batch accuracy: 0.52400
Time: 2018-07-15 01:20:40
TRAINING STATS: batch 70/486 in epoch 380,   batch loss: 1.69924, batch accuracy: 0.55400
Time: 2018-07-15 01:20:44
TRAINING STATS: batch 120/486 in epoch 380,  batch loss: 2.70446, batch accuracy: 0.18883
Time: 2018-07-15 01:20:47
TRAINING STATS: batch 170/486 in epoch 380,  batch loss: 2.34124, batch accuracy: 0.32667
Time: 2018-07-15 01:20:52
TRAINING STATS: batch 220/486 in epoch 380,  batch loss: 2.31773, batch accuracy: 0.35417
Time: 2018-07-15 01:20:56
TRAINING STATS: batch 270/486 in epoch 380,  batch loss: 2.22168, batch accuracy: 0.39117
Time: 2018-07-15 01:20:59
TRAINING STATS: batch 320/486 in epoch 380,  batch loss: 2.09444, batch accuracy: 0.44667
Time: 2018-07-15 01:21:04
TRAINING STATS: batch 370/486 in epoch 380,  batch loss: 2.19957, batch accuracy: 0.40700
Time: 2018-07-15 01:21:08
TRAINING STATS: batch 420/486 in epoch 380,  batch loss: 2.15856, batch accuracy: 0.41850
Time: 2018-07-15 01:21:11
TRAINING STATS: batch 470/486 in epoch 380,  batch loss: 2.16274, batch accuracy: 0.41467
Time: 2018-07-15 01:21:16
TRAINING STATS: batch 34/486 in epoch 381,   batch loss: 2.08570, batch accuracy: 0.44233
Time: 2018-07-15 01:21:20
TRAINING STATS: batch 84/486 in epoch 381,   batch loss: 2.05724, batch accuracy: 0.44783
Time: 2018-07-15 01:21:24
TRAINING STATS: batch 134/486 in epoch 381,  batch loss: 2.07018, batch accuracy: 0.44617
Time: 2018-07-15 01:21:28
TRAINING STATS: batch 184/486 in epoch 381,  batch loss: 2.04955, batch accuracy: 0.45150
Time: 2018-07-15 01:21:32
TRAINING STATS: batch 234/486 in epoch 381,  batch loss: 2.05241, batch accuracy: 0.45867
Time: 2018-07-15 01:21:35
TRAINING STATS: batch 284/486 in epoch 381,  batch loss: 2.00735, batch accuracy: 0.47183
Time: 2018-07-15 01:21:40
TRAINING STATS: batch 334/486 in epoch 381,  batch loss: 1.95011, batch accuracy: 0.48467
Time: 2018-07-15 01:21:44
TRAINING STATS: batch 384/486 in epoch 381,  batch loss: 1.91725, batch accuracy: 0.50350
Time: 2018-07-15 01:21:48
TRAINING STATS: batch 434/486 in epoch 381,  batch loss: 1.98550, batch accuracy: 0.46550
Time: 2018-07-15 01:21:52
TRAINING STATS: batch 484/486 in epoch 381,  batch loss: 1.94289, batch accuracy: 0.47733
Time: 2018-07-15 01:21:56
TRAINING STATS: batch 48/486 in epoch 382,   batch loss: 1.92296, batch accuracy: 0.49250
Time: 2018-07-15 01:22:00
TRAINING STATS: batch 98/486 in epoch 382,   batch loss: 1.87674, batch accuracy: 0.49950
Time: 2018-07-15 01:22:04
TRAINING STATS: batch 148/486 in epoch 382,  batch loss: 1.94645, batch accuracy: 0.48550
Time: 2018-07-15 01:22:08
TRAINING STATS: batch 198/486 in epoch 382,  batch loss: 1.88396, batch accuracy: 0.50050
Time: 2018-07-15 01:22:12
TRAINING STATS: batch 248/486 in epoch 382,  batch loss: 1.93230, batch accuracy: 0.49067
Time: 2018-07-15 01:22:16
TRAINING STATS: batch 298/486 in epoch 382,  batch loss: 1.91720, batch accuracy: 0.48467
Time: 2018-07-15 01:22:20
TRAINING STATS: batch 348/486 in epoch 382,  batch loss: 1.90700, batch accuracy: 0.50533
Time: 2018-07-15 01:22:24
TRAINING STATS: batch 398/486 in epoch 382,  batch loss: 1.88802, batch accuracy: 0.49133
Time: 2018-07-15 01:22:29
TRAINING STATS: batch 448/486 in epoch 382,  batch loss: 1.88066, batch accuracy: 0.49717
Time: 2018-07-15 01:22:32
TRAINING STATS: batch 12/486 in epoch 383,   batch loss: 1.89982, batch accuracy: 0.48983
Time: 2018-07-15 01:22:36
TRAINING STATS: batch 62/486 in epoch 383,   batch loss: 1.95133, batch accuracy: 0.48300
Time: 2018-07-15 01:22:41
TRAINING STATS: batch 112/486 in epoch 383,  batch loss: 1.87050, batch accuracy: 0.50367
Time: 2018-07-15 01:22:44
TRAINING STATS: batch 162/486 in epoch 383,  batch loss: 1.89485, batch accuracy: 0.50533
Time: 2018-07-15 01:22:48
TRAINING STATS: batch 212/486 in epoch 383,  batch loss: 1.80558, batch accuracy: 0.52767
Time: 2018-07-15 01:22:53
TRAINING STATS: batch 262/486 in epoch 383,  batch loss: 1.92776, batch accuracy: 0.49250
Time: 2018-07-15 01:22:56
TRAINING STATS: batch 312/486 in epoch 383,  batch loss: 1.88835, batch accuracy: 0.49500
Time: 2018-07-15 01:23:00
TRAINING STATS: batch 362/486 in epoch 383,  batch loss: 1.87526, batch accuracy: 0.50033
Time: 2018-07-15 01:23:05
TRAINING STATS: batch 412/486 in epoch 383,  batch loss: 1.84058, batch accuracy: 0.52750
Time: 2018-07-15 01:23:08
TRAINING STATS: batch 462/486 in epoch 383,  batch loss: 1.87127, batch accuracy: 0.50200
Time: 2018-07-15 01:23:12
TRAINING STATS: batch 26/486 in epoch 384,   batch loss: 1.89636, batch accuracy: 0.50450
Time: 2018-07-15 01:23:17
TRAINING STATS: batch 76/486 in epoch 384,   batch loss: 1.91580, batch accuracy: 0.49333
Time: 2018-07-15 01:23:20
TRAINING STATS: batch 126/486 in epoch 384,  batch loss: 1.90294, batch accuracy: 0.49250
Time: 2018-07-15 01:23:24
TRAINING STATS: batch 176/486 in epoch 384,  batch loss: 1.78187, batch accuracy: 0.52600
Time: 2018-07-15 01:23:29
TRAINING STATS: batch 226/486 in epoch 384,  batch loss: 1.84937, batch accuracy: 0.51167
Time: 2018-07-15 01:23:32
TRAINING STATS: batch 276/486 in epoch 384,  batch loss: 1.86288, batch accuracy: 0.50333
Time: 2018-07-15 01:23:36
TRAINING STATS: batch 326/486 in epoch 384,  batch loss: 1.88975, batch accuracy: 0.49833
Time: 2018-07-15 01:23:41
TRAINING STATS: batch 376/486 in epoch 384,  batch loss: 1.88897, batch accuracy: 0.49717
Time: 2018-07-15 01:23:44
TRAINING STATS: batch 426/486 in epoch 384,  batch loss: 1.85797, batch accuracy: 0.50383
Time: 2018-07-15 01:23:48
TRAINING STATS: batch 476/486 in epoch 384,  batch loss: 1.81623, batch accuracy: 0.52250
Time: 2018-07-15 01:23:53
TRAINING STATS: batch 40/486 in epoch 385,   batch loss: 1.82426, batch accuracy: 0.51600
Time: 2018-07-15 01:23:56
TRAINING STATS: batch 90/486 in epoch 385,   batch loss: 1.90025, batch accuracy: 0.50300
Time: 2018-07-15 01:24:00
TRAINING STATS: batch 140/486 in epoch 385,  batch loss: 1.79745, batch accuracy: 0.53067
Time: 2018-07-15 01:24:05
TRAINING STATS: batch 190/486 in epoch 385,  batch loss: 1.82852, batch accuracy: 0.51550
Time: 2018-07-15 01:24:08
TRAINING STATS: batch 240/486 in epoch 385,  batch loss: 1.82625, batch accuracy: 0.51533
Time: 2018-07-15 01:24:12
TRAINING STATS: batch 290/486 in epoch 385,  batch loss: 1.87447, batch accuracy: 0.49467
Time: 2018-07-15 01:24:17
TRAINING STATS: batch 340/486 in epoch 385,  batch loss: 1.91284, batch accuracy: 0.49083
Time: 2018-07-15 01:24:20
TRAINING STATS: batch 390/486 in epoch 385,  batch loss: 1.79566, batch accuracy: 0.52050
Time: 2018-07-15 01:24:24
TRAINING STATS: batch 440/486 in epoch 385,  batch loss: 1.83968, batch accuracy: 0.50667
Time: 2018-07-15 01:24:29
TRAINING STATS: batch 4/486 in epoch 386,    batch loss: 1.80576, batch accuracy: 0.52150
Time: 2018-07-15 01:24:33
TRAINING STATS: batch 54/486 in epoch 386,   batch loss: 1.84255, batch accuracy: 0.51850
Time: 2018-07-15 01:24:36
TRAINING STATS: batch 104/486 in epoch 386,  batch loss: 1.86235, batch accuracy: 0.50783
Time: 2018-07-15 01:24:41
TRAINING STATS: batch 154/486 in epoch 386,  batch loss: 1.82558, batch accuracy: 0.52183
Time: 2018-07-15 01:24:45
TRAINING STATS: batch 204/486 in epoch 386,  batch loss: 1.91507, batch accuracy: 0.49183
Time: 2018-07-15 01:24:48
TRAINING STATS: batch 254/486 in epoch 386,  batch loss: 1.79844, batch accuracy: 0.52283
Time: 2018-07-15 01:24:53
TRAINING STATS: batch 304/486 in epoch 386,  batch loss: 1.80045, batch accuracy: 0.52467
Time: 2018-07-15 01:24:57
TRAINING STATS: batch 354/486 in epoch 386,  batch loss: 1.85333, batch accuracy: 0.51200
Time: 2018-07-15 01:25:00
TRAINING STATS: batch 404/486 in epoch 386,  batch loss: 1.82215, batch accuracy: 0.51000
Time: 2018-07-15 01:25:05
TRAINING STATS: batch 454/486 in epoch 386,  batch loss: 1.70475, batch accuracy: 0.55067
Time: 2018-07-15 01:25:09
TRAINING STATS: batch 18/486 in epoch 387,   batch loss: 1.86558, batch accuracy: 0.50500
Time: 2018-07-15 01:25:12
TRAINING STATS: batch 68/486 in epoch 387,   batch loss: 1.71628, batch accuracy: 0.54750
Time: 2018-07-15 01:25:17
TRAINING STATS: batch 118/486 in epoch 387,  batch loss: 1.81507, batch accuracy: 0.52483
Time: 2018-07-15 01:25:21
TRAINING STATS: batch 168/486 in epoch 387,  batch loss: 1.76881, batch accuracy: 0.53517
Time: 2018-07-15 01:25:24
TRAINING STATS: batch 218/486 in epoch 387,  batch loss: 1.82219, batch accuracy: 0.51300
Time: 2018-07-15 01:25:29
TRAINING STATS: batch 268/486 in epoch 387,  batch loss: 1.78111, batch accuracy: 0.51950
Time: 2018-07-15 01:25:33
TRAINING STATS: batch 318/486 in epoch 387,  batch loss: 1.82327, batch accuracy: 0.50567
Time: 2018-07-15 01:25:36
TRAINING STATS: batch 368/486 in epoch 387,  batch loss: 1.84242, batch accuracy: 0.51017
Time: 2018-07-15 01:25:41
TRAINING STATS: batch 418/486 in epoch 387,  batch loss: 1.89229, batch accuracy: 0.48567
Time: 2018-07-15 01:25:45
TRAINING STATS: batch 468/486 in epoch 387,  batch loss: 1.83956, batch accuracy: 0.50867
Time: 2018-07-15 01:25:48
TRAINING STATS: batch 32/486 in epoch 388,   batch loss: 1.79856, batch accuracy: 0.51717
Time: 2018-07-15 01:25:53
TRAINING STATS: batch 82/486 in epoch 388,   batch loss: 1.86308, batch accuracy: 0.50250
Time: 2018-07-15 01:25:57
TRAINING STATS: batch 132/486 in epoch 388,  batch loss: 1.80161, batch accuracy: 0.52333
Time: 2018-07-15 01:26:01
TRAINING STATS: batch 182/486 in epoch 388,  batch loss: 1.88281, batch accuracy: 0.50033
Time: 2018-07-15 01:26:05
TRAINING STATS: batch 232/486 in epoch 388,  batch loss: 1.87295, batch accuracy: 0.49883
Time: 2018-07-15 01:26:09
TRAINING STATS: batch 282/486 in epoch 388,  batch loss: 1.78049, batch accuracy: 0.52250
Time: 2018-07-15 01:26:13
TRAINING STATS: batch 332/486 in epoch 388,  batch loss: 1.84743, batch accuracy: 0.50717
Time: 2018-07-15 01:26:17
TRAINING STATS: batch 382/486 in epoch 388,  batch loss: 1.84123, batch accuracy: 0.50950
Time: 2018-07-15 01:26:21
TRAINING STATS: batch 432/486 in epoch 388,  batch loss: 1.79183, batch accuracy: 0.52150
Time: 2018-07-15 01:26:25
TRAINING STATS: batch 482/486 in epoch 388,  batch loss: 1.80797, batch accuracy: 0.51700
Time: 2018-07-15 01:26:29
TRAINING STATS: batch 46/486 in epoch 389,   batch loss: 1.78908, batch accuracy: 0.53250
Time: 2018-07-15 01:26:33
TRAINING STATS: batch 96/486 in epoch 389,   batch loss: 1.88764, batch accuracy: 0.49633
Time: 2018-07-15 01:26:37
TRAINING STATS: batch 146/486 in epoch 389,  batch loss: 1.87034, batch accuracy: 0.50850
Time: 2018-07-15 01:26:41
TRAINING STATS: batch 196/486 in epoch 389,  batch loss: 1.88645, batch accuracy: 0.48467
Time: 2018-07-15 01:26:45
TRAINING STATS: batch 246/486 in epoch 389,  batch loss: 1.81357, batch accuracy: 0.51617
Time: 2018-07-15 01:26:49
TRAINING STATS: batch 296/486 in epoch 389,  batch loss: 1.79216, batch accuracy: 0.52117
Time: 2018-07-15 01:26:53
TRAINING STATS: batch 346/486 in epoch 389,  batch loss: 1.75177, batch accuracy: 0.53583
Time: 2018-07-15 01:26:57
TRAINING STATS: batch 396/486 in epoch 389,  batch loss: 1.81396, batch accuracy: 0.51067
Time: 2018-07-15 01:27:01
TRAINING STATS: batch 446/486 in epoch 389,  batch loss: 1.83338, batch accuracy: 0.51000
Time: 2018-07-15 01:27:05
TRAINING STATS: batch 10/486 in epoch 390,   batch loss: 1.86745, batch accuracy: 0.50033
Time: 2018-07-15 01:27:09
TRAINING STATS: batch 60/486 in epoch 390,   batch loss: 1.80467, batch accuracy: 0.52667
Time: 2018-07-15 01:27:13
TRAINING STATS: batch 110/486 in epoch 390,  batch loss: 1.86121, batch accuracy: 0.50267
Time: 2018-07-15 01:27:17
TRAINING STATS: batch 160/486 in epoch 390,  batch loss: 1.80070, batch accuracy: 0.51900
Time: 2018-07-15 01:27:21
TRAINING STATS: batch 210/486 in epoch 390,  batch loss: 1.76651, batch accuracy: 0.52650
Time: 2018-07-15 01:27:25
TRAINING STATS: batch 260/486 in epoch 390,  batch loss: 1.85280, batch accuracy: 0.50517
Time: 2018-07-15 01:27:30
TRAINING STATS: batch 310/486 in epoch 390,  batch loss: 1.83927, batch accuracy: 0.50150
Time: 2018-07-15 01:27:33
TRAINING STATS: batch 360/486 in epoch 390,  batch loss: 1.85190, batch accuracy: 0.50100
Time: 2018-07-15 01:27:37
TRAINING STATS: batch 410/486 in epoch 390,  batch loss: 1.76101, batch accuracy: 0.52983
Time: 2018-07-15 01:27:42
TRAINING STATS: batch 460/486 in epoch 390,  batch loss: 1.91634, batch accuracy: 0.47883
Time: 2018-07-15 01:27:45
TRAINING STATS: batch 24/486 in epoch 391,   batch loss: 1.88015, batch accuracy: 0.49183
Time: 2018-07-15 01:27:49
TRAINING STATS: batch 74/486 in epoch 391,   batch loss: 1.82647, batch accuracy: 0.50783
Time: 2018-07-15 01:27:54
TRAINING STATS: batch 124/486 in epoch 391,  batch loss: 1.82148, batch accuracy: 0.51050
Time: 2018-07-15 01:27:57
TRAINING STATS: batch 174/486 in epoch 391,  batch loss: 1.89008, batch accuracy: 0.49733
Time: 2018-07-15 01:28:01
TRAINING STATS: batch 224/486 in epoch 391,  batch loss: 1.85976, batch accuracy: 0.50167
Time: 2018-07-15 01:28:06
TRAINING STATS: batch 274/486 in epoch 391,  batch loss: 1.81900, batch accuracy: 0.51517
Time: 2018-07-15 01:28:09
TRAINING STATS: batch 324/486 in epoch 391,  batch loss: 1.83556, batch accuracy: 0.50500
Time: 2018-07-15 01:28:13
TRAINING STATS: batch 374/486 in epoch 391,  batch loss: 1.82475, batch accuracy: 0.50583
Time: 2018-07-15 01:28:18
TRAINING STATS: batch 424/486 in epoch 391,  batch loss: 1.78415, batch accuracy: 0.51900
Time: 2018-07-15 01:28:21
TRAINING STATS: batch 474/486 in epoch 391,  batch loss: 1.82418, batch accuracy: 0.50367
Time: 2018-07-15 01:28:25
TRAINING STATS: batch 38/486 in epoch 392,   batch loss: 1.82118, batch accuracy: 0.52100
Time: 2018-07-15 01:28:30
TRAINING STATS: batch 88/486 in epoch 392,   batch loss: 1.84958, batch accuracy: 0.49917
Time: 2018-07-15 01:28:33
TRAINING STATS: batch 138/486 in epoch 392,  batch loss: 1.83161, batch accuracy: 0.50333
Time: 2018-07-15 01:28:37
TRAINING STATS: batch 188/486 in epoch 392,  batch loss: 1.76570, batch accuracy: 0.52233
Time: 2018-07-15 01:28:42
TRAINING STATS: batch 238/486 in epoch 392,  batch loss: 1.79528, batch accuracy: 0.52133
Time: 2018-07-15 01:28:45
TRAINING STATS: batch 288/486 in epoch 392,  batch loss: 1.84206, batch accuracy: 0.49883
Time: 2018-07-15 01:28:49
TRAINING STATS: batch 338/486 in epoch 392,  batch loss: 1.80080, batch accuracy: 0.51017
Time: 2018-07-15 01:28:54
TRAINING STATS: batch 388/486 in epoch 392,  batch loss: 1.75512, batch accuracy: 0.52433
Time: 2018-07-15 01:28:57
TRAINING STATS: batch 438/486 in epoch 392,  batch loss: 1.81293, batch accuracy: 0.51383
Time: 2018-07-15 01:29:01
TRAINING STATS: batch 2/486 in epoch 393,    batch loss: 1.82557, batch accuracy: 0.50367
Time: 2018-07-15 01:29:06
TRAINING STATS: batch 52/486 in epoch 393,   batch loss: 1.86388, batch accuracy: 0.49333
Time: 2018-07-15 01:29:10
TRAINING STATS: batch 102/486 in epoch 393,  batch loss: 1.81031, batch accuracy: 0.51467
Time: 2018-07-15 01:29:13
TRAINING STATS: batch 152/486 in epoch 393,  batch loss: 1.76186, batch accuracy: 0.52817
Time: 2018-07-15 01:29:18
TRAINING STATS: batch 202/486 in epoch 393,  batch loss: 1.80546, batch accuracy: 0.51283
Time: 2018-07-15 01:29:22
TRAINING STATS: batch 252/486 in epoch 393,  batch loss: 1.75678, batch accuracy: 0.52433
Time: 2018-07-15 01:29:25
TRAINING STATS: batch 302/486 in epoch 393,  batch loss: 1.76587, batch accuracy: 0.52250
Time: 2018-07-15 01:29:30
TRAINING STATS: batch 352/486 in epoch 393,  batch loss: 1.76824, batch accuracy: 0.52700
Time: 2018-07-15 01:29:34
TRAINING STATS: batch 402/486 in epoch 393,  batch loss: 1.66960, batch accuracy: 0.55650
Time: 2018-07-15 01:29:37
TRAINING STATS: batch 452/486 in epoch 393,  batch loss: 1.78399, batch accuracy: 0.51500
Time: 2018-07-15 01:29:42
TRAINING STATS: batch 16/486 in epoch 394,   batch loss: 1.76395, batch accuracy: 0.52750
Time: 2018-07-15 01:29:46
TRAINING STATS: batch 66/486 in epoch 394,   batch loss: 1.78667, batch accuracy: 0.51650
Time: 2018-07-15 01:29:49
TRAINING STATS: batch 116/486 in epoch 394,  batch loss: 1.76073, batch accuracy: 0.52683
Time: 2018-07-15 01:29:54
TRAINING STATS: batch 166/486 in epoch 394,  batch loss: 1.72251, batch accuracy: 0.53533
Time: 2018-07-15 01:29:58
TRAINING STATS: batch 216/486 in epoch 394,  batch loss: 1.80303, batch accuracy: 0.52317
Time: 2018-07-15 01:30:01
TRAINING STATS: batch 266/486 in epoch 394,  batch loss: 1.80062, batch accuracy: 0.50783
Time: 2018-07-15 01:30:06
TRAINING STATS: batch 316/486 in epoch 394,  batch loss: 1.77921, batch accuracy: 0.52150
Time: 2018-07-15 01:30:10
TRAINING STATS: batch 366/486 in epoch 394,  batch loss: 1.84384, batch accuracy: 0.50350
Time: 2018-07-15 01:30:13
TRAINING STATS: batch 416/486 in epoch 394,  batch loss: 1.83506, batch accuracy: 0.50600
Time: 2018-07-15 01:30:18
TRAINING STATS: batch 466/486 in epoch 394,  batch loss: 1.70418, batch accuracy: 0.54133
Time: 2018-07-15 01:30:22
TRAINING STATS: batch 30/486 in epoch 395,   batch loss: 1.69395, batch accuracy: 0.54517
Time: 2018-07-15 01:30:25
TRAINING STATS: batch 80/486 in epoch 395,   batch loss: 1.79221, batch accuracy: 0.50633
Time: 2018-07-15 01:30:30
TRAINING STATS: batch 130/486 in epoch 395,  batch loss: 1.76714, batch accuracy: 0.52767
Time: 2018-07-15 01:30:34
TRAINING STATS: batch 180/486 in epoch 395,  batch loss: 1.83343, batch accuracy: 0.51000
Time: 2018-07-15 01:30:37
TRAINING STATS: batch 230/486 in epoch 395,  batch loss: 1.81597, batch accuracy: 0.50567
Time: 2018-07-15 01:30:42
TRAINING STATS: batch 280/486 in epoch 395,  batch loss: 1.76858, batch accuracy: 0.52117
Time: 2018-07-15 01:30:46
TRAINING STATS: batch 330/486 in epoch 395,  batch loss: 1.76561, batch accuracy: 0.52283
Time: 2018-07-15 01:30:49
TRAINING STATS: batch 380/486 in epoch 395,  batch loss: 1.76689, batch accuracy: 0.52817
Time: 2018-07-15 01:30:54
TRAINING STATS: batch 430/486 in epoch 395,  batch loss: 1.76952, batch accuracy: 0.52517
Time: 2018-07-15 01:30:58
TRAINING STATS: batch 480/486 in epoch 395,  batch loss: 1.81113, batch accuracy: 0.51183
Time: 2018-07-15 01:31:02
TRAINING STATS: batch 44/486 in epoch 396,   batch loss: 1.73756, batch accuracy: 0.52983
Time: 2018-07-15 01:31:06
TRAINING STATS: batch 94/486 in epoch 396,   batch loss: 1.82453, batch accuracy: 0.50783
Time: 2018-07-15 01:31:10
TRAINING STATS: batch 144/486 in epoch 396,  batch loss: 1.83813, batch accuracy: 0.50417
Time: 2018-07-15 01:31:14
TRAINING STATS: batch 194/486 in epoch 396,  batch loss: 1.86986, batch accuracy: 0.49533
Time: 2018-07-15 01:31:18
TRAINING STATS: batch 244/486 in epoch 396,  batch loss: 1.76317, batch accuracy: 0.52850
Time: 2018-07-15 01:31:22
TRAINING STATS: batch 294/486 in epoch 396,  batch loss: 1.75728, batch accuracy: 0.52533
Time: 2018-07-15 01:31:26
TRAINING STATS: batch 344/486 in epoch 396,  batch loss: 1.77234, batch accuracy: 0.52350
Time: 2018-07-15 01:31:30
TRAINING STATS: batch 394/486 in epoch 396,  batch loss: 1.75332, batch accuracy: 0.53100
Time: 2018-07-15 01:31:34
TRAINING STATS: batch 444/486 in epoch 396,  batch loss: 1.72670, batch accuracy: 0.53400
Time: 2018-07-15 01:31:38
TRAINING STATS: batch 8/486 in epoch 397,    batch loss: 1.76019, batch accuracy: 0.52083
Time: 2018-07-15 01:31:42
TRAINING STATS: batch 58/486 in epoch 397,   batch loss: 1.74186, batch accuracy: 0.53467
Time: 2018-07-15 01:31:46
TRAINING STATS: batch 108/486 in epoch 397,  batch loss: 1.82950, batch accuracy: 0.50833
Time: 2018-07-15 01:31:50
TRAINING STATS: batch 158/486 in epoch 397,  batch loss: 1.82740, batch accuracy: 0.50183
Time: 2018-07-15 01:31:55
TRAINING STATS: batch 208/486 in epoch 397,  batch loss: 1.79500, batch accuracy: 0.52017
Time: 2018-07-15 01:31:58
TRAINING STATS: batch 258/486 in epoch 397,  batch loss: 1.73592, batch accuracy: 0.53633
Time: 2018-07-15 01:32:02
TRAINING STATS: batch 308/486 in epoch 397,  batch loss: 1.78186, batch accuracy: 0.51867
Time: 2018-07-15 01:32:07
TRAINING STATS: batch 358/486 in epoch 397,  batch loss: 1.79804, batch accuracy: 0.51567
Time: 2018-07-15 01:32:10
TRAINING STATS: batch 408/486 in epoch 397,  batch loss: 1.82339, batch accuracy: 0.50483
Time: 2018-07-15 01:32:14
TRAINING STATS: batch 458/486 in epoch 397,  batch loss: 1.80850, batch accuracy: 0.51817
Time: 2018-07-15 01:32:19
TRAINING STATS: batch 22/486 in epoch 398,   batch loss: 1.83143, batch accuracy: 0.51450
Time: 2018-07-15 01:32:22
TRAINING STATS: batch 72/486 in epoch 398,   batch loss: 1.79731, batch accuracy: 0.51233
Time: 2018-07-15 01:32:26
TRAINING STATS: batch 122/486 in epoch 398,  batch loss: 1.72417, batch accuracy: 0.54067
Time: 2018-07-15 01:32:31
TRAINING STATS: batch 172/486 in epoch 398,  batch loss: 1.82739, batch accuracy: 0.50817
Time: 2018-07-15 01:32:34
TRAINING STATS: batch 222/486 in epoch 398,  batch loss: 1.77100, batch accuracy: 0.52317
Time: 2018-07-15 01:32:38
TRAINING STATS: batch 272/486 in epoch 398,  batch loss: 1.81189, batch accuracy: 0.50517
Time: 2018-07-15 01:32:43
TRAINING STATS: batch 322/486 in epoch 398,  batch loss: 1.76340, batch accuracy: 0.52100
Time: 2018-07-15 01:32:46
TRAINING STATS: batch 372/486 in epoch 398,  batch loss: 1.72378, batch accuracy: 0.54000
Time: 2018-07-15 01:32:50
TRAINING STATS: batch 422/486 in epoch 398,  batch loss: 1.75150, batch accuracy: 0.52967
Time: 2018-07-15 01:32:55
TRAINING STATS: batch 472/486 in epoch 398,  batch loss: 1.83751, batch accuracy: 0.49650
Time: 2018-07-15 01:32:58
TRAINING STATS: batch 36/486 in epoch 399,   batch loss: 1.83046, batch accuracy: 0.50817
Time: 2018-07-15 01:33:02
TRAINING STATS: batch 86/486 in epoch 399,   batch loss: 1.77853, batch accuracy: 0.52817
Time: 2018-07-15 01:33:07
TRAINING STATS: batch 136/486 in epoch 399,  batch loss: 1.83343, batch accuracy: 0.50017
Time: 2018-07-15 01:33:10
TRAINING STATS: batch 186/486 in epoch 399,  batch loss: 1.79580, batch accuracy: 0.51200
Time: 2018-07-15 01:33:14
TRAINING STATS: batch 236/486 in epoch 399,  batch loss: 1.80754, batch accuracy: 0.51133
Time: 2018-07-15 01:33:19
TRAINING STATS: batch 286/486 in epoch 399,  batch loss: 1.83299, batch accuracy: 0.50817
Time: 2018-07-15 01:33:22
TRAINING STATS: batch 336/486 in epoch 399,  batch loss: 1.75735, batch accuracy: 0.52300
Time: 2018-07-15 01:33:26
TRAINING STATS: batch 386/486 in epoch 399,  batch loss: 1.80665, batch accuracy: 0.51400
Time: 2018-07-15 01:33:31
TRAINING STATS: batch 436/486 in epoch 399,  batch loss: 1.80248, batch accuracy: 0.50567
Time: 2018-07-15 01:33:34
TRAINING STATS: batch 0/486 in epoch 400,    batch loss: 1.76551, batch accuracy: 0.52650
Time: 2018-07-15 01:33:38
TRAINING STATS: batch 50/486 in epoch 400,   batch loss: 1.74069, batch accuracy: 0.53750
Time: 2018-07-15 01:33:43
TRAINING STATS: batch 100/486 in epoch 400,  batch loss: 1.78961, batch accuracy: 0.52350
Time: 2018-07-15 01:33:47
TRAINING STATS: batch 150/486 in epoch 400,  batch loss: 1.73002, batch accuracy: 0.54117
Time: 2018-07-15 01:33:50
TRAINING STATS: batch 200/486 in epoch 400,  batch loss: 1.66805, batch accuracy: 0.55450
Time: 2018-07-15 01:33:55
TRAINING STATS: batch 250/486 in epoch 400,  batch loss: 1.83014, batch accuracy: 0.49567
Time: 2018-07-15 01:33:59
TRAINING STATS: batch 300/486 in epoch 400,  batch loss: 1.81897, batch accuracy: 0.51083
Time: 2018-07-15 01:34:02
TRAINING STATS: batch 350/486 in epoch 400,  batch loss: 1.79580, batch accuracy: 0.52267
Time: 2018-07-15 01:34:07
TRAINING STATS: batch 400/486 in epoch 400,  batch loss: 1.67069, batch accuracy: 0.55367
Time: 2018-07-15 01:34:11
TRAINING STATS: batch 450/486 in epoch 400,  batch loss: 1.83152, batch accuracy: 0.50100
Time: 2018-07-15 01:34:14
TRAINING STATS: batch 14/486 in epoch 401,   batch loss: 1.71660, batch accuracy: 0.53883
Time: 2018-07-15 01:34:19
TRAINING STATS: batch 64/486 in epoch 401,   batch loss: 1.85068, batch accuracy: 0.50450
Time: 2018-07-15 01:34:23
TRAINING STATS: batch 114/486 in epoch 401,  batch loss: 1.82382, batch accuracy: 0.50983
Time: 2018-07-15 01:34:26
TRAINING STATS: batch 164/486 in epoch 401,  batch loss: 1.71040, batch accuracy: 0.54000
Time: 2018-07-15 01:34:31
TRAINING STATS: batch 214/486 in epoch 401,  batch loss: 1.76977, batch accuracy: 0.52517
Time: 2018-07-15 01:34:35
TRAINING STATS: batch 264/486 in epoch 401,  batch loss: 1.81169, batch accuracy: 0.50800
Time: 2018-07-15 01:34:38
TRAINING STATS: batch 314/486 in epoch 401,  batch loss: 1.82996, batch accuracy: 0.50217
Time: 2018-07-15 01:34:43
TRAINING STATS: batch 364/486 in epoch 401,  batch loss: 1.75740, batch accuracy: 0.53033
Time: 2018-07-15 01:34:47
TRAINING STATS: batch 414/486 in epoch 401,  batch loss: 1.70325, batch accuracy: 0.54183
Time: 2018-07-15 01:34:50
TRAINING STATS: batch 464/486 in epoch 401,  batch loss: 1.74863, batch accuracy: 0.53083
Time: 2018-07-15 01:34:55
TRAINING STATS: batch 28/486 in epoch 402,   batch loss: 1.69754, batch accuracy: 0.54600
Time: 2018-07-15 01:34:59
TRAINING STATS: batch 78/486 in epoch 402,   batch loss: 1.77012, batch accuracy: 0.52867
Time: 2018-07-15 01:35:02
TRAINING STATS: batch 128/486 in epoch 402,  batch loss: 1.75084, batch accuracy: 0.52717
Time: 2018-07-15 01:35:07
TRAINING STATS: batch 178/486 in epoch 402,  batch loss: 1.66248, batch accuracy: 0.55267
Time: 2018-07-15 01:35:11
TRAINING STATS: batch 228/486 in epoch 402,  batch loss: 1.72633, batch accuracy: 0.54000
Time: 2018-07-15 01:35:15
TRAINING STATS: batch 278/486 in epoch 402,  batch loss: 1.71078, batch accuracy: 0.54317
Time: 2018-07-15 01:35:19
TRAINING STATS: batch 328/486 in epoch 402,  batch loss: 1.72283, batch accuracy: 0.53217
Time: 2018-07-15 01:35:23
TRAINING STATS: batch 378/486 in epoch 402,  batch loss: 1.76000, batch accuracy: 0.53200
Time: 2018-07-15 01:35:27
TRAINING STATS: batch 428/486 in epoch 402,  batch loss: 1.80777, batch accuracy: 0.51650
Time: 2018-07-15 01:35:31
TRAINING STATS: batch 478/486 in epoch 402,  batch loss: 1.77139, batch accuracy: 0.52483
Time: 2018-07-15 01:35:35
TRAINING STATS: batch 42/486 in epoch 403,   batch loss: 1.67186, batch accuracy: 0.55433
Time: 2018-07-15 01:35:39
TRAINING STATS: batch 92/486 in epoch 403,   batch loss: 1.78056, batch accuracy: 0.52250
Time: 2018-07-15 01:35:43
TRAINING STATS: batch 142/486 in epoch 403,  batch loss: 1.72078, batch accuracy: 0.54433
Time: 2018-07-15 01:35:47
TRAINING STATS: batch 192/486 in epoch 403,  batch loss: 1.74615, batch accuracy: 0.53467
Time: 2018-07-15 01:35:51
TRAINING STATS: batch 242/486 in epoch 403,  batch loss: 1.73799, batch accuracy: 0.53683
Time: 2018-07-15 01:35:55
TRAINING STATS: batch 292/486 in epoch 403,  batch loss: 1.74575, batch accuracy: 0.53083
Time: 2018-07-15 01:35:59
TRAINING STATS: batch 342/486 in epoch 403,  batch loss: 1.71152, batch accuracy: 0.53933
Time: 2018-07-15 01:36:03
TRAINING STATS: batch 392/486 in epoch 403,  batch loss: 1.67206, batch accuracy: 0.55417
Time: 2018-07-15 01:36:07
TRAINING STATS: batch 442/486 in epoch 403,  batch loss: 1.67152, batch accuracy: 0.55033
Time: 2018-07-15 01:36:11
TRAINING STATS: batch 6/486 in epoch 404,    batch loss: 1.79349, batch accuracy: 0.52500
Time: 2018-07-15 01:36:15
TRAINING STATS: batch 56/486 in epoch 404,   batch loss: 1.72904, batch accuracy: 0.53650
Time: 2018-07-15 01:36:19
TRAINING STATS: batch 106/486 in epoch 404,  batch loss: 1.88514, batch accuracy: 0.49367
Time: 2018-07-15 01:36:23
TRAINING STATS: batch 156/486 in epoch 404,  batch loss: 1.79138, batch accuracy: 0.51600
Time: 2018-07-15 01:36:27
TRAINING STATS: batch 206/486 in epoch 404,  batch loss: 1.83339, batch accuracy: 0.50833
Time: 2018-07-15 01:36:32
TRAINING STATS: batch 256/486 in epoch 404,  batch loss: 1.69415, batch accuracy: 0.54383
Time: 2018-07-15 01:36:35
TRAINING STATS: batch 306/486 in epoch 404,  batch loss: 1.76127, batch accuracy: 0.52650
Time: 2018-07-15 01:36:39
TRAINING STATS: batch 356/486 in epoch 404,  batch loss: 1.82497, batch accuracy: 0.50100
Time: 2018-07-15 01:36:44
TRAINING STATS: batch 406/486 in epoch 404,  batch loss: 1.82938, batch accuracy: 0.50083
Time: 2018-07-15 01:36:47
TRAINING STATS: batch 456/486 in epoch 404,  batch loss: 1.65811, batch accuracy: 0.55067
Time: 2018-07-15 01:36:51
TRAINING STATS: batch 20/486 in epoch 405,   batch loss: 1.75716, batch accuracy: 0.52633
Time: 2018-07-15 01:36:56
TRAINING STATS: batch 70/486 in epoch 405,   batch loss: 1.67090, batch accuracy: 0.55933
Time: 2018-07-15 01:36:59
TRAINING STATS: batch 120/486 in epoch 405,  batch loss: 1.69975, batch accuracy: 0.54617
Time: 2018-07-15 01:37:03
TRAINING STATS: batch 170/486 in epoch 405,  batch loss: 1.74672, batch accuracy: 0.53217
Time: 2018-07-15 01:37:08
TRAINING STATS: batch 220/486 in epoch 405,  batch loss: 1.69017, batch accuracy: 0.55450
Time: 2018-07-15 01:37:11
TRAINING STATS: batch 270/486 in epoch 405,  batch loss: 1.75757, batch accuracy: 0.51817
Time: 2018-07-15 01:37:15
TRAINING STATS: batch 320/486 in epoch 405,  batch loss: 1.69073, batch accuracy: 0.54700
Time: 2018-07-15 01:37:20
TRAINING STATS: batch 370/486 in epoch 405,  batch loss: 1.76224, batch accuracy: 0.52867
Time: 2018-07-15 01:37:23
TRAINING STATS: batch 420/486 in epoch 405,  batch loss: 1.79016, batch accuracy: 0.51700
Time: 2018-07-15 01:37:27
TRAINING STATS: batch 470/486 in epoch 405,  batch loss: 1.83844, batch accuracy: 0.50167
Time: 2018-07-15 01:37:32
TRAINING STATS: batch 34/486 in epoch 406,   batch loss: 1.76540, batch accuracy: 0.52867
Time: 2018-07-15 01:37:35
TRAINING STATS: batch 84/486 in epoch 406,   batch loss: 1.75632, batch accuracy: 0.52467
Time: 2018-07-15 01:37:39
TRAINING STATS: batch 134/486 in epoch 406,  batch loss: 1.78057, batch accuracy: 0.53100
Time: 2018-07-15 01:37:44
TRAINING STATS: batch 184/486 in epoch 406,  batch loss: 1.76906, batch accuracy: 0.51900
Time: 2018-07-15 01:37:47
TRAINING STATS: batch 234/486 in epoch 406,  batch loss: 1.81953, batch accuracy: 0.51567
Time: 2018-07-15 01:37:51
TRAINING STATS: batch 284/486 in epoch 406,  batch loss: 1.79430, batch accuracy: 0.51933
Time: 2018-07-15 01:37:56
TRAINING STATS: batch 334/486 in epoch 406,  batch loss: 1.74005, batch accuracy: 0.52683
Time: 2018-07-15 01:37:59
TRAINING STATS: batch 384/486 in epoch 406,  batch loss: 1.72346, batch accuracy: 0.53800
Time: 2018-07-15 01:38:03
TRAINING STATS: batch 434/486 in epoch 406,  batch loss: 1.81558, batch accuracy: 0.50567
Time: 2018-07-15 01:38:08
TRAINING STATS: batch 484/486 in epoch 406,  batch loss: 1.74591, batch accuracy: 0.52183
Time: 2018-07-15 01:38:11
TRAINING STATS: batch 48/486 in epoch 407,   batch loss: 1.80272, batch accuracy: 0.50983
Time: 2018-07-15 01:38:15
TRAINING STATS: batch 98/486 in epoch 407,   batch loss: 1.71555, batch accuracy: 0.54067
Time: 2018-07-15 01:38:20
TRAINING STATS: batch 148/486 in epoch 407,  batch loss: 1.78072, batch accuracy: 0.52250
Time: 2018-07-15 01:38:24
TRAINING STATS: batch 198/486 in epoch 407,  batch loss: 1.74842, batch accuracy: 0.52450
Time: 2018-07-15 01:38:27
TRAINING STATS: batch 248/486 in epoch 407,  batch loss: 1.77849, batch accuracy: 0.52450
Time: 2018-07-15 01:38:32
TRAINING STATS: batch 298/486 in epoch 407,  batch loss: 1.76705, batch accuracy: 0.51750
Time: 2018-07-15 01:38:36
TRAINING STATS: batch 348/486 in epoch 407,  batch loss: 1.76353, batch accuracy: 0.52733
Time: 2018-07-15 01:38:39
TRAINING STATS: batch 398/486 in epoch 407,  batch loss: 1.76976, batch accuracy: 0.52083
Time: 2018-07-15 01:38:44
TRAINING STATS: batch 448/486 in epoch 407,  batch loss: 1.76222, batch accuracy: 0.53483
Time: 2018-07-15 01:38:48
TRAINING STATS: batch 12/486 in epoch 408,   batch loss: 1.77628, batch accuracy: 0.52000
Time: 2018-07-15 01:38:51
TRAINING STATS: batch 62/486 in epoch 408,   batch loss: 1.83276, batch accuracy: 0.50667
Time: 2018-07-15 01:38:56
TRAINING STATS: batch 112/486 in epoch 408,  batch loss: 1.72764, batch accuracy: 0.53667
Time: 2018-07-15 01:39:00
TRAINING STATS: batch 162/486 in epoch 408,  batch loss: 1.76092, batch accuracy: 0.53233
Time: 2018-07-15 01:39:03
TRAINING STATS: batch 212/486 in epoch 408,  batch loss: 1.66285, batch accuracy: 0.55200
Time: 2018-07-15 01:39:08
TRAINING STATS: batch 262/486 in epoch 408,  batch loss: 1.84539, batch accuracy: 0.50483
Time: 2018-07-15 01:39:12
TRAINING STATS: batch 312/486 in epoch 408,  batch loss: 1.76616, batch accuracy: 0.51900
Time: 2018-07-15 01:39:16
TRAINING STATS: batch 362/486 in epoch 408,  batch loss: 1.76644, batch accuracy: 0.52917
Time: 2018-07-15 01:39:20
TRAINING STATS: batch 412/486 in epoch 408,  batch loss: 1.70131, batch accuracy: 0.55417
Time: 2018-07-15 01:39:24
TRAINING STATS: batch 462/486 in epoch 408,  batch loss: 1.75855, batch accuracy: 0.52683
Time: 2018-07-15 01:39:28
TRAINING STATS: batch 26/486 in epoch 409,   batch loss: 1.80942, batch accuracy: 0.51667
Time: 2018-07-15 01:39:32
TRAINING STATS: batch 76/486 in epoch 409,   batch loss: 1.81033, batch accuracy: 0.51817
Time: 2018-07-15 01:39:36
TRAINING STATS: batch 126/486 in epoch 409,  batch loss: 1.80118, batch accuracy: 0.51167
Time: 2018-07-15 01:39:40
TRAINING STATS: batch 176/486 in epoch 409,  batch loss: 1.66711, batch accuracy: 0.55367
Time: 2018-07-15 01:39:44
TRAINING STATS: batch 226/486 in epoch 409,  batch loss: 1.74203, batch accuracy: 0.53333
Time: 2018-07-15 01:39:48
TRAINING STATS: batch 276/486 in epoch 409,  batch loss: 1.74822, batch accuracy: 0.52800
Time: 2018-07-15 01:39:52
TRAINING STATS: batch 326/486 in epoch 409,  batch loss: 1.78989, batch accuracy: 0.51817
Time: 2018-07-15 01:39:56
TRAINING STATS: batch 376/486 in epoch 409,  batch loss: 1.80057, batch accuracy: 0.51650
Time: 2018-07-15 01:40:00
TRAINING STATS: batch 426/486 in epoch 409,  batch loss: 1.74703, batch accuracy: 0.52483
Time: 2018-07-15 01:40:04
TRAINING STATS: batch 476/486 in epoch 409,  batch loss: 1.70414, batch accuracy: 0.54283
Time: 2018-07-15 01:40:08
TRAINING STATS: batch 40/486 in epoch 410,   batch loss: 1.71178, batch accuracy: 0.53767
Time: 2018-07-15 01:40:12
TRAINING STATS: batch 90/486 in epoch 410,   batch loss: 1.77804, batch accuracy: 0.51867
Time: 2018-07-15 01:40:16
TRAINING STATS: batch 140/486 in epoch 410,  batch loss: 1.67791, batch accuracy: 0.55067
Time: 2018-07-15 01:40:21
TRAINING STATS: batch 190/486 in epoch 410,  batch loss: 1.71504, batch accuracy: 0.53650
Time: 2018-07-15 01:40:24
TRAINING STATS: batch 240/486 in epoch 410,  batch loss: 1.73474, batch accuracy: 0.53817
Time: 2018-07-15 01:40:28
TRAINING STATS: batch 290/486 in epoch 410,  batch loss: 1.77032, batch accuracy: 0.52883
Time: 2018-07-15 01:40:33
TRAINING STATS: batch 340/486 in epoch 410,  batch loss: 1.80493, batch accuracy: 0.51500
Time: 2018-07-15 01:40:36
TRAINING STATS: batch 390/486 in epoch 410,  batch loss: 1.67574, batch accuracy: 0.55183
Time: 2018-07-15 01:40:40
TRAINING STATS: batch 440/486 in epoch 410,  batch loss: 1.74647, batch accuracy: 0.52833
Time: 2018-07-15 01:40:45
TRAINING STATS: batch 4/486 in epoch 411,    batch loss: 1.69752, batch accuracy: 0.55017
Time: 2018-07-15 01:40:48
TRAINING STATS: batch 54/486 in epoch 411,   batch loss: 1.73869, batch accuracy: 0.53167
Time: 2018-07-15 01:40:52
TRAINING STATS: batch 104/486 in epoch 411,  batch loss: 1.75635, batch accuracy: 0.52817
Time: 2018-07-15 01:40:57
TRAINING STATS: batch 154/486 in epoch 411,  batch loss: 1.72555, batch accuracy: 0.53883
Time: 2018-07-15 01:41:00
TRAINING STATS: batch 204/486 in epoch 411,  batch loss: 1.81477, batch accuracy: 0.51600
Time: 2018-07-15 01:41:04
TRAINING STATS: batch 254/486 in epoch 411,  batch loss: 1.66878, batch accuracy: 0.55033
Time: 2018-07-15 01:41:09
TRAINING STATS: batch 304/486 in epoch 411,  batch loss: 1.69324, batch accuracy: 0.54967
Time: 2018-07-15 01:41:12
TRAINING STATS: batch 354/486 in epoch 411,  batch loss: 1.75083, batch accuracy: 0.53183
Time: 2018-07-15 01:41:16
TRAINING STATS: batch 404/486 in epoch 411,  batch loss: 1.73593, batch accuracy: 0.53133
Time: 2018-07-15 01:41:21
TRAINING STATS: batch 454/486 in epoch 411,  batch loss: 1.60661, batch accuracy: 0.56800
Time: 2018-07-15 01:41:24
TRAINING STATS: batch 18/486 in epoch 412,   batch loss: 1.78623, batch accuracy: 0.51767
Time: 2018-07-15 01:41:28
TRAINING STATS: batch 68/486 in epoch 412,   batch loss: 1.61616, batch accuracy: 0.57167
Time: 2018-07-15 01:41:33
TRAINING STATS: batch 118/486 in epoch 412,  batch loss: 1.72012, batch accuracy: 0.54367
Time: 2018-07-15 01:41:36
TRAINING STATS: batch 168/486 in epoch 412,  batch loss: 1.67597, batch accuracy: 0.55433
Time: 2018-07-15 01:41:40
TRAINING STATS: batch 218/486 in epoch 412,  batch loss: 1.72100, batch accuracy: 0.53783
Time: 2018-07-15 01:41:45
TRAINING STATS: batch 268/486 in epoch 412,  batch loss: 1.66994, batch accuracy: 0.54883
Time: 2018-07-15 01:41:48
TRAINING STATS: batch 318/486 in epoch 412,  batch loss: 1.71965, batch accuracy: 0.53717
Time: 2018-07-15 01:41:52
TRAINING STATS: batch 368/486 in epoch 412,  batch loss: 1.74692, batch accuracy: 0.52900
Time: 2018-07-15 01:41:57
TRAINING STATS: batch 418/486 in epoch 412,  batch loss: 1.79757, batch accuracy: 0.51117
Time: 2018-07-15 01:42:01
TRAINING STATS: batch 468/486 in epoch 412,  batch loss: 1.76496, batch accuracy: 0.52817
Time: 2018-07-15 01:42:04
TRAINING STATS: batch 32/486 in epoch 413,   batch loss: 1.70246, batch accuracy: 0.54250
Time: 2018-07-15 01:42:09
TRAINING STATS: batch 82/486 in epoch 413,   batch loss: 1.76448, batch accuracy: 0.52783
Time: 2018-07-15 01:42:13
TRAINING STATS: batch 132/486 in epoch 413,  batch loss: 1.72065, batch accuracy: 0.54450
Time: 2018-07-15 01:42:16
TRAINING STATS: batch 182/486 in epoch 413,  batch loss: 1.78373, batch accuracy: 0.52150
Time: 2018-07-15 01:42:21
TRAINING STATS: batch 232/486 in epoch 413,  batch loss: 1.75882, batch accuracy: 0.52683
Time: 2018-07-15 01:42:25
TRAINING STATS: batch 282/486 in epoch 413,  batch loss: 1.69543, batch accuracy: 0.54150
Time: 2018-07-15 01:42:28
TRAINING STATS: batch 332/486 in epoch 413,  batch loss: 1.76933, batch accuracy: 0.52833
Time: 2018-07-15 01:42:33
TRAINING STATS: batch 382/486 in epoch 413,  batch loss: 1.75576, batch accuracy: 0.53067
Time: 2018-07-15 01:42:37
TRAINING STATS: batch 432/486 in epoch 413,  batch loss: 1.68421, batch accuracy: 0.55350
Time: 2018-07-15 01:42:40
TRAINING STATS: batch 482/486 in epoch 413,  batch loss: 1.72273, batch accuracy: 0.54233
Time: 2018-07-15 01:42:45
TRAINING STATS: batch 46/486 in epoch 414,   batch loss: 1.71476, batch accuracy: 0.54317
Time: 2018-07-15 01:42:49
TRAINING STATS: batch 96/486 in epoch 414,   batch loss: 1.75633, batch accuracy: 0.53350
Time: 2018-07-15 01:42:52
TRAINING STATS: batch 146/486 in epoch 414,  batch loss: 1.77470, batch accuracy: 0.52983
Time: 2018-07-15 01:42:57
TRAINING STATS: batch 196/486 in epoch 414,  batch loss: 1.76947, batch accuracy: 0.52183
Time: 2018-07-15 01:43:01
TRAINING STATS: batch 246/486 in epoch 414,  batch loss: 1.71929, batch accuracy: 0.53683
Time: 2018-07-15 01:43:04
TRAINING STATS: batch 296/486 in epoch 414,  batch loss: 1.69173, batch accuracy: 0.54100
Time: 2018-07-15 01:43:09
TRAINING STATS: batch 346/486 in epoch 414,  batch loss: 1.65554, batch accuracy: 0.56433
Time: 2018-07-15 01:43:13
TRAINING STATS: batch 396/486 in epoch 414,  batch loss: 1.72004, batch accuracy: 0.54800
Time: 2018-07-15 01:43:17
TRAINING STATS: batch 446/486 in epoch 414,  batch loss: 1.75981, batch accuracy: 0.52567
Time: 2018-07-15 01:43:21
TRAINING STATS: batch 10/486 in epoch 415,   batch loss: 1.78240, batch accuracy: 0.52717
Time: 2018-07-15 01:43:25
TRAINING STATS: batch 60/486 in epoch 415,   batch loss: 1.73196, batch accuracy: 0.54600
Time: 2018-07-15 01:43:29
TRAINING STATS: batch 110/486 in epoch 415,  batch loss: 1.78557, batch accuracy: 0.52417
Time: 2018-07-15 01:43:33
TRAINING STATS: batch 160/486 in epoch 415,  batch loss: 1.71931, batch accuracy: 0.53767
Time: 2018-07-15 01:43:37
TRAINING STATS: batch 210/486 in epoch 415,  batch loss: 1.68894, batch accuracy: 0.54967
Time: 2018-07-15 01:43:41
TRAINING STATS: batch 260/486 in epoch 415,  batch loss: 1.77505, batch accuracy: 0.52250
Time: 2018-07-15 01:43:45
TRAINING STATS: batch 310/486 in epoch 415,  batch loss: 1.74948, batch accuracy: 0.52483
Time: 2018-07-15 01:43:49
TRAINING STATS: batch 360/486 in epoch 415,  batch loss: 1.79049, batch accuracy: 0.52133
Time: 2018-07-15 01:43:53
TRAINING STATS: batch 410/486 in epoch 415,  batch loss: 1.66424, batch accuracy: 0.56317
Time: 2018-07-15 01:43:57
TRAINING STATS: batch 460/486 in epoch 415,  batch loss: 1.86026, batch accuracy: 0.49333
Time: 2018-07-15 01:44:01
TRAINING STATS: batch 24/486 in epoch 416,   batch loss: 1.79124, batch accuracy: 0.52500
Time: 2018-07-15 01:44:05
TRAINING STATS: batch 74/486 in epoch 416,   batch loss: 1.76007, batch accuracy: 0.53550
Time: 2018-07-15 01:44:09
TRAINING STATS: batch 124/486 in epoch 416,  batch loss: 1.75604, batch accuracy: 0.53100
Time: 2018-07-15 01:44:13
TRAINING STATS: batch 174/486 in epoch 416,  batch loss: 1.80778, batch accuracy: 0.52600
Time: 2018-07-15 01:44:17
TRAINING STATS: batch 224/486 in epoch 416,  batch loss: 1.78980, batch accuracy: 0.52083
Time: 2018-07-15 01:44:21
TRAINING STATS: batch 274/486 in epoch 416,  batch loss: 1.73667, batch accuracy: 0.53383
Time: 2018-07-15 01:44:25
TRAINING STATS: batch 324/486 in epoch 416,  batch loss: 1.78257, batch accuracy: 0.52650
Time: 2018-07-15 01:44:29
TRAINING STATS: batch 374/486 in epoch 416,  batch loss: 1.77986, batch accuracy: 0.52650
Time: 2018-07-15 01:44:34
TRAINING STATS: batch 424/486 in epoch 416,  batch loss: 1.68596, batch accuracy: 0.54467
Time: 2018-07-15 01:44:37
TRAINING STATS: batch 474/486 in epoch 416,  batch loss: 1.74585, batch accuracy: 0.52800
Time: 2018-07-15 01:44:41
TRAINING STATS: batch 38/486 in epoch 417,   batch loss: 1.76591, batch accuracy: 0.53650
Time: 2018-07-15 01:44:46
TRAINING STATS: batch 88/486 in epoch 417,   batch loss: 1.77533, batch accuracy: 0.51933
Time: 2018-07-15 01:44:49
TRAINING STATS: batch 138/486 in epoch 417,  batch loss: 1.77329, batch accuracy: 0.52517
Time: 2018-07-15 01:44:53
TRAINING STATS: batch 188/486 in epoch 417,  batch loss: 1.69831, batch accuracy: 0.54583
Time: 2018-07-15 01:44:58
TRAINING STATS: batch 238/486 in epoch 417,  batch loss: 1.74318, batch accuracy: 0.53300
Time: 2018-07-15 01:45:01
TRAINING STATS: batch 288/486 in epoch 417,  batch loss: 1.78318, batch accuracy: 0.52750
Time: 2018-07-15 01:45:05
TRAINING STATS: batch 338/486 in epoch 417,  batch loss: 1.75962, batch accuracy: 0.52767
Time: 2018-07-15 01:45:10
TRAINING STATS: batch 388/486 in epoch 417,  batch loss: 1.70152, batch accuracy: 0.54000
Time: 2018-07-15 01:45:13
TRAINING STATS: batch 438/486 in epoch 417,  batch loss: 1.75840, batch accuracy: 0.53117
Time: 2018-07-15 01:45:17
TRAINING STATS: batch 2/486 in epoch 418,    batch loss: 1.75200, batch accuracy: 0.53167
Time: 2018-07-15 01:45:22
TRAINING STATS: batch 52/486 in epoch 418,   batch loss: 1.80078, batch accuracy: 0.51583
Time: 2018-07-15 01:45:25
TRAINING STATS: batch 102/486 in epoch 418,  batch loss: 1.76513, batch accuracy: 0.52983
Time: 2018-07-15 01:45:29
TRAINING STATS: batch 152/486 in epoch 418,  batch loss: 1.70016, batch accuracy: 0.54850
Time: 2018-07-15 01:45:34
TRAINING STATS: batch 202/486 in epoch 418,  batch loss: 1.75479, batch accuracy: 0.53950
Time: 2018-07-15 01:45:37
TRAINING STATS: batch 252/486 in epoch 418,  batch loss: 1.70716, batch accuracy: 0.54283
Time: 2018-07-15 01:45:41
TRAINING STATS: batch 302/486 in epoch 418,  batch loss: 1.69992, batch accuracy: 0.54400
Time: 2018-07-15 01:45:46
TRAINING STATS: batch 352/486 in epoch 418,  batch loss: 1.72252, batch accuracy: 0.53900
Time: 2018-07-15 01:45:49
TRAINING STATS: batch 402/486 in epoch 418,  batch loss: 1.63988, batch accuracy: 0.56450
Time: 2018-07-15 01:45:53
TRAINING STATS: batch 452/486 in epoch 418,  batch loss: 1.74444, batch accuracy: 0.53100
Time: 2018-07-15 01:45:58
TRAINING STATS: batch 16/486 in epoch 419,   batch loss: 1.70314, batch accuracy: 0.54683
Time: 2018-07-15 01:46:02
TRAINING STATS: batch 66/486 in epoch 419,   batch loss: 1.73118, batch accuracy: 0.53683
Time: 2018-07-15 01:46:05
TRAINING STATS: batch 116/486 in epoch 419,  batch loss: 1.70630, batch accuracy: 0.54750
Time: 2018-07-15 01:46:10
TRAINING STATS: batch 166/486 in epoch 419,  batch loss: 1.63831, batch accuracy: 0.56200
Time: 2018-07-15 01:46:14
TRAINING STATS: batch 216/486 in epoch 419,  batch loss: 1.75136, batch accuracy: 0.53533
Time: 2018-07-15 01:46:17
TRAINING STATS: batch 266/486 in epoch 419,  batch loss: 1.75370, batch accuracy: 0.52883
Time: 2018-07-15 01:46:22
TRAINING STATS: batch 316/486 in epoch 419,  batch loss: 1.73451, batch accuracy: 0.53650
Time: 2018-07-15 01:46:26
TRAINING STATS: batch 366/486 in epoch 419,  batch loss: 1.77931, batch accuracy: 0.52067
Time: 2018-07-15 01:46:29
TRAINING STATS: batch 416/486 in epoch 419,  batch loss: 1.76760, batch accuracy: 0.52050
Time: 2018-07-15 01:46:34
TRAINING STATS: batch 466/486 in epoch 419,  batch loss: 1.60129, batch accuracy: 0.56967
Time: 2018-07-15 01:46:38
TRAINING STATS: batch 30/486 in epoch 420,   batch loss: 1.62068, batch accuracy: 0.56883
Time: 2018-07-15 01:46:41
TRAINING STATS: batch 80/486 in epoch 420,   batch loss: 1.73158, batch accuracy: 0.53100
Time: 2018-07-15 01:46:46
TRAINING STATS: batch 130/486 in epoch 420,  batch loss: 1.71330, batch accuracy: 0.54917
Time: 2018-07-15 01:46:50
TRAINING STATS: batch 180/486 in epoch 420,  batch loss: 1.75253, batch accuracy: 0.53850
Time: 2018-07-15 01:46:53
TRAINING STATS: batch 230/486 in epoch 420,  batch loss: 1.74505, batch accuracy: 0.53067
Time: 2018-07-15 01:46:58
TRAINING STATS: batch 280/486 in epoch 420,  batch loss: 1.71887, batch accuracy: 0.53317
Time: 2018-07-15 01:47:02
TRAINING STATS: batch 330/486 in epoch 420,  batch loss: 1.69711, batch accuracy: 0.54533
Time: 2018-07-15 01:47:05
TRAINING STATS: batch 380/486 in epoch 420,  batch loss: 1.71869, batch accuracy: 0.54533
Time: 2018-07-15 01:47:10
TRAINING STATS: batch 430/486 in epoch 420,  batch loss: 1.66919, batch accuracy: 0.55967
Time: 2018-07-15 01:47:14
TRAINING STATS: batch 480/486 in epoch 420,  batch loss: 1.73917, batch accuracy: 0.53850
Time: 2018-07-15 01:47:18
TRAINING STATS: batch 44/486 in epoch 421,   batch loss: 1.67217, batch accuracy: 0.55267
Time: 2018-07-15 01:47:22
TRAINING STATS: batch 94/486 in epoch 421,   batch loss: 1.76561, batch accuracy: 0.53733
Time: 2018-07-15 01:47:26
TRAINING STATS: batch 144/486 in epoch 421,  batch loss: 1.79621, batch accuracy: 0.51700
Time: 2018-07-15 01:47:30
TRAINING STATS: batch 194/486 in epoch 421,  batch loss: 1.82124, batch accuracy: 0.50733
Time: 2018-07-15 01:47:34
TRAINING STATS: batch 244/486 in epoch 421,  batch loss: 1.72381, batch accuracy: 0.53850
Time: 2018-07-15 01:47:38
TRAINING STATS: batch 294/486 in epoch 421,  batch loss: 1.64281, batch accuracy: 0.55467
Time: 2018-07-15 01:47:42
TRAINING STATS: batch 344/486 in epoch 421,  batch loss: 1.70821, batch accuracy: 0.54317
Time: 2018-07-15 01:47:46
TRAINING STATS: batch 394/486 in epoch 421,  batch loss: 1.69152, batch accuracy: 0.55267
Time: 2018-07-15 01:47:50
TRAINING STATS: batch 444/486 in epoch 421,  batch loss: 1.67976, batch accuracy: 0.54933
Time: 2018-07-15 01:47:54
TRAINING STATS: batch 8/486 in epoch 422,    batch loss: 1.71879, batch accuracy: 0.53950
Time: 2018-07-15 01:47:59
TRAINING STATS: batch 58/486 in epoch 422,   batch loss: 1.71696, batch accuracy: 0.54367
Time: 2018-07-15 01:48:02
TRAINING STATS: batch 108/486 in epoch 422,  batch loss: 1.79547, batch accuracy: 0.51983
Time: 2018-07-15 01:48:06
TRAINING STATS: batch 158/486 in epoch 422,  batch loss: 1.78624, batch accuracy: 0.52050
Time: 2018-07-15 01:48:11
TRAINING STATS: batch 208/486 in epoch 422,  batch loss: 1.75008, batch accuracy: 0.53683
Time: 2018-07-15 01:48:14
TRAINING STATS: batch 258/486 in epoch 422,  batch loss: 1.68424, batch accuracy: 0.54583
Time: 2018-07-15 01:48:18
TRAINING STATS: batch 308/486 in epoch 422,  batch loss: 1.73448, batch accuracy: 0.53900
Time: 2018-07-15 01:48:23
TRAINING STATS: batch 358/486 in epoch 422,  batch loss: 1.75267, batch accuracy: 0.52950
Time: 2018-07-15 01:48:26
TRAINING STATS: batch 408/486 in epoch 422,  batch loss: 1.76715, batch accuracy: 0.52300
Time: 2018-07-15 01:48:30
TRAINING STATS: batch 458/486 in epoch 422,  batch loss: 1.78724, batch accuracy: 0.53300
Time: 2018-07-15 01:48:35
TRAINING STATS: batch 22/486 in epoch 423,   batch loss: 1.77595, batch accuracy: 0.53083
Time: 2018-07-15 01:48:38
TRAINING STATS: batch 72/486 in epoch 423,   batch loss: 1.76230, batch accuracy: 0.52150
Time: 2018-07-15 01:48:42
TRAINING STATS: batch 122/486 in epoch 423,  batch loss: 1.67536, batch accuracy: 0.55633
Time: 2018-07-15 01:48:47
TRAINING STATS: batch 172/486 in epoch 423,  batch loss: 1.77766, batch accuracy: 0.51867
Time: 2018-07-15 01:48:50
TRAINING STATS: batch 222/486 in epoch 423,  batch loss: 1.71468, batch accuracy: 0.53250
Time: 2018-07-15 01:48:54
TRAINING STATS: batch 272/486 in epoch 423,  batch loss: 1.76115, batch accuracy: 0.52400
Time: 2018-07-15 01:48:59
TRAINING STATS: batch 322/486 in epoch 423,  batch loss: 1.72376, batch accuracy: 0.53683
Time: 2018-07-15 01:49:02
TRAINING STATS: batch 372/486 in epoch 423,  batch loss: 1.67999, batch accuracy: 0.55067
Time: 2018-07-15 01:49:06
TRAINING STATS: batch 422/486 in epoch 423,  batch loss: 1.69838, batch accuracy: 0.54283
Time: 2018-07-15 01:49:11
TRAINING STATS: batch 472/486 in epoch 423,  batch loss: 1.78175, batch accuracy: 0.52450
Time: 2018-07-15 01:49:15
TRAINING STATS: batch 36/486 in epoch 424,   batch loss: 1.79258, batch accuracy: 0.52433
Time: 2018-07-15 01:49:18
TRAINING STATS: batch 86/486 in epoch 424,   batch loss: 1.72528, batch accuracy: 0.53883
Time: 2018-07-15 01:49:23
TRAINING STATS: batch 136/486 in epoch 424,  batch loss: 1.76903, batch accuracy: 0.52533
Time: 2018-07-15 01:49:27
TRAINING STATS: batch 186/486 in epoch 424,  batch loss: 1.72850, batch accuracy: 0.54050
Time: 2018-07-15 01:49:30
TRAINING STATS: batch 236/486 in epoch 424,  batch loss: 1.76208, batch accuracy: 0.52900
Time: 2018-07-15 01:49:35
TRAINING STATS: batch 286/486 in epoch 424,  batch loss: 1.76484, batch accuracy: 0.53100
Time: 2018-07-15 01:49:39
TRAINING STATS: batch 336/486 in epoch 424,  batch loss: 1.71553, batch accuracy: 0.54233
Time: 2018-07-15 01:49:42
TRAINING STATS: batch 386/486 in epoch 424,  batch loss: 1.77146, batch accuracy: 0.52700
Time: 2018-07-15 01:49:47
TRAINING STATS: batch 436/486 in epoch 424,  batch loss: 1.75805, batch accuracy: 0.52933
Time: 2018-07-15 01:49:51
TRAINING STATS: batch 0/486 in epoch 425,    batch loss: 1.70848, batch accuracy: 0.53750
Time: 2018-07-15 01:49:54
TRAINING STATS: batch 50/486 in epoch 425,   batch loss: 1.69314, batch accuracy: 0.55683
Time: 2018-07-15 01:49:59
TRAINING STATS: batch 100/486 in epoch 425,  batch loss: 1.74225, batch accuracy: 0.53667
Time: 2018-07-15 01:50:03
TRAINING STATS: batch 150/486 in epoch 425,  batch loss: 1.69010, batch accuracy: 0.55433
Time: 2018-07-15 01:50:06
TRAINING STATS: batch 200/486 in epoch 425,  batch loss: 1.61786, batch accuracy: 0.57167
Time: 2018-07-15 01:50:11
TRAINING STATS: batch 250/486 in epoch 425,  batch loss: 1.78526, batch accuracy: 0.51600
Time: 2018-07-15 01:50:15
TRAINING STATS: batch 300/486 in epoch 425,  batch loss: 1.75596, batch accuracy: 0.52250
Time: 2018-07-15 01:50:18
TRAINING STATS: batch 350/486 in epoch 425,  batch loss: 1.74563, batch accuracy: 0.54017
Time: 2018-07-15 01:50:23
TRAINING STATS: batch 400/486 in epoch 425,  batch loss: 1.64359, batch accuracy: 0.56350
Time: 2018-07-15 01:50:27
TRAINING STATS: batch 450/486 in epoch 425,  batch loss: 1.78441, batch accuracy: 0.52400
Time: 2018-07-15 01:50:31
TRAINING STATS: batch 14/486 in epoch 426,   batch loss: 1.66121, batch accuracy: 0.55767
Time: 2018-07-15 01:50:35
TRAINING STATS: batch 64/486 in epoch 426,   batch loss: 1.81895, batch accuracy: 0.50567
Time: 2018-07-15 01:50:39
TRAINING STATS: batch 114/486 in epoch 426,  batch loss: 1.76579, batch accuracy: 0.52717
Time: 2018-07-15 01:50:43
TRAINING STATS: batch 164/486 in epoch 426,  batch loss: 1.65295, batch accuracy: 0.56950
Time: 2018-07-15 01:50:47
TRAINING STATS: batch 214/486 in epoch 426,  batch loss: 1.72872, batch accuracy: 0.54050
Time: 2018-07-15 01:50:51
TRAINING STATS: batch 264/486 in epoch 426,  batch loss: 1.75643, batch accuracy: 0.52650
Time: 2018-07-15 01:50:55
TRAINING STATS: batch 314/486 in epoch 426,  batch loss: 1.78198, batch accuracy: 0.51583
Time: 2018-07-15 01:50:59
TRAINING STATS: batch 364/486 in epoch 426,  batch loss: 1.70235, batch accuracy: 0.54683
Time: 2018-07-15 01:51:03
TRAINING STATS: batch 414/486 in epoch 426,  batch loss: 1.65871, batch accuracy: 0.55950
Time: 2018-07-15 01:51:07
TRAINING STATS: batch 464/486 in epoch 426,  batch loss: 1.70301, batch accuracy: 0.55100
Time: 2018-07-15 01:51:11
TRAINING STATS: batch 28/486 in epoch 427,   batch loss: 1.65254, batch accuracy: 0.56033
Time: 2018-07-15 01:51:15
TRAINING STATS: batch 78/486 in epoch 427,   batch loss: 1.72721, batch accuracy: 0.54183
Time: 2018-07-15 01:51:19
TRAINING STATS: batch 128/486 in epoch 427,  batch loss: 1.71200, batch accuracy: 0.54600
Time: 2018-07-15 01:51:24
TRAINING STATS: batch 178/486 in epoch 427,  batch loss: 1.62065, batch accuracy: 0.56717
Time: 2018-07-15 01:51:27
TRAINING STATS: batch 228/486 in epoch 427,  batch loss: 1.68282, batch accuracy: 0.55467
Time: 2018-07-15 01:51:31
TRAINING STATS: batch 278/486 in epoch 427,  batch loss: 1.65397, batch accuracy: 0.55933
Time: 2018-07-15 01:51:36
TRAINING STATS: batch 328/486 in epoch 427,  batch loss: 1.68023, batch accuracy: 0.55250
Time: 2018-07-15 01:51:39
TRAINING STATS: batch 378/486 in epoch 427,  batch loss: 1.71937, batch accuracy: 0.54250
Time: 2018-07-15 01:51:43
TRAINING STATS: batch 428/486 in epoch 427,  batch loss: 1.76469, batch accuracy: 0.52883
Time: 2018-07-15 01:51:48
TRAINING STATS: batch 478/486 in epoch 427,  batch loss: 1.74862, batch accuracy: 0.52700
Time: 2018-07-15 01:51:51
TRAINING STATS: batch 42/486 in epoch 428,   batch loss: 1.63395, batch accuracy: 0.56317
Time: 2018-07-15 01:51:55
TRAINING STATS: batch 92/486 in epoch 428,   batch loss: 1.72161, batch accuracy: 0.53717
Time: 2018-07-15 01:52:00
TRAINING STATS: batch 142/486 in epoch 428,  batch loss: 1.69098, batch accuracy: 0.54950
Time: 2018-07-15 01:52:04
TRAINING STATS: batch 192/486 in epoch 428,  batch loss: 1.72040, batch accuracy: 0.54600
Time: 2018-07-15 01:52:07
TRAINING STATS: batch 242/486 in epoch 428,  batch loss: 1.68694, batch accuracy: 0.54733
Time: 2018-07-15 01:52:12
TRAINING STATS: batch 292/486 in epoch 428,  batch loss: 1.71893, batch accuracy: 0.53750
Time: 2018-07-15 01:52:16
TRAINING STATS: batch 342/486 in epoch 428,  batch loss: 1.69421, batch accuracy: 0.54917
Time: 2018-07-15 01:52:19
TRAINING STATS: batch 392/486 in epoch 428,  batch loss: 1.64309, batch accuracy: 0.55683
Time: 2018-07-15 01:52:24
TRAINING STATS: batch 442/486 in epoch 428,  batch loss: 1.63550, batch accuracy: 0.56650
Time: 2018-07-15 01:52:28
TRAINING STATS: batch 6/486 in epoch 429,    batch loss: 1.75357, batch accuracy: 0.53400
Time: 2018-07-15 01:52:31
TRAINING STATS: batch 56/486 in epoch 429,   batch loss: 1.67049, batch accuracy: 0.55267
Time: 2018-07-15 01:52:36
TRAINING STATS: batch 106/486 in epoch 429,  batch loss: 1.77279, batch accuracy: 0.52667
Time: 2018-07-15 01:52:40
TRAINING STATS: batch 156/486 in epoch 429,  batch loss: 1.75252, batch accuracy: 0.52400
Time: 2018-07-15 01:52:43
TRAINING STATS: batch 206/486 in epoch 429,  batch loss: 1.80162, batch accuracy: 0.51467
Time: 2018-07-15 01:52:48
TRAINING STATS: batch 256/486 in epoch 429,  batch loss: 1.65618, batch accuracy: 0.56017
Time: 2018-07-15 01:52:52
TRAINING STATS: batch 306/486 in epoch 429,  batch loss: 1.71088, batch accuracy: 0.54233
Time: 2018-07-15 01:52:55
TRAINING STATS: batch 356/486 in epoch 429,  batch loss: 1.75980, batch accuracy: 0.52233
Time: 2018-07-15 01:53:00
TRAINING STATS: batch 406/486 in epoch 429,  batch loss: 1.79176, batch accuracy: 0.51700
Time: 2018-07-15 01:53:04
TRAINING STATS: batch 456/486 in epoch 429,  batch loss: 1.59986, batch accuracy: 0.57833
Time: 2018-07-15 01:53:07
TRAINING STATS: batch 20/486 in epoch 430,   batch loss: 1.72849, batch accuracy: 0.53917
Time: 2018-07-15 01:53:12
TRAINING STATS: batch 70/486 in epoch 430,   batch loss: 1.61412, batch accuracy: 0.57550
Time: 2018-07-15 01:53:16
TRAINING STATS: batch 120/486 in epoch 430,  batch loss: 1.67017, batch accuracy: 0.55333
Time: 2018-07-15 01:53:20
TRAINING STATS: batch 170/486 in epoch 430,  batch loss: 1.69316, batch accuracy: 0.54500
Time: 2018-07-15 01:53:24
TRAINING STATS: batch 220/486 in epoch 430,  batch loss: 1.63711, batch accuracy: 0.57083
Time: 2018-07-15 01:53:28
TRAINING STATS: batch 270/486 in epoch 430,  batch loss: 1.72692, batch accuracy: 0.53000
Time: 2018-07-15 01:53:32
TRAINING STATS: batch 320/486 in epoch 430,  batch loss: 1.63931, batch accuracy: 0.55367
Time: 2018-07-15 01:53:36
TRAINING STATS: batch 370/486 in epoch 430,  batch loss: 1.68520, batch accuracy: 0.54933
Time: 2018-07-15 01:53:40
TRAINING STATS: batch 420/486 in epoch 430,  batch loss: 1.74672, batch accuracy: 0.53467
Time: 2018-07-15 01:53:44
TRAINING STATS: batch 470/486 in epoch 430,  batch loss: 1.80455, batch accuracy: 0.51083
Time: 2018-07-15 01:53:48
TRAINING STATS: batch 34/486 in epoch 431,   batch loss: 1.72211, batch accuracy: 0.53600
Time: 2018-07-15 01:53:52
TRAINING STATS: batch 84/486 in epoch 431,   batch loss: 1.71960, batch accuracy: 0.53233
Time: 2018-07-15 01:53:56
TRAINING STATS: batch 134/486 in epoch 431,  batch loss: 1.74230, batch accuracy: 0.53767
Time: 2018-07-15 01:54:00
TRAINING STATS: batch 184/486 in epoch 431,  batch loss: 1.72235, batch accuracy: 0.53583
Time: 2018-07-15 01:54:04
TRAINING STATS: batch 234/486 in epoch 431,  batch loss: 1.79370, batch accuracy: 0.52050
Time: 2018-07-15 01:54:08
TRAINING STATS: batch 284/486 in epoch 431,  batch loss: 1.75543, batch accuracy: 0.53050
Time: 2018-07-15 01:54:12
TRAINING STATS: batch 334/486 in epoch 431,  batch loss: 1.69033, batch accuracy: 0.54317
Time: 2018-07-15 01:54:16
TRAINING STATS: batch 384/486 in epoch 431,  batch loss: 1.68372, batch accuracy: 0.55500
Time: 2018-07-15 01:54:20
TRAINING STATS: batch 434/486 in epoch 431,  batch loss: 1.76373, batch accuracy: 0.52000
Time: 2018-07-15 01:54:24
TRAINING STATS: batch 484/486 in epoch 431,  batch loss: 1.72848, batch accuracy: 0.53383
Time: 2018-07-15 01:54:28
TRAINING STATS: batch 48/486 in epoch 432,   batch loss: 1.71751, batch accuracy: 0.53500
Time: 2018-07-15 01:54:32
TRAINING STATS: batch 98/486 in epoch 432,   batch loss: 1.65908, batch accuracy: 0.55517
Time: 2018-07-15 01:54:37
TRAINING STATS: batch 148/486 in epoch 432,  batch loss: 1.75653, batch accuracy: 0.53150
Time: 2018-07-15 01:54:40
TRAINING STATS: batch 198/486 in epoch 432,  batch loss: 1.69242, batch accuracy: 0.54250
Time: 2018-07-15 01:54:44
TRAINING STATS: batch 248/486 in epoch 432,  batch loss: 1.72668, batch accuracy: 0.53850
Time: 2018-07-15 01:54:49
TRAINING STATS: batch 298/486 in epoch 432,  batch loss: 1.72789, batch accuracy: 0.53183
Time: 2018-07-15 01:54:52
TRAINING STATS: batch 348/486 in epoch 432,  batch loss: 1.72004, batch accuracy: 0.54500
Time: 2018-07-15 01:54:56
TRAINING STATS: batch 398/486 in epoch 432,  batch loss: 1.70973, batch accuracy: 0.54033
Time: 2018-07-15 01:55:01
TRAINING STATS: batch 448/486 in epoch 432,  batch loss: 1.69433, batch accuracy: 0.55183
Time: 2018-07-15 01:55:04
TRAINING STATS: batch 12/486 in epoch 433,   batch loss: 1.72439, batch accuracy: 0.53517
Time: 2018-07-15 01:55:08
TRAINING STATS: batch 62/486 in epoch 433,   batch loss: 1.78145, batch accuracy: 0.52133
Time: 2018-07-15 01:55:13
TRAINING STATS: batch 112/486 in epoch 433,  batch loss: 1.70739, batch accuracy: 0.54250
Time: 2018-07-15 01:55:16
TRAINING STATS: batch 162/486 in epoch 433,  batch loss: 1.71505, batch accuracy: 0.55050
Time: 2018-07-15 01:55:20
TRAINING STATS: batch 212/486 in epoch 433,  batch loss: 1.63482, batch accuracy: 0.56483
Time: 2018-07-15 01:55:25
TRAINING STATS: batch 262/486 in epoch 433,  batch loss: 1.75941, batch accuracy: 0.52167
Time: 2018-07-15 01:55:28
TRAINING STATS: batch 312/486 in epoch 433,  batch loss: 1.72059, batch accuracy: 0.53767
Time: 2018-07-15 01:55:32
TRAINING STATS: batch 362/486 in epoch 433,  batch loss: 1.71634, batch accuracy: 0.54033
Time: 2018-07-15 01:55:37
TRAINING STATS: batch 412/486 in epoch 433,  batch loss: 1.65833, batch accuracy: 0.56333
Time: 2018-07-15 01:55:40
TRAINING STATS: batch 462/486 in epoch 433,  batch loss: 1.71823, batch accuracy: 0.53333
Time: 2018-07-15 01:55:44
TRAINING STATS: batch 26/486 in epoch 434,   batch loss: 1.75880, batch accuracy: 0.51967
Time: 2018-07-15 01:55:49
TRAINING STATS: batch 76/486 in epoch 434,   batch loss: 1.75568, batch accuracy: 0.53200
Time: 2018-07-15 01:55:52
TRAINING STATS: batch 126/486 in epoch 434,  batch loss: 1.74003, batch accuracy: 0.53667
Time: 2018-07-15 01:55:56
TRAINING STATS: batch 176/486 in epoch 434,  batch loss: 1.61727, batch accuracy: 0.57050
Time: 2018-07-15 01:56:01
TRAINING STATS: batch 226/486 in epoch 434,  batch loss: 1.67770, batch accuracy: 0.55833
Time: 2018-07-15 01:56:04
TRAINING STATS: batch 276/486 in epoch 434,  batch loss: 1.71971, batch accuracy: 0.54017
Time: 2018-07-15 01:56:08
TRAINING STATS: batch 326/486 in epoch 434,  batch loss: 1.75382, batch accuracy: 0.53167
Time: 2018-07-15 01:56:13
TRAINING STATS: batch 376/486 in epoch 434,  batch loss: 1.73046, batch accuracy: 0.53817
Time: 2018-07-15 01:56:16
TRAINING STATS: batch 426/486 in epoch 434,  batch loss: 1.71309, batch accuracy: 0.53850
Time: 2018-07-15 01:56:20
TRAINING STATS: batch 476/486 in epoch 434,  batch loss: 1.67462, batch accuracy: 0.55483
Time: 2018-07-15 01:56:25
TRAINING STATS: batch 40/486 in epoch 435,   batch loss: 1.66881, batch accuracy: 0.54900
Time: 2018-07-15 01:56:28
TRAINING STATS: batch 90/486 in epoch 435,   batch loss: 1.77161, batch accuracy: 0.51833
Time: 2018-07-15 01:56:32
TRAINING STATS: batch 140/486 in epoch 435,  batch loss: 1.64318, batch accuracy: 0.55567
Time: 2018-07-15 01:56:37
TRAINING STATS: batch 190/486 in epoch 435,  batch loss: 1.67856, batch accuracy: 0.55367
Time: 2018-07-15 01:56:41
TRAINING STATS: batch 240/486 in epoch 435,  batch loss: 1.70244, batch accuracy: 0.54383
Time: 2018-07-15 01:56:44
TRAINING STATS: batch 290/486 in epoch 435,  batch loss: 1.71841, batch accuracy: 0.53167
Time: 2018-07-15 01:56:49
TRAINING STATS: batch 340/486 in epoch 435,  batch loss: 1.77505, batch accuracy: 0.52300
Time: 2018-07-15 01:56:53
TRAINING STATS: batch 390/486 in epoch 435,  batch loss: 1.64482, batch accuracy: 0.55517
Time: 2018-07-15 01:56:56
TRAINING STATS: batch 440/486 in epoch 435,  batch loss: 1.71102, batch accuracy: 0.54550
Time: 2018-07-15 01:57:01
TRAINING STATS: batch 4/486 in epoch 436,    batch loss: 1.66305, batch accuracy: 0.54867
Time: 2018-07-15 01:57:05
TRAINING STATS: batch 54/486 in epoch 436,   batch loss: 1.70908, batch accuracy: 0.53967
Time: 2018-07-15 01:57:08
TRAINING STATS: batch 104/486 in epoch 436,  batch loss: 1.74721, batch accuracy: 0.53400
Time: 2018-07-15 01:57:13
TRAINING STATS: batch 154/486 in epoch 436,  batch loss: 1.68480, batch accuracy: 0.54717
Time: 2018-07-15 01:57:17
TRAINING STATS: batch 204/486 in epoch 436,  batch loss: 1.78189, batch accuracy: 0.52233
Time: 2018-07-15 01:57:20
TRAINING STATS: batch 254/486 in epoch 436,  batch loss: 1.63491, batch accuracy: 0.56017
Time: 2018-07-15 01:57:25
TRAINING STATS: batch 304/486 in epoch 436,  batch loss: 1.65468, batch accuracy: 0.56150
Time: 2018-07-15 01:57:29
TRAINING STATS: batch 354/486 in epoch 436,  batch loss: 1.70450, batch accuracy: 0.54100
Time: 2018-07-15 01:57:32
TRAINING STATS: batch 404/486 in epoch 436,  batch loss: 1.67535, batch accuracy: 0.54583
Time: 2018-07-15 01:57:37
TRAINING STATS: batch 454/486 in epoch 436,  batch loss: 1.57435, batch accuracy: 0.57983
Time: 2018-07-15 01:57:41
TRAINING STATS: batch 18/486 in epoch 437,   batch loss: 1.73526, batch accuracy: 0.53500
Time: 2018-07-15 01:57:44
TRAINING STATS: batch 68/486 in epoch 437,   batch loss: 1.56282, batch accuracy: 0.58167
Time: 2018-07-15 01:57:49
TRAINING STATS: batch 118/486 in epoch 437,  batch loss: 1.68515, batch accuracy: 0.55383
Time: 2018-07-15 01:57:53
TRAINING STATS: batch 168/486 in epoch 437,  batch loss: 1.63956, batch accuracy: 0.56200
Time: 2018-07-15 01:57:57
TRAINING STATS: batch 218/486 in epoch 437,  batch loss: 1.68825, batch accuracy: 0.54183
Time: 2018-07-15 01:58:01
TRAINING STATS: batch 268/486 in epoch 437,  batch loss: 1.64209, batch accuracy: 0.56033
Time: 2018-07-15 01:58:05
TRAINING STATS: batch 318/486 in epoch 437,  batch loss: 1.69643, batch accuracy: 0.53883
Time: 2018-07-15 01:58:09
TRAINING STATS: batch 368/486 in epoch 437,  batch loss: 1.70441, batch accuracy: 0.53950
Time: 2018-07-15 01:58:13
TRAINING STATS: batch 418/486 in epoch 437,  batch loss: 1.73941, batch accuracy: 0.52617
Time: 2018-07-15 01:58:17
TRAINING STATS: batch 468/486 in epoch 437,  batch loss: 1.72393, batch accuracy: 0.54517
Time: 2018-07-15 01:58:21
TRAINING STATS: batch 32/486 in epoch 438,   batch loss: 1.67196, batch accuracy: 0.55000
Time: 2018-07-15 01:58:26
TRAINING STATS: batch 82/486 in epoch 438,   batch loss: 1.73910, batch accuracy: 0.53133
Time: 2018-07-15 01:58:29
TRAINING STATS: batch 132/486 in epoch 438,  batch loss: 1.68495, batch accuracy: 0.55533
Time: 2018-07-15 01:58:33
TRAINING STATS: batch 182/486 in epoch 438,  batch loss: 1.74604, batch accuracy: 0.52683
Time: 2018-07-15 01:58:38
TRAINING STATS: batch 232/486 in epoch 438,  batch loss: 1.72956, batch accuracy: 0.53183
Time: 2018-07-15 01:58:41
TRAINING STATS: batch 282/486 in epoch 438,  batch loss: 1.66399, batch accuracy: 0.55167
Time: 2018-07-15 01:58:45
TRAINING STATS: batch 332/486 in epoch 438,  batch loss: 1.73375, batch accuracy: 0.53350
Time: 2018-07-15 01:58:50
TRAINING STATS: batch 382/486 in epoch 438,  batch loss: 1.72379, batch accuracy: 0.53900
Time: 2018-07-15 01:58:53
TRAINING STATS: batch 432/486 in epoch 438,  batch loss: 1.63917, batch accuracy: 0.56750
Time: 2018-07-15 01:58:57
TRAINING STATS: batch 482/486 in epoch 438,  batch loss: 1.68764, batch accuracy: 0.54867
Time: 2018-07-15 01:59:02
TRAINING STATS: batch 46/486 in epoch 439,   batch loss: 1.69449, batch accuracy: 0.54833
Time: 2018-07-15 01:59:05
TRAINING STATS: batch 96/486 in epoch 439,   batch loss: 1.72516, batch accuracy: 0.53767
Time: 2018-07-15 01:59:09
TRAINING STATS: batch 146/486 in epoch 439,  batch loss: 1.75839, batch accuracy: 0.52767
Time: 2018-07-15 01:59:14
TRAINING STATS: batch 196/486 in epoch 439,  batch loss: 1.75358, batch accuracy: 0.52717
Time: 2018-07-15 01:59:17
TRAINING STATS: batch 246/486 in epoch 439,  batch loss: 1.67949, batch accuracy: 0.54667
Time: 2018-07-15 01:59:21
TRAINING STATS: batch 296/486 in epoch 439,  batch loss: 1.66920, batch accuracy: 0.55367
Time: 2018-07-15 01:59:26
TRAINING STATS: batch 346/486 in epoch 439,  batch loss: 1.61719, batch accuracy: 0.56950
Time: 2018-07-15 01:59:30
TRAINING STATS: batch 396/486 in epoch 439,  batch loss: 1.67939, batch accuracy: 0.54717
Time: 2018-07-15 01:59:33
TRAINING STATS: batch 446/486 in epoch 439,  batch loss: 1.73203, batch accuracy: 0.53417
Time: 2018-07-15 01:59:38
TRAINING STATS: batch 10/486 in epoch 440,   batch loss: 1.74249, batch accuracy: 0.53567
Time: 2018-07-15 01:59:41
TRAINING STATS: batch 60/486 in epoch 440,   batch loss: 1.69498, batch accuracy: 0.54767
Time: 2018-07-15 01:59:45
TRAINING STATS: batch 110/486 in epoch 440,  batch loss: 1.75352, batch accuracy: 0.53150
Time: 2018-07-15 01:59:50
TRAINING STATS: batch 160/486 in epoch 440,  batch loss: 1.67764, batch accuracy: 0.54167
Time: 2018-07-15 01:59:54
TRAINING STATS: batch 210/486 in epoch 440,  batch loss: 1.65099, batch accuracy: 0.55283
Time: 2018-07-15 01:59:57
TRAINING STATS: batch 260/486 in epoch 440,  batch loss: 1.73509, batch accuracy: 0.53400
Time: 2018-07-15 02:00:02
TRAINING STATS: batch 310/486 in epoch 440,  batch loss: 1.72399, batch accuracy: 0.53450
Time: 2018-07-15 02:00:06
TRAINING STATS: batch 360/486 in epoch 440,  batch loss: 1.73020, batch accuracy: 0.53183
Time: 2018-07-15 02:00:09
TRAINING STATS: batch 410/486 in epoch 440,  batch loss: 1.63150, batch accuracy: 0.56967
Time: 2018-07-15 02:00:14
TRAINING STATS: batch 460/486 in epoch 440,  batch loss: 1.82501, batch accuracy: 0.50233
Time: 2018-07-15 02:00:18
TRAINING STATS: batch 24/486 in epoch 441,   batch loss: 1.75651, batch accuracy: 0.52817
Time: 2018-07-15 02:00:21
TRAINING STATS: batch 74/486 in epoch 441,   batch loss: 1.72590, batch accuracy: 0.54250
Time: 2018-07-15 02:00:26
TRAINING STATS: batch 124/486 in epoch 441,  batch loss: 1.72503, batch accuracy: 0.53717
Time: 2018-07-15 02:00:30
TRAINING STATS: batch 174/486 in epoch 441,  batch loss: 1.80845, batch accuracy: 0.51633
Time: 2018-07-15 02:00:33
TRAINING STATS: batch 224/486 in epoch 441,  batch loss: 1.76155, batch accuracy: 0.53200
Time: 2018-07-15 02:00:38
TRAINING STATS: batch 274/486 in epoch 441,  batch loss: 1.69143, batch accuracy: 0.54917
Time: 2018-07-15 02:00:42
TRAINING STATS: batch 324/486 in epoch 441,  batch loss: 1.75753, batch accuracy: 0.53067
Time: 2018-07-15 02:00:46
TRAINING STATS: batch 374/486 in epoch 441,  batch loss: 1.74755, batch accuracy: 0.53733
Time: 2018-07-15 02:00:50
TRAINING STATS: batch 424/486 in epoch 441,  batch loss: 1.65809, batch accuracy: 0.55000
Time: 2018-07-15 02:00:54
TRAINING STATS: batch 474/486 in epoch 441,  batch loss: 1.70183, batch accuracy: 0.54333
Time: 2018-07-15 02:00:58
TRAINING STATS: batch 38/486 in epoch 442,   batch loss: 1.71735, batch accuracy: 0.54183
Time: 2018-07-15 02:01:02
TRAINING STATS: batch 88/486 in epoch 442,   batch loss: 1.75200, batch accuracy: 0.52817
Time: 2018-07-15 02:01:06
TRAINING STATS: batch 138/486 in epoch 442,  batch loss: 1.74914, batch accuracy: 0.52433
Time: 2018-07-15 02:01:10
TRAINING STATS: batch 188/486 in epoch 442,  batch loss: 1.67259, batch accuracy: 0.55167
Time: 2018-07-15 02:01:14
TRAINING STATS: batch 238/486 in epoch 442,  batch loss: 1.70732, batch accuracy: 0.54333
Time: 2018-07-15 02:01:18
TRAINING STATS: batch 288/486 in epoch 442,  batch loss: 1.73261, batch accuracy: 0.53400
Time: 2018-07-15 02:01:22
TRAINING STATS: batch 338/486 in epoch 442,  batch loss: 1.71234, batch accuracy: 0.53750
Time: 2018-07-15 02:01:26
TRAINING STATS: batch 388/486 in epoch 442,  batch loss: 1.65646, batch accuracy: 0.55567
Time: 2018-07-15 02:01:30
TRAINING STATS: batch 438/486 in epoch 442,  batch loss: 1.73465, batch accuracy: 0.53767
Time: 2018-07-15 02:01:34
TRAINING STATS: batch 2/486 in epoch 443,    batch loss: 1.72957, batch accuracy: 0.53617
Time: 2018-07-15 02:01:38
TRAINING STATS: batch 52/486 in epoch 443,   batch loss: 1.78778, batch accuracy: 0.51967
Time: 2018-07-15 02:01:42
TRAINING STATS: batch 102/486 in epoch 443,  batch loss: 1.73774, batch accuracy: 0.54083
Time: 2018-07-15 02:01:46
TRAINING STATS: batch 152/486 in epoch 443,  batch loss: 1.66214, batch accuracy: 0.55317
Time: 2018-07-15 02:01:51
TRAINING STATS: batch 202/486 in epoch 443,  batch loss: 1.70552, batch accuracy: 0.54383
Time: 2018-07-15 02:01:54
TRAINING STATS: batch 252/486 in epoch 443,  batch loss: 1.66668, batch accuracy: 0.55900
Time: 2018-07-15 02:01:58
TRAINING STATS: batch 302/486 in epoch 443,  batch loss: 1.67491, batch accuracy: 0.54933
Time: 2018-07-15 02:02:03
TRAINING STATS: batch 352/486 in epoch 443,  batch loss: 1.69359, batch accuracy: 0.55050
Time: 2018-07-15 02:02:06
TRAINING STATS: batch 402/486 in epoch 443,  batch loss: 1.56890, batch accuracy: 0.58650
Time: 2018-07-15 02:02:10
TRAINING STATS: batch 452/486 in epoch 443,  batch loss: 1.71696, batch accuracy: 0.53283
Time: 2018-07-15 02:02:15
TRAINING STATS: batch 16/486 in epoch 444,   batch loss: 1.68988, batch accuracy: 0.55100
Time: 2018-07-15 02:02:18
TRAINING STATS: batch 66/486 in epoch 444,   batch loss: 1.68633, batch accuracy: 0.54517
Time: 2018-07-15 02:02:22
TRAINING STATS: batch 116/486 in epoch 444,  batch loss: 1.67994, batch accuracy: 0.54983
Time: 2018-07-15 02:02:27
TRAINING STATS: batch 166/486 in epoch 444,  batch loss: 1.61504, batch accuracy: 0.57317
Time: 2018-07-15 02:02:30
TRAINING STATS: batch 216/486 in epoch 444,  batch loss: 1.71920, batch accuracy: 0.54467
Time: 2018-07-15 02:02:34
TRAINING STATS: batch 266/486 in epoch 444,  batch loss: 1.69864, batch accuracy: 0.54000
Time: 2018-07-15 02:02:39
TRAINING STATS: batch 316/486 in epoch 444,  batch loss: 1.69180, batch accuracy: 0.55233
Time: 2018-07-15 02:02:42
TRAINING STATS: batch 366/486 in epoch 444,  batch loss: 1.75857, batch accuracy: 0.52300
Time: 2018-07-15 02:02:46
TRAINING STATS: batch 416/486 in epoch 444,  batch loss: 1.74709, batch accuracy: 0.52000
Time: 2018-07-15 02:02:51
TRAINING STATS: batch 466/486 in epoch 444,  batch loss: 1.57180, batch accuracy: 0.57550
Time: 2018-07-15 02:02:54
TRAINING STATS: batch 30/486 in epoch 445,   batch loss: 1.61945, batch accuracy: 0.57017
Time: 2018-07-15 02:02:58
TRAINING STATS: batch 80/486 in epoch 445,   batch loss: 1.70607, batch accuracy: 0.54083
Time: 2018-07-15 02:03:03
TRAINING STATS: batch 130/486 in epoch 445,  batch loss: 1.68174, batch accuracy: 0.55683
Time: 2018-07-15 02:03:06
TRAINING STATS: batch 180/486 in epoch 445,  batch loss: 1.74541, batch accuracy: 0.53917
Time: 2018-07-15 02:03:10
TRAINING STATS: batch 230/486 in epoch 445,  batch loss: 1.72800, batch accuracy: 0.53533
Time: 2018-07-15 02:03:15
TRAINING STATS: batch 280/486 in epoch 445,  batch loss: 1.69790, batch accuracy: 0.54350
Time: 2018-07-15 02:03:19
TRAINING STATS: batch 330/486 in epoch 445,  batch loss: 1.68796, batch accuracy: 0.54117
Time: 2018-07-15 02:03:22
TRAINING STATS: batch 380/486 in epoch 445,  batch loss: 1.68359, batch accuracy: 0.55217
Time: 2018-07-15 02:03:27
TRAINING STATS: batch 430/486 in epoch 445,  batch loss: 1.63126, batch accuracy: 0.56583
Time: 2018-07-15 02:03:31
TRAINING STATS: batch 480/486 in epoch 445,  batch loss: 1.73204, batch accuracy: 0.53683
Time: 2018-07-15 02:03:34
TRAINING STATS: batch 44/486 in epoch 446,   batch loss: 1.64364, batch accuracy: 0.56167
Time: 2018-07-15 02:03:39
TRAINING STATS: batch 94/486 in epoch 446,   batch loss: 1.75261, batch accuracy: 0.53200
Time: 2018-07-15 02:03:43
TRAINING STATS: batch 144/486 in epoch 446,  batch loss: 1.75700, batch accuracy: 0.53050
Time: 2018-07-15 02:03:46
TRAINING STATS: batch 194/486 in epoch 446,  batch loss: 1.78768, batch accuracy: 0.51600
Time: 2018-07-15 02:03:51
TRAINING STATS: batch 244/486 in epoch 446,  batch loss: 1.68374, batch accuracy: 0.55100
Time: 2018-07-15 02:03:55
TRAINING STATS: batch 294/486 in epoch 446,  batch loss: 1.61677, batch accuracy: 0.56933
Time: 2018-07-15 02:03:59
TRAINING STATS: batch 344/486 in epoch 446,  batch loss: 1.67874, batch accuracy: 0.55017
Time: 2018-07-15 02:04:03
TRAINING STATS: batch 394/486 in epoch 446,  batch loss: 1.66628, batch accuracy: 0.56300
Time: 2018-07-15 02:04:07
TRAINING STATS: batch 444/486 in epoch 446,  batch loss: 1.65517, batch accuracy: 0.56450
Time: 2018-07-15 02:04:11
TRAINING STATS: batch 8/486 in epoch 447,    batch loss: 1.67405, batch accuracy: 0.55067
Time: 2018-07-15 02:04:15
TRAINING STATS: batch 58/486 in epoch 447,   batch loss: 1.66412, batch accuracy: 0.55867
Time: 2018-07-15 02:04:19
TRAINING STATS: batch 108/486 in epoch 447,  batch loss: 1.76034, batch accuracy: 0.52800
Time: 2018-07-15 02:04:23
TRAINING STATS: batch 158/486 in epoch 447,  batch loss: 1.75834, batch accuracy: 0.52800
Time: 2018-07-15 02:04:27
TRAINING STATS: batch 208/486 in epoch 447,  batch loss: 1.74069, batch accuracy: 0.53533
Time: 2018-07-15 02:04:31
TRAINING STATS: batch 258/486 in epoch 447,  batch loss: 1.66021, batch accuracy: 0.56033
Time: 2018-07-15 02:04:35
TRAINING STATS: batch 308/486 in epoch 447,  batch loss: 1.70904, batch accuracy: 0.54267
Time: 2018-07-15 02:04:39
TRAINING STATS: batch 358/486 in epoch 447,  batch loss: 1.71738, batch accuracy: 0.53267
Time: 2018-07-15 02:04:43
TRAINING STATS: batch 408/486 in epoch 447,  batch loss: 1.75903, batch accuracy: 0.52633
Time: 2018-07-15 02:04:47
TRAINING STATS: batch 458/486 in epoch 447,  batch loss: 1.72546, batch accuracy: 0.54083
Time: 2018-07-15 02:04:51
TRAINING STATS: batch 22/486 in epoch 448,   batch loss: 1.74587, batch accuracy: 0.53817
Time: 2018-07-15 02:04:55
TRAINING STATS: batch 72/486 in epoch 448,   batch loss: 1.72851, batch accuracy: 0.53050
Time: 2018-07-15 02:04:59
TRAINING STATS: batch 122/486 in epoch 448,  batch loss: 1.65203, batch accuracy: 0.56550
Time: 2018-07-15 02:05:03
TRAINING STATS: batch 172/486 in epoch 448,  batch loss: 1.77778, batch accuracy: 0.52350
Time: 2018-07-15 02:05:07
TRAINING STATS: batch 222/486 in epoch 448,  batch loss: 1.70019, batch accuracy: 0.54067
Time: 2018-07-15 02:05:11
TRAINING STATS: batch 272/486 in epoch 448,  batch loss: 1.72462, batch accuracy: 0.53150
Time: 2018-07-15 02:05:15
TRAINING STATS: batch 322/486 in epoch 448,  batch loss: 1.69167, batch accuracy: 0.54033
Time: 2018-07-15 02:05:19
TRAINING STATS: batch 372/486 in epoch 448,  batch loss: 1.65480, batch accuracy: 0.55583
Time: 2018-07-15 02:05:23
TRAINING STATS: batch 422/486 in epoch 448,  batch loss: 1.69062, batch accuracy: 0.54600
Time: 2018-07-15 02:05:28
TRAINING STATS: batch 472/486 in epoch 448,  batch loss: 1.76235, batch accuracy: 0.53533
Time: 2018-07-15 02:05:31
TRAINING STATS: batch 36/486 in epoch 449,   batch loss: 1.78086, batch accuracy: 0.52850
Time: 2018-07-15 02:05:35
TRAINING STATS: batch 86/486 in epoch 449,   batch loss: 1.71387, batch accuracy: 0.54617
Time: 2018-07-15 02:05:40
TRAINING STATS: batch 136/486 in epoch 449,  batch loss: 1.75552, batch accuracy: 0.52183
Time: 2018-07-15 02:05:43
TRAINING STATS: batch 186/486 in epoch 449,  batch loss: 1.71578, batch accuracy: 0.53833
Time: 2018-07-15 02:05:47
TRAINING STATS: batch 236/486 in epoch 449,  batch loss: 1.74170, batch accuracy: 0.52983
Time: 2018-07-15 02:05:52
TRAINING STATS: batch 286/486 in epoch 449,  batch loss: 1.74056, batch accuracy: 0.53517
Time: 2018-07-15 02:05:55
TRAINING STATS: batch 336/486 in epoch 449,  batch loss: 1.68430, batch accuracy: 0.54567
Time: 2018-07-15 02:05:59
TRAINING STATS: batch 386/486 in epoch 449,  batch loss: 1.73585, batch accuracy: 0.53250
Time: 2018-07-15 02:06:04
TRAINING STATS: batch 436/486 in epoch 449,  batch loss: 1.73521, batch accuracy: 0.53533
Time: 2018-07-15 02:06:07
TRAINING STATS: batch 0/486 in epoch 450,    batch loss: 1.68959, batch accuracy: 0.54717
Time: 2018-07-15 02:06:11
TRAINING STATS: batch 50/486 in epoch 450,   batch loss: 1.66271, batch accuracy: 0.56000
Time: 2018-07-15 02:06:16
TRAINING STATS: batch 100/486 in epoch 450,  batch loss: 1.72845, batch accuracy: 0.54217
Time: 2018-07-15 02:06:19
TRAINING STATS: batch 150/486 in epoch 450,  batch loss: 1.67174, batch accuracy: 0.56117
Time: 2018-07-15 02:06:23
TRAINING STATS: batch 200/486 in epoch 450,  batch loss: 1.62293, batch accuracy: 0.56483
Time: 2018-07-15 02:06:28
TRAINING STATS: batch 250/486 in epoch 450,  batch loss: 1.74862, batch accuracy: 0.52367
Time: 2018-07-15 02:06:31
TRAINING STATS: batch 300/486 in epoch 450,  batch loss: 1.72922, batch accuracy: 0.52117
Time: 2018-07-15 02:06:35
TRAINING STATS: batch 350/486 in epoch 450,  batch loss: 1.71949, batch accuracy: 0.54433
Time: 2018-07-15 02:06:40
TRAINING STATS: batch 400/486 in epoch 450,  batch loss: 1.61123, batch accuracy: 0.56767
Time: 2018-07-15 02:06:43
TRAINING STATS: batch 450/486 in epoch 450,  batch loss: 1.76520, batch accuracy: 0.51917
Time: 2018-07-15 02:06:47
TRAINING STATS: batch 14/486 in epoch 451,   batch loss: 1.63610, batch accuracy: 0.56067
Time: 2018-07-15 02:06:52
TRAINING STATS: batch 64/486 in epoch 451,   batch loss: 1.79843, batch accuracy: 0.51483
Time: 2018-07-15 02:06:55
TRAINING STATS: batch 114/486 in epoch 451,  batch loss: 1.76043, batch accuracy: 0.52683
Time: 2018-07-15 02:06:59
TRAINING STATS: batch 164/486 in epoch 451,  batch loss: 1.63597, batch accuracy: 0.56917
Time: 2018-07-15 02:07:04
TRAINING STATS: batch 214/486 in epoch 451,  batch loss: 1.69786, batch accuracy: 0.55017
Time: 2018-07-15 02:07:07
TRAINING STATS: batch 264/486 in epoch 451,  batch loss: 1.74306, batch accuracy: 0.52117
Time: 2018-07-15 02:07:11
TRAINING STATS: batch 314/486 in epoch 451,  batch loss: 1.75058, batch accuracy: 0.52467
Time: 2018-07-15 02:07:16
TRAINING STATS: batch 364/486 in epoch 451,  batch loss: 1.69672, batch accuracy: 0.54900
Time: 2018-07-15 02:07:20
TRAINING STATS: batch 414/486 in epoch 451,  batch loss: 1.62228, batch accuracy: 0.56767
Time: 2018-07-15 02:07:23
TRAINING STATS: batch 464/486 in epoch 451,  batch loss: 1.65831, batch accuracy: 0.54833
Time: 2018-07-15 02:07:28
TRAINING STATS: batch 28/486 in epoch 452,   batch loss: 1.62287, batch accuracy: 0.56667
Time: 2018-07-15 02:07:32
TRAINING STATS: batch 78/486 in epoch 452,   batch loss: 1.70494, batch accuracy: 0.55117
Time: 2018-07-15 02:07:35
TRAINING STATS: batch 128/486 in epoch 452,  batch loss: 1.69533, batch accuracy: 0.54117
Time: 2018-07-15 02:07:40
TRAINING STATS: batch 178/486 in epoch 452,  batch loss: 1.59907, batch accuracy: 0.56883
Time: 2018-07-15 02:07:44
TRAINING STATS: batch 228/486 in epoch 452,  batch loss: 1.63647, batch accuracy: 0.55533
Time: 2018-07-15 02:07:47
TRAINING STATS: batch 278/486 in epoch 452,  batch loss: 1.62439, batch accuracy: 0.56783
Time: 2018-07-15 02:07:52
TRAINING STATS: batch 328/486 in epoch 452,  batch loss: 1.66592, batch accuracy: 0.55883
Time: 2018-07-15 02:07:56
TRAINING STATS: batch 378/486 in epoch 452,  batch loss: 1.68981, batch accuracy: 0.54600
Time: 2018-07-15 02:07:59
TRAINING STATS: batch 428/486 in epoch 452,  batch loss: 1.75071, batch accuracy: 0.52733
Time: 2018-07-15 02:08:04
TRAINING STATS: batch 478/486 in epoch 452,  batch loss: 1.71485, batch accuracy: 0.54483
Time: 2018-07-15 02:08:08
TRAINING STATS: batch 42/486 in epoch 453,   batch loss: 1.60606, batch accuracy: 0.56983
Time: 2018-07-15 02:08:11
TRAINING STATS: batch 92/486 in epoch 453,   batch loss: 1.70948, batch accuracy: 0.54017
Time: 2018-07-15 02:08:16
TRAINING STATS: batch 142/486 in epoch 453,  batch loss: 1.66531, batch accuracy: 0.55550
Time: 2018-07-15 02:08:20
TRAINING STATS: batch 192/486 in epoch 453,  batch loss: 1.69183, batch accuracy: 0.54733
Time: 2018-07-15 02:08:24
TRAINING STATS: batch 242/486 in epoch 453,  batch loss: 1.67539, batch accuracy: 0.54933
Time: 2018-07-15 02:08:28
TRAINING STATS: batch 292/486 in epoch 453,  batch loss: 1.68971, batch accuracy: 0.54233
Time: 2018-07-15 02:08:32
TRAINING STATS: batch 342/486 in epoch 453,  batch loss: 1.65844, batch accuracy: 0.55350
Time: 2018-07-15 02:08:36
TRAINING STATS: batch 392/486 in epoch 453,  batch loss: 1.60483, batch accuracy: 0.56700
Time: 2018-07-15 02:08:40
TRAINING STATS: batch 442/486 in epoch 453,  batch loss: 1.66569, batch accuracy: 0.55917
Time: 2018-07-15 02:08:44
TRAINING STATS: batch 6/486 in epoch 454,    batch loss: 1.74341, batch accuracy: 0.52833
Time: 2018-07-15 02:08:48
TRAINING STATS: batch 56/486 in epoch 454,   batch loss: 1.65447, batch accuracy: 0.55100
Time: 2018-07-15 02:08:52
TRAINING STATS: batch 106/486 in epoch 454,  batch loss: 1.75706, batch accuracy: 0.52750
Time: 2018-07-15 02:08:56
TRAINING STATS: batch 156/486 in epoch 454,  batch loss: 1.82625, batch accuracy: 0.50917
Time: 2018-07-15 02:09:00
TRAINING STATS: batch 206/486 in epoch 454,  batch loss: 1.76667, batch accuracy: 0.51917
Time: 2018-07-15 02:09:05
TRAINING STATS: batch 256/486 in epoch 454,  batch loss: 1.66009, batch accuracy: 0.55750
Time: 2018-07-15 02:09:08
TRAINING STATS: batch 306/486 in epoch 454,  batch loss: 1.70616, batch accuracy: 0.54800
Time: 2018-07-15 02:09:12
TRAINING STATS: batch 356/486 in epoch 454,  batch loss: 1.74522, batch accuracy: 0.53033
Time: 2018-07-15 02:09:17
TRAINING STATS: batch 406/486 in epoch 454,  batch loss: 1.76937, batch accuracy: 0.52483
Time: 2018-07-15 02:09:20
TRAINING STATS: batch 456/486 in epoch 454,  batch loss: 1.57059, batch accuracy: 0.58283
Time: 2018-07-15 02:09:24
TRAINING STATS: batch 20/486 in epoch 455,   batch loss: 1.69219, batch accuracy: 0.54067
Time: 2018-07-15 02:09:29
TRAINING STATS: batch 70/486 in epoch 455,   batch loss: 1.58613, batch accuracy: 0.58100
Time: 2018-07-15 02:09:32
TRAINING STATS: batch 120/486 in epoch 455,  batch loss: 1.65135, batch accuracy: 0.55750
Time: 2018-07-15 02:09:36
TRAINING STATS: batch 170/486 in epoch 455,  batch loss: 1.68587, batch accuracy: 0.54100
Time: 2018-07-15 02:09:41
TRAINING STATS: batch 220/486 in epoch 455,  batch loss: 1.62612, batch accuracy: 0.56950
Time: 2018-07-15 02:09:44
TRAINING STATS: batch 270/486 in epoch 455,  batch loss: 1.69612, batch accuracy: 0.53250
Time: 2018-07-15 02:09:48
TRAINING STATS: batch 320/486 in epoch 455,  batch loss: 1.63961, batch accuracy: 0.56117
Time: 2018-07-15 02:09:53
TRAINING STATS: batch 370/486 in epoch 455,  batch loss: 1.69352, batch accuracy: 0.54983
Time: 2018-07-15 02:09:56
TRAINING STATS: batch 420/486 in epoch 455,  batch loss: 1.72377, batch accuracy: 0.53650
Time: 2018-07-15 02:10:00
TRAINING STATS: batch 470/486 in epoch 455,  batch loss: 1.81797, batch accuracy: 0.49683
Time: 2018-07-15 02:10:05
TRAINING STATS: batch 34/486 in epoch 456,   batch loss: 1.73875, batch accuracy: 0.52767
Time: 2018-07-15 02:10:08
TRAINING STATS: batch 84/486 in epoch 456,   batch loss: 1.70696, batch accuracy: 0.53367
Time: 2018-07-15 02:10:12
TRAINING STATS: batch 134/486 in epoch 456,  batch loss: 1.72104, batch accuracy: 0.53833
Time: 2018-07-15 02:10:17
TRAINING STATS: batch 184/486 in epoch 456,  batch loss: 1.71595, batch accuracy: 0.53550
Time: 2018-07-15 02:10:20
TRAINING STATS: batch 234/486 in epoch 456,  batch loss: 1.78160, batch accuracy: 0.52717
Time: 2018-07-15 02:10:24
TRAINING STATS: batch 284/486 in epoch 456,  batch loss: 1.74084, batch accuracy: 0.53300
Time: 2018-07-15 02:10:29
TRAINING STATS: batch 334/486 in epoch 456,  batch loss: 1.68116, batch accuracy: 0.55050
Time: 2018-07-15 02:10:32
TRAINING STATS: batch 384/486 in epoch 456,  batch loss: 1.66748, batch accuracy: 0.56000
Time: 2018-07-15 02:10:36
TRAINING STATS: batch 434/486 in epoch 456,  batch loss: 1.74733, batch accuracy: 0.52467
Time: 2018-07-15 02:10:41
TRAINING STATS: batch 484/486 in epoch 456,  batch loss: 1.72086, batch accuracy: 0.52717
Time: 2018-07-15 02:10:45
TRAINING STATS: batch 48/486 in epoch 457,   batch loss: 1.69933, batch accuracy: 0.54667
Time: 2018-07-15 02:10:48
TRAINING STATS: batch 98/486 in epoch 457,   batch loss: 1.67199, batch accuracy: 0.55817
Time: 2018-07-15 02:10:53
TRAINING STATS: batch 148/486 in epoch 457,  batch loss: 1.73274, batch accuracy: 0.53617
Time: 2018-07-15 02:10:57
TRAINING STATS: batch 198/486 in epoch 457,  batch loss: 1.68584, batch accuracy: 0.54033
Time: 2018-07-15 02:11:00
TRAINING STATS: batch 248/486 in epoch 457,  batch loss: 1.73442, batch accuracy: 0.53250
Time: 2018-07-15 02:11:05
TRAINING STATS: batch 298/486 in epoch 457,  batch loss: 1.71004, batch accuracy: 0.53633
Time: 2018-07-15 02:11:09
TRAINING STATS: batch 348/486 in epoch 457,  batch loss: 1.69814, batch accuracy: 0.54717
Time: 2018-07-15 02:11:12
TRAINING STATS: batch 398/486 in epoch 457,  batch loss: 1.70089, batch accuracy: 0.54300
Time: 2018-07-15 02:11:17
TRAINING STATS: batch 448/486 in epoch 457,  batch loss: 1.68288, batch accuracy: 0.55017
Time: 2018-07-15 02:11:21
TRAINING STATS: batch 12/486 in epoch 458,   batch loss: 1.71568, batch accuracy: 0.53583
Time: 2018-07-15 02:11:24
TRAINING STATS: batch 62/486 in epoch 458,   batch loss: 1.77819, batch accuracy: 0.52267
Time: 2018-07-15 02:11:29
TRAINING STATS: batch 112/486 in epoch 458,  batch loss: 1.67071, batch accuracy: 0.54800
Time: 2018-07-15 02:11:33
TRAINING STATS: batch 162/486 in epoch 458,  batch loss: 1.70163, batch accuracy: 0.54500
Time: 2018-07-15 02:11:37
TRAINING STATS: batch 212/486 in epoch 458,  batch loss: 1.61923, batch accuracy: 0.56767
Time: 2018-07-15 02:11:41
TRAINING STATS: batch 262/486 in epoch 458,  batch loss: 1.75585, batch accuracy: 0.52567
Time: 2018-07-15 02:11:45
TRAINING STATS: batch 312/486 in epoch 458,  batch loss: 1.70315, batch accuracy: 0.53533
Time: 2018-07-15 02:11:48
TRAINING STATS: batch 362/486 in epoch 458,  batch loss: 1.69965, batch accuracy: 0.54183
Time: 2018-07-15 02:11:53
TRAINING STATS: batch 412/486 in epoch 458,  batch loss: 1.65184, batch accuracy: 0.56867
Time: 2018-07-15 02:11:57
TRAINING STATS: batch 462/486 in epoch 458,  batch loss: 1.70572, batch accuracy: 0.54850
Time: 2018-07-15 02:12:01
TRAINING STATS: batch 26/486 in epoch 459,   batch loss: 1.73122, batch accuracy: 0.53617
Time: 2018-07-15 02:12:05
TRAINING STATS: batch 76/486 in epoch 459,   batch loss: 1.76096, batch accuracy: 0.53133
Time: 2018-07-15 02:12:09
TRAINING STATS: batch 126/486 in epoch 459,  batch loss: 1.73723, batch accuracy: 0.52750
Time: 2018-07-15 02:12:13
TRAINING STATS: batch 176/486 in epoch 459,  batch loss: 1.61375, batch accuracy: 0.56950
Time: 2018-07-15 02:12:17
TRAINING STATS: batch 226/486 in epoch 459,  batch loss: 1.68206, batch accuracy: 0.55050
Time: 2018-07-15 02:12:21
TRAINING STATS: batch 276/486 in epoch 459,  batch loss: 1.68848, batch accuracy: 0.53650
Time: 2018-07-15 02:12:25
TRAINING STATS: batch 326/486 in epoch 459,  batch loss: 1.74345, batch accuracy: 0.52783
Time: 2018-07-15 02:12:29
TRAINING STATS: batch 376/486 in epoch 459,  batch loss: 1.73331, batch accuracy: 0.53150
Time: 2018-07-15 02:12:33
TRAINING STATS: batch 426/486 in epoch 459,  batch loss: 1.69923, batch accuracy: 0.53567
Time: 2018-07-15 02:12:37
TRAINING STATS: batch 476/486 in epoch 459,  batch loss: 1.66382, batch accuracy: 0.55850
Time: 2018-07-15 02:12:42
TRAINING STATS: batch 40/486 in epoch 460,   batch loss: 1.65612, batch accuracy: 0.55600
Time: 2018-07-15 02:12:45
TRAINING STATS: batch 90/486 in epoch 460,   batch loss: 1.72481, batch accuracy: 0.54317
Time: 2018-07-15 02:12:49
TRAINING STATS: batch 140/486 in epoch 460,  batch loss: 1.63524, batch accuracy: 0.55833
Time: 2018-07-15 02:12:54
TRAINING STATS: batch 190/486 in epoch 460,  batch loss: 1.66082, batch accuracy: 0.55367
Time: 2018-07-15 02:12:57
TRAINING STATS: batch 240/486 in epoch 460,  batch loss: 1.68054, batch accuracy: 0.55100
Time: 2018-07-15 02:13:01
TRAINING STATS: batch 290/486 in epoch 460,  batch loss: 1.71936, batch accuracy: 0.53333
Time: 2018-07-15 02:13:06
TRAINING STATS: batch 340/486 in epoch 460,  batch loss: 1.76596, batch accuracy: 0.52567
Time: 2018-07-15 02:13:09
TRAINING STATS: batch 390/486 in epoch 460,  batch loss: 1.62500, batch accuracy: 0.56417
Time: 2018-07-15 02:13:13
TRAINING STATS: batch 440/486 in epoch 460,  batch loss: 1.70408, batch accuracy: 0.54433
Time: 2018-07-15 02:13:18
TRAINING STATS: batch 4/486 in epoch 461,    batch loss: 1.65504, batch accuracy: 0.55667
Time: 2018-07-15 02:13:21
TRAINING STATS: batch 54/486 in epoch 461,   batch loss: 1.68610, batch accuracy: 0.54233
Time: 2018-07-15 02:13:25
TRAINING STATS: batch 104/486 in epoch 461,  batch loss: 1.72141, batch accuracy: 0.54133
Time: 2018-07-15 02:13:30
TRAINING STATS: batch 154/486 in epoch 461,  batch loss: 1.67930, batch accuracy: 0.54683
Time: 2018-07-15 02:13:33
TRAINING STATS: batch 204/486 in epoch 461,  batch loss: 1.76478, batch accuracy: 0.53217
Time: 2018-07-15 02:13:37
TRAINING STATS: batch 254/486 in epoch 461,  batch loss: 1.60796, batch accuracy: 0.56850
Time: 2018-07-15 02:13:42
TRAINING STATS: batch 304/486 in epoch 461,  batch loss: 1.65504, batch accuracy: 0.55683
Time: 2018-07-15 02:13:45
TRAINING STATS: batch 354/486 in epoch 461,  batch loss: 1.69134, batch accuracy: 0.54917
Time: 2018-07-15 02:13:49
TRAINING STATS: batch 404/486 in epoch 461,  batch loss: 1.68182, batch accuracy: 0.54583
Time: 2018-07-15 02:13:54
TRAINING STATS: batch 454/486 in epoch 461,  batch loss: 1.55854, batch accuracy: 0.58517
Time: 2018-07-15 02:13:57
TRAINING STATS: batch 18/486 in epoch 462,   batch loss: 1.71791, batch accuracy: 0.53700
Time: 2018-07-15 02:14:01
TRAINING STATS: batch 68/486 in epoch 462,   batch loss: 1.53406, batch accuracy: 0.59233
Time: 2018-07-15 02:14:06
TRAINING STATS: batch 118/486 in epoch 462,  batch loss: 1.67490, batch accuracy: 0.55033
Time: 2018-07-15 02:14:10
TRAINING STATS: batch 168/486 in epoch 462,  batch loss: 1.61160, batch accuracy: 0.56500
Time: 2018-07-15 02:14:13
TRAINING STATS: batch 218/486 in epoch 462,  batch loss: 1.67102, batch accuracy: 0.54417
Time: 2018-07-15 02:14:18
TRAINING STATS: batch 268/486 in epoch 462,  batch loss: 1.63919, batch accuracy: 0.55417
Time: 2018-07-15 02:14:22
TRAINING STATS: batch 318/486 in epoch 462,  batch loss: 1.67149, batch accuracy: 0.55017
Time: 2018-07-15 02:14:25
TRAINING STATS: batch 368/486 in epoch 462,  batch loss: 1.72144, batch accuracy: 0.53033
Time: 2018-07-15 02:14:30
TRAINING STATS: batch 418/486 in epoch 462,  batch loss: 1.73868, batch accuracy: 0.52617
Time: 2018-07-15 02:14:34
TRAINING STATS: batch 468/486 in epoch 462,  batch loss: 1.70058, batch accuracy: 0.55017
Time: 2018-07-15 02:14:37
TRAINING STATS: batch 32/486 in epoch 463,   batch loss: 1.66280, batch accuracy: 0.55367
Time: 2018-07-15 02:14:42
TRAINING STATS: batch 82/486 in epoch 463,   batch loss: 1.71206, batch accuracy: 0.53533
Time: 2018-07-15 02:14:46
TRAINING STATS: batch 132/486 in epoch 463,  batch loss: 1.67669, batch accuracy: 0.56433
Time: 2018-07-15 02:14:50
TRAINING STATS: batch 182/486 in epoch 463,  batch loss: 1.74238, batch accuracy: 0.52750
Time: 2018-07-15 02:14:54
TRAINING STATS: batch 232/486 in epoch 463,  batch loss: 1.72195, batch accuracy: 0.53383
Time: 2018-07-15 02:14:58
TRAINING STATS: batch 282/486 in epoch 463,  batch loss: 1.64283, batch accuracy: 0.55567
Time: 2018-07-15 02:15:02
TRAINING STATS: batch 332/486 in epoch 463,  batch loss: 1.71294, batch accuracy: 0.54317
Time: 2018-07-15 02:15:06
TRAINING STATS: batch 382/486 in epoch 463,  batch loss: 1.69899, batch accuracy: 0.54400
Time: 2018-07-15 02:15:10
TRAINING STATS: batch 432/486 in epoch 463,  batch loss: 1.63483, batch accuracy: 0.56650
Time: 2018-07-15 02:15:14
TRAINING STATS: batch 482/486 in epoch 463,  batch loss: 1.66823, batch accuracy: 0.55350
Time: 2018-07-15 02:15:18
TRAINING STATS: batch 46/486 in epoch 464,   batch loss: 1.65618, batch accuracy: 0.55933
Time: 2018-07-15 02:15:22
TRAINING STATS: batch 96/486 in epoch 464,   batch loss: 1.72462, batch accuracy: 0.54150
Time: 2018-07-15 02:15:26
TRAINING STATS: batch 146/486 in epoch 464,  batch loss: 1.74589, batch accuracy: 0.53050
Time: 2018-07-15 02:15:30
TRAINING STATS: batch 196/486 in epoch 464,  batch loss: 1.72653, batch accuracy: 0.53300
Time: 2018-07-15 02:15:34
TRAINING STATS: batch 246/486 in epoch 464,  batch loss: 1.66300, batch accuracy: 0.54817
Time: 2018-07-15 02:15:38
TRAINING STATS: batch 296/486 in epoch 464,  batch loss: 1.65827, batch accuracy: 0.55217
Time: 2018-07-15 02:15:42
TRAINING STATS: batch 346/486 in epoch 464,  batch loss: 1.59578, batch accuracy: 0.57717
Time: 2018-07-15 02:15:46
TRAINING STATS: batch 396/486 in epoch 464,  batch loss: 1.67155, batch accuracy: 0.55317
Time: 2018-07-15 02:15:50
TRAINING STATS: batch 446/486 in epoch 464,  batch loss: 1.69875, batch accuracy: 0.54450
Time: 2018-07-15 02:15:54
TRAINING STATS: batch 10/486 in epoch 465,   batch loss: 1.71427, batch accuracy: 0.53850
Time: 2018-07-15 02:15:58
TRAINING STATS: batch 60/486 in epoch 465,   batch loss: 1.67786, batch accuracy: 0.54567
Time: 2018-07-15 02:16:02
TRAINING STATS: batch 110/486 in epoch 465,  batch loss: 1.73007, batch accuracy: 0.54317
Time: 2018-07-15 02:16:07
TRAINING STATS: batch 160/486 in epoch 465,  batch loss: 1.67482, batch accuracy: 0.54733
Time: 2018-07-15 02:16:10
TRAINING STATS: batch 210/486 in epoch 465,  batch loss: 1.64277, batch accuracy: 0.55633
Time: 2018-07-15 02:16:14
TRAINING STATS: batch 260/486 in epoch 465,  batch loss: 1.71473, batch accuracy: 0.53433
Time: 2018-07-15 02:16:19
TRAINING STATS: batch 310/486 in epoch 465,  batch loss: 1.69834, batch accuracy: 0.54267
Time: 2018-07-15 02:16:22
TRAINING STATS: batch 360/486 in epoch 465,  batch loss: 1.71231, batch accuracy: 0.53883
Time: 2018-07-15 02:16:26
TRAINING STATS: batch 410/486 in epoch 465,  batch loss: 1.61806, batch accuracy: 0.56717
Time: 2018-07-15 02:16:31
TRAINING STATS: batch 460/486 in epoch 465,  batch loss: 1.81231, batch accuracy: 0.50533
Time: 2018-07-15 02:16:34
TRAINING STATS: batch 24/486 in epoch 466,   batch loss: 1.74909, batch accuracy: 0.53017
Time: 2018-07-15 02:16:38
TRAINING STATS: batch 74/486 in epoch 466,   batch loss: 1.70972, batch accuracy: 0.54250
Time: 2018-07-15 02:16:43
TRAINING STATS: batch 124/486 in epoch 466,  batch loss: 1.69544, batch accuracy: 0.54467
Time: 2018-07-15 02:16:47
TRAINING STATS: batch 174/486 in epoch 466,  batch loss: 1.76069, batch accuracy: 0.52600
Time: 2018-07-15 02:16:50
TRAINING STATS: batch 224/486 in epoch 466,  batch loss: 1.72377, batch accuracy: 0.54283
Time: 2018-07-15 02:16:55
TRAINING STATS: batch 274/486 in epoch 466,  batch loss: 1.69355, batch accuracy: 0.54017
Time: 2018-07-15 02:16:59
TRAINING STATS: batch 324/486 in epoch 466,  batch loss: 1.71618, batch accuracy: 0.53667
Time: 2018-07-15 02:17:02
TRAINING STATS: batch 374/486 in epoch 466,  batch loss: 1.73525, batch accuracy: 0.54250
Time: 2018-07-15 02:17:07
TRAINING STATS: batch 424/486 in epoch 466,  batch loss: 1.64536, batch accuracy: 0.55417
Time: 2018-07-15 02:17:11
TRAINING STATS: batch 474/486 in epoch 466,  batch loss: 1.70632, batch accuracy: 0.53950
Time: 2018-07-15 02:17:14
TRAINING STATS: batch 38/486 in epoch 467,   batch loss: 1.71382, batch accuracy: 0.54583
Time: 2018-07-15 02:17:19
TRAINING STATS: batch 88/486 in epoch 467,   batch loss: 1.73196, batch accuracy: 0.53200
Time: 2018-07-15 02:17:23
TRAINING STATS: batch 138/486 in epoch 467,  batch loss: 1.72450, batch accuracy: 0.53267
Time: 2018-07-15 02:17:26
TRAINING STATS: batch 188/486 in epoch 467,  batch loss: 1.63767, batch accuracy: 0.55433
Time: 2018-07-15 02:17:31
TRAINING STATS: batch 238/486 in epoch 467,  batch loss: 1.68059, batch accuracy: 0.55050
Time: 2018-07-15 02:17:35
TRAINING STATS: batch 288/486 in epoch 467,  batch loss: 1.72033, batch accuracy: 0.53633
Time: 2018-07-15 02:17:38
TRAINING STATS: batch 338/486 in epoch 467,  batch loss: 1.68111, batch accuracy: 0.54383
Time: 2018-07-15 02:17:43
TRAINING STATS: batch 388/486 in epoch 467,  batch loss: 1.66144, batch accuracy: 0.55833
Time: 2018-07-15 02:17:47
TRAINING STATS: batch 438/486 in epoch 467,  batch loss: 1.70466, batch accuracy: 0.53950
Time: 2018-07-15 02:17:50
TRAINING STATS: batch 2/486 in epoch 468,    batch loss: 1.71393, batch accuracy: 0.54050
Time: 2018-07-15 02:17:55
TRAINING STATS: batch 52/486 in epoch 468,   batch loss: 1.75455, batch accuracy: 0.52550
Time: 2018-07-15 02:17:59
TRAINING STATS: batch 102/486 in epoch 468,  batch loss: 1.71722, batch accuracy: 0.54283
Time: 2018-07-15 02:18:03
TRAINING STATS: batch 152/486 in epoch 468,  batch loss: 1.65918, batch accuracy: 0.55183
Time: 2018-07-15 02:18:07
TRAINING STATS: batch 202/486 in epoch 468,  batch loss: 1.71075, batch accuracy: 0.54250
Time: 2018-07-15 02:18:11
TRAINING STATS: batch 252/486 in epoch 468,  batch loss: 1.66111, batch accuracy: 0.56050
Time: 2018-07-15 02:18:15
TRAINING STATS: batch 302/486 in epoch 468,  batch loss: 1.65047, batch accuracy: 0.55883
Time: 2018-07-15 02:18:19
TRAINING STATS: batch 352/486 in epoch 468,  batch loss: 1.69069, batch accuracy: 0.54533
Time: 2018-07-15 02:18:23
TRAINING STATS: batch 402/486 in epoch 468,  batch loss: 1.55589, batch accuracy: 0.59067
Time: 2018-07-15 02:18:27
TRAINING STATS: batch 452/486 in epoch 468,  batch loss: 1.68798, batch accuracy: 0.54667
Time: 2018-07-15 02:18:31
TRAINING STATS: batch 16/486 in epoch 469,   batch loss: 1.67212, batch accuracy: 0.55417
Time: 2018-07-15 02:18:35
TRAINING STATS: batch 66/486 in epoch 469,   batch loss: 1.68079, batch accuracy: 0.55500
Time: 2018-07-15 02:18:39
TRAINING STATS: batch 116/486 in epoch 469,  batch loss: 1.65151, batch accuracy: 0.55833
Time: 2018-07-15 02:18:44
TRAINING STATS: batch 166/486 in epoch 469,  batch loss: 1.60518, batch accuracy: 0.56750
Time: 2018-07-15 02:18:47
TRAINING STATS: batch 216/486 in epoch 469,  batch loss: 1.70350, batch accuracy: 0.54300
Time: 2018-07-15 02:18:51
TRAINING STATS: batch 266/486 in epoch 469,  batch loss: 1.68276, batch accuracy: 0.54750
Time: 2018-07-15 02:18:55
TRAINING STATS: batch 316/486 in epoch 469,  batch loss: 1.68141, batch accuracy: 0.55033
Time: 2018-07-15 02:18:59
TRAINING STATS: batch 366/486 in epoch 469,  batch loss: 1.73376, batch accuracy: 0.53617
Time: 2018-07-15 02:19:03
TRAINING STATS: batch 416/486 in epoch 469,  batch loss: 1.72725, batch accuracy: 0.53850
Time: 2018-07-15 02:19:08
TRAINING STATS: batch 466/486 in epoch 469,  batch loss: 1.54551, batch accuracy: 0.59017
Time: 2018-07-15 02:19:11
TRAINING STATS: batch 30/486 in epoch 470,   batch loss: 1.57624, batch accuracy: 0.57333
Time: 2018-07-15 02:19:15
TRAINING STATS: batch 80/486 in epoch 470,   batch loss: 1.68052, batch accuracy: 0.54100
Time: 2018-07-15 02:19:19
TRAINING STATS: batch 130/486 in epoch 470,  batch loss: 1.68969, batch accuracy: 0.55017
Time: 2018-07-15 02:19:23
TRAINING STATS: batch 180/486 in epoch 470,  batch loss: 1.71164, batch accuracy: 0.54150
Time: 2018-07-15 02:19:27
TRAINING STATS: batch 230/486 in epoch 470,  batch loss: 1.71522, batch accuracy: 0.52783
Time: 2018-07-15 02:19:32
TRAINING STATS: batch 280/486 in epoch 470,  batch loss: 1.66531, batch accuracy: 0.54550
Time: 2018-07-15 02:19:35
TRAINING STATS: batch 330/486 in epoch 470,  batch loss: 1.65596, batch accuracy: 0.54750
Time: 2018-07-15 02:19:39
TRAINING STATS: batch 380/486 in epoch 470,  batch loss: 1.66578, batch accuracy: 0.55800
Time: 2018-07-15 02:19:44
TRAINING STATS: batch 430/486 in epoch 470,  batch loss: 1.61062, batch accuracy: 0.56733
Time: 2018-07-15 02:19:47
TRAINING STATS: batch 480/486 in epoch 470,  batch loss: 1.69483, batch accuracy: 0.55017
Time: 2018-07-15 02:19:51
TRAINING STATS: batch 44/486 in epoch 471,   batch loss: 1.64560, batch accuracy: 0.55667
Time: 2018-07-15 02:19:56
TRAINING STATS: batch 94/486 in epoch 471,   batch loss: 1.73266, batch accuracy: 0.53617
Time: 2018-07-15 02:19:59
TRAINING STATS: batch 144/486 in epoch 471,  batch loss: 1.74526, batch accuracy: 0.53083
Time: 2018-07-15 02:20:03
TRAINING STATS: batch 194/486 in epoch 471,  batch loss: 1.78925, batch accuracy: 0.51983
Time: 2018-07-15 02:20:08
TRAINING STATS: batch 244/486 in epoch 471,  batch loss: 1.66709, batch accuracy: 0.55250
Time: 2018-07-15 02:20:11
TRAINING STATS: batch 294/486 in epoch 471,  batch loss: 1.59969, batch accuracy: 0.57450
Time: 2018-07-15 02:20:15
TRAINING STATS: batch 344/486 in epoch 471,  batch loss: 1.65498, batch accuracy: 0.55200
Time: 2018-07-15 02:20:20
TRAINING STATS: batch 394/486 in epoch 471,  batch loss: 1.65367, batch accuracy: 0.56200
Time: 2018-07-15 02:20:23
TRAINING STATS: batch 444/486 in epoch 471,  batch loss: 1.62808, batch accuracy: 0.56550
Time: 2018-07-15 02:20:27
TRAINING STATS: batch 8/486 in epoch 472,    batch loss: 1.67919, batch accuracy: 0.54583
Time: 2018-07-15 02:20:32
TRAINING STATS: batch 58/486 in epoch 472,   batch loss: 1.67523, batch accuracy: 0.55817
Time: 2018-07-15 02:20:35
TRAINING STATS: batch 108/486 in epoch 472,  batch loss: 1.74575, batch accuracy: 0.52967
Time: 2018-07-15 02:20:39
TRAINING STATS: batch 158/486 in epoch 472,  batch loss: 1.76026, batch accuracy: 0.52033
Time: 2018-07-15 02:20:44
TRAINING STATS: batch 208/486 in epoch 472,  batch loss: 1.68847, batch accuracy: 0.54883
Time: 2018-07-15 02:20:47
TRAINING STATS: batch 258/486 in epoch 472,  batch loss: 1.62951, batch accuracy: 0.56433
Time: 2018-07-15 02:20:51
TRAINING STATS: batch 308/486 in epoch 472,  batch loss: 1.70274, batch accuracy: 0.54700
Time: 2018-07-15 02:20:56
TRAINING STATS: batch 358/486 in epoch 472,  batch loss: 1.72238, batch accuracy: 0.52550
Time: 2018-07-15 02:20:59
TRAINING STATS: batch 408/486 in epoch 472,  batch loss: 1.73902, batch accuracy: 0.52967
Time: 2018-07-15 02:21:03
TRAINING STATS: batch 458/486 in epoch 472,  batch loss: 1.71255, batch accuracy: 0.54300
Time: 2018-07-15 02:21:08
TRAINING STATS: batch 22/486 in epoch 473,   batch loss: 1.73270, batch accuracy: 0.54067
Time: 2018-07-15 02:21:11
TRAINING STATS: batch 72/486 in epoch 473,   batch loss: 1.72250, batch accuracy: 0.53300
Time: 2018-07-15 02:21:15
TRAINING STATS: batch 122/486 in epoch 473,  batch loss: 1.63462, batch accuracy: 0.56417
Time: 2018-07-15 02:21:20
TRAINING STATS: batch 172/486 in epoch 473,  batch loss: 1.74671, batch accuracy: 0.52917
Time: 2018-07-15 02:21:24
TRAINING STATS: batch 222/486 in epoch 473,  batch loss: 1.68066, batch accuracy: 0.54017
Time: 2018-07-15 02:21:27
TRAINING STATS: batch 272/486 in epoch 473,  batch loss: 1.71654, batch accuracy: 0.53700
Time: 2018-07-15 02:21:32
TRAINING STATS: batch 322/486 in epoch 473,  batch loss: 1.67349, batch accuracy: 0.54283
Time: 2018-07-15 02:21:36
TRAINING STATS: batch 372/486 in epoch 473,  batch loss: 1.63290, batch accuracy: 0.56017
Time: 2018-07-15 02:21:39
TRAINING STATS: batch 422/486 in epoch 473,  batch loss: 1.68049, batch accuracy: 0.54750
Time: 2018-07-15 02:21:44
TRAINING STATS: batch 472/486 in epoch 473,  batch loss: 1.75838, batch accuracy: 0.52367
Time: 2018-07-15 02:21:48
TRAINING STATS: batch 36/486 in epoch 474,   batch loss: 1.73980, batch accuracy: 0.53817
Time: 2018-07-15 02:21:51
TRAINING STATS: batch 86/486 in epoch 474,   batch loss: 1.67775, batch accuracy: 0.55333
Time: 2018-07-15 02:21:56
TRAINING STATS: batch 136/486 in epoch 474,  batch loss: 1.74749, batch accuracy: 0.52733
Time: 2018-07-15 02:22:00
TRAINING STATS: batch 186/486 in epoch 474,  batch loss: 1.74551, batch accuracy: 0.52383
Time: 2018-07-15 02:22:03
TRAINING STATS: batch 236/486 in epoch 474,  batch loss: 1.72133, batch accuracy: 0.53317
Time: 2018-07-15 02:22:08
TRAINING STATS: batch 286/486 in epoch 474,  batch loss: 1.72521, batch accuracy: 0.54133
Time: 2018-07-15 02:22:12
TRAINING STATS: batch 336/486 in epoch 474,  batch loss: 1.67086, batch accuracy: 0.55000
Time: 2018-07-15 02:22:15
TRAINING STATS: batch 386/486 in epoch 474,  batch loss: 1.72370, batch accuracy: 0.53617
Time: 2018-07-15 02:22:20
TRAINING STATS: batch 436/486 in epoch 474,  batch loss: 1.74233, batch accuracy: 0.52500
Time: 2018-07-15 02:22:24
TRAINING STATS: batch 0/486 in epoch 475,    batch loss: 1.67868, batch accuracy: 0.54950
Time: 2018-07-15 02:22:27
TRAINING STATS: batch 50/486 in epoch 475,   batch loss: 1.65013, batch accuracy: 0.56283
Time: 2018-07-15 02:22:32
TRAINING STATS: batch 100/486 in epoch 475,  batch loss: 1.72261, batch accuracy: 0.53450
Time: 2018-07-15 02:22:36
TRAINING STATS: batch 150/486 in epoch 475,  batch loss: 1.65278, batch accuracy: 0.56150
Time: 2018-07-15 02:22:39
TRAINING STATS: batch 200/486 in epoch 475,  batch loss: 1.57559, batch accuracy: 0.57783
Time: 2018-07-15 02:22:44
TRAINING STATS: batch 250/486 in epoch 475,  batch loss: 1.73897, batch accuracy: 0.52467
Time: 2018-07-15 02:22:48
TRAINING STATS: batch 300/486 in epoch 475,  batch loss: 1.71332, batch accuracy: 0.52850
Time: 2018-07-15 02:22:51
TRAINING STATS: batch 350/486 in epoch 475,  batch loss: 1.69821, batch accuracy: 0.54450
Time: 2018-07-15 02:22:56
TRAINING STATS: batch 400/486 in epoch 475,  batch loss: 1.58343, batch accuracy: 0.57117
Time: 2018-07-15 02:23:00
TRAINING STATS: batch 450/486 in epoch 475,  batch loss: 1.74752, batch accuracy: 0.52217
Time: 2018-07-15 02:23:04
TRAINING STATS: batch 14/486 in epoch 476,   batch loss: 1.63075, batch accuracy: 0.56383
Time: 2018-07-15 02:23:08
TRAINING STATS: batch 64/486 in epoch 476,   batch loss: 1.77879, batch accuracy: 0.51533
Time: 2018-07-15 02:23:12
TRAINING STATS: batch 114/486 in epoch 476,  batch loss: 1.73132, batch accuracy: 0.52933
Time: 2018-07-15 02:23:16
TRAINING STATS: batch 164/486 in epoch 476,  batch loss: 1.62701, batch accuracy: 0.57183
Time: 2018-07-15 02:23:20
TRAINING STATS: batch 214/486 in epoch 476,  batch loss: 1.67992, batch accuracy: 0.54883
Time: 2018-07-15 02:23:24
TRAINING STATS: batch 264/486 in epoch 476,  batch loss: 1.81298, batch accuracy: 0.51383
Time: 2018-07-15 02:23:28
TRAINING STATS: batch 314/486 in epoch 476,  batch loss: 1.77343, batch accuracy: 0.51717
Time: 2018-07-15 02:23:32
TRAINING STATS: batch 364/486 in epoch 476,  batch loss: 1.67128, batch accuracy: 0.55633
Time: 2018-07-15 02:23:36
TRAINING STATS: batch 414/486 in epoch 476,  batch loss: 1.62067, batch accuracy: 0.56933
Time: 2018-07-15 02:23:40
TRAINING STATS: batch 464/486 in epoch 476,  batch loss: 1.65293, batch accuracy: 0.55833
Time: 2018-07-15 02:23:44
TRAINING STATS: batch 28/486 in epoch 477,   batch loss: 1.60824, batch accuracy: 0.57017
Time: 2018-07-15 02:23:48
TRAINING STATS: batch 78/486 in epoch 477,   batch loss: 1.69786, batch accuracy: 0.55033
Time: 2018-07-15 02:23:52
TRAINING STATS: batch 128/486 in epoch 477,  batch loss: 1.68662, batch accuracy: 0.54383
Time: 2018-07-15 02:23:56
TRAINING STATS: batch 178/486 in epoch 477,  batch loss: 1.58314, batch accuracy: 0.57233
Time: 2018-07-15 02:24:00
TRAINING STATS: batch 228/486 in epoch 477,  batch loss: 1.63958, batch accuracy: 0.55567
Time: 2018-07-15 02:24:04
TRAINING STATS: batch 278/486 in epoch 477,  batch loss: 1.60622, batch accuracy: 0.57000
Time: 2018-07-15 02:24:09
TRAINING STATS: batch 328/486 in epoch 477,  batch loss: 1.65866, batch accuracy: 0.55533
Time: 2018-07-15 02:24:12
TRAINING STATS: batch 378/486 in epoch 477,  batch loss: 1.66986, batch accuracy: 0.55250
Time: 2018-07-15 02:24:16
TRAINING STATS: batch 428/486 in epoch 477,  batch loss: 1.72643, batch accuracy: 0.52850
Time: 2018-07-15 02:24:21
TRAINING STATS: batch 478/486 in epoch 477,  batch loss: 1.69074, batch accuracy: 0.54317
Time: 2018-07-15 02:24:24
TRAINING STATS: batch 42/486 in epoch 478,   batch loss: 1.61234, batch accuracy: 0.56117
Time: 2018-07-15 02:24:28
TRAINING STATS: batch 92/486 in epoch 478,   batch loss: 1.73469, batch accuracy: 0.53467
Time: 2018-07-15 02:24:32
TRAINING STATS: batch 142/486 in epoch 478,  batch loss: 1.63847, batch accuracy: 0.56017
Time: 2018-07-15 02:24:36
TRAINING STATS: batch 192/486 in epoch 478,  batch loss: 1.67961, batch accuracy: 0.55067
Time: 2018-07-15 02:24:40
TRAINING STATS: batch 242/486 in epoch 478,  batch loss: 1.65254, batch accuracy: 0.55583
Time: 2018-07-15 02:24:45
TRAINING STATS: batch 292/486 in epoch 478,  batch loss: 1.67620, batch accuracy: 0.54483
Time: 2018-07-15 02:24:48
TRAINING STATS: batch 342/486 in epoch 478,  batch loss: 1.64620, batch accuracy: 0.55950
Time: 2018-07-15 02:24:52
TRAINING STATS: batch 392/486 in epoch 478,  batch loss: 1.59245, batch accuracy: 0.57333
Time: 2018-07-15 02:24:57
TRAINING STATS: batch 442/486 in epoch 478,  batch loss: 1.59418, batch accuracy: 0.56883
Time: 2018-07-15 02:25:00
TRAINING STATS: batch 6/486 in epoch 479,    batch loss: 1.72119, batch accuracy: 0.53550
Time: 2018-07-15 02:25:04
TRAINING STATS: batch 56/486 in epoch 479,   batch loss: 1.65681, batch accuracy: 0.54550
Time: 2018-07-15 02:25:09
TRAINING STATS: batch 106/486 in epoch 479,  batch loss: 1.74282, batch accuracy: 0.52583
Time: 2018-07-15 02:25:12
TRAINING STATS: batch 156/486 in epoch 479,  batch loss: 1.71341, batch accuracy: 0.53567
Time: 2018-07-15 02:25:16
TRAINING STATS: batch 206/486 in epoch 479,  batch loss: 1.75722, batch accuracy: 0.52567
Time: 2018-07-15 02:25:21
TRAINING STATS: batch 256/486 in epoch 479,  batch loss: 1.61794, batch accuracy: 0.55433
Time: 2018-07-15 02:25:25
TRAINING STATS: batch 306/486 in epoch 479,  batch loss: 1.67482, batch accuracy: 0.55000
Time: 2018-07-15 02:25:28
TRAINING STATS: batch 356/486 in epoch 479,  batch loss: 1.75482, batch accuracy: 0.51617
Time: 2018-07-15 02:25:33
TRAINING STATS: batch 406/486 in epoch 479,  batch loss: 1.73881, batch accuracy: 0.52567
Time: 2018-07-15 02:25:36
TRAINING STATS: batch 456/486 in epoch 479,  batch loss: 1.56968, batch accuracy: 0.57617
Time: 2018-07-15 02:25:40
TRAINING STATS: batch 20/486 in epoch 480,   batch loss: 1.69369, batch accuracy: 0.54317
Time: 2018-07-15 02:25:45
TRAINING STATS: batch 70/486 in epoch 480,   batch loss: 1.57981, batch accuracy: 0.58033
Time: 2018-07-15 02:25:49
TRAINING STATS: batch 120/486 in epoch 480,  batch loss: 1.64456, batch accuracy: 0.55533
Time: 2018-07-15 02:25:52
TRAINING STATS: batch 170/486 in epoch 480,  batch loss: 1.67381, batch accuracy: 0.55050
Time: 2018-07-15 02:25:57
TRAINING STATS: batch 220/486 in epoch 480,  batch loss: 1.60936, batch accuracy: 0.57033
Time: 2018-07-15 02:26:01
TRAINING STATS: batch 270/486 in epoch 480,  batch loss: 1.67475, batch accuracy: 0.53983
Time: 2018-07-15 02:26:04
TRAINING STATS: batch 320/486 in epoch 480,  batch loss: 1.62252, batch accuracy: 0.56000
Time: 2018-07-15 02:26:09
TRAINING STATS: batch 370/486 in epoch 480,  batch loss: 1.66992, batch accuracy: 0.55167
Time: 2018-07-15 02:26:13
TRAINING STATS: batch 420/486 in epoch 480,  batch loss: 1.70023, batch accuracy: 0.54100
Time: 2018-07-15 02:26:16
TRAINING STATS: batch 470/486 in epoch 480,  batch loss: 1.78540, batch accuracy: 0.51017
Time: 2018-07-15 02:26:21
TRAINING STATS: batch 34/486 in epoch 481,   batch loss: 1.69902, batch accuracy: 0.54200
Time: 2018-07-15 02:26:25
TRAINING STATS: batch 84/486 in epoch 481,   batch loss: 1.68474, batch accuracy: 0.53683
Time: 2018-07-15 02:26:28
TRAINING STATS: batch 134/486 in epoch 481,  batch loss: 1.71049, batch accuracy: 0.54000
Time: 2018-07-15 02:26:33
TRAINING STATS: batch 184/486 in epoch 481,  batch loss: 1.69256, batch accuracy: 0.54350
Time: 2018-07-15 02:26:37
TRAINING STATS: batch 234/486 in epoch 481,  batch loss: 1.76626, batch accuracy: 0.52467
Time: 2018-07-15 02:26:40
TRAINING STATS: batch 284/486 in epoch 481,  batch loss: 1.72214, batch accuracy: 0.53550
Time: 2018-07-15 02:26:45
TRAINING STATS: batch 334/486 in epoch 481,  batch loss: 1.65458, batch accuracy: 0.54900
Time: 2018-07-15 02:26:49
TRAINING STATS: batch 384/486 in epoch 481,  batch loss: 1.64992, batch accuracy: 0.56000
Time: 2018-07-15 02:26:52
TRAINING STATS: batch 434/486 in epoch 481,  batch loss: 1.74244, batch accuracy: 0.52633
Time: 2018-07-15 02:26:57
TRAINING STATS: batch 484/486 in epoch 481,  batch loss: 1.70010, batch accuracy: 0.53633
Time: 2018-07-15 02:27:01
TRAINING STATS: batch 48/486 in epoch 482,   batch loss: 1.70138, batch accuracy: 0.54050
Time: 2018-07-15 02:27:05
TRAINING STATS: batch 98/486 in epoch 482,   batch loss: 1.62970, batch accuracy: 0.55950
Time: 2018-07-15 02:27:09
TRAINING STATS: batch 148/486 in epoch 482,  batch loss: 1.70775, batch accuracy: 0.54117
Time: 2018-07-15 02:27:13
TRAINING STATS: batch 198/486 in epoch 482,  batch loss: 1.67235, batch accuracy: 0.54533
Time: 2018-07-15 02:27:17
TRAINING STATS: batch 248/486 in epoch 482,  batch loss: 1.70771, batch accuracy: 0.53783
Time: 2018-07-15 02:27:21
TRAINING STATS: batch 298/486 in epoch 482,  batch loss: 1.69231, batch accuracy: 0.54133
Time: 2018-07-15 02:27:25
TRAINING STATS: batch 348/486 in epoch 482,  batch loss: 1.68706, batch accuracy: 0.54500
Time: 2018-07-15 02:27:29
TRAINING STATS: batch 398/486 in epoch 482,  batch loss: 1.67583, batch accuracy: 0.54967
Time: 2018-07-15 02:27:33
TRAINING STATS: batch 448/486 in epoch 482,  batch loss: 1.67501, batch accuracy: 0.55467
Time: 2018-07-15 02:27:37
TRAINING STATS: batch 12/486 in epoch 483,   batch loss: 1.70855, batch accuracy: 0.53233
Time: 2018-07-15 02:27:41
TRAINING STATS: batch 62/486 in epoch 483,   batch loss: 1.75234, batch accuracy: 0.52417
Time: 2018-07-15 02:27:45
TRAINING STATS: batch 112/486 in epoch 483,  batch loss: 1.66458, batch accuracy: 0.55383
Time: 2018-07-15 02:27:49
TRAINING STATS: batch 162/486 in epoch 483,  batch loss: 1.68728, batch accuracy: 0.54483
Time: 2018-07-15 02:27:53
TRAINING STATS: batch 212/486 in epoch 483,  batch loss: 1.61351, batch accuracy: 0.56833
Time: 2018-07-15 02:27:57
TRAINING STATS: batch 262/486 in epoch 483,  batch loss: 1.74628, batch accuracy: 0.52633
Time: 2018-07-15 02:28:01
TRAINING STATS: batch 312/486 in epoch 483,  batch loss: 1.68993, batch accuracy: 0.54117
Time: 2018-07-15 02:28:05
TRAINING STATS: batch 362/486 in epoch 483,  batch loss: 1.68914, batch accuracy: 0.54483
Time: 2018-07-15 02:28:09
TRAINING STATS: batch 412/486 in epoch 483,  batch loss: 1.63782, batch accuracy: 0.55933
Time: 2018-07-15 02:28:13
TRAINING STATS: batch 462/486 in epoch 483,  batch loss: 1.68284, batch accuracy: 0.54983
Time: 2018-07-15 02:28:17
TRAINING STATS: batch 26/486 in epoch 484,   batch loss: 1.72249, batch accuracy: 0.53233
Time: 2018-07-15 02:28:21
TRAINING STATS: batch 76/486 in epoch 484,   batch loss: 1.73022, batch accuracy: 0.53750
Time: 2018-07-15 02:28:25
TRAINING STATS: batch 126/486 in epoch 484,  batch loss: 1.71212, batch accuracy: 0.53283
Time: 2018-07-15 02:28:29
TRAINING STATS: batch 176/486 in epoch 484,  batch loss: 1.60145, batch accuracy: 0.57267
Time: 2018-07-15 02:28:33
TRAINING STATS: batch 226/486 in epoch 484,  batch loss: 1.66151, batch accuracy: 0.55367
Time: 2018-07-15 02:28:37
TRAINING STATS: batch 276/486 in epoch 484,  batch loss: 1.67774, batch accuracy: 0.54067
Time: 2018-07-15 02:28:41
TRAINING STATS: batch 326/486 in epoch 484,  batch loss: 1.73772, batch accuracy: 0.53000
Time: 2018-07-15 02:28:46
TRAINING STATS: batch 376/486 in epoch 484,  batch loss: 1.70300, batch accuracy: 0.54050
Time: 2018-07-15 02:28:49
TRAINING STATS: batch 426/486 in epoch 484,  batch loss: 1.71150, batch accuracy: 0.53417
Time: 2018-07-15 02:28:53
TRAINING STATS: batch 476/486 in epoch 484,  batch loss: 1.65722, batch accuracy: 0.55383
Time: 2018-07-15 02:28:58
TRAINING STATS: batch 40/486 in epoch 485,   batch loss: 1.64067, batch accuracy: 0.55600
Time: 2018-07-15 02:29:01
TRAINING STATS: batch 90/486 in epoch 485,   batch loss: 1.72046, batch accuracy: 0.53700
Time: 2018-07-15 02:29:05
TRAINING STATS: batch 140/486 in epoch 485,  batch loss: 1.61013, batch accuracy: 0.56033
Time: 2018-07-15 02:29:10
TRAINING STATS: batch 190/486 in epoch 485,  batch loss: 1.65277, batch accuracy: 0.55133
Time: 2018-07-15 02:29:13
TRAINING STATS: batch 240/486 in epoch 485,  batch loss: 1.64859, batch accuracy: 0.55433
Time: 2018-07-15 02:29:17
TRAINING STATS: batch 290/486 in epoch 485,  batch loss: 1.70897, batch accuracy: 0.53300
Time: 2018-07-15 02:29:22
TRAINING STATS: batch 340/486 in epoch 485,  batch loss: 1.75464, batch accuracy: 0.51983
Time: 2018-07-15 02:29:25
TRAINING STATS: batch 390/486 in epoch 485,  batch loss: 1.61512, batch accuracy: 0.56350
Time: 2018-07-15 02:29:29
TRAINING STATS: batch 440/486 in epoch 485,  batch loss: 1.67401, batch accuracy: 0.54900
Time: 2018-07-15 02:29:34
TRAINING STATS: batch 4/486 in epoch 486,    batch loss: 1.63869, batch accuracy: 0.56800
Time: 2018-07-15 02:29:37
TRAINING STATS: batch 54/486 in epoch 486,   batch loss: 1.67047, batch accuracy: 0.54883
Time: 2018-07-15 02:29:41
TRAINING STATS: batch 104/486 in epoch 486,  batch loss: 1.69502, batch accuracy: 0.54517
Time: 2018-07-15 02:29:46
TRAINING STATS: batch 154/486 in epoch 486,  batch loss: 1.66150, batch accuracy: 0.54933
Time: 2018-07-15 02:29:49
TRAINING STATS: batch 204/486 in epoch 486,  batch loss: 1.80368, batch accuracy: 0.51567
Time: 2018-07-15 02:29:53
TRAINING STATS: batch 254/486 in epoch 486,  batch loss: 1.61183, batch accuracy: 0.56817
Time: 2018-07-15 02:29:58
TRAINING STATS: batch 304/486 in epoch 486,  batch loss: 1.63758, batch accuracy: 0.56567
Time: 2018-07-15 02:30:01
TRAINING STATS: batch 354/486 in epoch 486,  batch loss: 1.67338, batch accuracy: 0.55267
Time: 2018-07-15 02:30:05
TRAINING STATS: batch 404/486 in epoch 486,  batch loss: 1.66741, batch accuracy: 0.54833
Time: 2018-07-15 02:30:10
TRAINING STATS: batch 454/486 in epoch 486,  batch loss: 1.53976, batch accuracy: 0.58767
Time: 2018-07-15 02:30:13
TRAINING STATS: batch 18/486 in epoch 487,   batch loss: 1.69722, batch accuracy: 0.53867
Time: 2018-07-15 02:30:17
TRAINING STATS: batch 68/486 in epoch 487,   batch loss: 1.53379, batch accuracy: 0.58300
Time: 2018-07-15 02:30:22
TRAINING STATS: batch 118/486 in epoch 487,  batch loss: 1.67087, batch accuracy: 0.55383
Time: 2018-07-15 02:30:25
TRAINING STATS: batch 168/486 in epoch 487,  batch loss: 1.61729, batch accuracy: 0.57033
Time: 2018-07-15 02:30:29
TRAINING STATS: batch 218/486 in epoch 487,  batch loss: 1.65451, batch accuracy: 0.54800
Time: 2018-07-15 02:30:34
TRAINING STATS: batch 268/486 in epoch 487,  batch loss: 1.63548, batch accuracy: 0.55683
Time: 2018-07-15 02:30:37
TRAINING STATS: batch 318/486 in epoch 487,  batch loss: 1.67577, batch accuracy: 0.54383
Time: 2018-07-15 02:30:41
TRAINING STATS: batch 368/486 in epoch 487,  batch loss: 1.68439, batch accuracy: 0.54500
Time: 2018-07-15 02:30:46
TRAINING STATS: batch 418/486 in epoch 487,  batch loss: 1.70552, batch accuracy: 0.53733
Time: 2018-07-15 02:30:50
TRAINING STATS: batch 468/486 in epoch 487,  batch loss: 1.69748, batch accuracy: 0.53917
Time: 2018-07-15 02:30:53
TRAINING STATS: batch 32/486 in epoch 488,   batch loss: 1.65835, batch accuracy: 0.55317
Time: 2018-07-15 02:30:58
TRAINING STATS: batch 82/486 in epoch 488,   batch loss: 1.71532, batch accuracy: 0.53333
Time: 2018-07-15 02:31:02
TRAINING STATS: batch 132/486 in epoch 488,  batch loss: 1.64642, batch accuracy: 0.56800
Time: 2018-07-15 02:31:05
TRAINING STATS: batch 182/486 in epoch 488,  batch loss: 1.72990, batch accuracy: 0.52617
Time: 2018-07-15 02:31:10
TRAINING STATS: batch 232/486 in epoch 488,  batch loss: 1.70945, batch accuracy: 0.53683
Time: 2018-07-15 02:31:14
TRAINING STATS: batch 282/486 in epoch 488,  batch loss: 1.63007, batch accuracy: 0.55450
Time: 2018-07-15 02:31:17
TRAINING STATS: batch 332/486 in epoch 488,  batch loss: 1.71149, batch accuracy: 0.53317
Time: 2018-07-15 02:31:22
TRAINING STATS: batch 382/486 in epoch 488,  batch loss: 1.69575, batch accuracy: 0.54533
Time: 2018-07-15 02:31:26
TRAINING STATS: batch 432/486 in epoch 488,  batch loss: 1.61471, batch accuracy: 0.56700
Time: 2018-07-15 02:31:29
TRAINING STATS: batch 482/486 in epoch 488,  batch loss: 1.67353, batch accuracy: 0.55167
Time: 2018-07-15 02:31:34
TRAINING STATS: batch 46/486 in epoch 489,   batch loss: 1.65557, batch accuracy: 0.55433
Time: 2018-07-15 02:31:38
TRAINING STATS: batch 96/486 in epoch 489,   batch loss: 1.71603, batch accuracy: 0.54050
Time: 2018-07-15 02:31:41
TRAINING STATS: batch 146/486 in epoch 489,  batch loss: 1.72597, batch accuracy: 0.53867
Time: 2018-07-15 02:31:46
TRAINING STATS: batch 196/486 in epoch 489,  batch loss: 1.75210, batch accuracy: 0.52850
Time: 2018-07-15 02:31:50
TRAINING STATS: batch 246/486 in epoch 489,  batch loss: 1.65526, batch accuracy: 0.55517
Time: 2018-07-15 02:31:53
TRAINING STATS: batch 296/486 in epoch 489,  batch loss: 1.64017, batch accuracy: 0.55617
Time: 2018-07-15 02:31:58
TRAINING STATS: batch 346/486 in epoch 489,  batch loss: 1.60501, batch accuracy: 0.57500
Time: 2018-07-15 02:32:02
TRAINING STATS: batch 396/486 in epoch 489,  batch loss: 1.67221, batch accuracy: 0.55383
Time: 2018-07-15 02:32:05
TRAINING STATS: batch 446/486 in epoch 489,  batch loss: 1.69970, batch accuracy: 0.54317
Time: 2018-07-15 02:32:10
TRAINING STATS: batch 10/486 in epoch 490,   batch loss: 1.71538, batch accuracy: 0.53200
Time: 2018-07-15 02:32:14
TRAINING STATS: batch 60/486 in epoch 490,   batch loss: 1.66783, batch accuracy: 0.55267
Time: 2018-07-15 02:32:17
TRAINING STATS: batch 110/486 in epoch 490,  batch loss: 1.73346, batch accuracy: 0.53450
Time: 2018-07-15 02:32:22
TRAINING STATS: batch 160/486 in epoch 490,  batch loss: 1.65219, batch accuracy: 0.55033
Time: 2018-07-15 02:32:26
TRAINING STATS: batch 210/486 in epoch 490,  batch loss: 1.60990, batch accuracy: 0.56250
Time: 2018-07-15 02:32:29
TRAINING STATS: batch 260/486 in epoch 490,  batch loss: 1.70283, batch accuracy: 0.53217
Time: 2018-07-15 02:32:34
TRAINING STATS: batch 310/486 in epoch 490,  batch loss: 1.69917, batch accuracy: 0.53333
Time: 2018-07-15 02:32:38
TRAINING STATS: batch 360/486 in epoch 490,  batch loss: 1.72878, batch accuracy: 0.52967
Time: 2018-07-15 02:32:42
TRAINING STATS: batch 410/486 in epoch 490,  batch loss: 1.61375, batch accuracy: 0.56467
Time: 2018-07-15 02:32:46
TRAINING STATS: batch 460/486 in epoch 490,  batch loss: 1.79185, batch accuracy: 0.51100
Time: 2018-07-15 02:32:50
TRAINING STATS: batch 24/486 in epoch 491,   batch loss: 1.75527, batch accuracy: 0.52450
Time: 2018-07-15 02:32:54
TRAINING STATS: batch 74/486 in epoch 491,   batch loss: 1.70151, batch accuracy: 0.54133
Time: 2018-07-15 02:32:58
TRAINING STATS: batch 124/486 in epoch 491,  batch loss: 1.70403, batch accuracy: 0.54133
Time: 2018-07-15 02:33:02
TRAINING STATS: batch 174/486 in epoch 491,  batch loss: 1.74653, batch accuracy: 0.52583
Time: 2018-07-15 02:33:06
TRAINING STATS: batch 224/486 in epoch 491,  batch loss: 1.71064, batch accuracy: 0.54517
Time: 2018-07-15 02:33:10
TRAINING STATS: batch 274/486 in epoch 491,  batch loss: 1.68392, batch accuracy: 0.55083
Time: 2018-07-15 02:33:14
TRAINING STATS: batch 324/486 in epoch 491,  batch loss: 1.71462, batch accuracy: 0.53967
Time: 2018-07-15 02:33:18
TRAINING STATS: batch 374/486 in epoch 491,  batch loss: 1.73217, batch accuracy: 0.53733
Time: 2018-07-15 02:33:22
TRAINING STATS: batch 424/486 in epoch 491,  batch loss: 1.63329, batch accuracy: 0.55483
Time: 2018-07-15 02:33:26
TRAINING STATS: batch 474/486 in epoch 491,  batch loss: 1.69285, batch accuracy: 0.53900
Time: 2018-07-15 02:33:30
TRAINING STATS: batch 38/486 in epoch 492,   batch loss: 1.70412, batch accuracy: 0.54750
Time: 2018-07-15 02:33:34
TRAINING STATS: batch 88/486 in epoch 492,   batch loss: 1.72543, batch accuracy: 0.53233
Time: 2018-07-15 02:33:38
TRAINING STATS: batch 138/486 in epoch 492,  batch loss: 1.71768, batch accuracy: 0.53100
Time: 2018-07-15 02:33:42
TRAINING STATS: batch 188/486 in epoch 492,  batch loss: 1.63610, batch accuracy: 0.55700
Time: 2018-07-15 02:33:46
TRAINING STATS: batch 238/486 in epoch 492,  batch loss: 1.66042, batch accuracy: 0.55067
Time: 2018-07-15 02:33:50
TRAINING STATS: batch 288/486 in epoch 492,  batch loss: 1.71364, batch accuracy: 0.53217
Time: 2018-07-15 02:33:54
TRAINING STATS: batch 338/486 in epoch 492,  batch loss: 1.68354, batch accuracy: 0.54650
Time: 2018-07-15 02:33:59
TRAINING STATS: batch 388/486 in epoch 492,  batch loss: 1.64474, batch accuracy: 0.55533
Time: 2018-07-15 02:34:02
TRAINING STATS: batch 438/486 in epoch 492,  batch loss: 1.70671, batch accuracy: 0.54033
Time: 2018-07-15 02:34:06
TRAINING STATS: batch 2/486 in epoch 493,    batch loss: 1.68935, batch accuracy: 0.54650
Time: 2018-07-15 02:34:11
TRAINING STATS: batch 52/486 in epoch 493,   batch loss: 1.74620, batch accuracy: 0.52617
Time: 2018-07-15 02:34:14
TRAINING STATS: batch 102/486 in epoch 493,  batch loss: 1.70633, batch accuracy: 0.54067
Time: 2018-07-15 02:34:18
TRAINING STATS: batch 152/486 in epoch 493,  batch loss: 1.64054, batch accuracy: 0.56083
Time: 2018-07-15 02:34:23
TRAINING STATS: batch 202/486 in epoch 493,  batch loss: 1.68510, batch accuracy: 0.55267
Time: 2018-07-15 02:34:26
TRAINING STATS: batch 252/486 in epoch 493,  batch loss: 1.65040, batch accuracy: 0.55933
Time: 2018-07-15 02:34:30
TRAINING STATS: batch 302/486 in epoch 493,  batch loss: 1.62615, batch accuracy: 0.55600
Time: 2018-07-15 02:34:35
TRAINING STATS: batch 352/486 in epoch 493,  batch loss: 1.65882, batch accuracy: 0.55567
Time: 2018-07-15 02:34:38
TRAINING STATS: batch 402/486 in epoch 493,  batch loss: 1.54751, batch accuracy: 0.59217
Time: 2018-07-15 02:34:42
TRAINING STATS: batch 452/486 in epoch 493,  batch loss: 1.66375, batch accuracy: 0.54383
Time: 2018-07-15 02:34:47
TRAINING STATS: batch 16/486 in epoch 494,   batch loss: 1.64774, batch accuracy: 0.56267
Time: 2018-07-15 02:34:50
TRAINING STATS: batch 66/486 in epoch 494,   batch loss: 1.66263, batch accuracy: 0.55367
Time: 2018-07-15 02:34:54
TRAINING STATS: batch 116/486 in epoch 494,  batch loss: 1.64827, batch accuracy: 0.56067
Time: 2018-07-15 02:34:59
TRAINING STATS: batch 166/486 in epoch 494,  batch loss: 1.57609, batch accuracy: 0.57217
Time: 2018-07-15 02:35:03
TRAINING STATS: batch 216/486 in epoch 494,  batch loss: 1.68266, batch accuracy: 0.54583
Time: 2018-07-15 02:35:06
TRAINING STATS: batch 266/486 in epoch 494,  batch loss: 1.66148, batch accuracy: 0.54733
Time: 2018-07-15 02:35:11
TRAINING STATS: batch 316/486 in epoch 494,  batch loss: 1.66455, batch accuracy: 0.55317
Time: 2018-07-15 02:35:15
TRAINING STATS: batch 366/486 in epoch 494,  batch loss: 1.71889, batch accuracy: 0.53667
Time: 2018-07-15 02:35:18
TRAINING STATS: batch 416/486 in epoch 494,  batch loss: 1.70727, batch accuracy: 0.53683
Time: 2018-07-15 02:35:23
TRAINING STATS: batch 466/486 in epoch 494,  batch loss: 1.61385, batch accuracy: 0.55733
Time: 2018-07-15 02:35:27
TRAINING STATS: batch 30/486 in epoch 495,   batch loss: 1.57528, batch accuracy: 0.57817
Time: 2018-07-15 02:35:31
TRAINING STATS: batch 80/486 in epoch 495,   batch loss: 1.67609, batch accuracy: 0.54467
Time: 2018-07-15 02:35:35
TRAINING STATS: batch 130/486 in epoch 495,  batch loss: 1.65887, batch accuracy: 0.55867
Time: 2018-07-15 02:35:39
TRAINING STATS: batch 180/486 in epoch 495,  batch loss: 1.72953, batch accuracy: 0.53800
Time: 2018-07-15 02:35:43
TRAINING STATS: batch 230/486 in epoch 495,  batch loss: 1.69540, batch accuracy: 0.54000
Time: 2018-07-15 02:35:47
TRAINING STATS: batch 280/486 in epoch 495,  batch loss: 1.68150, batch accuracy: 0.54050
Time: 2018-07-15 02:35:51
TRAINING STATS: batch 330/486 in epoch 495,  batch loss: 1.64466, batch accuracy: 0.54683
Time: 2018-07-15 02:35:55
TRAINING STATS: batch 380/486 in epoch 495,  batch loss: 1.63707, batch accuracy: 0.55983
Time: 2018-07-15 02:35:59
TRAINING STATS: batch 430/486 in epoch 495,  batch loss: 1.64173, batch accuracy: 0.55183
Time: 2018-07-15 02:36:03
TRAINING STATS: batch 480/486 in epoch 495,  batch loss: 1.69395, batch accuracy: 0.54700
Time: 2018-07-15 02:36:07
TRAINING STATS: batch 44/486 in epoch 496,   batch loss: 1.62469, batch accuracy: 0.56217
Time: 2018-07-15 02:36:11
TRAINING STATS: batch 94/486 in epoch 496,   batch loss: 1.72111, batch accuracy: 0.54117
Time: 2018-07-15 02:36:15
TRAINING STATS: batch 144/486 in epoch 496,  batch loss: 1.73632, batch accuracy: 0.52917
Time: 2018-07-15 02:36:19
TRAINING STATS: batch 194/486 in epoch 496,  batch loss: 1.77751, batch accuracy: 0.51817
Time: 2018-07-15 02:36:23
TRAINING STATS: batch 244/486 in epoch 496,  batch loss: 1.66354, batch accuracy: 0.55267
Time: 2018-07-15 02:36:27
TRAINING STATS: batch 294/486 in epoch 496,  batch loss: 1.62296, batch accuracy: 0.56333
Time: 2018-07-15 02:36:31
TRAINING STATS: batch 344/486 in epoch 496,  batch loss: 1.66093, batch accuracy: 0.54800
Time: 2018-07-15 02:36:36
TRAINING STATS: batch 394/486 in epoch 496,  batch loss: 1.62338, batch accuracy: 0.56750
Time: 2018-07-15 02:36:39
TRAINING STATS: batch 444/486 in epoch 496,  batch loss: 1.60279, batch accuracy: 0.57233
Time: 2018-07-15 02:36:43
TRAINING STATS: batch 8/486 in epoch 497,    batch loss: 1.65524, batch accuracy: 0.56267
Time: 2018-07-15 02:36:48
TRAINING STATS: batch 58/486 in epoch 497,   batch loss: 1.62333, batch accuracy: 0.56650
Time: 2018-07-15 02:36:51
TRAINING STATS: batch 108/486 in epoch 497,  batch loss: 1.72696, batch accuracy: 0.53683
Time: 2018-07-15 02:36:55
TRAINING STATS: batch 158/486 in epoch 497,  batch loss: 1.72892, batch accuracy: 0.53800
Time: 2018-07-15 02:37:00
TRAINING STATS: batch 208/486 in epoch 497,  batch loss: 1.68550, batch accuracy: 0.54350
Time: 2018-07-15 02:37:03
TRAINING STATS: batch 258/486 in epoch 497,  batch loss: 1.63525, batch accuracy: 0.55383
Time: 2018-07-15 02:37:07
TRAINING STATS: batch 308/486 in epoch 497,  batch loss: 1.70302, batch accuracy: 0.54183
Time: 2018-07-15 02:37:12
TRAINING STATS: batch 358/486 in epoch 497,  batch loss: 1.71159, batch accuracy: 0.53567
Time: 2018-07-15 02:37:15
TRAINING STATS: batch 408/486 in epoch 497,  batch loss: 1.72453, batch accuracy: 0.53033
Time: 2018-07-15 02:37:19
TRAINING STATS: batch 458/486 in epoch 497,  batch loss: 1.69667, batch accuracy: 0.54717
Time: 2018-07-15 02:37:24
TRAINING STATS: batch 22/486 in epoch 498,   batch loss: 1.72488, batch accuracy: 0.53600
Time: 2018-07-15 02:37:28
TRAINING STATS: batch 72/486 in epoch 498,   batch loss: 1.72412, batch accuracy: 0.52700
Time: 2018-07-15 02:37:31
TRAINING STATS: batch 122/486 in epoch 498,  batch loss: 1.64985, batch accuracy: 0.56167
Time: 2018-07-15 02:37:36
TRAINING STATS: batch 172/486 in epoch 498,  batch loss: 1.72647, batch accuracy: 0.53400
Time: 2018-07-15 02:37:40
TRAINING STATS: batch 222/486 in epoch 498,  batch loss: 1.64013, batch accuracy: 0.55233
Time: 2018-07-15 02:37:43
TRAINING STATS: batch 272/486 in epoch 498,  batch loss: 1.72647, batch accuracy: 0.53033
Time: 2018-07-15 02:37:48
TRAINING STATS: batch 322/486 in epoch 498,  batch loss: 1.66609, batch accuracy: 0.54550
Time: 2018-07-15 02:37:52
TRAINING STATS: batch 372/486 in epoch 498,  batch loss: 1.61355, batch accuracy: 0.56717
Time: 2018-07-15 02:37:55
TRAINING STATS: batch 422/486 in epoch 498,  batch loss: 1.64716, batch accuracy: 0.55317
Time: 2018-07-15 02:38:00
TRAINING STATS: batch 472/486 in epoch 498,  batch loss: 1.73504, batch accuracy: 0.53033
Time: 2018-07-15 02:38:04
TRAINING STATS: batch 36/486 in epoch 499,   batch loss: 1.72946, batch accuracy: 0.53583
Time: 2018-07-15 02:38:07
TRAINING STATS: batch 86/486 in epoch 499,   batch loss: 1.67169, batch accuracy: 0.54833
Time: 2018-07-15 02:38:12
TRAINING STATS: batch 136/486 in epoch 499,  batch loss: 1.72074, batch accuracy: 0.53400
Time: 2018-07-15 02:38:16
TRAINING STATS: batch 186/486 in epoch 499,  batch loss: 1.68998, batch accuracy: 0.54533
Time: 2018-07-15 02:38:19
TRAINING STATS: batch 236/486 in epoch 499,  batch loss: 1.70984, batch accuracy: 0.53067
Time: 2018-07-15 02:38:24
TRAINING STATS: batch 286/486 in epoch 499,  batch loss: 1.70883, batch accuracy: 0.54533
Time: 2018-07-15 02:38:28
TRAINING STATS: batch 336/486 in epoch 499,  batch loss: 1.67331, batch accuracy: 0.55067
Time: 2018-07-15 02:38:31
TRAINING STATS: batch 386/486 in epoch 499,  batch loss: 1.72373, batch accuracy: 0.53350
Time: 2018-07-15 02:38:36
TRAINING STATS: batch 436/486 in epoch 499,  batch loss: 1.70573, batch accuracy: 0.54533
Time: 2018-07-15 02:38:40
TRAINING STATS: batch 0/486 in epoch 500,    batch loss: 1.65378, batch accuracy: 0.55467
Time: 2018-07-15 02:38:44
TRAINING STATS: batch 50/486 in epoch 500,   batch loss: 1.63848, batch accuracy: 0.56583
Time: 2018-07-15 02:38:48
TRAINING STATS: batch 100/486 in epoch 500,  batch loss: 1.68557, batch accuracy: 0.55283
Time: 2018-07-15 02:38:52
TRAINING STATS: batch 150/486 in epoch 500,  batch loss: 1.65330, batch accuracy: 0.55817
Time: 2018-07-15 02:38:56
TRAINING STATS: batch 200/486 in epoch 500,  batch loss: 1.55223, batch accuracy: 0.58367
Time: 2018-07-15 02:39:00
TRAINING STATS: batch 250/486 in epoch 500,  batch loss: 1.73468, batch accuracy: 0.51683
Time: 2018-07-15 02:39:04
TRAINING STATS: batch 300/486 in epoch 500,  batch loss: 1.69995, batch accuracy: 0.53683
Time: 2018-07-15 02:39:08
TRAINING STATS: batch 350/486 in epoch 500,  batch loss: 1.68315, batch accuracy: 0.55100
Time: 2018-07-15 02:39:12
TRAINING STATS: batch 400/486 in epoch 500,  batch loss: 1.56019, batch accuracy: 0.57883
Time: 2018-07-15 02:39:16
TRAINING STATS: batch 450/486 in epoch 500,  batch loss: 1.72485, batch accuracy: 0.52983
Time: 2018-07-15 02:39:20
TRAINING STATS: batch 14/486 in epoch 501,   batch loss: 1.59935, batch accuracy: 0.57067
Time: 2018-07-15 02:39:24
TRAINING STATS: batch 64/486 in epoch 501,   batch loss: 1.77751, batch accuracy: 0.50833
Time: 2018-07-15 02:39:28
TRAINING STATS: batch 114/486 in epoch 501,  batch loss: 1.71847, batch accuracy: 0.53133
Time: 2018-07-15 02:39:32
TRAINING STATS: batch 164/486 in epoch 501,  batch loss: 1.60253, batch accuracy: 0.57183
Time: 2018-07-15 02:39:36
TRAINING STATS: batch 214/486 in epoch 501,  batch loss: 1.68172, batch accuracy: 0.54567
Time: 2018-07-15 02:39:40
TRAINING STATS: batch 264/486 in epoch 501,  batch loss: 1.70173, batch accuracy: 0.53667
Time: 2018-07-15 02:39:44
TRAINING STATS: batch 314/486 in epoch 501,  batch loss: 1.72535, batch accuracy: 0.53033
Time: 2018-07-15 02:39:49
TRAINING STATS: batch 364/486 in epoch 501,  batch loss: 1.65547, batch accuracy: 0.55283
Time: 2018-07-15 02:39:52
TRAINING STATS: batch 414/486 in epoch 501,  batch loss: 1.60642, batch accuracy: 0.56733
Time: 2018-07-15 02:39:56
TRAINING STATS: batch 464/486 in epoch 501,  batch loss: 1.62554, batch accuracy: 0.55983
Time: 2018-07-15 02:40:01
TRAINING STATS: batch 28/486 in epoch 502,   batch loss: 1.59598, batch accuracy: 0.57267
Time: 2018-07-15 02:40:04
TRAINING STATS: batch 78/486 in epoch 502,   batch loss: 1.66213, batch accuracy: 0.56167
Time: 2018-07-15 02:40:08
TRAINING STATS: batch 128/486 in epoch 502,  batch loss: 1.66005, batch accuracy: 0.55133
Time: 2018-07-15 02:40:13
TRAINING STATS: batch 178/486 in epoch 502,  batch loss: 1.57537, batch accuracy: 0.57150
Time: 2018-07-15 02:40:16
TRAINING STATS: batch 228/486 in epoch 502,  batch loss: 1.62050, batch accuracy: 0.55983
Time: 2018-07-15 02:40:20
TRAINING STATS: batch 278/486 in epoch 502,  batch loss: 1.61073, batch accuracy: 0.56500
Time: 2018-07-15 02:40:25
TRAINING STATS: batch 328/486 in epoch 502,  batch loss: 1.64065, batch accuracy: 0.55350
Time: 2018-07-15 02:40:28
TRAINING STATS: batch 378/486 in epoch 502,  batch loss: 1.66803, batch accuracy: 0.55567
Time: 2018-07-15 02:40:32
TRAINING STATS: batch 428/486 in epoch 502,  batch loss: 1.70386, batch accuracy: 0.53167
Time: 2018-07-15 02:40:37
TRAINING STATS: batch 478/486 in epoch 502,  batch loss: 1.69734, batch accuracy: 0.54650
Time: 2018-07-15 02:40:41
TRAINING STATS: batch 42/486 in epoch 503,   batch loss: 1.59962, batch accuracy: 0.56750
Time: 2018-07-15 02:40:44
TRAINING STATS: batch 92/486 in epoch 503,   batch loss: 1.68639, batch accuracy: 0.54900
Time: 2018-07-15 02:40:49
TRAINING STATS: batch 142/486 in epoch 503,  batch loss: 1.62500, batch accuracy: 0.55967
Time: 2018-07-15 02:40:53
TRAINING STATS: batch 192/486 in epoch 503,  batch loss: 1.67064, batch accuracy: 0.55083
Time: 2018-07-15 02:40:56
TRAINING STATS: batch 242/486 in epoch 503,  batch loss: 1.64671, batch accuracy: 0.55900
Time: 2018-07-15 02:41:01
TRAINING STATS: batch 292/486 in epoch 503,  batch loss: 1.64420, batch accuracy: 0.55767
Time: 2018-07-15 02:41:05
TRAINING STATS: batch 342/486 in epoch 503,  batch loss: 1.64554, batch accuracy: 0.55783
Time: 2018-07-15 02:41:08
TRAINING STATS: batch 392/486 in epoch 503,  batch loss: 1.60383, batch accuracy: 0.57383
Time: 2018-07-15 02:41:13
TRAINING STATS: batch 442/486 in epoch 503,  batch loss: 1.57954, batch accuracy: 0.57333
Time: 2018-07-15 02:41:17
TRAINING STATS: batch 6/486 in epoch 504,    batch loss: 1.71233, batch accuracy: 0.54000
Time: 2018-07-15 02:41:20
TRAINING STATS: batch 56/486 in epoch 504,   batch loss: 1.61259, batch accuracy: 0.56267
Time: 2018-07-15 02:41:25
TRAINING STATS: batch 106/486 in epoch 504,  batch loss: 1.74168, batch accuracy: 0.52333
Time: 2018-07-15 02:41:29
TRAINING STATS: batch 156/486 in epoch 504,  batch loss: 1.69599, batch accuracy: 0.53600
Time: 2018-07-15 02:41:33
TRAINING STATS: batch 206/486 in epoch 504,  batch loss: 1.76909, batch accuracy: 0.51650
Time: 2018-07-15 02:41:37
TRAINING STATS: batch 256/486 in epoch 504,  batch loss: 1.61850, batch accuracy: 0.56433
Time: 2018-07-15 02:41:41
TRAINING STATS: batch 306/486 in epoch 504,  batch loss: 1.66605, batch accuracy: 0.55200
Time: 2018-07-15 02:41:45
TRAINING STATS: batch 356/486 in epoch 504,  batch loss: 1.70444, batch accuracy: 0.53817
Time: 2018-07-15 02:41:49
TRAINING STATS: batch 406/486 in epoch 504,  batch loss: 1.73165, batch accuracy: 0.52600
Time: 2018-07-15 02:41:53
TRAINING STATS: batch 456/486 in epoch 504,  batch loss: 1.54705, batch accuracy: 0.58850
Time: 2018-07-15 02:41:57
TRAINING STATS: batch 20/486 in epoch 505,   batch loss: 1.66576, batch accuracy: 0.55133
Time: 2018-07-15 02:42:01
TRAINING STATS: batch 70/486 in epoch 505,   batch loss: 1.58870, batch accuracy: 0.57483
Time: 2018-07-15 02:42:05
TRAINING STATS: batch 120/486 in epoch 505,  batch loss: 1.61918, batch accuracy: 0.56683
Time: 2018-07-15 02:42:09
TRAINING STATS: batch 170/486 in epoch 505,  batch loss: 1.64744, batch accuracy: 0.55433
Time: 2018-07-15 02:42:13
TRAINING STATS: batch 220/486 in epoch 505,  batch loss: 1.58280, batch accuracy: 0.57383
Time: 2018-07-15 02:42:17
TRAINING STATS: batch 270/486 in epoch 505,  batch loss: 1.66592, batch accuracy: 0.53617
Time: 2018-07-15 02:42:21
TRAINING STATS: batch 320/486 in epoch 505,  batch loss: 1.61131, batch accuracy: 0.56550
Time: 2018-07-15 02:42:25
TRAINING STATS: batch 370/486 in epoch 505,  batch loss: 1.67175, batch accuracy: 0.54900
Time: 2018-07-15 02:42:29
TRAINING STATS: batch 420/486 in epoch 505,  batch loss: 1.69876, batch accuracy: 0.54350
Time: 2018-07-15 02:42:33
TRAINING STATS: batch 470/486 in epoch 505,  batch loss: 1.77034, batch accuracy: 0.51083
Time: 2018-07-15 02:42:37
TRAINING STATS: batch 34/486 in epoch 506,   batch loss: 1.67977, batch accuracy: 0.54633
Time: 2018-07-15 02:42:41
TRAINING STATS: batch 84/486 in epoch 506,   batch loss: 1.66841, batch accuracy: 0.54333
Time: 2018-07-15 02:42:45
TRAINING STATS: batch 134/486 in epoch 506,  batch loss: 1.68861, batch accuracy: 0.54500
Time: 2018-07-15 02:42:50
TRAINING STATS: batch 184/486 in epoch 506,  batch loss: 1.66846, batch accuracy: 0.54850
Time: 2018-07-15 02:42:53
TRAINING STATS: batch 234/486 in epoch 506,  batch loss: 1.74439, batch accuracy: 0.52667
Time: 2018-07-15 02:42:57
TRAINING STATS: batch 284/486 in epoch 506,  batch loss: 1.73061, batch accuracy: 0.53433
Time: 2018-07-15 02:43:01
TRAINING STATS: batch 334/486 in epoch 506,  batch loss: 1.64918, batch accuracy: 0.54933
Time: 2018-07-15 02:43:05
TRAINING STATS: batch 384/486 in epoch 506,  batch loss: 1.63756, batch accuracy: 0.56283
Time: 2018-07-15 02:43:09
TRAINING STATS: batch 434/486 in epoch 506,  batch loss: 1.72905, batch accuracy: 0.52917
Time: 2018-07-15 02:43:14
TRAINING STATS: batch 484/486 in epoch 506,  batch loss: 1.68704, batch accuracy: 0.53650
Time: 2018-07-15 02:43:17
TRAINING STATS: batch 48/486 in epoch 507,   batch loss: 1.69622, batch accuracy: 0.54283
Time: 2018-07-15 02:43:21
TRAINING STATS: batch 98/486 in epoch 507,   batch loss: 1.60265, batch accuracy: 0.56900
Time: 2018-07-15 02:43:26
TRAINING STATS: batch 148/486 in epoch 507,  batch loss: 1.70126, batch accuracy: 0.54533
Time: 2018-07-15 02:43:29
TRAINING STATS: batch 198/486 in epoch 507,  batch loss: 1.67160, batch accuracy: 0.54267
Time: 2018-07-15 02:43:33
TRAINING STATS: batch 248/486 in epoch 507,  batch loss: 1.69857, batch accuracy: 0.53617
Time: 2018-07-15 02:43:38
TRAINING STATS: batch 298/486 in epoch 507,  batch loss: 1.67746, batch accuracy: 0.54383
Time: 2018-07-15 02:43:42
TRAINING STATS: batch 348/486 in epoch 507,  batch loss: 1.66412, batch accuracy: 0.55267
Time: 2018-07-15 02:43:45
TRAINING STATS: batch 398/486 in epoch 507,  batch loss: 1.67262, batch accuracy: 0.55250
Time: 2018-07-15 02:43:50
TRAINING STATS: batch 448/486 in epoch 507,  batch loss: 1.67930, batch accuracy: 0.55633
Time: 2018-07-15 02:43:54
TRAINING STATS: batch 12/486 in epoch 508,   batch loss: 1.68375, batch accuracy: 0.54600
Time: 2018-07-15 02:43:57
TRAINING STATS: batch 62/486 in epoch 508,   batch loss: 1.74863, batch accuracy: 0.52617
Time: 2018-07-15 02:44:02
TRAINING STATS: batch 112/486 in epoch 508,  batch loss: 1.67941, batch accuracy: 0.54867
Time: 2018-07-15 02:44:06
TRAINING STATS: batch 162/486 in epoch 508,  batch loss: 1.67119, batch accuracy: 0.55233
Time: 2018-07-15 02:44:09
TRAINING STATS: batch 212/486 in epoch 508,  batch loss: 1.56586, batch accuracy: 0.57433
Time: 2018-07-15 02:44:14
TRAINING STATS: batch 262/486 in epoch 508,  batch loss: 1.72311, batch accuracy: 0.53333
Time: 2018-07-15 02:44:18
TRAINING STATS: batch 312/486 in epoch 508,  batch loss: 1.67133, batch accuracy: 0.53717
Time: 2018-07-15 02:44:21
TRAINING STATS: batch 362/486 in epoch 508,  batch loss: 1.67634, batch accuracy: 0.54717
Time: 2018-07-15 02:44:26
TRAINING STATS: batch 412/486 in epoch 508,  batch loss: 1.61891, batch accuracy: 0.57033
Time: 2018-07-15 02:44:30
TRAINING STATS: batch 462/486 in epoch 508,  batch loss: 1.69367, batch accuracy: 0.54217
Time: 2018-07-15 02:44:33
TRAINING STATS: batch 26/486 in epoch 509,   batch loss: 1.72252, batch accuracy: 0.53283
Time: 2018-07-15 02:44:38
TRAINING STATS: batch 76/486 in epoch 509,   batch loss: 1.70750, batch accuracy: 0.54633
Time: 2018-07-15 02:44:42
TRAINING STATS: batch 126/486 in epoch 509,  batch loss: 1.70640, batch accuracy: 0.53700
Time: 2018-07-15 02:44:45
TRAINING STATS: batch 176/486 in epoch 509,  batch loss: 1.59754, batch accuracy: 0.57867
Time: 2018-07-15 02:44:50
TRAINING STATS: batch 226/486 in epoch 509,  batch loss: 1.65101, batch accuracy: 0.56133
Time: 2018-07-15 02:44:54
TRAINING STATS: batch 276/486 in epoch 509,  batch loss: 1.65711, batch accuracy: 0.55300
Time: 2018-07-15 02:44:58
TRAINING STATS: batch 326/486 in epoch 509,  batch loss: 1.74846, batch accuracy: 0.52983
Time: 2018-07-15 02:45:02
TRAINING STATS: batch 376/486 in epoch 509,  batch loss: 1.69565, batch accuracy: 0.54100
Time: 2018-07-15 02:45:06
TRAINING STATS: batch 426/486 in epoch 509,  batch loss: 1.67367, batch accuracy: 0.54783
Time: 2018-07-15 02:45:10
TRAINING STATS: batch 476/486 in epoch 509,  batch loss: 1.62066, batch accuracy: 0.56500
Time: 2018-07-15 02:45:14
TRAINING STATS: batch 40/486 in epoch 510,   batch loss: 1.62990, batch accuracy: 0.55883
Time: 2018-07-15 02:45:18
TRAINING STATS: batch 90/486 in epoch 510,   batch loss: 1.70522, batch accuracy: 0.54517
Time: 2018-07-15 02:45:22
TRAINING STATS: batch 140/486 in epoch 510,  batch loss: 1.58867, batch accuracy: 0.56750
Time: 2018-07-15 02:45:26
TRAINING STATS: batch 190/486 in epoch 510,  batch loss: 1.68135, batch accuracy: 0.54583
Time: 2018-07-15 02:45:30
TRAINING STATS: batch 240/486 in epoch 510,  batch loss: 1.65509, batch accuracy: 0.54717
Time: 2018-07-15 02:45:34
TRAINING STATS: batch 290/486 in epoch 510,  batch loss: 1.71133, batch accuracy: 0.53117
Time: 2018-07-15 02:45:39
TRAINING STATS: batch 340/486 in epoch 510,  batch loss: 1.74252, batch accuracy: 0.52717
Time: 2018-07-15 02:45:42
TRAINING STATS: batch 390/486 in epoch 510,  batch loss: 1.58819, batch accuracy: 0.57300
Time: 2018-07-15 02:45:46
TRAINING STATS: batch 440/486 in epoch 510,  batch loss: 1.68013, batch accuracy: 0.54250
Time: 2018-07-15 02:45:51
TRAINING STATS: batch 4/486 in epoch 511,    batch loss: 1.64067, batch accuracy: 0.55733
Time: 2018-07-15 02:45:54
TRAINING STATS: batch 54/486 in epoch 511,   batch loss: 1.68015, batch accuracy: 0.54550
Time: 2018-07-15 02:45:58
TRAINING STATS: batch 104/486 in epoch 511,  batch loss: 1.70177, batch accuracy: 0.53317
Time: 2018-07-15 02:46:03
TRAINING STATS: batch 154/486 in epoch 511,  batch loss: 1.64630, batch accuracy: 0.55333
Time: 2018-07-15 02:46:06
TRAINING STATS: batch 204/486 in epoch 511,  batch loss: 1.73900, batch accuracy: 0.52750
Time: 2018-07-15 02:46:10
TRAINING STATS: batch 254/486 in epoch 511,  batch loss: 1.59702, batch accuracy: 0.56917
Time: 2018-07-15 02:46:15
TRAINING STATS: batch 304/486 in epoch 511,  batch loss: 1.61516, batch accuracy: 0.56700
Time: 2018-07-15 02:46:18
TRAINING STATS: batch 354/486 in epoch 511,  batch loss: 1.67343, batch accuracy: 0.54750
Time: 2018-07-15 02:46:22
TRAINING STATS: batch 404/486 in epoch 511,  batch loss: 1.64474, batch accuracy: 0.55717
Time: 2018-07-15 02:46:27
TRAINING STATS: batch 454/486 in epoch 511,  batch loss: 1.53043, batch accuracy: 0.59300
Time: 2018-07-15 02:46:30
TRAINING STATS: batch 18/486 in epoch 512,   batch loss: 1.70461, batch accuracy: 0.54617
Time: 2018-07-15 02:46:34
TRAINING STATS: batch 68/486 in epoch 512,   batch loss: 1.51732, batch accuracy: 0.60200
Time: 2018-07-15 02:46:39
TRAINING STATS: batch 118/486 in epoch 512,  batch loss: 1.64339, batch accuracy: 0.55783
Time: 2018-07-15 02:46:43
TRAINING STATS: batch 168/486 in epoch 512,  batch loss: 1.60082, batch accuracy: 0.57017
Time: 2018-07-15 02:46:46
TRAINING STATS: batch 218/486 in epoch 512,  batch loss: 1.64098, batch accuracy: 0.55400
Time: 2018-07-15 02:46:51
TRAINING STATS: batch 268/486 in epoch 512,  batch loss: 1.60493, batch accuracy: 0.56067
Time: 2018-07-15 02:46:55
TRAINING STATS: batch 318/486 in epoch 512,  batch loss: 1.65281, batch accuracy: 0.55750
Time: 2018-07-15 02:46:58
TRAINING STATS: batch 368/486 in epoch 512,  batch loss: 1.68237, batch accuracy: 0.53917
Time: 2018-07-15 02:47:03
TRAINING STATS: batch 418/486 in epoch 512,  batch loss: 1.72356, batch accuracy: 0.52800
Time: 2018-07-15 02:47:07
TRAINING STATS: batch 468/486 in epoch 512,  batch loss: 1.67953, batch accuracy: 0.54767
Time: 2018-07-15 02:47:10
TRAINING STATS: batch 32/486 in epoch 513,   batch loss: 1.65443, batch accuracy: 0.54600
Time: 2018-07-15 02:47:15
TRAINING STATS: batch 82/486 in epoch 513,   batch loss: 1.69560, batch accuracy: 0.53867
Time: 2018-07-15 02:47:19
TRAINING STATS: batch 132/486 in epoch 513,  batch loss: 1.64679, batch accuracy: 0.56650
Time: 2018-07-15 02:47:22
TRAINING STATS: batch 182/486 in epoch 513,  batch loss: 1.73304, batch accuracy: 0.52483
Time: 2018-07-15 02:47:27
TRAINING STATS: batch 232/486 in epoch 513,  batch loss: 1.68277, batch accuracy: 0.54650
Time: 2018-07-15 02:47:31
TRAINING STATS: batch 282/486 in epoch 513,  batch loss: 1.62183, batch accuracy: 0.55383
Time: 2018-07-15 02:47:35
TRAINING STATS: batch 332/486 in epoch 513,  batch loss: 1.70135, batch accuracy: 0.53883
Time: 2018-07-15 02:47:39
TRAINING STATS: batch 382/486 in epoch 513,  batch loss: 1.69356, batch accuracy: 0.54200
Time: 2018-07-15 02:47:43
TRAINING STATS: batch 432/486 in epoch 513,  batch loss: 1.60313, batch accuracy: 0.57100
Time: 2018-07-15 02:47:47
TRAINING STATS: batch 482/486 in epoch 513,  batch loss: 1.65260, batch accuracy: 0.55883
Time: 2018-07-15 02:47:51
TRAINING STATS: batch 46/486 in epoch 514,   batch loss: 1.63877, batch accuracy: 0.56183
Time: 2018-07-15 02:47:55
TRAINING STATS: batch 96/486 in epoch 514,   batch loss: 1.69388, batch accuracy: 0.53800
Time: 2018-07-15 02:47:58
TRAINING STATS: batch 146/486 in epoch 514,  batch loss: 1.71590, batch accuracy: 0.53400
Time: 2018-07-15 02:48:03
TRAINING STATS: batch 196/486 in epoch 514,  batch loss: 1.72612, batch accuracy: 0.53017
Time: 2018-07-15 02:48:07
TRAINING STATS: batch 246/486 in epoch 514,  batch loss: 1.61465, batch accuracy: 0.56350
Time: 2018-07-15 02:48:11
TRAINING STATS: batch 296/486 in epoch 514,  batch loss: 1.63228, batch accuracy: 0.55433
Time: 2018-07-15 02:48:15
TRAINING STATS: batch 346/486 in epoch 514,  batch loss: 1.59216, batch accuracy: 0.57717
Time: 2018-07-15 02:48:19
TRAINING STATS: batch 396/486 in epoch 514,  batch loss: 1.64457, batch accuracy: 0.56350
Time: 2018-07-15 02:48:23
TRAINING STATS: batch 446/486 in epoch 514,  batch loss: 1.67954, batch accuracy: 0.54767
Time: 2018-07-15 02:48:27
TRAINING STATS: batch 10/486 in epoch 515,   batch loss: 1.69569, batch accuracy: 0.54183
Time: 2018-07-15 02:48:31
TRAINING STATS: batch 60/486 in epoch 515,   batch loss: 1.66033, batch accuracy: 0.55500
Time: 2018-07-15 02:48:35
TRAINING STATS: batch 110/486 in epoch 515,  batch loss: 1.71536, batch accuracy: 0.54883
Time: 2018-07-15 02:48:40
TRAINING STATS: batch 160/486 in epoch 515,  batch loss: 1.63263, batch accuracy: 0.55533
Time: 2018-07-15 02:48:43
TRAINING STATS: batch 210/486 in epoch 515,  batch loss: 1.61513, batch accuracy: 0.55967
Time: 2018-07-15 02:48:47
TRAINING STATS: batch 260/486 in epoch 515,  batch loss: 1.70919, batch accuracy: 0.52783
Time: 2018-07-15 02:48:52
TRAINING STATS: batch 310/486 in epoch 515,  batch loss: 1.66791, batch accuracy: 0.55267
Time: 2018-07-15 02:48:55
TRAINING STATS: batch 360/486 in epoch 515,  batch loss: 1.69588, batch accuracy: 0.53683
Time: 2018-07-15 02:48:59
TRAINING STATS: batch 410/486 in epoch 515,  batch loss: 1.62266, batch accuracy: 0.57067
Time: 2018-07-15 02:49:04
TRAINING STATS: batch 460/486 in epoch 515,  batch loss: 1.79041, batch accuracy: 0.50917
Time: 2018-07-15 02:49:07
TRAINING STATS: batch 24/486 in epoch 516,   batch loss: 1.73842, batch accuracy: 0.53283
Time: 2018-07-15 02:49:11
TRAINING STATS: batch 74/486 in epoch 516,   batch loss: 1.68329, batch accuracy: 0.54317
Time: 2018-07-15 02:49:16
TRAINING STATS: batch 124/486 in epoch 516,  batch loss: 1.70231, batch accuracy: 0.54083
Time: 2018-07-15 02:49:20
TRAINING STATS: batch 174/486 in epoch 516,  batch loss: 1.75144, batch accuracy: 0.52467
Time: 2018-07-15 02:49:23
TRAINING STATS: batch 224/486 in epoch 516,  batch loss: 1.72076, batch accuracy: 0.54133
Time: 2018-07-15 02:49:28
TRAINING STATS: batch 274/486 in epoch 516,  batch loss: 1.67295, batch accuracy: 0.54033
Time: 2018-07-15 02:49:32
TRAINING STATS: batch 324/486 in epoch 516,  batch loss: 1.69502, batch accuracy: 0.53883
Time: 2018-07-15 02:49:35
TRAINING STATS: batch 374/486 in epoch 516,  batch loss: 1.71496, batch accuracy: 0.54200
Time: 2018-07-15 02:49:40
TRAINING STATS: batch 424/486 in epoch 516,  batch loss: 1.60753, batch accuracy: 0.56317
Time: 2018-07-15 02:49:44
TRAINING STATS: batch 474/486 in epoch 516,  batch loss: 1.67540, batch accuracy: 0.54117
Time: 2018-07-15 02:49:47
TRAINING STATS: batch 38/486 in epoch 517,   batch loss: 1.69254, batch accuracy: 0.54350
Time: 2018-07-15 02:49:52
TRAINING STATS: batch 88/486 in epoch 517,   batch loss: 1.70505, batch accuracy: 0.53567
Time: 2018-07-15 02:49:56
TRAINING STATS: batch 138/486 in epoch 517,  batch loss: 1.71289, batch accuracy: 0.53333
Time: 2018-07-15 02:49:59
TRAINING STATS: batch 188/486 in epoch 517,  batch loss: 1.64692, batch accuracy: 0.55633
Time: 2018-07-15 02:50:04
TRAINING STATS: batch 238/486 in epoch 517,  batch loss: 1.65766, batch accuracy: 0.55500
Time: 2018-07-15 02:50:08
TRAINING STATS: batch 288/486 in epoch 517,  batch loss: 1.69318, batch accuracy: 0.53233
Time: 2018-07-15 02:50:11
TRAINING STATS: batch 338/486 in epoch 517,  batch loss: 1.67543, batch accuracy: 0.54567
Time: 2018-07-15 02:50:16
TRAINING STATS: batch 388/486 in epoch 517,  batch loss: 1.63124, batch accuracy: 0.56183
Time: 2018-07-15 02:50:20
TRAINING STATS: batch 438/486 in epoch 517,  batch loss: 1.68357, batch accuracy: 0.54383
Time: 2018-07-15 02:50:23
TRAINING STATS: batch 2/486 in epoch 518,    batch loss: 1.70941, batch accuracy: 0.53583
Time: 2018-07-15 02:50:28
TRAINING STATS: batch 52/486 in epoch 518,   batch loss: 1.72371, batch accuracy: 0.52850
Time: 2018-07-15 02:50:32
TRAINING STATS: batch 102/486 in epoch 518,  batch loss: 1.69261, batch accuracy: 0.55383
Time: 2018-07-15 02:50:35
TRAINING STATS: batch 152/486 in epoch 518,  batch loss: 1.63805, batch accuracy: 0.55417
Time: 2018-07-15 02:50:40
TRAINING STATS: batch 202/486 in epoch 518,  batch loss: 1.67479, batch accuracy: 0.54867
Time: 2018-07-15 02:50:44
TRAINING STATS: batch 252/486 in epoch 518,  batch loss: 1.62965, batch accuracy: 0.56617
Time: 2018-07-15 02:50:47
TRAINING STATS: batch 302/486 in epoch 518,  batch loss: 1.61658, batch accuracy: 0.55717
Time: 2018-07-15 02:50:52
TRAINING STATS: batch 352/486 in epoch 518,  batch loss: 1.65034, batch accuracy: 0.55350
Time: 2018-07-15 02:50:56
TRAINING STATS: batch 402/486 in epoch 518,  batch loss: 1.54615, batch accuracy: 0.58633
Time: 2018-07-15 02:51:00
TRAINING STATS: batch 452/486 in epoch 518,  batch loss: 1.65302, batch accuracy: 0.54867
Time: 2018-07-15 02:51:04
TRAINING STATS: batch 16/486 in epoch 519,   batch loss: 1.63765, batch accuracy: 0.55650
Time: 2018-07-15 02:51:08
TRAINING STATS: batch 66/486 in epoch 519,   batch loss: 1.65662, batch accuracy: 0.55383
Time: 2018-07-15 02:51:12
TRAINING STATS: batch 116/486 in epoch 519,  batch loss: 1.65062, batch accuracy: 0.55933
Time: 2018-07-15 02:51:16
TRAINING STATS: batch 166/486 in epoch 519,  batch loss: 1.56409, batch accuracy: 0.57517
Time: 2018-07-15 02:51:20
TRAINING STATS: batch 216/486 in epoch 519,  batch loss: 1.68742, batch accuracy: 0.54800
Time: 2018-07-15 02:51:24
TRAINING STATS: batch 266/486 in epoch 519,  batch loss: 1.66402, batch accuracy: 0.54650
Time: 2018-07-15 02:51:28
TRAINING STATS: batch 316/486 in epoch 519,  batch loss: 1.65436, batch accuracy: 0.55617
Time: 2018-07-15 02:51:32
TRAINING STATS: batch 366/486 in epoch 519,  batch loss: 1.73025, batch accuracy: 0.52533
Time: 2018-07-15 02:51:36
TRAINING STATS: batch 416/486 in epoch 519,  batch loss: 1.68700, batch accuracy: 0.54450
Time: 2018-07-15 02:51:40
TRAINING STATS: batch 466/486 in epoch 519,  batch loss: 1.55847, batch accuracy: 0.57733
Time: 2018-07-15 02:51:44
TRAINING STATS: batch 30/486 in epoch 520,   batch loss: 1.55497, batch accuracy: 0.57250
Time: 2018-07-15 02:51:48
TRAINING STATS: batch 80/486 in epoch 520,   batch loss: 1.68356, batch accuracy: 0.53350
Time: 2018-07-15 02:51:53
TRAINING STATS: batch 130/486 in epoch 520,  batch loss: 1.65100, batch accuracy: 0.55917
Time: 2018-07-15 02:51:56
TRAINING STATS: batch 180/486 in epoch 520,  batch loss: 1.71248, batch accuracy: 0.54200
Time: 2018-07-15 02:52:00
TRAINING STATS: batch 230/486 in epoch 520,  batch loss: 1.67991, batch accuracy: 0.53567
Time: 2018-07-15 02:52:05
TRAINING STATS: batch 280/486 in epoch 520,  batch loss: 1.64145, batch accuracy: 0.55450
Time: 2018-07-15 02:52:08
TRAINING STATS: batch 330/486 in epoch 520,  batch loss: 1.64198, batch accuracy: 0.54717
Time: 2018-07-15 02:52:12
TRAINING STATS: batch 380/486 in epoch 520,  batch loss: 1.94036, batch accuracy: 0.48350
Time: 2018-07-15 02:52:17
TRAINING STATS: batch 430/486 in epoch 520,  batch loss: 1.80507, batch accuracy: 0.51633
Time: 2018-07-15 02:52:20
TRAINING STATS: batch 480/486 in epoch 520,  batch loss: 1.89469, batch accuracy: 0.49300
Time: 2018-07-15 02:52:24
TRAINING STATS: batch 44/486 in epoch 521,   batch loss: 1.79193, batch accuracy: 0.52050
Time: 2018-07-15 02:52:29
TRAINING STATS: batch 94/486 in epoch 521,   batch loss: 1.83518, batch accuracy: 0.51200
Time: 2018-07-15 02:52:32
TRAINING STATS: batch 144/486 in epoch 521,  batch loss: 1.85025, batch accuracy: 0.50383
Time: 2018-07-15 02:52:36
TRAINING STATS: batch 194/486 in epoch 521,  batch loss: 1.83420, batch accuracy: 0.50083
Time: 2018-07-15 02:52:41
TRAINING STATS: batch 244/486 in epoch 521,  batch loss: 1.73712, batch accuracy: 0.53750
Time: 2018-07-15 02:52:44
TRAINING STATS: batch 294/486 in epoch 521,  batch loss: 1.66861, batch accuracy: 0.55217
Time: 2018-07-15 02:52:48
TRAINING STATS: batch 344/486 in epoch 521,  batch loss: 1.72231, batch accuracy: 0.54067
Time: 2018-07-15 02:52:53
TRAINING STATS: batch 394/486 in epoch 521,  batch loss: 1.70021, batch accuracy: 0.54450
Time: 2018-07-15 02:52:56
TRAINING STATS: batch 444/486 in epoch 521,  batch loss: 1.67256, batch accuracy: 0.54933
Time: 2018-07-15 02:53:00
TRAINING STATS: batch 8/486 in epoch 522,    batch loss: 1.71650, batch accuracy: 0.53750
Time: 2018-07-15 02:53:05
TRAINING STATS: batch 58/486 in epoch 522,   batch loss: 1.68343, batch accuracy: 0.55233
Time: 2018-07-15 02:53:08
TRAINING STATS: batch 108/486 in epoch 522,  batch loss: 1.76728, batch accuracy: 0.52417
Time: 2018-07-15 02:53:12
TRAINING STATS: batch 158/486 in epoch 522,  batch loss: 1.76519, batch accuracy: 0.53050
Time: 2018-07-15 02:53:17
TRAINING STATS: batch 208/486 in epoch 522,  batch loss: 1.72056, batch accuracy: 0.53867
Time: 2018-07-15 02:53:20
TRAINING STATS: batch 258/486 in epoch 522,  batch loss: 1.64305, batch accuracy: 0.55617
Time: 2018-07-15 02:53:24
TRAINING STATS: batch 308/486 in epoch 522,  batch loss: 1.69541, batch accuracy: 0.54867
Time: 2018-07-15 02:53:29
TRAINING STATS: batch 358/486 in epoch 522,  batch loss: 1.70204, batch accuracy: 0.53900
Time: 2018-07-15 02:53:33
TRAINING STATS: batch 408/486 in epoch 522,  batch loss: 1.71596, batch accuracy: 0.53850
Time: 2018-07-15 02:53:36
TRAINING STATS: batch 458/486 in epoch 522,  batch loss: 1.69665, batch accuracy: 0.54300
Time: 2018-07-15 02:53:41
TRAINING STATS: batch 22/486 in epoch 523,   batch loss: 1.73464, batch accuracy: 0.54250
Time: 2018-07-15 02:53:45
TRAINING STATS: batch 72/486 in epoch 523,   batch loss: 1.70782, batch accuracy: 0.52833
Time: 2018-07-15 02:53:48
TRAINING STATS: batch 122/486 in epoch 523,  batch loss: 1.61712, batch accuracy: 0.56600
Time: 2018-07-15 02:53:53
TRAINING STATS: batch 172/486 in epoch 523,  batch loss: 1.72490, batch accuracy: 0.53033
Time: 2018-07-15 02:53:57
TRAINING STATS: batch 222/486 in epoch 523,  batch loss: 1.66267, batch accuracy: 0.54467
Time: 2018-07-15 02:54:00
TRAINING STATS: batch 272/486 in epoch 523,  batch loss: 1.70151, batch accuracy: 0.53600
Time: 2018-07-15 02:54:05
TRAINING STATS: batch 322/486 in epoch 523,  batch loss: 1.66389, batch accuracy: 0.54617
Time: 2018-07-15 02:54:09
TRAINING STATS: batch 372/486 in epoch 523,  batch loss: 1.64275, batch accuracy: 0.55833
Time: 2018-07-15 02:54:12
TRAINING STATS: batch 422/486 in epoch 523,  batch loss: 1.64103, batch accuracy: 0.56067
Time: 2018-07-15 02:54:17
TRAINING STATS: batch 472/486 in epoch 523,  batch loss: 1.74121, batch accuracy: 0.53183
Time: 2018-07-15 02:54:21
TRAINING STATS: batch 36/486 in epoch 524,   batch loss: 1.71462, batch accuracy: 0.54333
Time: 2018-07-15 02:54:24
TRAINING STATS: batch 86/486 in epoch 524,   batch loss: 1.66398, batch accuracy: 0.55133
Time: 2018-07-15 02:54:29
TRAINING STATS: batch 136/486 in epoch 524,  batch loss: 1.73170, batch accuracy: 0.52317
Time: 2018-07-15 02:54:33
TRAINING STATS: batch 186/486 in epoch 524,  batch loss: 1.66792, batch accuracy: 0.54450
Time: 2018-07-15 02:54:37
TRAINING STATS: batch 236/486 in epoch 524,  batch loss: 1.70391, batch accuracy: 0.53683
Time: 2018-07-15 02:54:41
TRAINING STATS: batch 286/486 in epoch 524,  batch loss: 1.69460, batch accuracy: 0.54100
Time: 2018-07-15 02:54:45
TRAINING STATS: batch 336/486 in epoch 524,  batch loss: 1.65418, batch accuracy: 0.55450
Time: 2018-07-15 02:54:49
TRAINING STATS: batch 386/486 in epoch 524,  batch loss: 1.70643, batch accuracy: 0.53983
Time: 2018-07-15 02:54:53
TRAINING STATS: batch 436/486 in epoch 524,  batch loss: 1.70103, batch accuracy: 0.54383
Time: 2018-07-15 02:54:57
TRAINING STATS: batch 0/486 in epoch 525,    batch loss: 1.67205, batch accuracy: 0.54700
Time: 2018-07-15 02:55:01
TRAINING STATS: batch 50/486 in epoch 525,   batch loss: 1.63950, batch accuracy: 0.56633
Time: 2018-07-15 02:55:05
TRAINING STATS: batch 100/486 in epoch 525,  batch loss: 1.73644, batch accuracy: 0.53083
Time: 2018-07-15 02:55:09
TRAINING STATS: batch 150/486 in epoch 525,  batch loss: 1.64280, batch accuracy: 0.56317
Time: 2018-07-15 02:55:13
TRAINING STATS: batch 200/486 in epoch 525,  batch loss: 1.55225, batch accuracy: 0.58083
Time: 2018-07-15 02:55:17
TRAINING STATS: batch 250/486 in epoch 525,  batch loss: 1.72576, batch accuracy: 0.52183
Time: 2018-07-15 02:55:21
TRAINING STATS: batch 300/486 in epoch 525,  batch loss: 1.71273, batch accuracy: 0.52533
Time: 2018-07-15 02:55:25
TRAINING STATS: batch 350/486 in epoch 525,  batch loss: 1.66840, batch accuracy: 0.54750
Time: 2018-07-15 02:55:29
TRAINING STATS: batch 400/486 in epoch 525,  batch loss: 1.55634, batch accuracy: 0.57917
Time: 2018-07-15 02:55:33
TRAINING STATS: batch 450/486 in epoch 525,  batch loss: 1.73533, batch accuracy: 0.52500
Time: 2018-07-15 02:55:37
TRAINING STATS: batch 14/486 in epoch 526,   batch loss: 1.59097, batch accuracy: 0.57767
Time: 2018-07-15 02:55:42
TRAINING STATS: batch 64/486 in epoch 526,   batch loss: 1.76808, batch accuracy: 0.51883
Time: 2018-07-15 02:55:45
TRAINING STATS: batch 114/486 in epoch 526,  batch loss: 1.71176, batch accuracy: 0.53750
Time: 2018-07-15 02:55:49
TRAINING STATS: batch 164/486 in epoch 526,  batch loss: 1.60584, batch accuracy: 0.56267
Time: 2018-07-15 02:55:54
TRAINING STATS: batch 214/486 in epoch 526,  batch loss: 1.66944, batch accuracy: 0.55450
Time: 2018-07-15 02:55:57
TRAINING STATS: batch 264/486 in epoch 526,  batch loss: 1.70198, batch accuracy: 0.52900
Time: 2018-07-15 02:56:01
TRAINING STATS: batch 314/486 in epoch 526,  batch loss: 1.71917, batch accuracy: 0.53367
Time: 2018-07-15 02:56:06
TRAINING STATS: batch 364/486 in epoch 526,  batch loss: 1.65139, batch accuracy: 0.55133
Time: 2018-07-15 02:56:09
TRAINING STATS: batch 414/486 in epoch 526,  batch loss: 1.61818, batch accuracy: 0.55900
Time: 2018-07-15 02:56:13
TRAINING STATS: batch 464/486 in epoch 526,  batch loss: 1.62478, batch accuracy: 0.55917
Time: 2018-07-15 02:56:18
TRAINING STATS: batch 28/486 in epoch 527,   batch loss: 1.63254, batch accuracy: 0.55367
Time: 2018-07-15 02:56:21
TRAINING STATS: batch 78/486 in epoch 527,   batch loss: 1.68342, batch accuracy: 0.54783
Time: 2018-07-15 02:56:25
TRAINING STATS: batch 128/486 in epoch 527,  batch loss: 1.65832, batch accuracy: 0.54967
Time: 2018-07-15 02:56:30
TRAINING STATS: batch 178/486 in epoch 527,  batch loss: 1.56425, batch accuracy: 0.57317
Time: 2018-07-15 02:56:33
TRAINING STATS: batch 228/486 in epoch 527,  batch loss: 1.62484, batch accuracy: 0.55850
Time: 2018-07-15 02:56:37
TRAINING STATS: batch 278/486 in epoch 527,  batch loss: 1.61823, batch accuracy: 0.56467
Time: 2018-07-15 02:56:42
TRAINING STATS: batch 328/486 in epoch 527,  batch loss: 1.63018, batch accuracy: 0.55733
Time: 2018-07-15 02:56:45
TRAINING STATS: batch 378/486 in epoch 527,  batch loss: 1.65620, batch accuracy: 0.55300
Time: 2018-07-15 02:56:49
TRAINING STATS: batch 428/486 in epoch 527,  batch loss: 1.72736, batch accuracy: 0.53117
Time: 2018-07-15 02:56:54
TRAINING STATS: batch 478/486 in epoch 527,  batch loss: 1.67549, batch accuracy: 0.54767
Time: 2018-07-15 02:56:57
TRAINING STATS: batch 42/486 in epoch 528,   batch loss: 1.60527, batch accuracy: 0.56383
Time: 2018-07-15 02:57:01
TRAINING STATS: batch 92/486 in epoch 528,   batch loss: 1.68896, batch accuracy: 0.54233
Time: 2018-07-15 02:57:06
TRAINING STATS: batch 142/486 in epoch 528,  batch loss: 1.64354, batch accuracy: 0.55500
Time: 2018-07-15 02:57:09
TRAINING STATS: batch 192/486 in epoch 528,  batch loss: 1.65976, batch accuracy: 0.55017
Time: 2018-07-15 02:57:13
TRAINING STATS: batch 242/486 in epoch 528,  batch loss: 1.63739, batch accuracy: 0.55867
Time: 2018-07-15 02:57:18
TRAINING STATS: batch 292/486 in epoch 528,  batch loss: 1.66292, batch accuracy: 0.55100
Time: 2018-07-15 02:57:22
TRAINING STATS: batch 342/486 in epoch 528,  batch loss: 1.65412, batch accuracy: 0.54800
Time: 2018-07-15 02:57:25
TRAINING STATS: batch 392/486 in epoch 528,  batch loss: 1.58115, batch accuracy: 0.57400
Time: 2018-07-15 02:57:30
TRAINING STATS: batch 442/486 in epoch 528,  batch loss: 1.57596, batch accuracy: 0.57250
Time: 2018-07-15 02:57:34
TRAINING STATS: batch 6/486 in epoch 529,    batch loss: 1.70063, batch accuracy: 0.53950
Time: 2018-07-15 02:57:37
TRAINING STATS: batch 56/486 in epoch 529,   batch loss: 1.62739, batch accuracy: 0.55650
Time: 2018-07-15 02:57:42
TRAINING STATS: batch 106/486 in epoch 529,  batch loss: 1.72253, batch accuracy: 0.53467
Time: 2018-07-15 02:57:46
TRAINING STATS: batch 156/486 in epoch 529,  batch loss: 1.69393, batch accuracy: 0.53383
Time: 2018-07-15 02:57:49
TRAINING STATS: batch 206/486 in epoch 529,  batch loss: 1.77216, batch accuracy: 0.52267
Time: 2018-07-15 02:57:54
TRAINING STATS: batch 256/486 in epoch 529,  batch loss: 1.60092, batch accuracy: 0.56700
Time: 2018-07-15 02:57:58
TRAINING STATS: batch 306/486 in epoch 529,  batch loss: 1.66148, batch accuracy: 0.54567
Time: 2018-07-15 02:58:01
TRAINING STATS: batch 356/486 in epoch 529,  batch loss: 1.71010, batch accuracy: 0.53633
Time: 2018-07-15 02:58:06
TRAINING STATS: batch 406/486 in epoch 529,  batch loss: 1.73671, batch accuracy: 0.52783
Time: 2018-07-15 02:58:10
TRAINING STATS: batch 456/486 in epoch 529,  batch loss: 1.55656, batch accuracy: 0.58683
Time: 2018-07-15 02:58:13
TRAINING STATS: batch 20/486 in epoch 530,   batch loss: 1.76307, batch accuracy: 0.52450
Time: 2018-07-15 02:58:18
TRAINING STATS: batch 70/486 in epoch 530,   batch loss: 1.63169, batch accuracy: 0.56500
Time: 2018-07-15 02:58:22
TRAINING STATS: batch 120/486 in epoch 530,  batch loss: 1.68036, batch accuracy: 0.55183
Time: 2018-07-15 02:58:25
TRAINING STATS: batch 170/486 in epoch 530,  batch loss: 1.69413, batch accuracy: 0.55117
Time: 2018-07-15 02:58:30
TRAINING STATS: batch 220/486 in epoch 530,  batch loss: 1.62893, batch accuracy: 0.56417
Time: 2018-07-15 02:58:34
TRAINING STATS: batch 270/486 in epoch 530,  batch loss: 1.72821, batch accuracy: 0.53017
Time: 2018-07-15 02:58:38
TRAINING STATS: batch 320/486 in epoch 530,  batch loss: 1.65279, batch accuracy: 0.55517
Time: 2018-07-15 02:58:42
TRAINING STATS: batch 370/486 in epoch 530,  batch loss: 1.72889, batch accuracy: 0.54217
Time: 2018-07-15 02:58:46
TRAINING STATS: batch 420/486 in epoch 530,  batch loss: 1.74145, batch accuracy: 0.53117
Time: 2018-07-15 02:58:50
TRAINING STATS: batch 470/486 in epoch 530,  batch loss: 1.81468, batch accuracy: 0.50050
Time: 2018-07-15 02:58:54
TRAINING STATS: batch 34/486 in epoch 531,   batch loss: 1.74292, batch accuracy: 0.53100
Time: 2018-07-15 02:58:58
TRAINING STATS: batch 84/486 in epoch 531,   batch loss: 1.71627, batch accuracy: 0.52500
Time: 2018-07-15 02:59:02
TRAINING STATS: batch 134/486 in epoch 531,  batch loss: 1.73162, batch accuracy: 0.52967
Time: 2018-07-15 02:59:06
TRAINING STATS: batch 184/486 in epoch 531,  batch loss: 1.73425, batch accuracy: 0.52917
Time: 2018-07-15 02:59:10
TRAINING STATS: batch 234/486 in epoch 531,  batch loss: 1.78202, batch accuracy: 0.52833
Time: 2018-07-15 02:59:14
TRAINING STATS: batch 284/486 in epoch 531,  batch loss: 1.75749, batch accuracy: 0.52667
Time: 2018-07-15 02:59:18
TRAINING STATS: batch 334/486 in epoch 531,  batch loss: 1.69659, batch accuracy: 0.54167
Time: 2018-07-15 02:59:22
TRAINING STATS: batch 384/486 in epoch 531,  batch loss: 1.68629, batch accuracy: 0.54950
Time: 2018-07-15 02:59:26
TRAINING STATS: batch 434/486 in epoch 531,  batch loss: 1.75695, batch accuracy: 0.52333
Time: 2018-07-15 02:59:30
TRAINING STATS: batch 484/486 in epoch 531,  batch loss: 1.72991, batch accuracy: 0.52400
Time: 2018-07-15 02:59:34
TRAINING STATS: batch 48/486 in epoch 532,   batch loss: 1.70902, batch accuracy: 0.54050
Time: 2018-07-15 02:59:38
TRAINING STATS: batch 98/486 in epoch 532,   batch loss: 1.65799, batch accuracy: 0.55467
Time: 2018-07-15 02:59:43
TRAINING STATS: batch 148/486 in epoch 532,  batch loss: 1.73088, batch accuracy: 0.53517
Time: 2018-07-15 02:59:46
TRAINING STATS: batch 198/486 in epoch 532,  batch loss: 1.69662, batch accuracy: 0.54233
Time: 2018-07-15 02:59:50
TRAINING STATS: batch 248/486 in epoch 532,  batch loss: 1.73156, batch accuracy: 0.53750
Time: 2018-07-15 02:59:55
TRAINING STATS: batch 298/486 in epoch 532,  batch loss: 1.72002, batch accuracy: 0.53750
Time: 2018-07-15 02:59:58
TRAINING STATS: batch 348/486 in epoch 532,  batch loss: 1.70731, batch accuracy: 0.54050
Time: 2018-07-15 03:00:02
TRAINING STATS: batch 398/486 in epoch 532,  batch loss: 1.72008, batch accuracy: 0.53283
Time: 2018-07-15 03:00:07
TRAINING STATS: batch 448/486 in epoch 532,  batch loss: 1.71554, batch accuracy: 0.54200
Time: 2018-07-15 03:00:10
TRAINING STATS: batch 12/486 in epoch 533,   batch loss: 1.74666, batch accuracy: 0.51367
Time: 2018-07-15 03:00:14
TRAINING STATS: batch 62/486 in epoch 533,   batch loss: 1.77013, batch accuracy: 0.51783
Time: 2018-07-15 03:00:19
TRAINING STATS: batch 112/486 in epoch 533,  batch loss: 1.68641, batch accuracy: 0.54550
Time: 2018-07-15 03:00:22
TRAINING STATS: batch 162/486 in epoch 533,  batch loss: 1.71354, batch accuracy: 0.54050
Time: 2018-07-15 03:00:26
TRAINING STATS: batch 212/486 in epoch 533,  batch loss: 1.62213, batch accuracy: 0.56167
Time: 2018-07-15 03:00:31
TRAINING STATS: batch 262/486 in epoch 533,  batch loss: 1.74842, batch accuracy: 0.52517
Time: 2018-07-15 03:00:35
TRAINING STATS: batch 312/486 in epoch 533,  batch loss: 1.70239, batch accuracy: 0.53033
Time: 2018-07-15 03:00:38
TRAINING STATS: batch 362/486 in epoch 533,  batch loss: 1.70641, batch accuracy: 0.53800
Time: 2018-07-15 03:00:43
TRAINING STATS: batch 412/486 in epoch 533,  batch loss: 1.65409, batch accuracy: 0.56267
Time: 2018-07-15 03:00:47
TRAINING STATS: batch 462/486 in epoch 533,  batch loss: 1.71505, batch accuracy: 0.53633
Time: 2018-07-15 03:00:50
TRAINING STATS: batch 26/486 in epoch 534,   batch loss: 1.73466, batch accuracy: 0.53200
Time: 2018-07-15 03:00:55
TRAINING STATS: batch 76/486 in epoch 534,   batch loss: 1.75546, batch accuracy: 0.52667
Time: 2018-07-15 03:00:59
TRAINING STATS: batch 126/486 in epoch 534,  batch loss: 1.76219, batch accuracy: 0.52400
Time: 2018-07-15 03:01:02
TRAINING STATS: batch 176/486 in epoch 534,  batch loss: 1.61779, batch accuracy: 0.56967
Time: 2018-07-15 03:01:07
TRAINING STATS: batch 226/486 in epoch 534,  batch loss: 1.68301, batch accuracy: 0.54367
Time: 2018-07-15 03:01:11
TRAINING STATS: batch 276/486 in epoch 534,  batch loss: 1.69093, batch accuracy: 0.54433
Time: 2018-07-15 03:01:14
TRAINING STATS: batch 326/486 in epoch 534,  batch loss: 1.76263, batch accuracy: 0.51783
Time: 2018-07-15 03:01:19
TRAINING STATS: batch 376/486 in epoch 534,  batch loss: 1.72324, batch accuracy: 0.53767
Time: 2018-07-15 03:01:23
TRAINING STATS: batch 426/486 in epoch 534,  batch loss: 1.69410, batch accuracy: 0.53600
Time: 2018-07-15 03:01:26
TRAINING STATS: batch 476/486 in epoch 534,  batch loss: 1.63619, batch accuracy: 0.56150
Time: 2018-07-15 03:01:31
TRAINING STATS: batch 40/486 in epoch 535,   batch loss: 1.65606, batch accuracy: 0.55100
Time: 2018-07-15 03:01:35
TRAINING STATS: batch 90/486 in epoch 535,   batch loss: 1.71978, batch accuracy: 0.53950
Time: 2018-07-15 03:01:39
TRAINING STATS: batch 140/486 in epoch 535,  batch loss: 1.63903, batch accuracy: 0.55050
Time: 2018-07-15 03:01:43
TRAINING STATS: batch 190/486 in epoch 535,  batch loss: 1.67202, batch accuracy: 0.55150
Time: 2018-07-15 03:01:47
TRAINING STATS: batch 240/486 in epoch 535,  batch loss: 1.68196, batch accuracy: 0.54150
Time: 2018-07-15 03:01:51
TRAINING STATS: batch 290/486 in epoch 535,  batch loss: 1.71678, batch accuracy: 0.53150
Time: 2018-07-15 03:01:55
TRAINING STATS: batch 340/486 in epoch 535,  batch loss: 1.76803, batch accuracy: 0.52350
Time: 2018-07-15 03:01:59
TRAINING STATS: batch 390/486 in epoch 535,  batch loss: 1.64542, batch accuracy: 0.55400
Time: 2018-07-15 03:02:03
TRAINING STATS: batch 440/486 in epoch 535,  batch loss: 1.70524, batch accuracy: 0.54000
Time: 2018-07-15 03:02:07
TRAINING STATS: batch 4/486 in epoch 536,    batch loss: 1.66728, batch accuracy: 0.55233
Time: 2018-07-15 03:02:11
TRAINING STATS: batch 54/486 in epoch 536,   batch loss: 1.70365, batch accuracy: 0.53517
Time: 2018-07-15 03:02:15
TRAINING STATS: batch 104/486 in epoch 536,  batch loss: 1.72140, batch accuracy: 0.54033
Time: 2018-07-15 03:02:19
TRAINING STATS: batch 154/486 in epoch 536,  batch loss: 1.66259, batch accuracy: 0.55817
Time: 2018-07-15 03:02:23
TRAINING STATS: batch 204/486 in epoch 536,  batch loss: 1.75776, batch accuracy: 0.52983
Time: 2018-07-15 03:02:27
TRAINING STATS: batch 254/486 in epoch 536,  batch loss: 1.62868, batch accuracy: 0.56000
Time: 2018-07-15 03:02:31
TRAINING STATS: batch 304/486 in epoch 536,  batch loss: 1.63938, batch accuracy: 0.55950
Time: 2018-07-15 03:02:35
TRAINING STATS: batch 354/486 in epoch 536,  batch loss: 1.69619, batch accuracy: 0.54267
Time: 2018-07-15 03:02:39
TRAINING STATS: batch 404/486 in epoch 536,  batch loss: 1.67162, batch accuracy: 0.54900
Time: 2018-07-15 03:02:43
TRAINING STATS: batch 454/486 in epoch 536,  batch loss: 1.57039, batch accuracy: 0.57850
Time: 2018-07-15 03:02:47
TRAINING STATS: batch 18/486 in epoch 537,   batch loss: 1.72283, batch accuracy: 0.53483
Time: 2018-07-15 03:02:51
TRAINING STATS: batch 68/486 in epoch 537,   batch loss: 1.54799, batch accuracy: 0.58600
Time: 2018-07-15 03:02:56
TRAINING STATS: batch 118/486 in epoch 537,  batch loss: 1.68924, batch accuracy: 0.54867
Time: 2018-07-15 03:02:59
TRAINING STATS: batch 168/486 in epoch 537,  batch loss: 1.61456, batch accuracy: 0.56950
Time: 2018-07-15 03:03:03
TRAINING STATS: batch 218/486 in epoch 537,  batch loss: 1.67377, batch accuracy: 0.54000
Time: 2018-07-15 03:03:08
TRAINING STATS: batch 268/486 in epoch 537,  batch loss: 1.65075, batch accuracy: 0.55450
Time: 2018-07-15 03:03:11
TRAINING STATS: batch 318/486 in epoch 537,  batch loss: 1.69536, batch accuracy: 0.54433
Time: 2018-07-15 03:03:15
TRAINING STATS: batch 368/486 in epoch 537,  batch loss: 1.71233, batch accuracy: 0.54183
Time: 2018-07-15 03:03:20
TRAINING STATS: batch 418/486 in epoch 537,  batch loss: 1.75495, batch accuracy: 0.52633
Time: 2018-07-15 03:03:23
TRAINING STATS: batch 468/486 in epoch 537,  batch loss: 1.70402, batch accuracy: 0.54500
Time: 2018-07-15 03:03:27
TRAINING STATS: batch 32/486 in epoch 538,   batch loss: 1.65870, batch accuracy: 0.54400
Time: 2018-07-15 03:03:32
TRAINING STATS: batch 82/486 in epoch 538,   batch loss: 1.72921, batch accuracy: 0.53650
Time: 2018-07-15 03:03:35
TRAINING STATS: batch 132/486 in epoch 538,  batch loss: 1.69444, batch accuracy: 0.56067
Time: 2018-07-15 03:03:39
TRAINING STATS: batch 182/486 in epoch 538,  batch loss: 1.73633, batch accuracy: 0.53283
Time: 2018-07-15 03:03:44
TRAINING STATS: batch 232/486 in epoch 538,  batch loss: 1.73617, batch accuracy: 0.52717
Time: 2018-07-15 03:03:47
TRAINING STATS: batch 282/486 in epoch 538,  batch loss: 1.64085, batch accuracy: 0.55967
Time: 2018-07-15 03:03:51
TRAINING STATS: batch 332/486 in epoch 538,  batch loss: 1.72196, batch accuracy: 0.53433
Time: 2018-07-15 03:03:56
TRAINING STATS: batch 382/486 in epoch 538,  batch loss: 1.71379, batch accuracy: 0.53717
Time: 2018-07-15 03:04:00
TRAINING STATS: batch 432/486 in epoch 538,  batch loss: 1.62757, batch accuracy: 0.56017
Time: 2018-07-15 03:04:03
TRAINING STATS: batch 482/486 in epoch 538,  batch loss: 1.68086, batch accuracy: 0.55167
Time: 2018-07-15 03:04:08
TRAINING STATS: batch 46/486 in epoch 539,   batch loss: 1.65754, batch accuracy: 0.55750
Time: 2018-07-15 03:04:12
TRAINING STATS: batch 96/486 in epoch 539,   batch loss: 1.72161, batch accuracy: 0.53683
Time: 2018-07-15 03:04:15
TRAINING STATS: batch 146/486 in epoch 539,  batch loss: 1.76412, batch accuracy: 0.52733
Time: 2018-07-15 03:04:20
TRAINING STATS: batch 196/486 in epoch 539,  batch loss: 1.74022, batch accuracy: 0.53417
Time: 2018-07-15 03:04:24
TRAINING STATS: batch 246/486 in epoch 539,  batch loss: 1.66788, batch accuracy: 0.54700
Time: 2018-07-15 03:04:27
TRAINING STATS: batch 296/486 in epoch 539,  batch loss: 1.64990, batch accuracy: 0.55083
Time: 2018-07-15 03:04:32
TRAINING STATS: batch 346/486 in epoch 539,  batch loss: 1.61485, batch accuracy: 0.57550
Time: 2018-07-15 03:04:36
TRAINING STATS: batch 396/486 in epoch 539,  batch loss: 1.67963, batch accuracy: 0.54967
Time: 2018-07-15 03:04:39
TRAINING STATS: batch 446/486 in epoch 539,  batch loss: 1.71408, batch accuracy: 0.53833
Time: 2018-07-15 03:04:44
TRAINING STATS: batch 10/486 in epoch 540,   batch loss: 1.72153, batch accuracy: 0.53333
Time: 2018-07-15 03:04:48
TRAINING STATS: batch 60/486 in epoch 540,   batch loss: 1.67501, batch accuracy: 0.55517
Time: 2018-07-15 03:04:51
TRAINING STATS: batch 110/486 in epoch 540,  batch loss: 1.73373, batch accuracy: 0.53717
Time: 2018-07-15 03:04:56
TRAINING STATS: batch 160/486 in epoch 540,  batch loss: 1.66252, batch accuracy: 0.54450
Time: 2018-07-15 03:05:00
TRAINING STATS: batch 210/486 in epoch 540,  batch loss: 1.74975, batch accuracy: 0.53317
Time: 2018-07-15 03:05:04
TRAINING STATS: batch 260/486 in epoch 540,  batch loss: 1.72035, batch accuracy: 0.52850
Time: 2018-07-15 03:05:08
TRAINING STATS: batch 310/486 in epoch 540,  batch loss: 1.69760, batch accuracy: 0.54717
Time: 2018-07-15 03:05:12
TRAINING STATS: batch 360/486 in epoch 540,  batch loss: 1.73236, batch accuracy: 0.53133
Time: 2018-07-15 03:05:15
TRAINING STATS: batch 410/486 in epoch 540,  batch loss: 1.61856, batch accuracy: 0.57350
Time: 2018-07-15 03:05:20
TRAINING STATS: batch 460/486 in epoch 540,  batch loss: 1.80639, batch accuracy: 0.50867
Time: 2018-07-15 03:05:24
TRAINING STATS: batch 24/486 in epoch 541,   batch loss: 1.76361, batch accuracy: 0.52100
Time: 2018-07-15 03:05:27
TRAINING STATS: batch 74/486 in epoch 541,   batch loss: 1.71345, batch accuracy: 0.53900
Time: 2018-07-15 03:05:32
TRAINING STATS: batch 124/486 in epoch 541,  batch loss: 1.70759, batch accuracy: 0.54000
Time: 2018-07-15 03:05:36
TRAINING STATS: batch 174/486 in epoch 541,  batch loss: 1.75769, batch accuracy: 0.52667
Time: 2018-07-15 03:05:40
TRAINING STATS: batch 224/486 in epoch 541,  batch loss: 1.73199, batch accuracy: 0.53683
Time: 2018-07-15 03:05:44
TRAINING STATS: batch 274/486 in epoch 541,  batch loss: 1.69112, batch accuracy: 0.54417
Time: 2018-07-15 03:05:48
TRAINING STATS: batch 324/486 in epoch 541,  batch loss: 1.76324, batch accuracy: 0.53200
Time: 2018-07-15 03:05:52
TRAINING STATS: batch 374/486 in epoch 541,  batch loss: 1.72930, batch accuracy: 0.54450
Time: 2018-07-15 03:05:56
TRAINING STATS: batch 424/486 in epoch 541,  batch loss: 1.64193, batch accuracy: 0.55933
Time: 2018-07-15 03:06:00
TRAINING STATS: batch 474/486 in epoch 541,  batch loss: 1.71076, batch accuracy: 0.54100
Time: 2018-07-15 03:06:04
TRAINING STATS: batch 38/486 in epoch 542,   batch loss: 1.71958, batch accuracy: 0.53983
Time: 2018-07-15 03:06:08
TRAINING STATS: batch 88/486 in epoch 542,   batch loss: 1.75357, batch accuracy: 0.52783
Time: 2018-07-15 03:06:12
TRAINING STATS: batch 138/486 in epoch 542,  batch loss: 1.74088, batch accuracy: 0.53017
Time: 2018-07-15 03:06:16
TRAINING STATS: batch 188/486 in epoch 542,  batch loss: 1.65379, batch accuracy: 0.55667
Time: 2018-07-15 03:06:21
TRAINING STATS: batch 238/486 in epoch 542,  batch loss: 1.66962, batch accuracy: 0.55950
Time: 2018-07-15 03:06:24
TRAINING STATS: batch 288/486 in epoch 542,  batch loss: 1.71507, batch accuracy: 0.53267
Time: 2018-07-15 03:06:28
TRAINING STATS: batch 338/486 in epoch 542,  batch loss: 1.68675, batch accuracy: 0.54467
Time: 2018-07-15 03:06:32
TRAINING STATS: batch 388/486 in epoch 542,  batch loss: 1.67506, batch accuracy: 0.55400
Time: 2018-07-15 03:06:36
TRAINING STATS: batch 438/486 in epoch 542,  batch loss: 1.71925, batch accuracy: 0.53883
Time: 2018-07-15 03:06:40
TRAINING STATS: batch 2/486 in epoch 543,    batch loss: 1.71638, batch accuracy: 0.53450
Time: 2018-07-15 03:06:45
TRAINING STATS: batch 52/486 in epoch 543,   batch loss: 1.76376, batch accuracy: 0.52217
Time: 2018-07-15 03:06:48
TRAINING STATS: batch 102/486 in epoch 543,  batch loss: 1.71974, batch accuracy: 0.54000
Time: 2018-07-15 03:06:52
TRAINING STATS: batch 152/486 in epoch 543,  batch loss: 1.66334, batch accuracy: 0.55800
Time: 2018-07-15 03:06:57
TRAINING STATS: batch 202/486 in epoch 543,  batch loss: 1.70133, batch accuracy: 0.54550
Time: 2018-07-15 03:07:00
TRAINING STATS: batch 252/486 in epoch 543,  batch loss: 1.66212, batch accuracy: 0.55033
Time: 2018-07-15 03:07:04
TRAINING STATS: batch 302/486 in epoch 543,  batch loss: 1.64942, batch accuracy: 0.55067
Time: 2018-07-15 03:07:09
TRAINING STATS: batch 352/486 in epoch 543,  batch loss: 1.66431, batch accuracy: 0.55483
Time: 2018-07-15 03:07:12
TRAINING STATS: batch 402/486 in epoch 543,  batch loss: 1.55727, batch accuracy: 0.58650
Time: 2018-07-15 03:07:16
TRAINING STATS: batch 452/486 in epoch 543,  batch loss: 1.67974, batch accuracy: 0.54667
Time: 2018-07-15 03:07:21
TRAINING STATS: batch 16/486 in epoch 544,   batch loss: 1.65698, batch accuracy: 0.55683
Time: 2018-07-15 03:07:24
TRAINING STATS: batch 66/486 in epoch 544,   batch loss: 1.68397, batch accuracy: 0.55550
Time: 2018-07-15 03:07:28
TRAINING STATS: batch 116/486 in epoch 544,  batch loss: 1.65751, batch accuracy: 0.55533
Time: 2018-07-15 03:07:33
TRAINING STATS: batch 166/486 in epoch 544,  batch loss: 1.59691, batch accuracy: 0.57267
Time: 2018-07-15 03:07:36
TRAINING STATS: batch 216/486 in epoch 544,  batch loss: 1.70195, batch accuracy: 0.54700
Time: 2018-07-15 03:07:40
TRAINING STATS: batch 266/486 in epoch 544,  batch loss: 1.68938, batch accuracy: 0.54333
Time: 2018-07-15 03:07:45
TRAINING STATS: batch 316/486 in epoch 544,  batch loss: 1.69210, batch accuracy: 0.55167
Time: 2018-07-15 03:07:49
TRAINING STATS: batch 366/486 in epoch 544,  batch loss: 1.73297, batch accuracy: 0.53450
Time: 2018-07-15 03:07:52
TRAINING STATS: batch 416/486 in epoch 544,  batch loss: 1.73037, batch accuracy: 0.53883
Time: 2018-07-15 03:07:57
TRAINING STATS: batch 466/486 in epoch 544,  batch loss: 1.55307, batch accuracy: 0.59067
Time: 2018-07-15 03:08:01
TRAINING STATS: batch 30/486 in epoch 545,   batch loss: 1.58323, batch accuracy: 0.57600
Time: 2018-07-15 03:08:04
TRAINING STATS: batch 80/486 in epoch 545,   batch loss: 1.68750, batch accuracy: 0.54367
Time: 2018-07-15 03:08:09
TRAINING STATS: batch 130/486 in epoch 545,  batch loss: 1.68498, batch accuracy: 0.55550
Time: 2018-07-15 03:08:12
TRAINING STATS: batch 180/486 in epoch 545,  batch loss: 1.71945, batch accuracy: 0.54150
Time: 2018-07-15 03:08:16
TRAINING STATS: batch 230/486 in epoch 545,  batch loss: 1.70295, batch accuracy: 0.53817
Time: 2018-07-15 03:08:21
TRAINING STATS: batch 280/486 in epoch 545,  batch loss: 1.67958, batch accuracy: 0.55133
Time: 2018-07-15 03:08:25
TRAINING STATS: batch 330/486 in epoch 545,  batch loss: 1.68293, batch accuracy: 0.54183
Time: 2018-07-15 03:08:28
TRAINING STATS: batch 380/486 in epoch 545,  batch loss: 1.67547, batch accuracy: 0.55317
Time: 2018-07-15 03:08:33
TRAINING STATS: batch 430/486 in epoch 545,  batch loss: 1.61683, batch accuracy: 0.57250
Time: 2018-07-15 03:08:37
TRAINING STATS: batch 480/486 in epoch 545,  batch loss: 1.69425, batch accuracy: 0.54967
Time: 2018-07-15 03:08:40
TRAINING STATS: batch 44/486 in epoch 546,   batch loss: 1.62449, batch accuracy: 0.56850
Time: 2018-07-15 03:08:45
TRAINING STATS: batch 94/486 in epoch 546,   batch loss: 1.73828, batch accuracy: 0.53117
Time: 2018-07-15 03:08:49
TRAINING STATS: batch 144/486 in epoch 546,  batch loss: 1.75431, batch accuracy: 0.52250
Time: 2018-07-15 03:08:52
TRAINING STATS: batch 194/486 in epoch 546,  batch loss: 1.79074, batch accuracy: 0.51367
Time: 2018-07-15 03:08:57
TRAINING STATS: batch 244/486 in epoch 546,  batch loss: 1.76300, batch accuracy: 0.53183
Time: 2018-07-15 03:09:01
TRAINING STATS: batch 294/486 in epoch 546,  batch loss: 1.61580, batch accuracy: 0.56700
Time: 2018-07-15 03:09:05
TRAINING STATS: batch 344/486 in epoch 546,  batch loss: 1.67184, batch accuracy: 0.55150
Time: 2018-07-15 03:09:09
TRAINING STATS: batch 394/486 in epoch 546,  batch loss: 1.64896, batch accuracy: 0.56850
Time: 2018-07-15 03:09:13
TRAINING STATS: batch 444/486 in epoch 546,  batch loss: 1.62929, batch accuracy: 0.56300
Time: 2018-07-15 03:09:17
TRAINING STATS: batch 8/486 in epoch 547,    batch loss: 1.67617, batch accuracy: 0.55983
Time: 2018-07-15 03:09:21
TRAINING STATS: batch 58/486 in epoch 547,   batch loss: 1.64987, batch accuracy: 0.56117
Time: 2018-07-15 03:09:25
TRAINING STATS: batch 108/486 in epoch 547,  batch loss: 1.75436, batch accuracy: 0.52667
Time: 2018-07-15 03:09:29
TRAINING STATS: batch 158/486 in epoch 547,  batch loss: 1.75403, batch accuracy: 0.53033
Time: 2018-07-15 03:09:33
TRAINING STATS: batch 208/486 in epoch 547,  batch loss: 1.70778, batch accuracy: 0.54600
Time: 2018-07-15 03:09:37
TRAINING STATS: batch 258/486 in epoch 547,  batch loss: 1.73590, batch accuracy: 0.54567
Time: 2018-07-15 03:09:41
TRAINING STATS: batch 308/486 in epoch 547,  batch loss: 1.73377, batch accuracy: 0.54650
Time: 2018-07-15 03:09:45
TRAINING STATS: batch 358/486 in epoch 547,  batch loss: 1.71313, batch accuracy: 0.54100
Time: 2018-07-15 03:09:49
TRAINING STATS: batch 408/486 in epoch 547,  batch loss: 1.72969, batch accuracy: 0.52600
Time: 2018-07-15 03:09:53
TRAINING STATS: batch 458/486 in epoch 547,  batch loss: 1.71713, batch accuracy: 0.54367
Time: 2018-07-15 03:09:57
TRAINING STATS: batch 22/486 in epoch 548,   batch loss: 1.73272, batch accuracy: 0.54000
Time: 2018-07-15 03:10:01
TRAINING STATS: batch 72/486 in epoch 548,   batch loss: 1.71399, batch accuracy: 0.53133
Time: 2018-07-15 03:10:05
TRAINING STATS: batch 122/486 in epoch 548,  batch loss: 1.64515, batch accuracy: 0.56033
Time: 2018-07-15 03:10:09
TRAINING STATS: batch 172/486 in epoch 548,  batch loss: 1.75526, batch accuracy: 0.53433
Time: 2018-07-15 03:10:13
TRAINING STATS: batch 222/486 in epoch 548,  batch loss: 1.68452, batch accuracy: 0.54433
Time: 2018-07-15 03:10:17
TRAINING STATS: batch 272/486 in epoch 548,  batch loss: 1.73757, batch accuracy: 0.53367
Time: 2018-07-15 03:10:21
TRAINING STATS: batch 322/486 in epoch 548,  batch loss: 1.68598, batch accuracy: 0.54750
Time: 2018-07-15 03:10:25
TRAINING STATS: batch 372/486 in epoch 548,  batch loss: 1.64700, batch accuracy: 0.56317
Time: 2018-07-15 03:10:29
TRAINING STATS: batch 422/486 in epoch 548,  batch loss: 1.68628, batch accuracy: 0.55417
Time: 2018-07-15 03:10:33
TRAINING STATS: batch 472/486 in epoch 548,  batch loss: 1.74778, batch accuracy: 0.53683
Time: 2018-07-15 03:10:37
TRAINING STATS: batch 36/486 in epoch 549,   batch loss: 1.75407, batch accuracy: 0.53333
Time: 2018-07-15 03:10:41
TRAINING STATS: batch 86/486 in epoch 549,   batch loss: 1.66939, batch accuracy: 0.55217
Time: 2018-07-15 03:10:45
TRAINING STATS: batch 136/486 in epoch 549,  batch loss: 1.72668, batch accuracy: 0.53667
Time: 2018-07-15 03:10:49
TRAINING STATS: batch 186/486 in epoch 549,  batch loss: 1.69871, batch accuracy: 0.54833
Time: 2018-07-15 03:10:53
TRAINING STATS: batch 236/486 in epoch 549,  batch loss: 1.71916, batch accuracy: 0.53183
Time: 2018-07-15 03:10:58
TRAINING STATS: batch 286/486 in epoch 549,  batch loss: 1.72180, batch accuracy: 0.53667
Time: 2018-07-15 03:11:01
TRAINING STATS: batch 336/486 in epoch 549,  batch loss: 1.67710, batch accuracy: 0.55083
Time: 2018-07-15 03:11:05
TRAINING STATS: batch 386/486 in epoch 549,  batch loss: 1.72753, batch accuracy: 0.53217
Time: 2018-07-15 03:11:10
TRAINING STATS: batch 436/486 in epoch 549,  batch loss: 1.72964, batch accuracy: 0.53717
Time: 2018-07-15 03:11:13
TRAINING STATS: batch 0/486 in epoch 550,    batch loss: 1.71620, batch accuracy: 0.52717
Time: 2018-07-15 03:11:17
TRAINING STATS: batch 50/486 in epoch 550,   batch loss: 1.65627, batch accuracy: 0.56050
Time: 2018-07-15 03:11:22
TRAINING STATS: batch 100/486 in epoch 550,  batch loss: 1.71233, batch accuracy: 0.54483
Time: 2018-07-15 03:11:25
TRAINING STATS: batch 150/486 in epoch 550,  batch loss: 1.65819, batch accuracy: 0.55833
Time: 2018-07-15 03:11:29
TRAINING STATS: batch 200/486 in epoch 550,  batch loss: 1.58386, batch accuracy: 0.57967
Time: 2018-07-15 03:11:34
TRAINING STATS: batch 250/486 in epoch 550,  batch loss: 1.73671, batch accuracy: 0.52683
Time: 2018-07-15 03:11:37
TRAINING STATS: batch 300/486 in epoch 550,  batch loss: 1.72109, batch accuracy: 0.52467
Time: 2018-07-15 03:11:41
TRAINING STATS: batch 350/486 in epoch 550,  batch loss: 1.70434, batch accuracy: 0.54767
Time: 2018-07-15 03:11:46
TRAINING STATS: batch 400/486 in epoch 550,  batch loss: 1.57993, batch accuracy: 0.57250
Time: 2018-07-15 03:11:49
TRAINING STATS: batch 450/486 in epoch 550,  batch loss: 1.74765, batch accuracy: 0.52683
Time: 2018-07-15 03:11:53
TRAINING STATS: batch 14/486 in epoch 551,   batch loss: 1.63593, batch accuracy: 0.56117
Time: 2018-07-15 03:11:58
TRAINING STATS: batch 64/486 in epoch 551,   batch loss: 1.78261, batch accuracy: 0.51983
Time: 2018-07-15 03:12:01
TRAINING STATS: batch 114/486 in epoch 551,  batch loss: 1.74679, batch accuracy: 0.52967
Time: 2018-07-15 03:12:05
TRAINING STATS: batch 164/486 in epoch 551,  batch loss: 1.62188, batch accuracy: 0.57200
Time: 2018-07-15 03:12:10
TRAINING STATS: batch 214/486 in epoch 551,  batch loss: 1.67925, batch accuracy: 0.55317
Time: 2018-07-15 03:12:13
TRAINING STATS: batch 264/486 in epoch 551,  batch loss: 1.74068, batch accuracy: 0.53133
Time: 2018-07-15 03:12:17
TRAINING STATS: batch 314/486 in epoch 551,  batch loss: 1.74972, batch accuracy: 0.52683
Time: 2018-07-15 03:12:22
TRAINING STATS: batch 364/486 in epoch 551,  batch loss: 1.65960, batch accuracy: 0.55650
Time: 2018-07-15 03:12:26
TRAINING STATS: batch 414/486 in epoch 551,  batch loss: 1.62045, batch accuracy: 0.56533
Time: 2018-07-15 03:12:29
TRAINING STATS: batch 464/486 in epoch 551,  batch loss: 1.65083, batch accuracy: 0.56217
Time: 2018-07-15 03:12:34
TRAINING STATS: batch 28/486 in epoch 552,   batch loss: 1.62130, batch accuracy: 0.56617
Time: 2018-07-15 03:12:38
TRAINING STATS: batch 78/486 in epoch 552,   batch loss: 1.71177, batch accuracy: 0.55083
Time: 2018-07-15 03:12:41
TRAINING STATS: batch 128/486 in epoch 552,  batch loss: 1.66956, batch accuracy: 0.54617
Time: 2018-07-15 03:12:46
TRAINING STATS: batch 178/486 in epoch 552,  batch loss: 1.58148, batch accuracy: 0.57617
Time: 2018-07-15 03:12:50
TRAINING STATS: batch 228/486 in epoch 552,  batch loss: 1.64538, batch accuracy: 0.55767
Time: 2018-07-15 03:12:53
TRAINING STATS: batch 278/486 in epoch 552,  batch loss: 1.62917, batch accuracy: 0.57233
Time: 2018-07-15 03:12:58
TRAINING STATS: batch 328/486 in epoch 552,  batch loss: 1.64487, batch accuracy: 0.55867
Time: 2018-07-15 03:13:02
TRAINING STATS: batch 378/486 in epoch 552,  batch loss: 1.67028, batch accuracy: 0.55683
Time: 2018-07-15 03:13:06
TRAINING STATS: batch 428/486 in epoch 552,  batch loss: 1.73902, batch accuracy: 0.53383
Time: 2018-07-15 03:13:10
TRAINING STATS: batch 478/486 in epoch 552,  batch loss: 1.70774, batch accuracy: 0.54500
Time: 2018-07-15 03:13:14
TRAINING STATS: batch 42/486 in epoch 553,   batch loss: 1.59570, batch accuracy: 0.56950
Time: 2018-07-15 03:13:18
TRAINING STATS: batch 92/486 in epoch 553,   batch loss: 1.70817, batch accuracy: 0.53650
Time: 2018-07-15 03:13:22
TRAINING STATS: batch 142/486 in epoch 553,  batch loss: 1.65075, batch accuracy: 0.55817
Time: 2018-07-15 03:13:26
TRAINING STATS: batch 192/486 in epoch 553,  batch loss: 1.69067, batch accuracy: 0.54883
Time: 2018-07-15 03:13:30
TRAINING STATS: batch 242/486 in epoch 553,  batch loss: 1.65706, batch accuracy: 0.55317
Time: 2018-07-15 03:13:34
TRAINING STATS: batch 292/486 in epoch 553,  batch loss: 1.68155, batch accuracy: 0.54700
Time: 2018-07-15 03:13:38
TRAINING STATS: batch 342/486 in epoch 553,  batch loss: 1.64105, batch accuracy: 0.55800
Time: 2018-07-15 03:13:42
TRAINING STATS: batch 392/486 in epoch 553,  batch loss: 1.59407, batch accuracy: 0.58083
Time: 2018-07-15 03:13:47
TRAINING STATS: batch 442/486 in epoch 553,  batch loss: 1.59309, batch accuracy: 0.57750
Time: 2018-07-15 03:13:50
TRAINING STATS: batch 6/486 in epoch 554,    batch loss: 1.75200, batch accuracy: 0.53300
Time: 2018-07-15 03:13:54
TRAINING STATS: batch 56/486 in epoch 554,   batch loss: 1.65132, batch accuracy: 0.55967
Time: 2018-07-15 03:13:59
TRAINING STATS: batch 106/486 in epoch 554,  batch loss: 1.73934, batch accuracy: 0.53233
Time: 2018-07-15 03:14:02
TRAINING STATS: batch 156/486 in epoch 554,  batch loss: 1.70386, batch accuracy: 0.54567
Time: 2018-07-15 03:14:06
TRAINING STATS: batch 206/486 in epoch 554,  batch loss: 1.76277, batch accuracy: 0.52850
Time: 2018-07-15 03:14:11
TRAINING STATS: batch 256/486 in epoch 554,  batch loss: 1.64458, batch accuracy: 0.55250
Time: 2018-07-15 03:14:14
TRAINING STATS: batch 306/486 in epoch 554,  batch loss: 1.68308, batch accuracy: 0.55350
Time: 2018-07-15 03:14:18
TRAINING STATS: batch 356/486 in epoch 554,  batch loss: 1.72095, batch accuracy: 0.54100
Time: 2018-07-15 03:14:23
TRAINING STATS: batch 406/486 in epoch 554,  batch loss: 1.76075, batch accuracy: 0.52117
Time: 2018-07-15 03:14:26
TRAINING STATS: batch 456/486 in epoch 554,  batch loss: 1.59025, batch accuracy: 0.58283
Time: 2018-07-15 03:14:30
TRAINING STATS: batch 20/486 in epoch 555,   batch loss: 1.68466, batch accuracy: 0.54667
Time: 2018-07-15 03:14:35
TRAINING STATS: batch 70/486 in epoch 555,   batch loss: 1.58406, batch accuracy: 0.58133
Time: 2018-07-15 03:14:38
TRAINING STATS: batch 120/486 in epoch 555,  batch loss: 1.62200, batch accuracy: 0.56950
Time: 2018-07-15 03:14:42
TRAINING STATS: batch 170/486 in epoch 555,  batch loss: 1.65683, batch accuracy: 0.55400
Time: 2018-07-15 03:14:47
TRAINING STATS: batch 220/486 in epoch 555,  batch loss: 1.61373, batch accuracy: 0.56783
Time: 2018-07-15 03:14:51
TRAINING STATS: batch 270/486 in epoch 555,  batch loss: 1.69684, batch accuracy: 0.54067
Time: 2018-07-15 03:14:54
TRAINING STATS: batch 320/486 in epoch 555,  batch loss: 1.63552, batch accuracy: 0.56017
Time: 2018-07-15 03:14:59
TRAINING STATS: batch 370/486 in epoch 555,  batch loss: 1.67887, batch accuracy: 0.54867
Time: 2018-07-15 03:15:03
TRAINING STATS: batch 420/486 in epoch 555,  batch loss: 1.70510, batch accuracy: 0.54417
Time: 2018-07-15 03:15:06
TRAINING STATS: batch 470/486 in epoch 555,  batch loss: 1.77809, batch accuracy: 0.51800
Time: 2018-07-15 03:15:11
TRAINING STATS: batch 34/486 in epoch 556,   batch loss: 1.71844, batch accuracy: 0.54583
Time: 2018-07-15 03:15:15
TRAINING STATS: batch 84/486 in epoch 556,   batch loss: 1.68987, batch accuracy: 0.53800
Time: 2018-07-15 03:15:18
TRAINING STATS: batch 134/486 in epoch 556,  batch loss: 1.70608, batch accuracy: 0.55117
Time: 2018-07-15 03:15:23
TRAINING STATS: batch 184/486 in epoch 556,  batch loss: 1.68294, batch accuracy: 0.54233
Time: 2018-07-15 03:15:27
TRAINING STATS: batch 234/486 in epoch 556,  batch loss: 1.75693, batch accuracy: 0.52850
Time: 2018-07-15 03:15:30
TRAINING STATS: batch 284/486 in epoch 556,  batch loss: 1.72902, batch accuracy: 0.53850
Time: 2018-07-15 03:15:35
TRAINING STATS: batch 334/486 in epoch 556,  batch loss: 1.66394, batch accuracy: 0.55217
Time: 2018-07-15 03:15:39
TRAINING STATS: batch 384/486 in epoch 556,  batch loss: 1.65266, batch accuracy: 0.56017
Time: 2018-07-15 03:15:43
TRAINING STATS: batch 434/486 in epoch 556,  batch loss: 1.71997, batch accuracy: 0.53650
Time: 2018-07-15 03:15:47
TRAINING STATS: batch 484/486 in epoch 556,  batch loss: 1.71450, batch accuracy: 0.54033
Time: 2018-07-15 03:15:51
TRAINING STATS: batch 48/486 in epoch 557,   batch loss: 1.74164, batch accuracy: 0.53850
Time: 2018-07-15 03:15:55
TRAINING STATS: batch 98/486 in epoch 557,   batch loss: 1.64170, batch accuracy: 0.55783
Time: 2018-07-15 03:15:59
TRAINING STATS: batch 148/486 in epoch 557,  batch loss: 1.71163, batch accuracy: 0.54650
Time: 2018-07-15 03:16:03
TRAINING STATS: batch 198/486 in epoch 557,  batch loss: 1.67575, batch accuracy: 0.54817
Time: 2018-07-15 03:16:07
TRAINING STATS: batch 248/486 in epoch 557,  batch loss: 1.70844, batch accuracy: 0.54250
Time: 2018-07-15 03:16:11
TRAINING STATS: batch 298/486 in epoch 557,  batch loss: 1.71777, batch accuracy: 0.53933
Time: 2018-07-15 03:16:15
TRAINING STATS: batch 348/486 in epoch 557,  batch loss: 1.69343, batch accuracy: 0.55067
Time: 2018-07-15 03:16:19
TRAINING STATS: batch 398/486 in epoch 557,  batch loss: 1.68821, batch accuracy: 0.54683
Time: 2018-07-15 03:16:24
TRAINING STATS: batch 448/486 in epoch 557,  batch loss: 1.69708, batch accuracy: 0.55083
Time: 2018-07-15 03:16:27
TRAINING STATS: batch 12/486 in epoch 558,   batch loss: 1.69427, batch accuracy: 0.54433
Time: 2018-07-15 03:16:31
TRAINING STATS: batch 62/486 in epoch 558,   batch loss: 1.75167, batch accuracy: 0.52450
Time: 2018-07-15 03:16:36
TRAINING STATS: batch 112/486 in epoch 558,  batch loss: 1.66964, batch accuracy: 0.54917
Time: 2018-07-15 03:16:39
TRAINING STATS: batch 162/486 in epoch 558,  batch loss: 1.69496, batch accuracy: 0.54867
Time: 2018-07-15 03:16:43
TRAINING STATS: batch 212/486 in epoch 558,  batch loss: 1.60435, batch accuracy: 0.57100
Time: 2018-07-15 03:16:48
TRAINING STATS: batch 262/486 in epoch 558,  batch loss: 1.73289, batch accuracy: 0.53850
Time: 2018-07-15 03:16:51
TRAINING STATS: batch 312/486 in epoch 558,  batch loss: 1.69060, batch accuracy: 0.53800
Time: 2018-07-15 03:16:55
TRAINING STATS: batch 362/486 in epoch 558,  batch loss: 1.68872, batch accuracy: 0.54583
Time: 2018-07-15 03:17:00
TRAINING STATS: batch 412/486 in epoch 558,  batch loss: 1.62965, batch accuracy: 0.57350
Time: 2018-07-15 03:17:03
TRAINING STATS: batch 462/486 in epoch 558,  batch loss: 1.69683, batch accuracy: 0.55217
Time: 2018-07-15 03:17:07
TRAINING STATS: batch 26/486 in epoch 559,   batch loss: 1.71272, batch accuracy: 0.54067
Time: 2018-07-15 03:17:12
TRAINING STATS: batch 76/486 in epoch 559,   batch loss: 1.80002, batch accuracy: 0.52117
Time: 2018-07-15 03:17:15
TRAINING STATS: batch 126/486 in epoch 559,  batch loss: 1.73881, batch accuracy: 0.53200
Time: 2018-07-15 03:17:19
TRAINING STATS: batch 176/486 in epoch 559,  batch loss: 1.61800, batch accuracy: 0.57983
Time: 2018-07-15 03:17:24
TRAINING STATS: batch 226/486 in epoch 559,  batch loss: 1.66773, batch accuracy: 0.55917
Time: 2018-07-15 03:17:27
TRAINING STATS: batch 276/486 in epoch 559,  batch loss: 1.67928, batch accuracy: 0.54667
Time: 2018-07-15 03:17:31
TRAINING STATS: batch 326/486 in epoch 559,  batch loss: 1.74594, batch accuracy: 0.53350
Time: 2018-07-15 03:17:36
TRAINING STATS: batch 376/486 in epoch 559,  batch loss: 1.73492, batch accuracy: 0.54217
Time: 2018-07-15 03:17:40
TRAINING STATS: batch 426/486 in epoch 559,  batch loss: 1.69924, batch accuracy: 0.53800
Time: 2018-07-15 03:17:43
TRAINING STATS: batch 476/486 in epoch 559,  batch loss: 1.63972, batch accuracy: 0.55667
Time: 2018-07-15 03:17:48
TRAINING STATS: batch 40/486 in epoch 560,   batch loss: 1.63892, batch accuracy: 0.56383
Time: 2018-07-15 03:17:52
TRAINING STATS: batch 90/486 in epoch 560,   batch loss: 1.74109, batch accuracy: 0.54100
Time: 2018-07-15 03:17:55
TRAINING STATS: batch 140/486 in epoch 560,  batch loss: 1.61025, batch accuracy: 0.56633
Time: 2018-07-15 03:18:00
TRAINING STATS: batch 190/486 in epoch 560,  batch loss: 1.64783, batch accuracy: 0.56083
Time: 2018-07-15 03:18:04
TRAINING STATS: batch 240/486 in epoch 560,  batch loss: 1.65491, batch accuracy: 0.55650
Time: 2018-07-15 03:18:07
TRAINING STATS: batch 290/486 in epoch 560,  batch loss: 1.70095, batch accuracy: 0.54250
Time: 2018-07-15 03:18:12
TRAINING STATS: batch 340/486 in epoch 560,  batch loss: 1.77759, batch accuracy: 0.51483
Time: 2018-07-15 03:18:16
TRAINING STATS: batch 390/486 in epoch 560,  batch loss: 1.64350, batch accuracy: 0.56650
Time: 2018-07-15 03:18:19
TRAINING STATS: batch 440/486 in epoch 560,  batch loss: 1.68927, batch accuracy: 0.55400
Time: 2018-07-15 03:18:24
TRAINING STATS: batch 4/486 in epoch 561,    batch loss: 1.63188, batch accuracy: 0.56833
Time: 2018-07-15 03:18:28
TRAINING STATS: batch 54/486 in epoch 561,   batch loss: 1.68619, batch accuracy: 0.55150
Time: 2018-07-15 03:18:31
TRAINING STATS: batch 104/486 in epoch 561,  batch loss: 1.69143, batch accuracy: 0.55250
Time: 2018-07-15 03:18:36
TRAINING STATS: batch 154/486 in epoch 561,  batch loss: 1.66156, batch accuracy: 0.55667
Time: 2018-07-15 03:18:40
TRAINING STATS: batch 204/486 in epoch 561,  batch loss: 1.75130, batch accuracy: 0.53717
Time: 2018-07-15 03:18:43
TRAINING STATS: batch 254/486 in epoch 561,  batch loss: 1.61981, batch accuracy: 0.56517
Time: 2018-07-15 03:18:48
TRAINING STATS: batch 304/486 in epoch 561,  batch loss: 1.62621, batch accuracy: 0.56817
Time: 2018-07-15 03:18:52
TRAINING STATS: batch 354/486 in epoch 561,  batch loss: 1.66964, batch accuracy: 0.54883
Time: 2018-07-15 03:18:55
TRAINING STATS: batch 404/486 in epoch 561,  batch loss: 1.67287, batch accuracy: 0.55417
Time: 2018-07-15 03:19:00
TRAINING STATS: batch 454/486 in epoch 561,  batch loss: 1.56523, batch accuracy: 0.58417
Time: 2018-07-15 03:19:04
TRAINING STATS: batch 18/486 in epoch 562,   batch loss: 1.86620, batch accuracy: 0.49717
Time: 2018-07-15 03:19:08
TRAINING STATS: batch 68/486 in epoch 562,   batch loss: 1.54903, batch accuracy: 0.59033
Time: 2018-07-15 03:19:12
TRAINING STATS: batch 118/486 in epoch 562,  batch loss: 1.69362, batch accuracy: 0.55367
Time: 2018-07-15 03:19:16
TRAINING STATS: batch 168/486 in epoch 562,  batch loss: 1.60758, batch accuracy: 0.57500
Time: 2018-07-15 03:19:20
TRAINING STATS: batch 218/486 in epoch 562,  batch loss: 1.65821, batch accuracy: 0.55300
Time: 2018-07-15 03:19:24
TRAINING STATS: batch 268/486 in epoch 562,  batch loss: 1.60864, batch accuracy: 0.57017
Time: 2018-07-15 03:19:28
TRAINING STATS: batch 318/486 in epoch 562,  batch loss: 1.68362, batch accuracy: 0.55200
Time: 2018-07-15 03:19:32
TRAINING STATS: batch 368/486 in epoch 562,  batch loss: 1.69692, batch accuracy: 0.54750
Time: 2018-07-15 03:19:36
TRAINING STATS: batch 418/486 in epoch 562,  batch loss: 1.73049, batch accuracy: 0.53333
Time: 2018-07-15 03:19:40
TRAINING STATS: batch 468/486 in epoch 562,  batch loss: 1.68112, batch accuracy: 0.55067
Time: 2018-07-15 03:19:44
TRAINING STATS: batch 32/486 in epoch 563,   batch loss: 1.63350, batch accuracy: 0.55883
Time: 2018-07-15 03:19:48
TRAINING STATS: batch 82/486 in epoch 563,   batch loss: 1.72477, batch accuracy: 0.53467
Time: 2018-07-15 03:19:52
TRAINING STATS: batch 132/486 in epoch 563,  batch loss: 1.67550, batch accuracy: 0.56183
Time: 2018-07-15 03:19:56
TRAINING STATS: batch 182/486 in epoch 563,  batch loss: 1.73323, batch accuracy: 0.53567
Time: 2018-07-15 03:20:00
TRAINING STATS: batch 232/486 in epoch 563,  batch loss: 1.70558, batch accuracy: 0.54883
Time: 2018-07-15 03:20:04
TRAINING STATS: batch 282/486 in epoch 563,  batch loss: 1.64187, batch accuracy: 0.56117
Time: 2018-07-15 03:20:08
TRAINING STATS: batch 332/486 in epoch 563,  batch loss: 1.72489, batch accuracy: 0.53950
Time: 2018-07-15 03:20:12
TRAINING STATS: batch 382/486 in epoch 563,  batch loss: 1.70939, batch accuracy: 0.54433
Time: 2018-07-15 03:20:16
TRAINING STATS: batch 432/486 in epoch 563,  batch loss: 1.60204, batch accuracy: 0.57233
Time: 2018-07-15 03:20:20
TRAINING STATS: batch 482/486 in epoch 563,  batch loss: 1.66342, batch accuracy: 0.55517
Time: 2018-07-15 03:20:25
TRAINING STATS: batch 46/486 in epoch 564,   batch loss: 1.65347, batch accuracy: 0.56733
Time: 2018-07-15 03:20:28
TRAINING STATS: batch 96/486 in epoch 564,   batch loss: 1.70717, batch accuracy: 0.54867
Time: 2018-07-15 03:20:32
TRAINING STATS: batch 146/486 in epoch 564,  batch loss: 1.71555, batch accuracy: 0.53850
Time: 2018-07-15 03:20:37
TRAINING STATS: batch 196/486 in epoch 564,  batch loss: 1.73950, batch accuracy: 0.53233
Time: 2018-07-15 03:20:40
TRAINING STATS: batch 246/486 in epoch 564,  batch loss: 1.64890, batch accuracy: 0.56200
Time: 2018-07-15 03:20:44
TRAINING STATS: batch 296/486 in epoch 564,  batch loss: 1.65304, batch accuracy: 0.55550
Time: 2018-07-15 03:20:49
TRAINING STATS: batch 346/486 in epoch 564,  batch loss: 1.59412, batch accuracy: 0.57683
Time: 2018-07-15 03:20:52
TRAINING STATS: batch 396/486 in epoch 564,  batch loss: 1.65628, batch accuracy: 0.56033
Time: 2018-07-15 03:20:56
TRAINING STATS: batch 446/486 in epoch 564,  batch loss: 1.69074, batch accuracy: 0.55050
Time: 2018-07-15 03:21:01
TRAINING STATS: batch 10/486 in epoch 565,   batch loss: 1.71685, batch accuracy: 0.54250
Time: 2018-07-15 03:21:05
TRAINING STATS: batch 60/486 in epoch 565,   batch loss: 1.65613, batch accuracy: 0.55850
Time: 2018-07-15 03:21:08
TRAINING STATS: batch 110/486 in epoch 565,  batch loss: 1.82386, batch accuracy: 0.51750
Time: 2018-07-15 03:21:13
TRAINING STATS: batch 160/486 in epoch 565,  batch loss: 1.66740, batch accuracy: 0.54800
Time: 2018-07-15 03:21:17
TRAINING STATS: batch 210/486 in epoch 565,  batch loss: 1.63369, batch accuracy: 0.56717
Time: 2018-07-15 03:21:20
TRAINING STATS: batch 260/486 in epoch 565,  batch loss: 1.70977, batch accuracy: 0.53917
Time: 2018-07-15 03:21:25
TRAINING STATS: batch 310/486 in epoch 565,  batch loss: 1.73935, batch accuracy: 0.53383
Time: 2018-07-15 03:21:29
TRAINING STATS: batch 360/486 in epoch 565,  batch loss: 1.70607, batch accuracy: 0.54333
Time: 2018-07-15 03:21:32
TRAINING STATS: batch 410/486 in epoch 565,  batch loss: 1.61205, batch accuracy: 0.58083
Time: 2018-07-15 03:21:37
TRAINING STATS: batch 460/486 in epoch 565,  batch loss: 1.79864, batch accuracy: 0.51917
Time: 2018-07-15 03:21:41
TRAINING STATS: batch 24/486 in epoch 566,   batch loss: 1.75241, batch accuracy: 0.53117
Time: 2018-07-15 03:21:44
TRAINING STATS: batch 74/486 in epoch 566,   batch loss: 1.69916, batch accuracy: 0.54567
Time: 2018-07-15 03:21:49
TRAINING STATS: batch 124/486 in epoch 566,  batch loss: 1.71202, batch accuracy: 0.54850
Time: 2018-07-15 03:21:53
TRAINING STATS: batch 174/486 in epoch 566,  batch loss: 1.74714, batch accuracy: 0.53483
Time: 2018-07-15 03:21:56
TRAINING STATS: batch 224/486 in epoch 566,  batch loss: 1.72536, batch accuracy: 0.54283
Time: 2018-07-15 03:22:01
TRAINING STATS: batch 274/486 in epoch 566,  batch loss: 1.68464, batch accuracy: 0.54850
Time: 2018-07-15 03:22:05
TRAINING STATS: batch 324/486 in epoch 566,  batch loss: 1.72205, batch accuracy: 0.54167
Time: 2018-07-15 03:22:08
TRAINING STATS: batch 374/486 in epoch 566,  batch loss: 1.71847, batch accuracy: 0.54700
Time: 2018-07-15 03:22:13
TRAINING STATS: batch 424/486 in epoch 566,  batch loss: 1.64536, batch accuracy: 0.56817
Time: 2018-07-15 03:22:17
TRAINING STATS: batch 474/486 in epoch 566,  batch loss: 1.70429, batch accuracy: 0.54683
Time: 2018-07-15 03:22:21
TRAINING STATS: batch 38/486 in epoch 567,   batch loss: 1.72295, batch accuracy: 0.54550
Time: 2018-07-15 03:22:25
TRAINING STATS: batch 88/486 in epoch 567,   batch loss: 1.73831, batch accuracy: 0.53083
Time: 2018-07-15 03:22:29
TRAINING STATS: batch 138/486 in epoch 567,  batch loss: 1.71628, batch accuracy: 0.53867
Time: 2018-07-15 03:22:33
TRAINING STATS: batch 188/486 in epoch 567,  batch loss: 1.63324, batch accuracy: 0.57017
Time: 2018-07-15 03:22:37
TRAINING STATS: batch 238/486 in epoch 567,  batch loss: 1.67280, batch accuracy: 0.55417
Time: 2018-07-15 03:22:41
TRAINING STATS: batch 288/486 in epoch 567,  batch loss: 1.71532, batch accuracy: 0.53967
Time: 2018-07-15 03:22:45
TRAINING STATS: batch 338/486 in epoch 567,  batch loss: 1.68698, batch accuracy: 0.55417
Time: 2018-07-15 03:22:49
TRAINING STATS: batch 388/486 in epoch 567,  batch loss: 1.64547, batch accuracy: 0.56383
Time: 2018-07-15 03:22:53
TRAINING STATS: batch 438/486 in epoch 567,  batch loss: 1.71370, batch accuracy: 0.53833
Time: 2018-07-15 03:22:57
TRAINING STATS: batch 2/486 in epoch 568,    batch loss: 1.71629, batch accuracy: 0.54533
Time: 2018-07-15 03:23:01
TRAINING STATS: batch 52/486 in epoch 568,   batch loss: 1.75070, batch accuracy: 0.52767
Time: 2018-07-15 03:23:05
TRAINING STATS: batch 102/486 in epoch 568,  batch loss: 1.70762, batch accuracy: 0.55233
Time: 2018-07-15 03:23:09
TRAINING STATS: batch 152/486 in epoch 568,  batch loss: 1.65281, batch accuracy: 0.56017
Time: 2018-07-15 03:23:13
TRAINING STATS: batch 202/486 in epoch 568,  batch loss: 1.68892, batch accuracy: 0.55100
Time: 2018-07-15 03:23:17
TRAINING STATS: batch 252/486 in epoch 568,  batch loss: 1.66210, batch accuracy: 0.56050
Time: 2018-07-15 03:23:21
TRAINING STATS: batch 302/486 in epoch 568,  batch loss: 1.62587, batch accuracy: 0.56200
Time: 2018-07-15 03:23:25
TRAINING STATS: batch 352/486 in epoch 568,  batch loss: 1.65225, batch accuracy: 0.55717
Time: 2018-07-15 03:23:29
TRAINING STATS: batch 402/486 in epoch 568,  batch loss: 1.54507, batch accuracy: 0.58683
Time: 2018-07-15 03:23:33
TRAINING STATS: batch 452/486 in epoch 568,  batch loss: 1.68632, batch accuracy: 0.54667
Time: 2018-07-15 03:23:38
TRAINING STATS: batch 16/486 in epoch 569,   batch loss: 1.66280, batch accuracy: 0.56100
Time: 2018-07-15 03:23:41
TRAINING STATS: batch 66/486 in epoch 569,   batch loss: 1.66451, batch accuracy: 0.56133
Time: 2018-07-15 03:23:45
TRAINING STATS: batch 116/486 in epoch 569,  batch loss: 1.67682, batch accuracy: 0.55300
Time: 2018-07-15 03:23:50
TRAINING STATS: batch 166/486 in epoch 569,  batch loss: 1.59479, batch accuracy: 0.57600
Time: 2018-07-15 03:23:53
TRAINING STATS: batch 216/486 in epoch 569,  batch loss: 1.68871, batch accuracy: 0.55533
Time: 2018-07-15 03:23:57
TRAINING STATS: batch 266/486 in epoch 569,  batch loss: 1.69000, batch accuracy: 0.54917
Time: 2018-07-15 03:24:02
TRAINING STATS: batch 316/486 in epoch 569,  batch loss: 1.67964, batch accuracy: 0.55250
Time: 2018-07-15 03:24:05
TRAINING STATS: batch 366/486 in epoch 569,  batch loss: 1.83888, batch accuracy: 0.49883
Time: 2018-07-15 03:24:09
TRAINING STATS: batch 416/486 in epoch 569,  batch loss: 1.75992, batch accuracy: 0.52033
Time: 2018-07-15 03:24:14
TRAINING STATS: batch 466/486 in epoch 569,  batch loss: 1.58303, batch accuracy: 0.57617
Time: 2018-07-15 03:24:17
TRAINING STATS: batch 30/486 in epoch 570,   batch loss: 1.58094, batch accuracy: 0.57900
Time: 2018-07-15 03:24:21
TRAINING STATS: batch 80/486 in epoch 570,   batch loss: 1.66605, batch accuracy: 0.54733
Time: 2018-07-15 03:24:26
TRAINING STATS: batch 130/486 in epoch 570,  batch loss: 1.66510, batch accuracy: 0.56100
Time: 2018-07-15 03:24:30
TRAINING STATS: batch 180/486 in epoch 570,  batch loss: 1.70454, batch accuracy: 0.54667
Time: 2018-07-15 03:24:33
TRAINING STATS: batch 230/486 in epoch 570,  batch loss: 1.70352, batch accuracy: 0.53867
Time: 2018-07-15 03:24:38
TRAINING STATS: batch 280/486 in epoch 570,  batch loss: 1.67047, batch accuracy: 0.54950
Time: 2018-07-15 03:24:42
TRAINING STATS: batch 330/486 in epoch 570,  batch loss: 1.64809, batch accuracy: 0.55500
Time: 2018-07-15 03:24:45
TRAINING STATS: batch 380/486 in epoch 570,  batch loss: 1.65443, batch accuracy: 0.56467
Time: 2018-07-15 03:24:50
TRAINING STATS: batch 430/486 in epoch 570,  batch loss: 1.60429, batch accuracy: 0.57583
Time: 2018-07-15 03:24:54
TRAINING STATS: batch 480/486 in epoch 570,  batch loss: 1.68537, batch accuracy: 0.54867
Time: 2018-07-15 03:24:57
TRAINING STATS: batch 44/486 in epoch 571,   batch loss: 1.62573, batch accuracy: 0.56383
Time: 2018-07-15 03:25:02
TRAINING STATS: batch 94/486 in epoch 571,   batch loss: 1.72842, batch accuracy: 0.53617
Time: 2018-07-15 03:25:06
TRAINING STATS: batch 144/486 in epoch 571,  batch loss: 1.74197, batch accuracy: 0.52983
Time: 2018-07-15 03:25:10
TRAINING STATS: batch 194/486 in epoch 571,  batch loss: 1.76453, batch accuracy: 0.52483
Time: 2018-07-15 03:25:14
TRAINING STATS: batch 244/486 in epoch 571,  batch loss: 1.67817, batch accuracy: 0.55650
Time: 2018-07-15 03:25:18
TRAINING STATS: batch 294/486 in epoch 571,  batch loss: 1.60482, batch accuracy: 0.57850
Time: 2018-07-15 03:25:22
TRAINING STATS: batch 344/486 in epoch 571,  batch loss: 1.66836, batch accuracy: 0.55383
Time: 2018-07-15 03:25:26
TRAINING STATS: batch 394/486 in epoch 571,  batch loss: 1.63810, batch accuracy: 0.56900
Time: 2018-07-15 03:25:30
TRAINING STATS: batch 444/486 in epoch 571,  batch loss: 1.61607, batch accuracy: 0.57100
Time: 2018-07-15 03:25:34
TRAINING STATS: batch 8/486 in epoch 572,    batch loss: 1.67423, batch accuracy: 0.55550
Time: 2018-07-15 03:25:38
TRAINING STATS: batch 58/486 in epoch 572,   batch loss: 1.64487, batch accuracy: 0.56067
Time: 2018-07-15 03:25:42
TRAINING STATS: batch 108/486 in epoch 572,  batch loss: 1.73755, batch accuracy: 0.53733
Time: 2018-07-15 03:25:46
TRAINING STATS: batch 158/486 in epoch 572,  batch loss: 1.74488, batch accuracy: 0.53933
Time: 2018-07-15 03:25:50
TRAINING STATS: batch 208/486 in epoch 572,  batch loss: 1.68484, batch accuracy: 0.55300
Time: 2018-07-15 03:25:54
TRAINING STATS: batch 258/486 in epoch 572,  batch loss: 1.63519, batch accuracy: 0.56117
Time: 2018-07-15 03:25:58
TRAINING STATS: batch 308/486 in epoch 572,  batch loss: 1.69319, batch accuracy: 0.55617
Time: 2018-07-15 03:26:02
TRAINING STATS: batch 358/486 in epoch 572,  batch loss: 1.69598, batch accuracy: 0.54400
Time: 2018-07-15 03:26:06
TRAINING STATS: batch 408/486 in epoch 572,  batch loss: 1.71056, batch accuracy: 0.53950
Time: 2018-07-15 03:26:10
TRAINING STATS: batch 458/486 in epoch 572,  batch loss: 1.70353, batch accuracy: 0.54550
Time: 2018-07-15 03:26:14
TRAINING STATS: batch 22/486 in epoch 573,   batch loss: 1.73243, batch accuracy: 0.54517
Time: 2018-07-15 03:26:18
TRAINING STATS: batch 72/486 in epoch 573,   batch loss: 1.71486, batch accuracy: 0.53383
Time: 2018-07-15 03:26:22
TRAINING STATS: batch 122/486 in epoch 573,  batch loss: 1.64336, batch accuracy: 0.56333
Time: 2018-07-15 03:26:27
TRAINING STATS: batch 172/486 in epoch 573,  batch loss: 1.74006, batch accuracy: 0.53517
Time: 2018-07-15 03:26:30
TRAINING STATS: batch 222/486 in epoch 573,  batch loss: 1.66075, batch accuracy: 0.55250
Time: 2018-07-15 03:26:34
TRAINING STATS: batch 272/486 in epoch 573,  batch loss: 1.71261, batch accuracy: 0.53900
Time: 2018-07-15 03:26:39
TRAINING STATS: batch 322/486 in epoch 573,  batch loss: 1.66816, batch accuracy: 0.55067
Time: 2018-07-15 03:26:42
TRAINING STATS: batch 372/486 in epoch 573,  batch loss: 1.63124, batch accuracy: 0.56533
Time: 2018-07-15 03:26:46
TRAINING STATS: batch 422/486 in epoch 573,  batch loss: 1.65617, batch accuracy: 0.56067
Time: 2018-07-15 03:26:51
TRAINING STATS: batch 472/486 in epoch 573,  batch loss: 1.74648, batch accuracy: 0.53500
Time: 2018-07-15 03:26:54
TRAINING STATS: batch 36/486 in epoch 574,   batch loss: 1.74569, batch accuracy: 0.53783
Time: 2018-07-15 03:26:58
TRAINING STATS: batch 86/486 in epoch 574,   batch loss: 1.66537, batch accuracy: 0.56083
Time: 2018-07-15 03:27:03
TRAINING STATS: batch 136/486 in epoch 574,  batch loss: 1.72527, batch accuracy: 0.53550
Time: 2018-07-15 03:27:06
TRAINING STATS: batch 186/486 in epoch 574,  batch loss: 1.70387, batch accuracy: 0.54617
Time: 2018-07-15 03:27:10
TRAINING STATS: batch 236/486 in epoch 574,  batch loss: 1.72198, batch accuracy: 0.53467
Time: 2018-07-15 03:27:15
TRAINING STATS: batch 286/486 in epoch 574,  batch loss: 1.72613, batch accuracy: 0.54650
Time: 2018-07-15 03:27:18
TRAINING STATS: batch 336/486 in epoch 574,  batch loss: 1.68955, batch accuracy: 0.54983
Time: 2018-07-15 03:27:22
TRAINING STATS: batch 386/486 in epoch 574,  batch loss: 1.76632, batch accuracy: 0.52583
Time: 2018-07-15 03:27:27
TRAINING STATS: batch 436/486 in epoch 574,  batch loss: 1.70726, batch accuracy: 0.54267
Time: 2018-07-15 03:27:30
TRAINING STATS: batch 0/486 in epoch 575,    batch loss: 1.66926, batch accuracy: 0.55733
Time: 2018-07-15 03:27:34
TRAINING STATS: batch 50/486 in epoch 575,   batch loss: 1.63920, batch accuracy: 0.56983
Time: 2018-07-15 03:27:39
TRAINING STATS: batch 100/486 in epoch 575,  batch loss: 1.69496, batch accuracy: 0.55033
Time: 2018-07-15 03:27:43
TRAINING STATS: batch 150/486 in epoch 575,  batch loss: 1.64437, batch accuracy: 0.56283
Time: 2018-07-15 03:27:46
TRAINING STATS: batch 200/486 in epoch 575,  batch loss: 1.57135, batch accuracy: 0.58833
Time: 2018-07-15 03:27:51
TRAINING STATS: batch 250/486 in epoch 575,  batch loss: 1.72598, batch accuracy: 0.53367
Time: 2018-07-15 03:27:55
TRAINING STATS: batch 300/486 in epoch 575,  batch loss: 1.69604, batch accuracy: 0.53717
Time: 2018-07-15 03:27:58
TRAINING STATS: batch 350/486 in epoch 575,  batch loss: 1.70995, batch accuracy: 0.54867
Time: 2018-07-15 03:28:03
TRAINING STATS: batch 400/486 in epoch 575,  batch loss: 1.56913, batch accuracy: 0.58133
Time: 2018-07-15 03:28:07
TRAINING STATS: batch 450/486 in epoch 575,  batch loss: 1.73442, batch accuracy: 0.53083
Time: 2018-07-15 03:28:10
TRAINING STATS: batch 14/486 in epoch 576,   batch loss: 1.58772, batch accuracy: 0.57883
Time: 2018-07-15 03:28:15
TRAINING STATS: batch 64/486 in epoch 576,   batch loss: 1.76385, batch accuracy: 0.52500
Time: 2018-07-15 03:28:19
TRAINING STATS: batch 114/486 in epoch 576,  batch loss: 1.71163, batch accuracy: 0.54267
Time: 2018-07-15 03:28:22
TRAINING STATS: batch 164/486 in epoch 576,  batch loss: 1.61187, batch accuracy: 0.57733
Time: 2018-07-15 03:28:27
TRAINING STATS: batch 214/486 in epoch 576,  batch loss: 1.67295, batch accuracy: 0.55300
Time: 2018-07-15 03:28:31
TRAINING STATS: batch 264/486 in epoch 576,  batch loss: 1.72257, batch accuracy: 0.53433
Time: 2018-07-15 03:28:34
TRAINING STATS: batch 314/486 in epoch 576,  batch loss: 1.73482, batch accuracy: 0.52717
Time: 2018-07-15 03:28:39
TRAINING STATS: batch 364/486 in epoch 576,  batch loss: 1.65424, batch accuracy: 0.56017
Time: 2018-07-15 03:28:43
TRAINING STATS: batch 414/486 in epoch 576,  batch loss: 1.60324, batch accuracy: 0.56850
Time: 2018-07-15 03:28:47
TRAINING STATS: batch 464/486 in epoch 576,  batch loss: 1.63768, batch accuracy: 0.56867
Time: 2018-07-15 03:28:51
TRAINING STATS: batch 28/486 in epoch 577,   batch loss: 1.62745, batch accuracy: 0.56883
Time: 2018-07-15 03:28:55
TRAINING STATS: batch 78/486 in epoch 577,   batch loss: 1.66838, batch accuracy: 0.56400
Time: 2018-07-15 03:28:58
TRAINING STATS: batch 128/486 in epoch 577,  batch loss: 1.65445, batch accuracy: 0.55300
Time: 2018-07-15 03:29:03
TRAINING STATS: batch 178/486 in epoch 577,  batch loss: 1.55954, batch accuracy: 0.58450
Time: 2018-07-15 03:29:07
TRAINING STATS: batch 228/486 in epoch 577,  batch loss: 1.62280, batch accuracy: 0.56717
Time: 2018-07-15 03:29:11
TRAINING STATS: batch 278/486 in epoch 577,  batch loss: 1.59405, batch accuracy: 0.57783
Time: 2018-07-15 03:29:15
TRAINING STATS: batch 328/486 in epoch 577,  batch loss: 1.63120, batch accuracy: 0.56133
Time: 2018-07-15 03:29:19
TRAINING STATS: batch 378/486 in epoch 577,  batch loss: 1.65808, batch accuracy: 0.56200
Time: 2018-07-15 03:29:23
TRAINING STATS: batch 428/486 in epoch 577,  batch loss: 1.70683, batch accuracy: 0.54333
Time: 2018-07-15 03:29:27
TRAINING STATS: batch 478/486 in epoch 577,  batch loss: 1.69189, batch accuracy: 0.54817
Time: 2018-07-15 03:29:31
TRAINING STATS: batch 42/486 in epoch 578,   batch loss: 1.59199, batch accuracy: 0.57567
Time: 2018-07-15 03:29:35
TRAINING STATS: batch 92/486 in epoch 578,   batch loss: 1.68921, batch accuracy: 0.54233
Time: 2018-07-15 03:29:39
TRAINING STATS: batch 142/486 in epoch 578,  batch loss: 1.64058, batch accuracy: 0.56433
Time: 2018-07-15 03:29:43
TRAINING STATS: batch 192/486 in epoch 578,  batch loss: 1.66720, batch accuracy: 0.55783
Time: 2018-07-15 03:29:47
TRAINING STATS: batch 242/486 in epoch 578,  batch loss: 1.63656, batch accuracy: 0.56433
Time: 2018-07-15 03:29:51
TRAINING STATS: batch 292/486 in epoch 578,  batch loss: 1.65506, batch accuracy: 0.55900
Time: 2018-07-15 03:29:55
TRAINING STATS: batch 342/486 in epoch 578,  batch loss: 1.62352, batch accuracy: 0.56933
Time: 2018-07-15 03:29:59
TRAINING STATS: batch 392/486 in epoch 578,  batch loss: 1.58812, batch accuracy: 0.57700
Time: 2018-07-15 03:30:03
TRAINING STATS: batch 442/486 in epoch 578,  batch loss: 1.57692, batch accuracy: 0.57783
Time: 2018-07-15 03:30:07
TRAINING STATS: batch 6/486 in epoch 579,    batch loss: 1.70028, batch accuracy: 0.55400
Time: 2018-07-15 03:30:11
TRAINING STATS: batch 56/486 in epoch 579,   batch loss: 1.63366, batch accuracy: 0.56133
Time: 2018-07-15 03:30:15
TRAINING STATS: batch 106/486 in epoch 579,  batch loss: 1.73421, batch accuracy: 0.53667
Time: 2018-07-15 03:30:19
TRAINING STATS: batch 156/486 in epoch 579,  batch loss: 1.70092, batch accuracy: 0.54267
Time: 2018-07-15 03:30:23
TRAINING STATS: batch 206/486 in epoch 579,  batch loss: 1.74450, batch accuracy: 0.53033
Time: 2018-07-15 03:30:28
TRAINING STATS: batch 256/486 in epoch 579,  batch loss: 1.60065, batch accuracy: 0.57100
Time: 2018-07-15 03:30:31
TRAINING STATS: batch 306/486 in epoch 579,  batch loss: 1.65530, batch accuracy: 0.55600
Time: 2018-07-15 03:30:35
TRAINING STATS: batch 356/486 in epoch 579,  batch loss: 1.71427, batch accuracy: 0.53933
Time: 2018-07-15 03:30:40
TRAINING STATS: batch 406/486 in epoch 579,  batch loss: 1.75516, batch accuracy: 0.52567
Time: 2018-07-15 03:30:43
TRAINING STATS: batch 456/486 in epoch 579,  batch loss: 1.57183, batch accuracy: 0.58250
Time: 2018-07-15 03:30:47
TRAINING STATS: batch 20/486 in epoch 580,   batch loss: 1.68115, batch accuracy: 0.55350
Time: 2018-07-15 03:30:52
TRAINING STATS: batch 70/486 in epoch 580,   batch loss: 1.55461, batch accuracy: 0.59133
Time: 2018-07-15 03:30:55
TRAINING STATS: batch 120/486 in epoch 580,  batch loss: 1.60252, batch accuracy: 0.57667
Time: 2018-07-15 03:30:59
TRAINING STATS: batch 170/486 in epoch 580,  batch loss: 1.64004, batch accuracy: 0.55800
Time: 2018-07-15 03:31:04
TRAINING STATS: batch 220/486 in epoch 580,  batch loss: 1.58631, batch accuracy: 0.58050
Time: 2018-07-15 03:31:07
TRAINING STATS: batch 270/486 in epoch 580,  batch loss: 1.67449, batch accuracy: 0.54450
Time: 2018-07-15 03:31:11
TRAINING STATS: batch 320/486 in epoch 580,  batch loss: 1.60949, batch accuracy: 0.56750
Time: 2018-07-15 03:31:16
TRAINING STATS: batch 370/486 in epoch 580,  batch loss: 1.77429, batch accuracy: 0.52750
Time: 2018-07-15 03:31:20
TRAINING STATS: batch 420/486 in epoch 580,  batch loss: 1.72272, batch accuracy: 0.53600
Time: 2018-07-15 03:31:23
TRAINING STATS: batch 470/486 in epoch 580,  batch loss: 1.76703, batch accuracy: 0.52117
Time: 2018-07-15 03:31:28
TRAINING STATS: batch 34/486 in epoch 581,   batch loss: 1.71147, batch accuracy: 0.54367
Time: 2018-07-15 03:31:32
TRAINING STATS: batch 84/486 in epoch 581,   batch loss: 1.67786, batch accuracy: 0.53950
Time: 2018-07-15 03:31:35
TRAINING STATS: batch 134/486 in epoch 581,  batch loss: 1.69277, batch accuracy: 0.55217
Time: 2018-07-15 03:31:40
TRAINING STATS: batch 184/486 in epoch 581,  batch loss: 1.67612, batch accuracy: 0.55067
Time: 2018-07-15 03:31:44
TRAINING STATS: batch 234/486 in epoch 581,  batch loss: 1.75577, batch accuracy: 0.53417
Time: 2018-07-15 03:31:47
TRAINING STATS: batch 284/486 in epoch 581,  batch loss: 1.71428, batch accuracy: 0.53717
Time: 2018-07-15 03:31:52
TRAINING STATS: batch 334/486 in epoch 581,  batch loss: 1.65831, batch accuracy: 0.55617
Time: 2018-07-15 03:31:56
TRAINING STATS: batch 384/486 in epoch 581,  batch loss: 1.64048, batch accuracy: 0.56300
Time: 2018-07-15 03:31:59
TRAINING STATS: batch 434/486 in epoch 581,  batch loss: 1.70808, batch accuracy: 0.53700
Time: 2018-07-15 03:32:04
TRAINING STATS: batch 484/486 in epoch 581,  batch loss: 1.67950, batch accuracy: 0.55183
Time: 2018-07-15 03:32:08
TRAINING STATS: batch 48/486 in epoch 582,   batch loss: 1.67898, batch accuracy: 0.55450
Time: 2018-07-15 03:32:12
TRAINING STATS: batch 98/486 in epoch 582,   batch loss: 1.60671, batch accuracy: 0.56900
Time: 2018-07-15 03:32:16
TRAINING STATS: batch 148/486 in epoch 582,  batch loss: 1.73964, batch accuracy: 0.53500
Time: 2018-07-15 03:32:20
TRAINING STATS: batch 198/486 in epoch 582,  batch loss: 1.66577, batch accuracy: 0.55050
Time: 2018-07-15 03:32:24
TRAINING STATS: batch 248/486 in epoch 582,  batch loss: 1.69981, batch accuracy: 0.54283
Time: 2018-07-15 03:32:28
TRAINING STATS: batch 298/486 in epoch 582,  batch loss: 1.68872, batch accuracy: 0.54867
Time: 2018-07-15 03:32:32
TRAINING STATS: batch 348/486 in epoch 582,  batch loss: 1.71476, batch accuracy: 0.53567
Time: 2018-07-15 03:32:36
TRAINING STATS: batch 398/486 in epoch 582,  batch loss: 1.66594, batch accuracy: 0.55350
Time: 2018-07-15 03:32:40
TRAINING STATS: batch 448/486 in epoch 582,  batch loss: 1.68892, batch accuracy: 0.55400
Time: 2018-07-15 03:32:44
TRAINING STATS: batch 12/486 in epoch 583,   batch loss: 1.72594, batch accuracy: 0.52883
Time: 2018-07-15 03:32:48
TRAINING STATS: batch 62/486 in epoch 583,   batch loss: 1.75263, batch accuracy: 0.52850
Time: 2018-07-15 03:32:53
TRAINING STATS: batch 112/486 in epoch 583,  batch loss: 1.65710, batch accuracy: 0.56150
Time: 2018-07-15 03:32:56
TRAINING STATS: batch 162/486 in epoch 583,  batch loss: 1.67387, batch accuracy: 0.55600
Time: 2018-07-15 03:33:00
TRAINING STATS: batch 212/486 in epoch 583,  batch loss: 1.59918, batch accuracy: 0.57017
Time: 2018-07-15 03:33:05
TRAINING STATS: batch 262/486 in epoch 583,  batch loss: 1.72757, batch accuracy: 0.53150
Time: 2018-07-15 03:33:08
TRAINING STATS: batch 312/486 in epoch 583,  batch loss: 1.67843, batch accuracy: 0.54400
Time: 2018-07-15 03:33:12
TRAINING STATS: batch 362/486 in epoch 583,  batch loss: 1.84599, batch accuracy: 0.50050
Time: 2018-07-15 03:33:17
TRAINING STATS: batch 412/486 in epoch 583,  batch loss: 1.63704, batch accuracy: 0.56567
Time: 2018-07-15 03:33:20
TRAINING STATS: batch 462/486 in epoch 583,  batch loss: 1.68936, batch accuracy: 0.54850
Time: 2018-07-15 03:33:24
TRAINING STATS: batch 26/486 in epoch 584,   batch loss: 1.70624, batch accuracy: 0.54750
Time: 2018-07-15 03:33:29
TRAINING STATS: batch 76/486 in epoch 584,   batch loss: 1.73562, batch accuracy: 0.53367
Time: 2018-07-15 03:33:32
TRAINING STATS: batch 126/486 in epoch 584,  batch loss: 1.71189, batch accuracy: 0.54317
Time: 2018-07-15 03:33:36
TRAINING STATS: batch 176/486 in epoch 584,  batch loss: 1.59310, batch accuracy: 0.58117
Time: 2018-07-15 03:33:41
TRAINING STATS: batch 226/486 in epoch 584,  batch loss: 1.66007, batch accuracy: 0.56067
Time: 2018-07-15 03:33:45
TRAINING STATS: batch 276/486 in epoch 584,  batch loss: 1.65704, batch accuracy: 0.55417
Time: 2018-07-15 03:33:48
TRAINING STATS: batch 326/486 in epoch 584,  batch loss: 1.71830, batch accuracy: 0.53417
Time: 2018-07-15 03:33:53
TRAINING STATS: batch 376/486 in epoch 584,  batch loss: 1.70033, batch accuracy: 0.54400
Time: 2018-07-15 03:33:57
TRAINING STATS: batch 426/486 in epoch 584,  batch loss: 1.66236, batch accuracy: 0.54967
Time: 2018-07-15 03:34:00
TRAINING STATS: batch 476/486 in epoch 584,  batch loss: 1.63864, batch accuracy: 0.56600
Time: 2018-07-15 03:34:05
TRAINING STATS: batch 40/486 in epoch 585,   batch loss: 1.66626, batch accuracy: 0.55117
Time: 2018-07-15 03:34:09
TRAINING STATS: batch 90/486 in epoch 585,   batch loss: 1.71175, batch accuracy: 0.54217
Time: 2018-07-15 03:34:12
TRAINING STATS: batch 140/486 in epoch 585,  batch loss: 1.60530, batch accuracy: 0.57017
Time: 2018-07-15 03:34:17
TRAINING STATS: batch 190/486 in epoch 585,  batch loss: 1.62902, batch accuracy: 0.56317
Time: 2018-07-15 03:34:21
TRAINING STATS: batch 240/486 in epoch 585,  batch loss: 1.64597, batch accuracy: 0.55700
Time: 2018-07-15 03:34:24
TRAINING STATS: batch 290/486 in epoch 585,  batch loss: 1.69556, batch accuracy: 0.54150
Time: 2018-07-15 03:34:29
TRAINING STATS: batch 340/486 in epoch 585,  batch loss: 1.73890, batch accuracy: 0.52983
Time: 2018-07-15 03:34:33
TRAINING STATS: batch 390/486 in epoch 585,  batch loss: 1.60822, batch accuracy: 0.57467
Time: 2018-07-15 03:34:36
TRAINING STATS: batch 440/486 in epoch 585,  batch loss: 1.67401, batch accuracy: 0.55583
Time: 2018-07-15 03:34:41
TRAINING STATS: batch 4/486 in epoch 586,    batch loss: 1.65094, batch accuracy: 0.56067
Time: 2018-07-15 03:34:45
TRAINING STATS: batch 54/486 in epoch 586,   batch loss: 1.68455, batch accuracy: 0.54717
Time: 2018-07-15 03:34:48
TRAINING STATS: batch 104/486 in epoch 586,  batch loss: 1.70134, batch accuracy: 0.53883
Time: 2018-07-15 03:34:53
TRAINING STATS: batch 154/486 in epoch 586,  batch loss: 1.64317, batch accuracy: 0.55800
Time: 2018-07-15 03:34:57
TRAINING STATS: batch 204/486 in epoch 586,  batch loss: 1.74295, batch accuracy: 0.53067
Time: 2018-07-15 03:35:00
TRAINING STATS: batch 254/486 in epoch 586,  batch loss: 1.59456, batch accuracy: 0.57250
Time: 2018-07-15 03:35:05
TRAINING STATS: batch 304/486 in epoch 586,  batch loss: 1.62387, batch accuracy: 0.56667
Time: 2018-07-15 03:35:09
TRAINING STATS: batch 354/486 in epoch 586,  batch loss: 1.67455, batch accuracy: 0.55650
Time: 2018-07-15 03:35:12
TRAINING STATS: batch 404/486 in epoch 586,  batch loss: 1.65479, batch accuracy: 0.56333
Time: 2018-07-15 03:35:17
TRAINING STATS: batch 454/486 in epoch 586,  batch loss: 1.54323, batch accuracy: 0.59050
Time: 2018-07-15 03:35:21
TRAINING STATS: batch 18/486 in epoch 587,   batch loss: 1.68938, batch accuracy: 0.54900
Time: 2018-07-15 03:35:24
TRAINING STATS: batch 68/486 in epoch 587,   batch loss: 1.51309, batch accuracy: 0.59583
Time: 2018-07-15 03:35:29
TRAINING STATS: batch 118/486 in epoch 587,  batch loss: 1.65877, batch accuracy: 0.55783
Time: 2018-07-15 03:35:33
TRAINING STATS: batch 168/486 in epoch 587,  batch loss: 1.59229, batch accuracy: 0.58067
Time: 2018-07-15 03:35:36
TRAINING STATS: batch 218/486 in epoch 587,  batch loss: 1.64910, batch accuracy: 0.55133
Time: 2018-07-15 03:35:41
TRAINING STATS: batch 268/486 in epoch 587,  batch loss: 1.61027, batch accuracy: 0.55933
Time: 2018-07-15 03:35:45
TRAINING STATS: batch 318/486 in epoch 587,  batch loss: 1.66637, batch accuracy: 0.55033
Time: 2018-07-15 03:35:49
TRAINING STATS: batch 368/486 in epoch 587,  batch loss: 1.67336, batch accuracy: 0.54917
Time: 2018-07-15 03:35:53
TRAINING STATS: batch 418/486 in epoch 587,  batch loss: 1.73216, batch accuracy: 0.53717
Time: 2018-07-15 03:35:57
TRAINING STATS: batch 468/486 in epoch 587,  batch loss: 1.68480, batch accuracy: 0.54683
Time: 2018-07-15 03:36:01
TRAINING STATS: batch 32/486 in epoch 588,   batch loss: 1.61986, batch accuracy: 0.56150
Time: 2018-07-15 03:36:05
TRAINING STATS: batch 82/486 in epoch 588,   batch loss: 1.69088, batch accuracy: 0.53867
Time: 2018-07-15 03:36:09
TRAINING STATS: batch 132/486 in epoch 588,  batch loss: 1.63977, batch accuracy: 0.57183
Time: 2018-07-15 03:36:13
TRAINING STATS: batch 182/486 in epoch 588,  batch loss: 1.70951, batch accuracy: 0.53667
Time: 2018-07-15 03:36:17
TRAINING STATS: batch 232/486 in epoch 588,  batch loss: 1.68766, batch accuracy: 0.54867
Time: 2018-07-15 03:36:21
TRAINING STATS: batch 282/486 in epoch 588,  batch loss: 1.63126, batch accuracy: 0.55133
Time: 2018-07-15 03:36:25
TRAINING STATS: batch 332/486 in epoch 588,  batch loss: 1.69694, batch accuracy: 0.54583
Time: 2018-07-15 03:36:29
TRAINING STATS: batch 382/486 in epoch 588,  batch loss: 1.68649, batch accuracy: 0.55450
Time: 2018-07-15 03:36:33
TRAINING STATS: batch 432/486 in epoch 588,  batch loss: 1.58731, batch accuracy: 0.58183
Time: 2018-07-15 03:36:37
TRAINING STATS: batch 482/486 in epoch 588,  batch loss: 1.66390, batch accuracy: 0.55617
Time: 2018-07-15 03:36:41
TRAINING STATS: batch 46/486 in epoch 589,   batch loss: 1.69435, batch accuracy: 0.55033
Time: 2018-07-15 03:36:45
TRAINING STATS: batch 96/486 in epoch 589,   batch loss: 1.69115, batch accuracy: 0.54667
Time: 2018-07-15 03:36:49
TRAINING STATS: batch 146/486 in epoch 589,  batch loss: 1.77455, batch accuracy: 0.52267
Time: 2018-07-15 03:36:54
TRAINING STATS: batch 196/486 in epoch 589,  batch loss: 1.72486, batch accuracy: 0.54050
Time: 2018-07-15 03:36:57
TRAINING STATS: batch 246/486 in epoch 589,  batch loss: 1.63528, batch accuracy: 0.56250
Time: 2018-07-15 03:37:01
TRAINING STATS: batch 296/486 in epoch 589,  batch loss: 1.63080, batch accuracy: 0.55717
Time: 2018-07-15 03:37:06
TRAINING STATS: batch 346/486 in epoch 589,  batch loss: 1.59497, batch accuracy: 0.58367
Time: 2018-07-15 03:37:09
TRAINING STATS: batch 396/486 in epoch 589,  batch loss: 1.64993, batch accuracy: 0.56050
Time: 2018-07-15 03:37:13
TRAINING STATS: batch 446/486 in epoch 589,  batch loss: 1.68235, batch accuracy: 0.54700
Time: 2018-07-15 03:37:18
TRAINING STATS: batch 10/486 in epoch 590,   batch loss: 1.70121, batch accuracy: 0.54350
Time: 2018-07-15 03:37:21
TRAINING STATS: batch 60/486 in epoch 590,   batch loss: 1.65581, batch accuracy: 0.55517
Time: 2018-07-15 03:37:25
TRAINING STATS: batch 110/486 in epoch 590,  batch loss: 1.70333, batch accuracy: 0.54517
Time: 2018-07-15 03:37:30
TRAINING STATS: batch 160/486 in epoch 590,  batch loss: 1.63684, batch accuracy: 0.56050
Time: 2018-07-15 03:37:33
TRAINING STATS: batch 210/486 in epoch 590,  batch loss: 1.61050, batch accuracy: 0.56617
Time: 2018-07-15 03:37:37
TRAINING STATS: batch 260/486 in epoch 590,  batch loss: 1.70606, batch accuracy: 0.53283
Time: 2018-07-15 03:37:42
TRAINING STATS: batch 310/486 in epoch 590,  batch loss: 1.67568, batch accuracy: 0.54650
Time: 2018-07-15 03:37:45
TRAINING STATS: batch 360/486 in epoch 590,  batch loss: 1.72799, batch accuracy: 0.53300
Time: 2018-07-15 03:37:49
TRAINING STATS: batch 410/486 in epoch 590,  batch loss: 1.62611, batch accuracy: 0.56683
Time: 2018-07-15 03:37:54
TRAINING STATS: batch 460/486 in epoch 590,  batch loss: 1.78404, batch accuracy: 0.51583
Time: 2018-07-15 03:37:57
TRAINING STATS: batch 24/486 in epoch 591,   batch loss: 1.74088, batch accuracy: 0.53400
Time: 2018-07-15 03:38:01
TRAINING STATS: batch 74/486 in epoch 591,   batch loss: 1.71736, batch accuracy: 0.53967
Time: 2018-07-15 03:38:06
TRAINING STATS: batch 124/486 in epoch 591,  batch loss: 1.68511, batch accuracy: 0.55417
Time: 2018-07-15 03:38:10
TRAINING STATS: batch 174/486 in epoch 591,  batch loss: 1.76665, batch accuracy: 0.52350
Time: 2018-07-15 03:38:13
TRAINING STATS: batch 224/486 in epoch 591,  batch loss: 1.71400, batch accuracy: 0.54217
Time: 2018-07-15 03:38:18
TRAINING STATS: batch 274/486 in epoch 591,  batch loss: 1.71417, batch accuracy: 0.52983
Time: 2018-07-15 03:38:22
TRAINING STATS: batch 324/486 in epoch 591,  batch loss: 1.70961, batch accuracy: 0.54250
Time: 2018-07-15 03:38:25
TRAINING STATS: batch 374/486 in epoch 591,  batch loss: 1.70947, batch accuracy: 0.54483
Time: 2018-07-15 03:38:30
TRAINING STATS: batch 424/486 in epoch 591,  batch loss: 1.62852, batch accuracy: 0.55917
Time: 2018-07-15 03:38:34
TRAINING STATS: batch 474/486 in epoch 591,  batch loss: 1.67933, batch accuracy: 0.54500
Time: 2018-07-15 03:38:37
TRAINING STATS: batch 38/486 in epoch 592,   batch loss: 1.68772, batch accuracy: 0.55083
Time: 2018-07-15 03:38:42
TRAINING STATS: batch 88/486 in epoch 592,   batch loss: 1.70876, batch accuracy: 0.53900
Time: 2018-07-15 03:38:46
TRAINING STATS: batch 138/486 in epoch 592,  batch loss: 1.70315, batch accuracy: 0.53700
Time: 2018-07-15 03:38:49
TRAINING STATS: batch 188/486 in epoch 592,  batch loss: 1.62261, batch accuracy: 0.56683
Time: 2018-07-15 03:38:54
TRAINING STATS: batch 238/486 in epoch 592,  batch loss: 1.64382, batch accuracy: 0.55517
Time: 2018-07-15 03:38:58
TRAINING STATS: batch 288/486 in epoch 592,  batch loss: 1.70274, batch accuracy: 0.54250
Time: 2018-07-15 03:39:01
TRAINING STATS: batch 338/486 in epoch 592,  batch loss: 1.66535, batch accuracy: 0.54800
Time: 2018-07-15 03:39:06
TRAINING STATS: batch 388/486 in epoch 592,  batch loss: 1.65285, batch accuracy: 0.55550
Time: 2018-07-15 03:39:10
TRAINING STATS: batch 438/486 in epoch 592,  batch loss: 1.70823, batch accuracy: 0.54383
Time: 2018-07-15 03:39:14
TRAINING STATS: batch 2/486 in epoch 593,    batch loss: 1.70208, batch accuracy: 0.54100
Time: 2018-07-15 03:39:18
TRAINING STATS: batch 52/486 in epoch 593,   batch loss: 1.74636, batch accuracy: 0.52950
Time: 2018-07-15 03:39:22
TRAINING STATS: batch 102/486 in epoch 593,  batch loss: 1.69802, batch accuracy: 0.54933
Time: 2018-07-15 03:39:26
TRAINING STATS: batch 152/486 in epoch 593,  batch loss: 1.63802, batch accuracy: 0.56233
Time: 2018-07-15 03:39:30
TRAINING STATS: batch 202/486 in epoch 593,  batch loss: 1.68167, batch accuracy: 0.55050
Time: 2018-07-15 03:39:34
TRAINING STATS: batch 252/486 in epoch 593,  batch loss: 1.64650, batch accuracy: 0.56217
Time: 2018-07-15 03:39:38
TRAINING STATS: batch 302/486 in epoch 593,  batch loss: 1.61743, batch accuracy: 0.55817
Time: 2018-07-15 03:39:42
TRAINING STATS: batch 352/486 in epoch 593,  batch loss: 1.71747, batch accuracy: 0.54633
Time: 2018-07-15 03:39:46
TRAINING STATS: batch 402/486 in epoch 593,  batch loss: 1.53854, batch accuracy: 0.59250
Time: 2018-07-15 03:39:50
TRAINING STATS: batch 452/486 in epoch 593,  batch loss: 1.66959, batch accuracy: 0.55267
Time: 2018-07-15 03:39:55
TRAINING STATS: batch 16/486 in epoch 594,   batch loss: 1.62907, batch accuracy: 0.56817
Time: 2018-07-15 03:39:58
TRAINING STATS: batch 66/486 in epoch 594,   batch loss: 1.66523, batch accuracy: 0.55617
Time: 2018-07-15 03:40:02
TRAINING STATS: batch 116/486 in epoch 594,  batch loss: 1.63334, batch accuracy: 0.56033
Time: 2018-07-15 03:40:06
TRAINING STATS: batch 166/486 in epoch 594,  batch loss: 1.57206, batch accuracy: 0.58117
Time: 2018-07-15 03:40:10
TRAINING STATS: batch 216/486 in epoch 594,  batch loss: 1.68753, batch accuracy: 0.55333
Time: 2018-07-15 03:40:14
TRAINING STATS: batch 266/486 in epoch 594,  batch loss: 1.67390, batch accuracy: 0.55600
Time: 2018-07-15 03:40:19
TRAINING STATS: batch 316/486 in epoch 594,  batch loss: 1.66365, batch accuracy: 0.55433
Time: 2018-07-15 03:40:22
TRAINING STATS: batch 366/486 in epoch 594,  batch loss: 1.72637, batch accuracy: 0.53550
Time: 2018-07-15 03:40:26
TRAINING STATS: batch 416/486 in epoch 594,  batch loss: 1.72110, batch accuracy: 0.54000
Time: 2018-07-15 03:40:31
TRAINING STATS: batch 466/486 in epoch 594,  batch loss: 1.53931, batch accuracy: 0.58850
Time: 2018-07-15 03:40:34
TRAINING STATS: batch 30/486 in epoch 595,   batch loss: 1.55760, batch accuracy: 0.58233
Time: 2018-07-15 03:40:38
TRAINING STATS: batch 80/486 in epoch 595,   batch loss: 1.66776, batch accuracy: 0.54917
Time: 2018-07-15 03:40:43
TRAINING STATS: batch 130/486 in epoch 595,  batch loss: 1.65370, batch accuracy: 0.56533
Time: 2018-07-15 03:40:46
TRAINING STATS: batch 180/486 in epoch 595,  batch loss: 1.69229, batch accuracy: 0.54717
Time: 2018-07-15 03:40:50
TRAINING STATS: batch 230/486 in epoch 595,  batch loss: 1.70399, batch accuracy: 0.53433
Time: 2018-07-15 03:40:55
TRAINING STATS: batch 280/486 in epoch 595,  batch loss: 1.67341, batch accuracy: 0.55233
Time: 2018-07-15 03:40:58
TRAINING STATS: batch 330/486 in epoch 595,  batch loss: 1.64136, batch accuracy: 0.55600
Time: 2018-07-15 03:41:02
TRAINING STATS: batch 380/486 in epoch 595,  batch loss: 1.65763, batch accuracy: 0.55450
Time: 2018-07-15 03:41:07
TRAINING STATS: batch 430/486 in epoch 595,  batch loss: 1.60483, batch accuracy: 0.57617
Time: 2018-07-15 03:41:11
TRAINING STATS: batch 480/486 in epoch 595,  batch loss: 1.66412, batch accuracy: 0.55800
Time: 2018-07-15 03:41:14
TRAINING STATS: batch 44/486 in epoch 596,   batch loss: 1.61642, batch accuracy: 0.56633
Time: 2018-07-15 03:41:19
TRAINING STATS: batch 94/486 in epoch 596,   batch loss: 1.71364, batch accuracy: 0.54250
Time: 2018-07-15 03:41:23
TRAINING STATS: batch 144/486 in epoch 596,  batch loss: 1.73260, batch accuracy: 0.53333
Time: 2018-07-15 03:41:26
TRAINING STATS: batch 194/486 in epoch 596,  batch loss: 1.76157, batch accuracy: 0.52600
Time: 2018-07-15 03:41:31
TRAINING STATS: batch 244/486 in epoch 596,  batch loss: 1.67095, batch accuracy: 0.55417
Time: 2018-07-15 03:41:35
TRAINING STATS: batch 294/486 in epoch 596,  batch loss: 1.59076, batch accuracy: 0.57800
Time: 2018-07-15 03:41:38
TRAINING STATS: batch 344/486 in epoch 596,  batch loss: 1.65206, batch accuracy: 0.55567
Time: 2018-07-15 03:41:43
TRAINING STATS: batch 394/486 in epoch 596,  batch loss: 1.62695, batch accuracy: 0.57500
Time: 2018-07-15 03:41:47
TRAINING STATS: batch 444/486 in epoch 596,  batch loss: 1.60151, batch accuracy: 0.57267
Time: 2018-07-15 03:41:50
TRAINING STATS: batch 8/486 in epoch 597,    batch loss: 1.64721, batch accuracy: 0.55817
Time: 2018-07-15 03:41:55
TRAINING STATS: batch 58/486 in epoch 597,   batch loss: 1.62979, batch accuracy: 0.56633
Time: 2018-07-15 03:41:59
TRAINING STATS: batch 108/486 in epoch 597,  batch loss: 1.72500, batch accuracy: 0.54133
Time: 2018-07-15 03:42:02
TRAINING STATS: batch 158/486 in epoch 597,  batch loss: 1.72122, batch accuracy: 0.53883
Time: 2018-07-15 03:42:07
TRAINING STATS: batch 208/486 in epoch 597,  batch loss: 1.68754, batch accuracy: 0.55417
Time: 2018-07-15 03:42:11
TRAINING STATS: batch 258/486 in epoch 597,  batch loss: 1.65017, batch accuracy: 0.56167
Time: 2018-07-15 03:42:14
TRAINING STATS: batch 308/486 in epoch 597,  batch loss: 1.67771, batch accuracy: 0.56150
Time: 2018-07-15 03:42:19
TRAINING STATS: batch 358/486 in epoch 597,  batch loss: 1.69187, batch accuracy: 0.54600
Time: 2018-07-15 03:42:23
TRAINING STATS: batch 408/486 in epoch 597,  batch loss: 1.72095, batch accuracy: 0.53783
Time: 2018-07-15 03:42:27
TRAINING STATS: batch 458/486 in epoch 597,  batch loss: 1.68929, batch accuracy: 0.54767
Time: 2018-07-15 03:42:31
TRAINING STATS: batch 22/486 in epoch 598,   batch loss: 1.72600, batch accuracy: 0.54683
Time: 2018-07-15 03:42:35
TRAINING STATS: batch 72/486 in epoch 598,   batch loss: 1.71211, batch accuracy: 0.53133
Time: 2018-07-15 03:42:39
TRAINING STATS: batch 122/486 in epoch 598,  batch loss: 1.61162, batch accuracy: 0.57383
Time: 2018-07-15 03:42:43
TRAINING STATS: batch 172/486 in epoch 598,  batch loss: 1.73274, batch accuracy: 0.53667
Time: 2018-07-15 03:42:47
TRAINING STATS: batch 222/486 in epoch 598,  batch loss: 1.67608, batch accuracy: 0.54733
Time: 2018-07-15 03:42:51
TRAINING STATS: batch 272/486 in epoch 598,  batch loss: 1.68339, batch accuracy: 0.54617
Time: 2018-07-15 03:42:55
TRAINING STATS: batch 322/486 in epoch 598,  batch loss: 1.65456, batch accuracy: 0.55667
Time: 2018-07-15 03:42:59
TRAINING STATS: batch 372/486 in epoch 598,  batch loss: 1.61392, batch accuracy: 0.56717
Time: 2018-07-15 03:43:03
TRAINING STATS: batch 422/486 in epoch 598,  batch loss: 1.63474, batch accuracy: 0.55850
Time: 2018-07-15 03:43:08
TRAINING STATS: batch 472/486 in epoch 598,  batch loss: 1.87896, batch accuracy: 0.48583
Time: 2018-07-15 03:43:11
TRAINING STATS: batch 36/486 in epoch 599,   batch loss: 1.73936, batch accuracy: 0.53750
Time: 2018-07-15 03:43:15
TRAINING STATS: batch 86/486 in epoch 599,   batch loss: 1.66267, batch accuracy: 0.55400
Time: 2018-07-15 03:43:20
TRAINING STATS: batch 136/486 in epoch 599,  batch loss: 1.70588, batch accuracy: 0.54200
Time: 2018-07-15 03:43:23
TRAINING STATS: batch 186/486 in epoch 599,  batch loss: 1.66827, batch accuracy: 0.55933
Time: 2018-07-15 03:43:27
TRAINING STATS: batch 236/486 in epoch 599,  batch loss: 1.70317, batch accuracy: 0.54467
Time: 2018-07-15 03:43:32
TRAINING STATS: batch 286/486 in epoch 599,  batch loss: 1.70550, batch accuracy: 0.54750
Time: 2018-07-15 03:43:35
TRAINING STATS: batch 336/486 in epoch 599,  batch loss: 1.66021, batch accuracy: 0.55933
Time: 2018-07-15 03:43:39
TRAINING STATS: batch 386/486 in epoch 599,  batch loss: 1.70799, batch accuracy: 0.54200
Time: 2018-07-15 03:43:44
TRAINING STATS: batch 436/486 in epoch 599,  batch loss: 1.67268, batch accuracy: 0.55133
Time: 2018-07-15 03:43:47
TRAINING STATS: batch 0/486 in epoch 600,    batch loss: 1.65276, batch accuracy: 0.55917
Time: 2018-07-15 03:43:51
TRAINING STATS: batch 50/486 in epoch 600,   batch loss: 1.65724, batch accuracy: 0.56867
Time: 2018-07-15 03:43:56
TRAINING STATS: batch 100/486 in epoch 600,  batch loss: 1.68728, batch accuracy: 0.55033
Time: 2018-07-15 03:43:59
TRAINING STATS: batch 150/486 in epoch 600,  batch loss: 1.63770, batch accuracy: 0.57100
Time: 2018-07-15 03:44:03
TRAINING STATS: batch 200/486 in epoch 600,  batch loss: 1.55418, batch accuracy: 0.59283
Time: 2018-07-15 03:44:08
TRAINING STATS: batch 250/486 in epoch 600,  batch loss: 1.72679, batch accuracy: 0.52567
Time: 2018-07-15 03:44:11
TRAINING STATS: batch 300/486 in epoch 600,  batch loss: 1.69681, batch accuracy: 0.53617
Time: 2018-07-15 03:44:15
TRAINING STATS: batch 350/486 in epoch 600,  batch loss: 1.66571, batch accuracy: 0.55683
Time: 2018-07-15 03:44:20
TRAINING STATS: batch 400/486 in epoch 600,  batch loss: 1.54813, batch accuracy: 0.58583
Time: 2018-07-15 03:44:24
TRAINING STATS: batch 450/486 in epoch 600,  batch loss: 1.71902, batch accuracy: 0.53050
Time: 2018-07-15 03:44:27
TRAINING STATS: batch 14/486 in epoch 601,   batch loss: 1.57960, batch accuracy: 0.58333
Time: 2018-07-15 03:44:32
TRAINING STATS: batch 64/486 in epoch 601,   batch loss: 1.76113, batch accuracy: 0.52817
Time: 2018-07-15 03:44:36
TRAINING STATS: batch 114/486 in epoch 601,  batch loss: 1.70519, batch accuracy: 0.54750
Time: 2018-07-15 03:44:39
TRAINING STATS: batch 164/486 in epoch 601,  batch loss: 1.59184, batch accuracy: 0.58217
Time: 2018-07-15 03:44:44
TRAINING STATS: batch 214/486 in epoch 601,  batch loss: 1.65684, batch accuracy: 0.56267
Time: 2018-07-15 03:44:48
TRAINING STATS: batch 264/486 in epoch 601,  batch loss: 1.68762, batch accuracy: 0.55233
Time: 2018-07-15 03:44:51
TRAINING STATS: batch 314/486 in epoch 601,  batch loss: 1.71228, batch accuracy: 0.53800
Time: 2018-07-15 03:44:56
TRAINING STATS: batch 364/486 in epoch 601,  batch loss: 1.64311, batch accuracy: 0.56700
Time: 2018-07-15 03:45:00
TRAINING STATS: batch 414/486 in epoch 601,  batch loss: 1.58812, batch accuracy: 0.57767
Time: 2018-07-15 03:45:03
TRAINING STATS: batch 464/486 in epoch 601,  batch loss: 1.61677, batch accuracy: 0.57067
Time: 2018-07-15 03:45:08
TRAINING STATS: batch 28/486 in epoch 602,   batch loss: 1.58712, batch accuracy: 0.57550
Time: 2018-07-15 03:45:12
TRAINING STATS: batch 78/486 in epoch 602,   batch loss: 1.65553, batch accuracy: 0.56550
Time: 2018-07-15 03:45:15
TRAINING STATS: batch 128/486 in epoch 602,  batch loss: 1.63046, batch accuracy: 0.56583
Time: 2018-07-15 03:45:20
TRAINING STATS: batch 178/486 in epoch 602,  batch loss: 1.57465, batch accuracy: 0.57550
Time: 2018-07-15 03:45:24
TRAINING STATS: batch 228/486 in epoch 602,  batch loss: 1.60026, batch accuracy: 0.57133
Time: 2018-07-15 03:45:27
TRAINING STATS: batch 278/486 in epoch 602,  batch loss: 1.59964, batch accuracy: 0.57500
Time: 2018-07-15 03:45:32
TRAINING STATS: batch 328/486 in epoch 602,  batch loss: 1.62055, batch accuracy: 0.56767
Time: 2018-07-15 03:45:36
TRAINING STATS: batch 378/486 in epoch 602,  batch loss: 1.64767, batch accuracy: 0.56500
Time: 2018-07-15 03:45:39
TRAINING STATS: batch 428/486 in epoch 602,  batch loss: 1.70700, batch accuracy: 0.53883
Time: 2018-07-15 03:45:44
TRAINING STATS: batch 478/486 in epoch 602,  batch loss: 1.66200, batch accuracy: 0.55633
Time: 2018-07-15 03:45:48
TRAINING STATS: batch 42/486 in epoch 603,   batch loss: 1.58219, batch accuracy: 0.57817
Time: 2018-07-15 03:45:51
TRAINING STATS: batch 92/486 in epoch 603,   batch loss: 1.68431, batch accuracy: 0.54767
Time: 2018-07-15 03:45:56
TRAINING STATS: batch 142/486 in epoch 603,  batch loss: 1.62602, batch accuracy: 0.57150
Time: 2018-07-15 03:46:00
TRAINING STATS: batch 192/486 in epoch 603,  batch loss: 1.66181, batch accuracy: 0.55433
Time: 2018-07-15 03:46:03
TRAINING STATS: batch 242/486 in epoch 603,  batch loss: 1.62961, batch accuracy: 0.56383
Time: 2018-07-15 03:46:08
TRAINING STATS: batch 292/486 in epoch 603,  batch loss: 1.64236, batch accuracy: 0.55783
Time: 2018-07-15 03:46:12
TRAINING STATS: batch 342/486 in epoch 603,  batch loss: 1.62697, batch accuracy: 0.55767
Time: 2018-07-15 03:46:15
TRAINING STATS: batch 392/486 in epoch 603,  batch loss: 1.58289, batch accuracy: 0.57900
Time: 2018-07-15 03:46:20
TRAINING STATS: batch 442/486 in epoch 603,  batch loss: 1.57495, batch accuracy: 0.58167
Time: 2018-07-15 03:46:24
TRAINING STATS: batch 6/486 in epoch 604,    batch loss: 1.70307, batch accuracy: 0.54917
Time: 2018-07-15 03:46:28
TRAINING STATS: batch 56/486 in epoch 604,   batch loss: 1.60929, batch accuracy: 0.56817
Time: 2018-07-15 03:46:32
TRAINING STATS: batch 106/486 in epoch 604,  batch loss: 1.75522, batch accuracy: 0.52400
Time: 2018-07-15 03:46:36
TRAINING STATS: batch 156/486 in epoch 604,  batch loss: 1.68399, batch accuracy: 0.54450
Time: 2018-07-15 03:46:40
TRAINING STATS: batch 206/486 in epoch 604,  batch loss: 1.75068, batch accuracy: 0.52933
Time: 2018-07-15 03:46:45
TRAINING STATS: batch 256/486 in epoch 604,  batch loss: 1.59210, batch accuracy: 0.57333
Time: 2018-07-15 03:46:48
TRAINING STATS: batch 306/486 in epoch 604,  batch loss: 1.63916, batch accuracy: 0.56300
Time: 2018-07-15 03:46:52
TRAINING STATS: batch 356/486 in epoch 604,  batch loss: 1.71307, batch accuracy: 0.54017
Time: 2018-07-15 03:46:56
TRAINING STATS: batch 406/486 in epoch 604,  batch loss: 1.71916, batch accuracy: 0.53400
Time: 2018-07-15 03:47:00
TRAINING STATS: batch 456/486 in epoch 604,  batch loss: 1.57347, batch accuracy: 0.58383
Time: 2018-07-15 03:47:04
TRAINING STATS: batch 20/486 in epoch 605,   batch loss: 1.66668, batch accuracy: 0.54867
Time: 2018-07-15 03:47:09
TRAINING STATS: batch 70/486 in epoch 605,   batch loss: 1.54452, batch accuracy: 0.59383
Time: 2018-07-15 03:47:12
TRAINING STATS: batch 120/486 in epoch 605,  batch loss: 1.59655, batch accuracy: 0.57567
Time: 2018-07-15 03:47:16
TRAINING STATS: batch 170/486 in epoch 605,  batch loss: 1.65459, batch accuracy: 0.56133
Time: 2018-07-15 03:47:21
TRAINING STATS: batch 220/486 in epoch 605,  batch loss: 1.57864, batch accuracy: 0.58800
Time: 2018-07-15 03:47:24
TRAINING STATS: batch 270/486 in epoch 605,  batch loss: 1.66046, batch accuracy: 0.54617
Time: 2018-07-15 03:47:28
TRAINING STATS: batch 320/486 in epoch 605,  batch loss: 1.58382, batch accuracy: 0.57883
Time: 2018-07-15 03:47:33
TRAINING STATS: batch 370/486 in epoch 605,  batch loss: 1.63860, batch accuracy: 0.56533
Time: 2018-07-15 03:47:36
TRAINING STATS: batch 420/486 in epoch 605,  batch loss: 1.67879, batch accuracy: 0.54883
Time: 2018-07-15 03:47:40
TRAINING STATS: batch 470/486 in epoch 605,  batch loss: 1.73766, batch accuracy: 0.52817
Time: 2018-07-15 03:47:45
TRAINING STATS: batch 34/486 in epoch 606,   batch loss: 1.67224, batch accuracy: 0.55233
Time: 2018-07-15 03:47:49
TRAINING STATS: batch 84/486 in epoch 606,   batch loss: 1.66069, batch accuracy: 0.54767
Time: 2018-07-15 03:47:52
TRAINING STATS: batch 134/486 in epoch 606,  batch loss: 1.67782, batch accuracy: 0.55750
Time: 2018-07-15 03:47:57
TRAINING STATS: batch 184/486 in epoch 606,  batch loss: 1.66556, batch accuracy: 0.54733
Time: 2018-07-15 03:48:01
TRAINING STATS: batch 234/486 in epoch 606,  batch loss: 1.72834, batch accuracy: 0.53700
Time: 2018-07-15 03:48:04
TRAINING STATS: batch 284/486 in epoch 606,  batch loss: 1.70204, batch accuracy: 0.54250
Time: 2018-07-15 03:48:09
TRAINING STATS: batch 334/486 in epoch 606,  batch loss: 1.63721, batch accuracy: 0.56333
Time: 2018-07-15 03:48:13
TRAINING STATS: batch 384/486 in epoch 606,  batch loss: 1.61748, batch accuracy: 0.57383
Time: 2018-07-15 03:48:16
TRAINING STATS: batch 434/486 in epoch 606,  batch loss: 1.69161, batch accuracy: 0.54167
Time: 2018-07-15 03:48:21
TRAINING STATS: batch 484/486 in epoch 606,  batch loss: 1.65790, batch accuracy: 0.55400
Time: 2018-07-15 03:48:24
TRAINING STATS: batch 48/486 in epoch 607,   batch loss: 1.66366, batch accuracy: 0.55150
Time: 2018-07-15 03:48:28
TRAINING STATS: batch 98/486 in epoch 607,   batch loss: 1.60267, batch accuracy: 0.56850
Time: 2018-07-15 03:48:33
TRAINING STATS: batch 148/486 in epoch 607,  batch loss: 1.68811, batch accuracy: 0.55583
Time: 2018-07-15 03:48:37
TRAINING STATS: batch 198/486 in epoch 607,  batch loss: 1.64337, batch accuracy: 0.55900
Time: 2018-07-15 03:48:40
TRAINING STATS: batch 248/486 in epoch 607,  batch loss: 1.67490, batch accuracy: 0.55700
Time: 2018-07-15 03:48:45
TRAINING STATS: batch 298/486 in epoch 607,  batch loss: 1.70242, batch accuracy: 0.53217
Time: 2018-07-15 03:48:49
TRAINING STATS: batch 348/486 in epoch 607,  batch loss: 1.65354, batch accuracy: 0.56367
Time: 2018-07-15 03:48:52
TRAINING STATS: batch 398/486 in epoch 607,  batch loss: 1.66342, batch accuracy: 0.55650
Time: 2018-07-15 03:48:57
TRAINING STATS: batch 448/486 in epoch 607,  batch loss: 1.64682, batch accuracy: 0.56833
Time: 2018-07-15 03:49:01
TRAINING STATS: batch 12/486 in epoch 608,   batch loss: 1.67747, batch accuracy: 0.54533
Time: 2018-07-15 03:49:04
TRAINING STATS: batch 62/486 in epoch 608,   batch loss: 1.73307, batch accuracy: 0.53167
Time: 2018-07-15 03:49:09
TRAINING STATS: batch 112/486 in epoch 608,  batch loss: 1.65799, batch accuracy: 0.55883
Time: 2018-07-15 03:49:13
TRAINING STATS: batch 162/486 in epoch 608,  batch loss: 1.66315, batch accuracy: 0.55833
Time: 2018-07-15 03:49:16
TRAINING STATS: batch 212/486 in epoch 608,  batch loss: 1.57261, batch accuracy: 0.57583
Time: 2018-07-15 03:49:21
TRAINING STATS: batch 262/486 in epoch 608,  batch loss: 1.72352, batch accuracy: 0.53617
Time: 2018-07-15 03:49:25
TRAINING STATS: batch 312/486 in epoch 608,  batch loss: 1.66158, batch accuracy: 0.54517
Time: 2018-07-15 03:49:29
TRAINING STATS: batch 362/486 in epoch 608,  batch loss: 1.66124, batch accuracy: 0.55683
Time: 2018-07-15 03:49:33
TRAINING STATS: batch 412/486 in epoch 608,  batch loss: 1.60150, batch accuracy: 0.57283
Time: 2018-07-15 03:49:37
TRAINING STATS: batch 462/486 in epoch 608,  batch loss: 1.66416, batch accuracy: 0.55533
Time: 2018-07-15 03:49:41
TRAINING STATS: batch 26/486 in epoch 609,   batch loss: 1.70337, batch accuracy: 0.54583
Time: 2018-07-15 03:49:45
TRAINING STATS: batch 76/486 in epoch 609,   batch loss: 1.72365, batch accuracy: 0.53383
Time: 2018-07-15 03:49:49
TRAINING STATS: batch 126/486 in epoch 609,  batch loss: 1.69529, batch accuracy: 0.54283
Time: 2018-07-15 03:49:53
TRAINING STATS: batch 176/486 in epoch 609,  batch loss: 1.59288, batch accuracy: 0.57467
Time: 2018-07-15 03:49:58
TRAINING STATS: batch 226/486 in epoch 609,  batch loss: 1.63969, batch accuracy: 0.56267
Time: 2018-07-15 03:50:01
TRAINING STATS: batch 276/486 in epoch 609,  batch loss: 1.64412, batch accuracy: 0.55833
Time: 2018-07-15 03:50:05
TRAINING STATS: batch 326/486 in epoch 609,  batch loss: 1.68728, batch accuracy: 0.54967
Time: 2018-07-15 03:50:10
TRAINING STATS: batch 376/486 in epoch 609,  batch loss: 1.68341, batch accuracy: 0.55017
Time: 2018-07-15 03:50:13
TRAINING STATS: batch 426/486 in epoch 609,  batch loss: 1.64118, batch accuracy: 0.55800
Time: 2018-07-15 03:50:17
TRAINING STATS: batch 476/486 in epoch 609,  batch loss: 1.61706, batch accuracy: 0.56417
Time: 2018-07-15 03:50:22
TRAINING STATS: batch 40/486 in epoch 610,   batch loss: 1.61454, batch accuracy: 0.56750
Time: 2018-07-15 03:50:25
TRAINING STATS: batch 90/486 in epoch 610,   batch loss: 1.69122, batch accuracy: 0.55167
Time: 2018-07-15 03:50:29
TRAINING STATS: batch 140/486 in epoch 610,  batch loss: 1.57943, batch accuracy: 0.57800
Time: 2018-07-15 03:50:34
TRAINING STATS: batch 190/486 in epoch 610,  batch loss: 1.62047, batch accuracy: 0.56367
Time: 2018-07-15 03:50:37
TRAINING STATS: batch 240/486 in epoch 610,  batch loss: 1.62836, batch accuracy: 0.56333
Time: 2018-07-15 03:50:41
TRAINING STATS: batch 290/486 in epoch 610,  batch loss: 1.65716, batch accuracy: 0.55283
Time: 2018-07-15 03:50:46
TRAINING STATS: batch 340/486 in epoch 610,  batch loss: 1.73426, batch accuracy: 0.53200
Time: 2018-07-15 03:50:49
TRAINING STATS: batch 390/486 in epoch 610,  batch loss: 1.59136, batch accuracy: 0.57917
Time: 2018-07-15 03:50:53
TRAINING STATS: batch 440/486 in epoch 610,  batch loss: 1.65327, batch accuracy: 0.55583
Time: 2018-07-15 03:50:58
TRAINING STATS: batch 4/486 in epoch 611,    batch loss: 1.59268, batch accuracy: 0.58100
Time: 2018-07-15 03:51:01
TRAINING STATS: batch 54/486 in epoch 611,   batch loss: 1.66677, batch accuracy: 0.54717
Time: 2018-07-15 03:51:05
TRAINING STATS: batch 104/486 in epoch 611,  batch loss: 1.66084, batch accuracy: 0.55350
Time: 2018-07-15 03:51:10
TRAINING STATS: batch 154/486 in epoch 611,  batch loss: 1.63362, batch accuracy: 0.56133
Time: 2018-07-15 03:51:14
TRAINING STATS: batch 204/486 in epoch 611,  batch loss: 1.72949, batch accuracy: 0.54117
Time: 2018-07-15 03:51:17
TRAINING STATS: batch 254/486 in epoch 611,  batch loss: 1.58314, batch accuracy: 0.58017
Time: 2018-07-15 03:51:22
TRAINING STATS: batch 304/486 in epoch 611,  batch loss: 1.60831, batch accuracy: 0.57083
Time: 2018-07-15 03:51:26
TRAINING STATS: batch 354/486 in epoch 611,  batch loss: 1.64874, batch accuracy: 0.55950
Time: 2018-07-15 03:51:29
TRAINING STATS: batch 404/486 in epoch 611,  batch loss: 1.62992, batch accuracy: 0.56400
Time: 2018-07-15 03:51:34
TRAINING STATS: batch 454/486 in epoch 611,  batch loss: 1.52975, batch accuracy: 0.59833
Time: 2018-07-15 03:51:38
TRAINING STATS: batch 18/486 in epoch 612,   batch loss: 1.69715, batch accuracy: 0.54517
Time: 2018-07-15 03:51:41
TRAINING STATS: batch 68/486 in epoch 612,   batch loss: 1.49634, batch accuracy: 0.60867
Time: 2018-07-15 03:51:46
TRAINING STATS: batch 118/486 in epoch 612,  batch loss: 1.64168, batch accuracy: 0.56233
Time: 2018-07-15 03:51:50
TRAINING STATS: batch 168/486 in epoch 612,  batch loss: 1.56812, batch accuracy: 0.58383
Time: 2018-07-15 03:51:53
TRAINING STATS: batch 218/486 in epoch 612,  batch loss: 1.63239, batch accuracy: 0.56150
Time: 2018-07-15 03:51:58
TRAINING STATS: batch 268/486 in epoch 612,  batch loss: 1.58822, batch accuracy: 0.57050
Time: 2018-07-15 03:52:02
TRAINING STATS: batch 318/486 in epoch 612,  batch loss: 1.65205, batch accuracy: 0.55717
Time: 2018-07-15 03:52:05
TRAINING STATS: batch 368/486 in epoch 612,  batch loss: 1.66554, batch accuracy: 0.54867
Time: 2018-07-15 03:52:10
TRAINING STATS: batch 418/486 in epoch 612,  batch loss: 1.72524, batch accuracy: 0.53400
Time: 2018-07-15 03:52:14
TRAINING STATS: batch 468/486 in epoch 612,  batch loss: 1.66168, batch accuracy: 0.55683
Time: 2018-07-15 03:52:17
TRAINING STATS: batch 32/486 in epoch 613,   batch loss: 1.60060, batch accuracy: 0.56717
Time: 2018-07-15 03:52:22
TRAINING STATS: batch 82/486 in epoch 613,   batch loss: 1.68530, batch accuracy: 0.54167
Time: 2018-07-15 03:52:26
TRAINING STATS: batch 132/486 in epoch 613,  batch loss: 1.64350, batch accuracy: 0.56450
Time: 2018-07-15 03:52:30
TRAINING STATS: batch 182/486 in epoch 613,  batch loss: 1.71710, batch accuracy: 0.53600
Time: 2018-07-15 03:52:34
TRAINING STATS: batch 232/486 in epoch 613,  batch loss: 1.68661, batch accuracy: 0.54917
Time: 2018-07-15 03:52:38
TRAINING STATS: batch 282/486 in epoch 613,  batch loss: 1.60089, batch accuracy: 0.56233
Time: 2018-07-15 03:52:42
TRAINING STATS: batch 332/486 in epoch 613,  batch loss: 1.67784, batch accuracy: 0.55017
Time: 2018-07-15 03:52:46
TRAINING STATS: batch 382/486 in epoch 613,  batch loss: 1.67329, batch accuracy: 0.55150
Time: 2018-07-15 03:52:50
TRAINING STATS: batch 432/486 in epoch 613,  batch loss: 1.57943, batch accuracy: 0.57783
Time: 2018-07-15 03:52:54
TRAINING STATS: batch 482/486 in epoch 613,  batch loss: 1.61609, batch accuracy: 0.57250
Time: 2018-07-15 03:52:58
TRAINING STATS: batch 46/486 in epoch 614,   batch loss: 1.61758, batch accuracy: 0.57400
Time: 2018-07-15 03:53:02
TRAINING STATS: batch 96/486 in epoch 614,   batch loss: 1.68796, batch accuracy: 0.54633
Time: 2018-07-15 03:53:06
TRAINING STATS: batch 146/486 in epoch 614,  batch loss: 1.72454, batch accuracy: 0.52983
Time: 2018-07-15 03:53:10
TRAINING STATS: batch 196/486 in epoch 614,  batch loss: 1.69318, batch accuracy: 0.54433
Time: 2018-07-15 03:53:14
TRAINING STATS: batch 246/486 in epoch 614,  batch loss: 1.61438, batch accuracy: 0.57150
Time: 2018-07-15 03:53:18
TRAINING STATS: batch 296/486 in epoch 614,  batch loss: 1.61120, batch accuracy: 0.56667
Time: 2018-07-15 03:53:22
TRAINING STATS: batch 346/486 in epoch 614,  batch loss: 1.58302, batch accuracy: 0.58683
Time: 2018-07-15 03:53:26
TRAINING STATS: batch 396/486 in epoch 614,  batch loss: 1.63973, batch accuracy: 0.56150
Time: 2018-07-15 03:53:30
TRAINING STATS: batch 446/486 in epoch 614,  batch loss: 1.66787, batch accuracy: 0.55250
Time: 2018-07-15 03:53:34
TRAINING STATS: batch 10/486 in epoch 615,   batch loss: 1.68263, batch accuracy: 0.54167
Time: 2018-07-15 03:53:38
TRAINING STATS: batch 60/486 in epoch 615,   batch loss: 1.64019, batch accuracy: 0.56200
Time: 2018-07-15 03:53:42
TRAINING STATS: batch 110/486 in epoch 615,  batch loss: 1.70431, batch accuracy: 0.54817
Time: 2018-07-15 03:53:46
TRAINING STATS: batch 160/486 in epoch 615,  batch loss: 1.63220, batch accuracy: 0.55817
Time: 2018-07-15 03:53:50
TRAINING STATS: batch 210/486 in epoch 615,  batch loss: 1.62319, batch accuracy: 0.55233
Time: 2018-07-15 03:53:54
TRAINING STATS: batch 260/486 in epoch 615,  batch loss: 1.73603, batch accuracy: 0.53400
Time: 2018-07-15 03:53:59
TRAINING STATS: batch 310/486 in epoch 615,  batch loss: 1.67061, batch accuracy: 0.54867
Time: 2018-07-15 03:54:02
TRAINING STATS: batch 360/486 in epoch 615,  batch loss: 1.68923, batch accuracy: 0.54483
Time: 2018-07-15 03:54:06
TRAINING STATS: batch 410/486 in epoch 615,  batch loss: 1.59186, batch accuracy: 0.57733
Time: 2018-07-15 03:54:11
TRAINING STATS: batch 460/486 in epoch 615,  batch loss: 1.78841, batch accuracy: 0.51233
Time: 2018-07-15 03:54:14
TRAINING STATS: batch 24/486 in epoch 616,   batch loss: 1.73314, batch accuracy: 0.53950
Time: 2018-07-15 03:54:18
TRAINING STATS: batch 74/486 in epoch 616,   batch loss: 1.67205, batch accuracy: 0.55450
Time: 2018-07-15 03:54:23
TRAINING STATS: batch 124/486 in epoch 616,  batch loss: 1.66623, batch accuracy: 0.55750
Time: 2018-07-15 03:54:26
TRAINING STATS: batch 174/486 in epoch 616,  batch loss: 1.73197, batch accuracy: 0.52833
Time: 2018-07-15 03:54:30
TRAINING STATS: batch 224/486 in epoch 616,  batch loss: 1.71920, batch accuracy: 0.53967
Time: 2018-07-15 03:54:35
TRAINING STATS: batch 274/486 in epoch 616,  batch loss: 1.66115, batch accuracy: 0.55733
Time: 2018-07-15 03:54:39
TRAINING STATS: batch 324/486 in epoch 616,  batch loss: 1.68280, batch accuracy: 0.54650
Time: 2018-07-15 03:54:42
TRAINING STATS: batch 374/486 in epoch 616,  batch loss: 1.68843, batch accuracy: 0.54783
Time: 2018-07-15 03:54:47
TRAINING STATS: batch 424/486 in epoch 616,  batch loss: 1.60574, batch accuracy: 0.56250
Time: 2018-07-15 03:54:51
TRAINING STATS: batch 474/486 in epoch 616,  batch loss: 1.65782, batch accuracy: 0.55400
Time: 2018-07-15 03:54:54
TRAINING STATS: batch 38/486 in epoch 617,   batch loss: 1.67031, batch accuracy: 0.55500
Time: 2018-07-15 03:54:59
TRAINING STATS: batch 88/486 in epoch 617,   batch loss: 1.69051, batch accuracy: 0.54017
Time: 2018-07-15 03:55:03
TRAINING STATS: batch 138/486 in epoch 617,  batch loss: 1.70409, batch accuracy: 0.53783
Time: 2018-07-15 03:55:06
TRAINING STATS: batch 188/486 in epoch 617,  batch loss: 1.63009, batch accuracy: 0.56617
Time: 2018-07-15 03:55:11
TRAINING STATS: batch 238/486 in epoch 617,  batch loss: 1.64315, batch accuracy: 0.56550
Time: 2018-07-15 03:55:15
TRAINING STATS: batch 288/486 in epoch 617,  batch loss: 1.67469, batch accuracy: 0.55250
Time: 2018-07-15 03:55:18
TRAINING STATS: batch 338/486 in epoch 617,  batch loss: 1.67054, batch accuracy: 0.54950
Time: 2018-07-15 03:55:23
TRAINING STATS: batch 388/486 in epoch 617,  batch loss: 1.62668, batch accuracy: 0.56167
Time: 2018-07-15 03:55:27
TRAINING STATS: batch 438/486 in epoch 617,  batch loss: 1.68456, batch accuracy: 0.55267
Time: 2018-07-15 03:55:30
TRAINING STATS: batch 2/486 in epoch 618,    batch loss: 1.69188, batch accuracy: 0.54383
Time: 2018-07-15 03:55:35
TRAINING STATS: batch 52/486 in epoch 618,   batch loss: 1.73501, batch accuracy: 0.53100
Time: 2018-07-15 03:55:39
TRAINING STATS: batch 102/486 in epoch 618,  batch loss: 1.67593, batch accuracy: 0.55600
Time: 2018-07-15 03:55:42
TRAINING STATS: batch 152/486 in epoch 618,  batch loss: 1.62142, batch accuracy: 0.56783
Time: 2018-07-15 03:55:47
TRAINING STATS: batch 202/486 in epoch 618,  batch loss: 1.69534, batch accuracy: 0.54700
Time: 2018-07-15 03:55:51
TRAINING STATS: batch 252/486 in epoch 618,  batch loss: 1.63079, batch accuracy: 0.56917
Time: 2018-07-15 03:55:55
TRAINING STATS: batch 302/486 in epoch 618,  batch loss: 1.64874, batch accuracy: 0.54667
Time: 2018-07-15 03:55:59
TRAINING STATS: batch 352/486 in epoch 618,  batch loss: 1.63613, batch accuracy: 0.56600
Time: 2018-07-15 03:56:03
TRAINING STATS: batch 402/486 in epoch 618,  batch loss: 1.52605, batch accuracy: 0.60200
Time: 2018-07-15 03:56:07
TRAINING STATS: batch 452/486 in epoch 618,  batch loss: 1.66041, batch accuracy: 0.55283
Time: 2018-07-15 03:56:11
TRAINING STATS: batch 16/486 in epoch 619,   batch loss: 1.60794, batch accuracy: 0.57383
Time: 2018-07-15 03:56:15
TRAINING STATS: batch 66/486 in epoch 619,   batch loss: 1.63179, batch accuracy: 0.56700
Time: 2018-07-15 03:56:19
TRAINING STATS: batch 116/486 in epoch 619,  batch loss: 1.62395, batch accuracy: 0.56317
Time: 2018-07-15 03:56:23
TRAINING STATS: batch 166/486 in epoch 619,  batch loss: 1.55305, batch accuracy: 0.58483
Time: 2018-07-15 03:56:27
TRAINING STATS: batch 216/486 in epoch 619,  batch loss: 1.67482, batch accuracy: 0.55500
Time: 2018-07-15 03:56:31
TRAINING STATS: batch 266/486 in epoch 619,  batch loss: 1.65522, batch accuracy: 0.55533
Time: 2018-07-15 03:56:36
TRAINING STATS: batch 316/486 in epoch 619,  batch loss: 1.65198, batch accuracy: 0.55350
Time: 2018-07-15 03:56:39
TRAINING STATS: batch 366/486 in epoch 619,  batch loss: 1.69861, batch accuracy: 0.54300
Time: 2018-07-15 03:56:43
TRAINING STATS: batch 416/486 in epoch 619,  batch loss: 1.69887, batch accuracy: 0.54167
Time: 2018-07-15 03:56:48
TRAINING STATS: batch 466/486 in epoch 619,  batch loss: 1.53180, batch accuracy: 0.59950
Time: 2018-07-15 03:56:51
TRAINING STATS: batch 30/486 in epoch 620,   batch loss: 1.53584, batch accuracy: 0.58700
Time: 2018-07-15 03:56:55
TRAINING STATS: batch 80/486 in epoch 620,   batch loss: 1.64800, batch accuracy: 0.55333
Time: 2018-07-15 03:57:00
TRAINING STATS: batch 130/486 in epoch 620,  batch loss: 1.64425, batch accuracy: 0.56617
Time: 2018-07-15 03:57:03
TRAINING STATS: batch 180/486 in epoch 620,  batch loss: 1.68177, batch accuracy: 0.55067
Time: 2018-07-15 03:57:07
TRAINING STATS: batch 230/486 in epoch 620,  batch loss: 1.67706, batch accuracy: 0.54200
Time: 2018-07-15 03:57:12
TRAINING STATS: batch 280/486 in epoch 620,  batch loss: 1.64932, batch accuracy: 0.55667
Time: 2018-07-15 03:57:15
TRAINING STATS: batch 330/486 in epoch 620,  batch loss: 1.62498, batch accuracy: 0.56433
Time: 2018-07-15 03:57:19
TRAINING STATS: batch 380/486 in epoch 620,  batch loss: 1.63740, batch accuracy: 0.56517
Time: 2018-07-15 03:57:24
TRAINING STATS: batch 430/486 in epoch 620,  batch loss: 1.59229, batch accuracy: 0.57950
Time: 2018-07-15 03:57:27
TRAINING STATS: batch 480/486 in epoch 620,  batch loss: 1.64286, batch accuracy: 0.56267
Time: 2018-07-15 03:57:31
TRAINING STATS: batch 44/486 in epoch 621,   batch loss: 1.58833, batch accuracy: 0.57233
Time: 2018-07-15 03:57:36
TRAINING STATS: batch 94/486 in epoch 621,   batch loss: 1.69309, batch accuracy: 0.54683
Time: 2018-07-15 03:57:39
TRAINING STATS: batch 144/486 in epoch 621,  batch loss: 1.72658, batch accuracy: 0.52900
Time: 2018-07-15 03:57:43
TRAINING STATS: batch 194/486 in epoch 621,  batch loss: 1.76363, batch accuracy: 0.52650
Time: 2018-07-15 03:57:48
TRAINING STATS: batch 244/486 in epoch 621,  batch loss: 1.64727, batch accuracy: 0.55483
Time: 2018-07-15 03:57:52
TRAINING STATS: batch 294/486 in epoch 621,  batch loss: 1.57167, batch accuracy: 0.57633
Time: 2018-07-15 03:57:55
TRAINING STATS: batch 344/486 in epoch 621,  batch loss: 1.63490, batch accuracy: 0.56267
Time: 2018-07-15 03:58:00
TRAINING STATS: batch 394/486 in epoch 621,  batch loss: 1.61162, batch accuracy: 0.57533
Time: 2018-07-15 03:58:04
TRAINING STATS: batch 444/486 in epoch 621,  batch loss: 1.60161, batch accuracy: 0.56883
Time: 2018-07-15 03:58:07
TRAINING STATS: batch 8/486 in epoch 622,    batch loss: 1.63780, batch accuracy: 0.56217
Time: 2018-07-15 03:58:12
TRAINING STATS: batch 58/486 in epoch 622,   batch loss: 1.61881, batch accuracy: 0.56650
Time: 2018-07-15 03:58:16
TRAINING STATS: batch 108/486 in epoch 622,  batch loss: 1.74191, batch accuracy: 0.53400
Time: 2018-07-15 03:58:19
TRAINING STATS: batch 158/486 in epoch 622,  batch loss: 1.70694, batch accuracy: 0.53917
Time: 2018-07-15 03:58:24
TRAINING STATS: batch 208/486 in epoch 622,  batch loss: 1.68433, batch accuracy: 0.55033
Time: 2018-07-15 03:58:28
TRAINING STATS: batch 258/486 in epoch 622,  batch loss: 1.62298, batch accuracy: 0.56833
Time: 2018-07-15 03:58:32
TRAINING STATS: batch 308/486 in epoch 622,  batch loss: 1.68570, batch accuracy: 0.55167
Time: 2018-07-15 03:58:36
TRAINING STATS: batch 358/486 in epoch 622,  batch loss: 1.68857, batch accuracy: 0.55117
Time: 2018-07-15 03:58:40
TRAINING STATS: batch 408/486 in epoch 622,  batch loss: 1.68190, batch accuracy: 0.54350
Time: 2018-07-15 03:58:44
TRAINING STATS: batch 458/486 in epoch 622,  batch loss: 1.69833, batch accuracy: 0.54633
Time: 2018-07-15 03:58:48
TRAINING STATS: batch 22/486 in epoch 623,   batch loss: 1.69683, batch accuracy: 0.55467
Time: 2018-07-15 03:58:52
TRAINING STATS: batch 72/486 in epoch 623,   batch loss: 1.67725, batch accuracy: 0.54667
Time: 2018-07-15 03:58:56
TRAINING STATS: batch 122/486 in epoch 623,  batch loss: 1.61171, batch accuracy: 0.56583
Time: 2018-07-15 03:59:00
TRAINING STATS: batch 172/486 in epoch 623,  batch loss: 1.70782, batch accuracy: 0.54400
Time: 2018-07-15 03:59:04
TRAINING STATS: batch 222/486 in epoch 623,  batch loss: 1.66227, batch accuracy: 0.54850
Time: 2018-07-15 03:59:07
TRAINING STATS: batch 272/486 in epoch 623,  batch loss: 1.73509, batch accuracy: 0.53500
Time: 2018-07-15 03:59:12
TRAINING STATS: batch 322/486 in epoch 623,  batch loss: 1.66615, batch accuracy: 0.55083
Time: 2018-07-15 03:59:16
TRAINING STATS: batch 372/486 in epoch 623,  batch loss: 1.59433, batch accuracy: 0.56983
Time: 2018-07-15 03:59:20
TRAINING STATS: batch 422/486 in epoch 623,  batch loss: 1.63181, batch accuracy: 0.56483
Time: 2018-07-15 03:59:24
TRAINING STATS: batch 472/486 in epoch 623,  batch loss: 1.77231, batch accuracy: 0.52650
Time: 2018-07-15 03:59:28
TRAINING STATS: batch 36/486 in epoch 624,   batch loss: 1.72618, batch accuracy: 0.53700
Time: 2018-07-15 03:59:32
TRAINING STATS: batch 86/486 in epoch 624,   batch loss: 1.64020, batch accuracy: 0.56800
Time: 2018-07-15 03:59:36
TRAINING STATS: batch 136/486 in epoch 624,  batch loss: 1.69533, batch accuracy: 0.54600
Time: 2018-07-15 03:59:40
TRAINING STATS: batch 186/486 in epoch 624,  batch loss: 1.67472, batch accuracy: 0.55567
Time: 2018-07-15 03:59:44
TRAINING STATS: batch 236/486 in epoch 624,  batch loss: 1.69393, batch accuracy: 0.54350
Time: 2018-07-15 03:59:48
TRAINING STATS: batch 286/486 in epoch 624,  batch loss: 1.68689, batch accuracy: 0.54517
Time: 2018-07-15 03:59:52
TRAINING STATS: batch 336/486 in epoch 624,  batch loss: 1.64775, batch accuracy: 0.55667
Time: 2018-07-15 03:59:56
TRAINING STATS: batch 386/486 in epoch 624,  batch loss: 1.69961, batch accuracy: 0.54000
Time: 2018-07-15 04:00:00
TRAINING STATS: batch 436/486 in epoch 624,  batch loss: 1.67177, batch accuracy: 0.55467
Time: 2018-07-15 04:00:04
TRAINING STATS: batch 0/486 in epoch 625,    batch loss: 1.64667, batch accuracy: 0.56033
Time: 2018-07-15 04:00:08
TRAINING STATS: batch 50/486 in epoch 625,   batch loss: 1.60486, batch accuracy: 0.57017
Time: 2018-07-15 04:00:13
TRAINING STATS: batch 100/486 in epoch 625,  batch loss: 1.70039, batch accuracy: 0.55417
Time: 2018-07-15 04:00:16
TRAINING STATS: batch 150/486 in epoch 625,  batch loss: 1.61819, batch accuracy: 0.57300
Time: 2018-07-15 04:00:20
TRAINING STATS: batch 200/486 in epoch 625,  batch loss: 1.54171, batch accuracy: 0.59267
Time: 2018-07-15 04:00:25
TRAINING STATS: batch 250/486 in epoch 625,  batch loss: 1.72519, batch accuracy: 0.52883
Time: 2018-07-15 04:00:28
TRAINING STATS: batch 300/486 in epoch 625,  batch loss: 1.68819, batch accuracy: 0.53367
Time: 2018-07-15 04:00:32
TRAINING STATS: batch 350/486 in epoch 625,  batch loss: 1.65802, batch accuracy: 0.55883
Time: 2018-07-15 04:00:37
TRAINING STATS: batch 400/486 in epoch 625,  batch loss: 1.53870, batch accuracy: 0.58517
Time: 2018-07-15 04:00:40
TRAINING STATS: batch 450/486 in epoch 625,  batch loss: 1.72791, batch accuracy: 0.53867
Time: 2018-07-15 04:00:44
TRAINING STATS: batch 14/486 in epoch 626,   batch loss: 1.56538, batch accuracy: 0.58100
Time: 2018-07-15 04:00:49
TRAINING STATS: batch 64/486 in epoch 626,   batch loss: 1.73898, batch accuracy: 0.52733
Time: 2018-07-15 04:00:52
TRAINING STATS: batch 114/486 in epoch 626,  batch loss: 1.70188, batch accuracy: 0.54567
Time: 2018-07-15 04:00:56
TRAINING STATS: batch 164/486 in epoch 626,  batch loss: 1.58799, batch accuracy: 0.57883
Time: 2018-07-15 04:01:01
TRAINING STATS: batch 214/486 in epoch 626,  batch loss: 1.64241, batch accuracy: 0.56250
Time: 2018-07-15 04:01:04
TRAINING STATS: batch 264/486 in epoch 626,  batch loss: 1.69508, batch accuracy: 0.54250
Time: 2018-07-15 04:01:08
TRAINING STATS: batch 314/486 in epoch 626,  batch loss: 1.70169, batch accuracy: 0.53417
Time: 2018-07-15 04:01:13
TRAINING STATS: batch 364/486 in epoch 626,  batch loss: 1.62830, batch accuracy: 0.56717
Time: 2018-07-15 04:01:17
TRAINING STATS: batch 414/486 in epoch 626,  batch loss: 1.59267, batch accuracy: 0.57167
Time: 2018-07-15 04:01:20
TRAINING STATS: batch 464/486 in epoch 626,  batch loss: 1.60405, batch accuracy: 0.57367
Time: 2018-07-15 04:01:25
TRAINING STATS: batch 28/486 in epoch 627,   batch loss: 1.57867, batch accuracy: 0.58433
Time: 2018-07-15 04:01:29
TRAINING STATS: batch 78/486 in epoch 627,   batch loss: 1.64605, batch accuracy: 0.56700
Time: 2018-07-15 04:01:32
TRAINING STATS: batch 128/486 in epoch 627,  batch loss: 1.64175, batch accuracy: 0.56017
Time: 2018-07-15 04:01:37
TRAINING STATS: batch 178/486 in epoch 627,  batch loss: 1.54506, batch accuracy: 0.57667
Time: 2018-07-15 04:01:41
TRAINING STATS: batch 228/486 in epoch 627,  batch loss: 1.60164, batch accuracy: 0.57733
Time: 2018-07-15 04:01:44
TRAINING STATS: batch 278/486 in epoch 627,  batch loss: 1.60142, batch accuracy: 0.57900
Time: 2018-07-15 04:01:49
TRAINING STATS: batch 328/486 in epoch 627,  batch loss: 1.61818, batch accuracy: 0.56233
Time: 2018-07-15 04:01:53
TRAINING STATS: batch 378/486 in epoch 627,  batch loss: 1.63993, batch accuracy: 0.56500
Time: 2018-07-15 04:01:56
TRAINING STATS: batch 428/486 in epoch 627,  batch loss: 1.72167, batch accuracy: 0.53400
Time: 2018-07-15 04:02:01
TRAINING STATS: batch 478/486 in epoch 627,  batch loss: 1.66161, batch accuracy: 0.55150
Time: 2018-07-15 04:02:05
TRAINING STATS: batch 42/486 in epoch 628,   batch loss: 1.56255, batch accuracy: 0.57883
Time: 2018-07-15 04:02:08
TRAINING STATS: batch 92/486 in epoch 628,   batch loss: 1.66333, batch accuracy: 0.55017
Time: 2018-07-15 04:02:13
TRAINING STATS: batch 142/486 in epoch 628,  batch loss: 1.61381, batch accuracy: 0.57017
Time: 2018-07-15 04:02:17
TRAINING STATS: batch 192/486 in epoch 628,  batch loss: 1.65622, batch accuracy: 0.55133
Time: 2018-07-15 04:02:20
TRAINING STATS: batch 242/486 in epoch 628,  batch loss: 1.61275, batch accuracy: 0.56467
Time: 2018-07-15 04:02:25
TRAINING STATS: batch 292/486 in epoch 628,  batch loss: 1.65003, batch accuracy: 0.55083
Time: 2018-07-15 04:02:29
TRAINING STATS: batch 342/486 in epoch 628,  batch loss: 1.64679, batch accuracy: 0.56067
Time: 2018-07-15 04:02:33
TRAINING STATS: batch 392/486 in epoch 628,  batch loss: 1.56663, batch accuracy: 0.58283
Time: 2018-07-15 04:02:37
TRAINING STATS: batch 442/486 in epoch 628,  batch loss: 1.56593, batch accuracy: 0.57850
Time: 2018-07-15 04:02:41
TRAINING STATS: batch 6/486 in epoch 629,    batch loss: 1.70022, batch accuracy: 0.54583
Time: 2018-07-15 04:02:44
TRAINING STATS: batch 56/486 in epoch 629,   batch loss: 1.63159, batch accuracy: 0.56067
Time: 2018-07-15 04:02:49
TRAINING STATS: batch 106/486 in epoch 629,  batch loss: 1.70941, batch accuracy: 0.53900
Time: 2018-07-15 04:02:53
TRAINING STATS: batch 156/486 in epoch 629,  batch loss: 1.66965, batch accuracy: 0.55150
Time: 2018-07-15 04:02:56
TRAINING STATS: batch 206/486 in epoch 629,  batch loss: 1.81318, batch accuracy: 0.50550
Time: 2018-07-15 04:03:01
TRAINING STATS: batch 256/486 in epoch 629,  batch loss: 1.65497, batch accuracy: 0.55933
Time: 2018-07-15 04:03:05
TRAINING STATS: batch 306/486 in epoch 629,  batch loss: 1.64858, batch accuracy: 0.56100
Time: 2018-07-15 04:03:08
TRAINING STATS: batch 356/486 in epoch 629,  batch loss: 1.68648, batch accuracy: 0.54533
Time: 2018-07-15 04:03:13
TRAINING STATS: batch 406/486 in epoch 629,  batch loss: 1.73510, batch accuracy: 0.52983
Time: 2018-07-15 04:03:17
TRAINING STATS: batch 456/486 in epoch 629,  batch loss: 1.53724, batch accuracy: 0.59200
Time: 2018-07-15 04:03:21
TRAINING STATS: batch 20/486 in epoch 630,   batch loss: 1.65046, batch accuracy: 0.56183
Time: 2018-07-15 04:03:25
TRAINING STATS: batch 70/486 in epoch 630,   batch loss: 1.53439, batch accuracy: 0.59583
Time: 2018-07-15 04:03:29
TRAINING STATS: batch 120/486 in epoch 630,  batch loss: 1.60013, batch accuracy: 0.57267
Time: 2018-07-15 04:03:33
TRAINING STATS: batch 170/486 in epoch 630,  batch loss: 1.63024, batch accuracy: 0.56883
Time: 2018-07-15 04:03:37
TRAINING STATS: batch 220/486 in epoch 630,  batch loss: 1.57086, batch accuracy: 0.58150
Time: 2018-07-15 04:03:41
TRAINING STATS: batch 270/486 in epoch 630,  batch loss: 1.65698, batch accuracy: 0.54383
Time: 2018-07-15 04:03:45
TRAINING STATS: batch 320/486 in epoch 630,  batch loss: 1.58408, batch accuracy: 0.57250
Time: 2018-07-15 04:03:49
TRAINING STATS: batch 370/486 in epoch 630,  batch loss: 1.65140, batch accuracy: 0.55783
Time: 2018-07-15 04:03:53
TRAINING STATS: batch 420/486 in epoch 630,  batch loss: 1.77428, batch accuracy: 0.51683
Time: 2018-07-15 04:03:57
TRAINING STATS: batch 470/486 in epoch 630,  batch loss: 1.76858, batch accuracy: 0.51467
Time: 2018-07-15 04:04:02
TRAINING STATS: batch 34/486 in epoch 631,   batch loss: 1.66838, batch accuracy: 0.55700
Time: 2018-07-15 04:04:05
TRAINING STATS: batch 84/486 in epoch 631,   batch loss: 1.67006, batch accuracy: 0.54450
Time: 2018-07-15 04:04:09
TRAINING STATS: batch 134/486 in epoch 631,  batch loss: 1.67502, batch accuracy: 0.56067
Time: 2018-07-15 04:04:14
TRAINING STATS: batch 184/486 in epoch 631,  batch loss: 1.66534, batch accuracy: 0.55617
Time: 2018-07-15 04:04:17
TRAINING STATS: batch 234/486 in epoch 631,  batch loss: 1.72777, batch accuracy: 0.54467
Time: 2018-07-15 04:04:21
TRAINING STATS: batch 284/486 in epoch 631,  batch loss: 1.71029, batch accuracy: 0.54217
Time: 2018-07-15 04:04:26
TRAINING STATS: batch 334/486 in epoch 631,  batch loss: 1.62348, batch accuracy: 0.56883
Time: 2018-07-15 04:04:29
TRAINING STATS: batch 384/486 in epoch 631,  batch loss: 1.61598, batch accuracy: 0.57367
Time: 2018-07-15 04:04:33
TRAINING STATS: batch 434/486 in epoch 631,  batch loss: 1.69077, batch accuracy: 0.54333
Time: 2018-07-15 04:04:38
TRAINING STATS: batch 484/486 in epoch 631,  batch loss: 1.67400, batch accuracy: 0.55433
Time: 2018-07-15 04:04:41
TRAINING STATS: batch 48/486 in epoch 632,   batch loss: 1.66499, batch accuracy: 0.55833
Time: 2018-07-15 04:04:45
TRAINING STATS: batch 98/486 in epoch 632,   batch loss: 1.59302, batch accuracy: 0.57183
Time: 2018-07-15 04:04:50
TRAINING STATS: batch 148/486 in epoch 632,  batch loss: 1.67461, batch accuracy: 0.55900
Time: 2018-07-15 04:04:53
TRAINING STATS: batch 198/486 in epoch 632,  batch loss: 1.62864, batch accuracy: 0.56133
Time: 2018-07-15 04:04:57
TRAINING STATS: batch 248/486 in epoch 632,  batch loss: 1.67447, batch accuracy: 0.55200
Time: 2018-07-15 04:05:02
TRAINING STATS: batch 298/486 in epoch 632,  batch loss: 1.67340, batch accuracy: 0.55750
Time: 2018-07-15 04:05:05
TRAINING STATS: batch 348/486 in epoch 632,  batch loss: 1.65540, batch accuracy: 0.56000
Time: 2018-07-15 04:05:09
TRAINING STATS: batch 398/486 in epoch 632,  batch loss: 1.65597, batch accuracy: 0.55950
Time: 2018-07-15 04:05:14
TRAINING STATS: batch 448/486 in epoch 632,  batch loss: 1.66510, batch accuracy: 0.56283
Time: 2018-07-15 04:05:18
TRAINING STATS: batch 12/486 in epoch 633,   batch loss: 1.66252, batch accuracy: 0.55567
Time: 2018-07-15 04:05:21
TRAINING STATS: batch 62/486 in epoch 633,   batch loss: 1.77168, batch accuracy: 0.51833
Time: 2018-07-15 04:05:26
TRAINING STATS: batch 112/486 in epoch 633,  batch loss: 1.64165, batch accuracy: 0.56200
Time: 2018-07-15 04:05:30
TRAINING STATS: batch 162/486 in epoch 633,  batch loss: 1.65389, batch accuracy: 0.55917
Time: 2018-07-15 04:05:33
TRAINING STATS: batch 212/486 in epoch 633,  batch loss: 1.56302, batch accuracy: 0.58100
Time: 2018-07-15 04:05:38
TRAINING STATS: batch 262/486 in epoch 633,  batch loss: 1.71595, batch accuracy: 0.54400
Time: 2018-07-15 04:05:42
TRAINING STATS: batch 312/486 in epoch 633,  batch loss: 1.65214, batch accuracy: 0.54767
Time: 2018-07-15 04:05:45
TRAINING STATS: batch 362/486 in epoch 633,  batch loss: 1.65232, batch accuracy: 0.55717
Time: 2018-07-15 04:05:50
TRAINING STATS: batch 412/486 in epoch 633,  batch loss: 1.60084, batch accuracy: 0.57067
Time: 2018-07-15 04:05:54
TRAINING STATS: batch 462/486 in epoch 633,  batch loss: 1.65002, batch accuracy: 0.56133
Time: 2018-07-15 04:05:58
TRAINING STATS: batch 26/486 in epoch 634,   batch loss: 1.68786, batch accuracy: 0.54900
Time: 2018-07-15 04:06:02
TRAINING STATS: batch 76/486 in epoch 634,   batch loss: 1.75950, batch accuracy: 0.52733
Time: 2018-07-15 04:06:06
TRAINING STATS: batch 126/486 in epoch 634,  batch loss: 1.68583, batch accuracy: 0.54550
Time: 2018-07-15 04:06:10
TRAINING STATS: batch 176/486 in epoch 634,  batch loss: 1.57233, batch accuracy: 0.58817
Time: 2018-07-15 04:06:14
TRAINING STATS: batch 226/486 in epoch 634,  batch loss: 1.62671, batch accuracy: 0.56717
Time: 2018-07-15 04:06:18
TRAINING STATS: batch 276/486 in epoch 634,  batch loss: 1.63646, batch accuracy: 0.55800
Time: 2018-07-15 04:06:22
TRAINING STATS: batch 326/486 in epoch 634,  batch loss: 1.69045, batch accuracy: 0.54767
Time: 2018-07-15 04:06:26
TRAINING STATS: batch 376/486 in epoch 634,  batch loss: 1.67491, batch accuracy: 0.55700
Time: 2018-07-15 04:06:30
TRAINING STATS: batch 426/486 in epoch 634,  batch loss: 1.63455, batch accuracy: 0.55183
Time: 2018-07-15 04:06:34
TRAINING STATS: batch 476/486 in epoch 634,  batch loss: 1.58902, batch accuracy: 0.57217
Time: 2018-07-15 04:06:38
TRAINING STATS: batch 40/486 in epoch 635,   batch loss: 1.61231, batch accuracy: 0.56300
Time: 2018-07-15 04:06:42
TRAINING STATS: batch 90/486 in epoch 635,   batch loss: 1.67478, batch accuracy: 0.54700
Time: 2018-07-15 04:06:46
TRAINING STATS: batch 140/486 in epoch 635,  batch loss: 1.58604, batch accuracy: 0.57583
Time: 2018-07-15 04:06:51
TRAINING STATS: batch 190/486 in epoch 635,  batch loss: 1.61710, batch accuracy: 0.57283
Time: 2018-07-15 04:06:54
TRAINING STATS: batch 240/486 in epoch 635,  batch loss: 1.62282, batch accuracy: 0.56583
Time: 2018-07-15 04:06:58
TRAINING STATS: batch 290/486 in epoch 635,  batch loss: 1.67941, batch accuracy: 0.54867
Time: 2018-07-15 04:07:03
TRAINING STATS: batch 340/486 in epoch 635,  batch loss: 1.72939, batch accuracy: 0.53567
Time: 2018-07-15 04:07:06
TRAINING STATS: batch 390/486 in epoch 635,  batch loss: 1.58888, batch accuracy: 0.57283
Time: 2018-07-15 04:07:10
TRAINING STATS: batch 440/486 in epoch 635,  batch loss: 1.64895, batch accuracy: 0.55450
Time: 2018-07-15 04:07:15
TRAINING STATS: batch 4/486 in epoch 636,    batch loss: 1.59327, batch accuracy: 0.57483
Time: 2018-07-15 04:07:18
TRAINING STATS: batch 54/486 in epoch 636,   batch loss: 1.64699, batch accuracy: 0.55767
Time: 2018-07-15 04:07:22
TRAINING STATS: batch 104/486 in epoch 636,  batch loss: 1.65104, batch accuracy: 0.55700
Time: 2018-07-15 04:07:27
TRAINING STATS: batch 154/486 in epoch 636,  batch loss: 1.62489, batch accuracy: 0.55767
Time: 2018-07-15 04:07:30
TRAINING STATS: batch 204/486 in epoch 636,  batch loss: 1.71079, batch accuracy: 0.54550
Time: 2018-07-15 04:07:34
TRAINING STATS: batch 254/486 in epoch 636,  batch loss: 1.58316, batch accuracy: 0.58100
Time: 2018-07-15 04:07:39
TRAINING STATS: batch 304/486 in epoch 636,  batch loss: 1.59893, batch accuracy: 0.57033
Time: 2018-07-15 04:07:42
TRAINING STATS: batch 354/486 in epoch 636,  batch loss: 1.64586, batch accuracy: 0.55650
Time: 2018-07-15 04:07:46
TRAINING STATS: batch 404/486 in epoch 636,  batch loss: 1.65373, batch accuracy: 0.56150
Time: 2018-07-15 04:07:51
TRAINING STATS: batch 454/486 in epoch 636,  batch loss: 1.52172, batch accuracy: 0.59450
Time: 2018-07-15 04:07:54
TRAINING STATS: batch 18/486 in epoch 637,   batch loss: 1.68600, batch accuracy: 0.55817
Time: 2018-07-15 04:07:58
TRAINING STATS: batch 68/486 in epoch 637,   batch loss: 1.49965, batch accuracy: 0.60267
Time: 2018-07-15 04:08:03
TRAINING STATS: batch 118/486 in epoch 637,  batch loss: 1.63371, batch accuracy: 0.56350
Time: 2018-07-15 04:08:07
TRAINING STATS: batch 168/486 in epoch 637,  batch loss: 1.56400, batch accuracy: 0.58567
Time: 2018-07-15 04:08:10
TRAINING STATS: batch 218/486 in epoch 637,  batch loss: 1.63767, batch accuracy: 0.55650
Time: 2018-07-15 04:08:15
TRAINING STATS: batch 268/486 in epoch 637,  batch loss: 1.63514, batch accuracy: 0.55550
Time: 2018-07-15 04:08:19
TRAINING STATS: batch 318/486 in epoch 637,  batch loss: 1.64738, batch accuracy: 0.55683
Time: 2018-07-15 04:08:22
TRAINING STATS: batch 368/486 in epoch 637,  batch loss: 1.66595, batch accuracy: 0.55100
Time: 2018-07-15 04:08:27
TRAINING STATS: batch 418/486 in epoch 637,  batch loss: 1.70299, batch accuracy: 0.53700
Time: 2018-07-15 04:08:31
TRAINING STATS: batch 468/486 in epoch 637,  batch loss: 1.65430, batch accuracy: 0.56067
Time: 2018-07-15 04:08:34
TRAINING STATS: batch 32/486 in epoch 638,   batch loss: 1.60792, batch accuracy: 0.56867
Time: 2018-07-15 04:08:39
TRAINING STATS: batch 82/486 in epoch 638,   batch loss: 1.67981, batch accuracy: 0.54350
Time: 2018-07-15 04:08:43
TRAINING STATS: batch 132/486 in epoch 638,  batch loss: 1.62837, batch accuracy: 0.56650
Time: 2018-07-15 04:08:46
TRAINING STATS: batch 182/486 in epoch 638,  batch loss: 1.70457, batch accuracy: 0.54467
Time: 2018-07-15 04:08:51
TRAINING STATS: batch 232/486 in epoch 638,  batch loss: 1.68503, batch accuracy: 0.55300
Time: 2018-07-15 04:08:55
TRAINING STATS: batch 282/486 in epoch 638,  batch loss: 1.60798, batch accuracy: 0.56650
Time: 2018-07-15 04:08:58
TRAINING STATS: batch 332/486 in epoch 638,  batch loss: 1.67017, batch accuracy: 0.55200
Time: 2018-07-15 04:09:03
TRAINING STATS: batch 382/486 in epoch 638,  batch loss: 1.65265, batch accuracy: 0.56167
Time: 2018-07-15 04:09:07
TRAINING STATS: batch 432/486 in epoch 638,  batch loss: 1.61526, batch accuracy: 0.57117
Time: 2018-07-15 04:09:10
TRAINING STATS: batch 482/486 in epoch 638,  batch loss: 1.67134, batch accuracy: 0.55833
Time: 2018-07-15 04:09:15
TRAINING STATS: batch 46/486 in epoch 639,   batch loss: 1.63560, batch accuracy: 0.57000
Time: 2018-07-15 04:09:19
TRAINING STATS: batch 96/486 in epoch 639,   batch loss: 1.67439, batch accuracy: 0.54650
Time: 2018-07-15 04:09:23
TRAINING STATS: batch 146/486 in epoch 639,  batch loss: 1.68307, batch accuracy: 0.55233
Time: 2018-07-15 04:09:27
TRAINING STATS: batch 196/486 in epoch 639,  batch loss: 1.69238, batch accuracy: 0.54850
Time: 2018-07-15 04:09:31
TRAINING STATS: batch 246/486 in epoch 639,  batch loss: 1.61879, batch accuracy: 0.57200
Time: 2018-07-15 04:09:35
TRAINING STATS: batch 296/486 in epoch 639,  batch loss: 1.61344, batch accuracy: 0.56733
Time: 2018-07-15 04:09:39
TRAINING STATS: batch 346/486 in epoch 639,  batch loss: 1.57976, batch accuracy: 0.58100
Time: 2018-07-15 04:09:43
TRAINING STATS: batch 396/486 in epoch 639,  batch loss: 1.64090, batch accuracy: 0.56600
Time: 2018-07-15 04:09:47
TRAINING STATS: batch 446/486 in epoch 639,  batch loss: 1.68011, batch accuracy: 0.54600
Time: 2018-07-15 04:09:51
TRAINING STATS: batch 10/486 in epoch 640,   batch loss: 1.69447, batch accuracy: 0.53883
Time: 2018-07-15 04:09:55
TRAINING STATS: batch 60/486 in epoch 640,   batch loss: 1.63282, batch accuracy: 0.56817
Time: 2018-07-15 04:09:59
TRAINING STATS: batch 110/486 in epoch 640,  batch loss: 1.71042, batch accuracy: 0.54583
Time: 2018-07-15 04:10:03
TRAINING STATS: batch 160/486 in epoch 640,  batch loss: 1.62991, batch accuracy: 0.56233
Time: 2018-07-15 04:10:07
TRAINING STATS: batch 210/486 in epoch 640,  batch loss: 1.58780, batch accuracy: 0.56750
Time: 2018-07-15 04:10:11
TRAINING STATS: batch 260/486 in epoch 640,  batch loss: 1.67669, batch accuracy: 0.54800
Time: 2018-07-15 04:10:15
TRAINING STATS: batch 310/486 in epoch 640,  batch loss: 1.66379, batch accuracy: 0.55433
Time: 2018-07-15 04:10:19
TRAINING STATS: batch 360/486 in epoch 640,  batch loss: 1.68798, batch accuracy: 0.54450
Time: 2018-07-15 04:10:23
TRAINING STATS: batch 410/486 in epoch 640,  batch loss: 1.58030, batch accuracy: 0.58583
Time: 2018-07-15 04:10:27
TRAINING STATS: batch 460/486 in epoch 640,  batch loss: 1.76916, batch accuracy: 0.52200
Time: 2018-07-15 04:10:31
TRAINING STATS: batch 24/486 in epoch 641,   batch loss: 1.71854, batch accuracy: 0.53983
Time: 2018-07-15 04:10:35
TRAINING STATS: batch 74/486 in epoch 641,   batch loss: 1.66971, batch accuracy: 0.55533
Time: 2018-07-15 04:10:40
TRAINING STATS: batch 124/486 in epoch 641,  batch loss: 1.65538, batch accuracy: 0.56267
Time: 2018-07-15 04:10:43
TRAINING STATS: batch 174/486 in epoch 641,  batch loss: 1.70474, batch accuracy: 0.54067
Time: 2018-07-15 04:10:47
TRAINING STATS: batch 224/486 in epoch 641,  batch loss: 1.68964, batch accuracy: 0.54750
Time: 2018-07-15 04:10:52
TRAINING STATS: batch 274/486 in epoch 641,  batch loss: 1.65249, batch accuracy: 0.54983
Time: 2018-07-15 04:10:55
TRAINING STATS: batch 324/486 in epoch 641,  batch loss: 1.71268, batch accuracy: 0.53967
Time: 2018-07-15 04:10:59
TRAINING STATS: batch 374/486 in epoch 641,  batch loss: 1.68659, batch accuracy: 0.54767
Time: 2018-07-15 04:11:04
TRAINING STATS: batch 424/486 in epoch 641,  batch loss: 1.60160, batch accuracy: 0.57517
Time: 2018-07-15 04:11:07
TRAINING STATS: batch 474/486 in epoch 641,  batch loss: 1.65691, batch accuracy: 0.56167
Time: 2018-07-15 04:11:11
TRAINING STATS: batch 38/486 in epoch 642,   batch loss: 1.66770, batch accuracy: 0.55483
Time: 2018-07-15 04:11:16
TRAINING STATS: batch 88/486 in epoch 642,   batch loss: 1.69612, batch accuracy: 0.54283
Time: 2018-07-15 04:11:20
TRAINING STATS: batch 138/486 in epoch 642,  batch loss: 1.70867, batch accuracy: 0.53833
Time: 2018-07-15 04:11:23
TRAINING STATS: batch 188/486 in epoch 642,  batch loss: 1.60018, batch accuracy: 0.57150
Time: 2018-07-15 04:11:28
TRAINING STATS: batch 238/486 in epoch 642,  batch loss: 1.64937, batch accuracy: 0.56583
Time: 2018-07-15 04:11:32
TRAINING STATS: batch 288/486 in epoch 642,  batch loss: 1.67739, batch accuracy: 0.54433
Time: 2018-07-15 04:11:35
TRAINING STATS: batch 338/486 in epoch 642,  batch loss: 1.66857, batch accuracy: 0.54783
Time: 2018-07-15 04:11:40
TRAINING STATS: batch 388/486 in epoch 642,  batch loss: 1.62458, batch accuracy: 0.56300
Time: 2018-07-15 04:11:44
TRAINING STATS: batch 438/486 in epoch 642,  batch loss: 1.70042, batch accuracy: 0.55300
Time: 2018-07-15 04:11:47
TRAINING STATS: batch 2/486 in epoch 643,    batch loss: 1.68527, batch accuracy: 0.54283
Time: 2018-07-15 04:11:52
TRAINING STATS: batch 52/486 in epoch 643,   batch loss: 1.73207, batch accuracy: 0.53067
Time: 2018-07-15 04:11:56
TRAINING STATS: batch 102/486 in epoch 643,  batch loss: 1.74603, batch accuracy: 0.53200
Time: 2018-07-15 04:11:59
TRAINING STATS: batch 152/486 in epoch 643,  batch loss: 1.61000, batch accuracy: 0.57233
Time: 2018-07-15 04:12:04
TRAINING STATS: batch 202/486 in epoch 643,  batch loss: 1.66380, batch accuracy: 0.55667
Time: 2018-07-15 04:12:08
TRAINING STATS: batch 252/486 in epoch 643,  batch loss: 1.69915, batch accuracy: 0.54000
Time: 2018-07-15 04:12:11
TRAINING STATS: batch 302/486 in epoch 643,  batch loss: 1.63717, batch accuracy: 0.56500
Time: 2018-07-15 04:12:16
TRAINING STATS: batch 352/486 in epoch 643,  batch loss: 1.66953, batch accuracy: 0.54700
Time: 2018-07-15 04:12:20
TRAINING STATS: batch 402/486 in epoch 643,  batch loss: 1.51764, batch accuracy: 0.59317
Time: 2018-07-15 04:12:23
TRAINING STATS: batch 452/486 in epoch 643,  batch loss: 1.65990, batch accuracy: 0.55117
Time: 2018-07-15 04:12:28
TRAINING STATS: batch 16/486 in epoch 644,   batch loss: 1.63132, batch accuracy: 0.56667
Time: 2018-07-15 04:12:32
TRAINING STATS: batch 66/486 in epoch 644,   batch loss: 1.63072, batch accuracy: 0.57300
Time: 2018-07-15 04:12:36
TRAINING STATS: batch 116/486 in epoch 644,  batch loss: 1.61981, batch accuracy: 0.56650
Time: 2018-07-15 04:12:40
TRAINING STATS: batch 166/486 in epoch 644,  batch loss: 1.56133, batch accuracy: 0.58467
Time: 2018-07-15 04:12:44
TRAINING STATS: batch 216/486 in epoch 644,  batch loss: 1.68564, batch accuracy: 0.55300
Time: 2018-07-15 04:12:48
TRAINING STATS: batch 266/486 in epoch 644,  batch loss: 1.64922, batch accuracy: 0.55567
Time: 2018-07-15 04:12:52
TRAINING STATS: batch 316/486 in epoch 644,  batch loss: 1.65322, batch accuracy: 0.55583
Time: 2018-07-15 04:12:56
TRAINING STATS: batch 366/486 in epoch 644,  batch loss: 1.71749, batch accuracy: 0.53950
Time: 2018-07-15 04:13:00
TRAINING STATS: batch 416/486 in epoch 644,  batch loss: 1.70023, batch accuracy: 0.54300
Time: 2018-07-15 04:13:04
TRAINING STATS: batch 466/486 in epoch 644,  batch loss: 1.55941, batch accuracy: 0.59083
Time: 2018-07-15 04:13:08
TRAINING STATS: batch 30/486 in epoch 645,   batch loss: 1.54362, batch accuracy: 0.58850
Time: 2018-07-15 04:13:12
TRAINING STATS: batch 80/486 in epoch 645,   batch loss: 1.65574, batch accuracy: 0.55683
Time: 2018-07-15 04:13:17
TRAINING STATS: batch 130/486 in epoch 645,  batch loss: 1.65413, batch accuracy: 0.56883
Time: 2018-07-15 04:13:20
TRAINING STATS: batch 180/486 in epoch 645,  batch loss: 1.67778, batch accuracy: 0.54767
Time: 2018-07-15 04:13:24
TRAINING STATS: batch 230/486 in epoch 645,  batch loss: 1.67131, batch accuracy: 0.54783
Time: 2018-07-15 04:13:29
TRAINING STATS: batch 280/486 in epoch 645,  batch loss: 1.64895, batch accuracy: 0.56267
Time: 2018-07-15 04:13:32
TRAINING STATS: batch 330/486 in epoch 645,  batch loss: 1.62910, batch accuracy: 0.55667
Time: 2018-07-15 04:13:36
TRAINING STATS: batch 380/486 in epoch 645,  batch loss: 1.62293, batch accuracy: 0.57067
Time: 2018-07-15 04:13:41
TRAINING STATS: batch 430/486 in epoch 645,  batch loss: 1.58885, batch accuracy: 0.57617
Time: 2018-07-15 04:13:44
TRAINING STATS: batch 480/486 in epoch 645,  batch loss: 1.65335, batch accuracy: 0.55567
Time: 2018-07-15 04:13:48
TRAINING STATS: batch 44/486 in epoch 646,   batch loss: 1.62804, batch accuracy: 0.56117
Time: 2018-07-15 04:13:53
TRAINING STATS: batch 94/486 in epoch 646,   batch loss: 1.71484, batch accuracy: 0.53900
Time: 2018-07-15 04:13:56
TRAINING STATS: batch 144/486 in epoch 646,  batch loss: 1.71993, batch accuracy: 0.53683
Time: 2018-07-15 04:14:00
TRAINING STATS: batch 194/486 in epoch 646,  batch loss: 1.73652, batch accuracy: 0.53850
Time: 2018-07-15 04:14:05
TRAINING STATS: batch 244/486 in epoch 646,  batch loss: 1.66703, batch accuracy: 0.55583
Time: 2018-07-15 04:14:08
TRAINING STATS: batch 294/486 in epoch 646,  batch loss: 1.56842, batch accuracy: 0.57667
Time: 2018-07-15 04:14:12
TRAINING STATS: batch 344/486 in epoch 646,  batch loss: 1.62634, batch accuracy: 0.56500
Time: 2018-07-15 04:14:17
TRAINING STATS: batch 394/486 in epoch 646,  batch loss: 1.61844, batch accuracy: 0.57250
Time: 2018-07-15 04:14:20
TRAINING STATS: batch 444/486 in epoch 646,  batch loss: 1.59376, batch accuracy: 0.57967
Time: 2018-07-15 04:14:24
TRAINING STATS: batch 8/486 in epoch 647,    batch loss: 1.63720, batch accuracy: 0.55617
Time: 2018-07-15 04:14:29
TRAINING STATS: batch 58/486 in epoch 647,   batch loss: 1.61581, batch accuracy: 0.56700
Time: 2018-07-15 04:14:32
TRAINING STATS: batch 108/486 in epoch 647,  batch loss: 1.70576, batch accuracy: 0.54950
Time: 2018-07-15 04:14:36
TRAINING STATS: batch 158/486 in epoch 647,  batch loss: 1.71012, batch accuracy: 0.54650
Time: 2018-07-15 04:14:41
TRAINING STATS: batch 208/486 in epoch 647,  batch loss: 1.67501, batch accuracy: 0.55217
Time: 2018-07-15 04:14:45
TRAINING STATS: batch 258/486 in epoch 647,  batch loss: 1.61184, batch accuracy: 0.56833
Time: 2018-07-15 04:14:48
TRAINING STATS: batch 308/486 in epoch 647,  batch loss: 1.65732, batch accuracy: 0.56167
Time: 2018-07-15 04:14:53
TRAINING STATS: batch 358/486 in epoch 647,  batch loss: 1.68772, batch accuracy: 0.54583
Time: 2018-07-15 04:14:57
TRAINING STATS: batch 408/486 in epoch 647,  batch loss: 1.68381, batch accuracy: 0.54500
Time: 2018-07-15 04:15:00
TRAINING STATS: batch 458/486 in epoch 647,  batch loss: 1.66891, batch accuracy: 0.55383
Time: 2018-07-15 04:15:05
TRAINING STATS: batch 22/486 in epoch 648,   batch loss: 1.71168, batch accuracy: 0.54667
Time: 2018-07-15 04:15:09
TRAINING STATS: batch 72/486 in epoch 648,   batch loss: 1.67737, batch accuracy: 0.53967
Time: 2018-07-15 04:15:12
TRAINING STATS: batch 122/486 in epoch 648,  batch loss: 1.59968, batch accuracy: 0.57517
Time: 2018-07-15 04:15:17
TRAINING STATS: batch 172/486 in epoch 648,  batch loss: 1.70784, batch accuracy: 0.54450
Time: 2018-07-15 04:15:21
TRAINING STATS: batch 222/486 in epoch 648,  batch loss: 1.64473, batch accuracy: 0.55967
Time: 2018-07-15 04:15:25
TRAINING STATS: batch 272/486 in epoch 648,  batch loss: 1.67875, batch accuracy: 0.54400
Time: 2018-07-15 04:15:29
TRAINING STATS: batch 322/486 in epoch 648,  batch loss: 1.64393, batch accuracy: 0.55450
Time: 2018-07-15 04:15:33
TRAINING STATS: batch 372/486 in epoch 648,  batch loss: 1.60138, batch accuracy: 0.56950
Time: 2018-07-15 04:15:37
TRAINING STATS: batch 422/486 in epoch 648,  batch loss: 1.62692, batch accuracy: 0.55900
Time: 2018-07-15 04:15:41
TRAINING STATS: batch 472/486 in epoch 648,  batch loss: 1.71187, batch accuracy: 0.54250
Time: 2018-07-15 04:15:45
TRAINING STATS: batch 36/486 in epoch 649,   batch loss: 1.71111, batch accuracy: 0.54317
Time: 2018-07-15 04:15:49
TRAINING STATS: batch 86/486 in epoch 649,   batch loss: 1.64480, batch accuracy: 0.56033
Time: 2018-07-15 04:15:53
TRAINING STATS: batch 136/486 in epoch 649,  batch loss: 1.70512, batch accuracy: 0.54800
Time: 2018-07-15 04:15:57
TRAINING STATS: batch 186/486 in epoch 649,  batch loss: 1.67010, batch accuracy: 0.55483
Time: 2018-07-15 04:16:01
TRAINING STATS: batch 236/486 in epoch 649,  batch loss: 1.69523, batch accuracy: 0.54267
Time: 2018-07-15 04:16:05
TRAINING STATS: batch 286/486 in epoch 649,  batch loss: 1.69849, batch accuracy: 0.54800
Time: 2018-07-15 04:16:09
TRAINING STATS: batch 336/486 in epoch 649,  batch loss: 1.64204, batch accuracy: 0.55967
Time: 2018-07-15 04:16:13
TRAINING STATS: batch 386/486 in epoch 649,  batch loss: 1.69149, batch accuracy: 0.54133
Time: 2018-07-15 04:16:18
TRAINING STATS: batch 436/486 in epoch 649,  batch loss: 1.67342, batch accuracy: 0.55750
Time: 2018-07-15 04:16:21
TRAINING STATS: batch 0/486 in epoch 650,    batch loss: 1.63562, batch accuracy: 0.56050
Time: 2018-07-15 04:16:25
TRAINING STATS: batch 50/486 in epoch 650,   batch loss: 1.61171, batch accuracy: 0.57317
Time: 2018-07-15 04:16:30
TRAINING STATS: batch 100/486 in epoch 650,  batch loss: 1.68411, batch accuracy: 0.54933
Time: 2018-07-15 04:16:33
TRAINING STATS: batch 150/486 in epoch 650,  batch loss: 1.63193, batch accuracy: 0.56400
Time: 2018-07-15 04:16:37
TRAINING STATS: batch 200/486 in epoch 650,  batch loss: 1.54994, batch accuracy: 0.58767
Time: 2018-07-15 04:16:42
TRAINING STATS: batch 250/486 in epoch 650,  batch loss: 1.71367, batch accuracy: 0.53133
Time: 2018-07-15 04:16:45
TRAINING STATS: batch 300/486 in epoch 650,  batch loss: 1.71024, batch accuracy: 0.53100
Time: 2018-07-15 04:16:49
TRAINING STATS: batch 350/486 in epoch 650,  batch loss: 1.67083, batch accuracy: 0.55600
Time: 2018-07-15 04:16:54
TRAINING STATS: batch 400/486 in epoch 650,  batch loss: 1.53629, batch accuracy: 0.58683
Time: 2018-07-15 04:16:57
TRAINING STATS: batch 450/486 in epoch 650,  batch loss: 1.71434, batch accuracy: 0.53750
Time: 2018-07-15 04:17:01
TRAINING STATS: batch 14/486 in epoch 651,   batch loss: 1.60394, batch accuracy: 0.57250
Time: 2018-07-15 04:17:06
TRAINING STATS: batch 64/486 in epoch 651,   batch loss: 1.73403, batch accuracy: 0.53150
Time: 2018-07-15 04:17:09
TRAINING STATS: batch 114/486 in epoch 651,  batch loss: 1.69103, batch accuracy: 0.54500
Time: 2018-07-15 04:17:13
TRAINING STATS: batch 164/486 in epoch 651,  batch loss: 1.59136, batch accuracy: 0.57800
Time: 2018-07-15 04:17:18
TRAINING STATS: batch 214/486 in epoch 651,  batch loss: 1.64709, batch accuracy: 0.56033
Time: 2018-07-15 04:17:22
TRAINING STATS: batch 264/486 in epoch 651,  batch loss: 1.68628, batch accuracy: 0.53867
Time: 2018-07-15 04:17:25
TRAINING STATS: batch 314/486 in epoch 651,  batch loss: 1.71249, batch accuracy: 0.52983
Time: 2018-07-15 04:17:30
TRAINING STATS: batch 364/486 in epoch 651,  batch loss: 1.62930, batch accuracy: 0.56383
Time: 2018-07-15 04:17:34
TRAINING STATS: batch 414/486 in epoch 651,  batch loss: 1.58570, batch accuracy: 0.57550
Time: 2018-07-15 04:17:37
TRAINING STATS: batch 464/486 in epoch 651,  batch loss: 1.60627, batch accuracy: 0.57167
Time: 2018-07-15 04:17:42
TRAINING STATS: batch 28/486 in epoch 652,   batch loss: 1.57207, batch accuracy: 0.57850
Time: 2018-07-15 04:17:46
TRAINING STATS: batch 78/486 in epoch 652,   batch loss: 1.64924, batch accuracy: 0.56600
Time: 2018-07-15 04:17:50
TRAINING STATS: batch 128/486 in epoch 652,  batch loss: 1.64108, batch accuracy: 0.55800
Time: 2018-07-15 04:17:54
TRAINING STATS: batch 178/486 in epoch 652,  batch loss: 1.55112, batch accuracy: 0.58383
Time: 2018-07-15 04:17:58
TRAINING STATS: batch 228/486 in epoch 652,  batch loss: 1.60194, batch accuracy: 0.56767
Time: 2018-07-15 04:18:02
TRAINING STATS: batch 278/486 in epoch 652,  batch loss: 1.57761, batch accuracy: 0.57933
Time: 2018-07-15 04:18:06
TRAINING STATS: batch 328/486 in epoch 652,  batch loss: 1.61169, batch accuracy: 0.56783
Time: 2018-07-15 04:18:10
TRAINING STATS: batch 378/486 in epoch 652,  batch loss: 1.64958, batch accuracy: 0.56083
Time: 2018-07-15 04:18:14
TRAINING STATS: batch 428/486 in epoch 652,  batch loss: 1.69647, batch accuracy: 0.53817
Time: 2018-07-15 04:18:18
TRAINING STATS: batch 478/486 in epoch 652,  batch loss: 1.65780, batch accuracy: 0.55300
Time: 2018-07-15 04:18:22
TRAINING STATS: batch 42/486 in epoch 653,   batch loss: 1.57369, batch accuracy: 0.57967
Time: 2018-07-15 04:18:26
TRAINING STATS: batch 92/486 in epoch 653,   batch loss: 1.66537, batch accuracy: 0.54850
Time: 2018-07-15 04:18:30
TRAINING STATS: batch 142/486 in epoch 653,  batch loss: 1.61942, batch accuracy: 0.56167
Time: 2018-07-15 04:18:34
TRAINING STATS: batch 192/486 in epoch 653,  batch loss: 1.65303, batch accuracy: 0.55583
Time: 2018-07-15 04:18:38
TRAINING STATS: batch 242/486 in epoch 653,  batch loss: 1.62739, batch accuracy: 0.56133
Time: 2018-07-15 04:18:43
TRAINING STATS: batch 292/486 in epoch 653,  batch loss: 1.63224, batch accuracy: 0.55533
Time: 2018-07-15 04:18:46
TRAINING STATS: batch 342/486 in epoch 653,  batch loss: 1.61808, batch accuracy: 0.56200
Time: 2018-07-15 04:18:50
TRAINING STATS: batch 392/486 in epoch 653,  batch loss: 1.55449, batch accuracy: 0.58867
Time: 2018-07-15 04:18:55
TRAINING STATS: batch 442/486 in epoch 653,  batch loss: 1.56305, batch accuracy: 0.57717
Time: 2018-07-15 04:18:58
TRAINING STATS: batch 6/486 in epoch 654,    batch loss: 1.68055, batch accuracy: 0.55500
Time: 2018-07-15 04:19:02
TRAINING STATS: batch 56/486 in epoch 654,   batch loss: 1.61509, batch accuracy: 0.56817
Time: 2018-07-15 04:19:07
TRAINING STATS: batch 106/486 in epoch 654,  batch loss: 1.69982, batch accuracy: 0.54317
Time: 2018-07-15 04:19:10
TRAINING STATS: batch 156/486 in epoch 654,  batch loss: 1.67890, batch accuracy: 0.54950
Time: 2018-07-15 04:19:14
TRAINING STATS: batch 206/486 in epoch 654,  batch loss: 1.70607, batch accuracy: 0.53967
Time: 2018-07-15 04:19:19
TRAINING STATS: batch 256/486 in epoch 654,  batch loss: 1.60750, batch accuracy: 0.56300
Time: 2018-07-15 04:19:22
TRAINING STATS: batch 306/486 in epoch 654,  batch loss: 1.65011, batch accuracy: 0.55683
Time: 2018-07-15 04:19:26
TRAINING STATS: batch 356/486 in epoch 654,  batch loss: 1.74826, batch accuracy: 0.52300
Time: 2018-07-15 04:19:31
TRAINING STATS: batch 406/486 in epoch 654,  batch loss: 1.73313, batch accuracy: 0.53400
Time: 2018-07-15 04:19:35
TRAINING STATS: batch 456/486 in epoch 654,  batch loss: 1.54393, batch accuracy: 0.58567
Time: 2018-07-15 04:19:38
TRAINING STATS: batch 20/486 in epoch 655,   batch loss: 1.66482, batch accuracy: 0.55100
Time: 2018-07-15 04:19:43
TRAINING STATS: batch 70/486 in epoch 655,   batch loss: 1.53716, batch accuracy: 0.58850
Time: 2018-07-15 04:19:47
TRAINING STATS: batch 120/486 in epoch 655,  batch loss: 1.60125, batch accuracy: 0.56717
Time: 2018-07-15 04:19:50
TRAINING STATS: batch 170/486 in epoch 655,  batch loss: 1.62837, batch accuracy: 0.55950
Time: 2018-07-15 04:19:55
TRAINING STATS: batch 220/486 in epoch 655,  batch loss: 1.56843, batch accuracy: 0.57733
Time: 2018-07-15 04:19:59
TRAINING STATS: batch 270/486 in epoch 655,  batch loss: 1.66147, batch accuracy: 0.53983
Time: 2018-07-15 04:20:02
TRAINING STATS: batch 320/486 in epoch 655,  batch loss: 1.58865, batch accuracy: 0.57333
Time: 2018-07-15 04:20:07
TRAINING STATS: batch 370/486 in epoch 655,  batch loss: 1.66345, batch accuracy: 0.56233
Time: 2018-07-15 04:20:11
TRAINING STATS: batch 420/486 in epoch 655,  batch loss: 1.68860, batch accuracy: 0.54433
Time: 2018-07-15 04:20:14
TRAINING STATS: batch 470/486 in epoch 655,  batch loss: 1.75235, batch accuracy: 0.52350
Time: 2018-07-15 04:20:19
TRAINING STATS: batch 34/486 in epoch 656,   batch loss: 1.65733, batch accuracy: 0.55433
Time: 2018-07-15 04:20:23
TRAINING STATS: batch 84/486 in epoch 656,   batch loss: 1.66659, batch accuracy: 0.54650
Time: 2018-07-15 04:20:26
TRAINING STATS: batch 134/486 in epoch 656,  batch loss: 1.68495, batch accuracy: 0.54783
Time: 2018-07-15 04:20:31
TRAINING STATS: batch 184/486 in epoch 656,  batch loss: 1.68037, batch accuracy: 0.54550
Time: 2018-07-15 04:20:35
TRAINING STATS: batch 234/486 in epoch 656,  batch loss: 1.72892, batch accuracy: 0.53550
Time: 2018-07-15 04:20:39
TRAINING STATS: batch 284/486 in epoch 656,  batch loss: 1.69009, batch accuracy: 0.54467
Time: 2018-07-15 04:20:43
TRAINING STATS: batch 334/486 in epoch 656,  batch loss: 1.63720, batch accuracy: 0.56617
Time: 2018-07-15 04:20:47
TRAINING STATS: batch 384/486 in epoch 656,  batch loss: 1.63068, batch accuracy: 0.56383
Time: 2018-07-15 04:20:51
TRAINING STATS: batch 434/486 in epoch 656,  batch loss: 1.71271, batch accuracy: 0.53833
Time: 2018-07-15 04:20:55
TRAINING STATS: batch 484/486 in epoch 656,  batch loss: 1.65271, batch accuracy: 0.55233
Time: 2018-07-15 04:20:59
TRAINING STATS: batch 48/486 in epoch 657,   batch loss: 1.64594, batch accuracy: 0.56250
Time: 2018-07-15 04:21:03
TRAINING STATS: batch 98/486 in epoch 657,   batch loss: 1.61777, batch accuracy: 0.56117
Time: 2018-07-15 04:21:07
TRAINING STATS: batch 148/486 in epoch 657,  batch loss: 1.68910, batch accuracy: 0.54767
Time: 2018-07-15 04:21:11
TRAINING STATS: batch 198/486 in epoch 657,  batch loss: 1.63854, batch accuracy: 0.55750
Time: 2018-07-15 04:21:15
TRAINING STATS: batch 248/486 in epoch 657,  batch loss: 1.66102, batch accuracy: 0.55600
Time: 2018-07-15 04:21:20
TRAINING STATS: batch 298/486 in epoch 657,  batch loss: 1.67993, batch accuracy: 0.54800
Time: 2018-07-15 04:21:23
TRAINING STATS: batch 348/486 in epoch 657,  batch loss: 1.64417, batch accuracy: 0.56117
Time: 2018-07-15 04:21:27
TRAINING STATS: batch 398/486 in epoch 657,  batch loss: 1.64075, batch accuracy: 0.55933
Time: 2018-07-15 04:21:32
TRAINING STATS: batch 448/486 in epoch 657,  batch loss: 1.71806, batch accuracy: 0.53967
Time: 2018-07-15 04:21:35
TRAINING STATS: batch 12/486 in epoch 658,   batch loss: 1.65632, batch accuracy: 0.55150
Time: 2018-07-15 04:21:39
TRAINING STATS: batch 62/486 in epoch 658,   batch loss: 1.72679, batch accuracy: 0.53350
Time: 2018-07-15 04:21:44
TRAINING STATS: batch 112/486 in epoch 658,  batch loss: 1.63052, batch accuracy: 0.56067
Time: 2018-07-15 04:21:47
TRAINING STATS: batch 162/486 in epoch 658,  batch loss: 1.66320, batch accuracy: 0.55167
Time: 2018-07-15 04:21:51
TRAINING STATS: batch 212/486 in epoch 658,  batch loss: 1.56894, batch accuracy: 0.57733
Time: 2018-07-15 04:21:56
TRAINING STATS: batch 262/486 in epoch 658,  batch loss: 1.70503, batch accuracy: 0.54050
Time: 2018-07-15 04:21:59
TRAINING STATS: batch 312/486 in epoch 658,  batch loss: 1.66064, batch accuracy: 0.54650
Time: 2018-07-15 04:22:03
TRAINING STATS: batch 362/486 in epoch 658,  batch loss: 1.63776, batch accuracy: 0.55483
Time: 2018-07-15 04:22:08
TRAINING STATS: batch 412/486 in epoch 658,  batch loss: 1.59870, batch accuracy: 0.57050
Time: 2018-07-15 04:22:11
TRAINING STATS: batch 462/486 in epoch 658,  batch loss: 1.64863, batch accuracy: 0.56133
Time: 2018-07-15 04:22:15
TRAINING STATS: batch 26/486 in epoch 659,   batch loss: 1.69392, batch accuracy: 0.54367
Time: 2018-07-15 04:22:20
TRAINING STATS: batch 76/486 in epoch 659,   batch loss: 1.69304, batch accuracy: 0.54650
Time: 2018-07-15 04:22:23
TRAINING STATS: batch 126/486 in epoch 659,  batch loss: 1.69234, batch accuracy: 0.53783
Time: 2018-07-15 04:22:27
TRAINING STATS: batch 176/486 in epoch 659,  batch loss: 1.56262, batch accuracy: 0.58450
Time: 2018-07-15 04:22:32
TRAINING STATS: batch 226/486 in epoch 659,  batch loss: 1.63262, batch accuracy: 0.56400
Time: 2018-07-15 04:22:35
TRAINING STATS: batch 276/486 in epoch 659,  batch loss: 1.65831, batch accuracy: 0.55000
Time: 2018-07-15 04:22:39
TRAINING STATS: batch 326/486 in epoch 659,  batch loss: 1.69025, batch accuracy: 0.54717
Time: 2018-07-15 04:22:44
TRAINING STATS: batch 376/486 in epoch 659,  batch loss: 1.69174, batch accuracy: 0.54667
Time: 2018-07-15 04:22:47
TRAINING STATS: batch 426/486 in epoch 659,  batch loss: 1.63688, batch accuracy: 0.55200
Time: 2018-07-15 04:22:51
TRAINING STATS: batch 476/486 in epoch 659,  batch loss: 1.59402, batch accuracy: 0.57433
Time: 2018-07-15 04:22:56
TRAINING STATS: batch 40/486 in epoch 660,   batch loss: 1.61858, batch accuracy: 0.56150
Time: 2018-07-15 04:23:00
TRAINING STATS: batch 90/486 in epoch 660,   batch loss: 1.67785, batch accuracy: 0.55267
Time: 2018-07-15 04:23:03
TRAINING STATS: batch 140/486 in epoch 660,  batch loss: 1.59417, batch accuracy: 0.57300
Time: 2018-07-15 04:23:08
TRAINING STATS: batch 190/486 in epoch 660,  batch loss: 1.62252, batch accuracy: 0.56017
Time: 2018-07-15 04:23:12
TRAINING STATS: batch 240/486 in epoch 660,  batch loss: 1.62200, batch accuracy: 0.56033
Time: 2018-07-15 04:23:15
TRAINING STATS: batch 290/486 in epoch 660,  batch loss: 1.68486, batch accuracy: 0.54900
Time: 2018-07-15 04:23:20
TRAINING STATS: batch 340/486 in epoch 660,  batch loss: 1.71727, batch accuracy: 0.53733
Time: 2018-07-15 04:23:24
TRAINING STATS: batch 390/486 in epoch 660,  batch loss: 1.57751, batch accuracy: 0.57567
Time: 2018-07-15 04:23:27
TRAINING STATS: batch 440/486 in epoch 660,  batch loss: 1.65197, batch accuracy: 0.55500
Time: 2018-07-15 04:23:32
TRAINING STATS: batch 4/486 in epoch 661,    batch loss: 1.59102, batch accuracy: 0.58050
Time: 2018-07-15 04:23:36
TRAINING STATS: batch 54/486 in epoch 661,   batch loss: 1.64040, batch accuracy: 0.55650
Time: 2018-07-15 04:23:39
TRAINING STATS: batch 104/486 in epoch 661,  batch loss: 1.72354, batch accuracy: 0.53983
Time: 2018-07-15 04:23:44
TRAINING STATS: batch 154/486 in epoch 661,  batch loss: 1.62632, batch accuracy: 0.56450
Time: 2018-07-15 04:23:48
TRAINING STATS: batch 204/486 in epoch 661,  batch loss: 1.71385, batch accuracy: 0.53767
Time: 2018-07-15 04:23:51
TRAINING STATS: batch 254/486 in epoch 661,  batch loss: 1.56227, batch accuracy: 0.57617
Time: 2018-07-15 04:23:56
TRAINING STATS: batch 304/486 in epoch 661,  batch loss: 1.62186, batch accuracy: 0.55883
Time: 2018-07-15 04:24:00
TRAINING STATS: batch 354/486 in epoch 661,  batch loss: 1.64887, batch accuracy: 0.55667
Time: 2018-07-15 04:24:04
TRAINING STATS: batch 404/486 in epoch 661,  batch loss: 1.63710, batch accuracy: 0.55733
Time: 2018-07-15 04:24:08
TRAINING STATS: batch 454/486 in epoch 661,  batch loss: 1.52572, batch accuracy: 0.58483
Time: 2018-07-15 04:24:12
TRAINING STATS: batch 18/486 in epoch 662,   batch loss: 1.66931, batch accuracy: 0.55267
Time: 2018-07-15 04:24:16
TRAINING STATS: batch 68/486 in epoch 662,   batch loss: 1.49214, batch accuracy: 0.60783
Time: 2018-07-15 04:24:20
TRAINING STATS: batch 118/486 in epoch 662,  batch loss: 1.63227, batch accuracy: 0.56667
Time: 2018-07-15 04:24:24
TRAINING STATS: batch 168/486 in epoch 662,  batch loss: 1.55903, batch accuracy: 0.58617
Time: 2018-07-15 04:24:28
TRAINING STATS: batch 218/486 in epoch 662,  batch loss: 1.63480, batch accuracy: 0.55550
Time: 2018-07-15 04:24:32
TRAINING STATS: batch 268/486 in epoch 662,  batch loss: 1.58623, batch accuracy: 0.56850
Time: 2018-07-15 04:24:36
TRAINING STATS: batch 318/486 in epoch 662,  batch loss: 1.64750, batch accuracy: 0.55150
Time: 2018-07-15 04:24:40
TRAINING STATS: batch 368/486 in epoch 662,  batch loss: 1.64898, batch accuracy: 0.55583
Time: 2018-07-15 04:24:44
TRAINING STATS: batch 418/486 in epoch 662,  batch loss: 1.73311, batch accuracy: 0.52383
Time: 2018-07-15 04:24:48
TRAINING STATS: batch 468/486 in epoch 662,  batch loss: 1.65029, batch accuracy: 0.55883
Time: 2018-07-15 04:24:52
TRAINING STATS: batch 32/486 in epoch 663,   batch loss: 1.60198, batch accuracy: 0.56733
Time: 2018-07-15 04:24:57
TRAINING STATS: batch 82/486 in epoch 663,   batch loss: 1.70869, batch accuracy: 0.53583
Time: 2018-07-15 04:25:00
TRAINING STATS: batch 132/486 in epoch 663,  batch loss: 1.63225, batch accuracy: 0.56900
Time: 2018-07-15 04:25:04
TRAINING STATS: batch 182/486 in epoch 663,  batch loss: 1.71247, batch accuracy: 0.54117
Time: 2018-07-15 04:25:09
TRAINING STATS: batch 232/486 in epoch 663,  batch loss: 1.67643, batch accuracy: 0.54683
Time: 2018-07-15 04:25:12
TRAINING STATS: batch 282/486 in epoch 663,  batch loss: 1.61482, batch accuracy: 0.56150
Time: 2018-07-15 04:25:16
TRAINING STATS: batch 332/486 in epoch 663,  batch loss: 1.67435, batch accuracy: 0.54917
Time: 2018-07-15 04:25:21
TRAINING STATS: batch 382/486 in epoch 663,  batch loss: 1.65250, batch accuracy: 0.56000
Time: 2018-07-15 04:25:24
TRAINING STATS: batch 432/486 in epoch 663,  batch loss: 1.57624, batch accuracy: 0.57417
Time: 2018-07-15 04:25:28
TRAINING STATS: batch 482/486 in epoch 663,  batch loss: 1.63096, batch accuracy: 0.56033
Time: 2018-07-15 04:25:33
TRAINING STATS: batch 46/486 in epoch 664,   batch loss: 1.63338, batch accuracy: 0.57033
Time: 2018-07-15 04:25:36
TRAINING STATS: batch 96/486 in epoch 664,   batch loss: 1.67902, batch accuracy: 0.55033
Time: 2018-07-15 04:25:40
TRAINING STATS: batch 146/486 in epoch 664,  batch loss: 1.70771, batch accuracy: 0.54533
Time: 2018-07-15 04:25:45
TRAINING STATS: batch 196/486 in epoch 664,  batch loss: 1.68686, batch accuracy: 0.54800
Time: 2018-07-15 04:25:48
TRAINING STATS: batch 246/486 in epoch 664,  batch loss: 1.61460, batch accuracy: 0.56667
Time: 2018-07-15 04:25:52
TRAINING STATS: batch 296/486 in epoch 664,  batch loss: 1.61266, batch accuracy: 0.56200
Time: 2018-07-15 04:25:57
TRAINING STATS: batch 346/486 in epoch 664,  batch loss: 1.55351, batch accuracy: 0.58817
Time: 2018-07-15 04:26:01
TRAINING STATS: batch 396/486 in epoch 664,  batch loss: 1.62056, batch accuracy: 0.56267
Time: 2018-07-15 04:26:04
TRAINING STATS: batch 446/486 in epoch 664,  batch loss: 1.65450, batch accuracy: 0.55283
Time: 2018-07-15 04:26:09
TRAINING STATS: batch 10/486 in epoch 665,   batch loss: 1.68284, batch accuracy: 0.54250
Time: 2018-07-15 04:26:13
TRAINING STATS: batch 60/486 in epoch 665,   batch loss: 1.62326, batch accuracy: 0.56783
Time: 2018-07-15 04:26:16
TRAINING STATS: batch 110/486 in epoch 665,  batch loss: 1.71952, batch accuracy: 0.54050
Time: 2018-07-15 04:26:21
TRAINING STATS: batch 160/486 in epoch 665,  batch loss: 1.62510, batch accuracy: 0.56250
Time: 2018-07-15 04:26:25
TRAINING STATS: batch 210/486 in epoch 665,  batch loss: 1.57836, batch accuracy: 0.57500
Time: 2018-07-15 04:26:28
TRAINING STATS: batch 260/486 in epoch 665,  batch loss: 1.68640, batch accuracy: 0.54083
Time: 2018-07-15 04:26:33
TRAINING STATS: batch 310/486 in epoch 665,  batch loss: 1.64733, batch accuracy: 0.55583
Time: 2018-07-15 04:26:37
TRAINING STATS: batch 360/486 in epoch 665,  batch loss: 1.68999, batch accuracy: 0.54367
Time: 2018-07-15 04:26:40
TRAINING STATS: batch 410/486 in epoch 665,  batch loss: 1.60243, batch accuracy: 0.57650
Time: 2018-07-15 04:26:45
TRAINING STATS: batch 460/486 in epoch 665,  batch loss: 1.76625, batch accuracy: 0.52267
Time: 2018-07-15 04:26:49
TRAINING STATS: batch 24/486 in epoch 666,   batch loss: 1.73262, batch accuracy: 0.53533
Time: 2018-07-15 04:26:52
TRAINING STATS: batch 74/486 in epoch 666,   batch loss: 1.67378, batch accuracy: 0.55067
Time: 2018-07-15 04:26:57
TRAINING STATS: batch 124/486 in epoch 666,  batch loss: 1.67070, batch accuracy: 0.55783
Time: 2018-07-15 04:27:01
TRAINING STATS: batch 174/486 in epoch 666,  batch loss: 1.71934, batch accuracy: 0.53533
Time: 2018-07-15 04:27:04
TRAINING STATS: batch 224/486 in epoch 666,  batch loss: 1.69874, batch accuracy: 0.54717
Time: 2018-07-15 04:27:09
TRAINING STATS: batch 274/486 in epoch 666,  batch loss: 1.65039, batch accuracy: 0.55250
Time: 2018-07-15 04:27:13
TRAINING STATS: batch 324/486 in epoch 666,  batch loss: 1.68983, batch accuracy: 0.54700
Time: 2018-07-15 04:27:17
TRAINING STATS: batch 374/486 in epoch 666,  batch loss: 1.68845, batch accuracy: 0.54933
Time: 2018-07-15 04:27:21
TRAINING STATS: batch 424/486 in epoch 666,  batch loss: 1.58701, batch accuracy: 0.57700
Time: 2018-07-15 04:27:25
TRAINING STATS: batch 474/486 in epoch 666,  batch loss: 1.64920, batch accuracy: 0.56083
Time: 2018-07-15 04:27:29
TRAINING STATS: batch 38/486 in epoch 667,   batch loss: 1.67064, batch accuracy: 0.55450
Time: 2018-07-15 04:27:33
TRAINING STATS: batch 88/486 in epoch 667,   batch loss: 1.70344, batch accuracy: 0.53217
Time: 2018-07-15 04:27:37
TRAINING STATS: batch 138/486 in epoch 667,  batch loss: 1.69140, batch accuracy: 0.54050
Time: 2018-07-15 04:27:41
TRAINING STATS: batch 188/486 in epoch 667,  batch loss: 1.60258, batch accuracy: 0.56883
Time: 2018-07-15 04:27:45
TRAINING STATS: batch 238/486 in epoch 667,  batch loss: 1.62450, batch accuracy: 0.56467
Time: 2018-07-15 04:27:49
TRAINING STATS: batch 288/486 in epoch 667,  batch loss: 1.66936, batch accuracy: 0.55117
Time: 2018-07-15 04:27:53
TRAINING STATS: batch 338/486 in epoch 667,  batch loss: 1.72663, batch accuracy: 0.53650
Time: 2018-07-15 04:27:57
TRAINING STATS: batch 388/486 in epoch 667,  batch loss: 1.64856, batch accuracy: 0.56067
Time: 2018-07-15 04:28:01
TRAINING STATS: batch 438/486 in epoch 667,  batch loss: 1.69060, batch accuracy: 0.55167
Time: 2018-07-15 04:28:05
TRAINING STATS: batch 2/486 in epoch 668,    batch loss: 1.65992, batch accuracy: 0.55400
Time: 2018-07-15 04:28:09
TRAINING STATS: batch 52/486 in epoch 668,   batch loss: 1.71152, batch accuracy: 0.53717
Time: 2018-07-15 04:28:13
TRAINING STATS: batch 102/486 in epoch 668,  batch loss: 1.69101, batch accuracy: 0.54583
Time: 2018-07-15 04:28:17
TRAINING STATS: batch 152/486 in epoch 668,  batch loss: 1.60793, batch accuracy: 0.57450
Time: 2018-07-15 04:28:21
TRAINING STATS: batch 202/486 in epoch 668,  batch loss: 1.66421, batch accuracy: 0.55250
Time: 2018-07-15 04:28:25
TRAINING STATS: batch 252/486 in epoch 668,  batch loss: 1.62119, batch accuracy: 0.56450
Time: 2018-07-15 04:28:29
TRAINING STATS: batch 302/486 in epoch 668,  batch loss: 1.61695, batch accuracy: 0.56133
Time: 2018-07-15 04:28:34
TRAINING STATS: batch 352/486 in epoch 668,  batch loss: 1.62633, batch accuracy: 0.56333
Time: 2018-07-15 04:28:37
TRAINING STATS: batch 402/486 in epoch 668,  batch loss: 1.54189, batch accuracy: 0.59833
Time: 2018-07-15 04:28:41
TRAINING STATS: batch 452/486 in epoch 668,  batch loss: 1.65715, batch accuracy: 0.55983
Time: 2018-07-15 04:28:46
TRAINING STATS: batch 16/486 in epoch 669,   batch loss: 1.62599, batch accuracy: 0.56633
Time: 2018-07-15 04:28:49
TRAINING STATS: batch 66/486 in epoch 669,   batch loss: 1.63145, batch accuracy: 0.57050
Time: 2018-07-15 04:28:53
TRAINING STATS: batch 116/486 in epoch 669,  batch loss: 1.60805, batch accuracy: 0.57250
Time: 2018-07-15 04:28:58
TRAINING STATS: batch 166/486 in epoch 669,  batch loss: 1.57189, batch accuracy: 0.57983
Time: 2018-07-15 04:29:01
TRAINING STATS: batch 216/486 in epoch 669,  batch loss: 1.69175, batch accuracy: 0.55217
Time: 2018-07-15 04:29:05
TRAINING STATS: batch 266/486 in epoch 669,  batch loss: 1.64874, batch accuracy: 0.55750
Time: 2018-07-15 04:29:10
TRAINING STATS: batch 316/486 in epoch 669,  batch loss: 1.65543, batch accuracy: 0.55250
Time: 2018-07-15 04:29:13
TRAINING STATS: batch 366/486 in epoch 669,  batch loss: 1.70614, batch accuracy: 0.54067
Time: 2018-07-15 04:29:17
TRAINING STATS: batch 416/486 in epoch 669,  batch loss: 1.68269, batch accuracy: 0.54600
Time: 2018-07-15 04:29:22
TRAINING STATS: batch 466/486 in epoch 669,  batch loss: 1.52319, batch accuracy: 0.59900
Time: 2018-07-15 04:29:25
TRAINING STATS: batch 30/486 in epoch 670,   batch loss: 1.53482, batch accuracy: 0.58833
Time: 2018-07-15 04:29:29
TRAINING STATS: batch 80/486 in epoch 670,   batch loss: 1.64136, batch accuracy: 0.55633
Time: 2018-07-15 04:29:34
TRAINING STATS: batch 130/486 in epoch 670,  batch loss: 1.63652, batch accuracy: 0.56567
Time: 2018-07-15 04:29:37
TRAINING STATS: batch 180/486 in epoch 670,  batch loss: 1.67543, batch accuracy: 0.55450
Time: 2018-07-15 04:29:41
TRAINING STATS: batch 230/486 in epoch 670,  batch loss: 1.67624, batch accuracy: 0.54200
Time: 2018-07-15 04:29:46
TRAINING STATS: batch 280/486 in epoch 670,  batch loss: 1.63737, batch accuracy: 0.55917
Time: 2018-07-15 04:29:49
TRAINING STATS: batch 330/486 in epoch 670,  batch loss: 1.62240, batch accuracy: 0.56183
Time: 2018-07-15 04:29:53
TRAINING STATS: batch 380/486 in epoch 670,  batch loss: 1.63007, batch accuracy: 0.56767
Time: 2018-07-15 04:29:58
TRAINING STATS: batch 430/486 in epoch 670,  batch loss: 1.59159, batch accuracy: 0.58083
Time: 2018-07-15 04:30:01
TRAINING STATS: batch 480/486 in epoch 670,  batch loss: 1.65452, batch accuracy: 0.55517
Time: 2018-07-15 04:30:05
TRAINING STATS: batch 44/486 in epoch 671,   batch loss: 1.58416, batch accuracy: 0.58167
Time: 2018-07-15 04:30:10
TRAINING STATS: batch 94/486 in epoch 671,   batch loss: 1.68789, batch accuracy: 0.55183
Time: 2018-07-15 04:30:13
TRAINING STATS: batch 144/486 in epoch 671,  batch loss: 1.73578, batch accuracy: 0.52933
Time: 2018-07-15 04:30:17
TRAINING STATS: batch 194/486 in epoch 671,  batch loss: 1.73955, batch accuracy: 0.53450
Time: 2018-07-15 04:30:22
TRAINING STATS: batch 244/486 in epoch 671,  batch loss: 1.63578, batch accuracy: 0.55950
Time: 2018-07-15 04:30:25
TRAINING STATS: batch 294/486 in epoch 671,  batch loss: 1.56256, batch accuracy: 0.57917
Time: 2018-07-15 04:30:29
TRAINING STATS: batch 344/486 in epoch 671,  batch loss: 1.61732, batch accuracy: 0.56717
Time: 2018-07-15 04:30:34
TRAINING STATS: batch 394/486 in epoch 671,  batch loss: 1.60830, batch accuracy: 0.57517
Time: 2018-07-15 04:30:38
TRAINING STATS: batch 444/486 in epoch 671,  batch loss: 1.58276, batch accuracy: 0.57883
Time: 2018-07-15 04:30:41
TRAINING STATS: batch 8/486 in epoch 672,    batch loss: 1.63374, batch accuracy: 0.56033
Time: 2018-07-15 04:30:46
TRAINING STATS: batch 58/486 in epoch 672,   batch loss: 1.61185, batch accuracy: 0.56700
Time: 2018-07-15 04:30:50
TRAINING STATS: batch 108/486 in epoch 672,  batch loss: 1.71836, batch accuracy: 0.54850
Time: 2018-07-15 04:30:53
TRAINING STATS: batch 158/486 in epoch 672,  batch loss: 1.70179, batch accuracy: 0.54400
Time: 2018-07-15 04:30:58
TRAINING STATS: batch 208/486 in epoch 672,  batch loss: 1.67212, batch accuracy: 0.55000
Time: 2018-07-15 04:31:02
TRAINING STATS: batch 258/486 in epoch 672,  batch loss: 1.60757, batch accuracy: 0.56333
Time: 2018-07-15 04:31:05
TRAINING STATS: batch 308/486 in epoch 672,  batch loss: 1.65712, batch accuracy: 0.56000
Time: 2018-07-15 04:31:10
TRAINING STATS: batch 358/486 in epoch 672,  batch loss: 1.67771, batch accuracy: 0.54950
Time: 2018-07-15 04:31:14
TRAINING STATS: batch 408/486 in epoch 672,  batch loss: 1.67233, batch accuracy: 0.55017
Time: 2018-07-15 04:31:17
TRAINING STATS: batch 458/486 in epoch 672,  batch loss: 1.66295, batch accuracy: 0.55617
Time: 2018-07-15 04:31:22
TRAINING STATS: batch 22/486 in epoch 673,   batch loss: 1.69841, batch accuracy: 0.55033
Time: 2018-07-15 04:31:26
TRAINING STATS: batch 72/486 in epoch 673,   batch loss: 1.67318, batch accuracy: 0.54750
Time: 2018-07-15 04:31:29
TRAINING STATS: batch 122/486 in epoch 673,  batch loss: 1.58687, batch accuracy: 0.57700
Time: 2018-07-15 04:31:34
TRAINING STATS: batch 172/486 in epoch 673,  batch loss: 1.70531, batch accuracy: 0.53700
Time: 2018-07-15 04:31:38
TRAINING STATS: batch 222/486 in epoch 673,  batch loss: 1.64953, batch accuracy: 0.55833
Time: 2018-07-15 04:31:42
TRAINING STATS: batch 272/486 in epoch 673,  batch loss: 1.69043, batch accuracy: 0.53983
Time: 2018-07-15 04:31:46
TRAINING STATS: batch 322/486 in epoch 673,  batch loss: 1.64479, batch accuracy: 0.55600
Time: 2018-07-15 04:31:50
TRAINING STATS: batch 372/486 in epoch 673,  batch loss: 1.59417, batch accuracy: 0.57333
Time: 2018-07-15 04:31:53
TRAINING STATS: batch 422/486 in epoch 673,  batch loss: 1.62407, batch accuracy: 0.56000
Time: 2018-07-15 04:31:58
TRAINING STATS: batch 472/486 in epoch 673,  batch loss: 1.71255, batch accuracy: 0.53917
Time: 2018-07-15 04:32:02
TRAINING STATS: batch 36/486 in epoch 674,   batch loss: 1.71606, batch accuracy: 0.54000
Time: 2018-07-15 04:32:06
TRAINING STATS: batch 86/486 in epoch 674,   batch loss: 1.63644, batch accuracy: 0.56433
Time: 2018-07-15 04:32:10
TRAINING STATS: batch 136/486 in epoch 674,  batch loss: 1.69133, batch accuracy: 0.54283
Time: 2018-07-15 04:32:14
TRAINING STATS: batch 186/486 in epoch 674,  batch loss: 1.64705, batch accuracy: 0.55800
Time: 2018-07-15 04:32:18
TRAINING STATS: batch 236/486 in epoch 674,  batch loss: 1.69511, batch accuracy: 0.53400
Time: 2018-07-15 04:32:22
TRAINING STATS: batch 286/486 in epoch 674,  batch loss: 1.69025, batch accuracy: 0.55167
Time: 2018-07-15 04:32:26
TRAINING STATS: batch 336/486 in epoch 674,  batch loss: 1.63412, batch accuracy: 0.56350
Time: 2018-07-15 04:32:30
TRAINING STATS: batch 386/486 in epoch 674,  batch loss: 1.70659, batch accuracy: 0.53167
Time: 2018-07-15 04:32:34
TRAINING STATS: batch 436/486 in epoch 674,  batch loss: 1.67024, batch accuracy: 0.55367
Time: 2018-07-15 04:32:38
TRAINING STATS: batch 0/486 in epoch 675,    batch loss: 1.65933, batch accuracy: 0.54983
Time: 2018-07-15 04:32:42
TRAINING STATS: batch 50/486 in epoch 675,   batch loss: 1.61726, batch accuracy: 0.57450
Time: 2018-07-15 04:32:47
TRAINING STATS: batch 100/486 in epoch 675,  batch loss: 1.66690, batch accuracy: 0.56017
Time: 2018-07-15 04:32:50
TRAINING STATS: batch 150/486 in epoch 675,  batch loss: 1.61132, batch accuracy: 0.56950
Time: 2018-07-15 04:32:54
TRAINING STATS: batch 200/486 in epoch 675,  batch loss: 1.52885, batch accuracy: 0.59017
Time: 2018-07-15 04:32:58
TRAINING STATS: batch 250/486 in epoch 675,  batch loss: 1.70294, batch accuracy: 0.53717
Time: 2018-07-15 04:33:02
TRAINING STATS: batch 300/486 in epoch 675,  batch loss: 1.67629, batch accuracy: 0.54167
Time: 2018-07-15 04:33:06
TRAINING STATS: batch 350/486 in epoch 675,  batch loss: 1.65115, batch accuracy: 0.56167
Time: 2018-07-15 04:33:10
TRAINING STATS: batch 400/486 in epoch 675,  batch loss: 1.54054, batch accuracy: 0.58883
Time: 2018-07-15 04:33:14
TRAINING STATS: batch 450/486 in epoch 675,  batch loss: 1.71078, batch accuracy: 0.53800
Time: 2018-07-15 04:33:18
TRAINING STATS: batch 14/486 in epoch 676,   batch loss: 1.57648, batch accuracy: 0.57583
Time: 2018-07-15 04:33:23
TRAINING STATS: batch 64/486 in epoch 676,   batch loss: 1.74931, batch accuracy: 0.52717
Time: 2018-07-15 04:33:26
TRAINING STATS: batch 114/486 in epoch 676,  batch loss: 1.68887, batch accuracy: 0.54717
Time: 2018-07-15 04:33:30
TRAINING STATS: batch 164/486 in epoch 676,  batch loss: 1.57219, batch accuracy: 0.57967
Time: 2018-07-15 04:33:35
TRAINING STATS: batch 214/486 in epoch 676,  batch loss: 1.65292, batch accuracy: 0.55817
Time: 2018-07-15 04:33:38
TRAINING STATS: batch 264/486 in epoch 676,  batch loss: 1.72137, batch accuracy: 0.53183
Time: 2018-07-15 04:33:42
TRAINING STATS: batch 314/486 in epoch 676,  batch loss: 1.72534, batch accuracy: 0.52833
Time: 2018-07-15 04:33:47
TRAINING STATS: batch 364/486 in epoch 676,  batch loss: 1.64187, batch accuracy: 0.56033
Time: 2018-07-15 04:33:50
TRAINING STATS: batch 414/486 in epoch 676,  batch loss: 1.59149, batch accuracy: 0.57450
Time: 2018-07-15 04:33:54
TRAINING STATS: batch 464/486 in epoch 676,  batch loss: 1.60248, batch accuracy: 0.57467
Time: 2018-07-15 04:33:59
TRAINING STATS: batch 28/486 in epoch 677,   batch loss: 1.56497, batch accuracy: 0.58200
Time: 2018-07-15 04:34:02
TRAINING STATS: batch 78/486 in epoch 677,   batch loss: 1.64252, batch accuracy: 0.56550
Time: 2018-07-15 04:34:06
TRAINING STATS: batch 128/486 in epoch 677,  batch loss: 1.64794, batch accuracy: 0.56150
Time: 2018-07-15 04:34:11
TRAINING STATS: batch 178/486 in epoch 677,  batch loss: 1.53262, batch accuracy: 0.58283
Time: 2018-07-15 04:34:14
TRAINING STATS: batch 228/486 in epoch 677,  batch loss: 1.59219, batch accuracy: 0.57233
Time: 2018-07-15 04:34:18
TRAINING STATS: batch 278/486 in epoch 677,  batch loss: 1.58448, batch accuracy: 0.57917
Time: 2018-07-15 04:34:23
TRAINING STATS: batch 328/486 in epoch 677,  batch loss: 1.60873, batch accuracy: 0.56833
Time: 2018-07-15 04:34:27
TRAINING STATS: batch 378/486 in epoch 677,  batch loss: 1.65323, batch accuracy: 0.56483
Time: 2018-07-15 04:34:30
TRAINING STATS: batch 428/486 in epoch 677,  batch loss: 1.69937, batch accuracy: 0.54033
Time: 2018-07-15 04:34:35
TRAINING STATS: batch 478/486 in epoch 677,  batch loss: 1.65528, batch accuracy: 0.55400
Time: 2018-07-15 04:34:39
TRAINING STATS: batch 42/486 in epoch 678,   batch loss: 1.56156, batch accuracy: 0.58450
Time: 2018-07-15 04:34:42
TRAINING STATS: batch 92/486 in epoch 678,   batch loss: 1.64930, batch accuracy: 0.55383
Time: 2018-07-15 04:34:47
TRAINING STATS: batch 142/486 in epoch 678,  batch loss: 1.60926, batch accuracy: 0.56967
Time: 2018-07-15 04:34:51
TRAINING STATS: batch 192/486 in epoch 678,  batch loss: 1.64016, batch accuracy: 0.56067
Time: 2018-07-15 04:34:54
TRAINING STATS: batch 242/486 in epoch 678,  batch loss: 1.60562, batch accuracy: 0.56650
Time: 2018-07-15 04:34:59
TRAINING STATS: batch 292/486 in epoch 678,  batch loss: 1.64815, batch accuracy: 0.55750
Time: 2018-07-15 04:35:03
TRAINING STATS: batch 342/486 in epoch 678,  batch loss: 1.63231, batch accuracy: 0.56217
Time: 2018-07-15 04:35:06
TRAINING STATS: batch 392/486 in epoch 678,  batch loss: 1.56085, batch accuracy: 0.58517
Time: 2018-07-15 04:35:11
TRAINING STATS: batch 442/486 in epoch 678,  batch loss: 1.55418, batch accuracy: 0.58717
Time: 2018-07-15 04:35:15
TRAINING STATS: batch 6/486 in epoch 679,    batch loss: 1.69938, batch accuracy: 0.54533
Time: 2018-07-15 04:35:18
TRAINING STATS: batch 56/486 in epoch 679,   batch loss: 1.60256, batch accuracy: 0.56850
Time: 2018-07-15 04:35:23
TRAINING STATS: batch 106/486 in epoch 679,  batch loss: 1.73498, batch accuracy: 0.53050
Time: 2018-07-15 04:35:27
TRAINING STATS: batch 156/486 in epoch 679,  batch loss: 1.67605, batch accuracy: 0.54850
Time: 2018-07-15 04:35:30
TRAINING STATS: batch 206/486 in epoch 679,  batch loss: 1.71002, batch accuracy: 0.53833
Time: 2018-07-15 04:35:35
TRAINING STATS: batch 256/486 in epoch 679,  batch loss: 1.57687, batch accuracy: 0.57100
Time: 2018-07-15 04:35:39
TRAINING STATS: batch 306/486 in epoch 679,  batch loss: 1.64219, batch accuracy: 0.56017
Time: 2018-07-15 04:35:42
TRAINING STATS: batch 356/486 in epoch 679,  batch loss: 1.68060, batch accuracy: 0.54817
Time: 2018-07-15 04:35:47
TRAINING STATS: batch 406/486 in epoch 679,  batch loss: 1.72965, batch accuracy: 0.53233
Time: 2018-07-15 04:35:51
TRAINING STATS: batch 456/486 in epoch 679,  batch loss: 1.53441, batch accuracy: 0.59217
Time: 2018-07-15 04:35:54
TRAINING STATS: batch 20/486 in epoch 680,   batch loss: 1.65366, batch accuracy: 0.56217
Time: 2018-07-15 04:35:59
TRAINING STATS: batch 70/486 in epoch 680,   batch loss: 1.53148, batch accuracy: 0.59467
Time: 2018-07-15 04:36:03
TRAINING STATS: batch 120/486 in epoch 680,  batch loss: 1.60130, batch accuracy: 0.56933
Time: 2018-07-15 04:36:07
TRAINING STATS: batch 170/486 in epoch 680,  batch loss: 1.63355, batch accuracy: 0.55850
Time: 2018-07-15 04:36:11
TRAINING STATS: batch 220/486 in epoch 680,  batch loss: 1.56228, batch accuracy: 0.58483
Time: 2018-07-15 04:36:15
TRAINING STATS: batch 270/486 in epoch 680,  batch loss: 1.65410, batch accuracy: 0.54217
Time: 2018-07-15 04:36:19
TRAINING STATS: batch 320/486 in epoch 680,  batch loss: 1.57466, batch accuracy: 0.57217
Time: 2018-07-15 04:36:23
TRAINING STATS: batch 370/486 in epoch 680,  batch loss: 1.63511, batch accuracy: 0.56300
Time: 2018-07-15 04:36:27
TRAINING STATS: batch 420/486 in epoch 680,  batch loss: 1.67554, batch accuracy: 0.54900
Time: 2018-07-15 04:36:31
TRAINING STATS: batch 470/486 in epoch 680,  batch loss: 1.73738, batch accuracy: 0.52967
Time: 2018-07-15 04:36:36
TRAINING STATS: batch 34/486 in epoch 681,   batch loss: 1.67238, batch accuracy: 0.55717
Time: 2018-07-15 04:36:39
TRAINING STATS: batch 84/486 in epoch 681,   batch loss: 1.66202, batch accuracy: 0.54850
Time: 2018-07-15 04:36:43
TRAINING STATS: batch 134/486 in epoch 681,  batch loss: 1.69271, batch accuracy: 0.54750
Time: 2018-07-15 04:36:48
TRAINING STATS: batch 184/486 in epoch 681,  batch loss: 1.65586, batch accuracy: 0.55450
Time: 2018-07-15 04:36:51
TRAINING STATS: batch 234/486 in epoch 681,  batch loss: 1.75786, batch accuracy: 0.52550
Time: 2018-07-15 04:36:55
TRAINING STATS: batch 284/486 in epoch 681,  batch loss: 1.70268, batch accuracy: 0.54000
Time: 2018-07-15 04:37:00
TRAINING STATS: batch 334/486 in epoch 681,  batch loss: 1.63096, batch accuracy: 0.56617
Time: 2018-07-15 04:37:03
TRAINING STATS: batch 384/486 in epoch 681,  batch loss: 1.62639, batch accuracy: 0.56800
Time: 2018-07-15 04:37:07
TRAINING STATS: batch 434/486 in epoch 681,  batch loss: 1.69570, batch accuracy: 0.54183
Time: 2018-07-15 04:37:12
TRAINING STATS: batch 484/486 in epoch 681,  batch loss: 1.64606, batch accuracy: 0.55967
Time: 2018-07-15 04:37:15
TRAINING STATS: batch 48/486 in epoch 682,   batch loss: 1.64585, batch accuracy: 0.55767
Time: 2018-07-15 04:37:19
TRAINING STATS: batch 98/486 in epoch 682,   batch loss: 1.59192, batch accuracy: 0.57250
Time: 2018-07-15 04:37:24
TRAINING STATS: batch 148/486 in epoch 682,  batch loss: 1.67148, batch accuracy: 0.55600
Time: 2018-07-15 04:37:28
TRAINING STATS: batch 198/486 in epoch 682,  batch loss: 1.62722, batch accuracy: 0.56133
Time: 2018-07-15 04:37:31
TRAINING STATS: batch 248/486 in epoch 682,  batch loss: 1.67802, batch accuracy: 0.54833
Time: 2018-07-15 04:37:36
TRAINING STATS: batch 298/486 in epoch 682,  batch loss: 1.67282, batch accuracy: 0.54783
Time: 2018-07-15 04:37:40
TRAINING STATS: batch 348/486 in epoch 682,  batch loss: 1.65150, batch accuracy: 0.56217
Time: 2018-07-15 04:37:43
TRAINING STATS: batch 398/486 in epoch 682,  batch loss: 1.64169, batch accuracy: 0.55717
Time: 2018-07-15 04:37:48
TRAINING STATS: batch 448/486 in epoch 682,  batch loss: 1.65599, batch accuracy: 0.56083
Time: 2018-07-15 04:37:51
TRAINING STATS: batch 12/486 in epoch 683,   batch loss: 1.66185, batch accuracy: 0.54750
Time: 2018-07-15 04:37:55
TRAINING STATS: batch 62/486 in epoch 683,   batch loss: 1.71707, batch accuracy: 0.53933
Time: 2018-07-15 04:38:00
TRAINING STATS: batch 112/486 in epoch 683,  batch loss: 1.63175, batch accuracy: 0.56533
Time: 2018-07-15 04:38:04
TRAINING STATS: batch 162/486 in epoch 683,  batch loss: 1.66361, batch accuracy: 0.55700
Time: 2018-07-15 04:38:07
TRAINING STATS: batch 212/486 in epoch 683,  batch loss: 1.57173, batch accuracy: 0.57133
Time: 2018-07-15 04:38:12
TRAINING STATS: batch 262/486 in epoch 683,  batch loss: 1.70278, batch accuracy: 0.54100
Time: 2018-07-15 04:38:16
TRAINING STATS: batch 312/486 in epoch 683,  batch loss: 1.65320, batch accuracy: 0.54317
Time: 2018-07-15 04:38:19
TRAINING STATS: batch 362/486 in epoch 683,  batch loss: 1.65280, batch accuracy: 0.55733
Time: 2018-07-15 04:38:24
TRAINING STATS: batch 412/486 in epoch 683,  batch loss: 1.61395, batch accuracy: 0.56633
Time: 2018-07-15 04:38:28
TRAINING STATS: batch 462/486 in epoch 683,  batch loss: 1.65485, batch accuracy: 0.56167
Time: 2018-07-15 04:38:31
TRAINING STATS: batch 26/486 in epoch 684,   batch loss: 1.68116, batch accuracy: 0.54800
Time: 2018-07-15 04:38:36
TRAINING STATS: batch 76/486 in epoch 684,   batch loss: 1.69571, batch accuracy: 0.54450
Time: 2018-07-15 04:38:40
TRAINING STATS: batch 126/486 in epoch 684,  batch loss: 1.69750, batch accuracy: 0.54250
Time: 2018-07-15 04:38:43
TRAINING STATS: batch 176/486 in epoch 684,  batch loss: 1.57575, batch accuracy: 0.58417
Time: 2018-07-15 04:38:48
TRAINING STATS: batch 226/486 in epoch 684,  batch loss: 1.64767, batch accuracy: 0.56467
Time: 2018-07-15 04:38:52
TRAINING STATS: batch 276/486 in epoch 684,  batch loss: 1.64206, batch accuracy: 0.55483
Time: 2018-07-15 04:38:55
TRAINING STATS: batch 326/486 in epoch 684,  batch loss: 1.67181, batch accuracy: 0.54833
Time: 2018-07-15 04:39:00
TRAINING STATS: batch 376/486 in epoch 684,  batch loss: 1.68075, batch accuracy: 0.54400
Time: 2018-07-15 04:39:04
TRAINING STATS: batch 426/486 in epoch 684,  batch loss: 1.64228, batch accuracy: 0.55267
Time: 2018-07-15 04:39:07
TRAINING STATS: batch 476/486 in epoch 684,  batch loss: 1.58368, batch accuracy: 0.57250
Time: 2018-07-15 04:39:12
TRAINING STATS: batch 40/486 in epoch 685,   batch loss: 1.61292, batch accuracy: 0.56317
Time: 2018-07-15 04:39:16
TRAINING STATS: batch 90/486 in epoch 685,   batch loss: 1.67325, batch accuracy: 0.55017
Time: 2018-07-15 04:39:19
TRAINING STATS: batch 140/486 in epoch 685,  batch loss: 1.57449, batch accuracy: 0.57433
Time: 2018-07-15 04:39:24
TRAINING STATS: batch 190/486 in epoch 685,  batch loss: 1.61907, batch accuracy: 0.56683
Time: 2018-07-15 04:39:28
TRAINING STATS: batch 240/486 in epoch 685,  batch loss: 1.61622, batch accuracy: 0.56533
Time: 2018-07-15 04:39:32
TRAINING STATS: batch 290/486 in epoch 685,  batch loss: 1.66325, batch accuracy: 0.55283
Time: 2018-07-15 04:39:36
TRAINING STATS: batch 340/486 in epoch 685,  batch loss: 1.71626, batch accuracy: 0.53633
Time: 2018-07-15 04:39:40
TRAINING STATS: batch 390/486 in epoch 685,  batch loss: 1.58642, batch accuracy: 0.58250
Time: 2018-07-15 04:39:44
TRAINING STATS: batch 440/486 in epoch 685,  batch loss: 1.64979, batch accuracy: 0.55500
Time: 2018-07-15 04:39:48
TRAINING STATS: batch 4/486 in epoch 686,    batch loss: 1.59195, batch accuracy: 0.58283
Time: 2018-07-15 04:39:52
TRAINING STATS: batch 54/486 in epoch 686,   batch loss: 1.63757, batch accuracy: 0.55833
Time: 2018-07-15 04:39:56
TRAINING STATS: batch 104/486 in epoch 686,  batch loss: 1.65523, batch accuracy: 0.56167
Time: 2018-07-15 04:40:00
TRAINING STATS: batch 154/486 in epoch 686,  batch loss: 1.61823, batch accuracy: 0.56550
Time: 2018-07-15 04:40:04
TRAINING STATS: batch 204/486 in epoch 686,  batch loss: 1.72837, batch accuracy: 0.54200
Time: 2018-07-15 04:40:08
TRAINING STATS: batch 254/486 in epoch 686,  batch loss: 1.56100, batch accuracy: 0.58017
Time: 2018-07-15 04:40:12
TRAINING STATS: batch 304/486 in epoch 686,  batch loss: 1.58667, batch accuracy: 0.57400
Time: 2018-07-15 04:40:16
TRAINING STATS: batch 354/486 in epoch 686,  batch loss: 1.65897, batch accuracy: 0.55100
Time: 2018-07-15 04:40:20
TRAINING STATS: batch 404/486 in epoch 686,  batch loss: 1.62771, batch accuracy: 0.55633
Time: 2018-07-15 04:40:24
TRAINING STATS: batch 454/486 in epoch 686,  batch loss: 1.51248, batch accuracy: 0.59567
Time: 2018-07-15 04:40:28
TRAINING STATS: batch 18/486 in epoch 687,   batch loss: 1.65704, batch accuracy: 0.55517
Time: 2018-07-15 04:40:32
TRAINING STATS: batch 68/486 in epoch 687,   batch loss: 1.49012, batch accuracy: 0.60600
Time: 2018-07-15 04:40:36
TRAINING STATS: batch 118/486 in epoch 687,  batch loss: 1.63108, batch accuracy: 0.56617
Time: 2018-07-15 04:40:40
TRAINING STATS: batch 168/486 in epoch 687,  batch loss: 1.57555, batch accuracy: 0.58467
Time: 2018-07-15 04:40:44
TRAINING STATS: batch 218/486 in epoch 687,  batch loss: 1.62550, batch accuracy: 0.56333
Time: 2018-07-15 04:40:49
TRAINING STATS: batch 268/486 in epoch 687,  batch loss: 1.58800, batch accuracy: 0.57017
Time: 2018-07-15 04:40:52
TRAINING STATS: batch 318/486 in epoch 687,  batch loss: 1.63367, batch accuracy: 0.55583
Time: 2018-07-15 04:40:56
TRAINING STATS: batch 368/486 in epoch 687,  batch loss: 1.65154, batch accuracy: 0.55083
Time: 2018-07-15 04:41:01
TRAINING STATS: batch 418/486 in epoch 687,  batch loss: 1.70424, batch accuracy: 0.53883
Time: 2018-07-15 04:41:04
TRAINING STATS: batch 468/486 in epoch 687,  batch loss: 1.69500, batch accuracy: 0.54683
Time: 2018-07-15 04:41:08
TRAINING STATS: batch 32/486 in epoch 688,   batch loss: 1.59701, batch accuracy: 0.56633
Time: 2018-07-15 04:41:13
TRAINING STATS: batch 82/486 in epoch 688,   batch loss: 1.68528, batch accuracy: 0.54267
Time: 2018-07-15 04:41:16
TRAINING STATS: batch 132/486 in epoch 688,  batch loss: 1.62675, batch accuracy: 0.57183
Time: 2018-07-15 04:41:20
TRAINING STATS: batch 182/486 in epoch 688,  batch loss: 1.71348, batch accuracy: 0.53533
Time: 2018-07-15 04:41:25
TRAINING STATS: batch 232/486 in epoch 688,  batch loss: 1.67360, batch accuracy: 0.54883
Time: 2018-07-15 04:41:29
TRAINING STATS: batch 282/486 in epoch 688,  batch loss: 1.62196, batch accuracy: 0.56033
Time: 2018-07-15 04:41:32
TRAINING STATS: batch 332/486 in epoch 688,  batch loss: 1.68844, batch accuracy: 0.55300
Time: 2018-07-15 04:41:37
TRAINING STATS: batch 382/486 in epoch 688,  batch loss: 1.66511, batch accuracy: 0.55167
Time: 2018-07-15 04:41:41
TRAINING STATS: batch 432/486 in epoch 688,  batch loss: 1.56244, batch accuracy: 0.57833
Time: 2018-07-15 04:41:44
TRAINING STATS: batch 482/486 in epoch 688,  batch loss: 1.62914, batch accuracy: 0.56383
Time: 2018-07-15 04:41:49
TRAINING STATS: batch 46/486 in epoch 689,   batch loss: 1.60103, batch accuracy: 0.57467
Time: 2018-07-15 04:41:52
TRAINING STATS: batch 96/486 in epoch 689,   batch loss: 1.68544, batch accuracy: 0.54583
Time: 2018-07-15 04:41:56
TRAINING STATS: batch 146/486 in epoch 689,  batch loss: 1.68911, batch accuracy: 0.54400
Time: 2018-07-15 04:42:01
TRAINING STATS: batch 196/486 in epoch 689,  batch loss: 1.68785, batch accuracy: 0.54500
Time: 2018-07-15 04:42:05
TRAINING STATS: batch 246/486 in epoch 689,  batch loss: 1.60842, batch accuracy: 0.56967
Time: 2018-07-15 04:42:08
TRAINING STATS: batch 296/486 in epoch 689,  batch loss: 1.60711, batch accuracy: 0.56617
Time: 2018-07-15 04:42:13
TRAINING STATS: batch 346/486 in epoch 689,  batch loss: 1.55455, batch accuracy: 0.58667
Time: 2018-07-15 04:42:17
TRAINING STATS: batch 396/486 in epoch 689,  batch loss: 1.65016, batch accuracy: 0.56067
Time: 2018-07-15 04:42:20
TRAINING STATS: batch 446/486 in epoch 689,  batch loss: 1.66360, batch accuracy: 0.55400
Time: 2018-07-15 04:42:25
TRAINING STATS: batch 10/486 in epoch 690,   batch loss: 1.69135, batch accuracy: 0.54067
Time: 2018-07-15 04:42:29
TRAINING STATS: batch 60/486 in epoch 690,   batch loss: 1.64184, batch accuracy: 0.56167
Time: 2018-07-15 04:42:32
TRAINING STATS: batch 110/486 in epoch 690,  batch loss: 1.70121, batch accuracy: 0.55133
Time: 2018-07-15 04:42:37
TRAINING STATS: batch 160/486 in epoch 690,  batch loss: 1.63522, batch accuracy: 0.54883
Time: 2018-07-15 04:42:41
TRAINING STATS: batch 210/486 in epoch 690,  batch loss: 1.61240, batch accuracy: 0.56233
Time: 2018-07-15 04:42:44
TRAINING STATS: batch 260/486 in epoch 690,  batch loss: 1.66258, batch accuracy: 0.54700
Time: 2018-07-15 04:42:49
TRAINING STATS: batch 310/486 in epoch 690,  batch loss: 1.65818, batch accuracy: 0.55233
Time: 2018-07-15 04:42:53
TRAINING STATS: batch 360/486 in epoch 690,  batch loss: 1.69665, batch accuracy: 0.54333
Time: 2018-07-15 04:42:56
TRAINING STATS: batch 410/486 in epoch 690,  batch loss: 1.60022, batch accuracy: 0.57483
Time: 2018-07-15 04:43:01
TRAINING STATS: batch 460/486 in epoch 690,  batch loss: 1.78728, batch accuracy: 0.51450
Time: 2018-07-15 04:43:05
TRAINING STATS: batch 24/486 in epoch 691,   batch loss: 1.71680, batch accuracy: 0.54200
Time: 2018-07-15 04:43:09
TRAINING STATS: batch 74/486 in epoch 691,   batch loss: 1.65879, batch accuracy: 0.55717
Time: 2018-07-15 04:43:13
TRAINING STATS: batch 124/486 in epoch 691,  batch loss: 1.67560, batch accuracy: 0.55600
Time: 2018-07-15 04:43:17
TRAINING STATS: batch 174/486 in epoch 691,  batch loss: 1.71356, batch accuracy: 0.53683
Time: 2018-07-15 04:43:21
TRAINING STATS: batch 224/486 in epoch 691,  batch loss: 1.69638, batch accuracy: 0.54583
Time: 2018-07-15 04:43:25
TRAINING STATS: batch 274/486 in epoch 691,  batch loss: 1.66933, batch accuracy: 0.54783
Time: 2018-07-15 04:43:29
TRAINING STATS: batch 324/486 in epoch 691,  batch loss: 1.69457, batch accuracy: 0.54433
Time: 2018-07-15 04:43:33
TRAINING STATS: batch 374/486 in epoch 691,  batch loss: 1.68661, batch accuracy: 0.54750
Time: 2018-07-15 04:43:37
TRAINING STATS: batch 424/486 in epoch 691,  batch loss: 1.60574, batch accuracy: 0.56600
Time: 2018-07-15 04:43:41
TRAINING STATS: batch 474/486 in epoch 691,  batch loss: 1.64758, batch accuracy: 0.56167
Time: 2018-07-15 04:43:45
TRAINING STATS: batch 38/486 in epoch 692,   batch loss: 1.67531, batch accuracy: 0.54950
Time: 2018-07-15 04:43:49
TRAINING STATS: batch 88/486 in epoch 692,   batch loss: 1.70174, batch accuracy: 0.53950
Time: 2018-07-15 04:43:53
TRAINING STATS: batch 138/486 in epoch 692,  batch loss: 1.69078, batch accuracy: 0.54333
Time: 2018-07-15 04:43:57
TRAINING STATS: batch 188/486 in epoch 692,  batch loss: 1.61921, batch accuracy: 0.57400
Time: 2018-07-15 04:44:01
TRAINING STATS: batch 238/486 in epoch 692,  batch loss: 1.61815, batch accuracy: 0.57033
Time: 2018-07-15 04:44:05
TRAINING STATS: batch 288/486 in epoch 692,  batch loss: 1.66834, batch accuracy: 0.54500
Time: 2018-07-15 04:44:09
TRAINING STATS: batch 338/486 in epoch 692,  batch loss: 1.63790, batch accuracy: 0.55333
Time: 2018-07-15 04:44:14
TRAINING STATS: batch 388/486 in epoch 692,  batch loss: 1.61759, batch accuracy: 0.56567
Time: 2018-07-15 04:44:17
TRAINING STATS: batch 438/486 in epoch 692,  batch loss: 1.66977, batch accuracy: 0.55700
Time: 2018-07-15 04:44:21
TRAINING STATS: batch 2/486 in epoch 693,    batch loss: 1.66934, batch accuracy: 0.54967
Time: 2018-07-15 04:44:26
TRAINING STATS: batch 52/486 in epoch 693,   batch loss: 1.71131, batch accuracy: 0.52817
Time: 2018-07-15 04:44:29
TRAINING STATS: batch 102/486 in epoch 693,  batch loss: 1.66359, batch accuracy: 0.55483
Time: 2018-07-15 04:44:33
TRAINING STATS: batch 152/486 in epoch 693,  batch loss: 1.61120, batch accuracy: 0.56950
Time: 2018-07-15 04:44:38
TRAINING STATS: batch 202/486 in epoch 693,  batch loss: 1.65449, batch accuracy: 0.55567
Time: 2018-07-15 04:44:41
TRAINING STATS: batch 252/486 in epoch 693,  batch loss: 1.61432, batch accuracy: 0.56700
Time: 2018-07-15 04:44:45
TRAINING STATS: batch 302/486 in epoch 693,  batch loss: 1.59973, batch accuracy: 0.56300
Time: 2018-07-15 04:44:50
TRAINING STATS: batch 352/486 in epoch 693,  batch loss: 1.62960, batch accuracy: 0.56450
Time: 2018-07-15 04:44:54
TRAINING STATS: batch 402/486 in epoch 693,  batch loss: 1.50499, batch accuracy: 0.60333
Time: 2018-07-15 04:44:57
TRAINING STATS: batch 452/486 in epoch 693,  batch loss: 1.62299, batch accuracy: 0.55967
Time: 2018-07-15 04:45:02
TRAINING STATS: batch 16/486 in epoch 694,   batch loss: 1.61375, batch accuracy: 0.56633
Time: 2018-07-15 04:45:06
TRAINING STATS: batch 66/486 in epoch 694,   batch loss: 1.63209, batch accuracy: 0.56283
Time: 2018-07-15 04:45:09
TRAINING STATS: batch 116/486 in epoch 694,  batch loss: 1.60775, batch accuracy: 0.56867
Time: 2018-07-15 04:45:14
TRAINING STATS: batch 166/486 in epoch 694,  batch loss: 1.54867, batch accuracy: 0.58433
Time: 2018-07-15 04:45:18
TRAINING STATS: batch 216/486 in epoch 694,  batch loss: 1.66142, batch accuracy: 0.55967
Time: 2018-07-15 04:45:21
TRAINING STATS: batch 266/486 in epoch 694,  batch loss: 1.64924, batch accuracy: 0.55533
Time: 2018-07-15 04:45:26
TRAINING STATS: batch 316/486 in epoch 694,  batch loss: 1.62950, batch accuracy: 0.56150
Time: 2018-07-15 04:45:30
TRAINING STATS: batch 366/486 in epoch 694,  batch loss: 1.70836, batch accuracy: 0.54517
Time: 2018-07-15 04:45:33
TRAINING STATS: batch 416/486 in epoch 694,  batch loss: 1.68343, batch accuracy: 0.54750
Time: 2018-07-15 04:45:38
TRAINING STATS: batch 466/486 in epoch 694,  batch loss: 1.50809, batch accuracy: 0.60150
Time: 2018-07-15 04:45:42
TRAINING STATS: batch 30/486 in epoch 695,   batch loss: 1.54901, batch accuracy: 0.58967
Time: 2018-07-15 04:45:45
TRAINING STATS: batch 80/486 in epoch 695,   batch loss: 1.63787, batch accuracy: 0.56467
Time: 2018-07-15 04:45:50
TRAINING STATS: batch 130/486 in epoch 695,  batch loss: 1.62043, batch accuracy: 0.56800
Time: 2018-07-15 04:45:54
TRAINING STATS: batch 180/486 in epoch 695,  batch loss: 1.66443, batch accuracy: 0.55483
Time: 2018-07-15 04:45:58
TRAINING STATS: batch 230/486 in epoch 695,  batch loss: 1.65837, batch accuracy: 0.55417
Time: 2018-07-15 04:46:02
TRAINING STATS: batch 280/486 in epoch 695,  batch loss: 1.64063, batch accuracy: 0.55483
Time: 2018-07-15 04:46:06
TRAINING STATS: batch 330/486 in epoch 695,  batch loss: 1.61046, batch accuracy: 0.56650
Time: 2018-07-15 04:46:10
TRAINING STATS: batch 380/486 in epoch 695,  batch loss: 1.60201, batch accuracy: 0.57333
Time: 2018-07-15 04:46:14
TRAINING STATS: batch 430/486 in epoch 695,  batch loss: 1.57007, batch accuracy: 0.58650
Time: 2018-07-15 04:46:18
TRAINING STATS: batch 480/486 in epoch 695,  batch loss: 1.64349, batch accuracy: 0.56350
Time: 2018-07-15 04:46:22
TRAINING STATS: batch 44/486 in epoch 696,   batch loss: 1.58309, batch accuracy: 0.57500
Time: 2018-07-15 04:46:26
TRAINING STATS: batch 94/486 in epoch 696,   batch loss: 1.68320, batch accuracy: 0.55133
Time: 2018-07-15 04:46:30
TRAINING STATS: batch 144/486 in epoch 696,  batch loss: 1.71332, batch accuracy: 0.53633
Time: 2018-07-15 04:46:34
TRAINING STATS: batch 194/486 in epoch 696,  batch loss: 1.73825, batch accuracy: 0.53617
Time: 2018-07-15 04:46:38
TRAINING STATS: batch 244/486 in epoch 696,  batch loss: 1.62028, batch accuracy: 0.56767
Time: 2018-07-15 04:46:42
TRAINING STATS: batch 294/486 in epoch 696,  batch loss: 1.56681, batch accuracy: 0.57617
Time: 2018-07-15 04:46:46
TRAINING STATS: batch 344/486 in epoch 696,  batch loss: 1.66729, batch accuracy: 0.55233
Time: 2018-07-15 04:46:51
TRAINING STATS: batch 394/486 in epoch 696,  batch loss: 1.63809, batch accuracy: 0.56783
Time: 2018-07-15 04:46:54
TRAINING STATS: batch 444/486 in epoch 696,  batch loss: 1.58728, batch accuracy: 0.57917
Time: 2018-07-15 04:46:58
TRAINING STATS: batch 8/486 in epoch 697,    batch loss: 1.63895, batch accuracy: 0.56250
Time: 2018-07-15 04:47:02
TRAINING STATS: batch 58/486 in epoch 697,   batch loss: 1.60949, batch accuracy: 0.57183
Time: 2018-07-15 04:47:06
TRAINING STATS: batch 108/486 in epoch 697,  batch loss: 1.69576, batch accuracy: 0.54967
Time: 2018-07-15 04:47:10
TRAINING STATS: batch 158/486 in epoch 697,  batch loss: 1.69481, batch accuracy: 0.54783
Time: 2018-07-15 04:47:15
TRAINING STATS: batch 208/486 in epoch 697,  batch loss: 1.65938, batch accuracy: 0.55517
Time: 2018-07-15 04:47:18
TRAINING STATS: batch 258/486 in epoch 697,  batch loss: 1.60233, batch accuracy: 0.57100
Time: 2018-07-15 04:47:22
TRAINING STATS: batch 308/486 in epoch 697,  batch loss: 1.65988, batch accuracy: 0.56117
Time: 2018-07-15 04:47:27
TRAINING STATS: batch 358/486 in epoch 697,  batch loss: 1.66687, batch accuracy: 0.55117
Time: 2018-07-15 04:47:30
TRAINING STATS: batch 408/486 in epoch 697,  batch loss: 1.68137, batch accuracy: 0.54483
Time: 2018-07-15 04:47:34
TRAINING STATS: batch 458/486 in epoch 697,  batch loss: 1.67088, batch accuracy: 0.55683
Time: 2018-07-15 04:47:39
TRAINING STATS: batch 22/486 in epoch 698,   batch loss: 1.68414, batch accuracy: 0.55783
Time: 2018-07-15 04:47:42
TRAINING STATS: batch 72/486 in epoch 698,   batch loss: 1.67091, batch accuracy: 0.54217
Time: 2018-07-15 04:47:46
TRAINING STATS: batch 122/486 in epoch 698,  batch loss: 1.63956, batch accuracy: 0.56450
Time: 2018-07-15 04:47:51
TRAINING STATS: batch 172/486 in epoch 698,  batch loss: 1.71792, batch accuracy: 0.54083
Time: 2018-07-15 04:47:54
TRAINING STATS: batch 222/486 in epoch 698,  batch loss: 1.66257, batch accuracy: 0.54783
Time: 2018-07-15 04:47:58
TRAINING STATS: batch 272/486 in epoch 698,  batch loss: 1.67474, batch accuracy: 0.54267
Time: 2018-07-15 04:48:03
TRAINING STATS: batch 322/486 in epoch 698,  batch loss: 1.64609, batch accuracy: 0.55250
Time: 2018-07-15 04:48:07
TRAINING STATS: batch 372/486 in epoch 698,  batch loss: 1.60718, batch accuracy: 0.57083
Time: 2018-07-15 04:48:10
TRAINING STATS: batch 422/486 in epoch 698,  batch loss: 1.61870, batch accuracy: 0.56133
Time: 2018-07-15 04:48:15
TRAINING STATS: batch 472/486 in epoch 698,  batch loss: 1.71621, batch accuracy: 0.53250
Time: 2018-07-15 04:48:19
TRAINING STATS: batch 36/486 in epoch 699,   batch loss: 1.71277, batch accuracy: 0.54217
Time: 2018-07-15 04:48:22
TRAINING STATS: batch 86/486 in epoch 699,   batch loss: 1.63846, batch accuracy: 0.56283
Time: 2018-07-15 04:48:27
TRAINING STATS: batch 136/486 in epoch 699,  batch loss: 1.68998, batch accuracy: 0.54567
Time: 2018-07-15 04:48:31
TRAINING STATS: batch 186/486 in epoch 699,  batch loss: 1.65375, batch accuracy: 0.55783
Time: 2018-07-15 04:48:34
TRAINING STATS: batch 236/486 in epoch 699,  batch loss: 1.68533, batch accuracy: 0.54417
Time: 2018-07-15 04:48:39
TRAINING STATS: batch 286/486 in epoch 699,  batch loss: 1.69646, batch accuracy: 0.54433
Time: 2018-07-15 04:48:43
TRAINING STATS: batch 336/486 in epoch 699,  batch loss: 1.63867, batch accuracy: 0.55883
Time: 2018-07-15 04:48:46
TRAINING STATS: batch 386/486 in epoch 699,  batch loss: 1.67997, batch accuracy: 0.54750
Time: 2018-07-15 04:48:51
TRAINING STATS: batch 436/486 in epoch 699,  batch loss: 1.66353, batch accuracy: 0.55467
Time: 2018-07-15 04:48:55
TRAINING STATS: batch 0/486 in epoch 700,    batch loss: 1.63859, batch accuracy: 0.55667
Time: 2018-07-15 04:48:58
TRAINING STATS: batch 50/486 in epoch 700,   batch loss: 1.60925, batch accuracy: 0.57300
Time: 2018-07-15 04:49:03
TRAINING STATS: batch 100/486 in epoch 700,  batch loss: 1.66541, batch accuracy: 0.55483
Time: 2018-07-15 04:49:07
TRAINING STATS: batch 150/486 in epoch 700,  batch loss: 1.60734, batch accuracy: 0.57533
Time: 2018-07-15 04:49:10
TRAINING STATS: batch 200/486 in epoch 700,  batch loss: 1.53095, batch accuracy: 0.59167
Time: 2018-07-15 04:49:15
TRAINING STATS: batch 250/486 in epoch 700,  batch loss: 1.69802, batch accuracy: 0.53767
Time: 2018-07-15 04:49:19
TRAINING STATS: batch 300/486 in epoch 700,  batch loss: 1.67136, batch accuracy: 0.54283
Time: 2018-07-15 04:49:22
TRAINING STATS: batch 350/486 in epoch 700,  batch loss: 1.65695, batch accuracy: 0.56183
Time: 2018-07-15 04:49:27
TRAINING STATS: batch 400/486 in epoch 700,  batch loss: 1.54274, batch accuracy: 0.59117
Time: 2018-07-15 04:49:31
TRAINING STATS: batch 450/486 in epoch 700,  batch loss: 1.71064, batch accuracy: 0.54050
Time: 2018-07-15 04:49:35
TRAINING STATS: batch 14/486 in epoch 701,   batch loss: 1.55702, batch accuracy: 0.58183
Time: 2018-07-15 04:49:39
TRAINING STATS: batch 64/486 in epoch 701,   batch loss: 1.74049, batch accuracy: 0.53450
Time: 2018-07-15 04:49:43
TRAINING STATS: batch 114/486 in epoch 701,  batch loss: 1.68701, batch accuracy: 0.54700
Time: 2018-07-15 04:49:47
TRAINING STATS: batch 164/486 in epoch 701,  batch loss: 1.56263, batch accuracy: 0.58700
Time: 2018-07-15 04:49:51
TRAINING STATS: batch 214/486 in epoch 701,  batch loss: 1.76075, batch accuracy: 0.53183
Time: 2018-07-15 04:49:55
TRAINING STATS: batch 264/486 in epoch 701,  batch loss: 1.71341, batch accuracy: 0.53900
Time: 2018-07-15 04:49:59
TRAINING STATS: batch 314/486 in epoch 701,  batch loss: 1.72739, batch accuracy: 0.53383
Time: 2018-07-15 04:50:03
TRAINING STATS: batch 364/486 in epoch 701,  batch loss: 1.62856, batch accuracy: 0.57133
Time: 2018-07-15 04:50:07
TRAINING STATS: batch 414/486 in epoch 701,  batch loss: 1.58870, batch accuracy: 0.57233
Time: 2018-07-15 04:50:11
TRAINING STATS: batch 464/486 in epoch 701,  batch loss: 1.62599, batch accuracy: 0.56750
Time: 2018-07-15 04:50:16
TRAINING STATS: batch 28/486 in epoch 702,   batch loss: 1.56093, batch accuracy: 0.58567
Time: 2018-07-15 04:50:19
TRAINING STATS: batch 78/486 in epoch 702,   batch loss: 1.64416, batch accuracy: 0.56167
Time: 2018-07-15 04:50:23
TRAINING STATS: batch 128/486 in epoch 702,  batch loss: 1.62375, batch accuracy: 0.56383
Time: 2018-07-15 04:50:28
TRAINING STATS: batch 178/486 in epoch 702,  batch loss: 1.52720, batch accuracy: 0.58417
Time: 2018-07-15 04:50:31
TRAINING STATS: batch 228/486 in epoch 702,  batch loss: 1.60404, batch accuracy: 0.57333
Time: 2018-07-15 04:50:35
TRAINING STATS: batch 278/486 in epoch 702,  batch loss: 1.56593, batch accuracy: 0.58283
Time: 2018-07-15 04:50:40
TRAINING STATS: batch 328/486 in epoch 702,  batch loss: 1.59530, batch accuracy: 0.57267
Time: 2018-07-15 04:50:43
TRAINING STATS: batch 378/486 in epoch 702,  batch loss: 1.62870, batch accuracy: 0.57150
Time: 2018-07-15 04:50:47
TRAINING STATS: batch 428/486 in epoch 702,  batch loss: 1.67432, batch accuracy: 0.55000
Time: 2018-07-15 04:50:52
TRAINING STATS: batch 478/486 in epoch 702,  batch loss: 1.65571, batch accuracy: 0.55117
Time: 2018-07-15 04:50:55
TRAINING STATS: batch 42/486 in epoch 703,   batch loss: 1.54824, batch accuracy: 0.58467
Time: 2018-07-15 04:50:59
TRAINING STATS: batch 92/486 in epoch 703,   batch loss: 1.65445, batch accuracy: 0.55617
Time: 2018-07-15 04:51:04
TRAINING STATS: batch 142/486 in epoch 703,  batch loss: 1.60292, batch accuracy: 0.57083
Time: 2018-07-15 04:51:07
TRAINING STATS: batch 192/486 in epoch 703,  batch loss: 1.65164, batch accuracy: 0.55783
Time: 2018-07-15 04:51:11
TRAINING STATS: batch 242/486 in epoch 703,  batch loss: 1.61789, batch accuracy: 0.56700
Time: 2018-07-15 04:51:16
TRAINING STATS: batch 292/486 in epoch 703,  batch loss: 1.63058, batch accuracy: 0.55950
Time: 2018-07-15 04:51:19
TRAINING STATS: batch 342/486 in epoch 703,  batch loss: 1.62970, batch accuracy: 0.56733
Time: 2018-07-15 04:51:23
TRAINING STATS: batch 392/486 in epoch 703,  batch loss: 1.55706, batch accuracy: 0.58283
Time: 2018-07-15 04:51:28
TRAINING STATS: batch 442/486 in epoch 703,  batch loss: 1.55638, batch accuracy: 0.58700
Time: 2018-07-15 04:51:31
TRAINING STATS: batch 6/486 in epoch 704,    batch loss: 1.67100, batch accuracy: 0.56083
Time: 2018-07-15 04:51:35
TRAINING STATS: batch 56/486 in epoch 704,   batch loss: 1.60215, batch accuracy: 0.56867
Time: 2018-07-15 04:51:40
TRAINING STATS: batch 106/486 in epoch 704,  batch loss: 1.69292, batch accuracy: 0.53950
Time: 2018-07-15 04:51:44
TRAINING STATS: batch 156/486 in epoch 704,  batch loss: 1.67791, batch accuracy: 0.55017
Time: 2018-07-15 04:51:47
TRAINING STATS: batch 206/486 in epoch 704,  batch loss: 1.73714, batch accuracy: 0.53600
Time: 2018-07-15 04:51:52
TRAINING STATS: batch 256/486 in epoch 704,  batch loss: 1.57191, batch accuracy: 0.57733
Time: 2018-07-15 04:51:56
TRAINING STATS: batch 306/486 in epoch 704,  batch loss: 1.63021, batch accuracy: 0.56517
Time: 2018-07-15 04:51:59
TRAINING STATS: batch 356/486 in epoch 704,  batch loss: 1.68643, batch accuracy: 0.54833
Time: 2018-07-15 04:52:04
TRAINING STATS: batch 406/486 in epoch 704,  batch loss: 1.71078, batch accuracy: 0.53733
Time: 2018-07-15 04:52:08
TRAINING STATS: batch 456/486 in epoch 704,  batch loss: 1.51904, batch accuracy: 0.59983
Time: 2018-07-15 04:52:11
TRAINING STATS: batch 20/486 in epoch 705,   batch loss: 1.65263, batch accuracy: 0.56117
Time: 2018-07-15 04:52:16
TRAINING STATS: batch 70/486 in epoch 705,   batch loss: 1.53238, batch accuracy: 0.59633
Time: 2018-07-15 04:52:20
TRAINING STATS: batch 120/486 in epoch 705,  batch loss: 1.58638, batch accuracy: 0.57783
Time: 2018-07-15 04:52:23
TRAINING STATS: batch 170/486 in epoch 705,  batch loss: 1.61721, batch accuracy: 0.56683
Time: 2018-07-15 04:52:28
TRAINING STATS: batch 220/486 in epoch 705,  batch loss: 1.56111, batch accuracy: 0.58417
Time: 2018-07-15 04:52:32
TRAINING STATS: batch 270/486 in epoch 705,  batch loss: 1.64360, batch accuracy: 0.54400
Time: 2018-07-15 04:52:35
TRAINING STATS: batch 320/486 in epoch 705,  batch loss: 1.57978, batch accuracy: 0.57617
Time: 2018-07-15 04:52:40
TRAINING STATS: batch 370/486 in epoch 705,  batch loss: 1.64106, batch accuracy: 0.56100
Time: 2018-07-15 04:52:44
TRAINING STATS: batch 420/486 in epoch 705,  batch loss: 1.67814, batch accuracy: 0.55067
Time: 2018-07-15 04:52:48
TRAINING STATS: batch 470/486 in epoch 705,  batch loss: 1.76657, batch accuracy: 0.51617
Time: 2018-07-15 04:52:52
TRAINING STATS: batch 34/486 in epoch 706,   batch loss: 1.65657, batch accuracy: 0.55900
Time: 2018-07-15 04:52:56
TRAINING STATS: batch 84/486 in epoch 706,   batch loss: 1.63858, batch accuracy: 0.54850
Time: 2018-07-15 04:53:00
TRAINING STATS: batch 134/486 in epoch 706,  batch loss: 1.68849, batch accuracy: 0.54867
Time: 2018-07-15 04:53:04
TRAINING STATS: batch 184/486 in epoch 706,  batch loss: 1.65103, batch accuracy: 0.55567
Time: 2018-07-15 04:53:08
TRAINING STATS: batch 234/486 in epoch 706,  batch loss: 1.71275, batch accuracy: 0.53950
Time: 2018-07-15 04:53:12
TRAINING STATS: batch 284/486 in epoch 706,  batch loss: 1.69666, batch accuracy: 0.54200
Time: 2018-07-15 04:53:16
TRAINING STATS: batch 334/486 in epoch 706,  batch loss: 1.62845, batch accuracy: 0.56517
Time: 2018-07-15 04:53:20
TRAINING STATS: batch 384/486 in epoch 706,  batch loss: 1.61504, batch accuracy: 0.56533
Time: 2018-07-15 04:53:23
TRAINING STATS: batch 434/486 in epoch 706,  batch loss: 1.68976, batch accuracy: 0.54517
Time: 2018-07-15 04:53:28
TRAINING STATS: batch 484/486 in epoch 706,  batch loss: 1.64974, batch accuracy: 0.55267
Time: 2018-07-15 04:53:32
TRAINING STATS: batch 48/486 in epoch 707,   batch loss: 1.64506, batch accuracy: 0.55950
Time: 2018-07-15 04:53:36
TRAINING STATS: batch 98/486 in epoch 707,   batch loss: 1.57589, batch accuracy: 0.57850
Time: 2018-07-15 04:53:40
TRAINING STATS: batch 148/486 in epoch 707,  batch loss: 1.67255, batch accuracy: 0.55483
Time: 2018-07-15 04:53:44
TRAINING STATS: batch 198/486 in epoch 707,  batch loss: 1.69847, batch accuracy: 0.53500
Time: 2018-07-15 04:53:48
TRAINING STATS: batch 248/486 in epoch 707,  batch loss: 1.67916, batch accuracy: 0.54967
Time: 2018-07-15 04:53:52
TRAINING STATS: batch 298/486 in epoch 707,  batch loss: 1.68186, batch accuracy: 0.54933
Time: 2018-07-15 04:53:56
TRAINING STATS: batch 348/486 in epoch 707,  batch loss: 1.64562, batch accuracy: 0.56333
Time: 2018-07-15 04:54:00
TRAINING STATS: batch 398/486 in epoch 707,  batch loss: 1.66028, batch accuracy: 0.56000
Time: 2018-07-15 04:54:04
TRAINING STATS: batch 448/486 in epoch 707,  batch loss: 1.64443, batch accuracy: 0.56317
Time: 2018-07-15 04:54:08
TRAINING STATS: batch 12/486 in epoch 708,   batch loss: 1.67875, batch accuracy: 0.54367
Time: 2018-07-15 04:54:12
TRAINING STATS: batch 62/486 in epoch 708,   batch loss: 1.73440, batch accuracy: 0.54350
Time: 2018-07-15 04:54:16
TRAINING STATS: batch 112/486 in epoch 708,  batch loss: 1.62435, batch accuracy: 0.56733
Time: 2018-07-15 04:54:20
TRAINING STATS: batch 162/486 in epoch 708,  batch loss: 1.66259, batch accuracy: 0.56333
Time: 2018-07-15 04:54:24
TRAINING STATS: batch 212/486 in epoch 708,  batch loss: 1.55103, batch accuracy: 0.57800
Time: 2018-07-15 04:54:29
TRAINING STATS: batch 262/486 in epoch 708,  batch loss: 1.70355, batch accuracy: 0.54483
Time: 2018-07-15 04:54:32
TRAINING STATS: batch 312/486 in epoch 708,  batch loss: 1.64456, batch accuracy: 0.54983
Time: 2018-07-15 04:54:36
TRAINING STATS: batch 362/486 in epoch 708,  batch loss: 1.65609, batch accuracy: 0.55467
Time: 2018-07-15 04:54:41
TRAINING STATS: batch 412/486 in epoch 708,  batch loss: 1.58475, batch accuracy: 0.57350
Time: 2018-07-15 04:54:44
TRAINING STATS: batch 462/486 in epoch 708,  batch loss: 1.66884, batch accuracy: 0.55550
Time: 2018-07-15 04:54:48
TRAINING STATS: batch 26/486 in epoch 709,   batch loss: 1.69000, batch accuracy: 0.54550
Time: 2018-07-15 04:54:53
TRAINING STATS: batch 76/486 in epoch 709,   batch loss: 1.69760, batch accuracy: 0.54217
Time: 2018-07-15 04:54:56
TRAINING STATS: batch 126/486 in epoch 709,  batch loss: 1.67857, batch accuracy: 0.55267
Time: 2018-07-15 04:55:00
TRAINING STATS: batch 176/486 in epoch 709,  batch loss: 1.65388, batch accuracy: 0.55483
Time: 2018-07-15 04:55:05
TRAINING STATS: batch 226/486 in epoch 709,  batch loss: 1.62424, batch accuracy: 0.56783
Time: 2018-07-15 04:55:08
TRAINING STATS: batch 276/486 in epoch 709,  batch loss: 1.62854, batch accuracy: 0.56117
Time: 2018-07-15 04:55:12
TRAINING STATS: batch 326/486 in epoch 709,  batch loss: 1.69341, batch accuracy: 0.54800
Time: 2018-07-15 04:55:17
TRAINING STATS: batch 376/486 in epoch 709,  batch loss: 1.67841, batch accuracy: 0.54467
Time: 2018-07-15 04:55:20
TRAINING STATS: batch 426/486 in epoch 709,  batch loss: 1.63219, batch accuracy: 0.55650
Time: 2018-07-15 04:55:24
TRAINING STATS: batch 476/486 in epoch 709,  batch loss: 1.59120, batch accuracy: 0.57850
Time: 2018-07-15 04:55:29
TRAINING STATS: batch 40/486 in epoch 710,   batch loss: 1.62632, batch accuracy: 0.56283
Time: 2018-07-15 04:55:33
TRAINING STATS: batch 90/486 in epoch 710,   batch loss: 1.67980, batch accuracy: 0.55433
Time: 2018-07-15 04:55:36
TRAINING STATS: batch 140/486 in epoch 710,  batch loss: 1.60007, batch accuracy: 0.56733
Time: 2018-07-15 04:55:41
TRAINING STATS: batch 190/486 in epoch 710,  batch loss: 1.61018, batch accuracy: 0.56950
Time: 2018-07-15 04:55:45
TRAINING STATS: batch 240/486 in epoch 710,  batch loss: 1.63377, batch accuracy: 0.55617
Time: 2018-07-15 04:55:48
TRAINING STATS: batch 290/486 in epoch 710,  batch loss: 1.67476, batch accuracy: 0.54900
Time: 2018-07-15 04:55:53
TRAINING STATS: batch 340/486 in epoch 710,  batch loss: 1.77294, batch accuracy: 0.51750
Time: 2018-07-15 04:55:57
TRAINING STATS: batch 390/486 in epoch 710,  batch loss: 1.58735, batch accuracy: 0.57550
Time: 2018-07-15 04:56:00
TRAINING STATS: batch 440/486 in epoch 710,  batch loss: 1.64646, batch accuracy: 0.55600
Time: 2018-07-15 04:56:05
TRAINING STATS: batch 4/486 in epoch 711,    batch loss: 1.61142, batch accuracy: 0.57783
Time: 2018-07-15 04:56:09
TRAINING STATS: batch 54/486 in epoch 711,   batch loss: 1.64586, batch accuracy: 0.56150
Time: 2018-07-15 04:56:12
TRAINING STATS: batch 104/486 in epoch 711,  batch loss: 1.64192, batch accuracy: 0.56100
Time: 2018-07-15 04:56:17
TRAINING STATS: batch 154/486 in epoch 711,  batch loss: 1.61689, batch accuracy: 0.56733
Time: 2018-07-15 04:56:21
TRAINING STATS: batch 204/486 in epoch 711,  batch loss: 1.71633, batch accuracy: 0.53683
Time: 2018-07-15 04:56:24
TRAINING STATS: batch 254/486 in epoch 711,  batch loss: 1.56633, batch accuracy: 0.58467
Time: 2018-07-15 04:56:29
TRAINING STATS: batch 304/486 in epoch 711,  batch loss: 1.60512, batch accuracy: 0.56583
Time: 2018-07-15 04:56:33
TRAINING STATS: batch 354/486 in epoch 711,  batch loss: 1.63380, batch accuracy: 0.55617
Time: 2018-07-15 04:56:37
TRAINING STATS: batch 404/486 in epoch 711,  batch loss: 1.63947, batch accuracy: 0.55733
Time: 2018-07-15 04:56:41
TRAINING STATS: batch 454/486 in epoch 711,  batch loss: 1.50154, batch accuracy: 0.60117
Time: 2018-07-15 04:56:45
TRAINING STATS: batch 18/486 in epoch 712,   batch loss: 1.66318, batch accuracy: 0.55783
Time: 2018-07-15 04:56:49
TRAINING STATS: batch 68/486 in epoch 712,   batch loss: 1.49519, batch accuracy: 0.60783
Time: 2018-07-15 04:56:53
TRAINING STATS: batch 118/486 in epoch 712,  batch loss: 1.63577, batch accuracy: 0.56283
Time: 2018-07-15 04:56:57
TRAINING STATS: batch 168/486 in epoch 712,  batch loss: 1.57294, batch accuracy: 0.57950
Time: 2018-07-15 04:57:01
TRAINING STATS: batch 218/486 in epoch 712,  batch loss: 1.62180, batch accuracy: 0.56433
Time: 2018-07-15 04:57:05
TRAINING STATS: batch 268/486 in epoch 712,  batch loss: 1.59184, batch accuracy: 0.56933
Time: 2018-07-15 04:57:09
TRAINING STATS: batch 318/486 in epoch 712,  batch loss: 1.65644, batch accuracy: 0.55033
Time: 2018-07-15 04:57:13
TRAINING STATS: batch 368/486 in epoch 712,  batch loss: 1.66118, batch accuracy: 0.55300
Time: 2018-07-15 04:57:17
TRAINING STATS: batch 418/486 in epoch 712,  batch loss: 1.71144, batch accuracy: 0.53783
Time: 2018-07-15 04:57:21
TRAINING STATS: batch 468/486 in epoch 712,  batch loss: 1.66516, batch accuracy: 0.55333
Time: 2018-07-15 04:57:25
TRAINING STATS: batch 32/486 in epoch 713,   batch loss: 1.60901, batch accuracy: 0.56933
Time: 2018-07-15 04:57:29
TRAINING STATS: batch 82/486 in epoch 713,   batch loss: 1.69792, batch accuracy: 0.54183
Time: 2018-07-15 04:57:33
TRAINING STATS: batch 132/486 in epoch 713,  batch loss: 1.63901, batch accuracy: 0.56350
Time: 2018-07-15 04:57:37
TRAINING STATS: batch 182/486 in epoch 713,  batch loss: 1.70099, batch accuracy: 0.54117
Time: 2018-07-15 04:57:41
TRAINING STATS: batch 232/486 in epoch 713,  batch loss: 1.67478, batch accuracy: 0.55250
Time: 2018-07-15 04:57:45
TRAINING STATS: batch 282/486 in epoch 713,  batch loss: 1.60836, batch accuracy: 0.56233
Time: 2018-07-15 04:57:49
TRAINING STATS: batch 332/486 in epoch 713,  batch loss: 1.67342, batch accuracy: 0.54900
Time: 2018-07-15 04:57:54
TRAINING STATS: batch 382/486 in epoch 713,  batch loss: 1.66534, batch accuracy: 0.56150
Time: 2018-07-15 04:57:57
TRAINING STATS: batch 432/486 in epoch 713,  batch loss: 1.56377, batch accuracy: 0.58200
Time: 2018-07-15 04:58:01
TRAINING STATS: batch 482/486 in epoch 713,  batch loss: 1.64197, batch accuracy: 0.56283
Time: 2018-07-15 04:58:06
TRAINING STATS: batch 46/486 in epoch 714,   batch loss: 1.64092, batch accuracy: 0.56683
Time: 2018-07-15 04:58:09
TRAINING STATS: batch 96/486 in epoch 714,   batch loss: 1.69409, batch accuracy: 0.54083
Time: 2018-07-15 04:58:13
TRAINING STATS: batch 146/486 in epoch 714,  batch loss: 1.69336, batch accuracy: 0.54850
Time: 2018-07-15 04:58:18
TRAINING STATS: batch 196/486 in epoch 714,  batch loss: 1.69371, batch accuracy: 0.54700
Time: 2018-07-15 04:58:21
TRAINING STATS: batch 246/486 in epoch 714,  batch loss: 1.61326, batch accuracy: 0.56717
Time: 2018-07-15 04:58:25
TRAINING STATS: batch 296/486 in epoch 714,  batch loss: 1.62039, batch accuracy: 0.56433
Time: 2018-07-15 04:58:30
TRAINING STATS: batch 346/486 in epoch 714,  batch loss: 1.55309, batch accuracy: 0.58633
Time: 2018-07-15 04:58:33
TRAINING STATS: batch 396/486 in epoch 714,  batch loss: 1.61851, batch accuracy: 0.56367
Time: 2018-07-15 04:58:37
TRAINING STATS: batch 446/486 in epoch 714,  batch loss: 1.66100, batch accuracy: 0.55550
Time: 2018-07-15 04:58:42
TRAINING STATS: batch 10/486 in epoch 715,   batch loss: 1.69265, batch accuracy: 0.54900
Time: 2018-07-15 04:58:45
TRAINING STATS: batch 60/486 in epoch 715,   batch loss: 1.62651, batch accuracy: 0.56733
Time: 2018-07-15 04:58:49
TRAINING STATS: batch 110/486 in epoch 715,  batch loss: 1.76789, batch accuracy: 0.52450
Time: 2018-07-15 04:58:54
TRAINING STATS: batch 160/486 in epoch 715,  batch loss: 1.64768, batch accuracy: 0.55750
Time: 2018-07-15 04:58:57
TRAINING STATS: batch 210/486 in epoch 715,  batch loss: 1.60278, batch accuracy: 0.56633
Time: 2018-07-15 04:59:01
TRAINING STATS: batch 260/486 in epoch 715,  batch loss: 1.67569, batch accuracy: 0.54600
Time: 2018-07-15 04:59:06
TRAINING STATS: batch 310/486 in epoch 715,  batch loss: 1.64913, batch accuracy: 0.55500
Time: 2018-07-15 04:59:09
TRAINING STATS: batch 360/486 in epoch 715,  batch loss: 1.69433, batch accuracy: 0.53967
Time: 2018-07-15 04:59:13
TRAINING STATS: batch 410/486 in epoch 715,  batch loss: 1.58027, batch accuracy: 0.57767
Time: 2018-07-15 04:59:18
TRAINING STATS: batch 460/486 in epoch 715,  batch loss: 1.76483, batch accuracy: 0.52067
Time: 2018-07-15 04:59:21
TRAINING STATS: batch 24/486 in epoch 716,   batch loss: 1.71005, batch accuracy: 0.54567
Time: 2018-07-15 04:59:25
TRAINING STATS: batch 74/486 in epoch 716,   batch loss: 1.66387, batch accuracy: 0.55500
Time: 2018-07-15 04:59:30
TRAINING STATS: batch 124/486 in epoch 716,  batch loss: 1.66672, batch accuracy: 0.55650
Time: 2018-07-15 04:59:34
TRAINING STATS: batch 174/486 in epoch 716,  batch loss: 1.72097, batch accuracy: 0.53400
Time: 2018-07-15 04:59:37
TRAINING STATS: batch 224/486 in epoch 716,  batch loss: 1.68490, batch accuracy: 0.54867
Time: 2018-07-15 04:59:42
TRAINING STATS: batch 274/486 in epoch 716,  batch loss: 1.66590, batch accuracy: 0.55667
Time: 2018-07-15 04:59:46
TRAINING STATS: batch 324/486 in epoch 716,  batch loss: 1.69266, batch accuracy: 0.54050
Time: 2018-07-15 04:59:49
TRAINING STATS: batch 374/486 in epoch 716,  batch loss: 1.68394, batch accuracy: 0.54767
Time: 2018-07-15 04:59:54
TRAINING STATS: batch 424/486 in epoch 716,  batch loss: 1.59851, batch accuracy: 0.57217
Time: 2018-07-15 04:59:58
TRAINING STATS: batch 474/486 in epoch 716,  batch loss: 1.64556, batch accuracy: 0.55650
Time: 2018-07-15 05:00:01
TRAINING STATS: batch 38/486 in epoch 717,   batch loss: 1.67147, batch accuracy: 0.55817
Time: 2018-07-15 05:00:06
TRAINING STATS: batch 88/486 in epoch 717,   batch loss: 1.74155, batch accuracy: 0.53517
Time: 2018-07-15 05:00:10
TRAINING STATS: batch 138/486 in epoch 717,  batch loss: 1.68058, batch accuracy: 0.54167
Time: 2018-07-15 05:00:13
TRAINING STATS: batch 188/486 in epoch 717,  batch loss: 1.59083, batch accuracy: 0.57350
Time: 2018-07-15 05:00:18
TRAINING STATS: batch 238/486 in epoch 717,  batch loss: 1.62273, batch accuracy: 0.56783
Time: 2018-07-15 05:00:22
TRAINING STATS: batch 288/486 in epoch 717,  batch loss: 1.69325, batch accuracy: 0.54450
Time: 2018-07-15 05:00:25
TRAINING STATS: batch 338/486 in epoch 717,  batch loss: 1.65905, batch accuracy: 0.55267
Time: 2018-07-15 05:00:30
TRAINING STATS: batch 388/486 in epoch 717,  batch loss: 1.63478, batch accuracy: 0.56167
Time: 2018-07-15 05:00:34
TRAINING STATS: batch 438/486 in epoch 717,  batch loss: 1.70132, batch accuracy: 0.54167
Time: 2018-07-15 05:00:37
TRAINING STATS: batch 2/486 in epoch 718,    batch loss: 1.67333, batch accuracy: 0.54950
Time: 2018-07-15 05:00:42
TRAINING STATS: batch 52/486 in epoch 718,   batch loss: 1.71418, batch accuracy: 0.53333
Time: 2018-07-15 05:00:46
TRAINING STATS: batch 102/486 in epoch 718,  batch loss: 1.68174, batch accuracy: 0.55267
Time: 2018-07-15 05:00:49
TRAINING STATS: batch 152/486 in epoch 718,  batch loss: 1.60165, batch accuracy: 0.56983
Time: 2018-07-15 05:00:54
TRAINING STATS: batch 202/486 in epoch 718,  batch loss: 1.65945, batch accuracy: 0.56183
Time: 2018-07-15 05:00:58
TRAINING STATS: batch 252/486 in epoch 718,  batch loss: 1.62666, batch accuracy: 0.56383
Time: 2018-07-15 05:01:02
TRAINING STATS: batch 302/486 in epoch 718,  batch loss: 1.61994, batch accuracy: 0.56650
Time: 2018-07-15 05:01:06
TRAINING STATS: batch 352/486 in epoch 718,  batch loss: 1.61770, batch accuracy: 0.56617
Time: 2018-07-15 05:01:10
TRAINING STATS: batch 402/486 in epoch 718,  batch loss: 1.50709, batch accuracy: 0.60150
Time: 2018-07-15 05:01:14
TRAINING STATS: batch 452/486 in epoch 718,  batch loss: 1.64510, batch accuracy: 0.55417
Time: 2018-07-15 05:01:18
TRAINING STATS: batch 16/486 in epoch 719,   batch loss: 1.60334, batch accuracy: 0.57233
Time: 2018-07-15 05:01:22
TRAINING STATS: batch 66/486 in epoch 719,   batch loss: 1.62325, batch accuracy: 0.57450
Time: 2018-07-15 05:01:26
TRAINING STATS: batch 116/486 in epoch 719,  batch loss: 1.60981, batch accuracy: 0.56267
Time: 2018-07-15 05:01:30
TRAINING STATS: batch 166/486 in epoch 719,  batch loss: 1.56944, batch accuracy: 0.58467
Time: 2018-07-15 05:01:34
TRAINING STATS: batch 216/486 in epoch 719,  batch loss: 1.66337, batch accuracy: 0.56033
Time: 2018-07-15 05:01:38
TRAINING STATS: batch 266/486 in epoch 719,  batch loss: 1.64185, batch accuracy: 0.55650
Time: 2018-07-15 05:01:42
TRAINING STATS: batch 316/486 in epoch 719,  batch loss: 1.65375, batch accuracy: 0.56100
Time: 2018-07-15 05:01:46
TRAINING STATS: batch 366/486 in epoch 719,  batch loss: 1.70274, batch accuracy: 0.54267
Time: 2018-07-15 05:01:50
TRAINING STATS: batch 416/486 in epoch 719,  batch loss: 1.68075, batch accuracy: 0.54617
Time: 2018-07-15 05:01:54
TRAINING STATS: batch 466/486 in epoch 719,  batch loss: 1.53187, batch accuracy: 0.59600
Time: 2018-07-15 05:01:58
TRAINING STATS: batch 30/486 in epoch 720,   batch loss: 1.54529, batch accuracy: 0.58650
Time: 2018-07-15 05:02:02
TRAINING STATS: batch 80/486 in epoch 720,   batch loss: 1.62942, batch accuracy: 0.55583
Time: 2018-07-15 05:02:07
TRAINING STATS: batch 130/486 in epoch 720,  batch loss: 1.62737, batch accuracy: 0.56833
Time: 2018-07-15 05:02:10
TRAINING STATS: batch 180/486 in epoch 720,  batch loss: 1.68503, batch accuracy: 0.55033
Time: 2018-07-15 05:02:14
TRAINING STATS: batch 230/486 in epoch 720,  batch loss: 1.66757, batch accuracy: 0.55050
Time: 2018-07-15 05:02:19
TRAINING STATS: batch 280/486 in epoch 720,  batch loss: 1.64163, batch accuracy: 0.56400
Time: 2018-07-15 05:02:22
TRAINING STATS: batch 330/486 in epoch 720,  batch loss: 1.62881, batch accuracy: 0.56117
Time: 2018-07-15 05:02:26
TRAINING STATS: batch 380/486 in epoch 720,  batch loss: 1.61464, batch accuracy: 0.57250
Time: 2018-07-15 05:02:31
TRAINING STATS: batch 430/486 in epoch 720,  batch loss: 1.55827, batch accuracy: 0.58550
Time: 2018-07-15 05:02:34
TRAINING STATS: batch 480/486 in epoch 720,  batch loss: 1.65761, batch accuracy: 0.56017
Time: 2018-07-15 05:02:38
TRAINING STATS: batch 44/486 in epoch 721,   batch loss: 1.59019, batch accuracy: 0.57383
Time: 2018-07-15 05:02:43
TRAINING STATS: batch 94/486 in epoch 721,   batch loss: 1.69259, batch accuracy: 0.54767
Time: 2018-07-15 05:02:46
TRAINING STATS: batch 144/486 in epoch 721,  batch loss: 1.71895, batch accuracy: 0.53400
Time: 2018-07-15 05:02:50
TRAINING STATS: batch 194/486 in epoch 721,  batch loss: 1.72237, batch accuracy: 0.52983
Time: 2018-07-15 05:02:55
TRAINING STATS: batch 244/486 in epoch 721,  batch loss: 1.63741, batch accuracy: 0.55850
Time: 2018-07-15 05:02:59
TRAINING STATS: batch 294/486 in epoch 721,  batch loss: 1.55734, batch accuracy: 0.58267
Time: 2018-07-15 05:03:02
TRAINING STATS: batch 344/486 in epoch 721,  batch loss: 1.61763, batch accuracy: 0.56250
Time: 2018-07-15 05:03:07
TRAINING STATS: batch 394/486 in epoch 721,  batch loss: 1.59980, batch accuracy: 0.56883
Time: 2018-07-15 05:03:11
TRAINING STATS: batch 444/486 in epoch 721,  batch loss: 1.57647, batch accuracy: 0.57817
Time: 2018-07-15 05:03:14
TRAINING STATS: batch 8/486 in epoch 722,    batch loss: 1.63044, batch accuracy: 0.55667
Time: 2018-07-15 05:03:19
TRAINING STATS: batch 58/486 in epoch 722,   batch loss: 1.60742, batch accuracy: 0.56900
Time: 2018-07-15 05:03:23
TRAINING STATS: batch 108/486 in epoch 722,  batch loss: 1.71183, batch accuracy: 0.54067
Time: 2018-07-15 05:03:26
TRAINING STATS: batch 158/486 in epoch 722,  batch loss: 1.68500, batch accuracy: 0.54667
Time: 2018-07-15 05:03:31
TRAINING STATS: batch 208/486 in epoch 722,  batch loss: 1.64849, batch accuracy: 0.55533
Time: 2018-07-15 05:03:35
TRAINING STATS: batch 258/486 in epoch 722,  batch loss: 1.60111, batch accuracy: 0.56850
Time: 2018-07-15 05:03:39
TRAINING STATS: batch 308/486 in epoch 722,  batch loss: 1.66666, batch accuracy: 0.55717
Time: 2018-07-15 05:03:43
TRAINING STATS: batch 358/486 in epoch 722,  batch loss: 1.67029, batch accuracy: 0.54367
Time: 2018-07-15 05:03:47
TRAINING STATS: batch 408/486 in epoch 722,  batch loss: 1.67741, batch accuracy: 0.54833
Time: 2018-07-15 05:03:51
TRAINING STATS: batch 458/486 in epoch 722,  batch loss: 1.66048, batch accuracy: 0.55617
Time: 2018-07-15 05:03:55
TRAINING STATS: batch 22/486 in epoch 723,   batch loss: 1.69966, batch accuracy: 0.54967
Time: 2018-07-15 05:03:59
TRAINING STATS: batch 72/486 in epoch 723,   batch loss: 1.67509, batch accuracy: 0.53983
Time: 2018-07-15 05:04:03
TRAINING STATS: batch 122/486 in epoch 723,  batch loss: 1.59319, batch accuracy: 0.57683
Time: 2018-07-15 05:04:07
TRAINING STATS: batch 172/486 in epoch 723,  batch loss: 1.71225, batch accuracy: 0.53283
Time: 2018-07-15 05:04:11
TRAINING STATS: batch 222/486 in epoch 723,  batch loss: 1.67267, batch accuracy: 0.55367
Time: 2018-07-15 05:04:15
TRAINING STATS: batch 272/486 in epoch 723,  batch loss: 1.66815, batch accuracy: 0.54067
Time: 2018-07-15 05:04:19
TRAINING STATS: batch 322/486 in epoch 723,  batch loss: 1.63868, batch accuracy: 0.55867
Time: 2018-07-15 05:04:23
TRAINING STATS: batch 372/486 in epoch 723,  batch loss: 1.58953, batch accuracy: 0.57183
Time: 2018-07-15 05:04:27
TRAINING STATS: batch 422/486 in epoch 723,  batch loss: 1.63220, batch accuracy: 0.55917
Time: 2018-07-15 05:04:31
TRAINING STATS: batch 472/486 in epoch 723,  batch loss: 1.71208, batch accuracy: 0.53850
Time: 2018-07-15 05:04:35
TRAINING STATS: batch 36/486 in epoch 724,   batch loss: 1.71544, batch accuracy: 0.54233
Time: 2018-07-15 05:04:39
TRAINING STATS: batch 86/486 in epoch 724,   batch loss: 1.65122, batch accuracy: 0.55633
Time: 2018-07-15 05:04:44
TRAINING STATS: batch 136/486 in epoch 724,  batch loss: 1.70128, batch accuracy: 0.54000
Time: 2018-07-15 05:04:47
TRAINING STATS: batch 186/486 in epoch 724,  batch loss: 1.65901, batch accuracy: 0.55433
Time: 2018-07-15 05:04:51
TRAINING STATS: batch 236/486 in epoch 724,  batch loss: 1.69181, batch accuracy: 0.54200
Time: 2018-07-15 05:04:56
TRAINING STATS: batch 286/486 in epoch 724,  batch loss: 1.69039, batch accuracy: 0.54917
Time: 2018-07-15 05:04:59
TRAINING STATS: batch 336/486 in epoch 724,  batch loss: 1.64544, batch accuracy: 0.56150
Time: 2018-07-15 05:05:03
TRAINING STATS: batch 386/486 in epoch 724,  batch loss: 1.69577, batch accuracy: 0.54000
Time: 2018-07-15 05:05:08
TRAINING STATS: batch 436/486 in epoch 724,  batch loss: 1.72172, batch accuracy: 0.54133
Time: 2018-07-15 05:05:11
TRAINING STATS: batch 0/486 in epoch 725,    batch loss: 1.63158, batch accuracy: 0.55900
Time: 2018-07-15 05:05:15
TRAINING STATS: batch 50/486 in epoch 725,   batch loss: 1.60343, batch accuracy: 0.57500
Time: 2018-07-15 05:05:20
TRAINING STATS: batch 100/486 in epoch 725,  batch loss: 1.66876, batch accuracy: 0.55717
Time: 2018-07-15 05:05:23
TRAINING STATS: batch 150/486 in epoch 725,  batch loss: 1.61821, batch accuracy: 0.56833
Time: 2018-07-15 05:05:27
TRAINING STATS: batch 200/486 in epoch 725,  batch loss: 1.52534, batch accuracy: 0.59150
Time: 2018-07-15 05:05:32
TRAINING STATS: batch 250/486 in epoch 725,  batch loss: 1.70230, batch accuracy: 0.53817
Time: 2018-07-15 05:05:36
TRAINING STATS: batch 300/486 in epoch 725,  batch loss: 1.67188, batch accuracy: 0.54317
Time: 2018-07-15 05:05:39
TRAINING STATS: batch 350/486 in epoch 725,  batch loss: 1.66708, batch accuracy: 0.55983
Time: 2018-07-15 05:05:44
TRAINING STATS: batch 400/486 in epoch 725,  batch loss: 1.53037, batch accuracy: 0.58933
Time: 2018-07-15 05:05:47
TRAINING STATS: batch 450/486 in epoch 725,  batch loss: 1.70423, batch accuracy: 0.53617
Time: 2018-07-15 05:05:51
TRAINING STATS: batch 14/486 in epoch 726,   batch loss: 1.55616, batch accuracy: 0.58383
Time: 2018-07-15 05:05:56
TRAINING STATS: batch 64/486 in epoch 726,   batch loss: 1.76008, batch accuracy: 0.52017
Time: 2018-07-15 05:05:59
TRAINING STATS: batch 114/486 in epoch 726,  batch loss: 1.68621, batch accuracy: 0.54283
Time: 2018-07-15 05:06:03
TRAINING STATS: batch 164/486 in epoch 726,  batch loss: 1.58765, batch accuracy: 0.57333
Time: 2018-07-15 05:06:08
TRAINING STATS: batch 214/486 in epoch 726,  batch loss: 1.63375, batch accuracy: 0.56467
Time: 2018-07-15 05:06:12
TRAINING STATS: batch 264/486 in epoch 726,  batch loss: 1.68800, batch accuracy: 0.53983
Time: 2018-07-15 05:06:15
TRAINING STATS: batch 314/486 in epoch 726,  batch loss: 1.70376, batch accuracy: 0.53050
Time: 2018-07-15 05:06:20
TRAINING STATS: batch 364/486 in epoch 726,  batch loss: 1.72223, batch accuracy: 0.53617
Time: 2018-07-15 05:06:24
TRAINING STATS: batch 414/486 in epoch 726,  batch loss: 1.61786, batch accuracy: 0.56233
Time: 2018-07-15 05:06:27
TRAINING STATS: batch 464/486 in epoch 726,  batch loss: 1.64201, batch accuracy: 0.56167
Time: 2018-07-15 05:06:32
TRAINING STATS: batch 28/486 in epoch 727,   batch loss: 1.58210, batch accuracy: 0.58117
Time: 2018-07-15 05:06:36
TRAINING STATS: batch 78/486 in epoch 727,   batch loss: 1.64552, batch accuracy: 0.56650
Time: 2018-07-15 05:06:39
TRAINING STATS: batch 128/486 in epoch 727,  batch loss: 1.62543, batch accuracy: 0.56100
Time: 2018-07-15 05:06:44
TRAINING STATS: batch 178/486 in epoch 727,  batch loss: 1.53503, batch accuracy: 0.58400
Time: 2018-07-15 05:06:48
TRAINING STATS: batch 228/486 in epoch 727,  batch loss: 1.58939, batch accuracy: 0.57033
Time: 2018-07-15 05:06:52
TRAINING STATS: batch 278/486 in epoch 727,  batch loss: 1.58459, batch accuracy: 0.57367
Time: 2018-07-15 05:06:56
TRAINING STATS: batch 328/486 in epoch 727,  batch loss: 1.61179, batch accuracy: 0.56417
Time: 2018-07-15 05:07:00
TRAINING STATS: batch 378/486 in epoch 727,  batch loss: 1.63912, batch accuracy: 0.56983
Time: 2018-07-15 05:07:03
TRAINING STATS: batch 428/486 in epoch 727,  batch loss: 1.70351, batch accuracy: 0.54033
Time: 2018-07-15 05:07:08
TRAINING STATS: batch 478/486 in epoch 727,  batch loss: 1.66026, batch accuracy: 0.55600
Time: 2018-07-15 05:07:12
TRAINING STATS: batch 42/486 in epoch 728,   batch loss: 1.55151, batch accuracy: 0.58583
Time: 2018-07-15 05:07:16
TRAINING STATS: batch 92/486 in epoch 728,   batch loss: 1.65235, batch accuracy: 0.54733
Time: 2018-07-15 05:07:20
TRAINING STATS: batch 142/486 in epoch 728,  batch loss: 1.60350, batch accuracy: 0.57033
Time: 2018-07-15 05:07:24
TRAINING STATS: batch 192/486 in epoch 728,  batch loss: 1.66174, batch accuracy: 0.54733
Time: 2018-07-15 05:07:27
TRAINING STATS: batch 242/486 in epoch 728,  batch loss: 1.61283, batch accuracy: 0.56317
Time: 2018-07-15 05:07:32
TRAINING STATS: batch 292/486 in epoch 728,  batch loss: 1.63197, batch accuracy: 0.55717
Time: 2018-07-15 05:07:36
TRAINING STATS: batch 342/486 in epoch 728,  batch loss: 1.72254, batch accuracy: 0.52833
Time: 2018-07-15 05:07:40
TRAINING STATS: batch 392/486 in epoch 728,  batch loss: 1.57385, batch accuracy: 0.57683
Time: 2018-07-15 05:07:44
TRAINING STATS: batch 442/486 in epoch 728,  batch loss: 1.56917, batch accuracy: 0.58200
Time: 2018-07-15 05:07:48
TRAINING STATS: batch 6/486 in epoch 729,    batch loss: 1.69105, batch accuracy: 0.55483
Time: 2018-07-15 05:07:52
TRAINING STATS: batch 56/486 in epoch 729,   batch loss: 1.60181, batch accuracy: 0.56600
Time: 2018-07-15 05:07:57
TRAINING STATS: batch 106/486 in epoch 729,  batch loss: 1.71915, batch accuracy: 0.53767
Time: 2018-07-15 05:08:00
TRAINING STATS: batch 156/486 in epoch 729,  batch loss: 1.66209, batch accuracy: 0.55133
Time: 2018-07-15 05:08:04
TRAINING STATS: batch 206/486 in epoch 729,  batch loss: 1.73012, batch accuracy: 0.52983
Time: 2018-07-15 05:08:09
TRAINING STATS: batch 256/486 in epoch 729,  batch loss: 1.60470, batch accuracy: 0.56500
Time: 2018-07-15 05:08:12
TRAINING STATS: batch 306/486 in epoch 729,  batch loss: 1.63501, batch accuracy: 0.55483
Time: 2018-07-15 05:08:16
TRAINING STATS: batch 356/486 in epoch 729,  batch loss: 1.69280, batch accuracy: 0.54317
Time: 2018-07-15 05:08:21
TRAINING STATS: batch 406/486 in epoch 729,  batch loss: 1.76274, batch accuracy: 0.52333
Time: 2018-07-15 05:08:24
TRAINING STATS: batch 456/486 in epoch 729,  batch loss: 1.54017, batch accuracy: 0.58667
Time: 2018-07-15 05:08:28
TRAINING STATS: batch 20/486 in epoch 730,   batch loss: 1.64773, batch accuracy: 0.55933
Time: 2018-07-15 05:08:33
TRAINING STATS: batch 70/486 in epoch 730,   batch loss: 1.53204, batch accuracy: 0.59350
Time: 2018-07-15 05:08:36
TRAINING STATS: batch 120/486 in epoch 730,  batch loss: 1.58879, batch accuracy: 0.57233
Time: 2018-07-15 05:08:40
TRAINING STATS: batch 170/486 in epoch 730,  batch loss: 1.62808, batch accuracy: 0.56117
Time: 2018-07-15 05:08:45
TRAINING STATS: batch 220/486 in epoch 730,  batch loss: 1.57026, batch accuracy: 0.58317
Time: 2018-07-15 05:08:48
TRAINING STATS: batch 270/486 in epoch 730,  batch loss: 1.72150, batch accuracy: 0.52883
Time: 2018-07-15 05:08:52
TRAINING STATS: batch 320/486 in epoch 730,  batch loss: 1.57820, batch accuracy: 0.57800
Time: 2018-07-15 05:08:57
TRAINING STATS: batch 370/486 in epoch 730,  batch loss: 1.67518, batch accuracy: 0.55333
Time: 2018-07-15 05:09:01
TRAINING STATS: batch 420/486 in epoch 730,  batch loss: 1.68416, batch accuracy: 0.55167
Time: 2018-07-15 05:09:04
TRAINING STATS: batch 470/486 in epoch 730,  batch loss: 1.74848, batch accuracy: 0.51667
Time: 2018-07-15 05:09:09
TRAINING STATS: batch 34/486 in epoch 731,   batch loss: 1.65312, batch accuracy: 0.56017
Time: 2018-07-15 05:09:13
TRAINING STATS: batch 84/486 in epoch 731,   batch loss: 1.65580, batch accuracy: 0.54817
Time: 2018-07-15 05:09:16
TRAINING STATS: batch 134/486 in epoch 731,  batch loss: 1.67982, batch accuracy: 0.55150
Time: 2018-07-15 05:09:21
TRAINING STATS: batch 184/486 in epoch 731,  batch loss: 1.64633, batch accuracy: 0.55667
Time: 2018-07-15 05:09:24
TRAINING STATS: batch 234/486 in epoch 731,  batch loss: 1.73792, batch accuracy: 0.52883
Time: 2018-07-15 05:09:28
TRAINING STATS: batch 284/486 in epoch 731,  batch loss: 1.68312, batch accuracy: 0.54817
Time: 2018-07-15 05:09:33
TRAINING STATS: batch 334/486 in epoch 731,  batch loss: 1.61618, batch accuracy: 0.56467
Time: 2018-07-15 05:09:37
TRAINING STATS: batch 384/486 in epoch 731,  batch loss: 1.61122, batch accuracy: 0.57200
Time: 2018-07-15 05:09:40
TRAINING STATS: batch 434/486 in epoch 731,  batch loss: 1.69137, batch accuracy: 0.53883
Time: 2018-07-15 05:09:45
TRAINING STATS: batch 484/486 in epoch 731,  batch loss: 1.64541, batch accuracy: 0.55817
Time: 2018-07-15 05:09:49
TRAINING STATS: batch 48/486 in epoch 732,   batch loss: 1.64225, batch accuracy: 0.55667
Time: 2018-07-15 05:09:52
TRAINING STATS: batch 98/486 in epoch 732,   batch loss: 1.57632, batch accuracy: 0.57650
Time: 2018-07-15 05:09:57
TRAINING STATS: batch 148/486 in epoch 732,  batch loss: 1.66907, batch accuracy: 0.55333
Time: 2018-07-15 05:10:01
TRAINING STATS: batch 198/486 in epoch 732,  batch loss: 1.61745, batch accuracy: 0.56267
Time: 2018-07-15 05:10:04
TRAINING STATS: batch 248/486 in epoch 732,  batch loss: 1.65995, batch accuracy: 0.55500
Time: 2018-07-15 05:10:09
TRAINING STATS: batch 298/486 in epoch 732,  batch loss: 1.66467, batch accuracy: 0.54367
Time: 2018-07-15 05:10:13
TRAINING STATS: batch 348/486 in epoch 732,  batch loss: 1.64381, batch accuracy: 0.56283
Time: 2018-07-15 05:10:17
TRAINING STATS: batch 398/486 in epoch 732,  batch loss: 1.64924, batch accuracy: 0.55967
Time: 2018-07-15 05:10:21
TRAINING STATS: batch 448/486 in epoch 732,  batch loss: 1.64921, batch accuracy: 0.56267
Time: 2018-07-15 05:10:25
TRAINING STATS: batch 12/486 in epoch 733,   batch loss: 1.66652, batch accuracy: 0.54850
Time: 2018-07-15 05:10:29
TRAINING STATS: batch 62/486 in epoch 733,   batch loss: 1.73703, batch accuracy: 0.52550
Time: 2018-07-15 05:10:33
TRAINING STATS: batch 112/486 in epoch 733,  batch loss: 1.61692, batch accuracy: 0.56100
Time: 2018-07-15 05:10:37
TRAINING STATS: batch 162/486 in epoch 733,  batch loss: 1.65241, batch accuracy: 0.56500
Time: 2018-07-15 05:10:41
TRAINING STATS: batch 212/486 in epoch 733,  batch loss: 1.54614, batch accuracy: 0.57533
Time: 2018-07-15 05:10:45
TRAINING STATS: batch 262/486 in epoch 733,  batch loss: 1.70736, batch accuracy: 0.54400
Time: 2018-07-15 05:10:49
TRAINING STATS: batch 312/486 in epoch 733,  batch loss: 1.65286, batch accuracy: 0.54817
Time: 2018-07-15 05:10:53
TRAINING STATS: batch 362/486 in epoch 733,  batch loss: 1.65507, batch accuracy: 0.55683
Time: 2018-07-15 05:10:58
TRAINING STATS: batch 412/486 in epoch 733,  batch loss: 1.60399, batch accuracy: 0.56883
Time: 2018-07-15 05:11:01
TRAINING STATS: batch 462/486 in epoch 733,  batch loss: 1.68030, batch accuracy: 0.55383
Time: 2018-07-15 05:11:05
TRAINING STATS: batch 26/486 in epoch 734,   batch loss: 1.68950, batch accuracy: 0.54267
Time: 2018-07-15 05:11:10
TRAINING STATS: batch 76/486 in epoch 734,   batch loss: 1.70351, batch accuracy: 0.54133
Time: 2018-07-15 05:11:13
TRAINING STATS: batch 126/486 in epoch 734,  batch loss: 1.70739, batch accuracy: 0.54233
Time: 2018-07-15 05:11:17
TRAINING STATS: batch 176/486 in epoch 734,  batch loss: 1.56456, batch accuracy: 0.57850
Time: 2018-07-15 05:11:22
TRAINING STATS: batch 226/486 in epoch 734,  batch loss: 1.62653, batch accuracy: 0.56100
Time: 2018-07-15 05:11:25
TRAINING STATS: batch 276/486 in epoch 734,  batch loss: 1.63938, batch accuracy: 0.55250
Time: 2018-07-15 05:11:29
TRAINING STATS: batch 326/486 in epoch 734,  batch loss: 1.67528, batch accuracy: 0.55150
Time: 2018-07-15 05:11:34
TRAINING STATS: batch 376/486 in epoch 734,  batch loss: 1.67337, batch accuracy: 0.55083
Time: 2018-07-15 05:11:37
TRAINING STATS: batch 426/486 in epoch 734,  batch loss: 1.62904, batch accuracy: 0.55867
Time: 2018-07-15 05:11:41
TRAINING STATS: batch 476/486 in epoch 734,  batch loss: 1.58320, batch accuracy: 0.57650
Time: 2018-07-15 05:11:46
TRAINING STATS: batch 40/486 in epoch 735,   batch loss: 1.59571, batch accuracy: 0.56983
Time: 2018-07-15 05:11:49
TRAINING STATS: batch 90/486 in epoch 735,   batch loss: 1.67675, batch accuracy: 0.54850
Time: 2018-07-15 05:11:53
TRAINING STATS: batch 140/486 in epoch 735,  batch loss: 1.58509, batch accuracy: 0.56783
Time: 2018-07-15 05:11:58
TRAINING STATS: batch 190/486 in epoch 735,  batch loss: 1.60728, batch accuracy: 0.56517
Time: 2018-07-15 05:12:02
TRAINING STATS: batch 240/486 in epoch 735,  batch loss: 1.61683, batch accuracy: 0.55683
Time: 2018-07-15 05:12:05
TRAINING STATS: batch 290/486 in epoch 735,  batch loss: 1.66330, batch accuracy: 0.54500
Time: 2018-07-15 05:12:10
TRAINING STATS: batch 340/486 in epoch 735,  batch loss: 1.71478, batch accuracy: 0.53100
Time: 2018-07-15 05:12:14
TRAINING STATS: batch 390/486 in epoch 735,  batch loss: 1.57081, batch accuracy: 0.58100
Time: 2018-07-15 05:12:17
TRAINING STATS: batch 440/486 in epoch 735,  batch loss: 1.65885, batch accuracy: 0.55333
Time: 2018-07-15 05:12:22
TRAINING STATS: batch 4/486 in epoch 736,    batch loss: 1.59344, batch accuracy: 0.57900
Time: 2018-07-15 05:12:26
TRAINING STATS: batch 54/486 in epoch 736,   batch loss: 1.64870, batch accuracy: 0.55633
Time: 2018-07-15 05:12:29
TRAINING STATS: batch 104/486 in epoch 736,  batch loss: 1.64784, batch accuracy: 0.56200
Time: 2018-07-15 05:12:34
TRAINING STATS: batch 154/486 in epoch 736,  batch loss: 1.60739, batch accuracy: 0.56267
Time: 2018-07-15 05:12:38
TRAINING STATS: batch 204/486 in epoch 736,  batch loss: 1.68946, batch accuracy: 0.54733
Time: 2018-07-15 05:12:41
TRAINING STATS: batch 254/486 in epoch 736,  batch loss: 1.56557, batch accuracy: 0.58017
Time: 2018-07-15 05:12:46
TRAINING STATS: batch 304/486 in epoch 736,  batch loss: 1.60021, batch accuracy: 0.56733
Time: 2018-07-15 05:12:50
TRAINING STATS: batch 354/486 in epoch 736,  batch loss: 1.63815, batch accuracy: 0.56117
Time: 2018-07-15 05:12:54
TRAINING STATS: batch 404/486 in epoch 736,  batch loss: 1.62083, batch accuracy: 0.55950
Time: 2018-07-15 05:12:58
TRAINING STATS: batch 454/486 in epoch 736,  batch loss: 1.50823, batch accuracy: 0.59433
Time: 2018-07-15 05:13:02
TRAINING STATS: batch 18/486 in epoch 737,   batch loss: 1.71263, batch accuracy: 0.53967
Time: 2018-07-15 05:13:06
TRAINING STATS: batch 68/486 in epoch 737,   batch loss: 1.48012, batch accuracy: 0.61050
Time: 2018-07-15 05:13:10
TRAINING STATS: batch 118/486 in epoch 737,  batch loss: 1.65182, batch accuracy: 0.55400
Time: 2018-07-15 05:13:14
TRAINING STATS: batch 168/486 in epoch 737,  batch loss: 1.56127, batch accuracy: 0.58550
Time: 2018-07-15 05:13:18
TRAINING STATS: batch 218/486 in epoch 737,  batch loss: 1.62224, batch accuracy: 0.56117
Time: 2018-07-15 05:13:22
TRAINING STATS: batch 268/486 in epoch 737,  batch loss: 1.57711, batch accuracy: 0.56467
Time: 2018-07-15 05:13:26
TRAINING STATS: batch 318/486 in epoch 737,  batch loss: 1.64583, batch accuracy: 0.54817
Time: 2018-07-15 05:13:30
TRAINING STATS: batch 368/486 in epoch 737,  batch loss: 1.64816, batch accuracy: 0.56200
Time: 2018-07-15 05:13:34
TRAINING STATS: batch 418/486 in epoch 737,  batch loss: 1.70568, batch accuracy: 0.54283
Time: 2018-07-15 05:13:38
TRAINING STATS: batch 468/486 in epoch 737,  batch loss: 1.63256, batch accuracy: 0.55983
Time: 2018-07-15 05:13:42
TRAINING STATS: batch 32/486 in epoch 738,   batch loss: 1.59198, batch accuracy: 0.57150
Time: 2018-07-15 05:13:46
TRAINING STATS: batch 82/486 in epoch 738,   batch loss: 1.66163, batch accuracy: 0.54917
Time: 2018-07-15 05:13:50
TRAINING STATS: batch 132/486 in epoch 738,  batch loss: 1.63034, batch accuracy: 0.56950
Time: 2018-07-15 05:13:54
TRAINING STATS: batch 182/486 in epoch 738,  batch loss: 1.69643, batch accuracy: 0.54200
Time: 2018-07-15 05:13:58
TRAINING STATS: batch 232/486 in epoch 738,  batch loss: 1.66963, batch accuracy: 0.55100
Time: 2018-07-15 05:14:02
TRAINING STATS: batch 282/486 in epoch 738,  batch loss: 1.59010, batch accuracy: 0.56700
Time: 2018-07-15 05:14:06
TRAINING STATS: batch 332/486 in epoch 738,  batch loss: 1.67087, batch accuracy: 0.55067
Time: 2018-07-15 05:14:10
TRAINING STATS: batch 382/486 in epoch 738,  batch loss: 1.65575, batch accuracy: 0.56183
Time: 2018-07-15 05:14:14
TRAINING STATS: batch 432/486 in epoch 738,  batch loss: 1.57454, batch accuracy: 0.56950
Time: 2018-07-15 05:14:18
TRAINING STATS: batch 482/486 in epoch 738,  batch loss: 1.62454, batch accuracy: 0.56383
Time: 2018-07-15 05:14:23
TRAINING STATS: batch 46/486 in epoch 739,   batch loss: 1.60390, batch accuracy: 0.57100
Time: 2018-07-15 05:14:26
TRAINING STATS: batch 96/486 in epoch 739,   batch loss: 1.66351, batch accuracy: 0.55133
Time: 2018-07-15 05:14:30
TRAINING STATS: batch 146/486 in epoch 739,  batch loss: 1.67247, batch accuracy: 0.55200
Time: 2018-07-15 05:14:35
TRAINING STATS: batch 196/486 in epoch 739,  batch loss: 1.69024, batch accuracy: 0.53933
Time: 2018-07-15 05:14:38
TRAINING STATS: batch 246/486 in epoch 739,  batch loss: 1.62065, batch accuracy: 0.56617
Time: 2018-07-15 05:14:42
TRAINING STATS: batch 296/486 in epoch 739,  batch loss: 1.64387, batch accuracy: 0.56133
Time: 2018-07-15 05:14:47
TRAINING STATS: batch 346/486 in epoch 739,  batch loss: 1.54660, batch accuracy: 0.58317
Time: 2018-07-15 05:14:50
TRAINING STATS: batch 396/486 in epoch 739,  batch loss: 1.61317, batch accuracy: 0.56450
Time: 2018-07-15 05:14:54
TRAINING STATS: batch 446/486 in epoch 739,  batch loss: 1.65109, batch accuracy: 0.55250
Time: 2018-07-15 05:14:59
TRAINING STATS: batch 10/486 in epoch 740,   batch loss: 1.68335, batch accuracy: 0.54117
Time: 2018-07-15 05:15:03
TRAINING STATS: batch 60/486 in epoch 740,   batch loss: 1.63174, batch accuracy: 0.56083
Time: 2018-07-15 05:15:06
TRAINING STATS: batch 110/486 in epoch 740,  batch loss: 1.70046, batch accuracy: 0.55083
Time: 2018-07-15 05:15:11
TRAINING STATS: batch 160/486 in epoch 740,  batch loss: 1.62974, batch accuracy: 0.55883
Time: 2018-07-15 05:15:15
TRAINING STATS: batch 210/486 in epoch 740,  batch loss: 1.58081, batch accuracy: 0.56967
Time: 2018-07-15 05:15:18
TRAINING STATS: batch 260/486 in epoch 740,  batch loss: 1.67370, batch accuracy: 0.54467
Time: 2018-07-15 05:15:23
TRAINING STATS: batch 310/486 in epoch 740,  batch loss: 1.64042, batch accuracy: 0.55933
Time: 2018-07-15 05:15:27
TRAINING STATS: batch 360/486 in epoch 740,  batch loss: 1.67563, batch accuracy: 0.54450
Time: 2018-07-15 05:15:30
TRAINING STATS: batch 410/486 in epoch 740,  batch loss: 1.58926, batch accuracy: 0.56833
Time: 2018-07-15 05:15:35
TRAINING STATS: batch 460/486 in epoch 740,  batch loss: 1.75503, batch accuracy: 0.52367
Time: 2018-07-15 05:15:39
TRAINING STATS: batch 24/486 in epoch 741,   batch loss: 1.71240, batch accuracy: 0.54000
Time: 2018-07-15 05:15:42
TRAINING STATS: batch 74/486 in epoch 741,   batch loss: 1.66283, batch accuracy: 0.55550
Time: 2018-07-15 05:15:47
TRAINING STATS: batch 124/486 in epoch 741,  batch loss: 1.65978, batch accuracy: 0.55983
Time: 2018-07-15 05:15:51
TRAINING STATS: batch 174/486 in epoch 741,  batch loss: 1.70473, batch accuracy: 0.54400
Time: 2018-07-15 05:15:54
TRAINING STATS: batch 224/486 in epoch 741,  batch loss: 1.68037, batch accuracy: 0.54883
Time: 2018-07-15 05:15:59
TRAINING STATS: batch 274/486 in epoch 741,  batch loss: 1.66337, batch accuracy: 0.55300
Time: 2018-07-15 05:16:03
TRAINING STATS: batch 324/486 in epoch 741,  batch loss: 1.68210, batch accuracy: 0.54683
Time: 2018-07-15 05:16:07
TRAINING STATS: batch 374/486 in epoch 741,  batch loss: 1.68012, batch accuracy: 0.54700
Time: 2018-07-15 05:16:11
TRAINING STATS: batch 424/486 in epoch 741,  batch loss: 1.58792, batch accuracy: 0.57550
Time: 2018-07-15 05:16:15
TRAINING STATS: batch 474/486 in epoch 741,  batch loss: 1.66598, batch accuracy: 0.55367
Time: 2018-07-15 05:16:19
TRAINING STATS: batch 38/486 in epoch 742,   batch loss: 1.67321, batch accuracy: 0.55617
Time: 2018-07-15 05:16:23
TRAINING STATS: batch 88/486 in epoch 742,   batch loss: 1.69729, batch accuracy: 0.53717
Time: 2018-07-15 05:16:27
TRAINING STATS: batch 138/486 in epoch 742,  batch loss: 1.68581, batch accuracy: 0.53883
Time: 2018-07-15 05:16:31
TRAINING STATS: batch 188/486 in epoch 742,  batch loss: 1.60507, batch accuracy: 0.57067
Time: 2018-07-15 05:16:35
TRAINING STATS: batch 238/486 in epoch 742,  batch loss: 1.61031, batch accuracy: 0.56800
Time: 2018-07-15 05:16:39
TRAINING STATS: batch 288/486 in epoch 742,  batch loss: 1.66480, batch accuracy: 0.54567
Time: 2018-07-15 05:16:43
TRAINING STATS: batch 338/486 in epoch 742,  batch loss: 1.66230, batch accuracy: 0.54467
Time: 2018-07-15 05:16:47
TRAINING STATS: batch 388/486 in epoch 742,  batch loss: 1.60383, batch accuracy: 0.57033
Time: 2018-07-15 05:16:51
TRAINING STATS: batch 438/486 in epoch 742,  batch loss: 1.65348, batch accuracy: 0.55900
Time: 2018-07-15 05:16:55
TRAINING STATS: batch 2/486 in epoch 743,    batch loss: 1.64453, batch accuracy: 0.54900
Time: 2018-07-15 05:17:00
TRAINING STATS: batch 52/486 in epoch 743,   batch loss: 1.77499, batch accuracy: 0.51350
Time: 2018-07-15 05:17:03
TRAINING STATS: batch 102/486 in epoch 743,  batch loss: 1.71093, batch accuracy: 0.54767
Time: 2018-07-15 05:17:07
TRAINING STATS: batch 152/486 in epoch 743,  batch loss: 1.60998, batch accuracy: 0.56617
Time: 2018-07-15 05:17:12
TRAINING STATS: batch 202/486 in epoch 743,  batch loss: 1.66199, batch accuracy: 0.55867
Time: 2018-07-15 05:17:15
TRAINING STATS: batch 252/486 in epoch 743,  batch loss: 1.61043, batch accuracy: 0.56183
Time: 2018-07-15 05:17:19
TRAINING STATS: batch 302/486 in epoch 743,  batch loss: 1.59541, batch accuracy: 0.56483
Time: 2018-07-15 05:17:24
TRAINING STATS: batch 352/486 in epoch 743,  batch loss: 1.61070, batch accuracy: 0.56550
Time: 2018-07-15 05:17:27
TRAINING STATS: batch 402/486 in epoch 743,  batch loss: 1.51630, batch accuracy: 0.59617
Time: 2018-07-15 05:17:31
TRAINING STATS: batch 452/486 in epoch 743,  batch loss: 1.66354, batch accuracy: 0.55183
Time: 2018-07-15 05:17:36
TRAINING STATS: batch 16/486 in epoch 744,   batch loss: 1.62119, batch accuracy: 0.56450
Time: 2018-07-15 05:17:39
TRAINING STATS: batch 66/486 in epoch 744,   batch loss: 1.63125, batch accuracy: 0.56550
Time: 2018-07-15 05:17:43
TRAINING STATS: batch 116/486 in epoch 744,  batch loss: 1.60519, batch accuracy: 0.56450
Time: 2018-07-15 05:17:48
TRAINING STATS: batch 166/486 in epoch 744,  batch loss: 1.54489, batch accuracy: 0.57950
Time: 2018-07-15 05:17:52
TRAINING STATS: batch 216/486 in epoch 744,  batch loss: 1.66345, batch accuracy: 0.55900
Time: 2018-07-15 05:17:55
TRAINING STATS: batch 266/486 in epoch 744,  batch loss: 1.63770, batch accuracy: 0.55550
Time: 2018-07-15 05:18:00
TRAINING STATS: batch 316/486 in epoch 744,  batch loss: 1.62911, batch accuracy: 0.55800
Time: 2018-07-15 05:18:03
TRAINING STATS: batch 366/486 in epoch 744,  batch loss: 1.70625, batch accuracy: 0.54150
Time: 2018-07-15 05:18:07
TRAINING STATS: batch 416/486 in epoch 744,  batch loss: 1.66985, batch accuracy: 0.54917
Time: 2018-07-15 05:18:12
TRAINING STATS: batch 466/486 in epoch 744,  batch loss: 1.49212, batch accuracy: 0.60500
Time: 2018-07-15 05:18:16
TRAINING STATS: batch 30/486 in epoch 745,   batch loss: 1.51676, batch accuracy: 0.59483
Time: 2018-07-15 05:18:19
TRAINING STATS: batch 80/486 in epoch 745,   batch loss: 1.63336, batch accuracy: 0.55833
Time: 2018-07-15 05:18:24
TRAINING STATS: batch 130/486 in epoch 745,  batch loss: 1.61551, batch accuracy: 0.56733
Time: 2018-07-15 05:18:28
TRAINING STATS: batch 180/486 in epoch 745,  batch loss: 1.65544, batch accuracy: 0.55633
Time: 2018-07-15 05:18:31
TRAINING STATS: batch 230/486 in epoch 745,  batch loss: 1.66787, batch accuracy: 0.54467
Time: 2018-07-15 05:18:36
TRAINING STATS: batch 280/486 in epoch 745,  batch loss: 1.61971, batch accuracy: 0.55800
Time: 2018-07-15 05:18:40
TRAINING STATS: batch 330/486 in epoch 745,  batch loss: 1.61210, batch accuracy: 0.56367
Time: 2018-07-15 05:18:43
TRAINING STATS: batch 380/486 in epoch 745,  batch loss: 1.62527, batch accuracy: 0.57433
Time: 2018-07-15 05:18:48
TRAINING STATS: batch 430/486 in epoch 745,  batch loss: 1.58781, batch accuracy: 0.57917
Time: 2018-07-15 05:18:52
TRAINING STATS: batch 480/486 in epoch 745,  batch loss: 1.65434, batch accuracy: 0.55633
Time: 2018-07-15 05:18:55
TRAINING STATS: batch 44/486 in epoch 746,   batch loss: 1.57252, batch accuracy: 0.57483
Time: 2018-07-15 05:19:00
TRAINING STATS: batch 94/486 in epoch 746,   batch loss: 1.71701, batch accuracy: 0.54250
Time: 2018-07-15 05:19:04
TRAINING STATS: batch 144/486 in epoch 746,  batch loss: 1.70031, batch accuracy: 0.53017
Time: 2018-07-15 05:19:08
TRAINING STATS: batch 194/486 in epoch 746,  batch loss: 1.74634, batch accuracy: 0.52533
Time: 2018-07-15 05:19:12
TRAINING STATS: batch 244/486 in epoch 746,  batch loss: 1.62764, batch accuracy: 0.55767
Time: 2018-07-15 05:19:16
TRAINING STATS: batch 294/486 in epoch 746,  batch loss: 1.56036, batch accuracy: 0.57600
Time: 2018-07-15 05:19:20
TRAINING STATS: batch 344/486 in epoch 746,  batch loss: 1.63018, batch accuracy: 0.55217
Time: 2018-07-15 05:19:24
TRAINING STATS: batch 394/486 in epoch 746,  batch loss: 1.58534, batch accuracy: 0.57683
Time: 2018-07-15 05:19:28
TRAINING STATS: batch 444/486 in epoch 746,  batch loss: 1.57872, batch accuracy: 0.58050
Time: 2018-07-15 05:19:32
TRAINING STATS: batch 8/486 in epoch 747,    batch loss: 1.63381, batch accuracy: 0.55683
Time: 2018-07-15 05:19:37
TRAINING STATS: batch 58/486 in epoch 747,   batch loss: 1.60845, batch accuracy: 0.56983
Time: 2018-07-15 05:19:40
TRAINING STATS: batch 108/486 in epoch 747,  batch loss: 1.69685, batch accuracy: 0.54583
Time: 2018-07-15 05:19:44
TRAINING STATS: batch 158/486 in epoch 747,  batch loss: 1.69068, batch accuracy: 0.54067
Time: 2018-07-15 05:19:49
TRAINING STATS: batch 208/486 in epoch 747,  batch loss: 1.65715, batch accuracy: 0.55683
Time: 2018-07-15 05:19:52
TRAINING STATS: batch 258/486 in epoch 747,  batch loss: 1.58886, batch accuracy: 0.56867
Time: 2018-07-15 05:19:56
TRAINING STATS: batch 308/486 in epoch 747,  batch loss: 1.63933, batch accuracy: 0.56783
Time: 2018-07-15 05:20:01
TRAINING STATS: batch 358/486 in epoch 747,  batch loss: 1.67002, batch accuracy: 0.54367
Time: 2018-07-15 05:20:04
TRAINING STATS: batch 408/486 in epoch 747,  batch loss: 1.74499, batch accuracy: 0.53200
Time: 2018-07-15 05:20:08
TRAINING STATS: batch 458/486 in epoch 747,  batch loss: 1.68025, batch accuracy: 0.54717
Time: 2018-07-15 05:20:13
TRAINING STATS: batch 22/486 in epoch 748,   batch loss: 1.70032, batch accuracy: 0.54733
Time: 2018-07-15 05:20:16
TRAINING STATS: batch 72/486 in epoch 748,   batch loss: 1.66916, batch accuracy: 0.54233
Time: 2018-07-15 05:20:20
TRAINING STATS: batch 122/486 in epoch 748,  batch loss: 1.60541, batch accuracy: 0.57183
Time: 2018-07-15 05:20:25
TRAINING STATS: batch 172/486 in epoch 748,  batch loss: 1.68680, batch accuracy: 0.54333
Time: 2018-07-15 05:20:28
TRAINING STATS: batch 222/486 in epoch 748,  batch loss: 1.63402, batch accuracy: 0.55183
Time: 2018-07-15 05:20:32
TRAINING STATS: batch 272/486 in epoch 748,  batch loss: 1.66996, batch accuracy: 0.54417
Time: 2018-07-15 05:20:37
TRAINING STATS: batch 322/486 in epoch 748,  batch loss: 1.64414, batch accuracy: 0.54900
Time: 2018-07-15 05:20:40
TRAINING STATS: batch 372/486 in epoch 748,  batch loss: 1.56641, batch accuracy: 0.58017
Time: 2018-07-15 05:20:44
TRAINING STATS: batch 422/486 in epoch 748,  batch loss: 1.62872, batch accuracy: 0.54983
Time: 2018-07-15 05:20:49
TRAINING STATS: batch 472/486 in epoch 748,  batch loss: 1.70207, batch accuracy: 0.54350
Time: 2018-07-15 05:20:52
TRAINING STATS: batch 36/486 in epoch 749,   batch loss: 1.68942, batch accuracy: 0.54050
Time: 2018-07-15 05:20:56
TRAINING STATS: batch 86/486 in epoch 749,   batch loss: 1.64835, batch accuracy: 0.55950
Time: 2018-07-15 05:21:01
TRAINING STATS: batch 136/486 in epoch 749,  batch loss: 1.67026, batch accuracy: 0.54250
Time: 2018-07-15 05:21:05
TRAINING STATS: batch 186/486 in epoch 749,  batch loss: 1.65617, batch accuracy: 0.55650
Time: 2018-07-15 05:21:08
TRAINING STATS: batch 236/486 in epoch 749,  batch loss: 1.67282, batch accuracy: 0.53850
Time: 2018-07-15 05:21:13
TRAINING STATS: batch 286/486 in epoch 749,  batch loss: 1.69432, batch accuracy: 0.53717
Time: 2018-07-15 05:21:17
TRAINING STATS: batch 336/486 in epoch 749,  batch loss: 1.63339, batch accuracy: 0.55833
Time: 2018-07-15 05:21:20
TRAINING STATS: batch 386/486 in epoch 749,  batch loss: 1.67362, batch accuracy: 0.53800
Time: 2018-07-15 05:21:25
TRAINING STATS: batch 436/486 in epoch 749,  batch loss: 1.66863, batch accuracy: 0.54767
Time: 2018-07-15 05:21:29
TRAINING STATS: batch 0/486 in epoch 750,    batch loss: 1.65498, batch accuracy: 0.55133
Time: 2018-07-15 05:21:32
TRAINING STATS: batch 50/486 in epoch 750,   batch loss: 1.60997, batch accuracy: 0.57050
Time: 2018-07-15 05:21:37
TRAINING STATS: batch 100/486 in epoch 750,  batch loss: 1.80874, batch accuracy: 0.51450
Time: 2018-07-15 05:21:41
TRAINING STATS: batch 150/486 in epoch 750,  batch loss: 1.71888, batch accuracy: 0.54450
Time: 2018-07-15 05:21:45
TRAINING STATS: batch 200/486 in epoch 750,  batch loss: 1.64877, batch accuracy: 0.56300
Time: 2018-07-15 05:21:49
TRAINING STATS: batch 250/486 in epoch 750,  batch loss: 1.81762, batch accuracy: 0.50150
Time: 2018-07-15 05:21:53
TRAINING STATS: batch 300/486 in epoch 750,  batch loss: 1.77103, batch accuracy: 0.51567
Time: 2018-07-15 05:21:56
TRAINING STATS: batch 350/486 in epoch 750,  batch loss: 1.74322, batch accuracy: 0.53150
Time: 2018-07-15 05:22:01
TRAINING STATS: batch 400/486 in epoch 750,  batch loss: 1.60187, batch accuracy: 0.56767
Time: 2018-07-15 05:22:05
TRAINING STATS: batch 450/486 in epoch 750,  batch loss: 1.78823, batch accuracy: 0.51200
Time: 2018-07-15 05:22:08
TRAINING STATS: batch 14/486 in epoch 751,   batch loss: 1.64720, batch accuracy: 0.55933
Time: 2018-07-15 05:22:13
TRAINING STATS: batch 64/486 in epoch 751,   batch loss: 1.83872, batch accuracy: 0.50100
Time: 2018-07-15 05:22:17
TRAINING STATS: batch 114/486 in epoch 751,  batch loss: 1.80475, batch accuracy: 0.51633
Time: 2018-07-15 05:22:21
TRAINING STATS: batch 164/486 in epoch 751,  batch loss: 1.65807, batch accuracy: 0.56150
Time: 2018-07-15 05:22:25
TRAINING STATS: batch 214/486 in epoch 751,  batch loss: 1.70818, batch accuracy: 0.54050
Time: 2018-07-15 05:22:29
TRAINING STATS: batch 264/486 in epoch 751,  batch loss: 1.74847, batch accuracy: 0.52767
Time: 2018-07-15 05:22:33
TRAINING STATS: batch 314/486 in epoch 751,  batch loss: 1.77408, batch accuracy: 0.51133
Time: 2018-07-15 05:22:37
TRAINING STATS: batch 364/486 in epoch 751,  batch loss: 1.75449, batch accuracy: 0.53100
Time: 2018-07-15 05:22:41
TRAINING STATS: batch 414/486 in epoch 751,  batch loss: 1.65320, batch accuracy: 0.55383
Time: 2018-07-15 05:22:45
TRAINING STATS: batch 464/486 in epoch 751,  batch loss: 1.67040, batch accuracy: 0.55217
Time: 2018-07-15 05:22:49
TRAINING STATS: batch 28/486 in epoch 752,   batch loss: 1.64804, batch accuracy: 0.56000
Time: 2018-07-15 05:22:53
TRAINING STATS: batch 78/486 in epoch 752,   batch loss: 1.71845, batch accuracy: 0.54433
Time: 2018-07-15 05:22:57
TRAINING STATS: batch 128/486 in epoch 752,  batch loss: 1.69706, batch accuracy: 0.54883
Time: 2018-07-15 05:23:01
TRAINING STATS: batch 178/486 in epoch 752,  batch loss: 1.59986, batch accuracy: 0.56633
Time: 2018-07-15 05:23:05
TRAINING STATS: batch 228/486 in epoch 752,  batch loss: 1.65148, batch accuracy: 0.54883
Time: 2018-07-15 05:23:09
TRAINING STATS: batch 278/486 in epoch 752,  batch loss: 1.65442, batch accuracy: 0.56250
Time: 2018-07-15 05:23:14
TRAINING STATS: batch 328/486 in epoch 752,  batch loss: 1.66544, batch accuracy: 0.55017
Time: 2018-07-15 05:23:17
TRAINING STATS: batch 378/486 in epoch 752,  batch loss: 1.69568, batch accuracy: 0.54633
Time: 2018-07-15 05:23:21
TRAINING STATS: batch 428/486 in epoch 752,  batch loss: 1.75324, batch accuracy: 0.52450
Time: 2018-07-15 05:23:26
TRAINING STATS: batch 478/486 in epoch 752,  batch loss: 1.70673, batch accuracy: 0.54233
Time: 2018-07-15 05:23:29
TRAINING STATS: batch 42/486 in epoch 753,   batch loss: 1.61128, batch accuracy: 0.56650
Time: 2018-07-15 05:23:33
TRAINING STATS: batch 92/486 in epoch 753,   batch loss: 1.72002, batch accuracy: 0.53717
Time: 2018-07-15 05:23:38
TRAINING STATS: batch 142/486 in epoch 753,  batch loss: 1.68166, batch accuracy: 0.54500
Time: 2018-07-15 05:23:41
TRAINING STATS: batch 192/486 in epoch 753,  batch loss: 1.71493, batch accuracy: 0.54067
Time: 2018-07-15 05:23:45
TRAINING STATS: batch 242/486 in epoch 753,  batch loss: 1.69857, batch accuracy: 0.54517
Time: 2018-07-15 05:23:50
TRAINING STATS: batch 292/486 in epoch 753,  batch loss: 1.67239, batch accuracy: 0.54950
Time: 2018-07-15 05:23:53
TRAINING STATS: batch 342/486 in epoch 753,  batch loss: 1.65791, batch accuracy: 0.54967
Time: 2018-07-15 05:23:57
TRAINING STATS: batch 392/486 in epoch 753,  batch loss: 1.62924, batch accuracy: 0.56750
Time: 2018-07-15 05:24:02
TRAINING STATS: batch 442/486 in epoch 753,  batch loss: 1.60842, batch accuracy: 0.57067
Time: 2018-07-15 05:24:06
TRAINING STATS: batch 6/486 in epoch 754,    batch loss: 1.73015, batch accuracy: 0.53933
Time: 2018-07-15 05:24:09
TRAINING STATS: batch 56/486 in epoch 754,   batch loss: 1.65022, batch accuracy: 0.55017
Time: 2018-07-15 05:24:14
TRAINING STATS: batch 106/486 in epoch 754,  batch loss: 1.78152, batch accuracy: 0.52317
Time: 2018-07-15 05:24:18
TRAINING STATS: batch 156/486 in epoch 754,  batch loss: 1.72067, batch accuracy: 0.53433
Time: 2018-07-15 05:24:21
TRAINING STATS: batch 206/486 in epoch 754,  batch loss: 1.78024, batch accuracy: 0.51033
Time: 2018-07-15 05:24:26
TRAINING STATS: batch 256/486 in epoch 754,  batch loss: 1.62591, batch accuracy: 0.56500
Time: 2018-07-15 05:24:30
TRAINING STATS: batch 306/486 in epoch 754,  batch loss: 1.68495, batch accuracy: 0.53783
Time: 2018-07-15 05:24:33
TRAINING STATS: batch 356/486 in epoch 754,  batch loss: 1.72963, batch accuracy: 0.53850
Time: 2018-07-15 05:24:38
TRAINING STATS: batch 406/486 in epoch 754,  batch loss: 1.75476, batch accuracy: 0.52717
Time: 2018-07-15 05:24:42
TRAINING STATS: batch 456/486 in epoch 754,  batch loss: 1.59097, batch accuracy: 0.57600
Time: 2018-07-15 05:24:45
TRAINING STATS: batch 20/486 in epoch 755,   batch loss: 1.69878, batch accuracy: 0.54650
Time: 2018-07-15 05:24:50
TRAINING STATS: batch 70/486 in epoch 755,   batch loss: 1.58632, batch accuracy: 0.58217
Time: 2018-07-15 05:24:54
TRAINING STATS: batch 120/486 in epoch 755,  batch loss: 1.62470, batch accuracy: 0.56083
Time: 2018-07-15 05:24:57
TRAINING STATS: batch 170/486 in epoch 755,  batch loss: 1.66505, batch accuracy: 0.55617
Time: 2018-07-15 05:25:02
TRAINING STATS: batch 220/486 in epoch 755,  batch loss: 1.62274, batch accuracy: 0.56767
Time: 2018-07-15 05:25:06
TRAINING STATS: batch 270/486 in epoch 755,  batch loss: 1.76828, batch accuracy: 0.51567
Time: 2018-07-15 05:25:10
TRAINING STATS: batch 320/486 in epoch 755,  batch loss: 1.66257, batch accuracy: 0.55183
Time: 2018-07-15 05:25:14
TRAINING STATS: batch 370/486 in epoch 755,  batch loss: 1.74863, batch accuracy: 0.53250
Time: 2018-07-15 05:25:18
TRAINING STATS: batch 420/486 in epoch 755,  batch loss: 1.73816, batch accuracy: 0.53850
Time: 2018-07-15 05:25:21
TRAINING STATS: batch 470/486 in epoch 755,  batch loss: 1.79514, batch accuracy: 0.51217
Time: 2018-07-15 05:25:26
TRAINING STATS: batch 34/486 in epoch 756,   batch loss: 1.71454, batch accuracy: 0.54567
Time: 2018-07-15 05:25:30
TRAINING STATS: batch 84/486 in epoch 756,   batch loss: 1.70990, batch accuracy: 0.53450
Time: 2018-07-15 05:25:34
TRAINING STATS: batch 134/486 in epoch 756,  batch loss: 1.71518, batch accuracy: 0.55000
Time: 2018-07-15 05:25:38
TRAINING STATS: batch 184/486 in epoch 756,  batch loss: 1.69019, batch accuracy: 0.54283
Time: 2018-07-15 05:25:42
TRAINING STATS: batch 234/486 in epoch 756,  batch loss: 1.78847, batch accuracy: 0.51750
Time: 2018-07-15 05:25:46
TRAINING STATS: batch 284/486 in epoch 756,  batch loss: 1.73853, batch accuracy: 0.53617
Time: 2018-07-15 05:25:51
TRAINING STATS: batch 334/486 in epoch 756,  batch loss: 1.66783, batch accuracy: 0.55167
Time: 2018-07-15 05:25:54
TRAINING STATS: batch 384/486 in epoch 756,  batch loss: 1.70915, batch accuracy: 0.53567
Time: 2018-07-15 05:25:58
TRAINING STATS: batch 434/486 in epoch 756,  batch loss: 1.75911, batch accuracy: 0.53217
Time: 2018-07-15 05:26:02
TRAINING STATS: batch 484/486 in epoch 756,  batch loss: 1.70365, batch accuracy: 0.53850
Time: 2018-07-15 05:26:06
TRAINING STATS: batch 48/486 in epoch 757,   batch loss: 1.69117, batch accuracy: 0.54583
Time: 2018-07-15 05:26:10
TRAINING STATS: batch 98/486 in epoch 757,   batch loss: 1.63322, batch accuracy: 0.56217
Time: 2018-07-15 05:26:15
TRAINING STATS: batch 148/486 in epoch 757,  batch loss: 1.72341, batch accuracy: 0.54650
Time: 2018-07-15 05:26:18
TRAINING STATS: batch 198/486 in epoch 757,  batch loss: 1.68277, batch accuracy: 0.54617
Time: 2018-07-15 05:26:22
TRAINING STATS: batch 248/486 in epoch 757,  batch loss: 1.72436, batch accuracy: 0.53983
Time: 2018-07-15 05:26:27
TRAINING STATS: batch 298/486 in epoch 757,  batch loss: 1.71513, batch accuracy: 0.53867
Time: 2018-07-15 05:26:30
TRAINING STATS: batch 348/486 in epoch 757,  batch loss: 1.70916, batch accuracy: 0.54750
Time: 2018-07-15 05:26:34
TRAINING STATS: batch 398/486 in epoch 757,  batch loss: 1.69159, batch accuracy: 0.54267
Time: 2018-07-15 05:26:39
TRAINING STATS: batch 448/486 in epoch 757,  batch loss: 1.69858, batch accuracy: 0.54883
Time: 2018-07-15 05:26:42
TRAINING STATS: batch 12/486 in epoch 758,   batch loss: 1.70630, batch accuracy: 0.53383
Time: 2018-07-15 05:26:46
TRAINING STATS: batch 62/486 in epoch 758,   batch loss: 1.76508, batch accuracy: 0.52550
Time: 2018-07-15 05:26:51
TRAINING STATS: batch 112/486 in epoch 758,  batch loss: 1.68187, batch accuracy: 0.54433
Time: 2018-07-15 05:26:54
TRAINING STATS: batch 162/486 in epoch 758,  batch loss: 1.70384, batch accuracy: 0.54200
Time: 2018-07-15 05:26:58
TRAINING STATS: batch 212/486 in epoch 758,  batch loss: 1.60816, batch accuracy: 0.56617
Time: 2018-07-15 05:27:03
TRAINING STATS: batch 262/486 in epoch 758,  batch loss: 1.73829, batch accuracy: 0.53800
Time: 2018-07-15 05:27:07
TRAINING STATS: batch 312/486 in epoch 758,  batch loss: 1.70964, batch accuracy: 0.53033
Time: 2018-07-15 05:27:10
TRAINING STATS: batch 362/486 in epoch 758,  batch loss: 1.70085, batch accuracy: 0.54567
Time: 2018-07-15 05:27:15
TRAINING STATS: batch 412/486 in epoch 758,  batch loss: 1.63717, batch accuracy: 0.56833
Time: 2018-07-15 05:27:19
TRAINING STATS: batch 462/486 in epoch 758,  batch loss: 1.73250, batch accuracy: 0.53467
Time: 2018-07-15 05:27:22
TRAINING STATS: batch 26/486 in epoch 759,   batch loss: 1.72134, batch accuracy: 0.54517
Time: 2018-07-15 05:27:27
TRAINING STATS: batch 76/486 in epoch 759,   batch loss: 1.74900, batch accuracy: 0.53300
Time: 2018-07-15 05:27:31
TRAINING STATS: batch 126/486 in epoch 759,  batch loss: 1.74139, batch accuracy: 0.53133
Time: 2018-07-15 05:27:34
TRAINING STATS: batch 176/486 in epoch 759,  batch loss: 1.61183, batch accuracy: 0.56917
Time: 2018-07-15 05:27:39
TRAINING STATS: batch 226/486 in epoch 759,  batch loss: 1.66990, batch accuracy: 0.55067
Time: 2018-07-15 05:27:43
TRAINING STATS: batch 276/486 in epoch 759,  batch loss: 1.67265, batch accuracy: 0.55083
Time: 2018-07-15 05:27:47
TRAINING STATS: batch 326/486 in epoch 759,  batch loss: 1.71734, batch accuracy: 0.53317
Time: 2018-07-15 05:27:51
TRAINING STATS: batch 376/486 in epoch 759,  batch loss: 1.70634, batch accuracy: 0.54100
Time: 2018-07-15 05:27:55
TRAINING STATS: batch 426/486 in epoch 759,  batch loss: 1.66914, batch accuracy: 0.55100
Time: 2018-07-15 05:27:58
TRAINING STATS: batch 476/486 in epoch 759,  batch loss: 1.62776, batch accuracy: 0.56467
Time: 2018-07-15 05:28:03
TRAINING STATS: batch 40/486 in epoch 760,   batch loss: 1.64914, batch accuracy: 0.55383
Time: 2018-07-15 05:28:07
TRAINING STATS: batch 90/486 in epoch 760,   batch loss: 1.73647, batch accuracy: 0.53433
Time: 2018-07-15 05:28:10
TRAINING STATS: batch 140/486 in epoch 760,  batch loss: 1.62571, batch accuracy: 0.56567
Time: 2018-07-15 05:28:15
TRAINING STATS: batch 190/486 in epoch 760,  batch loss: 1.66023, batch accuracy: 0.56133
Time: 2018-07-15 05:28:19
TRAINING STATS: batch 240/486 in epoch 760,  batch loss: 1.65548, batch accuracy: 0.55317
Time: 2018-07-15 05:28:23
TRAINING STATS: batch 290/486 in epoch 760,  batch loss: 1.69990, batch accuracy: 0.54233
Time: 2018-07-15 05:28:27
TRAINING STATS: batch 340/486 in epoch 760,  batch loss: 1.76233, batch accuracy: 0.52667
Time: 2018-07-15 05:28:31
TRAINING STATS: batch 390/486 in epoch 760,  batch loss: 1.63727, batch accuracy: 0.56617
Time: 2018-07-15 05:28:35
TRAINING STATS: batch 440/486 in epoch 760,  batch loss: 1.73347, batch accuracy: 0.52867
Time: 2018-07-15 05:28:39
TRAINING STATS: batch 4/486 in epoch 761,    batch loss: 1.62211, batch accuracy: 0.57183
Time: 2018-07-15 05:28:43
TRAINING STATS: batch 54/486 in epoch 761,   batch loss: 1.69543, batch accuracy: 0.54633
Time: 2018-07-15 05:28:47
TRAINING STATS: batch 104/486 in epoch 761,  batch loss: 1.69408, batch accuracy: 0.54667
Time: 2018-07-15 05:28:51
TRAINING STATS: batch 154/486 in epoch 761,  batch loss: 1.66757, batch accuracy: 0.55167
Time: 2018-07-15 05:28:55
TRAINING STATS: batch 204/486 in epoch 761,  batch loss: 1.74178, batch accuracy: 0.54100
Time: 2018-07-15 05:28:59
TRAINING STATS: batch 254/486 in epoch 761,  batch loss: 1.60336, batch accuracy: 0.56833
Time: 2018-07-15 05:29:03
TRAINING STATS: batch 304/486 in epoch 761,  batch loss: 1.63669, batch accuracy: 0.55767
Time: 2018-07-15 05:29:07
TRAINING STATS: batch 354/486 in epoch 761,  batch loss: 1.68830, batch accuracy: 0.54750
Time: 2018-07-15 05:29:11
TRAINING STATS: batch 404/486 in epoch 761,  batch loss: 1.66503, batch accuracy: 0.55083
Time: 2018-07-15 05:29:16
TRAINING STATS: batch 454/486 in epoch 761,  batch loss: 1.55195, batch accuracy: 0.58517
Time: 2018-07-15 05:29:19
TRAINING STATS: batch 18/486 in epoch 762,   batch loss: 1.70190, batch accuracy: 0.54867
Time: 2018-07-15 05:29:23
TRAINING STATS: batch 68/486 in epoch 762,   batch loss: 1.51320, batch accuracy: 0.60250
Time: 2018-07-15 05:29:28
TRAINING STATS: batch 118/486 in epoch 762,  batch loss: 1.66116, batch accuracy: 0.55133
Time: 2018-07-15 05:29:31
TRAINING STATS: batch 168/486 in epoch 762,  batch loss: 1.59048, batch accuracy: 0.57883
Time: 2018-07-15 05:29:35
TRAINING STATS: batch 218/486 in epoch 762,  batch loss: 1.64533, batch accuracy: 0.55550
Time: 2018-07-15 05:29:40
TRAINING STATS: batch 268/486 in epoch 762,  batch loss: 1.61088, batch accuracy: 0.56400
Time: 2018-07-15 05:29:43
TRAINING STATS: batch 318/486 in epoch 762,  batch loss: 1.65365, batch accuracy: 0.55783
Time: 2018-07-15 05:29:47
TRAINING STATS: batch 368/486 in epoch 762,  batch loss: 1.68950, batch accuracy: 0.54867
Time: 2018-07-15 05:29:52
TRAINING STATS: batch 418/486 in epoch 762,  batch loss: 1.72764, batch accuracy: 0.52917
Time: 2018-07-15 05:29:55
TRAINING STATS: batch 468/486 in epoch 762,  batch loss: 1.66055, batch accuracy: 0.55417
Time: 2018-07-15 05:29:59
TRAINING STATS: batch 32/486 in epoch 763,   batch loss: 1.62608, batch accuracy: 0.56033
Time: 2018-07-15 05:30:04
TRAINING STATS: batch 82/486 in epoch 763,   batch loss: 1.69816, batch accuracy: 0.54583
Time: 2018-07-15 05:30:07
TRAINING STATS: batch 132/486 in epoch 763,  batch loss: 1.64754, batch accuracy: 0.56533
Time: 2018-07-15 05:30:11
TRAINING STATS: batch 182/486 in epoch 763,  batch loss: 1.71145, batch accuracy: 0.53983
Time: 2018-07-15 05:30:16
TRAINING STATS: batch 232/486 in epoch 763,  batch loss: 1.69819, batch accuracy: 0.55033
Time: 2018-07-15 05:30:20
TRAINING STATS: batch 282/486 in epoch 763,  batch loss: 1.61448, batch accuracy: 0.56267
Time: 2018-07-15 05:30:23
TRAINING STATS: batch 332/486 in epoch 763,  batch loss: 1.70635, batch accuracy: 0.54350
Time: 2018-07-15 05:30:28
TRAINING STATS: batch 382/486 in epoch 763,  batch loss: 1.68412, batch accuracy: 0.54983
Time: 2018-07-15 05:30:32
TRAINING STATS: batch 432/486 in epoch 763,  batch loss: 1.57848, batch accuracy: 0.57150
Time: 2018-07-15 05:30:35
TRAINING STATS: batch 482/486 in epoch 763,  batch loss: 1.64401, batch accuracy: 0.56267
Time: 2018-07-15 05:30:40
TRAINING STATS: batch 46/486 in epoch 764,   batch loss: 1.64755, batch accuracy: 0.56350
Time: 2018-07-15 05:30:44
TRAINING STATS: batch 96/486 in epoch 764,   batch loss: 1.69914, batch accuracy: 0.54550
Time: 2018-07-15 05:30:47
TRAINING STATS: batch 146/486 in epoch 764,  batch loss: 1.70998, batch accuracy: 0.54300
Time: 2018-07-15 05:30:52
TRAINING STATS: batch 196/486 in epoch 764,  batch loss: 1.69469, batch accuracy: 0.53967
Time: 2018-07-15 05:30:56
TRAINING STATS: batch 246/486 in epoch 764,  batch loss: 1.62107, batch accuracy: 0.56550
Time: 2018-07-15 05:30:59
TRAINING STATS: batch 296/486 in epoch 764,  batch loss: 1.62858, batch accuracy: 0.56433
Time: 2018-07-15 05:31:04
TRAINING STATS: batch 346/486 in epoch 764,  batch loss: 1.55517, batch accuracy: 0.58367
Time: 2018-07-15 05:31:08
TRAINING STATS: batch 396/486 in epoch 764,  batch loss: 1.63041, batch accuracy: 0.56617
Time: 2018-07-15 05:31:12
TRAINING STATS: batch 446/486 in epoch 764,  batch loss: 1.66364, batch accuracy: 0.55183
Time: 2018-07-15 05:31:16
TRAINING STATS: batch 10/486 in epoch 765,   batch loss: 1.69458, batch accuracy: 0.54267
Time: 2018-07-15 05:31:20
TRAINING STATS: batch 60/486 in epoch 765,   batch loss: 1.64661, batch accuracy: 0.56083
Time: 2018-07-15 05:31:24
TRAINING STATS: batch 110/486 in epoch 765,  batch loss: 1.69892, batch accuracy: 0.54617
Time: 2018-07-15 05:31:28
TRAINING STATS: batch 160/486 in epoch 765,  batch loss: 1.62196, batch accuracy: 0.56050
Time: 2018-07-15 05:31:32
TRAINING STATS: batch 210/486 in epoch 765,  batch loss: 1.59614, batch accuracy: 0.56900
Time: 2018-07-15 05:31:36
TRAINING STATS: batch 260/486 in epoch 765,  batch loss: 1.68272, batch accuracy: 0.54133
Time: 2018-07-15 05:31:40
TRAINING STATS: batch 310/486 in epoch 765,  batch loss: 1.65384, batch accuracy: 0.55517
Time: 2018-07-15 05:31:44
TRAINING STATS: batch 360/486 in epoch 765,  batch loss: 1.76874, batch accuracy: 0.52033
Time: 2018-07-15 05:31:48
TRAINING STATS: batch 410/486 in epoch 765,  batch loss: 1.62994, batch accuracy: 0.56300
Time: 2018-07-15 05:31:52
TRAINING STATS: batch 460/486 in epoch 765,  batch loss: 1.78148, batch accuracy: 0.51017
Time: 2018-07-15 05:31:56
TRAINING STATS: batch 24/486 in epoch 766,   batch loss: 1.71405, batch accuracy: 0.54417
Time: 2018-07-15 05:32:00
TRAINING STATS: batch 74/486 in epoch 766,   batch loss: 1.66964, batch accuracy: 0.55533
Time: 2018-07-15 05:32:04
TRAINING STATS: batch 124/486 in epoch 766,  batch loss: 1.67208, batch accuracy: 0.56017
Time: 2018-07-15 05:32:08
TRAINING STATS: batch 174/486 in epoch 766,  batch loss: 1.70858, batch accuracy: 0.54433
Time: 2018-07-15 05:32:12
TRAINING STATS: batch 224/486 in epoch 766,  batch loss: 1.70047, batch accuracy: 0.54567
Time: 2018-07-15 05:32:17
TRAINING STATS: batch 274/486 in epoch 766,  batch loss: 1.66392, batch accuracy: 0.55033
Time: 2018-07-15 05:32:20
TRAINING STATS: batch 324/486 in epoch 766,  batch loss: 1.81814, batch accuracy: 0.51150
Time: 2018-07-15 05:32:24
TRAINING STATS: batch 374/486 in epoch 766,  batch loss: 1.71970, batch accuracy: 0.53633
Time: 2018-07-15 05:32:29
TRAINING STATS: batch 424/486 in epoch 766,  batch loss: 1.61243, batch accuracy: 0.57350
Time: 2018-07-15 05:32:32
TRAINING STATS: batch 474/486 in epoch 766,  batch loss: 1.65403, batch accuracy: 0.55950
Time: 2018-07-15 05:32:36
TRAINING STATS: batch 38/486 in epoch 767,   batch loss: 1.68360, batch accuracy: 0.54933
Time: 2018-07-15 05:32:41
TRAINING STATS: batch 88/486 in epoch 767,   batch loss: 1.68717, batch accuracy: 0.54283
Time: 2018-07-15 05:32:44
TRAINING STATS: batch 138/486 in epoch 767,  batch loss: 1.68807, batch accuracy: 0.54833
Time: 2018-07-15 05:32:48
TRAINING STATS: batch 188/486 in epoch 767,  batch loss: 1.60913, batch accuracy: 0.57433
Time: 2018-07-15 05:32:53
TRAINING STATS: batch 238/486 in epoch 767,  batch loss: 1.61976, batch accuracy: 0.57250
Time: 2018-07-15 05:32:56
TRAINING STATS: batch 288/486 in epoch 767,  batch loss: 1.66195, batch accuracy: 0.55283
Time: 2018-07-15 05:33:00
TRAINING STATS: batch 338/486 in epoch 767,  batch loss: 1.71654, batch accuracy: 0.53400
Time: 2018-07-15 05:33:05
TRAINING STATS: batch 388/486 in epoch 767,  batch loss: 1.64199, batch accuracy: 0.55617
Time: 2018-07-15 05:33:08
TRAINING STATS: batch 438/486 in epoch 767,  batch loss: 1.68497, batch accuracy: 0.55083
Time: 2018-07-15 05:33:12
TRAINING STATS: batch 2/486 in epoch 768,    batch loss: 1.65837, batch accuracy: 0.55350
Time: 2018-07-15 05:33:17
TRAINING STATS: batch 52/486 in epoch 768,   batch loss: 1.71479, batch accuracy: 0.53517
Time: 2018-07-15 05:33:20
TRAINING STATS: batch 102/486 in epoch 768,  batch loss: 1.66841, batch accuracy: 0.55850
Time: 2018-07-15 05:33:24
TRAINING STATS: batch 152/486 in epoch 768,  batch loss: 1.61888, batch accuracy: 0.57000
Time: 2018-07-15 05:33:29
TRAINING STATS: batch 202/486 in epoch 768,  batch loss: 1.64827, batch accuracy: 0.56250
Time: 2018-07-15 05:33:32
TRAINING STATS: batch 252/486 in epoch 768,  batch loss: 1.63684, batch accuracy: 0.56600
Time: 2018-07-15 05:33:36
TRAINING STATS: batch 302/486 in epoch 768,  batch loss: 1.59822, batch accuracy: 0.56833
Time: 2018-07-15 05:33:41
TRAINING STATS: batch 352/486 in epoch 768,  batch loss: 1.65139, batch accuracy: 0.55350
Time: 2018-07-15 05:33:45
TRAINING STATS: batch 402/486 in epoch 768,  batch loss: 1.51211, batch accuracy: 0.60150
Time: 2018-07-15 05:33:48
TRAINING STATS: batch 452/486 in epoch 768,  batch loss: 1.63566, batch accuracy: 0.55900
Time: 2018-07-15 05:33:53
TRAINING STATS: batch 16/486 in epoch 769,   batch loss: 1.61339, batch accuracy: 0.56817
Time: 2018-07-15 05:33:57
TRAINING STATS: batch 66/486 in epoch 769,   batch loss: 1.63138, batch accuracy: 0.56500
Time: 2018-07-15 05:34:00
TRAINING STATS: batch 116/486 in epoch 769,  batch loss: 1.60454, batch accuracy: 0.56600
Time: 2018-07-15 05:34:05
TRAINING STATS: batch 166/486 in epoch 769,  batch loss: 1.54778, batch accuracy: 0.58750
Time: 2018-07-15 05:34:09
TRAINING STATS: batch 216/486 in epoch 769,  batch loss: 1.65913, batch accuracy: 0.55983
Time: 2018-07-15 05:34:12
TRAINING STATS: batch 266/486 in epoch 769,  batch loss: 1.66828, batch accuracy: 0.54983
Time: 2018-07-15 05:34:17
TRAINING STATS: batch 316/486 in epoch 769,  batch loss: 1.65396, batch accuracy: 0.55500
Time: 2018-07-15 05:34:21
TRAINING STATS: batch 366/486 in epoch 769,  batch loss: 1.71059, batch accuracy: 0.54733
Time: 2018-07-15 05:34:24
TRAINING STATS: batch 416/486 in epoch 769,  batch loss: 1.66774, batch accuracy: 0.54583
Time: 2018-07-15 05:34:29
TRAINING STATS: batch 466/486 in epoch 769,  batch loss: 1.51027, batch accuracy: 0.60017
Time: 2018-07-15 05:34:33
TRAINING STATS: batch 30/486 in epoch 770,   batch loss: 1.54539, batch accuracy: 0.58583
Time: 2018-07-15 05:34:37
TRAINING STATS: batch 80/486 in epoch 770,   batch loss: 1.63480, batch accuracy: 0.55500
Time: 2018-07-15 05:34:41
TRAINING STATS: batch 130/486 in epoch 770,  batch loss: 1.61738, batch accuracy: 0.57167
Time: 2018-07-15 05:34:45
TRAINING STATS: batch 180/486 in epoch 770,  batch loss: 1.67126, batch accuracy: 0.55233
Time: 2018-07-15 05:34:48
TRAINING STATS: batch 230/486 in epoch 770,  batch loss: 1.65314, batch accuracy: 0.55317
Time: 2018-07-15 05:34:53
TRAINING STATS: batch 280/486 in epoch 770,  batch loss: 1.62869, batch accuracy: 0.55833
Time: 2018-07-15 05:34:57
TRAINING STATS: batch 330/486 in epoch 770,  batch loss: 1.62052, batch accuracy: 0.55867
Time: 2018-07-15 05:35:01
TRAINING STATS: batch 380/486 in epoch 770,  batch loss: 1.61162, batch accuracy: 0.57233
Time: 2018-07-15 05:35:05
TRAINING STATS: batch 430/486 in epoch 770,  batch loss: 1.59074, batch accuracy: 0.57933
Time: 2018-07-15 05:35:09
TRAINING STATS: batch 480/486 in epoch 770,  batch loss: 1.64619, batch accuracy: 0.55267
Time: 2018-07-15 05:35:13
TRAINING STATS: batch 44/486 in epoch 771,   batch loss: 1.57465, batch accuracy: 0.58133
Time: 2018-07-15 05:35:17
TRAINING STATS: batch 94/486 in epoch 771,   batch loss: 1.68292, batch accuracy: 0.54850
Time: 2018-07-15 05:35:21
TRAINING STATS: batch 144/486 in epoch 771,  batch loss: 1.71073, batch accuracy: 0.53650
Time: 2018-07-15 05:35:25
TRAINING STATS: batch 194/486 in epoch 771,  batch loss: 1.73725, batch accuracy: 0.52783
Time: 2018-07-15 05:35:29
TRAINING STATS: batch 244/486 in epoch 771,  batch loss: 1.63806, batch accuracy: 0.56067
Time: 2018-07-15 05:35:33
TRAINING STATS: batch 294/486 in epoch 771,  batch loss: 1.56182, batch accuracy: 0.58067
Time: 2018-07-15 05:35:37
TRAINING STATS: batch 344/486 in epoch 771,  batch loss: 1.61321, batch accuracy: 0.56600
Time: 2018-07-15 05:35:41
TRAINING STATS: batch 394/486 in epoch 771,  batch loss: 1.63678, batch accuracy: 0.56217
Time: 2018-07-15 05:35:45
TRAINING STATS: batch 444/486 in epoch 771,  batch loss: 1.60876, batch accuracy: 0.56783
Time: 2018-07-15 05:35:49
TRAINING STATS: batch 8/486 in epoch 772,    batch loss: 1.65211, batch accuracy: 0.55767
Time: 2018-07-15 05:35:53
TRAINING STATS: batch 58/486 in epoch 772,   batch loss: 1.61628, batch accuracy: 0.57150
Time: 2018-07-15 05:35:57
TRAINING STATS: batch 108/486 in epoch 772,  batch loss: 1.70056, batch accuracy: 0.54650
Time: 2018-07-15 05:36:01
TRAINING STATS: batch 158/486 in epoch 772,  batch loss: 1.68346, batch accuracy: 0.54717
Time: 2018-07-15 05:36:05
TRAINING STATS: batch 208/486 in epoch 772,  batch loss: 1.66172, batch accuracy: 0.55383
Time: 2018-07-15 05:36:09
TRAINING STATS: batch 258/486 in epoch 772,  batch loss: 1.59318, batch accuracy: 0.57633
Time: 2018-07-15 05:36:13
TRAINING STATS: batch 308/486 in epoch 772,  batch loss: 1.64534, batch accuracy: 0.56100
Time: 2018-07-15 05:36:17
TRAINING STATS: batch 358/486 in epoch 772,  batch loss: 1.65872, batch accuracy: 0.55700
Time: 2018-07-15 05:36:21
TRAINING STATS: batch 408/486 in epoch 772,  batch loss: 1.68108, batch accuracy: 0.55017
Time: 2018-07-15 05:36:25
TRAINING STATS: batch 458/486 in epoch 772,  batch loss: 1.66353, batch accuracy: 0.55483
Time: 2018-07-15 05:36:30
TRAINING STATS: batch 22/486 in epoch 773,   batch loss: 1.67763, batch accuracy: 0.55817
Time: 2018-07-15 05:36:33
TRAINING STATS: batch 72/486 in epoch 773,   batch loss: 1.66750, batch accuracy: 0.54167
Time: 2018-07-15 05:36:37
TRAINING STATS: batch 122/486 in epoch 773,  batch loss: 1.70924, batch accuracy: 0.54233
Time: 2018-07-15 05:36:42
TRAINING STATS: batch 172/486 in epoch 773,  batch loss: 1.69649, batch accuracy: 0.54433
Time: 2018-07-15 05:36:45
TRAINING STATS: batch 222/486 in epoch 773,  batch loss: 1.64357, batch accuracy: 0.55800
Time: 2018-07-15 05:36:49
TRAINING STATS: batch 272/486 in epoch 773,  batch loss: 1.67770, batch accuracy: 0.54367
Time: 2018-07-15 05:36:54
TRAINING STATS: batch 322/486 in epoch 773,  batch loss: 1.64104, batch accuracy: 0.55383
Time: 2018-07-15 05:36:57
TRAINING STATS: batch 372/486 in epoch 773,  batch loss: 1.57520, batch accuracy: 0.57650
Time: 2018-07-15 05:37:01
TRAINING STATS: batch 422/486 in epoch 773,  batch loss: 1.65321, batch accuracy: 0.55117
Time: 2018-07-15 05:37:06
TRAINING STATS: batch 472/486 in epoch 773,  batch loss: 1.71566, batch accuracy: 0.54083
Time: 2018-07-15 05:37:09
TRAINING STATS: batch 36/486 in epoch 774,   batch loss: 1.70268, batch accuracy: 0.54200
Time: 2018-07-15 05:37:13
TRAINING STATS: batch 86/486 in epoch 774,   batch loss: 1.65786, batch accuracy: 0.55783
Time: 2018-07-15 05:37:18
TRAINING STATS: batch 136/486 in epoch 774,  batch loss: 1.69364, batch accuracy: 0.54300
Time: 2018-07-15 05:37:22
TRAINING STATS: batch 186/486 in epoch 774,  batch loss: 1.66265, batch accuracy: 0.55933
Time: 2018-07-15 05:37:25
TRAINING STATS: batch 236/486 in epoch 774,  batch loss: 1.67582, batch accuracy: 0.54383
Time: 2018-07-15 05:37:30
TRAINING STATS: batch 286/486 in epoch 774,  batch loss: 1.68115, batch accuracy: 0.54667
Time: 2018-07-15 05:37:34
TRAINING STATS: batch 336/486 in epoch 774,  batch loss: 1.63335, batch accuracy: 0.56417
Time: 2018-07-15 05:37:37
TRAINING STATS: batch 386/486 in epoch 774,  batch loss: 1.69446, batch accuracy: 0.54000
Time: 2018-07-15 05:37:42
TRAINING STATS: batch 436/486 in epoch 774,  batch loss: 1.65989, batch accuracy: 0.55700
Time: 2018-07-15 05:37:46
TRAINING STATS: batch 0/486 in epoch 775,    batch loss: 1.62904, batch accuracy: 0.55833
Time: 2018-07-15 05:37:49
TRAINING STATS: batch 50/486 in epoch 775,   batch loss: 1.61504, batch accuracy: 0.56633
Time: 2018-07-15 05:37:54
TRAINING STATS: batch 100/486 in epoch 775,  batch loss: 1.67423, batch accuracy: 0.55467
Time: 2018-07-15 05:37:58
TRAINING STATS: batch 150/486 in epoch 775,  batch loss: 1.59856, batch accuracy: 0.57167
Time: 2018-07-15 05:38:01
TRAINING STATS: batch 200/486 in epoch 775,  batch loss: 1.51418, batch accuracy: 0.59700
Time: 2018-07-15 05:38:06
TRAINING STATS: batch 250/486 in epoch 775,  batch loss: 1.75314, batch accuracy: 0.52583
Time: 2018-07-15 05:38:10
TRAINING STATS: batch 300/486 in epoch 775,  batch loss: 1.68607, batch accuracy: 0.54283
Time: 2018-07-15 05:38:13
TRAINING STATS: batch 350/486 in epoch 775,  batch loss: 1.65445, batch accuracy: 0.55683
Time: 2018-07-15 05:38:18
TRAINING STATS: batch 400/486 in epoch 775,  batch loss: 1.52912, batch accuracy: 0.58767
Time: 2018-07-15 05:38:22
TRAINING STATS: batch 450/486 in epoch 775,  batch loss: 1.70134, batch accuracy: 0.53450
Time: 2018-07-15 05:38:26
TRAINING STATS: batch 14/486 in epoch 776,   batch loss: 1.55114, batch accuracy: 0.59200
Time: 2018-07-15 05:38:30
TRAINING STATS: batch 64/486 in epoch 776,   batch loss: 1.74515, batch accuracy: 0.52917
Time: 2018-07-15 05:38:34
TRAINING STATS: batch 114/486 in epoch 776,  batch loss: 1.67660, batch accuracy: 0.55083
Time: 2018-07-15 05:38:38
TRAINING STATS: batch 164/486 in epoch 776,  batch loss: 1.57569, batch accuracy: 0.58150
Time: 2018-07-15 05:38:42
TRAINING STATS: batch 214/486 in epoch 776,  batch loss: 1.62679, batch accuracy: 0.56300
Time: 2018-07-15 05:38:46
TRAINING STATS: batch 264/486 in epoch 776,  batch loss: 1.68693, batch accuracy: 0.54700
Time: 2018-07-15 05:38:50
TRAINING STATS: batch 314/486 in epoch 776,  batch loss: 1.69972, batch accuracy: 0.53217
Time: 2018-07-15 05:38:54
TRAINING STATS: batch 364/486 in epoch 776,  batch loss: 1.66876, batch accuracy: 0.55167
Time: 2018-07-15 05:38:58
TRAINING STATS: batch 414/486 in epoch 776,  batch loss: 1.62261, batch accuracy: 0.55850
Time: 2018-07-15 05:39:02
TRAINING STATS: batch 464/486 in epoch 776,  batch loss: 1.62394, batch accuracy: 0.56783
Time: 2018-07-15 05:39:06
TRAINING STATS: batch 28/486 in epoch 777,   batch loss: 1.57631, batch accuracy: 0.58483
Time: 2018-07-15 05:39:10
TRAINING STATS: batch 78/486 in epoch 777,   batch loss: 1.64062, batch accuracy: 0.56350
Time: 2018-07-15 05:39:14
TRAINING STATS: batch 128/486 in epoch 777,  batch loss: 1.63664, batch accuracy: 0.56017
Time: 2018-07-15 05:39:18
TRAINING STATS: batch 178/486 in epoch 777,  batch loss: 1.52392, batch accuracy: 0.58483
Time: 2018-07-15 05:39:22
TRAINING STATS: batch 228/486 in epoch 777,  batch loss: 1.57967, batch accuracy: 0.57833
Time: 2018-07-15 05:39:26
TRAINING STATS: batch 278/486 in epoch 777,  batch loss: 1.57445, batch accuracy: 0.57950
Time: 2018-07-15 05:39:30
TRAINING STATS: batch 328/486 in epoch 777,  batch loss: 1.60925, batch accuracy: 0.56567
Time: 2018-07-15 05:39:34
TRAINING STATS: batch 378/486 in epoch 777,  batch loss: 1.63157, batch accuracy: 0.56117
Time: 2018-07-15 05:39:38
TRAINING STATS: batch 428/486 in epoch 777,  batch loss: 1.67063, batch accuracy: 0.54900
Time: 2018-07-15 05:39:42
TRAINING STATS: batch 478/486 in epoch 777,  batch loss: 1.64887, batch accuracy: 0.55067
Time: 2018-07-15 05:39:46
TRAINING STATS: batch 42/486 in epoch 778,   batch loss: 1.54182, batch accuracy: 0.58333
Time: 2018-07-15 05:39:50
TRAINING STATS: batch 92/486 in epoch 778,   batch loss: 1.65558, batch accuracy: 0.55450
Time: 2018-07-15 05:39:55
TRAINING STATS: batch 142/486 in epoch 778,  batch loss: 1.60085, batch accuracy: 0.57033
Time: 2018-07-15 05:39:58
TRAINING STATS: batch 192/486 in epoch 778,  batch loss: 1.66309, batch accuracy: 0.54417
Time: 2018-07-15 05:40:02
TRAINING STATS: batch 242/486 in epoch 778,  batch loss: 1.60296, batch accuracy: 0.56600
Time: 2018-07-15 05:40:07
TRAINING STATS: batch 292/486 in epoch 778,  batch loss: 1.62456, batch accuracy: 0.55750
Time: 2018-07-15 05:40:10
TRAINING STATS: batch 342/486 in epoch 778,  batch loss: 1.58998, batch accuracy: 0.57033
Time: 2018-07-15 05:40:14
TRAINING STATS: batch 392/486 in epoch 778,  batch loss: 1.55669, batch accuracy: 0.58317
Time: 2018-07-15 05:40:19
TRAINING STATS: batch 442/486 in epoch 778,  batch loss: 1.55538, batch accuracy: 0.57967
Time: 2018-07-15 05:40:22
TRAINING STATS: batch 6/486 in epoch 779,    batch loss: 1.67767, batch accuracy: 0.55633
Time: 2018-07-15 05:40:26
TRAINING STATS: batch 56/486 in epoch 779,   batch loss: 1.59459, batch accuracy: 0.56167
Time: 2018-07-15 05:40:31
TRAINING STATS: batch 106/486 in epoch 779,  batch loss: 1.68988, batch accuracy: 0.54633
Time: 2018-07-15 05:40:34
TRAINING STATS: batch 156/486 in epoch 779,  batch loss: 1.70794, batch accuracy: 0.53267
Time: 2018-07-15 05:40:38
TRAINING STATS: batch 206/486 in epoch 779,  batch loss: 1.70871, batch accuracy: 0.53767
Time: 2018-07-15 05:40:43
TRAINING STATS: batch 256/486 in epoch 779,  batch loss: 1.58232, batch accuracy: 0.57117
Time: 2018-07-15 05:40:46
TRAINING STATS: batch 306/486 in epoch 779,  batch loss: 1.65604, batch accuracy: 0.56133
Time: 2018-07-15 05:40:50
TRAINING STATS: batch 356/486 in epoch 779,  batch loss: 1.67530, batch accuracy: 0.54650
Time: 2018-07-15 05:40:55
TRAINING STATS: batch 406/486 in epoch 779,  batch loss: 1.69850, batch accuracy: 0.53700
Time: 2018-07-15 05:40:58
TRAINING STATS: batch 456/486 in epoch 779,  batch loss: 1.51469, batch accuracy: 0.59567
Time: 2018-07-15 05:41:02
TRAINING STATS: batch 20/486 in epoch 780,   batch loss: 1.64721, batch accuracy: 0.56450
Time: 2018-07-15 05:41:07
TRAINING STATS: batch 70/486 in epoch 780,   batch loss: 1.52472, batch accuracy: 0.59350
Time: 2018-07-15 05:41:11
TRAINING STATS: batch 120/486 in epoch 780,  batch loss: 1.57265, batch accuracy: 0.57283
Time: 2018-07-15 05:41:14
TRAINING STATS: batch 170/486 in epoch 780,  batch loss: 1.61462, batch accuracy: 0.56767
Time: 2018-07-15 05:41:19
TRAINING STATS: batch 220/486 in epoch 780,  batch loss: 1.55149, batch accuracy: 0.58917
Time: 2018-07-15 05:41:23
TRAINING STATS: batch 270/486 in epoch 780,  batch loss: 1.64627, batch accuracy: 0.54600
Time: 2018-07-15 05:41:26
TRAINING STATS: batch 320/486 in epoch 780,  batch loss: 1.58811, batch accuracy: 0.56517
Time: 2018-07-15 05:41:31
TRAINING STATS: batch 370/486 in epoch 780,  batch loss: 1.63994, batch accuracy: 0.56583
Time: 2018-07-15 05:41:35
TRAINING STATS: batch 420/486 in epoch 780,  batch loss: 1.66754, batch accuracy: 0.55267
Time: 2018-07-15 05:41:38
TRAINING STATS: batch 470/486 in epoch 780,  batch loss: 1.73007, batch accuracy: 0.52667
Time: 2018-07-15 05:41:43
TRAINING STATS: batch 34/486 in epoch 781,   batch loss: 1.65983, batch accuracy: 0.55417
Time: 2018-07-15 05:41:47
TRAINING STATS: batch 84/486 in epoch 781,   batch loss: 1.63149, batch accuracy: 0.54983
Time: 2018-07-15 05:41:50
TRAINING STATS: batch 134/486 in epoch 781,  batch loss: 1.67084, batch accuracy: 0.55717
Time: 2018-07-15 05:41:55
TRAINING STATS: batch 184/486 in epoch 781,  batch loss: 1.63604, batch accuracy: 0.55900
Time: 2018-07-15 05:41:59
TRAINING STATS: batch 234/486 in epoch 781,  batch loss: 1.72073, batch accuracy: 0.54000
Time: 2018-07-15 05:42:03
TRAINING STATS: batch 284/486 in epoch 781,  batch loss: 1.67747, batch accuracy: 0.54800
Time: 2018-07-15 05:42:07
TRAINING STATS: batch 334/486 in epoch 781,  batch loss: 1.62032, batch accuracy: 0.56517
Time: 2018-07-15 05:42:11
TRAINING STATS: batch 384/486 in epoch 781,  batch loss: 1.60434, batch accuracy: 0.56733
Time: 2018-07-15 05:42:15
TRAINING STATS: batch 434/486 in epoch 781,  batch loss: 1.68210, batch accuracy: 0.54033
Time: 2018-07-15 05:42:19
TRAINING STATS: batch 484/486 in epoch 781,  batch loss: 1.63788, batch accuracy: 0.55750
Time: 2018-07-15 05:42:23
TRAINING STATS: batch 48/486 in epoch 782,   batch loss: 1.64552, batch accuracy: 0.55483
Time: 2018-07-15 05:42:27
TRAINING STATS: batch 98/486 in epoch 782,   batch loss: 1.58705, batch accuracy: 0.57300
Time: 2018-07-15 05:42:31
TRAINING STATS: batch 148/486 in epoch 782,  batch loss: 1.65964, batch accuracy: 0.55750
Time: 2018-07-15 05:42:35
TRAINING STATS: batch 198/486 in epoch 782,  batch loss: 1.62888, batch accuracy: 0.56000
Time: 2018-07-15 05:42:39
TRAINING STATS: batch 248/486 in epoch 782,  batch loss: 1.65524, batch accuracy: 0.55567
Time: 2018-07-15 05:42:43
TRAINING STATS: batch 298/486 in epoch 782,  batch loss: 1.71405, batch accuracy: 0.53767
Time: 2018-07-15 05:42:47
TRAINING STATS: batch 348/486 in epoch 782,  batch loss: 1.62814, batch accuracy: 0.55800
Time: 2018-07-15 05:42:51
TRAINING STATS: batch 398/486 in epoch 782,  batch loss: 1.63264, batch accuracy: 0.56083
Time: 2018-07-15 05:42:55
TRAINING STATS: batch 448/486 in epoch 782,  batch loss: 1.65268, batch accuracy: 0.56267
Time: 2018-07-15 05:42:59
TRAINING STATS: batch 12/486 in epoch 783,   batch loss: 1.65876, batch accuracy: 0.55200
Time: 2018-07-15 05:43:03
TRAINING STATS: batch 62/486 in epoch 783,   batch loss: 1.71050, batch accuracy: 0.53250
Time: 2018-07-15 05:43:08
TRAINING STATS: batch 112/486 in epoch 783,  batch loss: 1.63905, batch accuracy: 0.55183
Time: 2018-07-15 05:43:11
TRAINING STATS: batch 162/486 in epoch 783,  batch loss: 1.64154, batch accuracy: 0.56300
Time: 2018-07-15 05:43:15
TRAINING STATS: batch 212/486 in epoch 783,  batch loss: 1.55967, batch accuracy: 0.57767
Time: 2018-07-15 05:43:20
TRAINING STATS: batch 262/486 in epoch 783,  batch loss: 1.70485, batch accuracy: 0.53733
Time: 2018-07-15 05:43:23
TRAINING STATS: batch 312/486 in epoch 783,  batch loss: 1.65021, batch accuracy: 0.54150
Time: 2018-07-15 05:43:27
TRAINING STATS: batch 362/486 in epoch 783,  batch loss: 1.63912, batch accuracy: 0.55300
Time: 2018-07-15 05:43:32
TRAINING STATS: batch 412/486 in epoch 783,  batch loss: 1.59041, batch accuracy: 0.56967
Time: 2018-07-15 05:43:35
TRAINING STATS: batch 462/486 in epoch 783,  batch loss: 1.65427, batch accuracy: 0.55633
Time: 2018-07-15 05:43:39
TRAINING STATS: batch 26/486 in epoch 784,   batch loss: 1.69422, batch accuracy: 0.54450
Time: 2018-07-15 05:43:44
TRAINING STATS: batch 76/486 in epoch 784,   batch loss: 1.70652, batch accuracy: 0.53717
Time: 2018-07-15 05:43:47
TRAINING STATS: batch 126/486 in epoch 784,  batch loss: 1.68269, batch accuracy: 0.54600
Time: 2018-07-15 05:43:51
TRAINING STATS: batch 176/486 in epoch 784,  batch loss: 1.57182, batch accuracy: 0.58283
Time: 2018-07-15 05:43:56
TRAINING STATS: batch 226/486 in epoch 784,  batch loss: 1.61056, batch accuracy: 0.57083
Time: 2018-07-15 05:44:00
TRAINING STATS: batch 276/486 in epoch 784,  batch loss: 1.63014, batch accuracy: 0.56417
Time: 2018-07-15 05:44:03
TRAINING STATS: batch 326/486 in epoch 784,  batch loss: 1.66430, batch accuracy: 0.54783
Time: 2018-07-15 05:44:08
TRAINING STATS: batch 376/486 in epoch 784,  batch loss: 1.66162, batch accuracy: 0.55267
Time: 2018-07-15 05:44:12
TRAINING STATS: batch 426/486 in epoch 784,  batch loss: 1.63518, batch accuracy: 0.55483
Time: 2018-07-15 05:44:15
TRAINING STATS: batch 476/486 in epoch 784,  batch loss: 1.58352, batch accuracy: 0.57250
Time: 2018-07-15 05:44:20
TRAINING STATS: batch 40/486 in epoch 785,   batch loss: 1.58818, batch accuracy: 0.57467
Time: 2018-07-15 05:44:24
TRAINING STATS: batch 90/486 in epoch 785,   batch loss: 1.66473, batch accuracy: 0.55517
Time: 2018-07-15 05:44:27
TRAINING STATS: batch 140/486 in epoch 785,  batch loss: 1.57240, batch accuracy: 0.57100
Time: 2018-07-15 05:44:32
TRAINING STATS: batch 190/486 in epoch 785,  batch loss: 1.62902, batch accuracy: 0.56333
Time: 2018-07-15 05:44:36
TRAINING STATS: batch 240/486 in epoch 785,  batch loss: 1.66215, batch accuracy: 0.54500
Time: 2018-07-15 05:44:39
TRAINING STATS: batch 290/486 in epoch 785,  batch loss: 1.67620, batch accuracy: 0.54750
Time: 2018-07-15 05:44:44
TRAINING STATS: batch 340/486 in epoch 785,  batch loss: 1.71598, batch accuracy: 0.52850
Time: 2018-07-15 05:44:48
TRAINING STATS: batch 390/486 in epoch 785,  batch loss: 1.56548, batch accuracy: 0.58617
Time: 2018-07-15 05:44:51
TRAINING STATS: batch 440/486 in epoch 785,  batch loss: 1.63179, batch accuracy: 0.56183
Time: 2018-07-15 05:44:56
TRAINING STATS: batch 4/486 in epoch 786,    batch loss: 1.58030, batch accuracy: 0.58300
Time: 2018-07-15 05:45:00
TRAINING STATS: batch 54/486 in epoch 786,   batch loss: 1.63053, batch accuracy: 0.56033
Time: 2018-07-15 05:45:03
TRAINING STATS: batch 104/486 in epoch 786,  batch loss: 1.65435, batch accuracy: 0.55050
Time: 2018-07-15 05:45:08
TRAINING STATS: batch 154/486 in epoch 786,  batch loss: 1.63137, batch accuracy: 0.56183
Time: 2018-07-15 05:45:12
TRAINING STATS: batch 204/486 in epoch 786,  batch loss: 1.70018, batch accuracy: 0.53967
Time: 2018-07-15 05:45:16
TRAINING STATS: batch 254/486 in epoch 786,  batch loss: 1.57030, batch accuracy: 0.57517
Time: 2018-07-15 05:45:20
TRAINING STATS: batch 304/486 in epoch 786,  batch loss: 1.62942, batch accuracy: 0.56383
Time: 2018-07-15 05:45:24
TRAINING STATS: batch 354/486 in epoch 786,  batch loss: 1.65051, batch accuracy: 0.55833
Time: 2018-07-15 05:45:28
TRAINING STATS: batch 404/486 in epoch 786,  batch loss: 1.61147, batch accuracy: 0.56233
Time: 2018-07-15 05:45:32
TRAINING STATS: batch 454/486 in epoch 786,  batch loss: 1.49536, batch accuracy: 0.60100
Time: 2018-07-15 05:45:36
TRAINING STATS: batch 18/486 in epoch 787,   batch loss: 1.76099, batch accuracy: 0.52183
Time: 2018-07-15 05:45:39
TRAINING STATS: batch 68/486 in epoch 787,   batch loss: 1.48860, batch accuracy: 0.60117
Time: 2018-07-15 05:45:44
TRAINING STATS: batch 118/486 in epoch 787,  batch loss: 1.61916, batch accuracy: 0.56367
Time: 2018-07-15 05:45:48
TRAINING STATS: batch 168/486 in epoch 787,  batch loss: 1.55983, batch accuracy: 0.58483
Time: 2018-07-15 05:45:52
TRAINING STATS: batch 218/486 in epoch 787,  batch loss: 1.61216, batch accuracy: 0.56350
Time: 2018-07-15 05:45:56
TRAINING STATS: batch 268/486 in epoch 787,  batch loss: 1.57131, batch accuracy: 0.57550
Time: 2018-07-15 05:46:00
TRAINING STATS: batch 318/486 in epoch 787,  batch loss: 1.65229, batch accuracy: 0.55150
Time: 2018-07-15 05:46:04
TRAINING STATS: batch 368/486 in epoch 787,  batch loss: 1.64103, batch accuracy: 0.55733
Time: 2018-07-15 05:46:08
TRAINING STATS: batch 418/486 in epoch 787,  batch loss: 1.70646, batch accuracy: 0.54283
Time: 2018-07-15 05:46:12
TRAINING STATS: batch 468/486 in epoch 787,  batch loss: 1.64457, batch accuracy: 0.56200
Time: 2018-07-15 05:46:16
TRAINING STATS: batch 32/486 in epoch 788,   batch loss: 1.59792, batch accuracy: 0.56867
Time: 2018-07-15 05:46:20
TRAINING STATS: batch 82/486 in epoch 788,   batch loss: 1.65763, batch accuracy: 0.54800
Time: 2018-07-15 05:46:24
TRAINING STATS: batch 132/486 in epoch 788,  batch loss: 1.63331, batch accuracy: 0.56633
Time: 2018-07-15 05:46:28
TRAINING STATS: batch 182/486 in epoch 788,  batch loss: 1.68834, batch accuracy: 0.54733
Time: 2018-07-15 05:46:32
TRAINING STATS: batch 232/486 in epoch 788,  batch loss: 1.67160, batch accuracy: 0.54617
Time: 2018-07-15 05:46:36
TRAINING STATS: batch 282/486 in epoch 788,  batch loss: 1.60720, batch accuracy: 0.56517
Time: 2018-07-15 05:46:40
TRAINING STATS: batch 332/486 in epoch 788,  batch loss: 1.66030, batch accuracy: 0.55717
Time: 2018-07-15 05:46:45
TRAINING STATS: batch 382/486 in epoch 788,  batch loss: 1.64674, batch accuracy: 0.55967
Time: 2018-07-15 05:46:48
TRAINING STATS: batch 432/486 in epoch 788,  batch loss: 1.57022, batch accuracy: 0.57600
Time: 2018-07-15 05:46:52
TRAINING STATS: batch 482/486 in epoch 788,  batch loss: 1.61342, batch accuracy: 0.56800
Time: 2018-07-15 05:46:57
TRAINING STATS: batch 46/486 in epoch 789,   batch loss: 1.60224, batch accuracy: 0.57283
Time: 2018-07-15 05:47:00
TRAINING STATS: batch 96/486 in epoch 789,   batch loss: 1.66265, batch accuracy: 0.54817
Time: 2018-07-15 05:47:04
TRAINING STATS: batch 146/486 in epoch 789,  batch loss: 1.66463, batch accuracy: 0.55517
Time: 2018-07-15 05:47:09
TRAINING STATS: batch 196/486 in epoch 789,  batch loss: 1.69992, batch accuracy: 0.54433
Time: 2018-07-15 05:47:12
TRAINING STATS: batch 246/486 in epoch 789,  batch loss: 1.59438, batch accuracy: 0.57017
Time: 2018-07-15 05:47:16
TRAINING STATS: batch 296/486 in epoch 789,  batch loss: 1.59481, batch accuracy: 0.56800
Time: 2018-07-15 05:47:21
TRAINING STATS: batch 346/486 in epoch 789,  batch loss: 1.53746, batch accuracy: 0.59017
Time: 2018-07-15 05:47:24
TRAINING STATS: batch 396/486 in epoch 789,  batch loss: 1.61652, batch accuracy: 0.56700
Time: 2018-07-15 05:47:28
TRAINING STATS: batch 446/486 in epoch 789,  batch loss: 1.65069, batch accuracy: 0.56000
Time: 2018-07-15 05:47:33
TRAINING STATS: batch 10/486 in epoch 790,   batch loss: 1.66864, batch accuracy: 0.54500
Time: 2018-07-15 05:47:36
TRAINING STATS: batch 60/486 in epoch 790,   batch loss: 1.63570, batch accuracy: 0.56400
Time: 2018-07-15 05:47:40
TRAINING STATS: batch 110/486 in epoch 790,  batch loss: 1.67554, batch accuracy: 0.55267
Time: 2018-07-15 05:47:45
TRAINING STATS: batch 160/486 in epoch 790,  batch loss: 1.60461, batch accuracy: 0.57050
Time: 2018-07-15 05:47:49
TRAINING STATS: batch 210/486 in epoch 790,  batch loss: 1.57285, batch accuracy: 0.57750
Time: 2018-07-15 05:47:52
TRAINING STATS: batch 260/486 in epoch 790,  batch loss: 1.66782, batch accuracy: 0.54733
Time: 2018-07-15 05:47:57
TRAINING STATS: batch 310/486 in epoch 790,  batch loss: 1.64153, batch accuracy: 0.55367
Time: 2018-07-15 05:48:01
TRAINING STATS: batch 360/486 in epoch 790,  batch loss: 1.66289, batch accuracy: 0.55067
Time: 2018-07-15 05:48:04
TRAINING STATS: batch 410/486 in epoch 790,  batch loss: 1.57213, batch accuracy: 0.57700
Time: 2018-07-15 05:48:09
TRAINING STATS: batch 460/486 in epoch 790,  batch loss: 1.74585, batch accuracy: 0.52067
Time: 2018-07-15 05:48:12
TRAINING STATS: batch 24/486 in epoch 791,   batch loss: 1.75683, batch accuracy: 0.52533
Time: 2018-07-15 05:48:16
TRAINING STATS: batch 74/486 in epoch 791,   batch loss: 1.65720, batch accuracy: 0.55750
Time: 2018-07-15 05:48:21
TRAINING STATS: batch 124/486 in epoch 791,  batch loss: 1.64966, batch accuracy: 0.56567
Time: 2018-07-15 05:48:25
TRAINING STATS: batch 174/486 in epoch 791,  batch loss: 1.68815, batch accuracy: 0.54600
Time: 2018-07-15 05:48:28
TRAINING STATS: batch 224/486 in epoch 791,  batch loss: 1.68770, batch accuracy: 0.54583
Time: 2018-07-15 05:48:33
TRAINING STATS: batch 274/486 in epoch 791,  batch loss: 1.64517, batch accuracy: 0.55050
Time: 2018-07-15 05:48:37
TRAINING STATS: batch 324/486 in epoch 791,  batch loss: 1.69067, batch accuracy: 0.54550
Time: 2018-07-15 05:48:40
TRAINING STATS: batch 374/486 in epoch 791,  batch loss: 1.67409, batch accuracy: 0.54750
Time: 2018-07-15 05:48:45
TRAINING STATS: batch 424/486 in epoch 791,  batch loss: 1.58261, batch accuracy: 0.57317
Time: 2018-07-15 05:48:49
TRAINING STATS: batch 474/486 in epoch 791,  batch loss: 1.62634, batch accuracy: 0.56100
Time: 2018-07-15 05:48:52
TRAINING STATS: batch 38/486 in epoch 792,   batch loss: 1.66294, batch accuracy: 0.54817
Time: 2018-07-15 05:48:57
TRAINING STATS: batch 88/486 in epoch 792,   batch loss: 1.69014, batch accuracy: 0.53850
Time: 2018-07-15 05:49:01
TRAINING STATS: batch 138/486 in epoch 792,  batch loss: 1.70320, batch accuracy: 0.53867
Time: 2018-07-15 05:49:04
TRAINING STATS: batch 188/486 in epoch 792,  batch loss: 1.59115, batch accuracy: 0.57483
Time: 2018-07-15 05:49:09
TRAINING STATS: batch 238/486 in epoch 792,  batch loss: 1.60694, batch accuracy: 0.56567
Time: 2018-07-15 05:49:13
TRAINING STATS: batch 288/486 in epoch 792,  batch loss: 1.66040, batch accuracy: 0.55217
Time: 2018-07-15 05:49:17
TRAINING STATS: batch 338/486 in epoch 792,  batch loss: 1.64071, batch accuracy: 0.55183
Time: 2018-07-15 05:49:21
TRAINING STATS: batch 388/486 in epoch 792,  batch loss: 1.60127, batch accuracy: 0.56933
Time: 2018-07-15 05:49:25
TRAINING STATS: batch 438/486 in epoch 792,  batch loss: 1.66735, batch accuracy: 0.55350
Time: 2018-07-15 05:49:28
TRAINING STATS: batch 2/486 in epoch 793,    batch loss: 1.65048, batch accuracy: 0.55250
Time: 2018-07-15 05:49:33
TRAINING STATS: batch 52/486 in epoch 793,   batch loss: 1.72796, batch accuracy: 0.52983
Time: 2018-07-15 05:49:37
TRAINING STATS: batch 102/486 in epoch 793,  batch loss: 1.66366, batch accuracy: 0.55550
Time: 2018-07-15 05:49:41
TRAINING STATS: batch 152/486 in epoch 793,  batch loss: 1.60485, batch accuracy: 0.56883
Time: 2018-07-15 05:49:45
TRAINING STATS: batch 202/486 in epoch 793,  batch loss: 1.65510, batch accuracy: 0.56050
Time: 2018-07-15 05:49:49
TRAINING STATS: batch 252/486 in epoch 793,  batch loss: 1.60652, batch accuracy: 0.57233
Time: 2018-07-15 05:49:53
TRAINING STATS: batch 302/486 in epoch 793,  batch loss: 1.60235, batch accuracy: 0.56517
Time: 2018-07-15 05:49:58
TRAINING STATS: batch 352/486 in epoch 793,  batch loss: 1.61577, batch accuracy: 0.56967
Time: 2018-07-15 05:50:01
TRAINING STATS: batch 402/486 in epoch 793,  batch loss: 1.51443, batch accuracy: 0.59900
Time: 2018-07-15 05:50:05
TRAINING STATS: batch 452/486 in epoch 793,  batch loss: 1.62131, batch accuracy: 0.55400
Time: 2018-07-15 05:50:09
TRAINING STATS: batch 16/486 in epoch 794,   batch loss: 1.61318, batch accuracy: 0.56133
Time: 2018-07-15 05:50:13
TRAINING STATS: batch 66/486 in epoch 794,   batch loss: 1.62211, batch accuracy: 0.57200
Time: 2018-07-15 05:50:17
TRAINING STATS: batch 116/486 in epoch 794,  batch loss: 1.60454, batch accuracy: 0.56683
Time: 2018-07-15 05:50:22
TRAINING STATS: batch 166/486 in epoch 794,  batch loss: 1.53995, batch accuracy: 0.58950
Time: 2018-07-15 05:50:25
TRAINING STATS: batch 216/486 in epoch 794,  batch loss: 1.66822, batch accuracy: 0.54850
Time: 2018-07-15 05:50:29
TRAINING STATS: batch 266/486 in epoch 794,  batch loss: 1.64564, batch accuracy: 0.55733
Time: 2018-07-15 05:50:34
TRAINING STATS: batch 316/486 in epoch 794,  batch loss: 1.62394, batch accuracy: 0.56267
Time: 2018-07-15 05:50:37
TRAINING STATS: batch 366/486 in epoch 794,  batch loss: 1.70325, batch accuracy: 0.54533
Time: 2018-07-15 05:50:41
TRAINING STATS: batch 416/486 in epoch 794,  batch loss: 1.66106, batch accuracy: 0.55633
Time: 2018-07-15 05:50:46
TRAINING STATS: batch 466/486 in epoch 794,  batch loss: 1.49852, batch accuracy: 0.60017
Time: 2018-07-15 05:50:49
TRAINING STATS: batch 30/486 in epoch 795,   batch loss: 1.52359, batch accuracy: 0.59150
Time: 2018-07-15 05:50:53
TRAINING STATS: batch 80/486 in epoch 795,   batch loss: 1.63444, batch accuracy: 0.55800
Time: 2018-07-15 05:50:58
TRAINING STATS: batch 130/486 in epoch 795,  batch loss: 1.70346, batch accuracy: 0.55100
Time: 2018-07-15 05:51:02
TRAINING STATS: batch 180/486 in epoch 795,  batch loss: 1.67487, batch accuracy: 0.55333
Time: 2018-07-15 05:51:05
TRAINING STATS: batch 230/486 in epoch 795,  batch loss: 1.66601, batch accuracy: 0.54783
Time: 2018-07-15 05:51:10
TRAINING STATS: batch 280/486 in epoch 795,  batch loss: 1.62378, batch accuracy: 0.56483
Time: 2018-07-15 05:51:14
TRAINING STATS: batch 330/486 in epoch 795,  batch loss: 1.62538, batch accuracy: 0.56033
Time: 2018-07-15 05:51:17
TRAINING STATS: batch 380/486 in epoch 795,  batch loss: 1.63624, batch accuracy: 0.56867
Time: 2018-07-15 05:51:22
TRAINING STATS: batch 430/486 in epoch 795,  batch loss: 1.58682, batch accuracy: 0.57517
Time: 2018-07-15 05:51:26
TRAINING STATS: batch 480/486 in epoch 795,  batch loss: 1.65614, batch accuracy: 0.55750
Time: 2018-07-15 05:51:29
TRAINING STATS: batch 44/486 in epoch 796,   batch loss: 1.58869, batch accuracy: 0.57217
Time: 2018-07-15 05:51:34
TRAINING STATS: batch 94/486 in epoch 796,   batch loss: 1.69454, batch accuracy: 0.54633
Time: 2018-07-15 05:51:38
TRAINING STATS: batch 144/486 in epoch 796,  batch loss: 1.69772, batch accuracy: 0.54017
Time: 2018-07-15 05:51:41
TRAINING STATS: batch 194/486 in epoch 796,  batch loss: 1.72690, batch accuracy: 0.53433
Time: 2018-07-15 05:51:46
TRAINING STATS: batch 244/486 in epoch 796,  batch loss: 1.63704, batch accuracy: 0.56283
Time: 2018-07-15 05:51:50
TRAINING STATS: batch 294/486 in epoch 796,  batch loss: 1.56647, batch accuracy: 0.57767
Time: 2018-07-15 05:51:53
TRAINING STATS: batch 344/486 in epoch 796,  batch loss: 1.62107, batch accuracy: 0.56400
Time: 2018-07-15 05:51:58
TRAINING STATS: batch 394/486 in epoch 796,  batch loss: 1.59125, batch accuracy: 0.58217
Time: 2018-07-15 05:52:02
TRAINING STATS: batch 444/486 in epoch 796,  batch loss: 1.59306, batch accuracy: 0.57550
Time: 2018-07-15 05:52:05
TRAINING STATS: batch 8/486 in epoch 797,    batch loss: 1.62476, batch accuracy: 0.56433
Time: 2018-07-15 05:52:10
TRAINING STATS: batch 58/486 in epoch 797,   batch loss: 1.59370, batch accuracy: 0.57283
Time: 2018-07-15 05:52:14
TRAINING STATS: batch 108/486 in epoch 797,  batch loss: 1.69442, batch accuracy: 0.54950
Time: 2018-07-15 05:52:17
TRAINING STATS: batch 158/486 in epoch 797,  batch loss: 1.68707, batch accuracy: 0.54933
Time: 2018-07-15 05:52:22
TRAINING STATS: batch 208/486 in epoch 797,  batch loss: 1.64840, batch accuracy: 0.56050
Time: 2018-07-15 05:52:26
TRAINING STATS: batch 258/486 in epoch 797,  batch loss: 1.59053, batch accuracy: 0.57217
Time: 2018-07-15 05:52:30
TRAINING STATS: batch 308/486 in epoch 797,  batch loss: 1.64750, batch accuracy: 0.56633
Time: 2018-07-15 05:52:34
TRAINING STATS: batch 358/486 in epoch 797,  batch loss: 1.69884, batch accuracy: 0.54250
Time: 2018-07-15 05:52:38
TRAINING STATS: batch 408/486 in epoch 797,  batch loss: 1.68406, batch accuracy: 0.53667
Time: 2018-07-15 05:52:42
TRAINING STATS: batch 458/486 in epoch 797,  batch loss: 1.64907, batch accuracy: 0.55900
Time: 2018-07-15 05:52:46
TRAINING STATS: batch 22/486 in epoch 798,   batch loss: 1.70433, batch accuracy: 0.55317
Time: 2018-07-15 05:52:50
TRAINING STATS: batch 72/486 in epoch 798,   batch loss: 1.66576, batch accuracy: 0.54833
Time: 2018-07-15 05:52:54
TRAINING STATS: batch 122/486 in epoch 798,  batch loss: 1.57183, batch accuracy: 0.57983
Time: 2018-07-15 05:52:58
TRAINING STATS: batch 172/486 in epoch 798,  batch loss: 1.68838, batch accuracy: 0.54717
Time: 2018-07-15 05:53:02
TRAINING STATS: batch 222/486 in epoch 798,  batch loss: 1.64048, batch accuracy: 0.56067
Time: 2018-07-15 05:53:06
TRAINING STATS: batch 272/486 in epoch 798,  batch loss: 2.12317, batch accuracy: 0.39300
Time: 2018-07-15 05:53:11
TRAINING STATS: batch 322/486 in epoch 798,  batch loss: 2.04058, batch accuracy: 0.43883
Time: 2018-07-15 05:53:14
TRAINING STATS: batch 372/486 in epoch 798,  batch loss: 1.97448, batch accuracy: 0.46867
Time: 2018-07-15 05:53:18
TRAINING STATS: batch 422/486 in epoch 798,  batch loss: 1.95812, batch accuracy: 0.47550
Time: 2018-07-15 05:53:23
TRAINING STATS: batch 472/486 in epoch 798,  batch loss: 1.99184, batch accuracy: 0.46567
Time: 2018-07-15 05:53:26
TRAINING STATS: batch 36/486 in epoch 799,   batch loss: 1.97823, batch accuracy: 0.47700
Time: 2018-07-15 05:53:30
TRAINING STATS: batch 86/486 in epoch 799,   batch loss: 1.92681, batch accuracy: 0.50150
Time: 2018-07-15 05:53:34
TRAINING STATS: batch 136/486 in epoch 799,  batch loss: 1.95754, batch accuracy: 0.48283
Time: 2018-07-15 05:53:38
TRAINING STATS: batch 186/486 in epoch 799,  batch loss: 1.92372, batch accuracy: 0.50017
Time: 2018-07-15 05:53:42
TRAINING STATS: batch 236/486 in epoch 799,  batch loss: 1.93631, batch accuracy: 0.49883
Time: 2018-07-15 05:53:47
TRAINING STATS: batch 286/486 in epoch 799,  batch loss: 1.92289, batch accuracy: 0.49350
Time: 2018-07-15 05:53:50
TRAINING STATS: batch 336/486 in epoch 799,  batch loss: 1.87132, batch accuracy: 0.51183
Time: 2018-07-15 05:53:54
TRAINING STATS: batch 386/486 in epoch 799,  batch loss: 1.91712, batch accuracy: 0.49650
Time: 2018-07-15 05:53:59
TRAINING STATS: batch 436/486 in epoch 799,  batch loss: 1.92460, batch accuracy: 0.50500
Time: 2018-07-15 05:54:02
TRAINING STATS: batch 0/486 in epoch 800,    batch loss: 1.88183, batch accuracy: 0.50867
Time: 2018-07-15 05:54:06
TRAINING STATS: batch 50/486 in epoch 800,   batch loss: 1.84924, batch accuracy: 0.52150
Time: 2018-07-15 05:54:11
TRAINING STATS: batch 100/486 in epoch 800,  batch loss: 1.89720, batch accuracy: 0.50650
Time: 2018-07-15 05:54:14
TRAINING STATS: batch 150/486 in epoch 800,  batch loss: 1.85256, batch accuracy: 0.52817
Time: 2018-07-15 05:54:18
TRAINING STATS: batch 200/486 in epoch 800,  batch loss: 1.78322, batch accuracy: 0.54283
Time: 2018-07-15 05:54:23
TRAINING STATS: batch 250/486 in epoch 800,  batch loss: 1.91593, batch accuracy: 0.49650
Time: 2018-07-15 05:54:26
TRAINING STATS: batch 300/486 in epoch 800,  batch loss: 1.88567, batch accuracy: 0.50167
Time: 2018-07-15 05:54:30
TRAINING STATS: batch 350/486 in epoch 800,  batch loss: 1.87137, batch accuracy: 0.51750
Time: 2018-07-15 05:54:35
TRAINING STATS: batch 400/486 in epoch 800,  batch loss: 1.76394, batch accuracy: 0.54183
Time: 2018-07-15 05:54:38
TRAINING STATS: batch 450/486 in epoch 800,  batch loss: 1.90682, batch accuracy: 0.49700
Time: 2018-07-15 05:54:42
TRAINING STATS: batch 14/486 in epoch 801,   batch loss: 1.78394, batch accuracy: 0.53367
Time: 2018-07-15 05:54:47
TRAINING STATS: batch 64/486 in epoch 801,   batch loss: 1.93954, batch accuracy: 0.48767
Time: 2018-07-15 05:54:50
TRAINING STATS: batch 114/486 in epoch 801,  batch loss: 1.89624, batch accuracy: 0.50367
Time: 2018-07-15 05:54:54
TRAINING STATS: batch 164/486 in epoch 801,  batch loss: 1.79396, batch accuracy: 0.54333
Time: 2018-07-15 05:54:59
TRAINING STATS: batch 214/486 in epoch 801,  batch loss: 1.85106, batch accuracy: 0.51400
Time: 2018-07-15 05:55:02
TRAINING STATS: batch 264/486 in epoch 801,  batch loss: 1.89577, batch accuracy: 0.49700
Time: 2018-07-15 05:55:06
TRAINING STATS: batch 314/486 in epoch 801,  batch loss: 1.90075, batch accuracy: 0.49217
Time: 2018-07-15 05:55:11
TRAINING STATS: batch 364/486 in epoch 801,  batch loss: 1.83412, batch accuracy: 0.52017
Time: 2018-07-15 05:55:15
TRAINING STATS: batch 414/486 in epoch 801,  batch loss: 1.78774, batch accuracy: 0.53633
Time: 2018-07-15 05:55:18
TRAINING STATS: batch 464/486 in epoch 801,  batch loss: 1.82403, batch accuracy: 0.52433
Time: 2018-07-15 05:55:23
TRAINING STATS: batch 28/486 in epoch 802,   batch loss: 1.78997, batch accuracy: 0.53683
Time: 2018-07-15 05:55:27
TRAINING STATS: batch 78/486 in epoch 802,   batch loss: 1.84874, batch accuracy: 0.52317
Time: 2018-07-15 05:55:30
TRAINING STATS: batch 128/486 in epoch 802,  batch loss: 1.83321, batch accuracy: 0.52183
Time: 2018-07-15 05:55:35
TRAINING STATS: batch 178/486 in epoch 802,  batch loss: 1.73843, batch accuracy: 0.54600
Time: 2018-07-15 05:55:39
TRAINING STATS: batch 228/486 in epoch 802,  batch loss: 1.79450, batch accuracy: 0.53017
Time: 2018-07-15 05:55:42
TRAINING STATS: batch 278/486 in epoch 802,  batch loss: 1.78342, batch accuracy: 0.53400
Time: 2018-07-15 05:55:47
TRAINING STATS: batch 328/486 in epoch 802,  batch loss: 1.79858, batch accuracy: 0.52750
Time: 2018-07-15 05:55:51
TRAINING STATS: batch 378/486 in epoch 802,  batch loss: 1.85399, batch accuracy: 0.51750
Time: 2018-07-15 05:55:54
TRAINING STATS: batch 428/486 in epoch 802,  batch loss: 1.86930, batch accuracy: 0.51100
Time: 2018-07-15 05:55:59
TRAINING STATS: batch 478/486 in epoch 802,  batch loss: 1.83136, batch accuracy: 0.51917
Time: 2018-07-15 05:56:03
TRAINING STATS: batch 42/486 in epoch 803,   batch loss: 1.74694, batch accuracy: 0.54767
Time: 2018-07-15 05:56:06
TRAINING STATS: batch 92/486 in epoch 803,   batch loss: 1.83710, batch accuracy: 0.51583
Time: 2018-07-15 05:56:11
TRAINING STATS: batch 142/486 in epoch 803,  batch loss: 1.79035, batch accuracy: 0.52667
Time: 2018-07-15 05:56:15
TRAINING STATS: batch 192/486 in epoch 803,  batch loss: 1.82514, batch accuracy: 0.52150
Time: 2018-07-15 05:56:18
TRAINING STATS: batch 242/486 in epoch 803,  batch loss: 1.79593, batch accuracy: 0.53550
Time: 2018-07-15 05:56:23
TRAINING STATS: batch 292/486 in epoch 803,  batch loss: 1.82031, batch accuracy: 0.52517
Time: 2018-07-15 05:56:27
TRAINING STATS: batch 342/486 in epoch 803,  batch loss: 1.79820, batch accuracy: 0.52900
Time: 2018-07-15 05:56:31
TRAINING STATS: batch 392/486 in epoch 803,  batch loss: 1.75190, batch accuracy: 0.54950
Time: 2018-07-15 05:56:35
TRAINING STATS: batch 442/486 in epoch 803,  batch loss: 1.75107, batch accuracy: 0.54800
Time: 2018-07-15 05:56:39
TRAINING STATS: batch 6/486 in epoch 804,    batch loss: 1.86101, batch accuracy: 0.51317
Time: 2018-07-15 05:56:43
TRAINING STATS: batch 56/486 in epoch 804,   batch loss: 1.80073, batch accuracy: 0.52717
Time: 2018-07-15 05:56:47
TRAINING STATS: batch 106/486 in epoch 804,  batch loss: 1.87990, batch accuracy: 0.49717
Time: 2018-07-15 05:56:51
TRAINING STATS: batch 156/486 in epoch 804,  batch loss: 1.84393, batch accuracy: 0.50900
Time: 2018-07-15 05:56:55
TRAINING STATS: batch 206/486 in epoch 804,  batch loss: 1.87735, batch accuracy: 0.50067
Time: 2018-07-15 05:56:59
TRAINING STATS: batch 256/486 in epoch 804,  batch loss: 1.76999, batch accuracy: 0.53367
Time: 2018-07-15 05:57:03
TRAINING STATS: batch 306/486 in epoch 804,  batch loss: 1.83692, batch accuracy: 0.52383
Time: 2018-07-15 05:57:07
TRAINING STATS: batch 356/486 in epoch 804,  batch loss: 1.89177, batch accuracy: 0.49717
Time: 2018-07-15 05:57:11
TRAINING STATS: batch 406/486 in epoch 804,  batch loss: 1.86213, batch accuracy: 0.50450
Time: 2018-07-15 05:57:15
TRAINING STATS: batch 456/486 in epoch 804,  batch loss: 1.70970, batch accuracy: 0.56483
Time: 2018-07-15 05:57:19
TRAINING STATS: batch 20/486 in epoch 805,   batch loss: 1.80999, batch accuracy: 0.52400
Time: 2018-07-15 05:57:23
TRAINING STATS: batch 70/486 in epoch 805,   batch loss: 1.71473, batch accuracy: 0.56117
Time: 2018-07-15 05:57:27
TRAINING STATS: batch 120/486 in epoch 805,  batch loss: 1.77044, batch accuracy: 0.53783
Time: 2018-07-15 05:57:31
TRAINING STATS: batch 170/486 in epoch 805,  batch loss: 1.78850, batch accuracy: 0.53150
Time: 2018-07-15 05:57:35
TRAINING STATS: batch 220/486 in epoch 805,  batch loss: 1.73921, batch accuracy: 0.55283
Time: 2018-07-15 05:57:39
TRAINING STATS: batch 270/486 in epoch 805,  batch loss: 1.80080, batch accuracy: 0.52017
Time: 2018-07-15 05:57:43
TRAINING STATS: batch 320/486 in epoch 805,  batch loss: 1.74775, batch accuracy: 0.54550
Time: 2018-07-15 05:57:48
TRAINING STATS: batch 370/486 in epoch 805,  batch loss: 1.80353, batch accuracy: 0.53383
Time: 2018-07-15 05:57:51
TRAINING STATS: batch 420/486 in epoch 805,  batch loss: 1.83710, batch accuracy: 0.51500
Time: 2018-07-15 05:57:55
TRAINING STATS: batch 470/486 in epoch 805,  batch loss: 1.87352, batch accuracy: 0.50000
Time: 2018-07-15 05:58:00
TRAINING STATS: batch 34/486 in epoch 806,   batch loss: 1.82608, batch accuracy: 0.52700
Time: 2018-07-15 05:58:03
TRAINING STATS: batch 84/486 in epoch 806,   batch loss: 1.80717, batch accuracy: 0.52583
Time: 2018-07-15 05:58:07
TRAINING STATS: batch 134/486 in epoch 806,  batch loss: 1.82564, batch accuracy: 0.52683
Time: 2018-07-15 05:58:12
TRAINING STATS: batch 184/486 in epoch 806,  batch loss: 1.81015, batch accuracy: 0.52550
Time: 2018-07-15 05:58:15
TRAINING STATS: batch 234/486 in epoch 806,  batch loss: 1.85813, batch accuracy: 0.51200
Time: 2018-07-15 05:58:19
TRAINING STATS: batch 284/486 in epoch 806,  batch loss: 1.83372, batch accuracy: 0.51800
Time: 2018-07-15 05:58:24
TRAINING STATS: batch 334/486 in epoch 806,  batch loss: 1.77722, batch accuracy: 0.53450
Time: 2018-07-15 05:58:28
TRAINING STATS: batch 384/486 in epoch 806,  batch loss: 1.76245, batch accuracy: 0.53917
Time: 2018-07-15 05:58:31
TRAINING STATS: batch 434/486 in epoch 806,  batch loss: 1.83194, batch accuracy: 0.52017
Time: 2018-07-15 05:58:36
TRAINING STATS: batch 484/486 in epoch 806,  batch loss: 1.80816, batch accuracy: 0.51650
Time: 2018-07-15 05:58:40
TRAINING STATS: batch 48/486 in epoch 807,   batch loss: 1.80202, batch accuracy: 0.52850
Time: 2018-07-15 05:58:43
TRAINING STATS: batch 98/486 in epoch 807,   batch loss: 1.82507, batch accuracy: 0.53050
Time: 2018-07-15 05:58:48
TRAINING STATS: batch 148/486 in epoch 807,  batch loss: 1.83905, batch accuracy: 0.52983
Time: 2018-07-15 05:58:52
TRAINING STATS: batch 198/486 in epoch 807,  batch loss: 1.77793, batch accuracy: 0.53267
Time: 2018-07-15 05:58:55
TRAINING STATS: batch 248/486 in epoch 807,  batch loss: 1.79660, batch accuracy: 0.52933
Time: 2018-07-15 05:59:00
TRAINING STATS: batch 298/486 in epoch 807,  batch loss: 1.81038, batch accuracy: 0.52050
Time: 2018-07-15 05:59:04
TRAINING STATS: batch 348/486 in epoch 807,  batch loss: 1.80168, batch accuracy: 0.53100
Time: 2018-07-15 05:59:07
TRAINING STATS: batch 398/486 in epoch 807,  batch loss: 1.78395, batch accuracy: 0.52633
Time: 2018-07-15 05:59:12
TRAINING STATS: batch 448/486 in epoch 807,  batch loss: 1.77360, batch accuracy: 0.53417
Time: 2018-07-15 05:59:16
TRAINING STATS: batch 12/486 in epoch 808,   batch loss: 1.78840, batch accuracy: 0.53233
Time: 2018-07-15 05:59:19
TRAINING STATS: batch 62/486 in epoch 808,   batch loss: 1.83865, batch accuracy: 0.51517
Time: 2018-07-15 05:59:24
TRAINING STATS: batch 112/486 in epoch 808,  batch loss: 1.76242, batch accuracy: 0.54283
Time: 2018-07-15 05:59:28
TRAINING STATS: batch 162/486 in epoch 808,  batch loss: 1.77042, batch accuracy: 0.54133
Time: 2018-07-15 05:59:31
TRAINING STATS: batch 212/486 in epoch 808,  batch loss: 1.70172, batch accuracy: 0.55967
Time: 2018-07-15 05:59:36
TRAINING STATS: batch 262/486 in epoch 808,  batch loss: 1.84427, batch accuracy: 0.51717
Time: 2018-07-15 05:59:40
TRAINING STATS: batch 312/486 in epoch 808,  batch loss: 1.80194, batch accuracy: 0.51883
Time: 2018-07-15 05:59:44
TRAINING STATS: batch 362/486 in epoch 808,  batch loss: 1.79253, batch accuracy: 0.52883
Time: 2018-07-15 05:59:48
TRAINING STATS: batch 412/486 in epoch 808,  batch loss: 1.74360, batch accuracy: 0.55000
Time: 2018-07-15 05:59:52
TRAINING STATS: batch 462/486 in epoch 808,  batch loss: 1.78747, batch accuracy: 0.54217
Time: 2018-07-15 05:59:56
TRAINING STATS: batch 26/486 in epoch 809,   batch loss: 1.81586, batch accuracy: 0.52283
Time: 2018-07-15 06:00:00
TRAINING STATS: batch 76/486 in epoch 809,   batch loss: 1.81877, batch accuracy: 0.51483
Time: 2018-07-15 06:00:04
TRAINING STATS: batch 126/486 in epoch 809,  batch loss: 1.81336, batch accuracy: 0.52033
Time: 2018-07-15 06:00:08
TRAINING STATS: batch 176/486 in epoch 809,  batch loss: 1.70914, batch accuracy: 0.55117
Time: 2018-07-15 06:00:13
TRAINING STATS: batch 226/486 in epoch 809,  batch loss: 1.77430, batch accuracy: 0.53583
Time: 2018-07-15 06:00:16
TRAINING STATS: batch 276/486 in epoch 809,  batch loss: 1.77992, batch accuracy: 0.53217
Time: 2018-07-15 06:00:20
TRAINING STATS: batch 326/486 in epoch 809,  batch loss: 1.82454, batch accuracy: 0.51717
Time: 2018-07-15 06:00:24
TRAINING STATS: batch 376/486 in epoch 809,  batch loss: 1.79679, batch accuracy: 0.52867
Time: 2018-07-15 06:00:28
TRAINING STATS: batch 426/486 in epoch 809,  batch loss: 1.77608, batch accuracy: 0.52817
Time: 2018-07-15 06:00:32
TRAINING STATS: batch 476/486 in epoch 809,  batch loss: 1.72700, batch accuracy: 0.55100
Time: 2018-07-15 06:00:37
TRAINING STATS: batch 40/486 in epoch 810,   batch loss: 1.73325, batch accuracy: 0.55700
Time: 2018-07-15 06:00:40
TRAINING STATS: batch 90/486 in epoch 810,   batch loss: 1.81241, batch accuracy: 0.53383
Time: 2018-07-15 06:00:44
TRAINING STATS: batch 140/486 in epoch 810,  batch loss: 1.71796, batch accuracy: 0.56450
Time: 2018-07-15 06:00:49
TRAINING STATS: batch 190/486 in epoch 810,  batch loss: 1.74641, batch accuracy: 0.54300
Time: 2018-07-15 06:00:52
TRAINING STATS: batch 240/486 in epoch 810,  batch loss: 1.75392, batch accuracy: 0.54167
Time: 2018-07-15 06:00:56
TRAINING STATS: batch 290/486 in epoch 810,  batch loss: 1.78758, batch accuracy: 0.53067
Time: 2018-07-15 06:01:01
TRAINING STATS: batch 340/486 in epoch 810,  batch loss: 1.83975, batch accuracy: 0.51417
Time: 2018-07-15 06:01:04
TRAINING STATS: batch 390/486 in epoch 810,  batch loss: 1.70262, batch accuracy: 0.55850
Time: 2018-07-15 06:01:08
TRAINING STATS: batch 440/486 in epoch 810,  batch loss: 1.76634, batch accuracy: 0.53300
Time: 2018-07-15 06:01:13
TRAINING STATS: batch 4/486 in epoch 811,    batch loss: 1.71410, batch accuracy: 0.55250
Time: 2018-07-15 06:01:16
TRAINING STATS: batch 54/486 in epoch 811,   batch loss: 1.77267, batch accuracy: 0.53850
Time: 2018-07-15 06:01:20
TRAINING STATS: batch 104/486 in epoch 811,  batch loss: 1.78088, batch accuracy: 0.53800
Time: 2018-07-15 06:01:25
TRAINING STATS: batch 154/486 in epoch 811,  batch loss: 1.75675, batch accuracy: 0.54000
Time: 2018-07-15 06:01:28
TRAINING STATS: batch 204/486 in epoch 811,  batch loss: 1.82925, batch accuracy: 0.52117
Time: 2018-07-15 06:01:32
TRAINING STATS: batch 254/486 in epoch 811,  batch loss: 1.68189, batch accuracy: 0.55700
Time: 2018-07-15 06:01:37
TRAINING STATS: batch 304/486 in epoch 811,  batch loss: 1.73077, batch accuracy: 0.55017
Time: 2018-07-15 06:01:41
TRAINING STATS: batch 354/486 in epoch 811,  batch loss: 1.77929, batch accuracy: 0.53733
Time: 2018-07-15 06:01:44
TRAINING STATS: batch 404/486 in epoch 811,  batch loss: 1.74494, batch accuracy: 0.54217
Time: 2018-07-15 06:01:49
TRAINING STATS: batch 454/486 in epoch 811,  batch loss: 1.64482, batch accuracy: 0.57200
Time: 2018-07-15 06:01:53
TRAINING STATS: batch 18/486 in epoch 812,   batch loss: 1.79835, batch accuracy: 0.52767
Time: 2018-07-15 06:01:56
TRAINING STATS: batch 68/486 in epoch 812,   batch loss: 1.61567, batch accuracy: 0.58867
Time: 2018-07-15 06:02:01
TRAINING STATS: batch 118/486 in epoch 812,  batch loss: 1.75427, batch accuracy: 0.54667
Time: 2018-07-15 06:02:05
TRAINING STATS: batch 168/486 in epoch 812,  batch loss: 1.69586, batch accuracy: 0.56383
Time: 2018-07-15 06:02:08
TRAINING STATS: batch 218/486 in epoch 812,  batch loss: 1.76182, batch accuracy: 0.54017
Time: 2018-07-15 06:02:13
TRAINING STATS: batch 268/486 in epoch 812,  batch loss: 1.71321, batch accuracy: 0.54900
Time: 2018-07-15 06:02:17
TRAINING STATS: batch 318/486 in epoch 812,  batch loss: 1.78716, batch accuracy: 0.53383
Time: 2018-07-15 06:02:20
TRAINING STATS: batch 368/486 in epoch 812,  batch loss: 1.79770, batch accuracy: 0.52867
Time: 2018-07-15 06:02:25
TRAINING STATS: batch 418/486 in epoch 812,  batch loss: 1.82888, batch accuracy: 0.52417
Time: 2018-07-15 06:02:29
TRAINING STATS: batch 468/486 in epoch 812,  batch loss: 1.76840, batch accuracy: 0.53567
Time: 2018-07-15 06:02:32
TRAINING STATS: batch 32/486 in epoch 813,   batch loss: 1.71698, batch accuracy: 0.54883
Time: 2018-07-15 06:02:37
TRAINING STATS: batch 82/486 in epoch 813,   batch loss: 1.78451, batch accuracy: 0.53333
Time: 2018-07-15 06:02:41
TRAINING STATS: batch 132/486 in epoch 813,  batch loss: 1.76662, batch accuracy: 0.54817
Time: 2018-07-15 06:02:44
TRAINING STATS: batch 182/486 in epoch 813,  batch loss: 1.82532, batch accuracy: 0.52217
Time: 2018-07-15 06:02:49
TRAINING STATS: batch 232/486 in epoch 813,  batch loss: 1.80472, batch accuracy: 0.52917
Time: 2018-07-15 06:02:53
TRAINING STATS: batch 282/486 in epoch 813,  batch loss: 1.71655, batch accuracy: 0.55083
Time: 2018-07-15 06:02:57
TRAINING STATS: batch 332/486 in epoch 813,  batch loss: 1.80056, batch accuracy: 0.52800
Time: 2018-07-15 06:03:01
TRAINING STATS: batch 382/486 in epoch 813,  batch loss: 1.79975, batch accuracy: 0.53083
Time: 2018-07-15 06:03:05
TRAINING STATS: batch 432/486 in epoch 813,  batch loss: 1.70952, batch accuracy: 0.55533
Time: 2018-07-15 06:03:09
TRAINING STATS: batch 482/486 in epoch 813,  batch loss: 1.74027, batch accuracy: 0.54933
Time: 2018-07-15 06:03:13
TRAINING STATS: batch 46/486 in epoch 814,   batch loss: 1.73478, batch accuracy: 0.54717
Time: 2018-07-15 06:03:17
TRAINING STATS: batch 96/486 in epoch 814,   batch loss: 1.78118, batch accuracy: 0.52967
Time: 2018-07-15 06:03:21
TRAINING STATS: batch 146/486 in epoch 814,  batch loss: 1.79625, batch accuracy: 0.52450
Time: 2018-07-15 06:03:25
TRAINING STATS: batch 196/486 in epoch 814,  batch loss: 1.80330, batch accuracy: 0.51817
Time: 2018-07-15 06:03:29
TRAINING STATS: batch 246/486 in epoch 814,  batch loss: 1.71924, batch accuracy: 0.54767
Time: 2018-07-15 06:03:33
TRAINING STATS: batch 296/486 in epoch 814,  batch loss: 1.72980, batch accuracy: 0.54067
Time: 2018-07-15 06:03:37
TRAINING STATS: batch 346/486 in epoch 814,  batch loss: 1.68412, batch accuracy: 0.56483
Time: 2018-07-15 06:03:41
TRAINING STATS: batch 396/486 in epoch 814,  batch loss: 1.73344, batch accuracy: 0.54667
Time: 2018-07-15 06:03:45
TRAINING STATS: batch 446/486 in epoch 814,  batch loss: 1.77125, batch accuracy: 0.53400
Time: 2018-07-15 06:03:49
TRAINING STATS: batch 10/486 in epoch 815,   batch loss: 1.79117, batch accuracy: 0.52133
Time: 2018-07-15 06:03:53
TRAINING STATS: batch 60/486 in epoch 815,   batch loss: 1.74596, batch accuracy: 0.53467
Time: 2018-07-15 06:03:57
TRAINING STATS: batch 110/486 in epoch 815,  batch loss: 1.79559, batch accuracy: 0.52917
Time: 2018-07-15 06:04:02
TRAINING STATS: batch 160/486 in epoch 815,  batch loss: 1.71749, batch accuracy: 0.54267
Time: 2018-07-15 06:04:05
TRAINING STATS: batch 210/486 in epoch 815,  batch loss: 1.71421, batch accuracy: 0.55267
Time: 2018-07-15 06:04:09
TRAINING STATS: batch 260/486 in epoch 815,  batch loss: 1.78789, batch accuracy: 0.52067
Time: 2018-07-15 06:04:14
TRAINING STATS: batch 310/486 in epoch 815,  batch loss: 1.76475, batch accuracy: 0.53000
Time: 2018-07-15 06:04:17
TRAINING STATS: batch 360/486 in epoch 815,  batch loss: 1.80300, batch accuracy: 0.51983
Time: 2018-07-15 06:04:21
TRAINING STATS: batch 410/486 in epoch 815,  batch loss: 1.68332, batch accuracy: 0.55583
Time: 2018-07-15 06:04:26
TRAINING STATS: batch 460/486 in epoch 815,  batch loss: 1.87303, batch accuracy: 0.49717
Time: 2018-07-15 06:04:29
TRAINING STATS: batch 24/486 in epoch 816,   batch loss: 1.81316, batch accuracy: 0.51867
Time: 2018-07-15 06:04:33
TRAINING STATS: batch 74/486 in epoch 816,   batch loss: 1.78768, batch accuracy: 0.52617
Time: 2018-07-15 06:04:38
TRAINING STATS: batch 124/486 in epoch 816,  batch loss: 1.78606, batch accuracy: 0.53033
Time: 2018-07-15 06:04:41
TRAINING STATS: batch 174/486 in epoch 816,  batch loss: 1.81284, batch accuracy: 0.51817
Time: 2018-07-15 06:04:45
TRAINING STATS: batch 224/486 in epoch 816,  batch loss: 1.79066, batch accuracy: 0.52933
Time: 2018-07-15 06:04:50
TRAINING STATS: batch 274/486 in epoch 816,  batch loss: 1.75674, batch accuracy: 0.53483
Time: 2018-07-15 06:04:53
TRAINING STATS: batch 324/486 in epoch 816,  batch loss: 1.79173, batch accuracy: 0.52983
Time: 2018-07-15 06:04:57
TRAINING STATS: batch 374/486 in epoch 816,  batch loss: 1.77925, batch accuracy: 0.52933
Time: 2018-07-15 06:05:02
TRAINING STATS: batch 424/486 in epoch 816,  batch loss: 1.71303, batch accuracy: 0.54567
Time: 2018-07-15 06:05:05
TRAINING STATS: batch 474/486 in epoch 816,  batch loss: 1.74800, batch accuracy: 0.53500
Time: 2018-07-15 06:05:09
TRAINING STATS: batch 38/486 in epoch 817,   batch loss: 1.77591, batch accuracy: 0.53117
Time: 2018-07-15 06:05:14
TRAINING STATS: batch 88/486 in epoch 817,   batch loss: 1.80022, batch accuracy: 0.51667
Time: 2018-07-15 06:05:18
TRAINING STATS: batch 138/486 in epoch 817,  batch loss: 1.78752, batch accuracy: 0.52217
Time: 2018-07-15 06:05:21
TRAINING STATS: batch 188/486 in epoch 817,  batch loss: 1.70440, batch accuracy: 0.55133
Time: 2018-07-15 06:05:26
TRAINING STATS: batch 238/486 in epoch 817,  batch loss: 1.73921, batch accuracy: 0.54400
Time: 2018-07-15 06:05:30
TRAINING STATS: batch 288/486 in epoch 817,  batch loss: 1.77666, batch accuracy: 0.52067
Time: 2018-07-15 06:05:33
TRAINING STATS: batch 338/486 in epoch 817,  batch loss: 1.77892, batch accuracy: 0.52467
Time: 2018-07-15 06:05:38
TRAINING STATS: batch 388/486 in epoch 817,  batch loss: 1.70801, batch accuracy: 0.54433
Time: 2018-07-15 06:05:42
TRAINING STATS: batch 438/486 in epoch 817,  batch loss: 1.76976, batch accuracy: 0.53300
Time: 2018-07-15 06:05:45
TRAINING STATS: batch 2/486 in epoch 818,    batch loss: 1.77541, batch accuracy: 0.52567
Time: 2018-07-15 06:05:50
TRAINING STATS: batch 52/486 in epoch 818,   batch loss: 1.81108, batch accuracy: 0.51500
Time: 2018-07-15 06:05:54
TRAINING STATS: batch 102/486 in epoch 818,  batch loss: 1.79455, batch accuracy: 0.53133
Time: 2018-07-15 06:05:57
TRAINING STATS: batch 152/486 in epoch 818,  batch loss: 1.70286, batch accuracy: 0.55000
Time: 2018-07-15 06:06:02
TRAINING STATS: batch 202/486 in epoch 818,  batch loss: 1.74883, batch accuracy: 0.53767
Time: 2018-07-15 06:06:06
TRAINING STATS: batch 252/486 in epoch 818,  batch loss: 1.71779, batch accuracy: 0.54333
Time: 2018-07-15 06:06:09
TRAINING STATS: batch 302/486 in epoch 818,  batch loss: 1.73191, batch accuracy: 0.53950
Time: 2018-07-15 06:06:14
TRAINING STATS: batch 352/486 in epoch 818,  batch loss: 1.72789, batch accuracy: 0.54017
Time: 2018-07-15 06:06:18
TRAINING STATS: batch 402/486 in epoch 818,  batch loss: 1.61993, batch accuracy: 0.58533
Time: 2018-07-15 06:06:22
TRAINING STATS: batch 452/486 in epoch 818,  batch loss: 1.73823, batch accuracy: 0.53933
Time: 2018-07-15 06:06:26
TRAINING STATS: batch 16/486 in epoch 819,   batch loss: 1.85402, batch accuracy: 0.51200
Time: 2018-07-15 06:06:30
TRAINING STATS: batch 66/486 in epoch 819,   batch loss: 1.81231, batch accuracy: 0.52583
Time: 2018-07-15 06:06:34
TRAINING STATS: batch 116/486 in epoch 819,  batch loss: 1.72922, batch accuracy: 0.54600
Time: 2018-07-15 06:06:38
TRAINING STATS: batch 166/486 in epoch 819,  batch loss: 1.65858, batch accuracy: 0.56417
Time: 2018-07-15 06:06:42
TRAINING STATS: batch 216/486 in epoch 819,  batch loss: 1.75754, batch accuracy: 0.54117
Time: 2018-07-15 06:06:46
TRAINING STATS: batch 266/486 in epoch 819,  batch loss: 1.74260, batch accuracy: 0.53933
Time: 2018-07-15 06:06:50
TRAINING STATS: batch 316/486 in epoch 819,  batch loss: 1.72896, batch accuracy: 0.54683
Time: 2018-07-15 06:06:54
TRAINING STATS: batch 366/486 in epoch 819,  batch loss: 1.78934, batch accuracy: 0.52783
Time: 2018-07-15 06:06:58
TRAINING STATS: batch 416/486 in epoch 819,  batch loss: 1.75451, batch accuracy: 0.53300
Time: 2018-07-15 06:07:02
TRAINING STATS: batch 466/486 in epoch 819,  batch loss: 1.59597, batch accuracy: 0.58267
Time: 2018-07-15 06:07:06
TRAINING STATS: batch 30/486 in epoch 820,   batch loss: 1.63050, batch accuracy: 0.56967
Time: 2018-07-15 06:07:10
TRAINING STATS: batch 80/486 in epoch 820,   batch loss: 1.72838, batch accuracy: 0.54267
Time: 2018-07-15 06:07:15
TRAINING STATS: batch 130/486 in epoch 820,  batch loss: 1.71142, batch accuracy: 0.55683
Time: 2018-07-15 06:07:18
TRAINING STATS: batch 180/486 in epoch 820,  batch loss: 1.76522, batch accuracy: 0.52933
Time: 2018-07-15 06:07:22
TRAINING STATS: batch 230/486 in epoch 820,  batch loss: 1.76026, batch accuracy: 0.52800
Time: 2018-07-15 06:07:27
TRAINING STATS: batch 280/486 in epoch 820,  batch loss: 1.70581, batch accuracy: 0.54617
Time: 2018-07-15 06:07:30
TRAINING STATS: batch 330/486 in epoch 820,  batch loss: 1.70734, batch accuracy: 0.54283
Time: 2018-07-15 06:07:34
TRAINING STATS: batch 380/486 in epoch 820,  batch loss: 1.68394, batch accuracy: 0.55800
Time: 2018-07-15 06:07:39
TRAINING STATS: batch 430/486 in epoch 820,  batch loss: 1.65610, batch accuracy: 0.55667
Time: 2018-07-15 06:07:42
TRAINING STATS: batch 480/486 in epoch 820,  batch loss: 1.73724, batch accuracy: 0.54333
Time: 2018-07-15 06:07:46
TRAINING STATS: batch 44/486 in epoch 821,   batch loss: 1.66331, batch accuracy: 0.55883
Time: 2018-07-15 06:07:51
TRAINING STATS: batch 94/486 in epoch 821,   batch loss: 1.77695, batch accuracy: 0.53133
Time: 2018-07-15 06:07:54
TRAINING STATS: batch 144/486 in epoch 821,  batch loss: 1.77780, batch accuracy: 0.52733
Time: 2018-07-15 06:07:58
TRAINING STATS: batch 194/486 in epoch 821,  batch loss: 1.81964, batch accuracy: 0.51217
Time: 2018-07-15 06:08:03
TRAINING STATS: batch 244/486 in epoch 821,  batch loss: 1.70223, batch accuracy: 0.54633
Time: 2018-07-15 06:08:06
TRAINING STATS: batch 294/486 in epoch 821,  batch loss: 1.64705, batch accuracy: 0.56250
Time: 2018-07-15 06:08:10
TRAINING STATS: batch 344/486 in epoch 821,  batch loss: 1.70528, batch accuracy: 0.54433
Time: 2018-07-15 06:08:15
TRAINING STATS: batch 394/486 in epoch 821,  batch loss: 1.69946, batch accuracy: 0.54950
Time: 2018-07-15 06:08:19
TRAINING STATS: batch 444/486 in epoch 821,  batch loss: 1.68253, batch accuracy: 0.55850
Time: 2018-07-15 06:08:22
TRAINING STATS: batch 8/486 in epoch 822,    batch loss: 1.71008, batch accuracy: 0.54033
Time: 2018-07-15 06:08:27
TRAINING STATS: batch 58/486 in epoch 822,   batch loss: 1.67840, batch accuracy: 0.55617
Time: 2018-07-15 06:08:31
TRAINING STATS: batch 108/486 in epoch 822,  batch loss: 1.77081, batch accuracy: 0.53117
Time: 2018-07-15 06:08:34
TRAINING STATS: batch 158/486 in epoch 822,  batch loss: 1.77403, batch accuracy: 0.52183
Time: 2018-07-15 06:08:39
TRAINING STATS: batch 208/486 in epoch 822,  batch loss: 1.74684, batch accuracy: 0.53400
Time: 2018-07-15 06:08:43
TRAINING STATS: batch 258/486 in epoch 822,  batch loss: 1.67069, batch accuracy: 0.55667
Time: 2018-07-15 06:08:46
TRAINING STATS: batch 308/486 in epoch 822,  batch loss: 1.74329, batch accuracy: 0.54400
Time: 2018-07-15 06:08:51
TRAINING STATS: batch 358/486 in epoch 822,  batch loss: 1.73367, batch accuracy: 0.54667
Time: 2018-07-15 06:08:55
TRAINING STATS: batch 408/486 in epoch 822,  batch loss: 1.75661, batch accuracy: 0.52533
Time: 2018-07-15 06:08:58
TRAINING STATS: batch 458/486 in epoch 822,  batch loss: 1.75089, batch accuracy: 0.53933
Time: 2018-07-15 06:09:03
TRAINING STATS: batch 22/486 in epoch 823,   batch loss: 1.76390, batch accuracy: 0.53733
Time: 2018-07-15 06:09:07
TRAINING STATS: batch 72/486 in epoch 823,   batch loss: 1.74318, batch accuracy: 0.52933
Time: 2018-07-15 06:09:10
TRAINING STATS: batch 122/486 in epoch 823,  batch loss: 1.67016, batch accuracy: 0.56400
Time: 2018-07-15 06:09:15
TRAINING STATS: batch 172/486 in epoch 823,  batch loss: 1.77651, batch accuracy: 0.52867
Time: 2018-07-15 06:09:19
TRAINING STATS: batch 222/486 in epoch 823,  batch loss: 1.71349, batch accuracy: 0.53700
Time: 2018-07-15 06:09:23
TRAINING STATS: batch 272/486 in epoch 823,  batch loss: 1.74087, batch accuracy: 0.52950
Time: 2018-07-15 06:09:27
TRAINING STATS: batch 322/486 in epoch 823,  batch loss: 1.71577, batch accuracy: 0.54250
Time: 2018-07-15 06:09:31
TRAINING STATS: batch 372/486 in epoch 823,  batch loss: 1.66637, batch accuracy: 0.55883
Time: 2018-07-15 06:09:35
TRAINING STATS: batch 422/486 in epoch 823,  batch loss: 1.68943, batch accuracy: 0.55333
Time: 2018-07-15 06:09:39
TRAINING STATS: batch 472/486 in epoch 823,  batch loss: 1.76971, batch accuracy: 0.52267
Time: 2018-07-15 06:09:43
TRAINING STATS: batch 36/486 in epoch 824,   batch loss: 1.75894, batch accuracy: 0.53400
Time: 2018-07-15 06:09:47
TRAINING STATS: batch 86/486 in epoch 824,   batch loss: 1.73023, batch accuracy: 0.54367
Time: 2018-07-15 06:09:51
TRAINING STATS: batch 136/486 in epoch 824,  batch loss: 1.76816, batch accuracy: 0.52417
Time: 2018-07-15 06:09:55
TRAINING STATS: batch 186/486 in epoch 824,  batch loss: 1.72120, batch accuracy: 0.54433
Time: 2018-07-15 06:09:59
TRAINING STATS: batch 236/486 in epoch 824,  batch loss: 1.73731, batch accuracy: 0.53083
Time: 2018-07-15 06:10:03
TRAINING STATS: batch 286/486 in epoch 824,  batch loss: 1.76396, batch accuracy: 0.53583
Time: 2018-07-15 06:10:07
TRAINING STATS: batch 336/486 in epoch 824,  batch loss: 1.69416, batch accuracy: 0.54783
Time: 2018-07-15 06:10:11
TRAINING STATS: batch 386/486 in epoch 824,  batch loss: 1.74448, batch accuracy: 0.53600
Time: 2018-07-15 06:10:15
TRAINING STATS: batch 436/486 in epoch 824,  batch loss: 1.73328, batch accuracy: 0.54233
Time: 2018-07-15 06:10:19
TRAINING STATS: batch 0/486 in epoch 825,    batch loss: 1.68775, batch accuracy: 0.54967
Time: 2018-07-15 06:10:23
TRAINING STATS: batch 50/486 in epoch 825,   batch loss: 1.67075, batch accuracy: 0.56033
Time: 2018-07-15 06:10:27
TRAINING STATS: batch 100/486 in epoch 825,  batch loss: 1.74102, batch accuracy: 0.53633
Time: 2018-07-15 06:10:31
TRAINING STATS: batch 150/486 in epoch 825,  batch loss: 1.67447, batch accuracy: 0.55950
Time: 2018-07-15 06:10:35
TRAINING STATS: batch 200/486 in epoch 825,  batch loss: 1.59418, batch accuracy: 0.58033
Time: 2018-07-15 06:10:40
TRAINING STATS: batch 250/486 in epoch 825,  batch loss: 1.78484, batch accuracy: 0.52300
Time: 2018-07-15 06:10:43
TRAINING STATS: batch 300/486 in epoch 825,  batch loss: 1.76164, batch accuracy: 0.52933
Time: 2018-07-15 06:10:47
TRAINING STATS: batch 350/486 in epoch 825,  batch loss: 1.73078, batch accuracy: 0.54300
Time: 2018-07-15 06:10:52
TRAINING STATS: batch 400/486 in epoch 825,  batch loss: 1.60653, batch accuracy: 0.57483
Time: 2018-07-15 06:10:55
TRAINING STATS: batch 450/486 in epoch 825,  batch loss: 1.78994, batch accuracy: 0.51717
Time: 2018-07-15 06:10:59
TRAINING STATS: batch 14/486 in epoch 826,   batch loss: 1.63132, batch accuracy: 0.56717
Time: 2018-07-15 06:11:04
TRAINING STATS: batch 64/486 in epoch 826,   batch loss: 1.80645, batch accuracy: 0.51533
Time: 2018-07-15 06:11:07
TRAINING STATS: batch 114/486 in epoch 826,  batch loss: 1.74439, batch accuracy: 0.53583
Time: 2018-07-15 06:11:11
TRAINING STATS: batch 164/486 in epoch 826,  batch loss: 1.64548, batch accuracy: 0.57017
Time: 2018-07-15 06:11:16
TRAINING STATS: batch 214/486 in epoch 826,  batch loss: 1.71300, batch accuracy: 0.54450
Time: 2018-07-15 06:11:19
TRAINING STATS: batch 264/486 in epoch 826,  batch loss: 1.76206, batch accuracy: 0.52367
Time: 2018-07-15 06:11:23
TRAINING STATS: batch 314/486 in epoch 826,  batch loss: 1.77264, batch accuracy: 0.51617
Time: 2018-07-15 06:11:28
TRAINING STATS: batch 364/486 in epoch 826,  batch loss: 1.69366, batch accuracy: 0.54883
Time: 2018-07-15 06:11:31
TRAINING STATS: batch 414/486 in epoch 826,  batch loss: 1.65204, batch accuracy: 0.55600
Time: 2018-07-15 06:11:35
TRAINING STATS: batch 464/486 in epoch 826,  batch loss: 1.66583, batch accuracy: 0.55483
Time: 2018-07-15 06:11:40
TRAINING STATS: batch 28/486 in epoch 827,   batch loss: 1.64603, batch accuracy: 0.55950
Time: 2018-07-15 06:11:43
TRAINING STATS: batch 78/486 in epoch 827,   batch loss: 1.72401, batch accuracy: 0.54417
Time: 2018-07-15 06:11:47
TRAINING STATS: batch 128/486 in epoch 827,  batch loss: 1.68369, batch accuracy: 0.55417
Time: 2018-07-15 06:11:52
TRAINING STATS: batch 178/486 in epoch 827,  batch loss: 1.60617, batch accuracy: 0.56600
Time: 2018-07-15 06:11:56
TRAINING STATS: batch 228/486 in epoch 827,  batch loss: 1.65978, batch accuracy: 0.55700
Time: 2018-07-15 06:11:59
TRAINING STATS: batch 278/486 in epoch 827,  batch loss: 1.64494, batch accuracy: 0.56100
Time: 2018-07-15 06:12:04
TRAINING STATS: batch 328/486 in epoch 827,  batch loss: 1.67143, batch accuracy: 0.55117
Time: 2018-07-15 06:12:08
TRAINING STATS: batch 378/486 in epoch 827,  batch loss: 1.70703, batch accuracy: 0.54617
Time: 2018-07-15 06:12:11
TRAINING STATS: batch 428/486 in epoch 827,  batch loss: 1.73961, batch accuracy: 0.52483
Time: 2018-07-15 06:12:16
TRAINING STATS: batch 478/486 in epoch 827,  batch loss: 1.72201, batch accuracy: 0.53783
Time: 2018-07-15 06:12:20
TRAINING STATS: batch 42/486 in epoch 828,   batch loss: 1.60587, batch accuracy: 0.57167
Time: 2018-07-15 06:12:23
TRAINING STATS: batch 92/486 in epoch 828,   batch loss: 1.71213, batch accuracy: 0.54283
Time: 2018-07-15 06:12:28
TRAINING STATS: batch 142/486 in epoch 828,  batch loss: 1.67694, batch accuracy: 0.55133
Time: 2018-07-15 06:12:32
TRAINING STATS: batch 192/486 in epoch 828,  batch loss: 1.69749, batch accuracy: 0.54883
Time: 2018-07-15 06:12:36
TRAINING STATS: batch 242/486 in epoch 828,  batch loss: 1.66484, batch accuracy: 0.55283
Time: 2018-07-15 06:12:40
TRAINING STATS: batch 292/486 in epoch 828,  batch loss: 1.70039, batch accuracy: 0.54817
Time: 2018-07-15 06:12:44
TRAINING STATS: batch 342/486 in epoch 828,  batch loss: 1.67894, batch accuracy: 0.54350
Time: 2018-07-15 06:12:48
TRAINING STATS: batch 392/486 in epoch 828,  batch loss: 1.61845, batch accuracy: 0.57183
Time: 2018-07-15 06:12:52
TRAINING STATS: batch 442/486 in epoch 828,  batch loss: 1.62594, batch accuracy: 0.57217
Time: 2018-07-15 06:12:56
TRAINING STATS: batch 6/486 in epoch 829,    batch loss: 1.75451, batch accuracy: 0.52983
Time: 2018-07-15 06:13:00
TRAINING STATS: batch 56/486 in epoch 829,   batch loss: 1.67991, batch accuracy: 0.55050
Time: 2018-07-15 06:13:04
TRAINING STATS: batch 106/486 in epoch 829,  batch loss: 1.75477, batch accuracy: 0.52633
Time: 2018-07-15 06:13:08
TRAINING STATS: batch 156/486 in epoch 829,  batch loss: 1.73753, batch accuracy: 0.53533
Time: 2018-07-15 06:13:12
TRAINING STATS: batch 206/486 in epoch 829,  batch loss: 1.78284, batch accuracy: 0.51950
Time: 2018-07-15 06:13:17
TRAINING STATS: batch 256/486 in epoch 829,  batch loss: 1.65492, batch accuracy: 0.55650
Time: 2018-07-15 06:13:20
TRAINING STATS: batch 306/486 in epoch 829,  batch loss: 1.70428, batch accuracy: 0.53867
Time: 2018-07-15 06:13:24
TRAINING STATS: batch 356/486 in epoch 829,  batch loss: 1.75111, batch accuracy: 0.53133
Time: 2018-07-15 06:13:29
TRAINING STATS: batch 406/486 in epoch 829,  batch loss: 1.77083, batch accuracy: 0.52517
Time: 2018-07-15 06:13:32
TRAINING STATS: batch 456/486 in epoch 829,  batch loss: 1.60615, batch accuracy: 0.57917
Time: 2018-07-15 06:13:36
TRAINING STATS: batch 20/486 in epoch 830,   batch loss: 1.70083, batch accuracy: 0.54617
Time: 2018-07-15 06:13:41
TRAINING STATS: batch 70/486 in epoch 830,   batch loss: 1.59633, batch accuracy: 0.58050
Time: 2018-07-15 06:13:44
TRAINING STATS: batch 120/486 in epoch 830,  batch loss: 1.66141, batch accuracy: 0.55217
Time: 2018-07-15 06:13:48
TRAINING STATS: batch 170/486 in epoch 830,  batch loss: 1.67609, batch accuracy: 0.54983
Time: 2018-07-15 06:13:53
TRAINING STATS: batch 220/486 in epoch 830,  batch loss: 1.62217, batch accuracy: 0.56767
Time: 2018-07-15 06:13:56
TRAINING STATS: batch 270/486 in epoch 830,  batch loss: 1.71040, batch accuracy: 0.53150
Time: 2018-07-15 06:14:00
TRAINING STATS: batch 320/486 in epoch 830,  batch loss: 1.63245, batch accuracy: 0.55567
Time: 2018-07-15 06:14:05
TRAINING STATS: batch 370/486 in epoch 830,  batch loss: 1.69995, batch accuracy: 0.54867
Time: 2018-07-15 06:14:08
TRAINING STATS: batch 420/486 in epoch 830,  batch loss: 1.73220, batch accuracy: 0.53900
Time: 2018-07-15 06:14:12
TRAINING STATS: batch 470/486 in epoch 830,  batch loss: 1.78973, batch accuracy: 0.51800
Time: 2018-07-15 06:14:17
TRAINING STATS: batch 34/486 in epoch 831,   batch loss: 1.70820, batch accuracy: 0.54300
Time: 2018-07-15 06:14:21
TRAINING STATS: batch 84/486 in epoch 831,   batch loss: 1.75026, batch accuracy: 0.52783
Time: 2018-07-15 06:14:24
TRAINING STATS: batch 134/486 in epoch 831,  batch loss: 1.74917, batch accuracy: 0.53617
Time: 2018-07-15 06:14:29
TRAINING STATS: batch 184/486 in epoch 831,  batch loss: 1.72158, batch accuracy: 0.53650
Time: 2018-07-15 06:14:33
TRAINING STATS: batch 234/486 in epoch 831,  batch loss: 1.77457, batch accuracy: 0.52933
Time: 2018-07-15 06:14:36
TRAINING STATS: batch 284/486 in epoch 831,  batch loss: 1.74443, batch accuracy: 0.53233
Time: 2018-07-15 06:14:41
TRAINING STATS: batch 334/486 in epoch 831,  batch loss: 1.68333, batch accuracy: 0.55017
Time: 2018-07-15 06:14:45
TRAINING STATS: batch 384/486 in epoch 831,  batch loss: 1.65754, batch accuracy: 0.55817
Time: 2018-07-15 06:14:48
TRAINING STATS: batch 434/486 in epoch 831,  batch loss: 1.74510, batch accuracy: 0.52483
Time: 2018-07-15 06:14:53
TRAINING STATS: batch 484/486 in epoch 831,  batch loss: 1.71213, batch accuracy: 0.54200
Time: 2018-07-15 06:14:57
TRAINING STATS: batch 48/486 in epoch 832,   batch loss: 1.71385, batch accuracy: 0.54050
Time: 2018-07-15 06:15:00
TRAINING STATS: batch 98/486 in epoch 832,   batch loss: 1.65555, batch accuracy: 0.56000
Time: 2018-07-15 06:15:05
TRAINING STATS: batch 148/486 in epoch 832,  batch loss: 1.73243, batch accuracy: 0.53717
Time: 2018-07-15 06:15:09
TRAINING STATS: batch 198/486 in epoch 832,  batch loss: 1.68526, batch accuracy: 0.54717
Time: 2018-07-15 06:15:13
TRAINING STATS: batch 248/486 in epoch 832,  batch loss: 1.73234, batch accuracy: 0.53600
Time: 2018-07-15 06:15:17
TRAINING STATS: batch 298/486 in epoch 832,  batch loss: 1.72538, batch accuracy: 0.53583
Time: 2018-07-15 06:15:21
TRAINING STATS: batch 348/486 in epoch 832,  batch loss: 1.70169, batch accuracy: 0.54617
Time: 2018-07-15 06:15:25
TRAINING STATS: batch 398/486 in epoch 832,  batch loss: 1.69726, batch accuracy: 0.54983
Time: 2018-07-15 06:15:29
TRAINING STATS: batch 448/486 in epoch 832,  batch loss: 1.69143, batch accuracy: 0.55317
Time: 2018-07-15 06:15:33
TRAINING STATS: batch 12/486 in epoch 833,   batch loss: 1.71267, batch accuracy: 0.53683
Time: 2018-07-15 06:15:37
TRAINING STATS: batch 62/486 in epoch 833,   batch loss: 1.77404, batch accuracy: 0.52233
Time: 2018-07-15 06:15:41
TRAINING STATS: batch 112/486 in epoch 833,  batch loss: 1.69029, batch accuracy: 0.54633
Time: 2018-07-15 06:15:45
TRAINING STATS: batch 162/486 in epoch 833,  batch loss: 1.70311, batch accuracy: 0.54017
Time: 2018-07-15 06:15:49
TRAINING STATS: batch 212/486 in epoch 833,  batch loss: 1.62501, batch accuracy: 0.56633
Time: 2018-07-15 06:15:53
TRAINING STATS: batch 262/486 in epoch 833,  batch loss: 1.76160, batch accuracy: 0.52367
Time: 2018-07-15 06:15:57
TRAINING STATS: batch 312/486 in epoch 833,  batch loss: 1.69872, batch accuracy: 0.53483
Time: 2018-07-15 06:16:01
TRAINING STATS: batch 362/486 in epoch 833,  batch loss: 1.71058, batch accuracy: 0.54033
Time: 2018-07-15 06:16:06
TRAINING STATS: batch 412/486 in epoch 833,  batch loss: 1.64281, batch accuracy: 0.56367
Time: 2018-07-15 06:16:09
TRAINING STATS: batch 462/486 in epoch 833,  batch loss: 1.70922, batch accuracy: 0.54183
Time: 2018-07-15 06:16:13
TRAINING STATS: batch 26/486 in epoch 834,   batch loss: 1.73848, batch accuracy: 0.53617
Time: 2018-07-15 06:16:18
TRAINING STATS: batch 76/486 in epoch 834,   batch loss: 1.74273, batch accuracy: 0.53500
Time: 2018-07-15 06:16:21
TRAINING STATS: batch 126/486 in epoch 834,  batch loss: 1.72643, batch accuracy: 0.53883
Time: 2018-07-15 06:16:25
TRAINING STATS: batch 176/486 in epoch 834,  batch loss: 1.61860, batch accuracy: 0.56383
Time: 2018-07-15 06:16:29
TRAINING STATS: batch 226/486 in epoch 834,  batch loss: 1.67199, batch accuracy: 0.55533
Time: 2018-07-15 06:16:33
TRAINING STATS: batch 276/486 in epoch 834,  batch loss: 1.69952, batch accuracy: 0.54800
Time: 2018-07-15 06:16:37
TRAINING STATS: batch 326/486 in epoch 834,  batch loss: 1.77629, batch accuracy: 0.52300
Time: 2018-07-15 06:16:42
TRAINING STATS: batch 376/486 in epoch 834,  batch loss: 1.72501, batch accuracy: 0.54350
Time: 2018-07-15 06:16:45
TRAINING STATS: batch 426/486 in epoch 834,  batch loss: 1.70010, batch accuracy: 0.53983
Time: 2018-07-15 06:16:49
TRAINING STATS: batch 476/486 in epoch 834,  batch loss: 1.63209, batch accuracy: 0.56250
Time: 2018-07-15 06:16:54
TRAINING STATS: batch 40/486 in epoch 835,   batch loss: 1.65979, batch accuracy: 0.55533
Time: 2018-07-15 06:16:57
TRAINING STATS: batch 90/486 in epoch 835,   batch loss: 1.73148, batch accuracy: 0.53533
Time: 2018-07-15 06:17:01
TRAINING STATS: batch 140/486 in epoch 835,  batch loss: 1.62993, batch accuracy: 0.56100
Time: 2018-07-15 06:17:06
TRAINING STATS: batch 190/486 in epoch 835,  batch loss: 1.70283, batch accuracy: 0.54417
Time: 2018-07-15 06:17:09
TRAINING STATS: batch 240/486 in epoch 835,  batch loss: 1.68679, batch accuracy: 0.54650
Time: 2018-07-15 06:17:13
TRAINING STATS: batch 290/486 in epoch 835,  batch loss: 1.72101, batch accuracy: 0.53850
Time: 2018-07-15 06:17:18
TRAINING STATS: batch 340/486 in epoch 835,  batch loss: 1.77123, batch accuracy: 0.52033
Time: 2018-07-15 06:17:22
TRAINING STATS: batch 390/486 in epoch 835,  batch loss: 1.63675, batch accuracy: 0.57200
Time: 2018-07-15 06:17:25
TRAINING STATS: batch 440/486 in epoch 835,  batch loss: 1.70990, batch accuracy: 0.53767
Time: 2018-07-15 06:17:30
TRAINING STATS: batch 4/486 in epoch 836,    batch loss: 1.65324, batch accuracy: 0.55483
Time: 2018-07-15 06:17:34
TRAINING STATS: batch 54/486 in epoch 836,   batch loss: 1.68745, batch accuracy: 0.55133
Time: 2018-07-15 06:17:37
TRAINING STATS: batch 104/486 in epoch 836,  batch loss: 1.71821, batch accuracy: 0.54567
Time: 2018-07-15 06:17:42
TRAINING STATS: batch 154/486 in epoch 836,  batch loss: 1.68248, batch accuracy: 0.55150
Time: 2018-07-15 06:17:46
TRAINING STATS: batch 204/486 in epoch 836,  batch loss: 1.77596, batch accuracy: 0.52533
Time: 2018-07-15 06:17:49
TRAINING STATS: batch 254/486 in epoch 836,  batch loss: 1.62637, batch accuracy: 0.56000
Time: 2018-07-15 06:17:54
TRAINING STATS: batch 304/486 in epoch 836,  batch loss: 1.66351, batch accuracy: 0.55417
Time: 2018-07-15 06:17:58
TRAINING STATS: batch 354/486 in epoch 836,  batch loss: 1.71011, batch accuracy: 0.53967
Time: 2018-07-15 06:18:01
TRAINING STATS: batch 404/486 in epoch 836,  batch loss: 1.67904, batch accuracy: 0.54567
Time: 2018-07-15 06:18:06
TRAINING STATS: batch 454/486 in epoch 836,  batch loss: 1.56480, batch accuracy: 0.58400
Time: 2018-07-15 06:18:10
TRAINING STATS: batch 18/486 in epoch 837,   batch loss: 1.72247, batch accuracy: 0.53367
Time: 2018-07-15 06:18:14
TRAINING STATS: batch 68/486 in epoch 837,   batch loss: 1.55757, batch accuracy: 0.59500
Time: 2018-07-15 06:18:18
TRAINING STATS: batch 118/486 in epoch 837,  batch loss: 1.70044, batch accuracy: 0.54750
Time: 2018-07-15 06:18:22
TRAINING STATS: batch 168/486 in epoch 837,  batch loss: 1.62120, batch accuracy: 0.56750
Time: 2018-07-15 06:18:26
TRAINING STATS: batch 218/486 in epoch 837,  batch loss: 1.68202, batch accuracy: 0.54533
Time: 2018-07-15 06:18:30
TRAINING STATS: batch 268/486 in epoch 837,  batch loss: 1.65532, batch accuracy: 0.55033
Time: 2018-07-15 06:18:34
TRAINING STATS: batch 318/486 in epoch 837,  batch loss: 1.69244, batch accuracy: 0.54750
Time: 2018-07-15 06:18:38
TRAINING STATS: batch 368/486 in epoch 837,  batch loss: 1.73203, batch accuracy: 0.53967
Time: 2018-07-15 06:18:42
TRAINING STATS: batch 418/486 in epoch 837,  batch loss: 1.74882, batch accuracy: 0.53133
Time: 2018-07-15 06:18:46
TRAINING STATS: batch 468/486 in epoch 837,  batch loss: 1.68978, batch accuracy: 0.55167
Time: 2018-07-15 06:18:50
TRAINING STATS: batch 32/486 in epoch 838,   batch loss: 1.64118, batch accuracy: 0.56133
Time: 2018-07-15 06:18:54
TRAINING STATS: batch 82/486 in epoch 838,   batch loss: 1.72883, batch accuracy: 0.53017
Time: 2018-07-15 06:18:58
TRAINING STATS: batch 132/486 in epoch 838,  batch loss: 1.67189, batch accuracy: 0.55517
Time: 2018-07-15 06:19:02
TRAINING STATS: batch 182/486 in epoch 838,  batch loss: 1.75666, batch accuracy: 0.52217
Time: 2018-07-15 06:19:06
TRAINING STATS: batch 232/486 in epoch 838,  batch loss: 1.74587, batch accuracy: 0.53200
Time: 2018-07-15 06:19:10
TRAINING STATS: batch 282/486 in epoch 838,  batch loss: 1.66305, batch accuracy: 0.55050
Time: 2018-07-15 06:19:14
TRAINING STATS: batch 332/486 in epoch 838,  batch loss: 1.72381, batch accuracy: 0.53950
Time: 2018-07-15 06:19:19
TRAINING STATS: batch 382/486 in epoch 838,  batch loss: 1.72406, batch accuracy: 0.54267
Time: 2018-07-15 06:19:22
TRAINING STATS: batch 432/486 in epoch 838,  batch loss: 1.62789, batch accuracy: 0.56250
Time: 2018-07-15 06:19:26
TRAINING STATS: batch 482/486 in epoch 838,  batch loss: 1.68946, batch accuracy: 0.54900
Time: 2018-07-15 06:19:31
TRAINING STATS: batch 46/486 in epoch 839,   batch loss: 1.66736, batch accuracy: 0.55150
Time: 2018-07-15 06:19:34
TRAINING STATS: batch 96/486 in epoch 839,   batch loss: 1.72702, batch accuracy: 0.53867
Time: 2018-07-15 06:19:38
TRAINING STATS: batch 146/486 in epoch 839,  batch loss: 1.73505, batch accuracy: 0.53883
Time: 2018-07-15 06:19:43
TRAINING STATS: batch 196/486 in epoch 839,  batch loss: 1.73526, batch accuracy: 0.53467
Time: 2018-07-15 06:19:46
TRAINING STATS: batch 246/486 in epoch 839,  batch loss: 1.66889, batch accuracy: 0.55333
Time: 2018-07-15 06:19:50
TRAINING STATS: batch 296/486 in epoch 839,  batch loss: 1.65962, batch accuracy: 0.55500
Time: 2018-07-15 06:19:55
TRAINING STATS: batch 346/486 in epoch 839,  batch loss: 1.61957, batch accuracy: 0.57067
Time: 2018-07-15 06:19:59
TRAINING STATS: batch 396/486 in epoch 839,  batch loss: 1.69759, batch accuracy: 0.54467
Time: 2018-07-15 06:20:02
TRAINING STATS: batch 446/486 in epoch 839,  batch loss: 1.69937, batch accuracy: 0.54467
Time: 2018-07-15 06:20:07
TRAINING STATS: batch 10/486 in epoch 840,   batch loss: 1.73551, batch accuracy: 0.52600
Time: 2018-07-15 06:20:10
TRAINING STATS: batch 60/486 in epoch 840,   batch loss: 1.67675, batch accuracy: 0.55050
Time: 2018-07-15 06:20:14
TRAINING STATS: batch 110/486 in epoch 840,  batch loss: 1.75750, batch accuracy: 0.52400
Time: 2018-07-15 06:20:19
TRAINING STATS: batch 160/486 in epoch 840,  batch loss: 1.64958, batch accuracy: 0.55033
Time: 2018-07-15 06:20:23
TRAINING STATS: batch 210/486 in epoch 840,  batch loss: 1.64624, batch accuracy: 0.55967
Time: 2018-07-15 06:20:26
TRAINING STATS: batch 260/486 in epoch 840,  batch loss: 1.72787, batch accuracy: 0.53200
Time: 2018-07-15 06:20:31
TRAINING STATS: batch 310/486 in epoch 840,  batch loss: 1.70376, batch accuracy: 0.54000
Time: 2018-07-15 06:20:35
TRAINING STATS: batch 360/486 in epoch 840,  batch loss: 1.73298, batch accuracy: 0.53300
Time: 2018-07-15 06:20:38
TRAINING STATS: batch 410/486 in epoch 840,  batch loss: 1.63946, batch accuracy: 0.56467
Time: 2018-07-15 06:20:43
TRAINING STATS: batch 460/486 in epoch 840,  batch loss: 1.82597, batch accuracy: 0.50017
Time: 2018-07-15 06:20:47
TRAINING STATS: batch 24/486 in epoch 841,   batch loss: 1.75321, batch accuracy: 0.52600
Time: 2018-07-15 06:20:50
TRAINING STATS: batch 74/486 in epoch 841,   batch loss: 1.72734, batch accuracy: 0.53417
Time: 2018-07-15 06:20:55
TRAINING STATS: batch 124/486 in epoch 841,  batch loss: 1.72875, batch accuracy: 0.53967
Time: 2018-07-15 06:20:59
TRAINING STATS: batch 174/486 in epoch 841,  batch loss: 1.76156, batch accuracy: 0.52867
Time: 2018-07-15 06:21:02
TRAINING STATS: batch 224/486 in epoch 841,  batch loss: 1.73408, batch accuracy: 0.53367
Time: 2018-07-15 06:21:07
TRAINING STATS: batch 274/486 in epoch 841,  batch loss: 1.70930, batch accuracy: 0.54117
Time: 2018-07-15 06:21:11
TRAINING STATS: batch 324/486 in epoch 841,  batch loss: 1.73787, batch accuracy: 0.52550
Time: 2018-07-15 06:21:14
TRAINING STATS: batch 374/486 in epoch 841,  batch loss: 1.72827, batch accuracy: 0.53317
Time: 2018-07-15 06:21:19
TRAINING STATS: batch 424/486 in epoch 841,  batch loss: 1.64010, batch accuracy: 0.56433
Time: 2018-07-15 06:21:23
TRAINING STATS: batch 474/486 in epoch 841,  batch loss: 1.69457, batch accuracy: 0.54583
Time: 2018-07-15 06:21:26
TRAINING STATS: batch 38/486 in epoch 842,   batch loss: 1.72656, batch accuracy: 0.53800
Time: 2018-07-15 06:21:31
TRAINING STATS: batch 88/486 in epoch 842,   batch loss: 1.75040, batch accuracy: 0.53067
Time: 2018-07-15 06:21:35
TRAINING STATS: batch 138/486 in epoch 842,  batch loss: 1.74072, batch accuracy: 0.53567
Time: 2018-07-15 06:21:38
TRAINING STATS: batch 188/486 in epoch 842,  batch loss: 1.66031, batch accuracy: 0.56133
Time: 2018-07-15 06:21:43
TRAINING STATS: batch 238/486 in epoch 842,  batch loss: 1.68087, batch accuracy: 0.55683
Time: 2018-07-15 06:21:47
TRAINING STATS: batch 288/486 in epoch 842,  batch loss: 1.73814, batch accuracy: 0.52933
Time: 2018-07-15 06:21:51
TRAINING STATS: batch 338/486 in epoch 842,  batch loss: 1.70888, batch accuracy: 0.53567
Time: 2018-07-15 06:21:55
TRAINING STATS: batch 388/486 in epoch 842,  batch loss: 1.66402, batch accuracy: 0.55450
Time: 2018-07-15 06:21:59
TRAINING STATS: batch 438/486 in epoch 842,  batch loss: 1.72317, batch accuracy: 0.54167
Time: 2018-07-15 06:22:03
TRAINING STATS: batch 2/486 in epoch 843,    batch loss: 1.71836, batch accuracy: 0.54217
Time: 2018-07-15 06:22:07
TRAINING STATS: batch 52/486 in epoch 843,   batch loss: 1.76237, batch accuracy: 0.52483
Time: 2018-07-15 06:22:11
TRAINING STATS: batch 102/486 in epoch 843,  batch loss: 1.73789, batch accuracy: 0.53550
Time: 2018-07-15 06:22:15
TRAINING STATS: batch 152/486 in epoch 843,  batch loss: 1.65355, batch accuracy: 0.56250
Time: 2018-07-15 06:22:20
TRAINING STATS: batch 202/486 in epoch 843,  batch loss: 1.70899, batch accuracy: 0.53967
Time: 2018-07-15 06:22:23
TRAINING STATS: batch 252/486 in epoch 843,  batch loss: 1.66902, batch accuracy: 0.55367
Time: 2018-07-15 06:22:27
TRAINING STATS: batch 302/486 in epoch 843,  batch loss: 1.65254, batch accuracy: 0.55600
Time: 2018-07-15 06:22:32
TRAINING STATS: batch 352/486 in epoch 843,  batch loss: 1.67565, batch accuracy: 0.54583
Time: 2018-07-15 06:22:35
TRAINING STATS: batch 402/486 in epoch 843,  batch loss: 1.57239, batch accuracy: 0.58150
Time: 2018-07-15 06:22:39
TRAINING STATS: batch 452/486 in epoch 843,  batch loss: 1.70404, batch accuracy: 0.54133
Time: 2018-07-15 06:22:44
TRAINING STATS: batch 16/486 in epoch 844,   batch loss: 1.65925, batch accuracy: 0.55100
Time: 2018-07-15 06:22:47
TRAINING STATS: batch 66/486 in epoch 844,   batch loss: 1.68158, batch accuracy: 0.55167
Time: 2018-07-15 06:22:51
TRAINING STATS: batch 116/486 in epoch 844,  batch loss: 1.67366, batch accuracy: 0.55250
Time: 2018-07-15 06:22:56
TRAINING STATS: batch 166/486 in epoch 844,  batch loss: 1.61214, batch accuracy: 0.56717
Time: 2018-07-15 06:22:59
TRAINING STATS: batch 216/486 in epoch 844,  batch loss: 1.72304, batch accuracy: 0.54767
Time: 2018-07-15 06:23:03
TRAINING STATS: batch 266/486 in epoch 844,  batch loss: 1.71927, batch accuracy: 0.54233
Time: 2018-07-15 06:23:08
TRAINING STATS: batch 316/486 in epoch 844,  batch loss: 1.68610, batch accuracy: 0.54217
Time: 2018-07-15 06:23:11
TRAINING STATS: batch 366/486 in epoch 844,  batch loss: 1.75277, batch accuracy: 0.52917
Time: 2018-07-15 06:23:15
TRAINING STATS: batch 416/486 in epoch 844,  batch loss: 1.73769, batch accuracy: 0.52900
Time: 2018-07-15 06:23:20
TRAINING STATS: batch 466/486 in epoch 844,  batch loss: 1.56222, batch accuracy: 0.58667
Time: 2018-07-15 06:23:24
TRAINING STATS: batch 30/486 in epoch 845,   batch loss: 1.59125, batch accuracy: 0.56800
Time: 2018-07-15 06:23:27
TRAINING STATS: batch 80/486 in epoch 845,   batch loss: 1.70985, batch accuracy: 0.54033
Time: 2018-07-15 06:23:32
TRAINING STATS: batch 130/486 in epoch 845,  batch loss: 1.69135, batch accuracy: 0.55350
Time: 2018-07-15 06:23:36
TRAINING STATS: batch 180/486 in epoch 845,  batch loss: 1.72612, batch accuracy: 0.53483
Time: 2018-07-15 06:23:39
TRAINING STATS: batch 230/486 in epoch 845,  batch loss: 1.73578, batch accuracy: 0.52783
Time: 2018-07-15 06:23:44
TRAINING STATS: batch 280/486 in epoch 845,  batch loss: 1.69479, batch accuracy: 0.54467
Time: 2018-07-15 06:23:48
TRAINING STATS: batch 330/486 in epoch 845,  batch loss: 1.68274, batch accuracy: 0.54350
Time: 2018-07-15 06:23:51
TRAINING STATS: batch 380/486 in epoch 845,  batch loss: 1.66850, batch accuracy: 0.55300
Time: 2018-07-15 06:23:56
TRAINING STATS: batch 430/486 in epoch 845,  batch loss: 1.64958, batch accuracy: 0.55350
Time: 2018-07-15 06:24:00
TRAINING STATS: batch 480/486 in epoch 845,  batch loss: 1.70558, batch accuracy: 0.54433
Time: 2018-07-15 06:24:04
TRAINING STATS: batch 44/486 in epoch 846,   batch loss: 1.63562, batch accuracy: 0.56333
Time: 2018-07-15 06:24:08
TRAINING STATS: batch 94/486 in epoch 846,   batch loss: 1.75471, batch accuracy: 0.53100
Time: 2018-07-15 06:24:12
TRAINING STATS: batch 144/486 in epoch 846,  batch loss: 1.75079, batch accuracy: 0.52683
Time: 2018-07-15 06:24:16
TRAINING STATS: batch 194/486 in epoch 846,  batch loss: 1.79162, batch accuracy: 0.51533
Time: 2018-07-15 06:24:20
TRAINING STATS: batch 244/486 in epoch 846,  batch loss: 1.68683, batch accuracy: 0.55050
Time: 2018-07-15 06:24:24
TRAINING STATS: batch 294/486 in epoch 846,  batch loss: 1.62246, batch accuracy: 0.56517
Time: 2018-07-15 06:24:28
TRAINING STATS: batch 344/486 in epoch 846,  batch loss: 1.67736, batch accuracy: 0.54800
Time: 2018-07-15 06:24:32
TRAINING STATS: batch 394/486 in epoch 846,  batch loss: 1.65882, batch accuracy: 0.56150
Time: 2018-07-15 06:24:36
TRAINING STATS: batch 444/486 in epoch 846,  batch loss: 1.63429, batch accuracy: 0.56583
Time: 2018-07-15 06:24:40
TRAINING STATS: batch 8/486 in epoch 847,    batch loss: 1.67672, batch accuracy: 0.54900
Time: 2018-07-15 06:24:45
TRAINING STATS: batch 58/486 in epoch 847,   batch loss: 1.65797, batch accuracy: 0.55633
Time: 2018-07-15 06:24:48
TRAINING STATS: batch 108/486 in epoch 847,  batch loss: 1.74977, batch accuracy: 0.52900
Time: 2018-07-15 06:24:52
TRAINING STATS: batch 158/486 in epoch 847,  batch loss: 1.74779, batch accuracy: 0.53083
Time: 2018-07-15 06:24:57
TRAINING STATS: batch 208/486 in epoch 847,  batch loss: 1.71722, batch accuracy: 0.53850
Time: 2018-07-15 06:25:00
TRAINING STATS: batch 258/486 in epoch 847,  batch loss: 1.65769, batch accuracy: 0.55633
Time: 2018-07-15 06:25:04
TRAINING STATS: batch 308/486 in epoch 847,  batch loss: 1.71450, batch accuracy: 0.54383
Time: 2018-07-15 06:25:09
TRAINING STATS: batch 358/486 in epoch 847,  batch loss: 1.73576, batch accuracy: 0.53267
Time: 2018-07-15 06:25:12
TRAINING STATS: batch 408/486 in epoch 847,  batch loss: 1.74994, batch accuracy: 0.52533
Time: 2018-07-15 06:25:16
TRAINING STATS: batch 458/486 in epoch 847,  batch loss: 1.71376, batch accuracy: 0.54300
Time: 2018-07-15 06:25:21
TRAINING STATS: batch 22/486 in epoch 848,   batch loss: 1.74972, batch accuracy: 0.54067
Time: 2018-07-15 06:25:24
TRAINING STATS: batch 72/486 in epoch 848,   batch loss: 1.73086, batch accuracy: 0.52483
Time: 2018-07-15 06:25:28
TRAINING STATS: batch 122/486 in epoch 848,  batch loss: 1.64340, batch accuracy: 0.56367
Time: 2018-07-15 06:25:33
TRAINING STATS: batch 172/486 in epoch 848,  batch loss: 1.76235, batch accuracy: 0.52333
Time: 2018-07-15 06:25:36
TRAINING STATS: batch 222/486 in epoch 848,  batch loss: 1.68945, batch accuracy: 0.53633
Time: 2018-07-15 06:25:40
TRAINING STATS: batch 272/486 in epoch 848,  batch loss: 1.71934, batch accuracy: 0.53650
Time: 2018-07-15 06:25:45
TRAINING STATS: batch 322/486 in epoch 848,  batch loss: 1.69998, batch accuracy: 0.53933
Time: 2018-07-15 06:25:48
TRAINING STATS: batch 372/486 in epoch 848,  batch loss: 1.65338, batch accuracy: 0.55383
Time: 2018-07-15 06:25:52
TRAINING STATS: batch 422/486 in epoch 848,  batch loss: 1.66575, batch accuracy: 0.55383
Time: 2018-07-15 06:25:57
TRAINING STATS: batch 472/486 in epoch 848,  batch loss: 1.75201, batch accuracy: 0.52400
Time: 2018-07-15 06:26:01
TRAINING STATS: batch 36/486 in epoch 849,   batch loss: 1.74731, batch accuracy: 0.53583
Time: 2018-07-15 06:26:04
TRAINING STATS: batch 86/486 in epoch 849,   batch loss: 1.71099, batch accuracy: 0.54317
Time: 2018-07-15 06:26:09
TRAINING STATS: batch 136/486 in epoch 849,  batch loss: 1.75041, batch accuracy: 0.52400
Time: 2018-07-15 06:26:13
TRAINING STATS: batch 186/486 in epoch 849,  batch loss: 1.71487, batch accuracy: 0.54233
Time: 2018-07-15 06:26:16
TRAINING STATS: batch 236/486 in epoch 849,  batch loss: 1.75939, batch accuracy: 0.52333
Time: 2018-07-15 06:26:21
TRAINING STATS: batch 286/486 in epoch 849,  batch loss: 1.72762, batch accuracy: 0.53867
Time: 2018-07-15 06:26:25
TRAINING STATS: batch 336/486 in epoch 849,  batch loss: 1.69423, batch accuracy: 0.54250
Time: 2018-07-15 06:26:28
TRAINING STATS: batch 386/486 in epoch 849,  batch loss: 1.73316, batch accuracy: 0.53033
Time: 2018-07-15 06:26:33
TRAINING STATS: batch 436/486 in epoch 849,  batch loss: 1.71998, batch accuracy: 0.54483
Time: 2018-07-15 06:26:37
TRAINING STATS: batch 0/486 in epoch 850,    batch loss: 1.69323, batch accuracy: 0.53983
Time: 2018-07-15 06:26:41
TRAINING STATS: batch 50/486 in epoch 850,   batch loss: 1.64829, batch accuracy: 0.55367
Time: 2018-07-15 06:26:45
TRAINING STATS: batch 100/486 in epoch 850,  batch loss: 1.72467, batch accuracy: 0.53850
Time: 2018-07-15 06:26:49
TRAINING STATS: batch 150/486 in epoch 850,  batch loss: 1.66733, batch accuracy: 0.55767
Time: 2018-07-15 06:26:53
TRAINING STATS: batch 200/486 in epoch 850,  batch loss: 1.57451, batch accuracy: 0.58050
Time: 2018-07-15 06:26:57
TRAINING STATS: batch 250/486 in epoch 850,  batch loss: 1.75171, batch accuracy: 0.52383
Time: 2018-07-15 06:27:01
TRAINING STATS: batch 300/486 in epoch 850,  batch loss: 1.74973, batch accuracy: 0.52783
Time: 2018-07-15 06:27:05
TRAINING STATS: batch 350/486 in epoch 850,  batch loss: 1.71853, batch accuracy: 0.54450
Time: 2018-07-15 06:27:09
TRAINING STATS: batch 400/486 in epoch 850,  batch loss: 1.60013, batch accuracy: 0.56733
Time: 2018-07-15 06:27:13
TRAINING STATS: batch 450/486 in epoch 850,  batch loss: 1.75913, batch accuracy: 0.52450
Time: 2018-07-15 06:27:17
TRAINING STATS: batch 14/486 in epoch 851,   batch loss: 1.62446, batch accuracy: 0.56533
Time: 2018-07-15 06:27:22
TRAINING STATS: batch 64/486 in epoch 851,   batch loss: 1.79168, batch accuracy: 0.51717
Time: 2018-07-15 06:27:25
TRAINING STATS: batch 114/486 in epoch 851,  batch loss: 1.73889, batch accuracy: 0.53400
Time: 2018-07-15 06:27:29
TRAINING STATS: batch 164/486 in epoch 851,  batch loss: 1.63752, batch accuracy: 0.57117
Time: 2018-07-15 06:27:34
TRAINING STATS: batch 214/486 in epoch 851,  batch loss: 1.68636, batch accuracy: 0.54917
Time: 2018-07-15 06:27:37
TRAINING STATS: batch 264/486 in epoch 851,  batch loss: 1.72979, batch accuracy: 0.52533
Time: 2018-07-15 06:27:41
TRAINING STATS: batch 314/486 in epoch 851,  batch loss: 1.76148, batch accuracy: 0.52050
Time: 2018-07-15 06:27:46
TRAINING STATS: batch 364/486 in epoch 851,  batch loss: 1.68389, batch accuracy: 0.55200
Time: 2018-07-15 06:27:49
TRAINING STATS: batch 414/486 in epoch 851,  batch loss: 1.62786, batch accuracy: 0.55933
Time: 2018-07-15 06:27:53
TRAINING STATS: batch 464/486 in epoch 851,  batch loss: 1.65370, batch accuracy: 0.55950
Time: 2018-07-15 06:27:58
TRAINING STATS: batch 28/486 in epoch 852,   batch loss: 1.62413, batch accuracy: 0.56217
Time: 2018-07-15 06:28:01
TRAINING STATS: batch 78/486 in epoch 852,   batch loss: 1.70866, batch accuracy: 0.54800
Time: 2018-07-15 06:28:05
TRAINING STATS: batch 128/486 in epoch 852,  batch loss: 1.66195, batch accuracy: 0.56033
Time: 2018-07-15 06:28:10
TRAINING STATS: batch 178/486 in epoch 852,  batch loss: 1.58003, batch accuracy: 0.57350
Time: 2018-07-15 06:28:13
TRAINING STATS: batch 228/486 in epoch 852,  batch loss: 1.63982, batch accuracy: 0.56733
Time: 2018-07-15 06:28:17
TRAINING STATS: batch 278/486 in epoch 852,  batch loss: 1.62233, batch accuracy: 0.56500
Time: 2018-07-15 06:28:22
TRAINING STATS: batch 328/486 in epoch 852,  batch loss: 1.66532, batch accuracy: 0.55817
Time: 2018-07-15 06:28:26
TRAINING STATS: batch 378/486 in epoch 852,  batch loss: 1.69241, batch accuracy: 0.55367
Time: 2018-07-15 06:28:29
TRAINING STATS: batch 428/486 in epoch 852,  batch loss: 1.72242, batch accuracy: 0.53500
Time: 2018-07-15 06:28:34
TRAINING STATS: batch 478/486 in epoch 852,  batch loss: 1.70501, batch accuracy: 0.54267
Time: 2018-07-15 06:28:38
TRAINING STATS: batch 42/486 in epoch 853,   batch loss: 1.60233, batch accuracy: 0.56800
Time: 2018-07-15 06:28:41
TRAINING STATS: batch 92/486 in epoch 853,   batch loss: 1.72226, batch accuracy: 0.53517
Time: 2018-07-15 06:28:46
TRAINING STATS: batch 142/486 in epoch 853,  batch loss: 1.65674, batch accuracy: 0.55117
Time: 2018-07-15 06:28:50
TRAINING STATS: batch 192/486 in epoch 853,  batch loss: 1.69158, batch accuracy: 0.54033
Time: 2018-07-15 06:28:53
TRAINING STATS: batch 242/486 in epoch 853,  batch loss: 1.65058, batch accuracy: 0.56250
Time: 2018-07-15 06:28:58
TRAINING STATS: batch 292/486 in epoch 853,  batch loss: 1.67988, batch accuracy: 0.55383
Time: 2018-07-15 06:29:02
TRAINING STATS: batch 342/486 in epoch 853,  batch loss: 1.65498, batch accuracy: 0.55600
Time: 2018-07-15 06:29:05
TRAINING STATS: batch 392/486 in epoch 853,  batch loss: 1.61929, batch accuracy: 0.56433
Time: 2018-07-15 06:29:10
TRAINING STATS: batch 442/486 in epoch 853,  batch loss: 1.59660, batch accuracy: 0.57200
Time: 2018-07-15 06:29:14
TRAINING STATS: batch 6/486 in epoch 854,    batch loss: 1.72651, batch accuracy: 0.53317
Time: 2018-07-15 06:29:17
TRAINING STATS: batch 56/486 in epoch 854,   batch loss: 1.65435, batch accuracy: 0.55550
Time: 2018-07-15 06:29:22
TRAINING STATS: batch 106/486 in epoch 854,  batch loss: 1.80449, batch accuracy: 0.51650
Time: 2018-07-15 06:29:26
TRAINING STATS: batch 156/486 in epoch 854,  batch loss: 1.72544, batch accuracy: 0.53367
Time: 2018-07-15 06:29:30
TRAINING STATS: batch 206/486 in epoch 854,  batch loss: 1.75893, batch accuracy: 0.52717
Time: 2018-07-15 06:29:34
TRAINING STATS: batch 256/486 in epoch 854,  batch loss: 1.63513, batch accuracy: 0.55633
Time: 2018-07-15 06:29:38
TRAINING STATS: batch 306/486 in epoch 854,  batch loss: 1.70138, batch accuracy: 0.53933
Time: 2018-07-15 06:29:42
TRAINING STATS: batch 356/486 in epoch 854,  batch loss: 1.74236, batch accuracy: 0.53200
Time: 2018-07-15 06:29:46
TRAINING STATS: batch 406/486 in epoch 854,  batch loss: 1.74977, batch accuracy: 0.52667
Time: 2018-07-15 06:29:50
TRAINING STATS: batch 456/486 in epoch 854,  batch loss: 1.57138, batch accuracy: 0.58717
Time: 2018-07-15 06:29:54
TRAINING STATS: batch 20/486 in epoch 855,   batch loss: 1.69279, batch accuracy: 0.55117
Time: 2018-07-15 06:29:58
TRAINING STATS: batch 70/486 in epoch 855,   batch loss: 1.58968, batch accuracy: 0.57600
Time: 2018-07-15 06:30:02
TRAINING STATS: batch 120/486 in epoch 855,  batch loss: 1.63727, batch accuracy: 0.56167
Time: 2018-07-15 06:30:06
TRAINING STATS: batch 170/486 in epoch 855,  batch loss: 1.67553, batch accuracy: 0.55283
Time: 2018-07-15 06:30:11
TRAINING STATS: batch 220/486 in epoch 855,  batch loss: 1.60983, batch accuracy: 0.57167
Time: 2018-07-15 06:30:14
TRAINING STATS: batch 270/486 in epoch 855,  batch loss: 1.68993, batch accuracy: 0.53517
Time: 2018-07-15 06:30:18
TRAINING STATS: batch 320/486 in epoch 855,  batch loss: 1.64301, batch accuracy: 0.55867
Time: 2018-07-15 06:30:23
TRAINING STATS: batch 370/486 in epoch 855,  batch loss: 1.68815, batch accuracy: 0.54800
Time: 2018-07-15 06:30:26
TRAINING STATS: batch 420/486 in epoch 855,  batch loss: 1.71129, batch accuracy: 0.54317
Time: 2018-07-15 06:30:30
TRAINING STATS: batch 470/486 in epoch 855,  batch loss: 1.77760, batch accuracy: 0.51617
Time: 2018-07-15 06:30:35
TRAINING STATS: batch 34/486 in epoch 856,   batch loss: 1.70601, batch accuracy: 0.54417
Time: 2018-07-15 06:30:38
TRAINING STATS: batch 84/486 in epoch 856,   batch loss: 1.70247, batch accuracy: 0.53767
Time: 2018-07-15 06:30:42
TRAINING STATS: batch 134/486 in epoch 856,  batch loss: 1.71560, batch accuracy: 0.54950
Time: 2018-07-15 06:30:47
TRAINING STATS: batch 184/486 in epoch 856,  batch loss: 1.70831, batch accuracy: 0.54017
Time: 2018-07-15 06:30:50
TRAINING STATS: batch 234/486 in epoch 856,  batch loss: 1.76192, batch accuracy: 0.53250
Time: 2018-07-15 06:30:54
TRAINING STATS: batch 284/486 in epoch 856,  batch loss: 1.72816, batch accuracy: 0.53667
Time: 2018-07-15 06:30:59
TRAINING STATS: batch 334/486 in epoch 856,  batch loss: 1.67140, batch accuracy: 0.55083
Time: 2018-07-15 06:31:02
TRAINING STATS: batch 384/486 in epoch 856,  batch loss: 1.65819, batch accuracy: 0.55367
Time: 2018-07-15 06:31:06
TRAINING STATS: batch 434/486 in epoch 856,  batch loss: 1.73789, batch accuracy: 0.53267
Time: 2018-07-15 06:31:11
TRAINING STATS: batch 484/486 in epoch 856,  batch loss: 1.70102, batch accuracy: 0.54300
Time: 2018-07-15 06:31:14
TRAINING STATS: batch 48/486 in epoch 857,   batch loss: 1.76956, batch accuracy: 0.52900
Time: 2018-07-15 06:31:18
TRAINING STATS: batch 98/486 in epoch 857,   batch loss: 1.66747, batch accuracy: 0.55800
Time: 2018-07-15 06:31:23
TRAINING STATS: batch 148/486 in epoch 857,  batch loss: 1.72702, batch accuracy: 0.54267
Time: 2018-07-15 06:31:27
TRAINING STATS: batch 198/486 in epoch 857,  batch loss: 1.67040, batch accuracy: 0.55733
Time: 2018-07-15 06:31:30
TRAINING STATS: batch 248/486 in epoch 857,  batch loss: 1.71436, batch accuracy: 0.54517
Time: 2018-07-15 06:31:35
TRAINING STATS: batch 298/486 in epoch 857,  batch loss: 1.72114, batch accuracy: 0.53117
Time: 2018-07-15 06:31:39
TRAINING STATS: batch 348/486 in epoch 857,  batch loss: 1.69445, batch accuracy: 0.54750
Time: 2018-07-15 06:31:42
TRAINING STATS: batch 398/486 in epoch 857,  batch loss: 1.69587, batch accuracy: 0.54467
Time: 2018-07-15 06:31:47
TRAINING STATS: batch 448/486 in epoch 857,  batch loss: 1.69323, batch accuracy: 0.55183
Time: 2018-07-15 06:31:51
TRAINING STATS: batch 12/486 in epoch 858,   batch loss: 1.68854, batch accuracy: 0.54283
Time: 2018-07-15 06:31:54
TRAINING STATS: batch 62/486 in epoch 858,   batch loss: 1.78422, batch accuracy: 0.51567
Time: 2018-07-15 06:31:59
TRAINING STATS: batch 112/486 in epoch 858,  batch loss: 1.66726, batch accuracy: 0.55117
Time: 2018-07-15 06:32:03
TRAINING STATS: batch 162/486 in epoch 858,  batch loss: 1.69707, batch accuracy: 0.54150
Time: 2018-07-15 06:32:06
TRAINING STATS: batch 212/486 in epoch 858,  batch loss: 1.60317, batch accuracy: 0.56767
Time: 2018-07-15 06:32:11
TRAINING STATS: batch 262/486 in epoch 858,  batch loss: 1.76804, batch accuracy: 0.51883
Time: 2018-07-15 06:32:15
TRAINING STATS: batch 312/486 in epoch 858,  batch loss: 1.70113, batch accuracy: 0.53300
Time: 2018-07-15 06:32:18
TRAINING STATS: batch 362/486 in epoch 858,  batch loss: 1.70450, batch accuracy: 0.54217
Time: 2018-07-15 06:32:23
TRAINING STATS: batch 412/486 in epoch 858,  batch loss: 1.63942, batch accuracy: 0.55783
Time: 2018-07-15 06:32:27
TRAINING STATS: batch 462/486 in epoch 858,  batch loss: 1.73487, batch accuracy: 0.53050
Time: 2018-07-15 06:32:30
TRAINING STATS: batch 26/486 in epoch 859,   batch loss: 1.72477, batch accuracy: 0.52967
Time: 2018-07-15 06:32:35
TRAINING STATS: batch 76/486 in epoch 859,   batch loss: 1.74647, batch accuracy: 0.52833
Time: 2018-07-15 06:32:39
TRAINING STATS: batch 126/486 in epoch 859,  batch loss: 1.72983, batch accuracy: 0.53533
Time: 2018-07-15 06:32:43
TRAINING STATS: batch 176/486 in epoch 859,  batch loss: 1.62083, batch accuracy: 0.56600
Time: 2018-07-15 06:32:47
TRAINING STATS: batch 226/486 in epoch 859,  batch loss: 1.68539, batch accuracy: 0.55417
Time: 2018-07-15 06:32:51
TRAINING STATS: batch 276/486 in epoch 859,  batch loss: 1.69028, batch accuracy: 0.54333
Time: 2018-07-15 06:32:55
TRAINING STATS: batch 326/486 in epoch 859,  batch loss: 1.74913, batch accuracy: 0.52383
Time: 2018-07-15 06:32:59
TRAINING STATS: batch 376/486 in epoch 859,  batch loss: 1.71220, batch accuracy: 0.53933
Time: 2018-07-15 06:33:03
TRAINING STATS: batch 426/486 in epoch 859,  batch loss: 1.68154, batch accuracy: 0.54083
Time: 2018-07-15 06:33:07
TRAINING STATS: batch 476/486 in epoch 859,  batch loss: 1.63460, batch accuracy: 0.55883
Time: 2018-07-15 06:33:11
TRAINING STATS: batch 40/486 in epoch 860,   batch loss: 1.66414, batch accuracy: 0.55250
Time: 2018-07-15 06:33:15
TRAINING STATS: batch 90/486 in epoch 860,   batch loss: 1.72318, batch accuracy: 0.54617
Time: 2018-07-15 06:33:19
TRAINING STATS: batch 140/486 in epoch 860,  batch loss: 1.62558, batch accuracy: 0.56583
Time: 2018-07-15 06:33:24
TRAINING STATS: batch 190/486 in epoch 860,  batch loss: 1.67969, batch accuracy: 0.54933
Time: 2018-07-15 06:33:27
TRAINING STATS: batch 240/486 in epoch 860,  batch loss: 1.68796, batch accuracy: 0.54500
Time: 2018-07-15 06:33:31
TRAINING STATS: batch 290/486 in epoch 860,  batch loss: 1.71899, batch accuracy: 0.53933
Time: 2018-07-15 06:33:36
TRAINING STATS: batch 340/486 in epoch 860,  batch loss: 1.76601, batch accuracy: 0.52033
Time: 2018-07-15 06:33:39
TRAINING STATS: batch 390/486 in epoch 860,  batch loss: 1.63631, batch accuracy: 0.55967
Time: 2018-07-15 06:33:43
TRAINING STATS: batch 440/486 in epoch 860,  batch loss: 1.69813, batch accuracy: 0.54217
Time: 2018-07-15 06:33:48
TRAINING STATS: batch 4/486 in epoch 861,    batch loss: 1.64560, batch accuracy: 0.55767
Time: 2018-07-15 06:33:51
TRAINING STATS: batch 54/486 in epoch 861,   batch loss: 1.69424, batch accuracy: 0.54383
Time: 2018-07-15 06:33:55
TRAINING STATS: batch 104/486 in epoch 861,  batch loss: 1.70594, batch accuracy: 0.54783
Time: 2018-07-15 06:34:00
TRAINING STATS: batch 154/486 in epoch 861,  batch loss: 1.66891, batch accuracy: 0.55283
Time: 2018-07-15 06:34:04
TRAINING STATS: batch 204/486 in epoch 861,  batch loss: 1.75772, batch accuracy: 0.52767
Time: 2018-07-15 06:34:07
TRAINING STATS: batch 254/486 in epoch 861,  batch loss: 1.60751, batch accuracy: 0.56350
Time: 2018-07-15 06:34:12
TRAINING STATS: batch 304/486 in epoch 861,  batch loss: 1.63651, batch accuracy: 0.55933
Time: 2018-07-15 06:34:16
TRAINING STATS: batch 354/486 in epoch 861,  batch loss: 1.71120, batch accuracy: 0.53767
Time: 2018-07-15 06:34:19
TRAINING STATS: batch 404/486 in epoch 861,  batch loss: 1.66675, batch accuracy: 0.54500
Time: 2018-07-15 06:34:24
TRAINING STATS: batch 454/486 in epoch 861,  batch loss: 1.54950, batch accuracy: 0.58217
Time: 2018-07-15 06:34:28
TRAINING STATS: batch 18/486 in epoch 862,   batch loss: 1.71818, batch accuracy: 0.53717
Time: 2018-07-15 06:34:31
TRAINING STATS: batch 68/486 in epoch 862,   batch loss: 1.54322, batch accuracy: 0.59067
Time: 2018-07-15 06:34:36
TRAINING STATS: batch 118/486 in epoch 862,  batch loss: 1.67804, batch accuracy: 0.54733
Time: 2018-07-15 06:34:40
TRAINING STATS: batch 168/486 in epoch 862,  batch loss: 1.60141, batch accuracy: 0.57650
Time: 2018-07-15 06:34:44
TRAINING STATS: batch 218/486 in epoch 862,  batch loss: 1.66408, batch accuracy: 0.54517
Time: 2018-07-15 06:34:48
TRAINING STATS: batch 268/486 in epoch 862,  batch loss: 1.63176, batch accuracy: 0.55533
Time: 2018-07-15 06:34:52
TRAINING STATS: batch 318/486 in epoch 862,  batch loss: 1.67482, batch accuracy: 0.55117
Time: 2018-07-15 06:34:56
TRAINING STATS: batch 368/486 in epoch 862,  batch loss: 1.70428, batch accuracy: 0.53967
Time: 2018-07-15 06:35:00
TRAINING STATS: batch 418/486 in epoch 862,  batch loss: 1.73317, batch accuracy: 0.52483
Time: 2018-07-15 06:35:04
TRAINING STATS: batch 468/486 in epoch 862,  batch loss: 1.67788, batch accuracy: 0.55450
Time: 2018-07-15 06:35:08
TRAINING STATS: batch 32/486 in epoch 863,   batch loss: 1.64347, batch accuracy: 0.56017
Time: 2018-07-15 06:35:12
TRAINING STATS: batch 82/486 in epoch 863,   batch loss: 1.75371, batch accuracy: 0.52767
Time: 2018-07-15 06:35:16
TRAINING STATS: batch 132/486 in epoch 863,  batch loss: 1.67095, batch accuracy: 0.56217
Time: 2018-07-15 06:35:20
TRAINING STATS: batch 182/486 in epoch 863,  batch loss: 1.73338, batch accuracy: 0.52767
Time: 2018-07-15 06:35:25
TRAINING STATS: batch 232/486 in epoch 863,  batch loss: 1.71351, batch accuracy: 0.54033
Time: 2018-07-15 06:35:28
TRAINING STATS: batch 282/486 in epoch 863,  batch loss: 1.64138, batch accuracy: 0.55483
Time: 2018-07-15 06:35:32
TRAINING STATS: batch 332/486 in epoch 863,  batch loss: 1.71943, batch accuracy: 0.53900
Time: 2018-07-15 06:35:36
TRAINING STATS: batch 382/486 in epoch 863,  batch loss: 1.70718, batch accuracy: 0.54050
Time: 2018-07-15 06:35:40
TRAINING STATS: batch 432/486 in epoch 863,  batch loss: 1.60610, batch accuracy: 0.56550
Time: 2018-07-15 06:35:44
TRAINING STATS: batch 482/486 in epoch 863,  batch loss: 1.65889, batch accuracy: 0.55500
Time: 2018-07-15 06:35:49
TRAINING STATS: batch 46/486 in epoch 864,   batch loss: 1.66059, batch accuracy: 0.55583
Time: 2018-07-15 06:35:52
TRAINING STATS: batch 96/486 in epoch 864,   batch loss: 1.71309, batch accuracy: 0.53367
Time: 2018-07-15 06:35:56
TRAINING STATS: batch 146/486 in epoch 864,  batch loss: 1.71956, batch accuracy: 0.54400
Time: 2018-07-15 06:36:01
TRAINING STATS: batch 196/486 in epoch 864,  batch loss: 1.70848, batch accuracy: 0.53850
Time: 2018-07-15 06:36:04
TRAINING STATS: batch 246/486 in epoch 864,  batch loss: 1.64373, batch accuracy: 0.55650
Time: 2018-07-15 06:36:08
TRAINING STATS: batch 296/486 in epoch 864,  batch loss: 1.65382, batch accuracy: 0.54633
Time: 2018-07-15 06:36:13
TRAINING STATS: batch 346/486 in epoch 864,  batch loss: 1.60158, batch accuracy: 0.57900
Time: 2018-07-15 06:36:16
TRAINING STATS: batch 396/486 in epoch 864,  batch loss: 1.68053, batch accuracy: 0.54800
Time: 2018-07-15 06:36:20
TRAINING STATS: batch 446/486 in epoch 864,  batch loss: 1.69608, batch accuracy: 0.54033
Time: 2018-07-15 06:36:25
TRAINING STATS: batch 10/486 in epoch 865,   batch loss: 1.72845, batch accuracy: 0.52450
Time: 2018-07-15 06:36:28
TRAINING STATS: batch 60/486 in epoch 865,   batch loss: 1.67543, batch accuracy: 0.55117
Time: 2018-07-15 06:36:32
TRAINING STATS: batch 110/486 in epoch 865,  batch loss: 1.74040, batch accuracy: 0.53483
Time: 2018-07-15 06:36:37
TRAINING STATS: batch 160/486 in epoch 865,  batch loss: 1.64535, batch accuracy: 0.55600
Time: 2018-07-15 06:36:41
TRAINING STATS: batch 210/486 in epoch 865,  batch loss: 1.64364, batch accuracy: 0.55967
Time: 2018-07-15 06:36:44
TRAINING STATS: batch 260/486 in epoch 865,  batch loss: 1.70409, batch accuracy: 0.53483
Time: 2018-07-15 06:36:49
TRAINING STATS: batch 310/486 in epoch 865,  batch loss: 1.69768, batch accuracy: 0.54217
Time: 2018-07-15 06:36:53
TRAINING STATS: batch 360/486 in epoch 865,  batch loss: 1.72627, batch accuracy: 0.52767
Time: 2018-07-15 06:36:56
TRAINING STATS: batch 410/486 in epoch 865,  batch loss: 1.63479, batch accuracy: 0.56200
Time: 2018-07-15 06:37:01
TRAINING STATS: batch 460/486 in epoch 865,  batch loss: 1.79471, batch accuracy: 0.50717
Time: 2018-07-15 06:37:05
TRAINING STATS: batch 24/486 in epoch 866,   batch loss: 1.75523, batch accuracy: 0.52467
Time: 2018-07-15 06:37:08
TRAINING STATS: batch 74/486 in epoch 866,   batch loss: 1.72179, batch accuracy: 0.53717
Time: 2018-07-15 06:37:13
TRAINING STATS: batch 124/486 in epoch 866,  batch loss: 1.71031, batch accuracy: 0.54017
Time: 2018-07-15 06:37:17
TRAINING STATS: batch 174/486 in epoch 866,  batch loss: 1.74892, batch accuracy: 0.52717
Time: 2018-07-15 06:37:21
TRAINING STATS: batch 224/486 in epoch 866,  batch loss: 1.74745, batch accuracy: 0.53067
Time: 2018-07-15 06:37:25
TRAINING STATS: batch 274/486 in epoch 866,  batch loss: 1.69455, batch accuracy: 0.54467
Time: 2018-07-15 06:37:29
TRAINING STATS: batch 324/486 in epoch 866,  batch loss: 1.72380, batch accuracy: 0.53417
Time: 2018-07-15 06:37:33
TRAINING STATS: batch 374/486 in epoch 866,  batch loss: 1.72972, batch accuracy: 0.53933
Time: 2018-07-15 06:37:37
TRAINING STATS: batch 424/486 in epoch 866,  batch loss: 1.63000, batch accuracy: 0.56600
Time: 2018-07-15 06:37:41
TRAINING STATS: batch 474/486 in epoch 866,  batch loss: 1.67519, batch accuracy: 0.54550
Time: 2018-07-15 06:37:45
TRAINING STATS: batch 38/486 in epoch 867,   batch loss: 1.70432, batch accuracy: 0.54183
Time: 2018-07-15 06:37:49
TRAINING STATS: batch 88/486 in epoch 867,   batch loss: 1.74391, batch accuracy: 0.53117
Time: 2018-07-15 06:37:53
TRAINING STATS: batch 138/486 in epoch 867,  batch loss: 1.75045, batch accuracy: 0.52850
Time: 2018-07-15 06:37:56
TRAINING STATS: batch 188/486 in epoch 867,  batch loss: 1.64159, batch accuracy: 0.56633
Time: 2018-07-15 06:38:01
TRAINING STATS: batch 238/486 in epoch 867,  batch loss: 1.66953, batch accuracy: 0.55383
Time: 2018-07-15 06:38:05
TRAINING STATS: batch 288/486 in epoch 867,  batch loss: 1.72272, batch accuracy: 0.52967
Time: 2018-07-15 06:38:09
TRAINING STATS: batch 338/486 in epoch 867,  batch loss: 1.70833, batch accuracy: 0.53350
Time: 2018-07-15 06:38:13
TRAINING STATS: batch 388/486 in epoch 867,  batch loss: 1.64753, batch accuracy: 0.55250
Time: 2018-07-15 06:38:17
TRAINING STATS: batch 438/486 in epoch 867,  batch loss: 1.70711, batch accuracy: 0.54400
Time: 2018-07-15 06:38:21
TRAINING STATS: batch 2/486 in epoch 868,    batch loss: 1.71703, batch accuracy: 0.53417
Time: 2018-07-15 06:38:25
TRAINING STATS: batch 52/486 in epoch 868,   batch loss: 1.74848, batch accuracy: 0.52167
Time: 2018-07-15 06:38:29
TRAINING STATS: batch 102/486 in epoch 868,  batch loss: 1.72021, batch accuracy: 0.53867
Time: 2018-07-15 06:38:33
TRAINING STATS: batch 152/486 in epoch 868,  batch loss: 1.65311, batch accuracy: 0.56150
Time: 2018-07-15 06:38:37
TRAINING STATS: batch 202/486 in epoch 868,  batch loss: 1.70590, batch accuracy: 0.54567
Time: 2018-07-15 06:38:41
TRAINING STATS: batch 252/486 in epoch 868,  batch loss: 1.65426, batch accuracy: 0.55317
Time: 2018-07-15 06:38:45
TRAINING STATS: batch 302/486 in epoch 868,  batch loss: 1.64931, batch accuracy: 0.55583
Time: 2018-07-15 06:38:50
TRAINING STATS: batch 352/486 in epoch 868,  batch loss: 1.66492, batch accuracy: 0.55900
Time: 2018-07-15 06:38:53
TRAINING STATS: batch 402/486 in epoch 868,  batch loss: 1.55143, batch accuracy: 0.59133
Time: 2018-07-15 06:38:57
TRAINING STATS: batch 452/486 in epoch 868,  batch loss: 1.69019, batch accuracy: 0.53700
Time: 2018-07-15 06:39:02
TRAINING STATS: batch 16/486 in epoch 869,   batch loss: 1.66000, batch accuracy: 0.55783
Time: 2018-07-15 06:39:05
TRAINING STATS: batch 66/486 in epoch 869,   batch loss: 1.69637, batch accuracy: 0.55400
Time: 2018-07-15 06:39:09
TRAINING STATS: batch 116/486 in epoch 869,  batch loss: 1.66219, batch accuracy: 0.56000
Time: 2018-07-15 06:39:14
TRAINING STATS: batch 166/486 in epoch 869,  batch loss: 1.59935, batch accuracy: 0.57867
Time: 2018-07-15 06:39:17
TRAINING STATS: batch 216/486 in epoch 869,  batch loss: 1.71871, batch accuracy: 0.54367
Time: 2018-07-15 06:39:21
TRAINING STATS: batch 266/486 in epoch 869,  batch loss: 1.70339, batch accuracy: 0.54167
Time: 2018-07-15 06:39:26
TRAINING STATS: batch 316/486 in epoch 869,  batch loss: 1.68221, batch accuracy: 0.54850
Time: 2018-07-15 06:39:29
TRAINING STATS: batch 366/486 in epoch 869,  batch loss: 1.74279, batch accuracy: 0.53583
Time: 2018-07-15 06:39:33
TRAINING STATS: batch 416/486 in epoch 869,  batch loss: 1.71589, batch accuracy: 0.53767
Time: 2018-07-15 06:39:38
TRAINING STATS: batch 466/486 in epoch 869,  batch loss: 1.55173, batch accuracy: 0.58100
Time: 2018-07-15 06:39:42
TRAINING STATS: batch 30/486 in epoch 870,   batch loss: 1.58574, batch accuracy: 0.57167
Time: 2018-07-15 06:39:45
TRAINING STATS: batch 80/486 in epoch 870,   batch loss: 1.69318, batch accuracy: 0.54383
Time: 2018-07-15 06:39:50
TRAINING STATS: batch 130/486 in epoch 870,  batch loss: 1.66444, batch accuracy: 0.55867
Time: 2018-07-15 06:39:54
TRAINING STATS: batch 180/486 in epoch 870,  batch loss: 1.71543, batch accuracy: 0.53700
Time: 2018-07-15 06:39:57
TRAINING STATS: batch 230/486 in epoch 870,  batch loss: 1.72075, batch accuracy: 0.52850
Time: 2018-07-15 06:40:02
TRAINING STATS: batch 280/486 in epoch 870,  batch loss: 1.67858, batch accuracy: 0.54550
Time: 2018-07-15 06:40:06
TRAINING STATS: batch 330/486 in epoch 870,  batch loss: 1.66085, batch accuracy: 0.55050
Time: 2018-07-15 06:40:09
TRAINING STATS: batch 380/486 in epoch 870,  batch loss: 1.65350, batch accuracy: 0.55567
Time: 2018-07-15 06:40:14
TRAINING STATS: batch 430/486 in epoch 870,  batch loss: 1.60980, batch accuracy: 0.56350
Time: 2018-07-15 06:40:18
TRAINING STATS: batch 480/486 in epoch 870,  batch loss: 1.68697, batch accuracy: 0.54500
Time: 2018-07-15 06:40:21
TRAINING STATS: batch 44/486 in epoch 871,   batch loss: 1.63528, batch accuracy: 0.56550
Time: 2018-07-15 06:40:26
TRAINING STATS: batch 94/486 in epoch 871,   batch loss: 1.73421, batch accuracy: 0.53517
Time: 2018-07-15 06:40:30
TRAINING STATS: batch 144/486 in epoch 871,  batch loss: 1.75234, batch accuracy: 0.52250
Time: 2018-07-15 06:40:33
TRAINING STATS: batch 194/486 in epoch 871,  batch loss: 1.78420, batch accuracy: 0.51867
Time: 2018-07-15 06:40:38
TRAINING STATS: batch 244/486 in epoch 871,  batch loss: 1.67712, batch accuracy: 0.55250
Time: 2018-07-15 06:40:42
TRAINING STATS: batch 294/486 in epoch 871,  batch loss: 1.59866, batch accuracy: 0.56717
Time: 2018-07-15 06:40:46
TRAINING STATS: batch 344/486 in epoch 871,  batch loss: 1.65804, batch accuracy: 0.55483
Time: 2018-07-15 06:40:50
TRAINING STATS: batch 394/486 in epoch 871,  batch loss: 1.67524, batch accuracy: 0.55417
Time: 2018-07-15 06:40:54
TRAINING STATS: batch 444/486 in epoch 871,  batch loss: 1.62832, batch accuracy: 0.56450
Time: 2018-07-15 06:40:58
TRAINING STATS: batch 8/486 in epoch 872,    batch loss: 1.68585, batch accuracy: 0.54300
Time: 2018-07-15 06:41:02
TRAINING STATS: batch 58/486 in epoch 872,   batch loss: 1.65154, batch accuracy: 0.55217
Time: 2018-07-15 06:41:06
TRAINING STATS: batch 108/486 in epoch 872,  batch loss: 1.78252, batch accuracy: 0.52317
Time: 2018-07-15 06:41:10
TRAINING STATS: batch 158/486 in epoch 872,  batch loss: 1.73334, batch accuracy: 0.53367
Time: 2018-07-15 06:41:14
TRAINING STATS: batch 208/486 in epoch 872,  batch loss: 1.72554, batch accuracy: 0.53983
Time: 2018-07-15 06:41:18
TRAINING STATS: batch 258/486 in epoch 872,  batch loss: 1.65617, batch accuracy: 0.55750
Time: 2018-07-15 06:41:22
TRAINING STATS: batch 308/486 in epoch 872,  batch loss: 1.69408, batch accuracy: 0.54733
Time: 2018-07-15 06:41:26
TRAINING STATS: batch 358/486 in epoch 872,  batch loss: 1.69601, batch accuracy: 0.54017
Time: 2018-07-15 06:41:30
TRAINING STATS: batch 408/486 in epoch 872,  batch loss: 1.74265, batch accuracy: 0.53167
Time: 2018-07-15 06:41:34
TRAINING STATS: batch 458/486 in epoch 872,  batch loss: 1.70460, batch accuracy: 0.54483
Time: 2018-07-15 06:41:38
TRAINING STATS: batch 22/486 in epoch 873,   batch loss: 1.74158, batch accuracy: 0.53600
Time: 2018-07-15 06:41:42
TRAINING STATS: batch 72/486 in epoch 873,   batch loss: 1.72951, batch accuracy: 0.52517
Time: 2018-07-15 06:41:46
TRAINING STATS: batch 122/486 in epoch 873,  batch loss: 1.67063, batch accuracy: 0.55033
Time: 2018-07-15 06:41:50
TRAINING STATS: batch 172/486 in epoch 873,  batch loss: 1.74582, batch accuracy: 0.52983
Time: 2018-07-15 06:41:54
TRAINING STATS: batch 222/486 in epoch 873,  batch loss: 1.68117, batch accuracy: 0.54283
Time: 2018-07-15 06:41:58
TRAINING STATS: batch 272/486 in epoch 873,  batch loss: 1.72404, batch accuracy: 0.52883
Time: 2018-07-15 06:42:03
TRAINING STATS: batch 322/486 in epoch 873,  batch loss: 1.66827, batch accuracy: 0.54517
Time: 2018-07-15 06:42:06
TRAINING STATS: batch 372/486 in epoch 873,  batch loss: 1.63050, batch accuracy: 0.55883
Time: 2018-07-15 06:42:10
TRAINING STATS: batch 422/486 in epoch 873,  batch loss: 1.65443, batch accuracy: 0.55483
Time: 2018-07-15 06:42:15
TRAINING STATS: batch 472/486 in epoch 873,  batch loss: 1.75131, batch accuracy: 0.52767
Time: 2018-07-15 06:42:18
TRAINING STATS: batch 36/486 in epoch 874,   batch loss: 1.74381, batch accuracy: 0.53350
Time: 2018-07-15 06:42:22
TRAINING STATS: batch 86/486 in epoch 874,   batch loss: 1.69003, batch accuracy: 0.54783
Time: 2018-07-15 06:42:27
TRAINING STATS: batch 136/486 in epoch 874,  batch loss: 1.74141, batch accuracy: 0.52683
Time: 2018-07-15 06:42:30
TRAINING STATS: batch 186/486 in epoch 874,  batch loss: 1.70348, batch accuracy: 0.53533
Time: 2018-07-15 06:42:34
TRAINING STATS: batch 236/486 in epoch 874,  batch loss: 1.72486, batch accuracy: 0.52950
Time: 2018-07-15 06:42:39
TRAINING STATS: batch 286/486 in epoch 874,  batch loss: 1.72302, batch accuracy: 0.53517
Time: 2018-07-15 06:42:42
TRAINING STATS: batch 336/486 in epoch 874,  batch loss: 1.67140, batch accuracy: 0.54683
Time: 2018-07-15 06:42:46
TRAINING STATS: batch 386/486 in epoch 874,  batch loss: 1.73271, batch accuracy: 0.52967
Time: 2018-07-15 06:42:51
TRAINING STATS: batch 436/486 in epoch 874,  batch loss: 1.70307, batch accuracy: 0.54350
Time: 2018-07-15 06:42:54
TRAINING STATS: batch 0/486 in epoch 875,    batch loss: 1.67644, batch accuracy: 0.54600
Time: 2018-07-15 06:42:58
TRAINING STATS: batch 50/486 in epoch 875,   batch loss: 1.63926, batch accuracy: 0.55617
Time: 2018-07-15 06:43:03
TRAINING STATS: batch 100/486 in epoch 875,  batch loss: 1.70097, batch accuracy: 0.54100
Time: 2018-07-15 06:43:07
TRAINING STATS: batch 150/486 in epoch 875,  batch loss: 1.64819, batch accuracy: 0.55900
Time: 2018-07-15 06:43:10
TRAINING STATS: batch 200/486 in epoch 875,  batch loss: 1.57254, batch accuracy: 0.57550
Time: 2018-07-15 06:43:15
TRAINING STATS: batch 250/486 in epoch 875,  batch loss: 1.74933, batch accuracy: 0.52583
Time: 2018-07-15 06:43:19
TRAINING STATS: batch 300/486 in epoch 875,  batch loss: 1.73201, batch accuracy: 0.53083
Time: 2018-07-15 06:43:22
TRAINING STATS: batch 350/486 in epoch 875,  batch loss: 1.69937, batch accuracy: 0.55000
Time: 2018-07-15 06:43:27
TRAINING STATS: batch 400/486 in epoch 875,  batch loss: 1.57527, batch accuracy: 0.57383
Time: 2018-07-15 06:43:31
TRAINING STATS: batch 450/486 in epoch 875,  batch loss: 1.77778, batch accuracy: 0.51217
Time: 2018-07-15 06:43:34
TRAINING STATS: batch 14/486 in epoch 876,   batch loss: 1.60893, batch accuracy: 0.57350
Time: 2018-07-15 06:43:39
TRAINING STATS: batch 64/486 in epoch 876,   batch loss: 1.78597, batch accuracy: 0.51817
Time: 2018-07-15 06:43:43
TRAINING STATS: batch 114/486 in epoch 876,  batch loss: 1.73567, batch accuracy: 0.52917
Time: 2018-07-15 06:43:46
TRAINING STATS: batch 164/486 in epoch 876,  batch loss: 1.64129, batch accuracy: 0.57050
Time: 2018-07-15 06:43:51
TRAINING STATS: batch 214/486 in epoch 876,  batch loss: 1.68298, batch accuracy: 0.54767
Time: 2018-07-15 06:43:55
TRAINING STATS: batch 264/486 in epoch 876,  batch loss: 1.81742, batch accuracy: 0.49700
Time: 2018-07-15 06:43:58
TRAINING STATS: batch 314/486 in epoch 876,  batch loss: 1.82141, batch accuracy: 0.50317
Time: 2018-07-15 06:44:03
TRAINING STATS: batch 364/486 in epoch 876,  batch loss: 1.68567, batch accuracy: 0.55150
Time: 2018-07-15 06:44:07
TRAINING STATS: batch 414/486 in epoch 876,  batch loss: 1.63798, batch accuracy: 0.55733
Time: 2018-07-15 06:44:10
TRAINING STATS: batch 464/486 in epoch 876,  batch loss: 1.67411, batch accuracy: 0.55433
Time: 2018-07-15 06:44:15
TRAINING STATS: batch 28/486 in epoch 877,   batch loss: 1.62047, batch accuracy: 0.56450
Time: 2018-07-15 06:44:19
TRAINING STATS: batch 78/486 in epoch 877,   batch loss: 1.68919, batch accuracy: 0.54467
Time: 2018-07-15 06:44:23
TRAINING STATS: batch 128/486 in epoch 877,  batch loss: 1.65551, batch accuracy: 0.55367
Time: 2018-07-15 06:44:27
TRAINING STATS: batch 178/486 in epoch 877,  batch loss: 1.58185, batch accuracy: 0.57267
Time: 2018-07-15 06:44:31
TRAINING STATS: batch 228/486 in epoch 877,  batch loss: 1.62948, batch accuracy: 0.55917
Time: 2018-07-15 06:44:35
TRAINING STATS: batch 278/486 in epoch 877,  batch loss: 1.61512, batch accuracy: 0.56450
Time: 2018-07-15 06:44:39
TRAINING STATS: batch 328/486 in epoch 877,  batch loss: 1.65735, batch accuracy: 0.55350
Time: 2018-07-15 06:44:43
TRAINING STATS: batch 378/486 in epoch 877,  batch loss: 1.68357, batch accuracy: 0.54917
Time: 2018-07-15 06:44:47
TRAINING STATS: batch 428/486 in epoch 877,  batch loss: 1.71941, batch accuracy: 0.53483
Time: 2018-07-15 06:44:52
TRAINING STATS: batch 478/486 in epoch 877,  batch loss: 1.69126, batch accuracy: 0.54217
Time: 2018-07-15 06:44:55
TRAINING STATS: batch 42/486 in epoch 878,   batch loss: 1.60378, batch accuracy: 0.56917
Time: 2018-07-15 06:44:59
TRAINING STATS: batch 92/486 in epoch 878,   batch loss: 1.69616, batch accuracy: 0.54400
Time: 2018-07-15 06:45:04
TRAINING STATS: batch 142/486 in epoch 878,  batch loss: 1.63917, batch accuracy: 0.55950
Time: 2018-07-15 06:45:07
TRAINING STATS: batch 192/486 in epoch 878,  batch loss: 1.66939, batch accuracy: 0.54667
Time: 2018-07-15 06:45:11
TRAINING STATS: batch 242/486 in epoch 878,  batch loss: 1.64662, batch accuracy: 0.55700
Time: 2018-07-15 06:45:16
TRAINING STATS: batch 292/486 in epoch 878,  batch loss: 1.66687, batch accuracy: 0.54983
Time: 2018-07-15 06:45:19
TRAINING STATS: batch 342/486 in epoch 878,  batch loss: 1.65928, batch accuracy: 0.55133
Time: 2018-07-15 06:45:23
TRAINING STATS: batch 392/486 in epoch 878,  batch loss: 1.59280, batch accuracy: 0.57450
Time: 2018-07-15 06:45:28
TRAINING STATS: batch 442/486 in epoch 878,  batch loss: 1.57964, batch accuracy: 0.57567
Time: 2018-07-15 06:45:31
TRAINING STATS: batch 6/486 in epoch 879,    batch loss: 1.71416, batch accuracy: 0.54250
Time: 2018-07-15 06:45:35
TRAINING STATS: batch 56/486 in epoch 879,   batch loss: 1.65142, batch accuracy: 0.55483
Time: 2018-07-15 06:45:40
TRAINING STATS: batch 106/486 in epoch 879,  batch loss: 1.79712, batch accuracy: 0.51483
Time: 2018-07-15 06:45:44
TRAINING STATS: batch 156/486 in epoch 879,  batch loss: 1.73310, batch accuracy: 0.53450
Time: 2018-07-15 06:45:47
TRAINING STATS: batch 206/486 in epoch 879,  batch loss: 1.76325, batch accuracy: 0.52383
Time: 2018-07-15 06:45:52
TRAINING STATS: batch 256/486 in epoch 879,  batch loss: 1.62083, batch accuracy: 0.55950
Time: 2018-07-15 06:45:55
TRAINING STATS: batch 306/486 in epoch 879,  batch loss: 1.67601, batch accuracy: 0.54950
Time: 2018-07-15 06:45:59
TRAINING STATS: batch 356/486 in epoch 879,  batch loss: 1.75714, batch accuracy: 0.52467
Time: 2018-07-15 06:46:04
TRAINING STATS: batch 406/486 in epoch 879,  batch loss: 1.76222, batch accuracy: 0.51767
Time: 2018-07-15 06:46:08
TRAINING STATS: batch 456/486 in epoch 879,  batch loss: 1.55961, batch accuracy: 0.58950
Time: 2018-07-15 06:46:11
TRAINING STATS: batch 20/486 in epoch 880,   batch loss: 1.67270, batch accuracy: 0.54683
Time: 2018-07-15 06:46:16
TRAINING STATS: batch 70/486 in epoch 880,   batch loss: 1.57969, batch accuracy: 0.57533
Time: 2018-07-15 06:46:20
TRAINING STATS: batch 120/486 in epoch 880,  batch loss: 1.61798, batch accuracy: 0.56650
Time: 2018-07-15 06:46:23
TRAINING STATS: batch 170/486 in epoch 880,  batch loss: 1.68190, batch accuracy: 0.55567
Time: 2018-07-15 06:46:28
TRAINING STATS: batch 220/486 in epoch 880,  batch loss: 1.60749, batch accuracy: 0.57650
Time: 2018-07-15 06:46:32
TRAINING STATS: batch 270/486 in epoch 880,  batch loss: 1.68490, batch accuracy: 0.53317
Time: 2018-07-15 06:46:35
TRAINING STATS: batch 320/486 in epoch 880,  batch loss: 1.63705, batch accuracy: 0.55717
Time: 2018-07-15 06:46:40
TRAINING STATS: batch 370/486 in epoch 880,  batch loss: 1.67116, batch accuracy: 0.54617
Time: 2018-07-15 06:46:44
TRAINING STATS: batch 420/486 in epoch 880,  batch loss: 1.70931, batch accuracy: 0.54133
Time: 2018-07-15 06:46:48
TRAINING STATS: batch 470/486 in epoch 880,  batch loss: 1.78674, batch accuracy: 0.51283
Time: 2018-07-15 06:46:52
TRAINING STATS: batch 34/486 in epoch 881,   batch loss: 1.69843, batch accuracy: 0.55117
Time: 2018-07-15 06:46:56
TRAINING STATS: batch 84/486 in epoch 881,   batch loss: 1.67953, batch accuracy: 0.54100
Time: 2018-07-15 06:46:59
TRAINING STATS: batch 134/486 in epoch 881,  batch loss: 1.70031, batch accuracy: 0.54433
Time: 2018-07-15 06:47:04
TRAINING STATS: batch 184/486 in epoch 881,  batch loss: 1.69727, batch accuracy: 0.54150
Time: 2018-07-15 06:47:08
TRAINING STATS: batch 234/486 in epoch 881,  batch loss: 1.74295, batch accuracy: 0.52900
Time: 2018-07-15 06:47:12
TRAINING STATS: batch 284/486 in epoch 881,  batch loss: 1.73149, batch accuracy: 0.53450
Time: 2018-07-15 06:47:16
TRAINING STATS: batch 334/486 in epoch 881,  batch loss: 1.67745, batch accuracy: 0.55067
Time: 2018-07-15 06:47:20
TRAINING STATS: batch 384/486 in epoch 881,  batch loss: 1.66330, batch accuracy: 0.55050
Time: 2018-07-15 06:47:24
TRAINING STATS: batch 434/486 in epoch 881,  batch loss: 1.74863, batch accuracy: 0.52067
Time: 2018-07-15 06:47:29
TRAINING STATS: batch 484/486 in epoch 881,  batch loss: 1.68248, batch accuracy: 0.54067
Time: 2018-07-15 06:47:32
TRAINING STATS: batch 48/486 in epoch 882,   batch loss: 1.67931, batch accuracy: 0.54533
Time: 2018-07-15 06:47:36
TRAINING STATS: batch 98/486 in epoch 882,   batch loss: 1.64193, batch accuracy: 0.55600
Time: 2018-07-15 06:47:41
TRAINING STATS: batch 148/486 in epoch 882,  batch loss: 1.71307, batch accuracy: 0.54833
Time: 2018-07-15 06:47:44
TRAINING STATS: batch 198/486 in epoch 882,  batch loss: 1.67449, batch accuracy: 0.54883
Time: 2018-07-15 06:47:48
TRAINING STATS: batch 248/486 in epoch 882,  batch loss: 1.71555, batch accuracy: 0.53933
Time: 2018-07-15 06:47:53
TRAINING STATS: batch 298/486 in epoch 882,  batch loss: 1.70446, batch accuracy: 0.53250
Time: 2018-07-15 06:47:56
TRAINING STATS: batch 348/486 in epoch 882,  batch loss: 1.69945, batch accuracy: 0.54467
Time: 2018-07-15 06:48:00
TRAINING STATS: batch 398/486 in epoch 882,  batch loss: 1.69333, batch accuracy: 0.54517
Time: 2018-07-15 06:48:05
TRAINING STATS: batch 448/486 in epoch 882,  batch loss: 1.68136, batch accuracy: 0.55067
Time: 2018-07-15 06:48:08
TRAINING STATS: batch 12/486 in epoch 883,   batch loss: 1.70619, batch accuracy: 0.53717
Time: 2018-07-15 06:48:12
TRAINING STATS: batch 62/486 in epoch 883,   batch loss: 1.75682, batch accuracy: 0.52000
Time: 2018-07-15 06:48:17
TRAINING STATS: batch 112/486 in epoch 883,  batch loss: 1.69468, batch accuracy: 0.53833
Time: 2018-07-15 06:48:20
TRAINING STATS: batch 162/486 in epoch 883,  batch loss: 1.68825, batch accuracy: 0.54700
Time: 2018-07-15 06:48:24
TRAINING STATS: batch 212/486 in epoch 883,  batch loss: 1.62646, batch accuracy: 0.56917
Time: 2018-07-15 06:48:29
TRAINING STATS: batch 262/486 in epoch 883,  batch loss: 1.75162, batch accuracy: 0.52317
Time: 2018-07-15 06:48:32
TRAINING STATS: batch 312/486 in epoch 883,  batch loss: 1.70260, batch accuracy: 0.52867
Time: 2018-07-15 06:48:36
TRAINING STATS: batch 362/486 in epoch 883,  batch loss: 1.70106, batch accuracy: 0.53717
Time: 2018-07-15 06:48:41
TRAINING STATS: batch 412/486 in epoch 883,  batch loss: 1.62003, batch accuracy: 0.56717
Time: 2018-07-15 06:48:44
TRAINING STATS: batch 462/486 in epoch 883,  batch loss: 1.70111, batch accuracy: 0.53950
Time: 2018-07-15 06:48:48
TRAINING STATS: batch 26/486 in epoch 884,   batch loss: 1.70856, batch accuracy: 0.53150
Time: 2018-07-15 06:48:53
TRAINING STATS: batch 76/486 in epoch 884,   batch loss: 1.73764, batch accuracy: 0.52967
Time: 2018-07-15 06:48:57
TRAINING STATS: batch 126/486 in epoch 884,  batch loss: 1.73778, batch accuracy: 0.52550
Time: 2018-07-15 06:49:00
TRAINING STATS: batch 176/486 in epoch 884,  batch loss: 1.62042, batch accuracy: 0.56750
Time: 2018-07-15 06:49:05
TRAINING STATS: batch 226/486 in epoch 884,  batch loss: 1.66161, batch accuracy: 0.55067
Time: 2018-07-15 06:49:09
TRAINING STATS: batch 276/486 in epoch 884,  batch loss: 1.68313, batch accuracy: 0.54167
Time: 2018-07-15 06:49:12
TRAINING STATS: batch 326/486 in epoch 884,  batch loss: 1.73139, batch accuracy: 0.53450
Time: 2018-07-15 06:49:17
TRAINING STATS: batch 376/486 in epoch 884,  batch loss: 1.70213, batch accuracy: 0.54250
Time: 2018-07-15 06:49:20
TRAINING STATS: batch 426/486 in epoch 884,  batch loss: 1.66887, batch accuracy: 0.54433
Time: 2018-07-15 06:49:24
TRAINING STATS: batch 476/486 in epoch 884,  batch loss: 1.63065, batch accuracy: 0.56317
Time: 2018-07-15 06:49:29
TRAINING STATS: batch 40/486 in epoch 885,   batch loss: 1.65105, batch accuracy: 0.55417
Time: 2018-07-15 06:49:33
TRAINING STATS: batch 90/486 in epoch 885,   batch loss: 1.72033, batch accuracy: 0.53517
Time: 2018-07-15 06:49:36
TRAINING STATS: batch 140/486 in epoch 885,  batch loss: 1.61469, batch accuracy: 0.56300
Time: 2018-07-15 06:49:41
TRAINING STATS: batch 190/486 in epoch 885,  batch loss: 1.65988, batch accuracy: 0.55150
Time: 2018-07-15 06:49:45
TRAINING STATS: batch 240/486 in epoch 885,  batch loss: 1.67222, batch accuracy: 0.54833
Time: 2018-07-15 06:49:48
TRAINING STATS: batch 290/486 in epoch 885,  batch loss: 1.70502, batch accuracy: 0.53933
Time: 2018-07-15 06:49:53
TRAINING STATS: batch 340/486 in epoch 885,  batch loss: 1.76253, batch accuracy: 0.52517
Time: 2018-07-15 06:49:57
TRAINING STATS: batch 390/486 in epoch 885,  batch loss: 1.62003, batch accuracy: 0.56733
Time: 2018-07-15 06:50:00
TRAINING STATS: batch 440/486 in epoch 885,  batch loss: 1.68470, batch accuracy: 0.54000
Time: 2018-07-15 06:50:05
TRAINING STATS: batch 4/486 in epoch 886,    batch loss: 1.63892, batch accuracy: 0.56133
Time: 2018-07-15 06:50:09
TRAINING STATS: batch 54/486 in epoch 886,   batch loss: 1.68901, batch accuracy: 0.54200
Time: 2018-07-15 06:50:13
TRAINING STATS: batch 104/486 in epoch 886,  batch loss: 1.70004, batch accuracy: 0.54250
Time: 2018-07-15 06:50:17
TRAINING STATS: batch 154/486 in epoch 886,  batch loss: 1.67415, batch accuracy: 0.55450
Time: 2018-07-15 06:50:21
TRAINING STATS: batch 204/486 in epoch 886,  batch loss: 1.74451, batch accuracy: 0.52700
Time: 2018-07-15 06:50:25
TRAINING STATS: batch 254/486 in epoch 886,  batch loss: 1.60839, batch accuracy: 0.56133
Time: 2018-07-15 06:50:29
TRAINING STATS: batch 304/486 in epoch 886,  batch loss: 1.63559, batch accuracy: 0.55783
Time: 2018-07-15 06:50:33
TRAINING STATS: batch 354/486 in epoch 886,  batch loss: 1.69468, batch accuracy: 0.54167
Time: 2018-07-15 06:50:37
TRAINING STATS: batch 404/486 in epoch 886,  batch loss: 1.66200, batch accuracy: 0.55050
Time: 2018-07-15 06:50:41
TRAINING STATS: batch 454/486 in epoch 886,  batch loss: 1.54535, batch accuracy: 0.58167
Time: 2018-07-15 06:50:45
TRAINING STATS: batch 18/486 in epoch 887,   batch loss: 1.71218, batch accuracy: 0.53983
Time: 2018-07-15 06:50:49
TRAINING STATS: batch 68/486 in epoch 887,   batch loss: 1.53415, batch accuracy: 0.58817
Time: 2018-07-15 06:50:53
TRAINING STATS: batch 118/486 in epoch 887,  batch loss: 1.66553, batch accuracy: 0.55383
Time: 2018-07-15 06:50:57
TRAINING STATS: batch 168/486 in epoch 887,  batch loss: 1.61328, batch accuracy: 0.56817
Time: 2018-07-15 06:51:01
TRAINING STATS: batch 218/486 in epoch 887,  batch loss: 1.67773, batch accuracy: 0.55133
Time: 2018-07-15 06:51:06
TRAINING STATS: batch 268/486 in epoch 887,  batch loss: 1.63914, batch accuracy: 0.55283
Time: 2018-07-15 06:51:09
TRAINING STATS: batch 318/486 in epoch 887,  batch loss: 1.67373, batch accuracy: 0.54300
Time: 2018-07-15 06:51:13
TRAINING STATS: batch 368/486 in epoch 887,  batch loss: 1.70218, batch accuracy: 0.54200
Time: 2018-07-15 06:51:18
TRAINING STATS: batch 418/486 in epoch 887,  batch loss: 1.73771, batch accuracy: 0.53050
Time: 2018-07-15 06:51:21
TRAINING STATS: batch 468/486 in epoch 887,  batch loss: 1.67700, batch accuracy: 0.54600
Time: 2018-07-15 06:51:25
TRAINING STATS: batch 32/486 in epoch 888,   batch loss: 1.65678, batch accuracy: 0.54417
Time: 2018-07-15 06:51:30
TRAINING STATS: batch 82/486 in epoch 888,   batch loss: 1.71922, batch accuracy: 0.53067
Time: 2018-07-15 06:51:33
TRAINING STATS: batch 132/486 in epoch 888,  batch loss: 1.66700, batch accuracy: 0.55700
Time: 2018-07-15 06:51:37
TRAINING STATS: batch 182/486 in epoch 888,  batch loss: 1.73740, batch accuracy: 0.53067
Time: 2018-07-15 06:51:42
TRAINING STATS: batch 232/486 in epoch 888,  batch loss: 1.71224, batch accuracy: 0.53933
Time: 2018-07-15 06:51:45
TRAINING STATS: batch 282/486 in epoch 888,  batch loss: 1.64730, batch accuracy: 0.55550
Time: 2018-07-15 06:51:49
TRAINING STATS: batch 332/486 in epoch 888,  batch loss: 1.70018, batch accuracy: 0.54050
Time: 2018-07-15 06:51:54
TRAINING STATS: batch 382/486 in epoch 888,  batch loss: 1.70948, batch accuracy: 0.54200
Time: 2018-07-15 06:51:57
TRAINING STATS: batch 432/486 in epoch 888,  batch loss: 1.76532, batch accuracy: 0.52217
Time: 2018-07-15 06:52:01
TRAINING STATS: batch 482/486 in epoch 888,  batch loss: 1.74179, batch accuracy: 0.52967
Time: 2018-07-15 06:52:06
TRAINING STATS: batch 46/486 in epoch 889,   batch loss: 1.72785, batch accuracy: 0.53917
Time: 2018-07-15 06:52:10
TRAINING STATS: batch 96/486 in epoch 889,   batch loss: 1.79989, batch accuracy: 0.51100
Time: 2018-07-15 06:52:13
TRAINING STATS: batch 146/486 in epoch 889,  batch loss: 1.80964, batch accuracy: 0.52083
Time: 2018-07-15 06:52:18
TRAINING STATS: batch 196/486 in epoch 889,  batch loss: 1.80368, batch accuracy: 0.51850
Time: 2018-07-15 06:52:22
TRAINING STATS: batch 246/486 in epoch 889,  batch loss: 1.72810, batch accuracy: 0.53700
Time: 2018-07-15 06:52:25
TRAINING STATS: batch 296/486 in epoch 889,  batch loss: 1.71320, batch accuracy: 0.53733
Time: 2018-07-15 06:52:30
TRAINING STATS: batch 346/486 in epoch 889,  batch loss: 1.69552, batch accuracy: 0.55817
Time: 2018-07-15 06:52:34
TRAINING STATS: batch 396/486 in epoch 889,  batch loss: 1.75444, batch accuracy: 0.52950
Time: 2018-07-15 06:52:37
TRAINING STATS: batch 446/486 in epoch 889,  batch loss: 1.77626, batch accuracy: 0.52783
Time: 2018-07-15 06:52:42
TRAINING STATS: batch 10/486 in epoch 890,   batch loss: 1.79178, batch accuracy: 0.52300
Time: 2018-07-15 06:52:46
TRAINING STATS: batch 60/486 in epoch 890,   batch loss: 1.75551, batch accuracy: 0.52900
Time: 2018-07-15 06:52:50
TRAINING STATS: batch 110/486 in epoch 890,  batch loss: 1.80244, batch accuracy: 0.52683
Time: 2018-07-15 06:52:54
TRAINING STATS: batch 160/486 in epoch 890,  batch loss: 1.71989, batch accuracy: 0.54033
Time: 2018-07-15 06:52:58
TRAINING STATS: batch 210/486 in epoch 890,  batch loss: 1.70999, batch accuracy: 0.54433
Time: 2018-07-15 06:53:02
TRAINING STATS: batch 260/486 in epoch 890,  batch loss: 1.77722, batch accuracy: 0.51917
Time: 2018-07-15 06:53:06
TRAINING STATS: batch 310/486 in epoch 890,  batch loss: 1.76775, batch accuracy: 0.52900
Time: 2018-07-15 06:53:10
TRAINING STATS: batch 360/486 in epoch 890,  batch loss: 1.77764, batch accuracy: 0.52050
Time: 2018-07-15 06:53:14
TRAINING STATS: batch 410/486 in epoch 890,  batch loss: 1.67785, batch accuracy: 0.55433
Time: 2018-07-15 06:53:18
TRAINING STATS: batch 460/486 in epoch 890,  batch loss: 1.85525, batch accuracy: 0.49517
Time: 2018-07-15 06:53:22
TRAINING STATS: batch 24/486 in epoch 891,   batch loss: 1.77990, batch accuracy: 0.52083
Time: 2018-07-15 06:53:26
TRAINING STATS: batch 74/486 in epoch 891,   batch loss: 1.73177, batch accuracy: 0.53483
Time: 2018-07-15 06:53:31
TRAINING STATS: batch 124/486 in epoch 891,  batch loss: 1.73024, batch accuracy: 0.54267
Time: 2018-07-15 06:53:34
TRAINING STATS: batch 174/486 in epoch 891,  batch loss: 1.76617, batch accuracy: 0.51983
Time: 2018-07-15 06:53:38
TRAINING STATS: batch 224/486 in epoch 891,  batch loss: 1.73337, batch accuracy: 0.53217
Time: 2018-07-15 06:53:43
TRAINING STATS: batch 274/486 in epoch 891,  batch loss: 1.71626, batch accuracy: 0.54383
Time: 2018-07-15 06:53:46
TRAINING STATS: batch 324/486 in epoch 891,  batch loss: 1.72709, batch accuracy: 0.53833
Time: 2018-07-15 06:53:50
TRAINING STATS: batch 374/486 in epoch 891,  batch loss: 1.72135, batch accuracy: 0.53567
Time: 2018-07-15 06:53:55
TRAINING STATS: batch 424/486 in epoch 891,  batch loss: 1.63180, batch accuracy: 0.56050
Time: 2018-07-15 06:53:58
TRAINING STATS: batch 474/486 in epoch 891,  batch loss: 1.69060, batch accuracy: 0.54367
Time: 2018-07-15 06:54:02
TRAINING STATS: batch 38/486 in epoch 892,   batch loss: 1.70682, batch accuracy: 0.54183
Time: 2018-07-15 06:54:07
TRAINING STATS: batch 88/486 in epoch 892,   batch loss: 1.74224, batch accuracy: 0.52533
Time: 2018-07-15 06:54:11
TRAINING STATS: batch 138/486 in epoch 892,  batch loss: 1.74507, batch accuracy: 0.52667
Time: 2018-07-15 06:54:14
TRAINING STATS: batch 188/486 in epoch 892,  batch loss: 1.63883, batch accuracy: 0.56317
Time: 2018-07-15 06:54:19
TRAINING STATS: batch 238/486 in epoch 892,  batch loss: 1.66665, batch accuracy: 0.55500
Time: 2018-07-15 06:54:23
TRAINING STATS: batch 288/486 in epoch 892,  batch loss: 1.72143, batch accuracy: 0.52900
Time: 2018-07-15 06:54:26
TRAINING STATS: batch 338/486 in epoch 892,  batch loss: 1.70976, batch accuracy: 0.53433
Time: 2018-07-15 06:54:31
TRAINING STATS: batch 388/486 in epoch 892,  batch loss: 1.64542, batch accuracy: 0.55150
Time: 2018-07-15 06:54:35
TRAINING STATS: batch 438/486 in epoch 892,  batch loss: 1.69793, batch accuracy: 0.54167
Time: 2018-07-15 06:54:38
TRAINING STATS: batch 2/486 in epoch 893,    batch loss: 1.69846, batch accuracy: 0.54500
Time: 2018-07-15 06:54:43
TRAINING STATS: batch 52/486 in epoch 893,   batch loss: 1.76225, batch accuracy: 0.52033
Time: 2018-07-15 06:54:47
TRAINING STATS: batch 102/486 in epoch 893,  batch loss: 1.72182, batch accuracy: 0.53617
Time: 2018-07-15 06:54:50
TRAINING STATS: batch 152/486 in epoch 893,  batch loss: 1.64754, batch accuracy: 0.55983
Time: 2018-07-15 06:54:55
TRAINING STATS: batch 202/486 in epoch 893,  batch loss: 1.68021, batch accuracy: 0.54883
Time: 2018-07-15 06:54:59
TRAINING STATS: batch 252/486 in epoch 893,  batch loss: 1.64799, batch accuracy: 0.54900
Time: 2018-07-15 06:55:03
TRAINING STATS: batch 302/486 in epoch 893,  batch loss: 1.64532, batch accuracy: 0.55617
Time: 2018-07-15 06:55:07
TRAINING STATS: batch 352/486 in epoch 893,  batch loss: 1.68179, batch accuracy: 0.54933
Time: 2018-07-15 06:55:11
TRAINING STATS: batch 402/486 in epoch 893,  batch loss: 1.55530, batch accuracy: 0.58450
Time: 2018-07-15 06:55:15
TRAINING STATS: batch 452/486 in epoch 893,  batch loss: 1.67498, batch accuracy: 0.54350
Time: 2018-07-15 06:55:19
TRAINING STATS: batch 16/486 in epoch 894,   batch loss: 1.66850, batch accuracy: 0.54517
Time: 2018-07-15 06:55:23
TRAINING STATS: batch 66/486 in epoch 894,   batch loss: 1.70139, batch accuracy: 0.53683
Time: 2018-07-15 06:55:27
TRAINING STATS: batch 116/486 in epoch 894,  batch loss: 1.65004, batch accuracy: 0.55600
Time: 2018-07-15 06:55:32
TRAINING STATS: batch 166/486 in epoch 894,  batch loss: 1.60544, batch accuracy: 0.56650
Time: 2018-07-15 06:55:35
TRAINING STATS: batch 216/486 in epoch 894,  batch loss: 1.69700, batch accuracy: 0.54517
Time: 2018-07-15 06:55:39
TRAINING STATS: batch 266/486 in epoch 894,  batch loss: 1.67657, batch accuracy: 0.54417
Time: 2018-07-15 06:55:44
TRAINING STATS: batch 316/486 in epoch 894,  batch loss: 1.69475, batch accuracy: 0.53783
Time: 2018-07-15 06:55:47
TRAINING STATS: batch 366/486 in epoch 894,  batch loss: 1.74179, batch accuracy: 0.53133
Time: 2018-07-15 06:55:51
TRAINING STATS: batch 416/486 in epoch 894,  batch loss: 1.71396, batch accuracy: 0.54183
Time: 2018-07-15 06:55:56
TRAINING STATS: batch 466/486 in epoch 894,  batch loss: 1.55652, batch accuracy: 0.58317
Time: 2018-07-15 06:55:59
TRAINING STATS: batch 30/486 in epoch 895,   batch loss: 1.57696, batch accuracy: 0.56900
Time: 2018-07-15 06:56:03
TRAINING STATS: batch 80/486 in epoch 895,   batch loss: 1.68421, batch accuracy: 0.53983
Time: 2018-07-15 06:56:08
TRAINING STATS: batch 130/486 in epoch 895,  batch loss: 1.66022, batch accuracy: 0.55700
Time: 2018-07-15 06:56:11
TRAINING STATS: batch 180/486 in epoch 895,  batch loss: 1.71099, batch accuracy: 0.54067
Time: 2018-07-15 06:56:15
TRAINING STATS: batch 230/486 in epoch 895,  batch loss: 1.70749, batch accuracy: 0.53083
Time: 2018-07-15 06:56:20
TRAINING STATS: batch 280/486 in epoch 895,  batch loss: 1.67097, batch accuracy: 0.54767
Time: 2018-07-15 06:56:23
TRAINING STATS: batch 330/486 in epoch 895,  batch loss: 1.66153, batch accuracy: 0.55333
Time: 2018-07-15 06:56:27
TRAINING STATS: batch 380/486 in epoch 895,  batch loss: 1.66155, batch accuracy: 0.55700
Time: 2018-07-15 06:56:32
TRAINING STATS: batch 430/486 in epoch 895,  batch loss: 1.61612, batch accuracy: 0.56917
Time: 2018-07-15 06:56:35
TRAINING STATS: batch 480/486 in epoch 895,  batch loss: 1.68588, batch accuracy: 0.54833
Time: 2018-07-15 06:56:39
TRAINING STATS: batch 44/486 in epoch 896,   batch loss: 1.62361, batch accuracy: 0.56283
Time: 2018-07-15 06:56:44
TRAINING STATS: batch 94/486 in epoch 896,   batch loss: 1.72715, batch accuracy: 0.54167
Time: 2018-07-15 06:56:48
TRAINING STATS: batch 144/486 in epoch 896,  batch loss: 1.73553, batch accuracy: 0.53083
Time: 2018-07-15 06:56:51
TRAINING STATS: batch 194/486 in epoch 896,  batch loss: 1.77210, batch accuracy: 0.51433
Time: 2018-07-15 06:56:56
TRAINING STATS: batch 244/486 in epoch 896,  batch loss: 1.65571, batch accuracy: 0.55450
Time: 2018-07-15 06:57:00
TRAINING STATS: batch 294/486 in epoch 896,  batch loss: 1.60753, batch accuracy: 0.56800
Time: 2018-07-15 06:57:03
TRAINING STATS: batch 344/486 in epoch 896,  batch loss: 1.66800, batch accuracy: 0.54450
Time: 2018-07-15 06:57:08
TRAINING STATS: batch 394/486 in epoch 896,  batch loss: 1.64978, batch accuracy: 0.55767
Time: 2018-07-15 06:57:12
TRAINING STATS: batch 444/486 in epoch 896,  batch loss: 1.62590, batch accuracy: 0.56083
Time: 2018-07-15 06:57:15
TRAINING STATS: batch 8/486 in epoch 897,    batch loss: 1.67051, batch accuracy: 0.54400
Time: 2018-07-15 06:57:20
TRAINING STATS: batch 58/486 in epoch 897,   batch loss: 1.64811, batch accuracy: 0.55733
Time: 2018-07-15 06:57:24
TRAINING STATS: batch 108/486 in epoch 897,  batch loss: 1.74577, batch accuracy: 0.53083
Time: 2018-07-15 06:57:28
TRAINING STATS: batch 158/486 in epoch 897,  batch loss: 1.73659, batch accuracy: 0.53150
Time: 2018-07-15 06:57:32
TRAINING STATS: batch 208/486 in epoch 897,  batch loss: 1.70679, batch accuracy: 0.54183
Time: 2018-07-15 06:57:36
TRAINING STATS: batch 258/486 in epoch 897,  batch loss: 1.64474, batch accuracy: 0.55583
Time: 2018-07-15 06:57:40
TRAINING STATS: batch 308/486 in epoch 897,  batch loss: 1.69641, batch accuracy: 0.54717
Time: 2018-07-15 06:57:44
TRAINING STATS: batch 358/486 in epoch 897,  batch loss: 1.72680, batch accuracy: 0.53883
Time: 2018-07-15 06:57:48
TRAINING STATS: batch 408/486 in epoch 897,  batch loss: 1.72153, batch accuracy: 0.52617
Time: 2018-07-15 06:57:52
TRAINING STATS: batch 458/486 in epoch 897,  batch loss: 1.70469, batch accuracy: 0.54400
Time: 2018-07-15 06:57:56
TRAINING STATS: batch 22/486 in epoch 898,   batch loss: 1.72264, batch accuracy: 0.54050
Time: 2018-07-15 06:58:00
TRAINING STATS: batch 72/486 in epoch 898,   batch loss: 1.72512, batch accuracy: 0.52150
Time: 2018-07-15 06:58:04
TRAINING STATS: batch 122/486 in epoch 898,  batch loss: 1.63236, batch accuracy: 0.56017
Time: 2018-07-15 06:58:08
TRAINING STATS: batch 172/486 in epoch 898,  batch loss: 1.73465, batch accuracy: 0.52917
Time: 2018-07-15 06:58:12
TRAINING STATS: batch 222/486 in epoch 898,  batch loss: 1.68597, batch accuracy: 0.53633
Time: 2018-07-15 06:58:16
TRAINING STATS: batch 272/486 in epoch 898,  batch loss: 1.70428, batch accuracy: 0.53233
Time: 2018-07-15 06:58:20
TRAINING STATS: batch 322/486 in epoch 898,  batch loss: 1.67129, batch accuracy: 0.54367
Time: 2018-07-15 06:58:24
TRAINING STATS: batch 372/486 in epoch 898,  batch loss: 1.62502, batch accuracy: 0.55517
Time: 2018-07-15 06:58:28
TRAINING STATS: batch 422/486 in epoch 898,  batch loss: 1.66216, batch accuracy: 0.55083
Time: 2018-07-15 06:58:32
TRAINING STATS: batch 472/486 in epoch 898,  batch loss: 1.72583, batch accuracy: 0.53117
Time: 2018-07-15 06:58:36
TRAINING STATS: batch 36/486 in epoch 899,   batch loss: 1.73462, batch accuracy: 0.52833
Time: 2018-07-15 06:58:40
TRAINING STATS: batch 86/486 in epoch 899,   batch loss: 1.70541, batch accuracy: 0.54867
Time: 2018-07-15 06:58:44
TRAINING STATS: batch 136/486 in epoch 899,  batch loss: 1.73104, batch accuracy: 0.52983
Time: 2018-07-15 06:58:48
TRAINING STATS: batch 186/486 in epoch 899,  batch loss: 1.70424, batch accuracy: 0.54317
Time: 2018-07-15 06:58:52
TRAINING STATS: batch 236/486 in epoch 899,  batch loss: 1.74546, batch accuracy: 0.51867
Time: 2018-07-15 06:58:57
TRAINING STATS: batch 286/486 in epoch 899,  batch loss: 1.71343, batch accuracy: 0.54067
Time: 2018-07-15 06:59:00
TRAINING STATS: batch 336/486 in epoch 899,  batch loss: 1.66448, batch accuracy: 0.54450
Time: 2018-07-15 06:59:04
TRAINING STATS: batch 386/486 in epoch 899,  batch loss: 1.72684, batch accuracy: 0.53450
Time: 2018-07-15 06:59:09
TRAINING STATS: batch 436/486 in epoch 899,  batch loss: 1.69974, batch accuracy: 0.54733
Time: 2018-07-15 06:59:12
TRAINING STATS: batch 0/486 in epoch 900,    batch loss: 1.67691, batch accuracy: 0.55200
Time: 2018-07-15 06:59:16
TRAINING STATS: batch 50/486 in epoch 900,   batch loss: 1.63858, batch accuracy: 0.55383
Time: 2018-07-15 06:59:21
TRAINING STATS: batch 100/486 in epoch 900,  batch loss: 1.70023, batch accuracy: 0.54367
Time: 2018-07-15 06:59:24
TRAINING STATS: batch 150/486 in epoch 900,  batch loss: 1.68547, batch accuracy: 0.54750
Time: 2018-07-15 06:59:28
TRAINING STATS: batch 200/486 in epoch 900,  batch loss: 1.57436, batch accuracy: 0.57700
Time: 2018-07-15 06:59:33
TRAINING STATS: batch 250/486 in epoch 900,  batch loss: 1.75032, batch accuracy: 0.52067
Time: 2018-07-15 06:59:37
TRAINING STATS: batch 300/486 in epoch 900,  batch loss: 1.72174, batch accuracy: 0.52617
Time: 2018-07-15 06:59:40
TRAINING STATS: batch 350/486 in epoch 900,  batch loss: 1.68901, batch accuracy: 0.54650
Time: 2018-07-15 06:59:45
TRAINING STATS: batch 400/486 in epoch 900,  batch loss: 1.58000, batch accuracy: 0.57450
Time: 2018-07-15 06:59:48
TRAINING STATS: batch 450/486 in epoch 900,  batch loss: 1.74053, batch accuracy: 0.52167
Time: 2018-07-15 06:59:52
TRAINING STATS: batch 14/486 in epoch 901,   batch loss: 1.61694, batch accuracy: 0.56950
Time: 2018-07-15 06:59:57
TRAINING STATS: batch 64/486 in epoch 901,   batch loss: 1.78726, batch accuracy: 0.52050
Time: 2018-07-15 07:00:00
TRAINING STATS: batch 114/486 in epoch 901,  batch loss: 1.72805, batch accuracy: 0.53400
Time: 2018-07-15 07:00:04
TRAINING STATS: batch 164/486 in epoch 901,  batch loss: 1.62625, batch accuracy: 0.57167
Time: 2018-07-15 07:00:09
TRAINING STATS: batch 214/486 in epoch 901,  batch loss: 1.67169, batch accuracy: 0.54883
Time: 2018-07-15 07:00:13
TRAINING STATS: batch 264/486 in epoch 901,  batch loss: 1.73270, batch accuracy: 0.52533
Time: 2018-07-15 07:00:16
TRAINING STATS: batch 314/486 in epoch 901,  batch loss: 1.75194, batch accuracy: 0.52267
Time: 2018-07-15 07:00:21
TRAINING STATS: batch 364/486 in epoch 901,  batch loss: 1.67183, batch accuracy: 0.54717
Time: 2018-07-15 07:00:25
TRAINING STATS: batch 414/486 in epoch 901,  batch loss: 1.61751, batch accuracy: 0.56133
Time: 2018-07-15 07:00:28
TRAINING STATS: batch 464/486 in epoch 901,  batch loss: 1.64111, batch accuracy: 0.55817
Time: 2018-07-15 07:00:33
TRAINING STATS: batch 28/486 in epoch 902,   batch loss: 1.61298, batch accuracy: 0.56400
Time: 2018-07-15 07:00:37
TRAINING STATS: batch 78/486 in epoch 902,   batch loss: 1.66832, batch accuracy: 0.55133
Time: 2018-07-15 07:00:40
TRAINING STATS: batch 128/486 in epoch 902,  batch loss: 1.66246, batch accuracy: 0.55317
Time: 2018-07-15 07:00:45
TRAINING STATS: batch 178/486 in epoch 902,  batch loss: 1.58631, batch accuracy: 0.57883
Time: 2018-07-15 07:00:49
TRAINING STATS: batch 228/486 in epoch 902,  batch loss: 1.63105, batch accuracy: 0.55983
Time: 2018-07-15 07:00:53
TRAINING STATS: batch 278/486 in epoch 902,  batch loss: 1.62495, batch accuracy: 0.56417
Time: 2018-07-15 07:00:57
TRAINING STATS: batch 328/486 in epoch 902,  batch loss: 1.63976, batch accuracy: 0.55917
Time: 2018-07-15 07:01:01
TRAINING STATS: batch 378/486 in epoch 902,  batch loss: 1.68903, batch accuracy: 0.54683
Time: 2018-07-15 07:01:05
TRAINING STATS: batch 428/486 in epoch 902,  batch loss: 1.72135, batch accuracy: 0.52867
Time: 2018-07-15 07:01:09
TRAINING STATS: batch 478/486 in epoch 902,  batch loss: 1.68853, batch accuracy: 0.54583
Time: 2018-07-15 07:01:13
TRAINING STATS: batch 42/486 in epoch 903,   batch loss: 1.58842, batch accuracy: 0.57133
Time: 2018-07-15 07:01:17
TRAINING STATS: batch 92/486 in epoch 903,   batch loss: 1.70075, batch accuracy: 0.53983
Time: 2018-07-15 07:01:21
TRAINING STATS: batch 142/486 in epoch 903,  batch loss: 1.63141, batch accuracy: 0.55817
Time: 2018-07-15 07:01:25
TRAINING STATS: batch 192/486 in epoch 903,  batch loss: 1.66557, batch accuracy: 0.55133
Time: 2018-07-15 07:01:29
TRAINING STATS: batch 242/486 in epoch 903,  batch loss: 1.64325, batch accuracy: 0.55750
Time: 2018-07-15 07:01:34
TRAINING STATS: batch 292/486 in epoch 903,  batch loss: 1.66725, batch accuracy: 0.55033
Time: 2018-07-15 07:01:37
TRAINING STATS: batch 342/486 in epoch 903,  batch loss: 1.67660, batch accuracy: 0.54883
Time: 2018-07-15 07:01:41
TRAINING STATS: batch 392/486 in epoch 903,  batch loss: 1.59685, batch accuracy: 0.57250
Time: 2018-07-15 07:01:46
TRAINING STATS: batch 442/486 in epoch 903,  batch loss: 1.58612, batch accuracy: 0.57033
Time: 2018-07-15 07:01:49
TRAINING STATS: batch 6/486 in epoch 904,    batch loss: 1.71242, batch accuracy: 0.54100
Time: 2018-07-15 07:01:53
TRAINING STATS: batch 56/486 in epoch 904,   batch loss: 1.64784, batch accuracy: 0.55100
Time: 2018-07-15 07:01:58
TRAINING STATS: batch 106/486 in epoch 904,  batch loss: 1.74576, batch accuracy: 0.52950
Time: 2018-07-15 07:02:01
TRAINING STATS: batch 156/486 in epoch 904,  batch loss: 1.70529, batch accuracy: 0.54167
Time: 2018-07-15 07:02:05
TRAINING STATS: batch 206/486 in epoch 904,  batch loss: 1.75747, batch accuracy: 0.52483
Time: 2018-07-15 07:02:10
TRAINING STATS: batch 256/486 in epoch 904,  batch loss: 1.62436, batch accuracy: 0.55617
Time: 2018-07-15 07:02:13
TRAINING STATS: batch 306/486 in epoch 904,  batch loss: 1.67208, batch accuracy: 0.54767
Time: 2018-07-15 07:02:17
TRAINING STATS: batch 356/486 in epoch 904,  batch loss: 1.71927, batch accuracy: 0.53467
Time: 2018-07-15 07:02:22
TRAINING STATS: batch 406/486 in epoch 904,  batch loss: 1.75902, batch accuracy: 0.51750
Time: 2018-07-15 07:02:26
TRAINING STATS: batch 456/486 in epoch 904,  batch loss: 1.56150, batch accuracy: 0.58400
Time: 2018-07-15 07:02:29
TRAINING STATS: batch 20/486 in epoch 905,   batch loss: 1.68992, batch accuracy: 0.54283
Time: 2018-07-15 07:02:34
TRAINING STATS: batch 70/486 in epoch 905,   batch loss: 1.56799, batch accuracy: 0.58100
Time: 2018-07-15 07:02:38
TRAINING STATS: batch 120/486 in epoch 905,  batch loss: 1.61321, batch accuracy: 0.56950
Time: 2018-07-15 07:02:41
TRAINING STATS: batch 170/486 in epoch 905,  batch loss: 1.67623, batch accuracy: 0.55450
Time: 2018-07-15 07:02:46
TRAINING STATS: batch 220/486 in epoch 905,  batch loss: 1.60687, batch accuracy: 0.57233
Time: 2018-07-15 07:02:50
TRAINING STATS: batch 270/486 in epoch 905,  batch loss: 1.69003, batch accuracy: 0.53117
Time: 2018-07-15 07:02:54
TRAINING STATS: batch 320/486 in epoch 905,  batch loss: 1.61472, batch accuracy: 0.56217
Time: 2018-07-15 07:02:58
TRAINING STATS: batch 370/486 in epoch 905,  batch loss: 1.67875, batch accuracy: 0.54750
Time: 2018-07-15 07:03:02
TRAINING STATS: batch 420/486 in epoch 905,  batch loss: 1.71483, batch accuracy: 0.54133
Time: 2018-07-15 07:03:06
TRAINING STATS: batch 470/486 in epoch 905,  batch loss: 1.77249, batch accuracy: 0.51833
Time: 2018-07-15 07:03:10
TRAINING STATS: batch 34/486 in epoch 906,   batch loss: 1.68301, batch accuracy: 0.54800
Time: 2018-07-15 07:03:14
TRAINING STATS: batch 84/486 in epoch 906,   batch loss: 1.69035, batch accuracy: 0.53650
Time: 2018-07-15 07:03:18
TRAINING STATS: batch 134/486 in epoch 906,  batch loss: 1.71602, batch accuracy: 0.53933
Time: 2018-07-15 07:03:22
TRAINING STATS: batch 184/486 in epoch 906,  batch loss: 1.70959, batch accuracy: 0.54100
Time: 2018-07-15 07:03:26
TRAINING STATS: batch 234/486 in epoch 906,  batch loss: 1.74911, batch accuracy: 0.51883
Time: 2018-07-15 07:03:30
TRAINING STATS: batch 284/486 in epoch 906,  batch loss: 1.72737, batch accuracy: 0.52917
Time: 2018-07-15 07:03:35
TRAINING STATS: batch 334/486 in epoch 906,  batch loss: 1.68053, batch accuracy: 0.55217
Time: 2018-07-15 07:03:38
TRAINING STATS: batch 384/486 in epoch 906,  batch loss: 1.66247, batch accuracy: 0.55150
Time: 2018-07-15 07:03:42
TRAINING STATS: batch 434/486 in epoch 906,  batch loss: 1.72691, batch accuracy: 0.52567
Time: 2018-07-15 07:03:47
TRAINING STATS: batch 484/486 in epoch 906,  batch loss: 1.68456, batch accuracy: 0.54300
Time: 2018-07-15 07:03:50
TRAINING STATS: batch 48/486 in epoch 907,   batch loss: 1.67881, batch accuracy: 0.53883
Time: 2018-07-15 07:03:54
TRAINING STATS: batch 98/486 in epoch 907,   batch loss: 1.63660, batch accuracy: 0.56083
Time: 2018-07-15 07:03:59
TRAINING STATS: batch 148/486 in epoch 907,  batch loss: 1.71720, batch accuracy: 0.53900
Time: 2018-07-15 07:04:02
TRAINING STATS: batch 198/486 in epoch 907,  batch loss: 1.66704, batch accuracy: 0.54900
Time: 2018-07-15 07:04:06
TRAINING STATS: batch 248/486 in epoch 907,  batch loss: 1.70059, batch accuracy: 0.54083
Time: 2018-07-15 07:04:11
TRAINING STATS: batch 298/486 in epoch 907,  batch loss: 1.70146, batch accuracy: 0.53833
Time: 2018-07-15 07:04:15
TRAINING STATS: batch 348/486 in epoch 907,  batch loss: 1.68004, batch accuracy: 0.54833
Time: 2018-07-15 07:04:18
TRAINING STATS: batch 398/486 in epoch 907,  batch loss: 1.68299, batch accuracy: 0.54183
Time: 2018-07-15 07:04:23
TRAINING STATS: batch 448/486 in epoch 907,  batch loss: 1.67612, batch accuracy: 0.54833
Time: 2018-07-15 07:04:27
TRAINING STATS: batch 12/486 in epoch 908,   batch loss: 1.70250, batch accuracy: 0.54050
Time: 2018-07-15 07:04:30
TRAINING STATS: batch 62/486 in epoch 908,   batch loss: 1.75393, batch accuracy: 0.52500
Time: 2018-07-15 07:04:35
TRAINING STATS: batch 112/486 in epoch 908,  batch loss: 1.66752, batch accuracy: 0.54550
Time: 2018-07-15 07:04:39
TRAINING STATS: batch 162/486 in epoch 908,  batch loss: 1.68325, batch accuracy: 0.54450
Time: 2018-07-15 07:04:42
TRAINING STATS: batch 212/486 in epoch 908,  batch loss: 1.60541, batch accuracy: 0.56367
Time: 2018-07-15 07:04:47
TRAINING STATS: batch 262/486 in epoch 908,  batch loss: 1.73938, batch accuracy: 0.52450
Time: 2018-07-15 07:04:51
TRAINING STATS: batch 312/486 in epoch 908,  batch loss: 1.67645, batch accuracy: 0.54033
Time: 2018-07-15 07:04:54
TRAINING STATS: batch 362/486 in epoch 908,  batch loss: 1.68315, batch accuracy: 0.54300
Time: 2018-07-15 07:04:59
TRAINING STATS: batch 412/486 in epoch 908,  batch loss: 1.84229, batch accuracy: 0.49900
Time: 2018-07-15 07:05:03
TRAINING STATS: batch 462/486 in epoch 908,  batch loss: 1.83904, batch accuracy: 0.50033
Time: 2018-07-15 07:05:06
TRAINING STATS: batch 26/486 in epoch 909,   batch loss: 1.86815, batch accuracy: 0.49550
Time: 2018-07-15 07:05:11
TRAINING STATS: batch 76/486 in epoch 909,   batch loss: 1.86545, batch accuracy: 0.49550
Time: 2018-07-15 07:05:15
TRAINING STATS: batch 126/486 in epoch 909,  batch loss: 1.83666, batch accuracy: 0.50700
Time: 2018-07-15 07:05:18
TRAINING STATS: batch 176/486 in epoch 909,  batch loss: 1.73764, batch accuracy: 0.53267
Time: 2018-07-15 07:05:23
TRAINING STATS: batch 226/486 in epoch 909,  batch loss: 1.79130, batch accuracy: 0.51650
Time: 2018-07-15 07:05:27
TRAINING STATS: batch 276/486 in epoch 909,  batch loss: 1.79990, batch accuracy: 0.51333
Time: 2018-07-15 07:05:31
TRAINING STATS: batch 326/486 in epoch 909,  batch loss: 1.84243, batch accuracy: 0.49917
Time: 2018-07-15 07:05:35
TRAINING STATS: batch 376/486 in epoch 909,  batch loss: 1.83704, batch accuracy: 0.50383
Time: 2018-07-15 07:05:39
TRAINING STATS: batch 426/486 in epoch 909,  batch loss: 1.77053, batch accuracy: 0.52033
Time: 2018-07-15 07:05:43
TRAINING STATS: batch 476/486 in epoch 909,  batch loss: 1.77749, batch accuracy: 0.52450
Time: 2018-07-15 07:05:48
TRAINING STATS: batch 40/486 in epoch 910,   batch loss: 1.77354, batch accuracy: 0.52633
Time: 2018-07-15 07:05:51
TRAINING STATS: batch 90/486 in epoch 910,   batch loss: 1.83799, batch accuracy: 0.50183
Time: 2018-07-15 07:05:55
TRAINING STATS: batch 140/486 in epoch 910,  batch loss: 1.72077, batch accuracy: 0.54117
Time: 2018-07-15 07:06:00
TRAINING STATS: batch 190/486 in epoch 910,  batch loss: 1.77202, batch accuracy: 0.52950
Time: 2018-07-15 07:06:03
TRAINING STATS: batch 240/486 in epoch 910,  batch loss: 1.76264, batch accuracy: 0.52767
Time: 2018-07-15 07:06:07
TRAINING STATS: batch 290/486 in epoch 910,  batch loss: 1.80703, batch accuracy: 0.50700
Time: 2018-07-15 07:06:12
TRAINING STATS: batch 340/486 in epoch 910,  batch loss: 1.87154, batch accuracy: 0.49550
Time: 2018-07-15 07:06:15
TRAINING STATS: batch 390/486 in epoch 910,  batch loss: 1.71961, batch accuracy: 0.53933
Time: 2018-07-15 07:06:19
TRAINING STATS: batch 440/486 in epoch 910,  batch loss: 1.78035, batch accuracy: 0.51933
Time: 2018-07-15 07:06:24
TRAINING STATS: batch 4/486 in epoch 911,    batch loss: 1.73969, batch accuracy: 0.53733
Time: 2018-07-15 07:06:27
TRAINING STATS: batch 54/486 in epoch 911,   batch loss: 1.78748, batch accuracy: 0.52233
Time: 2018-07-15 07:06:31
TRAINING STATS: batch 104/486 in epoch 911,  batch loss: 1.79542, batch accuracy: 0.51850
Time: 2018-07-15 07:06:36
TRAINING STATS: batch 154/486 in epoch 911,  batch loss: 1.77578, batch accuracy: 0.52183
Time: 2018-07-15 07:06:40
TRAINING STATS: batch 204/486 in epoch 911,  batch loss: 1.85559, batch accuracy: 0.49967
Time: 2018-07-15 07:06:43
TRAINING STATS: batch 254/486 in epoch 911,  batch loss: 1.70930, batch accuracy: 0.53683
Time: 2018-07-15 07:06:48
TRAINING STATS: batch 304/486 in epoch 911,  batch loss: 1.73072, batch accuracy: 0.53850
Time: 2018-07-15 07:06:52
TRAINING STATS: batch 354/486 in epoch 911,  batch loss: 1.78601, batch accuracy: 0.51750
Time: 2018-07-15 07:06:55
TRAINING STATS: batch 404/486 in epoch 911,  batch loss: 1.76125, batch accuracy: 0.52350
Time: 2018-07-15 07:07:00
TRAINING STATS: batch 454/486 in epoch 911,  batch loss: 1.63579, batch accuracy: 0.56733
Time: 2018-07-15 07:07:04
TRAINING STATS: batch 18/486 in epoch 912,   batch loss: 1.78863, batch accuracy: 0.52167
Time: 2018-07-15 07:07:07
TRAINING STATS: batch 68/486 in epoch 912,   batch loss: 1.64274, batch accuracy: 0.56017
Time: 2018-07-15 07:07:12
TRAINING STATS: batch 118/486 in epoch 912,  batch loss: 1.76376, batch accuracy: 0.52550
Time: 2018-07-15 07:07:16
TRAINING STATS: batch 168/486 in epoch 912,  batch loss: 1.71139, batch accuracy: 0.54233
Time: 2018-07-15 07:07:20
TRAINING STATS: batch 218/486 in epoch 912,  batch loss: 1.74890, batch accuracy: 0.52700
Time: 2018-07-15 07:07:24
TRAINING STATS: batch 268/486 in epoch 912,  batch loss: 1.72305, batch accuracy: 0.52867
Time: 2018-07-15 07:07:28
TRAINING STATS: batch 318/486 in epoch 912,  batch loss: 1.76760, batch accuracy: 0.52767
Time: 2018-07-15 07:07:32
TRAINING STATS: batch 368/486 in epoch 912,  batch loss: 1.78797, batch accuracy: 0.52250
Time: 2018-07-15 07:07:36
TRAINING STATS: batch 418/486 in epoch 912,  batch loss: 1.83398, batch accuracy: 0.50783
Time: 2018-07-15 07:07:40
TRAINING STATS: batch 468/486 in epoch 912,  batch loss: 1.77232, batch accuracy: 0.52433
Time: 2018-07-15 07:07:44
TRAINING STATS: batch 32/486 in epoch 913,   batch loss: 1.70507, batch accuracy: 0.54733
Time: 2018-07-15 07:07:48
TRAINING STATS: batch 82/486 in epoch 913,   batch loss: 1.78339, batch accuracy: 0.51433
Time: 2018-07-15 07:07:52
TRAINING STATS: batch 132/486 in epoch 913,  batch loss: 1.74965, batch accuracy: 0.53733
Time: 2018-07-15 07:07:56
TRAINING STATS: batch 182/486 in epoch 913,  batch loss: 1.79896, batch accuracy: 0.52083
Time: 2018-07-15 07:08:01
TRAINING STATS: batch 232/486 in epoch 913,  batch loss: 1.77132, batch accuracy: 0.52383
Time: 2018-07-15 07:08:04
TRAINING STATS: batch 282/486 in epoch 913,  batch loss: 1.69899, batch accuracy: 0.53767
Time: 2018-07-15 07:08:08
TRAINING STATS: batch 332/486 in epoch 913,  batch loss: 1.75387, batch accuracy: 0.53333
Time: 2018-07-15 07:08:13
TRAINING STATS: batch 382/486 in epoch 913,  batch loss: 1.74500, batch accuracy: 0.53583
Time: 2018-07-15 07:08:16
TRAINING STATS: batch 432/486 in epoch 913,  batch loss: 1.64568, batch accuracy: 0.56150
Time: 2018-07-15 07:08:20
TRAINING STATS: batch 482/486 in epoch 913,  batch loss: 1.70926, batch accuracy: 0.53733
Time: 2018-07-15 07:08:25
TRAINING STATS: batch 46/486 in epoch 914,   batch loss: 1.67473, batch accuracy: 0.55400
Time: 2018-07-15 07:08:28
TRAINING STATS: batch 96/486 in epoch 914,   batch loss: 1.74478, batch accuracy: 0.53250
Time: 2018-07-15 07:08:32
TRAINING STATS: batch 146/486 in epoch 914,  batch loss: 1.75538, batch accuracy: 0.53133
Time: 2018-07-15 07:08:37
TRAINING STATS: batch 196/486 in epoch 914,  batch loss: 1.74540, batch accuracy: 0.53183
Time: 2018-07-15 07:08:40
TRAINING STATS: batch 246/486 in epoch 914,  batch loss: 1.67328, batch accuracy: 0.55400
Time: 2018-07-15 07:08:44
TRAINING STATS: batch 296/486 in epoch 914,  batch loss: 1.67929, batch accuracy: 0.54450
Time: 2018-07-15 07:08:49
TRAINING STATS: batch 346/486 in epoch 914,  batch loss: 1.63649, batch accuracy: 0.56683
Time: 2018-07-15 07:08:53
TRAINING STATS: batch 396/486 in epoch 914,  batch loss: 1.69219, batch accuracy: 0.54350
Time: 2018-07-15 07:08:56
TRAINING STATS: batch 446/486 in epoch 914,  batch loss: 1.72495, batch accuracy: 0.54100
Time: 2018-07-15 07:09:01
TRAINING STATS: batch 10/486 in epoch 915,   batch loss: 1.74344, batch accuracy: 0.52333
Time: 2018-07-15 07:09:05
TRAINING STATS: batch 60/486 in epoch 915,   batch loss: 1.67219, batch accuracy: 0.55067
Time: 2018-07-15 07:09:08
TRAINING STATS: batch 110/486 in epoch 915,  batch loss: 1.75450, batch accuracy: 0.53317
Time: 2018-07-15 07:09:13
TRAINING STATS: batch 160/486 in epoch 915,  batch loss: 1.65636, batch accuracy: 0.54800
Time: 2018-07-15 07:09:17
TRAINING STATS: batch 210/486 in epoch 915,  batch loss: 1.64764, batch accuracy: 0.56200
Time: 2018-07-15 07:09:20
TRAINING STATS: batch 260/486 in epoch 915,  batch loss: 1.72174, batch accuracy: 0.53183
Time: 2018-07-15 07:09:25
TRAINING STATS: batch 310/486 in epoch 915,  batch loss: 1.69449, batch accuracy: 0.54200
Time: 2018-07-15 07:09:29
TRAINING STATS: batch 360/486 in epoch 915,  batch loss: 1.72887, batch accuracy: 0.53150
Time: 2018-07-15 07:09:33
TRAINING STATS: batch 410/486 in epoch 915,  batch loss: 1.63438, batch accuracy: 0.56200
Time: 2018-07-15 07:09:37
TRAINING STATS: batch 460/486 in epoch 915,  batch loss: 1.80365, batch accuracy: 0.50450
Time: 2018-07-15 07:09:41
TRAINING STATS: batch 24/486 in epoch 916,   batch loss: 1.74890, batch accuracy: 0.53183
Time: 2018-07-15 07:09:45
TRAINING STATS: batch 74/486 in epoch 916,   batch loss: 1.72465, batch accuracy: 0.53517
Time: 2018-07-15 07:09:49
TRAINING STATS: batch 124/486 in epoch 916,  batch loss: 1.70777, batch accuracy: 0.54583
Time: 2018-07-15 07:09:53
TRAINING STATS: batch 174/486 in epoch 916,  batch loss: 1.77417, batch accuracy: 0.52317
Time: 2018-07-15 07:09:57
TRAINING STATS: batch 224/486 in epoch 916,  batch loss: 1.73478, batch accuracy: 0.54350
Time: 2018-07-15 07:10:01
TRAINING STATS: batch 274/486 in epoch 916,  batch loss: 1.69997, batch accuracy: 0.55017
Time: 2018-07-15 07:10:05
TRAINING STATS: batch 324/486 in epoch 916,  batch loss: 1.73061, batch accuracy: 0.53733
Time: 2018-07-15 07:10:09
TRAINING STATS: batch 374/486 in epoch 916,  batch loss: 1.72014, batch accuracy: 0.53567
Time: 2018-07-15 07:10:14
TRAINING STATS: batch 424/486 in epoch 916,  batch loss: 1.62291, batch accuracy: 0.56250
Time: 2018-07-15 07:10:17
TRAINING STATS: batch 474/486 in epoch 916,  batch loss: 1.69296, batch accuracy: 0.54350
Time: 2018-07-15 07:10:21
TRAINING STATS: batch 38/486 in epoch 917,   batch loss: 1.71687, batch accuracy: 0.53933
Time: 2018-07-15 07:10:26
TRAINING STATS: batch 88/486 in epoch 917,   batch loss: 1.74228, batch accuracy: 0.53233
Time: 2018-07-15 07:10:29
TRAINING STATS: batch 138/486 in epoch 917,  batch loss: 1.75793, batch accuracy: 0.52583
Time: 2018-07-15 07:10:33
TRAINING STATS: batch 188/486 in epoch 917,  batch loss: 1.64838, batch accuracy: 0.56083
Time: 2018-07-15 07:10:38
TRAINING STATS: batch 238/486 in epoch 917,  batch loss: 1.67626, batch accuracy: 0.55333
Time: 2018-07-15 07:10:42
TRAINING STATS: batch 288/486 in epoch 917,  batch loss: 1.73084, batch accuracy: 0.52817
Time: 2018-07-15 07:10:45
TRAINING STATS: batch 338/486 in epoch 917,  batch loss: 1.70769, batch accuracy: 0.53300
Time: 2018-07-15 07:10:50
TRAINING STATS: batch 388/486 in epoch 917,  batch loss: 1.69254, batch accuracy: 0.54617
Time: 2018-07-15 07:10:54
TRAINING STATS: batch 438/486 in epoch 917,  batch loss: 1.71483, batch accuracy: 0.54483
Time: 2018-07-15 07:10:57
TRAINING STATS: batch 2/486 in epoch 918,    batch loss: 1.71639, batch accuracy: 0.53533
Time: 2018-07-15 07:11:02
TRAINING STATS: batch 52/486 in epoch 918,   batch loss: 1.77060, batch accuracy: 0.51550
Time: 2018-07-15 07:11:06
TRAINING STATS: batch 102/486 in epoch 918,  batch loss: 1.72314, batch accuracy: 0.54483
Time: 2018-07-15 07:11:09
TRAINING STATS: batch 152/486 in epoch 918,  batch loss: 1.65336, batch accuracy: 0.55933
Time: 2018-07-15 07:11:14
TRAINING STATS: batch 202/486 in epoch 918,  batch loss: 1.68384, batch accuracy: 0.54117
Time: 2018-07-15 07:11:18
TRAINING STATS: batch 252/486 in epoch 918,  batch loss: 1.66256, batch accuracy: 0.55517
Time: 2018-07-15 07:11:21
TRAINING STATS: batch 302/486 in epoch 918,  batch loss: 1.64662, batch accuracy: 0.55383
Time: 2018-07-15 07:11:26
TRAINING STATS: batch 352/486 in epoch 918,  batch loss: 1.66631, batch accuracy: 0.55417
Time: 2018-07-15 07:11:30
TRAINING STATS: batch 402/486 in epoch 918,  batch loss: 1.56919, batch accuracy: 0.58200
Time: 2018-07-15 07:11:34
TRAINING STATS: batch 452/486 in epoch 918,  batch loss: 1.68801, batch accuracy: 0.53783
Time: 2018-07-15 07:11:38
TRAINING STATS: batch 16/486 in epoch 919,   batch loss: 1.65152, batch accuracy: 0.56033
Time: 2018-07-15 07:11:42
TRAINING STATS: batch 66/486 in epoch 919,   batch loss: 1.68195, batch accuracy: 0.54950
Time: 2018-07-15 07:11:46
TRAINING STATS: batch 116/486 in epoch 919,  batch loss: 1.65670, batch accuracy: 0.55983
Time: 2018-07-15 07:11:50
TRAINING STATS: batch 166/486 in epoch 919,  batch loss: 1.60868, batch accuracy: 0.57167
Time: 2018-07-15 07:11:54
TRAINING STATS: batch 216/486 in epoch 919,  batch loss: 1.71713, batch accuracy: 0.54250
Time: 2018-07-15 07:11:58
TRAINING STATS: batch 266/486 in epoch 919,  batch loss: 1.68850, batch accuracy: 0.54367
Time: 2018-07-15 07:12:03
TRAINING STATS: batch 316/486 in epoch 919,  batch loss: 1.67727, batch accuracy: 0.54167
Time: 2018-07-15 07:12:06
TRAINING STATS: batch 366/486 in epoch 919,  batch loss: 1.74305, batch accuracy: 0.53533
Time: 2018-07-15 07:12:10
TRAINING STATS: batch 416/486 in epoch 919,  batch loss: 1.71627, batch accuracy: 0.53750
Time: 2018-07-15 07:12:15
TRAINING STATS: batch 466/486 in epoch 919,  batch loss: 1.55653, batch accuracy: 0.58817
Time: 2018-07-15 07:12:18
TRAINING STATS: batch 30/486 in epoch 920,   batch loss: 1.59506, batch accuracy: 0.56767
Time: 2018-07-15 07:12:22
TRAINING STATS: batch 80/486 in epoch 920,   batch loss: 1.68704, batch accuracy: 0.54550
Time: 2018-07-15 07:12:27
TRAINING STATS: batch 130/486 in epoch 920,  batch loss: 1.66057, batch accuracy: 0.56000
Time: 2018-07-15 07:12:30
TRAINING STATS: batch 180/486 in epoch 920,  batch loss: 1.72245, batch accuracy: 0.54283
Time: 2018-07-15 07:12:34
TRAINING STATS: batch 230/486 in epoch 920,  batch loss: 1.71313, batch accuracy: 0.53117
Time: 2018-07-15 07:12:39
TRAINING STATS: batch 280/486 in epoch 920,  batch loss: 1.67919, batch accuracy: 0.54433
Time: 2018-07-15 07:12:42
TRAINING STATS: batch 330/486 in epoch 920,  batch loss: 1.67245, batch accuracy: 0.55317
Time: 2018-07-15 07:12:46
TRAINING STATS: batch 380/486 in epoch 920,  batch loss: 1.66385, batch accuracy: 0.55317
Time: 2018-07-15 07:12:51
TRAINING STATS: batch 430/486 in epoch 920,  batch loss: 1.60538, batch accuracy: 0.56950
Time: 2018-07-15 07:12:55
TRAINING STATS: batch 480/486 in epoch 920,  batch loss: 1.70044, batch accuracy: 0.54600
Time: 2018-07-15 07:12:58
TRAINING STATS: batch 44/486 in epoch 921,   batch loss: 1.63091, batch accuracy: 0.56800
Time: 2018-07-15 07:13:03
TRAINING STATS: batch 94/486 in epoch 921,   batch loss: 1.72687, batch accuracy: 0.53850
Time: 2018-07-15 07:13:07
TRAINING STATS: batch 144/486 in epoch 921,  batch loss: 1.73429, batch accuracy: 0.53433
Time: 2018-07-15 07:13:10
TRAINING STATS: batch 194/486 in epoch 921,  batch loss: 1.79055, batch accuracy: 0.51683
Time: 2018-07-15 07:13:15
TRAINING STATS: batch 244/486 in epoch 921,  batch loss: 1.66590, batch accuracy: 0.55850
Time: 2018-07-15 07:13:19
TRAINING STATS: batch 294/486 in epoch 921,  batch loss: 1.61425, batch accuracy: 0.56217
Time: 2018-07-15 07:13:22
TRAINING STATS: batch 344/486 in epoch 921,  batch loss: 1.68829, batch accuracy: 0.54350
Time: 2018-07-15 07:13:27
TRAINING STATS: batch 394/486 in epoch 921,  batch loss: 1.64628, batch accuracy: 0.55833
Time: 2018-07-15 07:13:31
TRAINING STATS: batch 444/486 in epoch 921,  batch loss: 1.62739, batch accuracy: 0.57100
Time: 2018-07-15 07:13:35
TRAINING STATS: batch 8/486 in epoch 922,    batch loss: 1.67911, batch accuracy: 0.54700
Time: 2018-07-15 07:13:39
TRAINING STATS: batch 58/486 in epoch 922,   batch loss: 1.65202, batch accuracy: 0.55683
Time: 2018-07-15 07:13:43
TRAINING STATS: batch 108/486 in epoch 922,  batch loss: 1.74401, batch accuracy: 0.52983
Time: 2018-07-15 07:13:47
TRAINING STATS: batch 158/486 in epoch 922,  batch loss: 1.72937, batch accuracy: 0.53867
Time: 2018-07-15 07:13:51
TRAINING STATS: batch 208/486 in epoch 922,  batch loss: 1.70073, batch accuracy: 0.54683
Time: 2018-07-15 07:13:55
TRAINING STATS: batch 258/486 in epoch 922,  batch loss: 1.63764, batch accuracy: 0.56150
Time: 2018-07-15 07:13:59
TRAINING STATS: batch 308/486 in epoch 922,  batch loss: 1.71380, batch accuracy: 0.54583
Time: 2018-07-15 07:14:03
TRAINING STATS: batch 358/486 in epoch 922,  batch loss: 1.71433, batch accuracy: 0.53433
Time: 2018-07-15 07:14:07
TRAINING STATS: batch 408/486 in epoch 922,  batch loss: 1.73148, batch accuracy: 0.52850
Time: 2018-07-15 07:14:11
TRAINING STATS: batch 458/486 in epoch 922,  batch loss: 1.70312, batch accuracy: 0.55183
Time: 2018-07-15 07:14:16
TRAINING STATS: batch 22/486 in epoch 923,   batch loss: 1.72231, batch accuracy: 0.54717
Time: 2018-07-15 07:14:19
TRAINING STATS: batch 72/486 in epoch 923,   batch loss: 1.71539, batch accuracy: 0.52600
Time: 2018-07-15 07:14:23
TRAINING STATS: batch 122/486 in epoch 923,  batch loss: 1.63249, batch accuracy: 0.56850
Time: 2018-07-15 07:14:28
TRAINING STATS: batch 172/486 in epoch 923,  batch loss: 1.74130, batch accuracy: 0.53283
Time: 2018-07-15 07:14:31
TRAINING STATS: batch 222/486 in epoch 923,  batch loss: 1.69330, batch accuracy: 0.54200
Time: 2018-07-15 07:14:35
TRAINING STATS: batch 272/486 in epoch 923,  batch loss: 1.70807, batch accuracy: 0.53967
Time: 2018-07-15 07:14:40
TRAINING STATS: batch 322/486 in epoch 923,  batch loss: 1.67626, batch accuracy: 0.54333
Time: 2018-07-15 07:14:43
TRAINING STATS: batch 372/486 in epoch 923,  batch loss: 1.63374, batch accuracy: 0.55833
Time: 2018-07-15 07:14:47
TRAINING STATS: batch 422/486 in epoch 923,  batch loss: 1.67251, batch accuracy: 0.55000
Time: 2018-07-15 07:14:52
TRAINING STATS: batch 472/486 in epoch 923,  batch loss: 1.73283, batch accuracy: 0.53417
Time: 2018-07-15 07:14:55
TRAINING STATS: batch 36/486 in epoch 924,   batch loss: 1.75004, batch accuracy: 0.53067
Time: 2018-07-15 07:14:59
TRAINING STATS: batch 86/486 in epoch 924,   batch loss: 1.68656, batch accuracy: 0.55550
Time: 2018-07-15 07:15:04
TRAINING STATS: batch 136/486 in epoch 924,  batch loss: 1.74894, batch accuracy: 0.52650
Time: 2018-07-15 07:15:07
TRAINING STATS: batch 186/486 in epoch 924,  batch loss: 1.70166, batch accuracy: 0.54550
Time: 2018-07-15 07:15:11
TRAINING STATS: batch 236/486 in epoch 924,  batch loss: 1.73111, batch accuracy: 0.52967
Time: 2018-07-15 07:15:16
TRAINING STATS: batch 286/486 in epoch 924,  batch loss: 1.72209, batch accuracy: 0.53817
Time: 2018-07-15 07:15:20
TRAINING STATS: batch 336/486 in epoch 924,  batch loss: 1.69066, batch accuracy: 0.54533
Time: 2018-07-15 07:15:23
TRAINING STATS: batch 386/486 in epoch 924,  batch loss: 1.72075, batch accuracy: 0.53367
Time: 2018-07-15 07:15:28
TRAINING STATS: batch 436/486 in epoch 924,  batch loss: 1.71535, batch accuracy: 0.54533
Time: 2018-07-15 07:15:32
TRAINING STATS: batch 0/486 in epoch 925,    batch loss: 1.67240, batch accuracy: 0.55217
Time: 2018-07-15 07:15:35
TRAINING STATS: batch 50/486 in epoch 925,   batch loss: 1.64192, batch accuracy: 0.56050
Time: 2018-07-15 07:15:40
TRAINING STATS: batch 100/486 in epoch 925,  batch loss: 1.71634, batch accuracy: 0.53967
Time: 2018-07-15 07:15:44
TRAINING STATS: batch 150/486 in epoch 925,  batch loss: 1.67551, batch accuracy: 0.55333
Time: 2018-07-15 07:15:47
TRAINING STATS: batch 200/486 in epoch 925,  batch loss: 1.57086, batch accuracy: 0.57917
Time: 2018-07-15 07:15:52
TRAINING STATS: batch 250/486 in epoch 925,  batch loss: 1.75149, batch accuracy: 0.52850
Time: 2018-07-15 07:15:56
TRAINING STATS: batch 300/486 in epoch 925,  batch loss: 1.72433, batch accuracy: 0.53133
Time: 2018-07-15 07:15:59
TRAINING STATS: batch 350/486 in epoch 925,  batch loss: 1.70102, batch accuracy: 0.54950
Time: 2018-07-15 07:16:04
TRAINING STATS: batch 400/486 in epoch 925,  batch loss: 1.57603, batch accuracy: 0.57633
Time: 2018-07-15 07:16:08
TRAINING STATS: batch 450/486 in epoch 925,  batch loss: 1.75849, batch accuracy: 0.52267
Time: 2018-07-15 07:16:11
TRAINING STATS: batch 14/486 in epoch 926,   batch loss: 1.60828, batch accuracy: 0.57267
Time: 2018-07-15 07:16:16
TRAINING STATS: batch 64/486 in epoch 926,   batch loss: 1.77281, batch accuracy: 0.52200
Time: 2018-07-15 07:16:20
TRAINING STATS: batch 114/486 in epoch 926,  batch loss: 1.71846, batch accuracy: 0.53383
Time: 2018-07-15 07:16:24
TRAINING STATS: batch 164/486 in epoch 926,  batch loss: 1.63280, batch accuracy: 0.57083
Time: 2018-07-15 07:16:28
TRAINING STATS: batch 214/486 in epoch 926,  batch loss: 1.67760, batch accuracy: 0.54900
Time: 2018-07-15 07:16:32
TRAINING STATS: batch 264/486 in epoch 926,  batch loss: 1.72633, batch accuracy: 0.53350
Time: 2018-07-15 07:16:36
TRAINING STATS: batch 314/486 in epoch 926,  batch loss: 1.75549, batch accuracy: 0.51900
Time: 2018-07-15 07:16:40
TRAINING STATS: batch 364/486 in epoch 926,  batch loss: 1.67564, batch accuracy: 0.55400
Time: 2018-07-15 07:16:44
TRAINING STATS: batch 414/486 in epoch 926,  batch loss: 1.62685, batch accuracy: 0.56167
Time: 2018-07-15 07:16:48
TRAINING STATS: batch 464/486 in epoch 926,  batch loss: 1.65155, batch accuracy: 0.55583
Time: 2018-07-15 07:16:53
TRAINING STATS: batch 28/486 in epoch 927,   batch loss: 1.60770, batch accuracy: 0.57250
Time: 2018-07-15 07:16:56
TRAINING STATS: batch 78/486 in epoch 927,   batch loss: 1.68141, batch accuracy: 0.55333
Time: 2018-07-15 07:17:00
TRAINING STATS: batch 128/486 in epoch 927,  batch loss: 1.65573, batch accuracy: 0.55567
Time: 2018-07-15 07:17:05
TRAINING STATS: batch 178/486 in epoch 927,  batch loss: 1.58774, batch accuracy: 0.57417
Time: 2018-07-15 07:17:08
TRAINING STATS: batch 228/486 in epoch 927,  batch loss: 1.63114, batch accuracy: 0.56317
Time: 2018-07-15 07:17:12
TRAINING STATS: batch 278/486 in epoch 927,  batch loss: 1.62767, batch accuracy: 0.56350
Time: 2018-07-15 07:17:17
TRAINING STATS: batch 328/486 in epoch 927,  batch loss: 1.64975, batch accuracy: 0.56383
Time: 2018-07-15 07:17:20
TRAINING STATS: batch 378/486 in epoch 927,  batch loss: 1.68751, batch accuracy: 0.54850
Time: 2018-07-15 07:17:24
TRAINING STATS: batch 428/486 in epoch 927,  batch loss: 1.71821, batch accuracy: 0.53750
Time: 2018-07-15 07:17:29
TRAINING STATS: batch 478/486 in epoch 927,  batch loss: 1.69198, batch accuracy: 0.54467
Time: 2018-07-15 07:17:32
TRAINING STATS: batch 42/486 in epoch 928,   batch loss: 1.58717, batch accuracy: 0.57650
Time: 2018-07-15 07:17:36
TRAINING STATS: batch 92/486 in epoch 928,   batch loss: 1.70509, batch accuracy: 0.53917
Time: 2018-07-15 07:17:41
TRAINING STATS: batch 142/486 in epoch 928,  batch loss: 1.62693, batch accuracy: 0.55667
Time: 2018-07-15 07:17:44
TRAINING STATS: batch 192/486 in epoch 928,  batch loss: 1.66431, batch accuracy: 0.55000
Time: 2018-07-15 07:17:48
TRAINING STATS: batch 242/486 in epoch 928,  batch loss: 1.65129, batch accuracy: 0.55867
Time: 2018-07-15 07:17:53
TRAINING STATS: batch 292/486 in epoch 928,  batch loss: 1.66265, batch accuracy: 0.55617
Time: 2018-07-15 07:17:57
TRAINING STATS: batch 342/486 in epoch 928,  batch loss: 1.65397, batch accuracy: 0.55483
Time: 2018-07-15 07:18:00
TRAINING STATS: batch 392/486 in epoch 928,  batch loss: 1.62368, batch accuracy: 0.56133
Time: 2018-07-15 07:18:05
TRAINING STATS: batch 442/486 in epoch 928,  batch loss: 1.64444, batch accuracy: 0.55900
Time: 2018-07-15 07:18:08
TRAINING STATS: batch 6/486 in epoch 929,    batch loss: 1.72903, batch accuracy: 0.53800
Time: 2018-07-15 07:18:12
TRAINING STATS: batch 56/486 in epoch 929,   batch loss: 1.64181, batch accuracy: 0.55950
Time: 2018-07-15 07:18:17
TRAINING STATS: batch 106/486 in epoch 929,  batch loss: 1.75991, batch accuracy: 0.52783
Time: 2018-07-15 07:18:21
TRAINING STATS: batch 156/486 in epoch 929,  batch loss: 1.72075, batch accuracy: 0.54483
Time: 2018-07-15 07:18:24
TRAINING STATS: batch 206/486 in epoch 929,  batch loss: 1.80399, batch accuracy: 0.51250
Time: 2018-07-15 07:18:29
TRAINING STATS: batch 256/486 in epoch 929,  batch loss: 1.62213, batch accuracy: 0.56050
Time: 2018-07-15 07:18:33
TRAINING STATS: batch 306/486 in epoch 929,  batch loss: 1.68293, batch accuracy: 0.54817
Time: 2018-07-15 07:18:36
TRAINING STATS: batch 356/486 in epoch 929,  batch loss: 1.73369, batch accuracy: 0.53050
Time: 2018-07-15 07:18:41
TRAINING STATS: batch 406/486 in epoch 929,  batch loss: 1.75328, batch accuracy: 0.52400
Time: 2018-07-15 07:18:45
TRAINING STATS: batch 456/486 in epoch 929,  batch loss: 1.56674, batch accuracy: 0.58933
Time: 2018-07-15 07:18:49
TRAINING STATS: batch 20/486 in epoch 930,   batch loss: 1.66982, batch accuracy: 0.54717
Time: 2018-07-15 07:18:53
TRAINING STATS: batch 70/486 in epoch 930,   batch loss: 1.57862, batch accuracy: 0.58017
Time: 2018-07-15 07:18:57
TRAINING STATS: batch 120/486 in epoch 930,  batch loss: 1.63126, batch accuracy: 0.55833
Time: 2018-07-15 07:19:01
TRAINING STATS: batch 170/486 in epoch 930,  batch loss: 1.68072, batch accuracy: 0.55333
Time: 2018-07-15 07:19:05
TRAINING STATS: batch 220/486 in epoch 930,  batch loss: 1.60762, batch accuracy: 0.57233
Time: 2018-07-15 07:19:09
TRAINING STATS: batch 270/486 in epoch 930,  batch loss: 1.67456, batch accuracy: 0.54117
Time: 2018-07-15 07:19:13
TRAINING STATS: batch 320/486 in epoch 930,  batch loss: 1.62800, batch accuracy: 0.56300
Time: 2018-07-15 07:19:17
TRAINING STATS: batch 370/486 in epoch 930,  batch loss: 1.67818, batch accuracy: 0.55317
Time: 2018-07-15 07:19:21
TRAINING STATS: batch 420/486 in epoch 930,  batch loss: 1.71085, batch accuracy: 0.54183
Time: 2018-07-15 07:19:25
TRAINING STATS: batch 470/486 in epoch 930,  batch loss: 1.77144, batch accuracy: 0.52467
Time: 2018-07-15 07:19:29
TRAINING STATS: batch 34/486 in epoch 931,   batch loss: 1.69672, batch accuracy: 0.55050
Time: 2018-07-15 07:19:33
TRAINING STATS: batch 84/486 in epoch 931,   batch loss: 1.69484, batch accuracy: 0.53667
Time: 2018-07-15 07:19:37
TRAINING STATS: batch 134/486 in epoch 931,  batch loss: 1.70889, batch accuracy: 0.54317
Time: 2018-07-15 07:19:42
TRAINING STATS: batch 184/486 in epoch 931,  batch loss: 1.75027, batch accuracy: 0.52933
Time: 2018-07-15 07:19:45
TRAINING STATS: batch 234/486 in epoch 931,  batch loss: 1.75881, batch accuracy: 0.52650
Time: 2018-07-15 07:19:49
TRAINING STATS: batch 284/486 in epoch 931,  batch loss: 1.74304, batch accuracy: 0.52817
Time: 2018-07-15 07:19:54
TRAINING STATS: batch 334/486 in epoch 931,  batch loss: 1.66660, batch accuracy: 0.55033
Time: 2018-07-15 07:19:57
TRAINING STATS: batch 384/486 in epoch 931,  batch loss: 1.65481, batch accuracy: 0.55333
Time: 2018-07-15 07:20:01
TRAINING STATS: batch 434/486 in epoch 931,  batch loss: 1.74679, batch accuracy: 0.52550
Time: 2018-07-15 07:20:06
TRAINING STATS: batch 484/486 in epoch 931,  batch loss: 1.68576, batch accuracy: 0.54367
Time: 2018-07-15 07:20:09
TRAINING STATS: batch 48/486 in epoch 932,   batch loss: 1.68664, batch accuracy: 0.54567
Time: 2018-07-15 07:20:13
TRAINING STATS: batch 98/486 in epoch 932,   batch loss: 1.65996, batch accuracy: 0.55700
Time: 2018-07-15 07:20:18
TRAINING STATS: batch 148/486 in epoch 932,  batch loss: 1.73402, batch accuracy: 0.54533
Time: 2018-07-15 07:20:21
TRAINING STATS: batch 198/486 in epoch 932,  batch loss: 1.68003, batch accuracy: 0.55000
Time: 2018-07-15 07:20:25
TRAINING STATS: batch 248/486 in epoch 932,  batch loss: 1.70899, batch accuracy: 0.54117
Time: 2018-07-15 07:20:30
TRAINING STATS: batch 298/486 in epoch 932,  batch loss: 1.72186, batch accuracy: 0.53183
Time: 2018-07-15 07:20:34
TRAINING STATS: batch 348/486 in epoch 932,  batch loss: 1.68384, batch accuracy: 0.54583
Time: 2018-07-15 07:20:37
TRAINING STATS: batch 398/486 in epoch 932,  batch loss: 1.70069, batch accuracy: 0.54333
Time: 2018-07-15 07:20:42
TRAINING STATS: batch 448/486 in epoch 932,  batch loss: 1.66467, batch accuracy: 0.55950
Time: 2018-07-15 07:20:46
TRAINING STATS: batch 12/486 in epoch 933,   batch loss: 1.68886, batch accuracy: 0.54417
Time: 2018-07-15 07:20:49
TRAINING STATS: batch 62/486 in epoch 933,   batch loss: 1.78058, batch accuracy: 0.51567
Time: 2018-07-15 07:20:54
TRAINING STATS: batch 112/486 in epoch 933,  batch loss: 1.68187, batch accuracy: 0.54367
Time: 2018-07-15 07:20:58
TRAINING STATS: batch 162/486 in epoch 933,  batch loss: 1.67819, batch accuracy: 0.55183
Time: 2018-07-15 07:21:01
TRAINING STATS: batch 212/486 in epoch 933,  batch loss: 1.58718, batch accuracy: 0.57200
Time: 2018-07-15 07:21:06
TRAINING STATS: batch 262/486 in epoch 933,  batch loss: 1.73163, batch accuracy: 0.53483
Time: 2018-07-15 07:21:10
TRAINING STATS: batch 312/486 in epoch 933,  batch loss: 1.69372, batch accuracy: 0.53533
Time: 2018-07-15 07:21:14
TRAINING STATS: batch 362/486 in epoch 933,  batch loss: 1.69062, batch accuracy: 0.54833
Time: 2018-07-15 07:21:18
TRAINING STATS: batch 412/486 in epoch 933,  batch loss: 1.62724, batch accuracy: 0.56967
Time: 2018-07-15 07:21:22
TRAINING STATS: batch 462/486 in epoch 933,  batch loss: 1.69633, batch accuracy: 0.53417
Time: 2018-07-15 07:21:26
TRAINING STATS: batch 26/486 in epoch 934,   batch loss: 1.70628, batch accuracy: 0.54033
Time: 2018-07-15 07:21:30
TRAINING STATS: batch 76/486 in epoch 934,   batch loss: 1.73467, batch accuracy: 0.53517
Time: 2018-07-15 07:21:34
TRAINING STATS: batch 126/486 in epoch 934,  batch loss: 1.72365, batch accuracy: 0.53617
Time: 2018-07-15 07:21:38
TRAINING STATS: batch 176/486 in epoch 934,  batch loss: 1.60329, batch accuracy: 0.56883
Time: 2018-07-15 07:21:42
TRAINING STATS: batch 226/486 in epoch 934,  batch loss: 1.65816, batch accuracy: 0.55700
Time: 2018-07-15 07:21:46
TRAINING STATS: batch 276/486 in epoch 934,  batch loss: 1.69515, batch accuracy: 0.54750
Time: 2018-07-15 07:21:50
TRAINING STATS: batch 326/486 in epoch 934,  batch loss: 1.73650, batch accuracy: 0.53867
Time: 2018-07-15 07:21:54
TRAINING STATS: batch 376/486 in epoch 934,  batch loss: 1.69837, batch accuracy: 0.54233
Time: 2018-07-15 07:21:58
TRAINING STATS: batch 426/486 in epoch 934,  batch loss: 1.70302, batch accuracy: 0.53667
Time: 2018-07-15 07:22:02
TRAINING STATS: batch 476/486 in epoch 934,  batch loss: 1.65102, batch accuracy: 0.55917
Time: 2018-07-15 07:22:07
TRAINING STATS: batch 40/486 in epoch 935,   batch loss: 1.66725, batch accuracy: 0.56133
Time: 2018-07-15 07:22:10
TRAINING STATS: batch 90/486 in epoch 935,   batch loss: 1.73391, batch accuracy: 0.53250
Time: 2018-07-15 07:22:14
TRAINING STATS: batch 140/486 in epoch 935,  batch loss: 1.62994, batch accuracy: 0.56950
Time: 2018-07-15 07:22:19
TRAINING STATS: batch 190/486 in epoch 935,  batch loss: 1.66598, batch accuracy: 0.55250
Time: 2018-07-15 07:22:22
TRAINING STATS: batch 240/486 in epoch 935,  batch loss: 1.67347, batch accuracy: 0.55117
Time: 2018-07-15 07:22:26
TRAINING STATS: batch 290/486 in epoch 935,  batch loss: 1.70149, batch accuracy: 0.53883
Time: 2018-07-15 07:22:31
TRAINING STATS: batch 340/486 in epoch 935,  batch loss: 1.78612, batch accuracy: 0.50933
Time: 2018-07-15 07:22:34
TRAINING STATS: batch 390/486 in epoch 935,  batch loss: 1.63131, batch accuracy: 0.56517
Time: 2018-07-15 07:22:38
TRAINING STATS: batch 440/486 in epoch 935,  batch loss: 1.68901, batch accuracy: 0.54650
Time: 2018-07-15 07:22:43
TRAINING STATS: batch 4/486 in epoch 936,    batch loss: 1.64058, batch accuracy: 0.56067
Time: 2018-07-15 07:22:46
TRAINING STATS: batch 54/486 in epoch 936,   batch loss: 1.69074, batch accuracy: 0.54583
Time: 2018-07-15 07:22:50
TRAINING STATS: batch 104/486 in epoch 936,  batch loss: 1.70836, batch accuracy: 0.55150
Time: 2018-07-15 07:22:55
TRAINING STATS: batch 154/486 in epoch 936,  batch loss: 1.66917, batch accuracy: 0.55317
Time: 2018-07-15 07:22:59
TRAINING STATS: batch 204/486 in epoch 936,  batch loss: 1.75203, batch accuracy: 0.52883
Time: 2018-07-15 07:23:02
TRAINING STATS: batch 254/486 in epoch 936,  batch loss: 1.60153, batch accuracy: 0.57000
Time: 2018-07-15 07:23:07
TRAINING STATS: batch 304/486 in epoch 936,  batch loss: 1.63281, batch accuracy: 0.57050
Time: 2018-07-15 07:23:11
TRAINING STATS: batch 354/486 in epoch 936,  batch loss: 1.69735, batch accuracy: 0.54500
Time: 2018-07-15 07:23:14
TRAINING STATS: batch 404/486 in epoch 936,  batch loss: 1.66693, batch accuracy: 0.55517
Time: 2018-07-15 07:23:19
TRAINING STATS: batch 454/486 in epoch 936,  batch loss: 1.53564, batch accuracy: 0.59017
Time: 2018-07-15 07:23:23
TRAINING STATS: batch 18/486 in epoch 937,   batch loss: 1.71021, batch accuracy: 0.54300
Time: 2018-07-15 07:23:26
TRAINING STATS: batch 68/486 in epoch 937,   batch loss: 1.54163, batch accuracy: 0.58450
Time: 2018-07-15 07:23:31
TRAINING STATS: batch 118/486 in epoch 937,  batch loss: 1.66245, batch accuracy: 0.55050
Time: 2018-07-15 07:23:35
TRAINING STATS: batch 168/486 in epoch 937,  batch loss: 1.59991, batch accuracy: 0.57350
Time: 2018-07-15 07:23:39
TRAINING STATS: batch 218/486 in epoch 937,  batch loss: 1.66204, batch accuracy: 0.55250
Time: 2018-07-15 07:23:43
TRAINING STATS: batch 268/486 in epoch 937,  batch loss: 1.63204, batch accuracy: 0.55650
Time: 2018-07-15 07:23:47
TRAINING STATS: batch 318/486 in epoch 937,  batch loss: 1.69879, batch accuracy: 0.54333
Time: 2018-07-15 07:23:51
TRAINING STATS: batch 368/486 in epoch 937,  batch loss: 1.71127, batch accuracy: 0.53633
Time: 2018-07-15 07:23:55
TRAINING STATS: batch 418/486 in epoch 937,  batch loss: 1.73669, batch accuracy: 0.52700
Time: 2018-07-15 07:23:59
TRAINING STATS: batch 468/486 in epoch 937,  batch loss: 1.68866, batch accuracy: 0.54967
Time: 2018-07-15 07:24:03
TRAINING STATS: batch 32/486 in epoch 938,   batch loss: 1.64926, batch accuracy: 0.55450
Time: 2018-07-15 07:24:08
TRAINING STATS: batch 82/486 in epoch 938,   batch loss: 1.73217, batch accuracy: 0.53150
Time: 2018-07-15 07:24:11
TRAINING STATS: batch 132/486 in epoch 938,  batch loss: 1.67238, batch accuracy: 0.55433
Time: 2018-07-15 07:24:15
TRAINING STATS: batch 182/486 in epoch 938,  batch loss: 1.73376, batch accuracy: 0.53000
Time: 2018-07-15 07:24:20
TRAINING STATS: batch 232/486 in epoch 938,  batch loss: 1.71083, batch accuracy: 0.54067
Time: 2018-07-15 07:24:23
TRAINING STATS: batch 282/486 in epoch 938,  batch loss: 1.64781, batch accuracy: 0.56317
Time: 2018-07-15 07:24:27
TRAINING STATS: batch 332/486 in epoch 938,  batch loss: 1.71027, batch accuracy: 0.54217
Time: 2018-07-15 07:24:32
TRAINING STATS: batch 382/486 in epoch 938,  batch loss: 1.69960, batch accuracy: 0.54750
Time: 2018-07-15 07:24:35
TRAINING STATS: batch 432/486 in epoch 938,  batch loss: 1.60808, batch accuracy: 0.56983
Time: 2018-07-15 07:24:39
TRAINING STATS: batch 482/486 in epoch 938,  batch loss: 1.66223, batch accuracy: 0.54900
Time: 2018-07-15 07:24:44
TRAINING STATS: batch 46/486 in epoch 939,   batch loss: 1.65540, batch accuracy: 0.56200
Time: 2018-07-15 07:24:47
TRAINING STATS: batch 96/486 in epoch 939,   batch loss: 1.72163, batch accuracy: 0.53350
Time: 2018-07-15 07:24:51
TRAINING STATS: batch 146/486 in epoch 939,  batch loss: 1.71885, batch accuracy: 0.54267
Time: 2018-07-15 07:24:56
TRAINING STATS: batch 196/486 in epoch 939,  batch loss: 1.72164, batch accuracy: 0.53400
Time: 2018-07-15 07:25:00
TRAINING STATS: batch 246/486 in epoch 939,  batch loss: 1.63552, batch accuracy: 0.55817
Time: 2018-07-15 07:25:03
TRAINING STATS: batch 296/486 in epoch 939,  batch loss: 1.65838, batch accuracy: 0.55033
Time: 2018-07-15 07:25:08
TRAINING STATS: batch 346/486 in epoch 939,  batch loss: 1.60480, batch accuracy: 0.57100
Time: 2018-07-15 07:25:12
TRAINING STATS: batch 396/486 in epoch 939,  batch loss: 1.68813, batch accuracy: 0.54767
Time: 2018-07-15 07:25:15
TRAINING STATS: batch 446/486 in epoch 939,  batch loss: 1.68588, batch accuracy: 0.54883
Time: 2018-07-15 07:25:20
TRAINING STATS: batch 10/486 in epoch 940,   batch loss: 1.71370, batch accuracy: 0.52850
Time: 2018-07-15 07:25:24
TRAINING STATS: batch 60/486 in epoch 940,   batch loss: 1.66448, batch accuracy: 0.55517
Time: 2018-07-15 07:25:27
TRAINING STATS: batch 110/486 in epoch 940,  batch loss: 1.75438, batch accuracy: 0.52867
Time: 2018-07-15 07:25:32
TRAINING STATS: batch 160/486 in epoch 940,  batch loss: 1.65255, batch accuracy: 0.54800
Time: 2018-07-15 07:25:36
TRAINING STATS: batch 210/486 in epoch 940,  batch loss: 1.62449, batch accuracy: 0.56650
Time: 2018-07-15 07:25:39
TRAINING STATS: batch 260/486 in epoch 940,  batch loss: 1.70069, batch accuracy: 0.53950
Time: 2018-07-15 07:25:44
TRAINING STATS: batch 310/486 in epoch 940,  batch loss: 1.68486, batch accuracy: 0.55017
Time: 2018-07-15 07:25:48
TRAINING STATS: batch 360/486 in epoch 940,  batch loss: 1.69639, batch accuracy: 0.54183
Time: 2018-07-15 07:25:51
TRAINING STATS: batch 410/486 in epoch 940,  batch loss: 1.61293, batch accuracy: 0.56750
Time: 2018-07-15 07:25:56
TRAINING STATS: batch 460/486 in epoch 940,  batch loss: 1.79917, batch accuracy: 0.50950
Time: 2018-07-15 07:26:00
TRAINING STATS: batch 24/486 in epoch 941,   batch loss: 1.74991, batch accuracy: 0.53350
Time: 2018-07-15 07:26:03
TRAINING STATS: batch 74/486 in epoch 941,   batch loss: 1.71826, batch accuracy: 0.53917
Time: 2018-07-15 07:26:08
TRAINING STATS: batch 124/486 in epoch 941,  batch loss: 1.70419, batch accuracy: 0.54500
Time: 2018-07-15 07:26:12
TRAINING STATS: batch 174/486 in epoch 941,  batch loss: 1.75590, batch accuracy: 0.53000
Time: 2018-07-15 07:26:16
TRAINING STATS: batch 224/486 in epoch 941,  batch loss: 1.72612, batch accuracy: 0.53517
Time: 2018-07-15 07:26:20
TRAINING STATS: batch 274/486 in epoch 941,  batch loss: 1.68521, batch accuracy: 0.54783
Time: 2018-07-15 07:26:24
TRAINING STATS: batch 324/486 in epoch 941,  batch loss: 1.71361, batch accuracy: 0.54117
Time: 2018-07-15 07:26:28
TRAINING STATS: batch 374/486 in epoch 941,  batch loss: 1.71070, batch accuracy: 0.53800
Time: 2018-07-15 07:26:33
TRAINING STATS: batch 424/486 in epoch 941,  batch loss: 1.61762, batch accuracy: 0.56933
Time: 2018-07-15 07:26:36
TRAINING STATS: batch 474/486 in epoch 941,  batch loss: 1.70544, batch accuracy: 0.54167
Time: 2018-07-15 07:26:40
TRAINING STATS: batch 38/486 in epoch 942,   batch loss: 1.70688, batch accuracy: 0.54467
Time: 2018-07-15 07:26:45
TRAINING STATS: batch 88/486 in epoch 942,   batch loss: 1.73368, batch accuracy: 0.53350
Time: 2018-07-15 07:26:48
TRAINING STATS: batch 138/486 in epoch 942,  batch loss: 1.73831, batch accuracy: 0.52883
Time: 2018-07-15 07:26:52
TRAINING STATS: batch 188/486 in epoch 942,  batch loss: 1.64863, batch accuracy: 0.56167
Time: 2018-07-15 07:26:57
TRAINING STATS: batch 238/486 in epoch 942,  batch loss: 1.67887, batch accuracy: 0.55183
Time: 2018-07-15 07:27:00
TRAINING STATS: batch 288/486 in epoch 942,  batch loss: 1.71585, batch accuracy: 0.53383
Time: 2018-07-15 07:27:04
TRAINING STATS: batch 338/486 in epoch 942,  batch loss: 1.68664, batch accuracy: 0.53550
Time: 2018-07-15 07:27:09
TRAINING STATS: batch 388/486 in epoch 942,  batch loss: 1.65469, batch accuracy: 0.56017
Time: 2018-07-15 07:27:13
TRAINING STATS: batch 438/486 in epoch 942,  batch loss: 1.72895, batch accuracy: 0.53867
Time: 2018-07-15 07:27:16
TRAINING STATS: batch 2/486 in epoch 943,    batch loss: 1.68631, batch accuracy: 0.54400
Time: 2018-07-15 07:27:21
TRAINING STATS: batch 52/486 in epoch 943,   batch loss: 1.75698, batch accuracy: 0.51517
Time: 2018-07-15 07:27:24
TRAINING STATS: batch 102/486 in epoch 943,  batch loss: 1.71561, batch accuracy: 0.54383
Time: 2018-07-15 07:27:28
TRAINING STATS: batch 152/486 in epoch 943,  batch loss: 1.64876, batch accuracy: 0.55967
Time: 2018-07-15 07:27:33
TRAINING STATS: batch 202/486 in epoch 943,  batch loss: 1.67930, batch accuracy: 0.54917
Time: 2018-07-15 07:27:37
TRAINING STATS: batch 252/486 in epoch 943,  batch loss: 1.64776, batch accuracy: 0.55700
Time: 2018-07-15 07:27:40
TRAINING STATS: batch 302/486 in epoch 943,  batch loss: 1.63053, batch accuracy: 0.55700
Time: 2018-07-15 07:27:45
TRAINING STATS: batch 352/486 in epoch 943,  batch loss: 1.65744, batch accuracy: 0.56233
Time: 2018-07-15 07:27:49
TRAINING STATS: batch 402/486 in epoch 943,  batch loss: 1.55858, batch accuracy: 0.59217
Time: 2018-07-15 07:27:52
TRAINING STATS: batch 452/486 in epoch 943,  batch loss: 1.79446, batch accuracy: 0.51833
Time: 2018-07-15 07:27:57
TRAINING STATS: batch 16/486 in epoch 944,   batch loss: 1.69358, batch accuracy: 0.54550
Time: 2018-07-15 07:28:01
TRAINING STATS: batch 66/486 in epoch 944,   batch loss: 1.69936, batch accuracy: 0.54167
Time: 2018-07-15 07:28:04
TRAINING STATS: batch 116/486 in epoch 944,  batch loss: 1.65485, batch accuracy: 0.55933
Time: 2018-07-15 07:28:09
TRAINING STATS: batch 166/486 in epoch 944,  batch loss: 1.59319, batch accuracy: 0.57083
Time: 2018-07-15 07:28:13
TRAINING STATS: batch 216/486 in epoch 944,  batch loss: 1.72895, batch accuracy: 0.54350
Time: 2018-07-15 07:28:16
TRAINING STATS: batch 266/486 in epoch 944,  batch loss: 1.69594, batch accuracy: 0.54217
Time: 2018-07-15 07:28:21
TRAINING STATS: batch 316/486 in epoch 944,  batch loss: 1.67321, batch accuracy: 0.54850
Time: 2018-07-15 07:28:25
TRAINING STATS: batch 366/486 in epoch 944,  batch loss: 1.74671, batch accuracy: 0.53450
Time: 2018-07-15 07:28:29
TRAINING STATS: batch 416/486 in epoch 944,  batch loss: 1.72359, batch accuracy: 0.53733
Time: 2018-07-15 07:28:33
TRAINING STATS: batch 466/486 in epoch 944,  batch loss: 1.56769, batch accuracy: 0.57900
Time: 2018-07-15 07:28:37
TRAINING STATS: batch 30/486 in epoch 945,   batch loss: 1.57462, batch accuracy: 0.57800
Time: 2018-07-15 07:28:41
TRAINING STATS: batch 80/486 in epoch 945,   batch loss: 1.68304, batch accuracy: 0.54033
Time: 2018-07-15 07:28:45
TRAINING STATS: batch 130/486 in epoch 945,  batch loss: 1.67363, batch accuracy: 0.56000
Time: 2018-07-15 07:28:49
TRAINING STATS: batch 180/486 in epoch 945,  batch loss: 1.70782, batch accuracy: 0.54217
Time: 2018-07-15 07:28:53
TRAINING STATS: batch 230/486 in epoch 945,  batch loss: 1.70414, batch accuracy: 0.53650
Time: 2018-07-15 07:28:57
TRAINING STATS: batch 280/486 in epoch 945,  batch loss: 1.67414, batch accuracy: 0.55050
Time: 2018-07-15 07:29:01
TRAINING STATS: batch 330/486 in epoch 945,  batch loss: 1.66145, batch accuracy: 0.55433
Time: 2018-07-15 07:29:05
TRAINING STATS: batch 380/486 in epoch 945,  batch loss: 1.65706, batch accuracy: 0.56083
Time: 2018-07-15 07:29:10
TRAINING STATS: batch 430/486 in epoch 945,  batch loss: 1.63491, batch accuracy: 0.56950
Time: 2018-07-15 07:29:13
TRAINING STATS: batch 480/486 in epoch 945,  batch loss: 1.70114, batch accuracy: 0.54433
Time: 2018-07-15 07:29:17
TRAINING STATS: batch 44/486 in epoch 946,   batch loss: 1.63507, batch accuracy: 0.56667
Time: 2018-07-15 07:29:22
TRAINING STATS: batch 94/486 in epoch 946,   batch loss: 1.73557, batch accuracy: 0.53383
Time: 2018-07-15 07:29:25
TRAINING STATS: batch 144/486 in epoch 946,  batch loss: 1.74301, batch accuracy: 0.52783
Time: 2018-07-15 07:29:29
TRAINING STATS: batch 194/486 in epoch 946,  batch loss: 1.76926, batch accuracy: 0.52183
Time: 2018-07-15 07:29:34
TRAINING STATS: batch 244/486 in epoch 946,  batch loss: 1.66837, batch accuracy: 0.55100
Time: 2018-07-15 07:29:37
TRAINING STATS: batch 294/486 in epoch 946,  batch loss: 1.60216, batch accuracy: 0.57150
Time: 2018-07-15 07:29:41
TRAINING STATS: batch 344/486 in epoch 946,  batch loss: 1.67213, batch accuracy: 0.54300
Time: 2018-07-15 07:29:46
TRAINING STATS: batch 394/486 in epoch 946,  batch loss: 1.64697, batch accuracy: 0.56133
Time: 2018-07-15 07:29:49
TRAINING STATS: batch 444/486 in epoch 946,  batch loss: 1.63118, batch accuracy: 0.56783
Time: 2018-07-15 07:29:53
TRAINING STATS: batch 8/486 in epoch 947,    batch loss: 1.67195, batch accuracy: 0.54900
Time: 2018-07-15 07:29:58
TRAINING STATS: batch 58/486 in epoch 947,   batch loss: 1.66733, batch accuracy: 0.55267
Time: 2018-07-15 07:30:02
TRAINING STATS: batch 108/486 in epoch 947,  batch loss: 1.75374, batch accuracy: 0.53517
Time: 2018-07-15 07:30:05
TRAINING STATS: batch 158/486 in epoch 947,  batch loss: 1.73182, batch accuracy: 0.53817
Time: 2018-07-15 07:30:10
TRAINING STATS: batch 208/486 in epoch 947,  batch loss: 1.70623, batch accuracy: 0.54383
Time: 2018-07-15 07:30:14
TRAINING STATS: batch 258/486 in epoch 947,  batch loss: 1.63861, batch accuracy: 0.56517
Time: 2018-07-15 07:30:17
TRAINING STATS: batch 308/486 in epoch 947,  batch loss: 1.70203, batch accuracy: 0.55083
Time: 2018-07-15 07:30:22
TRAINING STATS: batch 358/486 in epoch 947,  batch loss: 1.70275, batch accuracy: 0.54167
Time: 2018-07-15 07:30:26
TRAINING STATS: batch 408/486 in epoch 947,  batch loss: 1.94495, batch accuracy: 0.45683
Time: 2018-07-15 07:30:29
TRAINING STATS: batch 458/486 in epoch 947,  batch loss: 1.86690, batch accuracy: 0.49833
Time: 2018-07-15 07:30:34
TRAINING STATS: batch 22/486 in epoch 948,   batch loss: 1.84302, batch accuracy: 0.51233
Time: 2018-07-15 07:30:38
TRAINING STATS: batch 72/486 in epoch 948,   batch loss: 1.80271, batch accuracy: 0.50950
Time: 2018-07-15 07:30:42
TRAINING STATS: batch 122/486 in epoch 948,  batch loss: 1.74137, batch accuracy: 0.53767
Time: 2018-07-15 07:30:46
TRAINING STATS: batch 172/486 in epoch 948,  batch loss: 1.81394, batch accuracy: 0.51750
Time: 2018-07-15 07:30:50
TRAINING STATS: batch 222/486 in epoch 948,  batch loss: 1.75266, batch accuracy: 0.52533
Time: 2018-07-15 07:30:54
TRAINING STATS: batch 272/486 in epoch 948,  batch loss: 1.79559, batch accuracy: 0.50283
Time: 2018-07-15 07:30:58
TRAINING STATS: batch 322/486 in epoch 948,  batch loss: 1.77269, batch accuracy: 0.51950
Time: 2018-07-15 07:31:02
TRAINING STATS: batch 372/486 in epoch 948,  batch loss: 1.71068, batch accuracy: 0.54083
Time: 2018-07-15 07:31:06
TRAINING STATS: batch 422/486 in epoch 948,  batch loss: 1.73551, batch accuracy: 0.53733
Time: 2018-07-15 07:31:11
TRAINING STATS: batch 472/486 in epoch 948,  batch loss: 1.79846, batch accuracy: 0.51783
Time: 2018-07-15 07:31:14
TRAINING STATS: batch 36/486 in epoch 949,   batch loss: 1.79680, batch accuracy: 0.51867
Time: 2018-07-15 07:31:18
TRAINING STATS: batch 86/486 in epoch 949,   batch loss: 1.74672, batch accuracy: 0.53200
Time: 2018-07-15 07:31:23
TRAINING STATS: batch 136/486 in epoch 949,  batch loss: 1.80964, batch accuracy: 0.50917
Time: 2018-07-15 07:31:26
TRAINING STATS: batch 186/486 in epoch 949,  batch loss: 1.76332, batch accuracy: 0.52967
Time: 2018-07-15 07:31:30
TRAINING STATS: batch 236/486 in epoch 949,  batch loss: 1.79136, batch accuracy: 0.51150
Time: 2018-07-15 07:31:35
TRAINING STATS: batch 286/486 in epoch 949,  batch loss: 1.78971, batch accuracy: 0.52650
Time: 2018-07-15 07:31:38
TRAINING STATS: batch 336/486 in epoch 949,  batch loss: 1.75168, batch accuracy: 0.53050
Time: 2018-07-15 07:31:42
TRAINING STATS: batch 386/486 in epoch 949,  batch loss: 1.77557, batch accuracy: 0.52250
Time: 2018-07-15 07:31:47
TRAINING STATS: batch 436/486 in epoch 949,  batch loss: 1.75683, batch accuracy: 0.54017
Time: 2018-07-15 07:31:50
TRAINING STATS: batch 0/486 in epoch 950,    batch loss: 1.70814, batch accuracy: 0.54150
Time: 2018-07-15 07:31:54
TRAINING STATS: batch 50/486 in epoch 950,   batch loss: 1.67104, batch accuracy: 0.55967
Time: 2018-07-15 07:31:59
TRAINING STATS: batch 100/486 in epoch 950,  batch loss: 1.74439, batch accuracy: 0.53350
Time: 2018-07-15 07:32:02
TRAINING STATS: batch 150/486 in epoch 950,  batch loss: 1.68341, batch accuracy: 0.54917
Time: 2018-07-15 07:32:06
TRAINING STATS: batch 200/486 in epoch 950,  batch loss: 1.59020, batch accuracy: 0.58250
Time: 2018-07-15 07:32:11
TRAINING STATS: batch 250/486 in epoch 950,  batch loss: 1.76502, batch accuracy: 0.51950
Time: 2018-07-15 07:32:14
TRAINING STATS: batch 300/486 in epoch 950,  batch loss: 1.74121, batch accuracy: 0.53417
Time: 2018-07-15 07:32:18
TRAINING STATS: batch 350/486 in epoch 950,  batch loss: 1.70376, batch accuracy: 0.54550
Time: 2018-07-15 07:32:23
TRAINING STATS: batch 400/486 in epoch 950,  batch loss: 1.59279, batch accuracy: 0.56883
Time: 2018-07-15 07:32:27
TRAINING STATS: batch 450/486 in epoch 950,  batch loss: 1.76917, batch accuracy: 0.51717
Time: 2018-07-15 07:32:30
TRAINING STATS: batch 14/486 in epoch 951,   batch loss: 1.62348, batch accuracy: 0.55917
Time: 2018-07-15 07:32:35
TRAINING STATS: batch 64/486 in epoch 951,   batch loss: 1.78527, batch accuracy: 0.52017
Time: 2018-07-15 07:32:39
TRAINING STATS: batch 114/486 in epoch 951,  batch loss: 1.72401, batch accuracy: 0.53750
Time: 2018-07-15 07:32:42
TRAINING STATS: batch 164/486 in epoch 951,  batch loss: 1.64229, batch accuracy: 0.57050
Time: 2018-07-15 07:32:47
TRAINING STATS: batch 214/486 in epoch 951,  batch loss: 1.68812, batch accuracy: 0.54783
Time: 2018-07-15 07:32:51
TRAINING STATS: batch 264/486 in epoch 951,  batch loss: 1.73656, batch accuracy: 0.53100
Time: 2018-07-15 07:32:54
TRAINING STATS: batch 314/486 in epoch 951,  batch loss: 1.74897, batch accuracy: 0.52183
Time: 2018-07-15 07:32:59
TRAINING STATS: batch 364/486 in epoch 951,  batch loss: 1.67684, batch accuracy: 0.55550
Time: 2018-07-15 07:33:03
TRAINING STATS: batch 414/486 in epoch 951,  batch loss: 1.61188, batch accuracy: 0.55967
Time: 2018-07-15 07:33:07
TRAINING STATS: batch 464/486 in epoch 951,  batch loss: 1.64340, batch accuracy: 0.55767
Time: 2018-07-15 07:33:11
TRAINING STATS: batch 28/486 in epoch 952,   batch loss: 1.61452, batch accuracy: 0.57100
Time: 2018-07-15 07:33:15
TRAINING STATS: batch 78/486 in epoch 952,   batch loss: 1.70027, batch accuracy: 0.54700
Time: 2018-07-15 07:33:19
TRAINING STATS: batch 128/486 in epoch 952,  batch loss: 1.71075, batch accuracy: 0.54133
Time: 2018-07-15 07:33:23
TRAINING STATS: batch 178/486 in epoch 952,  batch loss: 1.60450, batch accuracy: 0.56817
Time: 2018-07-15 07:33:27
TRAINING STATS: batch 228/486 in epoch 952,  batch loss: 1.65118, batch accuracy: 0.55500
Time: 2018-07-15 07:33:31
TRAINING STATS: batch 278/486 in epoch 952,  batch loss: 1.63457, batch accuracy: 0.56800
Time: 2018-07-15 07:33:35
TRAINING STATS: batch 328/486 in epoch 952,  batch loss: 1.64042, batch accuracy: 0.55833
Time: 2018-07-15 07:33:39
TRAINING STATS: batch 378/486 in epoch 952,  batch loss: 1.67864, batch accuracy: 0.55033
Time: 2018-07-15 07:33:43
TRAINING STATS: batch 428/486 in epoch 952,  batch loss: 1.72305, batch accuracy: 0.53333
Time: 2018-07-15 07:33:48
TRAINING STATS: batch 478/486 in epoch 952,  batch loss: 1.69718, batch accuracy: 0.54633
Time: 2018-07-15 07:33:51
TRAINING STATS: batch 42/486 in epoch 953,   batch loss: 1.59661, batch accuracy: 0.57667
Time: 2018-07-15 07:33:55
TRAINING STATS: batch 92/486 in epoch 953,   batch loss: 1.68915, batch accuracy: 0.54450
Time: 2018-07-15 07:34:00
TRAINING STATS: batch 142/486 in epoch 953,  batch loss: 1.64277, batch accuracy: 0.55483
Time: 2018-07-15 07:34:03
TRAINING STATS: batch 192/486 in epoch 953,  batch loss: 1.67610, batch accuracy: 0.54600
Time: 2018-07-15 07:34:07
TRAINING STATS: batch 242/486 in epoch 953,  batch loss: 1.65173, batch accuracy: 0.55417
Time: 2018-07-15 07:34:12
TRAINING STATS: batch 292/486 in epoch 953,  batch loss: 1.67461, batch accuracy: 0.55250
Time: 2018-07-15 07:34:15
TRAINING STATS: batch 342/486 in epoch 953,  batch loss: 1.64517, batch accuracy: 0.55017
Time: 2018-07-15 07:34:19
TRAINING STATS: batch 392/486 in epoch 953,  batch loss: 1.60550, batch accuracy: 0.56767
Time: 2018-07-15 07:34:24
TRAINING STATS: batch 442/486 in epoch 953,  batch loss: 1.58810, batch accuracy: 0.57300
Time: 2018-07-15 07:34:27
TRAINING STATS: batch 6/486 in epoch 954,    batch loss: 1.72582, batch accuracy: 0.53650
Time: 2018-07-15 07:34:31
TRAINING STATS: batch 56/486 in epoch 954,   batch loss: 1.65906, batch accuracy: 0.55600
Time: 2018-07-15 07:34:36
TRAINING STATS: batch 106/486 in epoch 954,  batch loss: 1.74696, batch accuracy: 0.53350
Time: 2018-07-15 07:34:39
TRAINING STATS: batch 156/486 in epoch 954,  batch loss: 1.71963, batch accuracy: 0.54050
Time: 2018-07-15 07:34:43
TRAINING STATS: batch 206/486 in epoch 954,  batch loss: 1.76619, batch accuracy: 0.52667
Time: 2018-07-15 07:34:48
TRAINING STATS: batch 256/486 in epoch 954,  batch loss: 1.62127, batch accuracy: 0.56183
Time: 2018-07-15 07:34:52
TRAINING STATS: batch 306/486 in epoch 954,  batch loss: 1.69743, batch accuracy: 0.54567
Time: 2018-07-15 07:34:55
TRAINING STATS: batch 356/486 in epoch 954,  batch loss: 1.73726, batch accuracy: 0.52783
Time: 2018-07-15 07:35:00
TRAINING STATS: batch 406/486 in epoch 954,  batch loss: 1.76259, batch accuracy: 0.52350
Time: 2018-07-15 07:35:04
TRAINING STATS: batch 456/486 in epoch 954,  batch loss: 1.59134, batch accuracy: 0.57917
Time: 2018-07-15 07:35:07
TRAINING STATS: batch 20/486 in epoch 955,   batch loss: 1.68761, batch accuracy: 0.54000
Time: 2018-07-15 07:35:12
TRAINING STATS: batch 70/486 in epoch 955,   batch loss: 1.61347, batch accuracy: 0.56833
Time: 2018-07-15 07:35:16
TRAINING STATS: batch 120/486 in epoch 955,  batch loss: 1.63874, batch accuracy: 0.55833
Time: 2018-07-15 07:35:19
TRAINING STATS: batch 170/486 in epoch 955,  batch loss: 1.68554, batch accuracy: 0.55767
Time: 2018-07-15 07:35:24
TRAINING STATS: batch 220/486 in epoch 955,  batch loss: 1.61019, batch accuracy: 0.57183
Time: 2018-07-15 07:35:28
TRAINING STATS: batch 270/486 in epoch 955,  batch loss: 1.68064, batch accuracy: 0.53533
Time: 2018-07-15 07:35:32
TRAINING STATS: batch 320/486 in epoch 955,  batch loss: 1.63602, batch accuracy: 0.55717
Time: 2018-07-15 07:35:36
TRAINING STATS: batch 370/486 in epoch 955,  batch loss: 1.69695, batch accuracy: 0.54417
Time: 2018-07-15 07:35:40
TRAINING STATS: batch 420/486 in epoch 955,  batch loss: 1.71680, batch accuracy: 0.54133
Time: 2018-07-15 07:35:44
TRAINING STATS: batch 470/486 in epoch 955,  batch loss: 1.77293, batch accuracy: 0.51633
Time: 2018-07-15 07:35:48
TRAINING STATS: batch 34/486 in epoch 956,   batch loss: 1.69693, batch accuracy: 0.54367
Time: 2018-07-15 07:35:52
TRAINING STATS: batch 84/486 in epoch 956,   batch loss: 1.70485, batch accuracy: 0.53667
Time: 2018-07-15 07:35:56
TRAINING STATS: batch 134/486 in epoch 956,  batch loss: 1.70585, batch accuracy: 0.53967
Time: 2018-07-15 07:36:00
TRAINING STATS: batch 184/486 in epoch 956,  batch loss: 1.72584, batch accuracy: 0.52900
Time: 2018-07-15 07:36:04
TRAINING STATS: batch 234/486 in epoch 956,  batch loss: 1.76047, batch accuracy: 0.52567
Time: 2018-07-15 07:36:08
TRAINING STATS: batch 284/486 in epoch 956,  batch loss: 1.74561, batch accuracy: 0.53050
Time: 2018-07-15 07:36:13
TRAINING STATS: batch 334/486 in epoch 956,  batch loss: 1.66707, batch accuracy: 0.54817
Time: 2018-07-15 07:36:16
TRAINING STATS: batch 384/486 in epoch 956,  batch loss: 1.65172, batch accuracy: 0.55417
Time: 2018-07-15 07:36:20
TRAINING STATS: batch 434/486 in epoch 956,  batch loss: 1.72551, batch accuracy: 0.53150
Time: 2018-07-15 07:36:25
TRAINING STATS: batch 484/486 in epoch 956,  batch loss: 1.69271, batch accuracy: 0.54433
Time: 2018-07-15 07:36:28
TRAINING STATS: batch 48/486 in epoch 957,   batch loss: 1.68738, batch accuracy: 0.54250
Time: 2018-07-15 07:36:32
TRAINING STATS: batch 98/486 in epoch 957,   batch loss: 1.66214, batch accuracy: 0.55233
Time: 2018-07-15 07:36:37
TRAINING STATS: batch 148/486 in epoch 957,  batch loss: 1.73620, batch accuracy: 0.54433
Time: 2018-07-15 07:36:40
TRAINING STATS: batch 198/486 in epoch 957,  batch loss: 1.67454, batch accuracy: 0.55333
Time: 2018-07-15 07:36:44
TRAINING STATS: batch 248/486 in epoch 957,  batch loss: 1.70628, batch accuracy: 0.54267
Time: 2018-07-15 07:36:49
TRAINING STATS: batch 298/486 in epoch 957,  batch loss: 1.72231, batch accuracy: 0.53500
Time: 2018-07-15 07:36:52
TRAINING STATS: batch 348/486 in epoch 957,  batch loss: 1.69934, batch accuracy: 0.54717
Time: 2018-07-15 07:36:56
TRAINING STATS: batch 398/486 in epoch 957,  batch loss: 1.69313, batch accuracy: 0.54867
Time: 2018-07-15 07:37:01
TRAINING STATS: batch 448/486 in epoch 957,  batch loss: 1.68277, batch accuracy: 0.55050
Time: 2018-07-15 07:37:05
TRAINING STATS: batch 12/486 in epoch 958,   batch loss: 1.71246, batch accuracy: 0.53333
Time: 2018-07-15 07:37:08
TRAINING STATS: batch 62/486 in epoch 958,   batch loss: 1.75663, batch accuracy: 0.52600
Time: 2018-07-15 07:37:13
TRAINING STATS: batch 112/486 in epoch 958,  batch loss: 1.67394, batch accuracy: 0.54767
Time: 2018-07-15 07:37:17
TRAINING STATS: batch 162/486 in epoch 958,  batch loss: 1.69092, batch accuracy: 0.54950
Time: 2018-07-15 07:37:20
TRAINING STATS: batch 212/486 in epoch 958,  batch loss: 1.58973, batch accuracy: 0.57700
Time: 2018-07-15 07:37:25
TRAINING STATS: batch 262/486 in epoch 958,  batch loss: 1.73797, batch accuracy: 0.53383
Time: 2018-07-15 07:37:29
TRAINING STATS: batch 312/486 in epoch 958,  batch loss: 1.68078, batch accuracy: 0.54100
Time: 2018-07-15 07:37:32
TRAINING STATS: batch 362/486 in epoch 958,  batch loss: 1.68524, batch accuracy: 0.55267
Time: 2018-07-15 07:37:37
TRAINING STATS: batch 412/486 in epoch 958,  batch loss: 1.62260, batch accuracy: 0.56550
Time: 2018-07-15 07:37:41
TRAINING STATS: batch 462/486 in epoch 958,  batch loss: 1.69829, batch accuracy: 0.53717
Time: 2018-07-15 07:37:44
TRAINING STATS: batch 26/486 in epoch 959,   batch loss: 1.72220, batch accuracy: 0.53383
Time: 2018-07-15 07:37:49
TRAINING STATS: batch 76/486 in epoch 959,   batch loss: 1.72728, batch accuracy: 0.53550
Time: 2018-07-15 07:37:53
TRAINING STATS: batch 126/486 in epoch 959,  batch loss: 1.72358, batch accuracy: 0.53767
Time: 2018-07-15 07:37:56
TRAINING STATS: batch 176/486 in epoch 959,  batch loss: 1.60682, batch accuracy: 0.57533
Time: 2018-07-15 07:38:01
TRAINING STATS: batch 226/486 in epoch 959,  batch loss: 1.67667, batch accuracy: 0.55467
Time: 2018-07-15 07:38:05
TRAINING STATS: batch 276/486 in epoch 959,  batch loss: 1.69448, batch accuracy: 0.54300
Time: 2018-07-15 07:38:09
TRAINING STATS: batch 326/486 in epoch 959,  batch loss: 1.72873, batch accuracy: 0.53800
Time: 2018-07-15 07:38:13
TRAINING STATS: batch 376/486 in epoch 959,  batch loss: 1.71304, batch accuracy: 0.53867
Time: 2018-07-15 07:38:17
TRAINING STATS: batch 426/486 in epoch 959,  batch loss: 1.68621, batch accuracy: 0.53917
Time: 2018-07-15 07:38:21
TRAINING STATS: batch 476/486 in epoch 959,  batch loss: 1.62554, batch accuracy: 0.56583
Time: 2018-07-15 07:38:25
TRAINING STATS: batch 40/486 in epoch 960,   batch loss: 1.65873, batch accuracy: 0.56067
Time: 2018-07-15 07:38:29
TRAINING STATS: batch 90/486 in epoch 960,   batch loss: 1.71958, batch accuracy: 0.53617
Time: 2018-07-15 07:38:33
TRAINING STATS: batch 140/486 in epoch 960,  batch loss: 1.63206, batch accuracy: 0.56450
Time: 2018-07-15 07:38:38
TRAINING STATS: batch 190/486 in epoch 960,  batch loss: 1.66247, batch accuracy: 0.55150
Time: 2018-07-15 07:38:41
TRAINING STATS: batch 240/486 in epoch 960,  batch loss: 1.65406, batch accuracy: 0.55267
Time: 2018-07-15 07:38:45
TRAINING STATS: batch 290/486 in epoch 960,  batch loss: 1.72061, batch accuracy: 0.52733
Time: 2018-07-15 07:38:50
TRAINING STATS: batch 340/486 in epoch 960,  batch loss: 1.74753, batch accuracy: 0.52667
Time: 2018-07-15 07:38:53
TRAINING STATS: batch 390/486 in epoch 960,  batch loss: 1.61251, batch accuracy: 0.57450
Time: 2018-07-15 07:38:57
TRAINING STATS: batch 440/486 in epoch 960,  batch loss: 1.68474, batch accuracy: 0.54517
Time: 2018-07-15 07:39:02
TRAINING STATS: batch 4/486 in epoch 961,    batch loss: 1.62670, batch accuracy: 0.56167
Time: 2018-07-15 07:39:05
TRAINING STATS: batch 54/486 in epoch 961,   batch loss: 1.68466, batch accuracy: 0.54667
Time: 2018-07-15 07:39:09
TRAINING STATS: batch 104/486 in epoch 961,  batch loss: 1.69859, batch accuracy: 0.54517
Time: 2018-07-15 07:39:14
TRAINING STATS: batch 154/486 in epoch 961,  batch loss: 1.66268, batch accuracy: 0.56000
Time: 2018-07-15 07:39:17
TRAINING STATS: batch 204/486 in epoch 961,  batch loss: 1.74227, batch accuracy: 0.53050
Time: 2018-07-15 07:39:21
TRAINING STATS: batch 254/486 in epoch 961,  batch loss: 1.61716, batch accuracy: 0.55833
Time: 2018-07-15 07:39:26
TRAINING STATS: batch 304/486 in epoch 961,  batch loss: 1.64562, batch accuracy: 0.56317
Time: 2018-07-15 07:39:29
TRAINING STATS: batch 354/486 in epoch 961,  batch loss: 1.68895, batch accuracy: 0.55150
Time: 2018-07-15 07:39:33
TRAINING STATS: batch 404/486 in epoch 961,  batch loss: 1.65719, batch accuracy: 0.55817
Time: 2018-07-15 07:39:38
TRAINING STATS: batch 454/486 in epoch 961,  batch loss: 1.54751, batch accuracy: 0.59083
Time: 2018-07-15 07:39:41
TRAINING STATS: batch 18/486 in epoch 962,   batch loss: 1.71087, batch accuracy: 0.54000
Time: 2018-07-15 07:39:45
TRAINING STATS: batch 68/486 in epoch 962,   batch loss: 1.53818, batch accuracy: 0.59550
Time: 2018-07-15 07:39:50
TRAINING STATS: batch 118/486 in epoch 962,  batch loss: 1.67910, batch accuracy: 0.54850
Time: 2018-07-15 07:39:54
TRAINING STATS: batch 168/486 in epoch 962,  batch loss: 1.59090, batch accuracy: 0.57800
Time: 2018-07-15 07:39:57
TRAINING STATS: batch 218/486 in epoch 962,  batch loss: 1.66092, batch accuracy: 0.55717
Time: 2018-07-15 07:40:02
TRAINING STATS: batch 268/486 in epoch 962,  batch loss: 1.62009, batch accuracy: 0.56367
Time: 2018-07-15 07:40:06
TRAINING STATS: batch 318/486 in epoch 962,  batch loss: 1.69746, batch accuracy: 0.54033
Time: 2018-07-15 07:40:09
TRAINING STATS: batch 368/486 in epoch 962,  batch loss: 1.71256, batch accuracy: 0.54267
Time: 2018-07-15 07:40:14
TRAINING STATS: batch 418/486 in epoch 962,  batch loss: 1.72541, batch accuracy: 0.53750
Time: 2018-07-15 07:40:18
TRAINING STATS: batch 468/486 in epoch 962,  batch loss: 1.68853, batch accuracy: 0.55067
Time: 2018-07-15 07:40:21
TRAINING STATS: batch 32/486 in epoch 963,   batch loss: 1.63214, batch accuracy: 0.55483
Time: 2018-07-15 07:40:26
TRAINING STATS: batch 82/486 in epoch 963,   batch loss: 1.70702, batch accuracy: 0.53750
Time: 2018-07-15 07:40:30
TRAINING STATS: batch 132/486 in epoch 963,  batch loss: 1.66879, batch accuracy: 0.55650
Time: 2018-07-15 07:40:34
TRAINING STATS: batch 182/486 in epoch 963,  batch loss: 1.73770, batch accuracy: 0.53450
Time: 2018-07-15 07:40:38
TRAINING STATS: batch 232/486 in epoch 963,  batch loss: 1.71892, batch accuracy: 0.54383
Time: 2018-07-15 07:40:42
TRAINING STATS: batch 282/486 in epoch 963,  batch loss: 1.62614, batch accuracy: 0.56067
Time: 2018-07-15 07:40:46
TRAINING STATS: batch 332/486 in epoch 963,  batch loss: 1.71326, batch accuracy: 0.54233
Time: 2018-07-15 07:40:50
TRAINING STATS: batch 382/486 in epoch 963,  batch loss: 1.70993, batch accuracy: 0.54500
Time: 2018-07-15 07:40:54
TRAINING STATS: batch 432/486 in epoch 963,  batch loss: 1.60034, batch accuracy: 0.56833
Time: 2018-07-15 07:40:58
TRAINING STATS: batch 482/486 in epoch 963,  batch loss: 1.67476, batch accuracy: 0.55350
Time: 2018-07-15 07:41:02
TRAINING STATS: batch 46/486 in epoch 964,   batch loss: 1.64986, batch accuracy: 0.55950
Time: 2018-07-15 07:41:06
TRAINING STATS: batch 96/486 in epoch 964,   batch loss: 1.70686, batch accuracy: 0.54467
Time: 2018-07-15 07:41:10
TRAINING STATS: batch 146/486 in epoch 964,  batch loss: 1.73804, batch accuracy: 0.53183
Time: 2018-07-15 07:41:14
TRAINING STATS: batch 196/486 in epoch 964,  batch loss: 1.71130, batch accuracy: 0.53433
Time: 2018-07-15 07:41:18
TRAINING STATS: batch 246/486 in epoch 964,  batch loss: 1.64362, batch accuracy: 0.55500
Time: 2018-07-15 07:41:22
TRAINING STATS: batch 296/486 in epoch 964,  batch loss: 1.64894, batch accuracy: 0.55183
Time: 2018-07-15 07:41:26
TRAINING STATS: batch 346/486 in epoch 964,  batch loss: 1.61021, batch accuracy: 0.57333
Time: 2018-07-15 07:41:30
TRAINING STATS: batch 396/486 in epoch 964,  batch loss: 1.65755, batch accuracy: 0.56033
Time: 2018-07-15 07:41:34
TRAINING STATS: batch 446/486 in epoch 964,  batch loss: 1.68477, batch accuracy: 0.54950
Time: 2018-07-15 07:41:38
TRAINING STATS: batch 10/486 in epoch 965,   batch loss: 1.72227, batch accuracy: 0.53867
Time: 2018-07-15 07:41:42
TRAINING STATS: batch 60/486 in epoch 965,   batch loss: 1.66519, batch accuracy: 0.54933
Time: 2018-07-15 07:41:46
TRAINING STATS: batch 110/486 in epoch 965,  batch loss: 1.74193, batch accuracy: 0.53267
Time: 2018-07-15 07:41:51
TRAINING STATS: batch 160/486 in epoch 965,  batch loss: 1.65132, batch accuracy: 0.55017
Time: 2018-07-15 07:41:54
TRAINING STATS: batch 210/486 in epoch 965,  batch loss: 1.67478, batch accuracy: 0.54900
Time: 2018-07-15 07:41:58
TRAINING STATS: batch 260/486 in epoch 965,  batch loss: 1.73152, batch accuracy: 0.53200
Time: 2018-07-15 07:42:03
TRAINING STATS: batch 310/486 in epoch 965,  batch loss: 1.70120, batch accuracy: 0.54833
Time: 2018-07-15 07:42:06
TRAINING STATS: batch 360/486 in epoch 965,  batch loss: 1.71244, batch accuracy: 0.54050
Time: 2018-07-15 07:42:10
TRAINING STATS: batch 410/486 in epoch 965,  batch loss: 1.62217, batch accuracy: 0.56533
Time: 2018-07-15 07:42:15
TRAINING STATS: batch 460/486 in epoch 965,  batch loss: 1.82165, batch accuracy: 0.50533
Time: 2018-07-15 07:42:18
TRAINING STATS: batch 24/486 in epoch 966,   batch loss: 1.74118, batch accuracy: 0.53267
Time: 2018-07-15 07:42:22
TRAINING STATS: batch 74/486 in epoch 966,   batch loss: 1.71737, batch accuracy: 0.54017
Time: 2018-07-15 07:42:27
TRAINING STATS: batch 124/486 in epoch 966,  batch loss: 1.70435, batch accuracy: 0.54367
Time: 2018-07-15 07:42:31
TRAINING STATS: batch 174/486 in epoch 966,  batch loss: 1.75340, batch accuracy: 0.52683
Time: 2018-07-15 07:42:34
TRAINING STATS: batch 224/486 in epoch 966,  batch loss: 1.71258, batch accuracy: 0.53967
Time: 2018-07-15 07:42:39
TRAINING STATS: batch 274/486 in epoch 966,  batch loss: 1.68917, batch accuracy: 0.54700
Time: 2018-07-15 07:42:43
TRAINING STATS: batch 324/486 in epoch 966,  batch loss: 1.71155, batch accuracy: 0.54450
Time: 2018-07-15 07:42:46
TRAINING STATS: batch 374/486 in epoch 966,  batch loss: 1.72389, batch accuracy: 0.53950
Time: 2018-07-15 07:42:51
TRAINING STATS: batch 424/486 in epoch 966,  batch loss: 1.62099, batch accuracy: 0.56500
Time: 2018-07-15 07:42:55
TRAINING STATS: batch 474/486 in epoch 966,  batch loss: 1.67646, batch accuracy: 0.54833
Time: 2018-07-15 07:42:58
TRAINING STATS: batch 38/486 in epoch 967,   batch loss: 1.69346, batch accuracy: 0.55317
Time: 2018-07-15 07:43:03
TRAINING STATS: batch 88/486 in epoch 967,   batch loss: 1.74286, batch accuracy: 0.53050
Time: 2018-07-15 07:43:07
TRAINING STATS: batch 138/486 in epoch 967,  batch loss: 1.73032, batch accuracy: 0.53550
Time: 2018-07-15 07:43:10
TRAINING STATS: batch 188/486 in epoch 967,  batch loss: 1.63678, batch accuracy: 0.56500
Time: 2018-07-15 07:43:15
TRAINING STATS: batch 238/486 in epoch 967,  batch loss: 1.67214, batch accuracy: 0.55717
Time: 2018-07-15 07:43:19
TRAINING STATS: batch 288/486 in epoch 967,  batch loss: 1.70674, batch accuracy: 0.53850
Time: 2018-07-15 07:43:23
TRAINING STATS: batch 338/486 in epoch 967,  batch loss: 1.69764, batch accuracy: 0.54617
Time: 2018-07-15 07:43:27
TRAINING STATS: batch 388/486 in epoch 967,  batch loss: 1.63466, batch accuracy: 0.56133
Time: 2018-07-15 07:43:31
TRAINING STATS: batch 438/486 in epoch 967,  batch loss: 1.71037, batch accuracy: 0.54550
Time: 2018-07-15 07:43:35
TRAINING STATS: batch 2/486 in epoch 968,    batch loss: 1.68570, batch accuracy: 0.54450
Time: 2018-07-15 07:43:39
TRAINING STATS: batch 52/486 in epoch 968,   batch loss: 1.74795, batch accuracy: 0.52083
Time: 2018-07-15 07:43:43
TRAINING STATS: batch 102/486 in epoch 968,  batch loss: 1.71075, batch accuracy: 0.54033
Time: 2018-07-15 07:43:47
TRAINING STATS: batch 152/486 in epoch 968,  batch loss: 1.65530, batch accuracy: 0.55800
Time: 2018-07-15 07:43:51
TRAINING STATS: batch 202/486 in epoch 968,  batch loss: 1.67602, batch accuracy: 0.55200
Time: 2018-07-15 07:43:55
TRAINING STATS: batch 252/486 in epoch 968,  batch loss: 1.64387, batch accuracy: 0.56400
Time: 2018-07-15 07:43:59
TRAINING STATS: batch 302/486 in epoch 968,  batch loss: 1.63490, batch accuracy: 0.55833
Time: 2018-07-15 07:44:03
TRAINING STATS: batch 352/486 in epoch 968,  batch loss: 1.67153, batch accuracy: 0.55750
Time: 2018-07-15 07:44:07
TRAINING STATS: batch 402/486 in epoch 968,  batch loss: 1.55574, batch accuracy: 0.59367
Time: 2018-07-15 07:44:11
TRAINING STATS: batch 452/486 in epoch 968,  batch loss: 1.68753, batch accuracy: 0.54550
Time: 2018-07-15 07:44:16
TRAINING STATS: batch 16/486 in epoch 969,   batch loss: 1.64899, batch accuracy: 0.55650
Time: 2018-07-15 07:44:19
TRAINING STATS: batch 66/486 in epoch 969,   batch loss: 1.66841, batch accuracy: 0.55450
Time: 2018-07-15 07:44:23
TRAINING STATS: batch 116/486 in epoch 969,  batch loss: 1.65822, batch accuracy: 0.55867
Time: 2018-07-15 07:44:28
TRAINING STATS: batch 166/486 in epoch 969,  batch loss: 1.59593, batch accuracy: 0.57683
Time: 2018-07-15 07:44:31
TRAINING STATS: batch 216/486 in epoch 969,  batch loss: 1.70344, batch accuracy: 0.54917
Time: 2018-07-15 07:44:35
TRAINING STATS: batch 266/486 in epoch 969,  batch loss: 1.70159, batch accuracy: 0.53967
Time: 2018-07-15 07:44:40
TRAINING STATS: batch 316/486 in epoch 969,  batch loss: 1.67456, batch accuracy: 0.54517
Time: 2018-07-15 07:44:43
TRAINING STATS: batch 366/486 in epoch 969,  batch loss: 1.74772, batch accuracy: 0.52867
Time: 2018-07-15 07:44:47
TRAINING STATS: batch 416/486 in epoch 969,  batch loss: 1.71856, batch accuracy: 0.53733
Time: 2018-07-15 07:44:52
TRAINING STATS: batch 466/486 in epoch 969,  batch loss: 1.56177, batch accuracy: 0.58033
Time: 2018-07-15 07:44:55
TRAINING STATS: batch 30/486 in epoch 970,   batch loss: 1.57161, batch accuracy: 0.57900
Time: 2018-07-15 07:44:59
TRAINING STATS: batch 80/486 in epoch 970,   batch loss: 1.68549, batch accuracy: 0.53900
Time: 2018-07-15 07:45:04
TRAINING STATS: batch 130/486 in epoch 970,  batch loss: 1.67824, batch accuracy: 0.55383
Time: 2018-07-15 07:45:08
TRAINING STATS: batch 180/486 in epoch 970,  batch loss: 1.72168, batch accuracy: 0.54267
Time: 2018-07-15 07:45:11
TRAINING STATS: batch 230/486 in epoch 970,  batch loss: 1.70693, batch accuracy: 0.53833
Time: 2018-07-15 07:45:16
TRAINING STATS: batch 280/486 in epoch 970,  batch loss: 1.68090, batch accuracy: 0.53917
Time: 2018-07-15 07:45:20
TRAINING STATS: batch 330/486 in epoch 970,  batch loss: 1.66183, batch accuracy: 0.55400
Time: 2018-07-15 07:45:23
TRAINING STATS: batch 380/486 in epoch 970,  batch loss: 1.65120, batch accuracy: 0.56967
Time: 2018-07-15 07:45:28
TRAINING STATS: batch 430/486 in epoch 970,  batch loss: 1.61486, batch accuracy: 0.57283
Time: 2018-07-15 07:45:32
TRAINING STATS: batch 480/486 in epoch 970,  batch loss: 1.70657, batch accuracy: 0.54767
Time: 2018-07-15 07:45:35
TRAINING STATS: batch 44/486 in epoch 971,   batch loss: 1.72941, batch accuracy: 0.52817
Time: 2018-07-15 07:45:40
TRAINING STATS: batch 94/486 in epoch 971,   batch loss: 1.76226, batch accuracy: 0.53133
Time: 2018-07-15 07:45:44
TRAINING STATS: batch 144/486 in epoch 971,  batch loss: 1.74372, batch accuracy: 0.53433
Time: 2018-07-15 07:45:48
TRAINING STATS: batch 194/486 in epoch 971,  batch loss: 1.77399, batch accuracy: 0.51517
Time: 2018-07-15 07:45:52
TRAINING STATS: batch 244/486 in epoch 971,  batch loss: 1.66181, batch accuracy: 0.55300
Time: 2018-07-15 07:45:56
TRAINING STATS: batch 294/486 in epoch 971,  batch loss: 1.60255, batch accuracy: 0.57800
Time: 2018-07-15 07:46:00
TRAINING STATS: batch 344/486 in epoch 971,  batch loss: 1.66671, batch accuracy: 0.54883
Time: 2018-07-15 07:46:04
TRAINING STATS: batch 394/486 in epoch 971,  batch loss: 1.64537, batch accuracy: 0.56100
Time: 2018-07-15 07:46:08
TRAINING STATS: batch 444/486 in epoch 971,  batch loss: 1.61699, batch accuracy: 0.56967
Time: 2018-07-15 07:46:12
TRAINING STATS: batch 8/486 in epoch 972,    batch loss: 1.67344, batch accuracy: 0.55150
Time: 2018-07-15 07:46:16
TRAINING STATS: batch 58/486 in epoch 972,   batch loss: 1.65647, batch accuracy: 0.56100
Time: 2018-07-15 07:46:20
TRAINING STATS: batch 108/486 in epoch 972,  batch loss: 1.75944, batch accuracy: 0.53050
Time: 2018-07-15 07:46:24
TRAINING STATS: batch 158/486 in epoch 972,  batch loss: 1.72738, batch accuracy: 0.54150
Time: 2018-07-15 07:46:29
TRAINING STATS: batch 208/486 in epoch 972,  batch loss: 1.69576, batch accuracy: 0.54567
Time: 2018-07-15 07:46:32
TRAINING STATS: batch 258/486 in epoch 972,  batch loss: 1.64194, batch accuracy: 0.56150
Time: 2018-07-15 07:46:36
TRAINING STATS: batch 308/486 in epoch 972,  batch loss: 1.69714, batch accuracy: 0.55200
Time: 2018-07-15 07:46:41
TRAINING STATS: batch 358/486 in epoch 972,  batch loss: 1.70537, batch accuracy: 0.54083
Time: 2018-07-15 07:46:44
TRAINING STATS: batch 408/486 in epoch 972,  batch loss: 1.71451, batch accuracy: 0.54367
Time: 2018-07-15 07:46:48
TRAINING STATS: batch 458/486 in epoch 972,  batch loss: 1.70299, batch accuracy: 0.54350
Time: 2018-07-15 07:46:53
TRAINING STATS: batch 22/486 in epoch 973,   batch loss: 1.71660, batch accuracy: 0.55350
Time: 2018-07-15 07:46:56
TRAINING STATS: batch 72/486 in epoch 973,   batch loss: 1.69550, batch accuracy: 0.53800
Time: 2018-07-15 07:47:00
TRAINING STATS: batch 122/486 in epoch 973,  batch loss: 1.62633, batch accuracy: 0.57083
Time: 2018-07-15 07:47:05
TRAINING STATS: batch 172/486 in epoch 973,  batch loss: 1.74013, batch accuracy: 0.53533
Time: 2018-07-15 07:47:08
TRAINING STATS: batch 222/486 in epoch 973,  batch loss: 1.68688, batch accuracy: 0.54450
Time: 2018-07-15 07:47:12
TRAINING STATS: batch 272/486 in epoch 973,  batch loss: 1.71533, batch accuracy: 0.53133
Time: 2018-07-15 07:47:17
TRAINING STATS: batch 322/486 in epoch 973,  batch loss: 1.67358, batch accuracy: 0.54717
Time: 2018-07-15 07:47:20
TRAINING STATS: batch 372/486 in epoch 973,  batch loss: 1.63797, batch accuracy: 0.55717
Time: 2018-07-15 07:47:24
TRAINING STATS: batch 422/486 in epoch 973,  batch loss: 1.68152, batch accuracy: 0.54750
Time: 2018-07-15 07:47:29
TRAINING STATS: batch 472/486 in epoch 973,  batch loss: 1.76285, batch accuracy: 0.52133
Time: 2018-07-15 07:47:32
TRAINING STATS: batch 36/486 in epoch 974,   batch loss: 1.73296, batch accuracy: 0.53983
Time: 2018-07-15 07:47:36
TRAINING STATS: batch 86/486 in epoch 974,   batch loss: 1.67487, batch accuracy: 0.55767
Time: 2018-07-15 07:47:41
TRAINING STATS: batch 136/486 in epoch 974,  batch loss: 1.73809, batch accuracy: 0.53167
Time: 2018-07-15 07:47:44
TRAINING STATS: batch 186/486 in epoch 974,  batch loss: 1.69231, batch accuracy: 0.55183
Time: 2018-07-15 07:47:48
TRAINING STATS: batch 236/486 in epoch 974,  batch loss: 1.70724, batch accuracy: 0.53883
Time: 2018-07-15 07:47:53
TRAINING STATS: batch 286/486 in epoch 974,  batch loss: 1.72876, batch accuracy: 0.53450
Time: 2018-07-15 07:47:57
TRAINING STATS: batch 336/486 in epoch 974,  batch loss: 1.66637, batch accuracy: 0.55100
Time: 2018-07-15 07:48:00
TRAINING STATS: batch 386/486 in epoch 974,  batch loss: 1.72278, batch accuracy: 0.53817
Time: 2018-07-15 07:48:05
TRAINING STATS: batch 436/486 in epoch 974,  batch loss: 1.70173, batch accuracy: 0.54467
Time: 2018-07-15 07:48:09
TRAINING STATS: batch 0/486 in epoch 975,    batch loss: 1.66525, batch accuracy: 0.55183
Time: 2018-07-15 07:48:12
TRAINING STATS: batch 50/486 in epoch 975,   batch loss: 1.64716, batch accuracy: 0.56017
Time: 2018-07-15 07:48:17
TRAINING STATS: batch 100/486 in epoch 975,  batch loss: 1.71121, batch accuracy: 0.53933
Time: 2018-07-15 07:48:21
TRAINING STATS: batch 150/486 in epoch 975,  batch loss: 1.65401, batch accuracy: 0.56583
Time: 2018-07-15 07:48:24
TRAINING STATS: batch 200/486 in epoch 975,  batch loss: 1.55828, batch accuracy: 0.58450
Time: 2018-07-15 07:48:29
TRAINING STATS: batch 250/486 in epoch 975,  batch loss: 1.75220, batch accuracy: 0.52683
Time: 2018-07-15 07:48:33
TRAINING STATS: batch 300/486 in epoch 975,  batch loss: 1.72367, batch accuracy: 0.53367
Time: 2018-07-15 07:48:37
TRAINING STATS: batch 350/486 in epoch 975,  batch loss: 1.69749, batch accuracy: 0.55033
Time: 2018-07-15 07:48:41
TRAINING STATS: batch 400/486 in epoch 975,  batch loss: 1.58231, batch accuracy: 0.57850
Time: 2018-07-15 07:48:45
TRAINING STATS: batch 450/486 in epoch 975,  batch loss: 1.74920, batch accuracy: 0.52383
Time: 2018-07-15 07:48:49
TRAINING STATS: batch 14/486 in epoch 976,   batch loss: 1.60887, batch accuracy: 0.57283
Time: 2018-07-15 07:48:53
TRAINING STATS: batch 64/486 in epoch 976,   batch loss: 1.77641, batch accuracy: 0.52167
Time: 2018-07-15 07:48:57
TRAINING STATS: batch 114/486 in epoch 976,  batch loss: 1.73806, batch accuracy: 0.53300
Time: 2018-07-15 07:49:01
TRAINING STATS: batch 164/486 in epoch 976,  batch loss: 1.63189, batch accuracy: 0.56933
Time: 2018-07-15 07:49:05
TRAINING STATS: batch 214/486 in epoch 976,  batch loss: 1.68697, batch accuracy: 0.53967
Time: 2018-07-15 07:49:09
TRAINING STATS: batch 264/486 in epoch 976,  batch loss: 1.73594, batch accuracy: 0.53600
Time: 2018-07-15 07:49:13
TRAINING STATS: batch 314/486 in epoch 976,  batch loss: 1.74712, batch accuracy: 0.52250
Time: 2018-07-15 07:49:17
TRAINING STATS: batch 364/486 in epoch 976,  batch loss: 1.65798, batch accuracy: 0.55767
Time: 2018-07-15 07:49:21
TRAINING STATS: batch 414/486 in epoch 976,  batch loss: 1.61090, batch accuracy: 0.56317
Time: 2018-07-15 07:49:25
TRAINING STATS: batch 464/486 in epoch 976,  batch loss: 1.65047, batch accuracy: 0.55800
Time: 2018-07-15 07:49:29
TRAINING STATS: batch 28/486 in epoch 977,   batch loss: 1.61444, batch accuracy: 0.57050
Time: 2018-07-15 07:49:33
TRAINING STATS: batch 78/486 in epoch 977,   batch loss: 1.69146, batch accuracy: 0.55317
Time: 2018-07-15 07:49:37
TRAINING STATS: batch 128/486 in epoch 977,  batch loss: 1.65508, batch accuracy: 0.56133
Time: 2018-07-15 07:49:41
TRAINING STATS: batch 178/486 in epoch 977,  batch loss: 1.57971, batch accuracy: 0.57333
Time: 2018-07-15 07:49:45
TRAINING STATS: batch 228/486 in epoch 977,  batch loss: 1.62315, batch accuracy: 0.56833
Time: 2018-07-15 07:49:49
TRAINING STATS: batch 278/486 in epoch 977,  batch loss: 1.62793, batch accuracy: 0.56450
Time: 2018-07-15 07:49:54
TRAINING STATS: batch 328/486 in epoch 977,  batch loss: 1.63914, batch accuracy: 0.55700
Time: 2018-07-15 07:49:57
TRAINING STATS: batch 378/486 in epoch 977,  batch loss: 1.68535, batch accuracy: 0.54633
Time: 2018-07-15 07:50:01
TRAINING STATS: batch 428/486 in epoch 977,  batch loss: 1.72655, batch accuracy: 0.53450
Time: 2018-07-15 07:50:06
TRAINING STATS: batch 478/486 in epoch 977,  batch loss: 1.71576, batch accuracy: 0.53500
Time: 2018-07-15 07:50:09
TRAINING STATS: batch 42/486 in epoch 978,   batch loss: 1.58420, batch accuracy: 0.57883
Time: 2018-07-15 07:50:13
TRAINING STATS: batch 92/486 in epoch 978,   batch loss: 1.69632, batch accuracy: 0.54983
Time: 2018-07-15 07:50:18
TRAINING STATS: batch 142/486 in epoch 978,  batch loss: 1.62880, batch accuracy: 0.55850
Time: 2018-07-15 07:50:21
TRAINING STATS: batch 192/486 in epoch 978,  batch loss: 1.66440, batch accuracy: 0.55050
Time: 2018-07-15 07:50:25
TRAINING STATS: batch 242/486 in epoch 978,  batch loss: 1.64061, batch accuracy: 0.56733
Time: 2018-07-15 07:50:30
TRAINING STATS: batch 292/486 in epoch 978,  batch loss: 1.67348, batch accuracy: 0.56083
Time: 2018-07-15 07:50:33
TRAINING STATS: batch 342/486 in epoch 978,  batch loss: 1.64678, batch accuracy: 0.55833
Time: 2018-07-15 07:50:37
TRAINING STATS: batch 392/486 in epoch 978,  batch loss: 1.59192, batch accuracy: 0.58033
Time: 2018-07-15 07:50:42
TRAINING STATS: batch 442/486 in epoch 978,  batch loss: 1.59675, batch accuracy: 0.57267
Time: 2018-07-15 07:50:46
TRAINING STATS: batch 6/486 in epoch 979,    batch loss: 1.74917, batch accuracy: 0.53367
Time: 2018-07-15 07:50:49
TRAINING STATS: batch 56/486 in epoch 979,   batch loss: 1.64361, batch accuracy: 0.55683
Time: 2018-07-15 07:50:54
TRAINING STATS: batch 106/486 in epoch 979,  batch loss: 1.76257, batch accuracy: 0.53033
Time: 2018-07-15 07:50:58
TRAINING STATS: batch 156/486 in epoch 979,  batch loss: 1.71472, batch accuracy: 0.54317
Time: 2018-07-15 07:51:01
TRAINING STATS: batch 206/486 in epoch 979,  batch loss: 1.76553, batch accuracy: 0.52283
Time: 2018-07-15 07:51:06
TRAINING STATS: batch 256/486 in epoch 979,  batch loss: 1.62319, batch accuracy: 0.55883
Time: 2018-07-15 07:51:10
TRAINING STATS: batch 306/486 in epoch 979,  batch loss: 1.68702, batch accuracy: 0.54933
Time: 2018-07-15 07:51:13
TRAINING STATS: batch 356/486 in epoch 979,  batch loss: 1.72591, batch accuracy: 0.53350
Time: 2018-07-15 07:51:18
TRAINING STATS: batch 406/486 in epoch 979,  batch loss: 1.75421, batch accuracy: 0.52883
Time: 2018-07-15 07:51:22
TRAINING STATS: batch 456/486 in epoch 979,  batch loss: 1.57370, batch accuracy: 0.58567
Time: 2018-07-15 07:51:25
TRAINING STATS: batch 20/486 in epoch 980,   batch loss: 1.67827, batch accuracy: 0.54800
Time: 2018-07-15 07:51:30
TRAINING STATS: batch 70/486 in epoch 980,   batch loss: 1.56999, batch accuracy: 0.58217
Time: 2018-07-15 07:51:34
TRAINING STATS: batch 120/486 in epoch 980,  batch loss: 1.63549, batch accuracy: 0.56483
Time: 2018-07-15 07:51:37
TRAINING STATS: batch 170/486 in epoch 980,  batch loss: 1.65664, batch accuracy: 0.55983
Time: 2018-07-15 07:51:42
TRAINING STATS: batch 220/486 in epoch 980,  batch loss: 1.59783, batch accuracy: 0.57500
Time: 2018-07-15 07:51:46
TRAINING STATS: batch 270/486 in epoch 980,  batch loss: 1.67302, batch accuracy: 0.53183
Time: 2018-07-15 07:51:50
TRAINING STATS: batch 320/486 in epoch 980,  batch loss: 1.62775, batch accuracy: 0.55917
Time: 2018-07-15 07:51:54
TRAINING STATS: batch 370/486 in epoch 980,  batch loss: 1.68899, batch accuracy: 0.54333
Time: 2018-07-15 07:51:58
TRAINING STATS: batch 420/486 in epoch 980,  batch loss: 1.71305, batch accuracy: 0.54183
Time: 2018-07-15 07:52:02
TRAINING STATS: batch 470/486 in epoch 980,  batch loss: 1.77819, batch accuracy: 0.52383
Time: 2018-07-15 07:52:06
TRAINING STATS: batch 34/486 in epoch 981,   batch loss: 1.70929, batch accuracy: 0.54417
Time: 2018-07-15 07:52:10
TRAINING STATS: batch 84/486 in epoch 981,   batch loss: 1.68694, batch accuracy: 0.54150
Time: 2018-07-15 07:52:14
TRAINING STATS: batch 134/486 in epoch 981,  batch loss: 1.70912, batch accuracy: 0.53850
Time: 2018-07-15 07:52:19
TRAINING STATS: batch 184/486 in epoch 981,  batch loss: 1.70191, batch accuracy: 0.53933
Time: 2018-07-15 07:52:22
TRAINING STATS: batch 234/486 in epoch 981,  batch loss: 1.75214, batch accuracy: 0.52650
Time: 2018-07-15 07:52:26
TRAINING STATS: batch 284/486 in epoch 981,  batch loss: 1.72728, batch accuracy: 0.53550
Time: 2018-07-15 07:52:31
TRAINING STATS: batch 334/486 in epoch 981,  batch loss: 1.66223, batch accuracy: 0.56133
Time: 2018-07-15 07:52:34
TRAINING STATS: batch 384/486 in epoch 981,  batch loss: 1.65131, batch accuracy: 0.54867
Time: 2018-07-15 07:52:38
TRAINING STATS: batch 434/486 in epoch 981,  batch loss: 1.73773, batch accuracy: 0.52783
Time: 2018-07-15 07:52:43
TRAINING STATS: batch 484/486 in epoch 981,  batch loss: 1.69118, batch accuracy: 0.54567
Time: 2018-07-15 07:52:46
TRAINING STATS: batch 48/486 in epoch 982,   batch loss: 1.66772, batch accuracy: 0.54867
Time: 2018-07-15 07:52:50
TRAINING STATS: batch 98/486 in epoch 982,   batch loss: 1.62504, batch accuracy: 0.56900
Time: 2018-07-15 07:52:55
TRAINING STATS: batch 148/486 in epoch 982,  batch loss: 1.71063, batch accuracy: 0.55133
Time: 2018-07-15 07:52:58
TRAINING STATS: batch 198/486 in epoch 982,  batch loss: 1.66865, batch accuracy: 0.54667
Time: 2018-07-15 07:53:02
TRAINING STATS: batch 248/486 in epoch 982,  batch loss: 1.69478, batch accuracy: 0.54450
Time: 2018-07-15 07:53:07
TRAINING STATS: batch 298/486 in epoch 982,  batch loss: 1.69626, batch accuracy: 0.53867
Time: 2018-07-15 07:53:11
TRAINING STATS: batch 348/486 in epoch 982,  batch loss: 1.68650, batch accuracy: 0.54583
Time: 2018-07-15 07:53:14
TRAINING STATS: batch 398/486 in epoch 982,  batch loss: 1.68295, batch accuracy: 0.55467
Time: 2018-07-15 07:53:19
TRAINING STATS: batch 448/486 in epoch 982,  batch loss: 1.66556, batch accuracy: 0.55700
Time: 2018-07-15 07:53:23
TRAINING STATS: batch 12/486 in epoch 983,   batch loss: 1.70358, batch accuracy: 0.53917
Time: 2018-07-15 07:53:26
TRAINING STATS: batch 62/486 in epoch 983,   batch loss: 1.75888, batch accuracy: 0.51967
Time: 2018-07-15 07:53:31
TRAINING STATS: batch 112/486 in epoch 983,  batch loss: 1.66492, batch accuracy: 0.55383
Time: 2018-07-15 07:53:35
TRAINING STATS: batch 162/486 in epoch 983,  batch loss: 1.68958, batch accuracy: 0.54983
Time: 2018-07-15 07:53:38
TRAINING STATS: batch 212/486 in epoch 983,  batch loss: 1.58840, batch accuracy: 0.57517
Time: 2018-07-15 07:53:43
TRAINING STATS: batch 262/486 in epoch 983,  batch loss: 1.73043, batch accuracy: 0.53333
Time: 2018-07-15 07:53:47
TRAINING STATS: batch 312/486 in epoch 983,  batch loss: 1.68444, batch accuracy: 0.53300
Time: 2018-07-15 07:53:51
TRAINING STATS: batch 362/486 in epoch 983,  batch loss: 1.68468, batch accuracy: 0.54533
Time: 2018-07-15 07:53:55
TRAINING STATS: batch 412/486 in epoch 983,  batch loss: 1.62175, batch accuracy: 0.56867
Time: 2018-07-15 07:53:59
TRAINING STATS: batch 462/486 in epoch 983,  batch loss: 1.70016, batch accuracy: 0.54233
Time: 2018-07-15 07:54:03
TRAINING STATS: batch 26/486 in epoch 984,   batch loss: 1.70233, batch accuracy: 0.54217
Time: 2018-07-15 07:54:07
TRAINING STATS: batch 76/486 in epoch 984,   batch loss: 1.72924, batch accuracy: 0.53650
Time: 2018-07-15 07:54:11
TRAINING STATS: batch 126/486 in epoch 984,  batch loss: 1.72005, batch accuracy: 0.53417
Time: 2018-07-15 07:54:15
TRAINING STATS: batch 176/486 in epoch 984,  batch loss: 1.62447, batch accuracy: 0.57267
Time: 2018-07-15 07:54:19
TRAINING STATS: batch 226/486 in epoch 984,  batch loss: 1.68265, batch accuracy: 0.54983
Time: 2018-07-15 07:54:23
TRAINING STATS: batch 276/486 in epoch 984,  batch loss: 1.68164, batch accuracy: 0.54933
Time: 2018-07-15 07:54:27
TRAINING STATS: batch 326/486 in epoch 984,  batch loss: 1.74455, batch accuracy: 0.53567
Time: 2018-07-15 07:54:32
TRAINING STATS: batch 376/486 in epoch 984,  batch loss: 1.70629, batch accuracy: 0.53767
Time: 2018-07-15 07:54:35
TRAINING STATS: batch 426/486 in epoch 984,  batch loss: 1.67219, batch accuracy: 0.54933
Time: 2018-07-15 07:54:39
TRAINING STATS: batch 476/486 in epoch 984,  batch loss: 1.61331, batch accuracy: 0.56683
Time: 2018-07-15 07:54:44
TRAINING STATS: batch 40/486 in epoch 985,   batch loss: 1.63779, batch accuracy: 0.56900
Time: 2018-07-15 07:54:47
TRAINING STATS: batch 90/486 in epoch 985,   batch loss: 1.70285, batch accuracy: 0.54233
Time: 2018-07-15 07:54:51
TRAINING STATS: batch 140/486 in epoch 985,  batch loss: 1.64734, batch accuracy: 0.55833
Time: 2018-07-15 07:54:56
TRAINING STATS: batch 190/486 in epoch 985,  batch loss: 1.65743, batch accuracy: 0.55500
Time: 2018-07-15 07:54:59
TRAINING STATS: batch 240/486 in epoch 985,  batch loss: 1.66213, batch accuracy: 0.55067
Time: 2018-07-15 07:55:03
TRAINING STATS: batch 290/486 in epoch 985,  batch loss: 1.69645, batch accuracy: 0.54033
Time: 2018-07-15 07:55:08
TRAINING STATS: batch 340/486 in epoch 985,  batch loss: 1.75125, batch accuracy: 0.52367
Time: 2018-07-15 07:55:12
TRAINING STATS: batch 390/486 in epoch 985,  batch loss: 1.64374, batch accuracy: 0.56083
Time: 2018-07-15 07:55:15
TRAINING STATS: batch 440/486 in epoch 985,  batch loss: 1.70708, batch accuracy: 0.53783
Time: 2018-07-15 07:55:20
TRAINING STATS: batch 4/486 in epoch 986,    batch loss: 1.62581, batch accuracy: 0.56283
Time: 2018-07-15 07:55:24
TRAINING STATS: batch 54/486 in epoch 986,   batch loss: 1.67915, batch accuracy: 0.55300
Time: 2018-07-15 07:55:27
TRAINING STATS: batch 104/486 in epoch 986,  batch loss: 1.69267, batch accuracy: 0.55683
Time: 2018-07-15 07:55:32
TRAINING STATS: batch 154/486 in epoch 986,  batch loss: 1.66512, batch accuracy: 0.55783
Time: 2018-07-15 07:55:36
TRAINING STATS: batch 204/486 in epoch 986,  batch loss: 1.79756, batch accuracy: 0.51933
Time: 2018-07-15 07:55:39
TRAINING STATS: batch 254/486 in epoch 986,  batch loss: 1.61693, batch accuracy: 0.55733
Time: 2018-07-15 07:55:44
TRAINING STATS: batch 304/486 in epoch 986,  batch loss: 1.64358, batch accuracy: 0.56300
Time: 2018-07-15 07:55:48
TRAINING STATS: batch 354/486 in epoch 986,  batch loss: 1.67948, batch accuracy: 0.55100
Time: 2018-07-15 07:55:52
TRAINING STATS: batch 404/486 in epoch 986,  batch loss: 1.64418, batch accuracy: 0.55850
Time: 2018-07-15 07:55:56
TRAINING STATS: batch 454/486 in epoch 986,  batch loss: 1.55051, batch accuracy: 0.58250
Time: 2018-07-15 07:56:00
TRAINING STATS: batch 18/486 in epoch 987,   batch loss: 1.69736, batch accuracy: 0.54467
Time: 2018-07-15 07:56:04
TRAINING STATS: batch 68/486 in epoch 987,   batch loss: 1.53009, batch accuracy: 0.59183
Time: 2018-07-15 07:56:08
TRAINING STATS: batch 118/486 in epoch 987,  batch loss: 1.66066, batch accuracy: 0.55617
Time: 2018-07-15 07:56:12
TRAINING STATS: batch 168/486 in epoch 987,  batch loss: 1.59839, batch accuracy: 0.57333
Time: 2018-07-15 07:56:16
TRAINING STATS: batch 218/486 in epoch 987,  batch loss: 1.66484, batch accuracy: 0.55750
Time: 2018-07-15 07:56:20
TRAINING STATS: batch 268/486 in epoch 987,  batch loss: 1.62501, batch accuracy: 0.56133
Time: 2018-07-15 07:56:24
TRAINING STATS: batch 318/486 in epoch 987,  batch loss: 1.66285, batch accuracy: 0.54733
Time: 2018-07-15 07:56:28
TRAINING STATS: batch 368/486 in epoch 987,  batch loss: 1.69323, batch accuracy: 0.53900
Time: 2018-07-15 07:56:33
TRAINING STATS: batch 418/486 in epoch 987,  batch loss: 1.73053, batch accuracy: 0.53783
Time: 2018-07-15 07:56:36
TRAINING STATS: batch 468/486 in epoch 987,  batch loss: 1.68973, batch accuracy: 0.54267
Time: 2018-07-15 07:56:40
TRAINING STATS: batch 32/486 in epoch 988,   batch loss: 1.62108, batch accuracy: 0.55983
Time: 2018-07-15 07:56:45
TRAINING STATS: batch 82/486 in epoch 988,   batch loss: 1.70893, batch accuracy: 0.53650
Time: 2018-07-15 07:56:48
TRAINING STATS: batch 132/486 in epoch 988,  batch loss: 1.66933, batch accuracy: 0.56033
Time: 2018-07-15 07:56:52
TRAINING STATS: batch 182/486 in epoch 988,  batch loss: 1.71367, batch accuracy: 0.53600
Time: 2018-07-15 07:56:57
TRAINING STATS: batch 232/486 in epoch 988,  batch loss: 1.69539, batch accuracy: 0.54250
Time: 2018-07-15 07:57:00
TRAINING STATS: batch 282/486 in epoch 988,  batch loss: 1.63331, batch accuracy: 0.55217
Time: 2018-07-15 07:57:04
TRAINING STATS: batch 332/486 in epoch 988,  batch loss: 1.71147, batch accuracy: 0.54333
Time: 2018-07-15 07:57:09
TRAINING STATS: batch 382/486 in epoch 988,  batch loss: 1.69100, batch accuracy: 0.54567
Time: 2018-07-15 07:57:12
TRAINING STATS: batch 432/486 in epoch 988,  batch loss: 1.60425, batch accuracy: 0.56883
Time: 2018-07-15 07:57:16
TRAINING STATS: batch 482/486 in epoch 988,  batch loss: 1.65898, batch accuracy: 0.55667
Time: 2018-07-15 07:57:21
TRAINING STATS: batch 46/486 in epoch 989,   batch loss: 1.64022, batch accuracy: 0.56333
Time: 2018-07-15 07:57:24
TRAINING STATS: batch 96/486 in epoch 989,   batch loss: 1.70627, batch accuracy: 0.54217
Time: 2018-07-15 07:57:28
TRAINING STATS: batch 146/486 in epoch 989,  batch loss: 1.71652, batch accuracy: 0.53983
Time: 2018-07-15 07:57:33
TRAINING STATS: batch 196/486 in epoch 989,  batch loss: 1.70824, batch accuracy: 0.53367
Time: 2018-07-15 07:57:37
TRAINING STATS: batch 246/486 in epoch 989,  batch loss: 1.64994, batch accuracy: 0.55683
Time: 2018-07-15 07:57:40
TRAINING STATS: batch 296/486 in epoch 989,  batch loss: 1.65054, batch accuracy: 0.55400
Time: 2018-07-15 07:57:45
TRAINING STATS: batch 346/486 in epoch 989,  batch loss: 1.61849, batch accuracy: 0.56900
Time: 2018-07-15 07:57:49
TRAINING STATS: batch 396/486 in epoch 989,  batch loss: 1.65502, batch accuracy: 0.55933
Time: 2018-07-15 07:57:52
TRAINING STATS: batch 446/486 in epoch 989,  batch loss: 1.69056, batch accuracy: 0.54700
Time: 2018-07-15 07:57:57
TRAINING STATS: batch 10/486 in epoch 990,   batch loss: 1.71581, batch accuracy: 0.53717
Time: 2018-07-15 07:58:01
TRAINING STATS: batch 60/486 in epoch 990,   batch loss: 1.67595, batch accuracy: 0.54733
Time: 2018-07-15 07:58:04
TRAINING STATS: batch 110/486 in epoch 990,  batch loss: 1.74069, batch accuracy: 0.52967
Time: 2018-07-15 07:58:09
TRAINING STATS: batch 160/486 in epoch 990,  batch loss: 1.64060, batch accuracy: 0.55400
Time: 2018-07-15 07:58:13
TRAINING STATS: batch 210/486 in epoch 990,  batch loss: 1.64971, batch accuracy: 0.55550
Time: 2018-07-15 07:58:16
TRAINING STATS: batch 260/486 in epoch 990,  batch loss: 1.70139, batch accuracy: 0.54133
Time: 2018-07-15 07:58:21
TRAINING STATS: batch 310/486 in epoch 990,  batch loss: 1.69106, batch accuracy: 0.54433
Time: 2018-07-15 07:58:25
TRAINING STATS: batch 360/486 in epoch 990,  batch loss: 1.68979, batch accuracy: 0.54083
Time: 2018-07-15 07:58:29
TRAINING STATS: batch 410/486 in epoch 990,  batch loss: 1.64078, batch accuracy: 0.55700
Time: 2018-07-15 07:58:33
TRAINING STATS: batch 460/486 in epoch 990,  batch loss: 1.81352, batch accuracy: 0.50383
Time: 2018-07-15 07:58:37
TRAINING STATS: batch 24/486 in epoch 991,   batch loss: 1.73864, batch accuracy: 0.53317
Time: 2018-07-15 07:58:41
TRAINING STATS: batch 74/486 in epoch 991,   batch loss: 1.71641, batch accuracy: 0.54017
Time: 2018-07-15 07:58:45
TRAINING STATS: batch 124/486 in epoch 991,  batch loss: 1.69233, batch accuracy: 0.54950
Time: 2018-07-15 07:58:49
TRAINING STATS: batch 174/486 in epoch 991,  batch loss: 1.74295, batch accuracy: 0.53150
Time: 2018-07-15 07:58:53
TRAINING STATS: batch 224/486 in epoch 991,  batch loss: 1.71736, batch accuracy: 0.53650
Time: 2018-07-15 07:58:58
TRAINING STATS: batch 274/486 in epoch 991,  batch loss: 1.67618, batch accuracy: 0.55200
Time: 2018-07-15 07:59:01
TRAINING STATS: batch 324/486 in epoch 991,  batch loss: 1.71224, batch accuracy: 0.53833
Time: 2018-07-15 07:59:05
TRAINING STATS: batch 374/486 in epoch 991,  batch loss: 1.71826, batch accuracy: 0.53600
Time: 2018-07-15 07:59:10
TRAINING STATS: batch 424/486 in epoch 991,  batch loss: 1.61198, batch accuracy: 0.57300
Time: 2018-07-15 07:59:13
TRAINING STATS: batch 474/486 in epoch 991,  batch loss: 1.67729, batch accuracy: 0.54850
Time: 2018-07-15 07:59:17
TRAINING STATS: batch 38/486 in epoch 992,   batch loss: 1.69751, batch accuracy: 0.54833
Time: 2018-07-15 07:59:22
TRAINING STATS: batch 88/486 in epoch 992,   batch loss: 1.73197, batch accuracy: 0.53750
Time: 2018-07-15 07:59:25
TRAINING STATS: batch 138/486 in epoch 992,  batch loss: 1.73938, batch accuracy: 0.53433
Time: 2018-07-15 07:59:29
TRAINING STATS: batch 188/486 in epoch 992,  batch loss: 1.65071, batch accuracy: 0.55950
Time: 2018-07-15 07:59:34
TRAINING STATS: batch 238/486 in epoch 992,  batch loss: 1.65276, batch accuracy: 0.55867
Time: 2018-07-15 07:59:37
TRAINING STATS: batch 288/486 in epoch 992,  batch loss: 1.69032, batch accuracy: 0.54350
Time: 2018-07-15 07:59:41
TRAINING STATS: batch 338/486 in epoch 992,  batch loss: 1.70414, batch accuracy: 0.53950
Time: 2018-07-15 07:59:46
TRAINING STATS: batch 388/486 in epoch 992,  batch loss: 1.63239, batch accuracy: 0.56583
Time: 2018-07-15 07:59:49
TRAINING STATS: batch 438/486 in epoch 992,  batch loss: 1.69440, batch accuracy: 0.54617
Time: 2018-07-15 07:59:53
TRAINING STATS: batch 2/486 in epoch 993,    batch loss: 1.70709, batch accuracy: 0.54250
Time: 2018-07-15 07:59:58
TRAINING STATS: batch 52/486 in epoch 993,   batch loss: 1.74750, batch accuracy: 0.53067
Time: 2018-07-15 08:00:02
TRAINING STATS: batch 102/486 in epoch 993,  batch loss: 1.72605, batch accuracy: 0.53983
Time: 2018-07-15 08:00:05
TRAINING STATS: batch 152/486 in epoch 993,  batch loss: 1.64953, batch accuracy: 0.55917
Time: 2018-07-15 08:00:10
TRAINING STATS: batch 202/486 in epoch 993,  batch loss: 1.67557, batch accuracy: 0.55000
Time: 2018-07-15 08:00:14
TRAINING STATS: batch 252/486 in epoch 993,  batch loss: 1.62573, batch accuracy: 0.56883
Time: 2018-07-15 08:00:17
TRAINING STATS: batch 302/486 in epoch 993,  batch loss: 1.63688, batch accuracy: 0.56267
Time: 2018-07-15 08:00:22
TRAINING STATS: batch 352/486 in epoch 993,  batch loss: 1.66387, batch accuracy: 0.56017
Time: 2018-07-15 08:00:26
TRAINING STATS: batch 402/486 in epoch 993,  batch loss: 1.53511, batch accuracy: 0.59083
Time: 2018-07-15 08:00:29
TRAINING STATS: batch 452/486 in epoch 993,  batch loss: 1.67911, batch accuracy: 0.54767
Time: 2018-07-15 08:00:34
TRAINING STATS: batch 16/486 in epoch 994,   batch loss: 1.66256, batch accuracy: 0.55267
Time: 2018-07-15 08:00:38
TRAINING STATS: batch 66/486 in epoch 994,   batch loss: 1.67231, batch accuracy: 0.55750
Time: 2018-07-15 08:00:42
TRAINING STATS: batch 116/486 in epoch 994,  batch loss: 1.66127, batch accuracy: 0.55050
Time: 2018-07-15 08:00:46
TRAINING STATS: batch 166/486 in epoch 994,  batch loss: 1.58764, batch accuracy: 0.57650
Time: 2018-07-15 08:00:50
TRAINING STATS: batch 216/486 in epoch 994,  batch loss: 1.72201, batch accuracy: 0.54083
Time: 2018-07-15 08:00:53
TRAINING STATS: batch 266/486 in epoch 994,  batch loss: 1.67308, batch accuracy: 0.54983
Time: 2018-07-15 08:00:58
TRAINING STATS: batch 316/486 in epoch 994,  batch loss: 1.66588, batch accuracy: 0.55217
Time: 2018-07-15 08:01:02
TRAINING STATS: batch 366/486 in epoch 994,  batch loss: 1.74135, batch accuracy: 0.53267
Time: 2018-07-15 08:01:06
TRAINING STATS: batch 416/486 in epoch 994,  batch loss: 1.72026, batch accuracy: 0.54317
Time: 2018-07-15 08:01:10
TRAINING STATS: batch 466/486 in epoch 994,  batch loss: 1.54000, batch accuracy: 0.59083
Time: 2018-07-15 08:01:14
TRAINING STATS: batch 30/486 in epoch 995,   batch loss: 1.56310, batch accuracy: 0.57617
Time: 2018-07-15 08:01:18
TRAINING STATS: batch 80/486 in epoch 995,   batch loss: 1.68046, batch accuracy: 0.54200
Time: 2018-07-15 08:01:22
TRAINING STATS: batch 130/486 in epoch 995,  batch loss: 1.65103, batch accuracy: 0.56733
Time: 2018-07-15 08:01:26
TRAINING STATS: batch 180/486 in epoch 995,  batch loss: 1.69192, batch accuracy: 0.54650
Time: 2018-07-15 08:01:30
TRAINING STATS: batch 230/486 in epoch 995,  batch loss: 1.69172, batch accuracy: 0.54283
Time: 2018-07-15 08:01:34
TRAINING STATS: batch 280/486 in epoch 995,  batch loss: 1.67030, batch accuracy: 0.54800
Time: 2018-07-15 08:01:38
TRAINING STATS: batch 330/486 in epoch 995,  batch loss: 1.65011, batch accuracy: 0.55200
Time: 2018-07-15 08:01:42
TRAINING STATS: batch 380/486 in epoch 995,  batch loss: 1.64864, batch accuracy: 0.55967
Time: 2018-07-15 08:01:47
TRAINING STATS: batch 430/486 in epoch 995,  batch loss: 1.60085, batch accuracy: 0.57283
Time: 2018-07-15 08:01:50
TRAINING STATS: batch 480/486 in epoch 995,  batch loss: 1.68024, batch accuracy: 0.55683
Time: 2018-07-15 08:01:54
TRAINING STATS: batch 44/486 in epoch 996,   batch loss: 1.62391, batch accuracy: 0.57350
Time: 2018-07-15 08:01:59
TRAINING STATS: batch 94/486 in epoch 996,   batch loss: 1.79364, batch accuracy: 0.52067
Time: 2018-07-15 08:02:02
TRAINING STATS: batch 144/486 in epoch 996,  batch loss: 1.86704, batch accuracy: 0.49217
Time: 2018-07-15 08:02:06
TRAINING STATS: batch 194/486 in epoch 996,  batch loss: 1.84092, batch accuracy: 0.50550
Time: 2018-07-15 08:02:11
TRAINING STATS: batch 244/486 in epoch 996,  batch loss: 1.72583, batch accuracy: 0.54383
Time: 2018-07-15 08:02:14
TRAINING STATS: batch 294/486 in epoch 996,  batch loss: 1.68558, batch accuracy: 0.54850
Time: 2018-07-15 08:02:18
TRAINING STATS: batch 344/486 in epoch 996,  batch loss: 1.71281, batch accuracy: 0.53900
Time: 2018-07-15 08:02:23
TRAINING STATS: batch 394/486 in epoch 996,  batch loss: 1.69198, batch accuracy: 0.55017
Time: 2018-07-15 08:02:26
TRAINING STATS: batch 444/486 in epoch 996,  batch loss: 1.64524, batch accuracy: 0.56250
Time: 2018-07-15 08:02:30
TRAINING STATS: batch 8/486 in epoch 997,    batch loss: 1.67969, batch accuracy: 0.54950
Time: 2018-07-15 08:02:35
TRAINING STATS: batch 58/486 in epoch 997,   batch loss: 1.65158, batch accuracy: 0.56517
Time: 2018-07-15 08:02:39
TRAINING STATS: batch 108/486 in epoch 997,  batch loss: 1.75018, batch accuracy: 0.53250
Time: 2018-07-15 08:02:42
TRAINING STATS: batch 158/486 in epoch 997,  batch loss: 1.72486, batch accuracy: 0.53483
Time: 2018-07-15 08:02:47
TRAINING STATS: batch 208/486 in epoch 997,  batch loss: 1.70512, batch accuracy: 0.53517
Time: 2018-07-15 08:02:51
TRAINING STATS: batch 258/486 in epoch 997,  batch loss: 1.64099, batch accuracy: 0.56117
Time: 2018-07-15 08:02:54
TRAINING STATS: batch 308/486 in epoch 997,  batch loss: 1.68659, batch accuracy: 0.55533
Time: 2018-07-15 08:02:59
TRAINING STATS: batch 358/486 in epoch 997,  batch loss: 1.69270, batch accuracy: 0.54183
Time: 2018-07-15 08:03:03
TRAINING STATS: batch 408/486 in epoch 997,  batch loss: 1.72137, batch accuracy: 0.53300
Time: 2018-07-15 08:03:06
TRAINING STATS: batch 458/486 in epoch 997,  batch loss: 1.72091, batch accuracy: 0.53317
Time: 2018-07-15 08:03:11
TRAINING STATS: batch 22/486 in epoch 998,   batch loss: 1.75148, batch accuracy: 0.53783
Time: 2018-07-15 08:03:15
TRAINING STATS: batch 72/486 in epoch 998,   batch loss: 1.70645, batch accuracy: 0.53450
Time: 2018-07-15 08:03:19
TRAINING STATS: batch 122/486 in epoch 998,  batch loss: 1.63834, batch accuracy: 0.56250
Time: 2018-07-15 08:03:23
TRAINING STATS: batch 172/486 in epoch 998,  batch loss: 1.73966, batch accuracy: 0.53850
Time: 2018-07-15 08:03:27
TRAINING STATS: batch 222/486 in epoch 998,  batch loss: 1.68589, batch accuracy: 0.54267
Time: 2018-07-15 08:03:31
TRAINING STATS: batch 272/486 in epoch 998,  batch loss: 1.70660, batch accuracy: 0.53617
Time: 2018-07-15 08:03:35
TRAINING STATS: batch 322/486 in epoch 998,  batch loss: 1.83293, batch accuracy: 0.49583
Time: 2018-07-15 08:03:39
TRAINING STATS: batch 372/486 in epoch 998,  batch loss: 1.70935, batch accuracy: 0.53917
Time: 2018-07-15 08:03:43
TRAINING STATS: batch 422/486 in epoch 998,  batch loss: 1.74709, batch accuracy: 0.52683
Time: 2018-07-15 08:03:47
TRAINING STATS: batch 472/486 in epoch 998,  batch loss: 1.79330, batch accuracy: 0.51767
Time: 2018-07-15 08:03:51
TRAINING STATS: batch 36/486 in epoch 999,   batch loss: 1.78307, batch accuracy: 0.52167
Time: 2018-07-15 08:03:55
TRAINING STATS: batch 86/486 in epoch 999,   batch loss: 1.70604, batch accuracy: 0.55300
Time: 2018-07-15 08:04:00
TRAINING STATS: batch 136/486 in epoch 999,  batch loss: 1.75277, batch accuracy: 0.52417
Time: 2018-07-15 08:04:03
TRAINING STATS: batch 186/486 in epoch 999,  batch loss: 1.71587, batch accuracy: 0.54367
Time: 2018-07-15 08:04:07
TRAINING STATS: batch 236/486 in epoch 999,  batch loss: 1.72178, batch accuracy: 0.53750
Time: 2018-07-15 08:04:12
TRAINING STATS: batch 286/486 in epoch 999,  batch loss: 1.72043, batch accuracy: 0.53550
Time: 2018-07-15 08:04:15
TRAINING STATS: batch 336/486 in epoch 999,  batch loss: 1.67544, batch accuracy: 0.55017
Time: 2018-07-15 08:04:19
TRAINING STATS: batch 386/486 in epoch 999,  batch loss: 1.72541, batch accuracy: 0.54233
Time: 2018-07-15 08:04:24
TRAINING STATS: batch 436/486 in epoch 999,  batch loss: 1.71041, batch accuracy: 0.54417
Time: 2018-07-15 08:04:27
TRAINING STATS: batch 0/486 in epoch 1000,   batch loss: 1.71519, batch accuracy: 0.53200
Time: 2018-07-15 08:04:31
TRAINING STATS: batch 50/486 in epoch 1000,  batch loss: 1.65046, batch accuracy: 0.55583
Time: 2018-07-15 08:04:36
TRAINING STATS: batch 100/486 in epoch 1000, batch loss: 1.70567, batch accuracy: 0.54150
Time: 2018-07-15 08:04:40
TRAINING STATS: batch 150/486 in epoch 1000, batch loss: 1.66731, batch accuracy: 0.56050
Time: 2018-07-15 08:04:43
TRAINING STATS: batch 200/486 in epoch 1000, batch loss: 1.60773, batch accuracy: 0.57750
Time: 2018-07-15 08:04:48
TRAINING STATS: batch 250/486 in epoch 1000, batch loss: 1.75181, batch accuracy: 0.52767
Time: 2018-07-15 08:04:52
TRAINING STATS: batch 300/486 in epoch 1000, batch loss: 1.72762, batch accuracy: 0.53133
Time: 2018-07-15 08:04:55
TRAINING STATS: batch 350/486 in epoch 1000, batch loss: 1.69548, batch accuracy: 0.55217
Time: 2018-07-15 08:05:00
TRAINING STATS: batch 400/486 in epoch 1000, batch loss: 1.58474, batch accuracy: 0.57400
Time: 2018-07-15 08:05:04
TRAINING STATS: batch 450/486 in epoch 1000, batch loss: 1.74696, batch accuracy: 0.53000
Time: 2018-07-15 08:05:07
TRAINING STATS: batch 14/486 in epoch 1001,  batch loss: 1.61209, batch accuracy: 0.57550
Time: 2018-07-15 08:05:12
TRAINING STATS: batch 64/486 in epoch 1001,  batch loss: 1.77191, batch accuracy: 0.52217
Time: 2018-07-15 08:05:16
TRAINING STATS: batch 114/486 in epoch 1001, batch loss: 1.73450, batch accuracy: 0.53433
Time: 2018-07-15 08:05:20
TRAINING STATS: batch 164/486 in epoch 1001, batch loss: 1.62171, batch accuracy: 0.57167
Time: 2018-07-15 08:05:24
TRAINING STATS: batch 214/486 in epoch 1001, batch loss: 1.67971, batch accuracy: 0.54200
Time: 2018-07-15 08:05:28
TRAINING STATS: batch 264/486 in epoch 1001, batch loss: 1.71966, batch accuracy: 0.53333
Time: 2018-07-15 08:05:32
TRAINING STATS: batch 314/486 in epoch 1001, batch loss: 1.75398, batch accuracy: 0.52500
Time: 2018-07-15 08:05:36
TRAINING STATS: batch 364/486 in epoch 1001, batch loss: 1.67359, batch accuracy: 0.55417
Time: 2018-07-15 08:05:40
TRAINING STATS: batch 414/486 in epoch 1001, batch loss: 1.61237, batch accuracy: 0.56983
Time: 2018-07-15 08:05:44
TRAINING STATS: batch 464/486 in epoch 1001, batch loss: 1.64892, batch accuracy: 0.55817
Time: 2018-07-15 08:05:48
TRAINING STATS: batch 28/486 in epoch 1002,  batch loss: 1.63215, batch accuracy: 0.57017
Time: 2018-07-15 08:05:52
TRAINING STATS: batch 78/486 in epoch 1002,  batch loss: 1.69580, batch accuracy: 0.55333
Time: 2018-07-15 08:05:56
TRAINING STATS: batch 128/486 in epoch 1002, batch loss: 1.66118, batch accuracy: 0.55983
Time: 2018-07-15 08:06:00
TRAINING STATS: batch 178/486 in epoch 1002, batch loss: 1.56841, batch accuracy: 0.57800
Time: 2018-07-15 08:06:04
TRAINING STATS: batch 228/486 in epoch 1002, batch loss: 1.61554, batch accuracy: 0.56833
Time: 2018-07-15 08:06:08
TRAINING STATS: batch 278/486 in epoch 1002, batch loss: 1.61876, batch accuracy: 0.56450
Time: 2018-07-15 08:06:12
TRAINING STATS: batch 328/486 in epoch 1002, batch loss: 1.64045, batch accuracy: 0.56167
Time: 2018-07-15 08:06:16
TRAINING STATS: batch 378/486 in epoch 1002, batch loss: 1.68095, batch accuracy: 0.55717
Time: 2018-07-15 08:06:20
TRAINING STATS: batch 428/486 in epoch 1002, batch loss: 1.71108, batch accuracy: 0.53950
Time: 2018-07-15 08:06:25
TRAINING STATS: batch 478/486 in epoch 1002, batch loss: 1.68883, batch accuracy: 0.54633
Time: 2018-07-15 08:06:28
TRAINING STATS: batch 42/486 in epoch 1003,  batch loss: 1.61152, batch accuracy: 0.56883
Time: 2018-07-15 08:06:32
TRAINING STATS: batch 92/486 in epoch 1003,  batch loss: 1.68429, batch accuracy: 0.55250
Time: 2018-07-15 08:06:37
TRAINING STATS: batch 142/486 in epoch 1003, batch loss: 1.62440, batch accuracy: 0.55817
Time: 2018-07-15 08:06:40
TRAINING STATS: batch 192/486 in epoch 1003, batch loss: 1.67067, batch accuracy: 0.55767
Time: 2018-07-15 08:06:44
TRAINING STATS: batch 242/486 in epoch 1003, batch loss: 1.63006, batch accuracy: 0.56300
Time: 2018-07-15 08:06:49
TRAINING STATS: batch 292/486 in epoch 1003, batch loss: 1.66574, batch accuracy: 0.56050
Time: 2018-07-15 08:06:52
TRAINING STATS: batch 342/486 in epoch 1003, batch loss: 1.64272, batch accuracy: 0.55983
Time: 2018-07-15 08:06:56
TRAINING STATS: batch 392/486 in epoch 1003, batch loss: 1.59944, batch accuracy: 0.57283
Time: 2018-07-15 08:07:01
TRAINING STATS: batch 442/486 in epoch 1003, batch loss: 1.57660, batch accuracy: 0.57933
Time: 2018-07-15 08:07:04
TRAINING STATS: batch 6/486 in epoch 1004,   batch loss: 1.71939, batch accuracy: 0.54617
Time: 2018-07-15 08:07:08
TRAINING STATS: batch 56/486 in epoch 1004,  batch loss: 1.64041, batch accuracy: 0.55883
Time: 2018-07-15 08:07:13
TRAINING STATS: batch 106/486 in epoch 1004, batch loss: 1.75328, batch accuracy: 0.53417
Time: 2018-07-15 08:07:17
TRAINING STATS: batch 156/486 in epoch 1004, batch loss: 1.71231, batch accuracy: 0.54200
Time: 2018-07-15 08:07:20
TRAINING STATS: batch 206/486 in epoch 1004, batch loss: 1.74517, batch accuracy: 0.53900
Time: 2018-07-15 08:07:25
TRAINING STATS: batch 256/486 in epoch 1004, batch loss: 1.61647, batch accuracy: 0.56667
Time: 2018-07-15 08:07:29
TRAINING STATS: batch 306/486 in epoch 1004, batch loss: 1.68497, batch accuracy: 0.55250
Time: 2018-07-15 08:07:32
TRAINING STATS: batch 356/486 in epoch 1004, batch loss: 1.72486, batch accuracy: 0.53183
Time: 2018-07-15 08:07:37
TRAINING STATS: batch 406/486 in epoch 1004, batch loss: 1.73700, batch accuracy: 0.53083
Time: 2018-07-15 08:07:41
TRAINING STATS: batch 456/486 in epoch 1004, batch loss: 1.54400, batch accuracy: 0.59650
Time: 2018-07-15 08:07:44
TRAINING STATS: batch 20/486 in epoch 1005,  batch loss: 1.66747, batch accuracy: 0.55567
Time: 2018-07-15 08:07:49
TRAINING STATS: batch 70/486 in epoch 1005,  batch loss: 1.56109, batch accuracy: 0.58967
Time: 2018-07-15 08:07:53
TRAINING STATS: batch 120/486 in epoch 1005, batch loss: 1.61606, batch accuracy: 0.56983
Time: 2018-07-15 08:07:56
TRAINING STATS: batch 170/486 in epoch 1005, batch loss: 1.65657, batch accuracy: 0.55383
Time: 2018-07-15 08:08:01
TRAINING STATS: batch 220/486 in epoch 1005, batch loss: 1.60347, batch accuracy: 0.57917
Time: 2018-07-15 08:08:05
TRAINING STATS: batch 270/486 in epoch 1005, batch loss: 1.66423, batch accuracy: 0.54067
Time: 2018-07-15 08:08:09
TRAINING STATS: batch 320/486 in epoch 1005, batch loss: 1.61472, batch accuracy: 0.55733
Time: 2018-07-15 08:08:13
TRAINING STATS: batch 370/486 in epoch 1005, batch loss: 1.69187, batch accuracy: 0.54417
Time: 2018-07-15 08:08:17
TRAINING STATS: batch 420/486 in epoch 1005, batch loss: 1.70619, batch accuracy: 0.54200
Time: 2018-07-15 08:08:21
TRAINING STATS: batch 470/486 in epoch 1005, batch loss: 1.75455, batch accuracy: 0.52817
Time: 2018-07-15 08:08:25
TRAINING STATS: batch 34/486 in epoch 1006,  batch loss: 1.67802, batch accuracy: 0.55067
Time: 2018-07-15 08:08:29
TRAINING STATS: batch 84/486 in epoch 1006,  batch loss: 1.67239, batch accuracy: 0.54383
Time: 2018-07-15 08:08:33
TRAINING STATS: batch 134/486 in epoch 1006, batch loss: 1.70021, batch accuracy: 0.54750
Time: 2018-07-15 08:08:37
TRAINING STATS: batch 184/486 in epoch 1006, batch loss: 1.67666, batch accuracy: 0.55300
Time: 2018-07-15 08:08:41
TRAINING STATS: batch 234/486 in epoch 1006, batch loss: 1.72197, batch accuracy: 0.53933
Time: 2018-07-15 08:08:45
TRAINING STATS: batch 284/486 in epoch 1006, batch loss: 1.74819, batch accuracy: 0.53517
Time: 2018-07-15 08:08:49
TRAINING STATS: batch 334/486 in epoch 1006, batch loss: 1.66813, batch accuracy: 0.54917
Time: 2018-07-15 08:08:53
TRAINING STATS: batch 384/486 in epoch 1006, batch loss: 1.64387, batch accuracy: 0.55683
Time: 2018-07-15 08:08:57
TRAINING STATS: batch 434/486 in epoch 1006, batch loss: 1.72039, batch accuracy: 0.54167
Time: 2018-07-15 08:09:02
TRAINING STATS: batch 484/486 in epoch 1006, batch loss: 1.68067, batch accuracy: 0.54767
Time: 2018-07-15 08:09:05
TRAINING STATS: batch 48/486 in epoch 1007,  batch loss: 1.66711, batch accuracy: 0.55100
Time: 2018-07-15 08:09:09
TRAINING STATS: batch 98/486 in epoch 1007,  batch loss: 1.63237, batch accuracy: 0.57283
Time: 2018-07-15 08:09:14
TRAINING STATS: batch 148/486 in epoch 1007, batch loss: 1.71511, batch accuracy: 0.55133
Time: 2018-07-15 08:09:17
TRAINING STATS: batch 198/486 in epoch 1007, batch loss: 1.66513, batch accuracy: 0.55267
Time: 2018-07-15 08:09:21
TRAINING STATS: batch 248/486 in epoch 1007, batch loss: 1.69666, batch accuracy: 0.53983
Time: 2018-07-15 08:09:26
TRAINING STATS: batch 298/486 in epoch 1007, batch loss: 1.69033, batch accuracy: 0.53717
Time: 2018-07-15 08:09:29
TRAINING STATS: batch 348/486 in epoch 1007, batch loss: 1.70292, batch accuracy: 0.54767
Time: 2018-07-15 08:09:33
TRAINING STATS: batch 398/486 in epoch 1007, batch loss: 1.68795, batch accuracy: 0.55000
Time: 2018-07-15 08:09:38
TRAINING STATS: batch 448/486 in epoch 1007, batch loss: 1.66012, batch accuracy: 0.55933
Time: 2018-07-15 08:09:41
TRAINING STATS: batch 12/486 in epoch 1008,  batch loss: 1.67878, batch accuracy: 0.54800
Time: 2018-07-15 08:09:45
TRAINING STATS: batch 62/486 in epoch 1008,  batch loss: 1.74145, batch accuracy: 0.52900
Time: 2018-07-15 08:09:50
TRAINING STATS: batch 112/486 in epoch 1008, batch loss: 1.67564, batch accuracy: 0.54617
Time: 2018-07-15 08:09:54
TRAINING STATS: batch 162/486 in epoch 1008, batch loss: 1.67774, batch accuracy: 0.55050
Time: 2018-07-15 08:09:57
TRAINING STATS: batch 212/486 in epoch 1008, batch loss: 1.58361, batch accuracy: 0.58383
Time: 2018-07-15 08:10:02
TRAINING STATS: batch 262/486 in epoch 1008, batch loss: 1.72199, batch accuracy: 0.54167
Time: 2018-07-15 08:10:06
TRAINING STATS: batch 312/486 in epoch 1008, batch loss: 1.68426, batch accuracy: 0.53250
Time: 2018-07-15 08:10:09
TRAINING STATS: batch 362/486 in epoch 1008, batch loss: 1.66513, batch accuracy: 0.56017
Time: 2018-07-15 08:10:14
TRAINING STATS: batch 412/486 in epoch 1008, batch loss: 1.63116, batch accuracy: 0.56167
Time: 2018-07-15 08:10:18
TRAINING STATS: batch 462/486 in epoch 1008, batch loss: 1.68783, batch accuracy: 0.54783
Time: 2018-07-15 08:10:21
TRAINING STATS: batch 26/486 in epoch 1009,  batch loss: 1.71571, batch accuracy: 0.53333
Time: 2018-07-15 08:10:26
TRAINING STATS: batch 76/486 in epoch 1009,  batch loss: 1.71722, batch accuracy: 0.53550
Time: 2018-07-15 08:10:30
TRAINING STATS: batch 126/486 in epoch 1009, batch loss: 1.71333, batch accuracy: 0.53850
Time: 2018-07-15 08:10:33
TRAINING STATS: batch 176/486 in epoch 1009, batch loss: 1.60131, batch accuracy: 0.57817
Time: 2018-07-15 08:10:38
TRAINING STATS: batch 226/486 in epoch 1009, batch loss: 1.71680, batch accuracy: 0.54283
Time: 2018-07-15 08:10:42
TRAINING STATS: batch 276/486 in epoch 1009, batch loss: 1.69642, batch accuracy: 0.54733
Time: 2018-07-15 08:10:46
TRAINING STATS: batch 326/486 in epoch 1009, batch loss: 1.71574, batch accuracy: 0.54700
Time: 2018-07-15 08:10:50
TRAINING STATS: batch 376/486 in epoch 1009, batch loss: 1.70668, batch accuracy: 0.54133
Time: 2018-07-15 08:10:54
TRAINING STATS: batch 426/486 in epoch 1009, batch loss: 1.64940, batch accuracy: 0.55117
Time: 2018-07-15 08:10:58
TRAINING STATS: batch 476/486 in epoch 1009, batch loss: 1.61509, batch accuracy: 0.56600
Time: 2018-07-15 08:11:02
TRAINING STATS: batch 40/486 in epoch 1010,  batch loss: 1.64137, batch accuracy: 0.56367
Time: 2018-07-15 08:11:06
TRAINING STATS: batch 90/486 in epoch 1010,  batch loss: 1.71166, batch accuracy: 0.54467
Time: 2018-07-15 08:11:10
TRAINING STATS: batch 140/486 in epoch 1010, batch loss: 1.62211, batch accuracy: 0.56667
Time: 2018-07-15 08:11:14
TRAINING STATS: batch 190/486 in epoch 1010, batch loss: 1.75477, batch accuracy: 0.52067
Time: 2018-07-15 08:11:18
TRAINING STATS: batch 240/486 in epoch 1010, batch loss: 1.72211, batch accuracy: 0.53383
Time: 2018-07-15 08:11:22
TRAINING STATS: batch 290/486 in epoch 1010, batch loss: 1.75783, batch accuracy: 0.51133
Time: 2018-07-15 08:11:27
TRAINING STATS: batch 340/486 in epoch 1010, batch loss: 1.77501, batch accuracy: 0.52017
Time: 2018-07-15 08:11:30
TRAINING STATS: batch 390/486 in epoch 1010, batch loss: 1.62327, batch accuracy: 0.56817
Time: 2018-07-15 08:11:34
TRAINING STATS: batch 440/486 in epoch 1010, batch loss: 1.68731, batch accuracy: 0.54467
Time: 2018-07-15 08:11:39
TRAINING STATS: batch 4/486 in epoch 1011,   batch loss: 1.64393, batch accuracy: 0.56517
Time: 2018-07-15 08:11:42
TRAINING STATS: batch 54/486 in epoch 1011,  batch loss: 1.68180, batch accuracy: 0.54917
Time: 2018-07-15 08:11:46
TRAINING STATS: batch 104/486 in epoch 1011, batch loss: 1.69048, batch accuracy: 0.55717
Time: 2018-07-15 08:11:51
TRAINING STATS: batch 154/486 in epoch 1011, batch loss: 1.66588, batch accuracy: 0.55550
Time: 2018-07-15 08:11:54
TRAINING STATS: batch 204/486 in epoch 1011, batch loss: 1.74014, batch accuracy: 0.53383
Time: 2018-07-15 08:11:58
TRAINING STATS: batch 254/486 in epoch 1011, batch loss: 1.60321, batch accuracy: 0.56533
Time: 2018-07-15 08:12:03
TRAINING STATS: batch 304/486 in epoch 1011, batch loss: 1.63880, batch accuracy: 0.56233
Time: 2018-07-15 08:12:07
TRAINING STATS: batch 354/486 in epoch 1011, batch loss: 1.67662, batch accuracy: 0.55933
Time: 2018-07-15 08:12:10
TRAINING STATS: batch 404/486 in epoch 1011, batch loss: 1.64978, batch accuracy: 0.55617
Time: 2018-07-15 08:12:15
TRAINING STATS: batch 454/486 in epoch 1011, batch loss: 1.54999, batch accuracy: 0.58517
Time: 2018-07-15 08:12:19
TRAINING STATS: batch 18/486 in epoch 1012,  batch loss: 1.70504, batch accuracy: 0.54833
Time: 2018-07-15 08:12:22
TRAINING STATS: batch 68/486 in epoch 1012,  batch loss: 1.52601, batch accuracy: 0.60133
Time: 2018-07-15 08:12:27
TRAINING STATS: batch 118/486 in epoch 1012, batch loss: 1.68383, batch accuracy: 0.54900
Time: 2018-07-15 08:12:31
TRAINING STATS: batch 168/486 in epoch 1012, batch loss: 1.60211, batch accuracy: 0.57383
Time: 2018-07-15 08:12:34
TRAINING STATS: batch 218/486 in epoch 1012, batch loss: 1.65263, batch accuracy: 0.56033
Time: 2018-07-15 08:12:39
TRAINING STATS: batch 268/486 in epoch 1012, batch loss: 1.61557, batch accuracy: 0.57033
Time: 2018-07-15 08:12:43
TRAINING STATS: batch 318/486 in epoch 1012, batch loss: 1.66873, batch accuracy: 0.55250
Time: 2018-07-15 08:12:47
TRAINING STATS: batch 368/486 in epoch 1012, batch loss: 1.69477, batch accuracy: 0.54133
Time: 2018-07-15 08:12:51
TRAINING STATS: batch 418/486 in epoch 1012, batch loss: 1.72610, batch accuracy: 0.53900
Time: 2018-07-15 08:12:55
TRAINING STATS: batch 468/486 in epoch 1012, batch loss: 1.66923, batch accuracy: 0.55250
Time: 2018-07-15 08:12:59
TRAINING STATS: batch 32/486 in epoch 1013,  batch loss: 1.61771, batch accuracy: 0.56800
Time: 2018-07-15 08:13:03
TRAINING STATS: batch 82/486 in epoch 1013,  batch loss: 1.69754, batch accuracy: 0.54767
Time: 2018-07-15 08:13:07
TRAINING STATS: batch 132/486 in epoch 1013, batch loss: 1.64337, batch accuracy: 0.56700
Time: 2018-07-15 08:13:11
TRAINING STATS: batch 182/486 in epoch 1013, batch loss: 1.72313, batch accuracy: 0.53450
Time: 2018-07-15 08:13:15
TRAINING STATS: batch 232/486 in epoch 1013, batch loss: 1.72889, batch accuracy: 0.53250
Time: 2018-07-15 08:13:19
TRAINING STATS: batch 282/486 in epoch 1013, batch loss: 1.62997, batch accuracy: 0.56083
Time: 2018-07-15 08:13:23
TRAINING STATS: batch 332/486 in epoch 1013, batch loss: 1.71114, batch accuracy: 0.54283
Time: 2018-07-15 08:13:27
TRAINING STATS: batch 382/486 in epoch 1013, batch loss: 1.69384, batch accuracy: 0.54667
Time: 2018-07-15 08:13:31
TRAINING STATS: batch 432/486 in epoch 1013, batch loss: 1.60740, batch accuracy: 0.56867
Time: 2018-07-15 08:13:35
TRAINING STATS: batch 482/486 in epoch 1013, batch loss: 1.65835, batch accuracy: 0.55150
Time: 2018-07-15 08:13:39
TRAINING STATS: batch 46/486 in epoch 1014,  batch loss: 1.63757, batch accuracy: 0.56650
Time: 2018-07-15 08:13:43
TRAINING STATS: batch 96/486 in epoch 1014,  batch loss: 1.69777, batch accuracy: 0.54833
Time: 2018-07-15 08:13:47
TRAINING STATS: batch 146/486 in epoch 1014, batch loss: 1.72024, batch accuracy: 0.53800
Time: 2018-07-15 08:13:51
TRAINING STATS: batch 196/486 in epoch 1014, batch loss: 1.70417, batch accuracy: 0.54467
Time: 2018-07-15 08:13:55
TRAINING STATS: batch 246/486 in epoch 1014, batch loss: 1.64168, batch accuracy: 0.56133
Time: 2018-07-15 08:13:59
TRAINING STATS: batch 296/486 in epoch 1014, batch loss: 1.62788, batch accuracy: 0.55983
Time: 2018-07-15 08:14:04
TRAINING STATS: batch 346/486 in epoch 1014, batch loss: 1.58420, batch accuracy: 0.58317
Time: 2018-07-15 08:14:07
TRAINING STATS: batch 396/486 in epoch 1014, batch loss: 1.64299, batch accuracy: 0.56683
Time: 2018-07-15 08:14:11
TRAINING STATS: batch 446/486 in epoch 1014, batch loss: 1.69558, batch accuracy: 0.54383
Time: 2018-07-15 08:14:16
TRAINING STATS: batch 10/486 in epoch 1015,  batch loss: 1.71295, batch accuracy: 0.53950
Time: 2018-07-15 08:14:19
TRAINING STATS: batch 60/486 in epoch 1015,  batch loss: 1.66008, batch accuracy: 0.55183
Time: 2018-07-15 08:14:23
TRAINING STATS: batch 110/486 in epoch 1015, batch loss: 1.72822, batch accuracy: 0.54233
Time: 2018-07-15 08:14:28
TRAINING STATS: batch 160/486 in epoch 1015, batch loss: 1.63474, batch accuracy: 0.55850
Time: 2018-07-15 08:14:32
TRAINING STATS: batch 210/486 in epoch 1015, batch loss: 1.62773, batch accuracy: 0.56750
Time: 2018-07-15 08:14:35
TRAINING STATS: batch 260/486 in epoch 1015, batch loss: 1.71663, batch accuracy: 0.53433
Time: 2018-07-15 08:14:40
TRAINING STATS: batch 310/486 in epoch 1015, batch loss: 1.68423, batch accuracy: 0.55283
Time: 2018-07-15 08:14:44
TRAINING STATS: batch 360/486 in epoch 1015, batch loss: 1.70654, batch accuracy: 0.54017
Time: 2018-07-15 08:14:47
TRAINING STATS: batch 410/486 in epoch 1015, batch loss: 1.60574, batch accuracy: 0.57500
Time: 2018-07-15 08:14:52
TRAINING STATS: batch 460/486 in epoch 1015, batch loss: 1.79768, batch accuracy: 0.51550
Time: 2018-07-15 08:14:56
TRAINING STATS: batch 24/486 in epoch 1016,  batch loss: 1.73573, batch accuracy: 0.53583
Time: 2018-07-15 08:14:59
TRAINING STATS: batch 74/486 in epoch 1016,  batch loss: 1.69849, batch accuracy: 0.55050
Time: 2018-07-15 08:15:04
TRAINING STATS: batch 124/486 in epoch 1016, batch loss: 1.68990, batch accuracy: 0.55250
Time: 2018-07-15 08:15:08
TRAINING STATS: batch 174/486 in epoch 1016, batch loss: 1.73973, batch accuracy: 0.53133
Time: 2018-07-15 08:15:12
TRAINING STATS: batch 224/486 in epoch 1016, batch loss: 1.70724, batch accuracy: 0.54117
Time: 2018-07-15 08:15:16
TRAINING STATS: batch 274/486 in epoch 1016, batch loss: 1.70629, batch accuracy: 0.54633
Time: 2018-07-15 08:15:20
TRAINING STATS: batch 324/486 in epoch 1016, batch loss: 1.71310, batch accuracy: 0.53867
Time: 2018-07-15 08:15:24
TRAINING STATS: batch 374/486 in epoch 1016, batch loss: 1.71452, batch accuracy: 0.53850
Time: 2018-07-15 08:15:28
TRAINING STATS: batch 424/486 in epoch 1016, batch loss: 1.61224, batch accuracy: 0.57467
Time: 2018-07-15 08:15:32
TRAINING STATS: batch 474/486 in epoch 1016, batch loss: 1.67080, batch accuracy: 0.54633
Time: 2018-07-15 08:15:36
TRAINING STATS: batch 38/486 in epoch 1017,  batch loss: 1.69293, batch accuracy: 0.55017
Time: 2018-07-15 08:15:41
TRAINING STATS: batch 88/486 in epoch 1017,  batch loss: 1.73495, batch accuracy: 0.53333
Time: 2018-07-15 08:15:44
TRAINING STATS: batch 138/486 in epoch 1017, batch loss: 1.73669, batch accuracy: 0.52933
Time: 2018-07-15 08:15:48
TRAINING STATS: batch 188/486 in epoch 1017, batch loss: 1.64068, batch accuracy: 0.56317
Time: 2018-07-15 08:15:53
TRAINING STATS: batch 238/486 in epoch 1017, batch loss: 1.64718, batch accuracy: 0.56917
Time: 2018-07-15 08:15:56
TRAINING STATS: batch 288/486 in epoch 1017, batch loss: 1.69534, batch accuracy: 0.54050
Time: 2018-07-15 08:16:00
TRAINING STATS: batch 338/486 in epoch 1017, batch loss: 1.67754, batch accuracy: 0.54483
Time: 2018-07-15 08:16:05
TRAINING STATS: batch 388/486 in epoch 1017, batch loss: 1.62552, batch accuracy: 0.56450
Time: 2018-07-15 08:16:08
TRAINING STATS: batch 438/486 in epoch 1017, batch loss: 1.70107, batch accuracy: 0.54983
Time: 2018-07-15 08:16:12
TRAINING STATS: batch 2/486 in epoch 1018,   batch loss: 1.68410, batch accuracy: 0.54550
Time: 2018-07-15 08:16:17
TRAINING STATS: batch 52/486 in epoch 1018,  batch loss: 1.73857, batch accuracy: 0.53267
Time: 2018-07-15 08:16:21
TRAINING STATS: batch 102/486 in epoch 1018, batch loss: 1.71711, batch accuracy: 0.54500
Time: 2018-07-15 08:16:24
TRAINING STATS: batch 152/486 in epoch 1018, batch loss: 1.64522, batch accuracy: 0.55950
Time: 2018-07-15 08:16:29
TRAINING STATS: batch 202/486 in epoch 1018, batch loss: 1.67180, batch accuracy: 0.55717
Time: 2018-07-15 08:16:33
TRAINING STATS: batch 252/486 in epoch 1018, batch loss: 1.64045, batch accuracy: 0.56367
Time: 2018-07-15 08:16:36
TRAINING STATS: batch 302/486 in epoch 1018, batch loss: 1.64500, batch accuracy: 0.56517
Time: 2018-07-15 08:16:41
TRAINING STATS: batch 352/486 in epoch 1018, batch loss: 1.66983, batch accuracy: 0.55917
Time: 2018-07-15 08:16:45
TRAINING STATS: batch 402/486 in epoch 1018, batch loss: 1.55654, batch accuracy: 0.58983
Time: 2018-07-15 08:16:48
TRAINING STATS: batch 452/486 in epoch 1018, batch loss: 1.69727, batch accuracy: 0.54350
Time: 2018-07-15 08:16:53
TRAINING STATS: batch 16/486 in epoch 1019,  batch loss: 1.64490, batch accuracy: 0.55717
Time: 2018-07-15 08:16:57
TRAINING STATS: batch 66/486 in epoch 1019,  batch loss: 1.68525, batch accuracy: 0.55083
Time: 2018-07-15 08:17:00
TRAINING STATS: batch 116/486 in epoch 1019, batch loss: 1.64132, batch accuracy: 0.56200
Time: 2018-07-15 08:17:05
TRAINING STATS: batch 166/486 in epoch 1019, batch loss: 1.59858, batch accuracy: 0.57817
Time: 2018-07-15 08:17:09
TRAINING STATS: batch 216/486 in epoch 1019, batch loss: 1.70299, batch accuracy: 0.54317
Time: 2018-07-15 08:17:12
TRAINING STATS: batch 266/486 in epoch 1019, batch loss: 1.67026, batch accuracy: 0.55217
Time: 2018-07-15 08:17:17
TRAINING STATS: batch 316/486 in epoch 1019, batch loss: 1.67269, batch accuracy: 0.55100
Time: 2018-07-15 08:17:21
TRAINING STATS: batch 366/486 in epoch 1019, batch loss: 1.72733, batch accuracy: 0.53800
Time: 2018-07-15 08:17:25
TRAINING STATS: batch 416/486 in epoch 1019, batch loss: 1.70890, batch accuracy: 0.53850
Time: 2018-07-15 08:17:29
TRAINING STATS: batch 466/486 in epoch 1019, batch loss: 1.54241, batch accuracy: 0.59550
Time: 2018-07-15 08:17:33
TRAINING STATS: batch 30/486 in epoch 1020,  batch loss: 1.56727, batch accuracy: 0.57817
Time: 2018-07-15 08:17:37
TRAINING STATS: batch 80/486 in epoch 1020,  batch loss: 1.68493, batch accuracy: 0.54033
Time: 2018-07-15 08:17:41
TRAINING STATS: batch 130/486 in epoch 1020, batch loss: 1.66017, batch accuracy: 0.56300
Time: 2018-07-15 08:17:45
TRAINING STATS: batch 180/486 in epoch 1020, batch loss: 1.72032, batch accuracy: 0.53517
Time: 2018-07-15 08:17:49
TRAINING STATS: batch 230/486 in epoch 1020, batch loss: 1.70105, batch accuracy: 0.54467
Time: 2018-07-15 08:17:53
TRAINING STATS: batch 280/486 in epoch 1020, batch loss: 1.65928, batch accuracy: 0.55100
Time: 2018-07-15 08:17:57
TRAINING STATS: batch 330/486 in epoch 1020, batch loss: 1.65801, batch accuracy: 0.55467
Time: 2018-07-15 08:18:01
TRAINING STATS: batch 380/486 in epoch 1020, batch loss: 1.65292, batch accuracy: 0.56183
Time: 2018-07-15 08:18:06
TRAINING STATS: batch 430/486 in epoch 1020, batch loss: 1.62412, batch accuracy: 0.57200
Time: 2018-07-15 08:18:09
TRAINING STATS: batch 480/486 in epoch 1020, batch loss: 1.68867, batch accuracy: 0.54567
Time: 2018-07-15 08:18:13
TRAINING STATS: batch 44/486 in epoch 1021,  batch loss: 1.61524, batch accuracy: 0.57067
Time: 2018-07-15 08:18:18
TRAINING STATS: batch 94/486 in epoch 1021,  batch loss: 1.71674, batch accuracy: 0.54383
Time: 2018-07-15 08:18:22
TRAINING STATS: batch 144/486 in epoch 1021, batch loss: 1.75244, batch accuracy: 0.52550
Time: 2018-07-15 08:18:25
TRAINING STATS: batch 194/486 in epoch 1021, batch loss: 1.76526, batch accuracy: 0.52300
Time: 2018-07-15 08:18:30
TRAINING STATS: batch 244/486 in epoch 1021, batch loss: 1.67046, batch accuracy: 0.54650
Time: 2018-07-15 08:18:34
TRAINING STATS: batch 294/486 in epoch 1021, batch loss: 1.59837, batch accuracy: 0.57283
Time: 2018-07-15 08:18:37
TRAINING STATS: batch 344/486 in epoch 1021, batch loss: 1.65703, batch accuracy: 0.55367
Time: 2018-07-15 08:18:42
TRAINING STATS: batch 394/486 in epoch 1021, batch loss: 1.65176, batch accuracy: 0.56100
Time: 2018-07-15 08:18:46
TRAINING STATS: batch 444/486 in epoch 1021, batch loss: 1.61346, batch accuracy: 0.57183
Time: 2018-07-15 08:18:49
TRAINING STATS: batch 8/486 in epoch 1022,   batch loss: 1.66961, batch accuracy: 0.54933
Time: 2018-07-15 08:18:54
TRAINING STATS: batch 58/486 in epoch 1022,  batch loss: 1.67226, batch accuracy: 0.55517
Time: 2018-07-15 08:18:58
TRAINING STATS: batch 108/486 in epoch 1022, batch loss: 1.87943, batch accuracy: 0.49617
Time: 2018-07-15 08:19:02
TRAINING STATS: batch 158/486 in epoch 1022, batch loss: 1.81080, batch accuracy: 0.51683
Time: 2018-07-15 08:19:06
TRAINING STATS: batch 208/486 in epoch 1022, batch loss: 1.76726, batch accuracy: 0.51933
Time: 2018-07-15 08:19:10
TRAINING STATS: batch 258/486 in epoch 1022, batch loss: 1.65972, batch accuracy: 0.55800
Time: 2018-07-15 08:19:14
TRAINING STATS: batch 308/486 in epoch 1022, batch loss: 1.71924, batch accuracy: 0.54883
Time: 2018-07-15 08:19:18
TRAINING STATS: batch 358/486 in epoch 1022, batch loss: 1.72856, batch accuracy: 0.52933
Time: 2018-07-15 08:19:22
TRAINING STATS: batch 408/486 in epoch 1022, batch loss: 1.72931, batch accuracy: 0.53517
Time: 2018-07-15 08:19:26
TRAINING STATS: batch 458/486 in epoch 1022, batch loss: 1.68813, batch accuracy: 0.54600
Time: 2018-07-15 08:19:30
TRAINING STATS: batch 22/486 in epoch 1023,  batch loss: 1.74007, batch accuracy: 0.54200
Time: 2018-07-15 08:19:34
TRAINING STATS: batch 72/486 in epoch 1023,  batch loss: 1.70662, batch accuracy: 0.53617
Time: 2018-07-15 08:19:38
TRAINING STATS: batch 122/486 in epoch 1023, batch loss: 1.62954, batch accuracy: 0.56783
Time: 2018-07-15 08:19:42
TRAINING STATS: batch 172/486 in epoch 1023, batch loss: 1.75526, batch accuracy: 0.52833
Time: 2018-07-15 08:19:46
TRAINING STATS: batch 222/486 in epoch 1023, batch loss: 1.68104, batch accuracy: 0.54783
Time: 2018-07-15 08:19:50
TRAINING STATS: batch 272/486 in epoch 1023, batch loss: 1.71469, batch accuracy: 0.53150
Time: 2018-07-15 08:19:55
TRAINING STATS: batch 322/486 in epoch 1023, batch loss: 1.67253, batch accuracy: 0.55100
Time: 2018-07-15 08:19:58
TRAINING STATS: batch 372/486 in epoch 1023, batch loss: 1.62016, batch accuracy: 0.56733
Time: 2018-07-15 08:20:02
TRAINING STATS: batch 422/486 in epoch 1023, batch loss: 1.64631, batch accuracy: 0.55450
Time: 2018-07-15 08:20:07
TRAINING STATS: batch 472/486 in epoch 1023, batch loss: 1.73683, batch accuracy: 0.53367
Time: 2018-07-15 08:20:10
TRAINING STATS: batch 36/486 in epoch 1024,  batch loss: 1.74063, batch accuracy: 0.53967
Time: 2018-07-15 08:20:14
TRAINING STATS: batch 86/486 in epoch 1024,  batch loss: 1.67887, batch accuracy: 0.55883
Time: 2018-07-15 08:20:19
TRAINING STATS: batch 136/486 in epoch 1024, batch loss: 1.73636, batch accuracy: 0.53850
Time: 2018-07-15 08:20:22
TRAINING STATS: batch 186/486 in epoch 1024, batch loss: 1.72954, batch accuracy: 0.54050
Time: 2018-07-15 08:20:26
TRAINING STATS: batch 236/486 in epoch 1024, batch loss: 1.72301, batch accuracy: 0.53833
Time: 2018-07-15 08:20:31
TRAINING STATS: batch 286/486 in epoch 1024, batch loss: 1.71872, batch accuracy: 0.53917
Time: 2018-07-15 08:20:34
TRAINING STATS: batch 336/486 in epoch 1024, batch loss: 1.65194, batch accuracy: 0.56083
Time: 2018-07-15 08:20:38
TRAINING STATS: batch 386/486 in epoch 1024, batch loss: 1.72213, batch accuracy: 0.53583
Time: 2018-07-15 08:20:43
TRAINING STATS: batch 436/486 in epoch 1024, batch loss: 1.80151, batch accuracy: 0.51667
Time: 2018-07-15 08:20:47
TRAINING STATS: batch 0/486 in epoch 1025,   batch loss: 1.70986, batch accuracy: 0.53467
Time: 2018-07-15 08:20:50
TRAINING STATS: batch 50/486 in epoch 1025,  batch loss: 1.65409, batch accuracy: 0.55917
Time: 2018-07-15 08:20:55
TRAINING STATS: batch 100/486 in epoch 1025, batch loss: 1.70456, batch accuracy: 0.54867
Time: 2018-07-15 08:20:59
TRAINING STATS: batch 150/486 in epoch 1025, batch loss: 1.63940, batch accuracy: 0.56650
Time: 2018-07-15 08:21:02
TRAINING STATS: batch 200/486 in epoch 1025, batch loss: 1.57482, batch accuracy: 0.57950
Time: 2018-07-15 08:21:07
TRAINING STATS: batch 250/486 in epoch 1025, batch loss: 1.73032, batch accuracy: 0.53267
Time: 2018-07-15 08:21:11
TRAINING STATS: batch 300/486 in epoch 1025, batch loss: 1.71956, batch accuracy: 0.52867
Time: 2018-07-15 08:21:14
TRAINING STATS: batch 350/486 in epoch 1025, batch loss: 1.69902, batch accuracy: 0.55050
Time: 2018-07-15 08:21:19
TRAINING STATS: batch 400/486 in epoch 1025, batch loss: 1.57591, batch accuracy: 0.57417
Time: 2018-07-15 08:21:23
TRAINING STATS: batch 450/486 in epoch 1025, batch loss: 1.74101, batch accuracy: 0.53000
Time: 2018-07-15 08:21:27
TRAINING STATS: batch 14/486 in epoch 1026,  batch loss: 1.59692, batch accuracy: 0.57867
Time: 2018-07-15 08:21:31
TRAINING STATS: batch 64/486 in epoch 1026,  batch loss: 1.76478, batch accuracy: 0.52600
Time: 2018-07-15 08:21:35
TRAINING STATS: batch 114/486 in epoch 1026, batch loss: 1.73106, batch accuracy: 0.53450
Time: 2018-07-15 08:21:39
TRAINING STATS: batch 164/486 in epoch 1026, batch loss: 1.62818, batch accuracy: 0.57350
Time: 2018-07-15 08:21:43
TRAINING STATS: batch 214/486 in epoch 1026, batch loss: 1.66435, batch accuracy: 0.55150
Time: 2018-07-15 08:21:47
TRAINING STATS: batch 264/486 in epoch 1026, batch loss: 1.72089, batch accuracy: 0.53233
Time: 2018-07-15 08:21:51
TRAINING STATS: batch 314/486 in epoch 1026, batch loss: 1.74156, batch accuracy: 0.53067
Time: 2018-07-15 08:21:55
TRAINING STATS: batch 364/486 in epoch 1026, batch loss: 1.67089, batch accuracy: 0.55617
Time: 2018-07-15 08:21:59
TRAINING STATS: batch 414/486 in epoch 1026, batch loss: 1.60774, batch accuracy: 0.56467
Time: 2018-07-15 08:22:03
TRAINING STATS: batch 464/486 in epoch 1026, batch loss: 1.64184, batch accuracy: 0.56233
Time: 2018-07-15 08:22:08
TRAINING STATS: batch 28/486 in epoch 1027,  batch loss: 1.61082, batch accuracy: 0.57017
Time: 2018-07-15 08:22:11
TRAINING STATS: batch 78/486 in epoch 1027,  batch loss: 1.67900, batch accuracy: 0.55033
Time: 2018-07-15 08:22:15
TRAINING STATS: batch 128/486 in epoch 1027, batch loss: 1.66966, batch accuracy: 0.55867
Time: 2018-07-15 08:22:20
TRAINING STATS: batch 178/486 in epoch 1027, batch loss: 1.57971, batch accuracy: 0.56967
Time: 2018-07-15 08:22:23
TRAINING STATS: batch 228/486 in epoch 1027, batch loss: 1.62286, batch accuracy: 0.57033
Time: 2018-07-15 08:22:27
TRAINING STATS: batch 278/486 in epoch 1027, batch loss: 1.61418, batch accuracy: 0.57567
Time: 2018-07-15 08:22:32
TRAINING STATS: batch 328/486 in epoch 1027, batch loss: 1.63221, batch accuracy: 0.56383
Time: 2018-07-15 08:22:35
TRAINING STATS: batch 378/486 in epoch 1027, batch loss: 1.68663, batch accuracy: 0.55817
Time: 2018-07-15 08:22:39
TRAINING STATS: batch 428/486 in epoch 1027, batch loss: 1.71349, batch accuracy: 0.53900
Time: 2018-07-15 08:22:44
TRAINING STATS: batch 478/486 in epoch 1027, batch loss: 1.68601, batch accuracy: 0.54883
Time: 2018-07-15 08:22:48
TRAINING STATS: batch 42/486 in epoch 1028,  batch loss: 1.59744, batch accuracy: 0.57667
Time: 2018-07-15 08:22:51
TRAINING STATS: batch 92/486 in epoch 1028,  batch loss: 1.70231, batch accuracy: 0.53867
Time: 2018-07-15 08:22:56
TRAINING STATS: batch 142/486 in epoch 1028, batch loss: 1.63595, batch accuracy: 0.55683
Time: 2018-07-15 08:23:00
TRAINING STATS: batch 192/486 in epoch 1028, batch loss: 1.68355, batch accuracy: 0.54867
Time: 2018-07-15 08:23:03
TRAINING STATS: batch 242/486 in epoch 1028, batch loss: 1.65299, batch accuracy: 0.56683
Time: 2018-07-15 08:23:08
TRAINING STATS: batch 292/486 in epoch 1028, batch loss: 1.68056, batch accuracy: 0.54883
Time: 2018-07-15 08:23:12
TRAINING STATS: batch 342/486 in epoch 1028, batch loss: 1.63802, batch accuracy: 0.55900
Time: 2018-07-15 08:23:15
TRAINING STATS: batch 392/486 in epoch 1028, batch loss: 1.58970, batch accuracy: 0.57883
Time: 2018-07-15 08:23:20
TRAINING STATS: batch 442/486 in epoch 1028, batch loss: 1.57675, batch accuracy: 0.57950
Time: 2018-07-15 08:23:24
TRAINING STATS: batch 6/486 in epoch 1029,   batch loss: 1.71019, batch accuracy: 0.54850
Time: 2018-07-15 08:23:28
TRAINING STATS: batch 56/486 in epoch 1029,  batch loss: 1.63781, batch accuracy: 0.55983
Time: 2018-07-15 08:23:32
TRAINING STATS: batch 106/486 in epoch 1029, batch loss: 1.72611, batch accuracy: 0.53150
Time: 2018-07-15 08:23:36
TRAINING STATS: batch 156/486 in epoch 1029, batch loss: 1.69424, batch accuracy: 0.54650
Time: 2018-07-15 08:23:40
TRAINING STATS: batch 206/486 in epoch 1029, batch loss: 1.75316, batch accuracy: 0.52883
Time: 2018-07-15 08:23:44
TRAINING STATS: batch 256/486 in epoch 1029, batch loss: 1.63036, batch accuracy: 0.56333
Time: 2018-07-15 08:23:48
TRAINING STATS: batch 306/486 in epoch 1029, batch loss: 1.67340, batch accuracy: 0.55333
Time: 2018-07-15 08:23:52
TRAINING STATS: batch 356/486 in epoch 1029, batch loss: 1.70889, batch accuracy: 0.53833
Time: 2018-07-15 08:23:56
TRAINING STATS: batch 406/486 in epoch 1029, batch loss: 1.75317, batch accuracy: 0.52767
Time: 2018-07-15 08:24:00
TRAINING STATS: batch 456/486 in epoch 1029, batch loss: 1.54897, batch accuracy: 0.59800
Time: 2018-07-15 08:24:04
TRAINING STATS: batch 20/486 in epoch 1030,  batch loss: 1.66036, batch accuracy: 0.55967
Time: 2018-07-15 08:24:09
TRAINING STATS: batch 70/486 in epoch 1030,  batch loss: 1.56801, batch accuracy: 0.58700
Time: 2018-07-15 08:24:12
TRAINING STATS: batch 120/486 in epoch 1030, batch loss: 1.61875, batch accuracy: 0.56683
Time: 2018-07-15 08:24:16
TRAINING STATS: batch 170/486 in epoch 1030, batch loss: 1.65116, batch accuracy: 0.56350
Time: 2018-07-15 08:24:21
TRAINING STATS: batch 220/486 in epoch 1030, batch loss: 1.59110, batch accuracy: 0.58500
Time: 2018-07-15 08:24:24
TRAINING STATS: batch 270/486 in epoch 1030, batch loss: 1.68517, batch accuracy: 0.53867
Time: 2018-07-15 08:24:28
TRAINING STATS: batch 320/486 in epoch 1030, batch loss: 1.59961, batch accuracy: 0.56767
Time: 2018-07-15 08:24:33
TRAINING STATS: batch 370/486 in epoch 1030, batch loss: 1.65706, batch accuracy: 0.55833
Time: 2018-07-15 08:24:36
TRAINING STATS: batch 420/486 in epoch 1030, batch loss: 1.70071, batch accuracy: 0.54900
Time: 2018-07-15 08:24:40
TRAINING STATS: batch 470/486 in epoch 1030, batch loss: 1.74891, batch accuracy: 0.53300
Time: 2018-07-15 08:24:45
TRAINING STATS: batch 34/486 in epoch 1031,  batch loss: 1.68570, batch accuracy: 0.54933
Time: 2018-07-15 08:24:49
TRAINING STATS: batch 84/486 in epoch 1031,  batch loss: 1.68441, batch accuracy: 0.54167
Time: 2018-07-15 08:24:52
TRAINING STATS: batch 134/486 in epoch 1031, batch loss: 1.71589, batch accuracy: 0.54833
Time: 2018-07-15 08:24:57
TRAINING STATS: batch 184/486 in epoch 1031, batch loss: 1.68441, batch accuracy: 0.55150
Time: 2018-07-15 08:25:01
TRAINING STATS: batch 234/486 in epoch 1031, batch loss: 1.73367, batch accuracy: 0.53450
Time: 2018-07-15 08:25:04
TRAINING STATS: batch 284/486 in epoch 1031, batch loss: 1.72132, batch accuracy: 0.53500
Time: 2018-07-15 08:25:09
TRAINING STATS: batch 334/486 in epoch 1031, batch loss: 1.65662, batch accuracy: 0.56017
Time: 2018-07-15 08:25:13
TRAINING STATS: batch 384/486 in epoch 1031, batch loss: 1.64611, batch accuracy: 0.55800
Time: 2018-07-15 08:25:16
TRAINING STATS: batch 434/486 in epoch 1031, batch loss: 1.78115, batch accuracy: 0.51033
Time: 2018-07-15 08:25:21
TRAINING STATS: batch 484/486 in epoch 1031, batch loss: 1.68314, batch accuracy: 0.54567
Time: 2018-07-15 08:25:25
TRAINING STATS: batch 48/486 in epoch 1032,  batch loss: 1.66133, batch accuracy: 0.55117
Time: 2018-07-15 08:25:29
TRAINING STATS: batch 98/486 in epoch 1032,  batch loss: 1.64423, batch accuracy: 0.55883
Time: 2018-07-15 08:25:33
TRAINING STATS: batch 148/486 in epoch 1032, batch loss: 1.71382, batch accuracy: 0.55417
Time: 2018-07-15 08:25:37
TRAINING STATS: batch 198/486 in epoch 1032, batch loss: 1.65313, batch accuracy: 0.55367
Time: 2018-07-15 08:25:41
TRAINING STATS: batch 248/486 in epoch 1032, batch loss: 1.71115, batch accuracy: 0.54200
Time: 2018-07-15 08:25:45
TRAINING STATS: batch 298/486 in epoch 1032, batch loss: 1.69831, batch accuracy: 0.54050
Time: 2018-07-15 08:25:49
TRAINING STATS: batch 348/486 in epoch 1032, batch loss: 1.66838, batch accuracy: 0.56417
Time: 2018-07-15 08:25:53
TRAINING STATS: batch 398/486 in epoch 1032, batch loss: 1.67233, batch accuracy: 0.54867
Time: 2018-07-15 08:25:57
TRAINING STATS: batch 448/486 in epoch 1032, batch loss: 1.66290, batch accuracy: 0.55583
Time: 2018-07-15 08:26:01
TRAINING STATS: batch 12/486 in epoch 1033,  batch loss: 1.68059, batch accuracy: 0.54900
Time: 2018-07-15 08:26:05
TRAINING STATS: batch 62/486 in epoch 1033,  batch loss: 1.73812, batch accuracy: 0.52983
Time: 2018-07-15 08:26:10
TRAINING STATS: batch 112/486 in epoch 1033, batch loss: 1.65103, batch accuracy: 0.55833
Time: 2018-07-15 08:26:13
TRAINING STATS: batch 162/486 in epoch 1033, batch loss: 1.67579, batch accuracy: 0.55150
Time: 2018-07-15 08:26:17
TRAINING STATS: batch 212/486 in epoch 1033, batch loss: 1.64134, batch accuracy: 0.56167
Time: 2018-07-15 08:26:22
TRAINING STATS: batch 262/486 in epoch 1033, batch loss: 1.74079, batch accuracy: 0.52683
Time: 2018-07-15 08:26:25
TRAINING STATS: batch 312/486 in epoch 1033, batch loss: 1.68643, batch accuracy: 0.53867
Time: 2018-07-15 08:26:29
TRAINING STATS: batch 362/486 in epoch 1033, batch loss: 1.71700, batch accuracy: 0.54467
Time: 2018-07-15 08:26:34
TRAINING STATS: batch 412/486 in epoch 1033, batch loss: 1.62563, batch accuracy: 0.56783
Time: 2018-07-15 08:26:37
TRAINING STATS: batch 462/486 in epoch 1033, batch loss: 1.69433, batch accuracy: 0.54533
Time: 2018-07-15 08:26:41
TRAINING STATS: batch 26/486 in epoch 1034,  batch loss: 1.71829, batch accuracy: 0.54350
Time: 2018-07-15 08:26:46
TRAINING STATS: batch 76/486 in epoch 1034,  batch loss: 1.73093, batch accuracy: 0.53383
Time: 2018-07-15 08:26:50
TRAINING STATS: batch 126/486 in epoch 1034, batch loss: 1.71660, batch accuracy: 0.53833
Time: 2018-07-15 08:26:53
TRAINING STATS: batch 176/486 in epoch 1034, batch loss: 1.61619, batch accuracy: 0.57217
Time: 2018-07-15 08:26:58
TRAINING STATS: batch 226/486 in epoch 1034, batch loss: 1.66573, batch accuracy: 0.55850
Time: 2018-07-15 08:27:02
TRAINING STATS: batch 276/486 in epoch 1034, batch loss: 1.67598, batch accuracy: 0.55483
Time: 2018-07-15 08:27:05
TRAINING STATS: batch 326/486 in epoch 1034, batch loss: 1.72039, batch accuracy: 0.54400
Time: 2018-07-15 08:27:10
TRAINING STATS: batch 376/486 in epoch 1034, batch loss: 1.70586, batch accuracy: 0.54633
Time: 2018-07-15 08:27:14
TRAINING STATS: batch 426/486 in epoch 1034, batch loss: 1.64943, batch accuracy: 0.55550
Time: 2018-07-15 08:27:17
TRAINING STATS: batch 476/486 in epoch 1034, batch loss: 1.60565, batch accuracy: 0.57133
Time: 2018-07-15 08:27:22
TRAINING STATS: batch 40/486 in epoch 1035,  batch loss: 1.64329, batch accuracy: 0.56733
Time: 2018-07-15 08:27:26
TRAINING STATS: batch 90/486 in epoch 1035,  batch loss: 1.72145, batch accuracy: 0.54017
Time: 2018-07-15 08:27:29
TRAINING STATS: batch 140/486 in epoch 1035, batch loss: 1.61639, batch accuracy: 0.56717
Time: 2018-07-15 08:27:34
TRAINING STATS: batch 190/486 in epoch 1035, batch loss: 1.65057, batch accuracy: 0.55700
Time: 2018-07-15 08:27:38
TRAINING STATS: batch 240/486 in epoch 1035, batch loss: 1.65678, batch accuracy: 0.55467
Time: 2018-07-15 08:27:42
TRAINING STATS: batch 290/486 in epoch 1035, batch loss: 1.70819, batch accuracy: 0.53517
Time: 2018-07-15 08:27:46
TRAINING STATS: batch 340/486 in epoch 1035, batch loss: 1.73235, batch accuracy: 0.53167
Time: 2018-07-15 08:27:50
TRAINING STATS: batch 390/486 in epoch 1035, batch loss: 1.61295, batch accuracy: 0.57233
Time: 2018-07-15 08:27:54
TRAINING STATS: batch 440/486 in epoch 1035, batch loss: 1.66953, batch accuracy: 0.55833
Time: 2018-07-15 08:27:58
TRAINING STATS: batch 4/486 in epoch 1036,   batch loss: 1.62108, batch accuracy: 0.56117
Time: 2018-07-15 08:28:02
TRAINING STATS: batch 54/486 in epoch 1036,  batch loss: 1.67798, batch accuracy: 0.54950
Time: 2018-07-15 08:28:06
TRAINING STATS: batch 104/486 in epoch 1036, batch loss: 1.69085, batch accuracy: 0.54900
Time: 2018-07-15 08:28:11
TRAINING STATS: batch 154/486 in epoch 1036, batch loss: 1.67745, batch accuracy: 0.55000
Time: 2018-07-15 08:28:14
TRAINING STATS: batch 204/486 in epoch 1036, batch loss: 1.74289, batch accuracy: 0.53783
Time: 2018-07-15 08:28:18
TRAINING STATS: batch 254/486 in epoch 1036, batch loss: 1.59239, batch accuracy: 0.57033
Time: 2018-07-15 08:28:23
TRAINING STATS: batch 304/486 in epoch 1036, batch loss: 1.62169, batch accuracy: 0.56883
Time: 2018-07-15 08:28:26
TRAINING STATS: batch 354/486 in epoch 1036, batch loss: 1.68600, batch accuracy: 0.55217
Time: 2018-07-15 08:28:30
TRAINING STATS: batch 404/486 in epoch 1036, batch loss: 1.64613, batch accuracy: 0.55633
Time: 2018-07-15 08:28:35
TRAINING STATS: batch 454/486 in epoch 1036, batch loss: 1.53855, batch accuracy: 0.59150
Time: 2018-07-15 08:28:38
TRAINING STATS: batch 18/486 in epoch 1037,  batch loss: 1.70627, batch accuracy: 0.54817
Time: 2018-07-15 08:28:42
TRAINING STATS: batch 68/486 in epoch 1037,  batch loss: 1.52474, batch accuracy: 0.60050
Time: 2018-07-15 08:28:47
TRAINING STATS: batch 118/486 in epoch 1037, batch loss: 1.67847, batch accuracy: 0.55217
Time: 2018-07-15 08:28:51
TRAINING STATS: batch 168/486 in epoch 1037, batch loss: 1.59248, batch accuracy: 0.58350
Time: 2018-07-15 08:28:55
TRAINING STATS: batch 218/486 in epoch 1037, batch loss: 1.67223, batch accuracy: 0.55567
Time: 2018-07-15 08:28:59
TRAINING STATS: batch 268/486 in epoch 1037, batch loss: 1.61195, batch accuracy: 0.56600
Time: 2018-07-15 08:29:03
TRAINING STATS: batch 318/486 in epoch 1037, batch loss: 1.67817, batch accuracy: 0.54867
Time: 2018-07-15 08:29:07
TRAINING STATS: batch 368/486 in epoch 1037, batch loss: 1.69293, batch accuracy: 0.54233
Time: 2018-07-15 08:29:11
TRAINING STATS: batch 418/486 in epoch 1037, batch loss: 1.73148, batch accuracy: 0.53267
Time: 2018-07-15 08:29:15
TRAINING STATS: batch 468/486 in epoch 1037, batch loss: 1.67907, batch accuracy: 0.54950
Time: 2018-07-15 08:29:19
TRAINING STATS: batch 32/486 in epoch 1038,  batch loss: 1.61220, batch accuracy: 0.56850
Time: 2018-07-15 08:29:23
TRAINING STATS: batch 82/486 in epoch 1038,  batch loss: 1.71325, batch accuracy: 0.54117
Time: 2018-07-15 08:29:27
TRAINING STATS: batch 132/486 in epoch 1038, batch loss: 1.66047, batch accuracy: 0.55750
Time: 2018-07-15 08:29:31
TRAINING STATS: batch 182/486 in epoch 1038, batch loss: 1.71538, batch accuracy: 0.54000
Time: 2018-07-15 08:29:36
TRAINING STATS: batch 232/486 in epoch 1038, batch loss: 1.71441, batch accuracy: 0.53750
Time: 2018-07-15 08:29:39
TRAINING STATS: batch 282/486 in epoch 1038, batch loss: 1.64593, batch accuracy: 0.55950
Time: 2018-07-15 08:29:43
TRAINING STATS: batch 332/486 in epoch 1038, batch loss: 1.71098, batch accuracy: 0.54567
Time: 2018-07-15 08:29:48
TRAINING STATS: batch 382/486 in epoch 1038, batch loss: 1.70308, batch accuracy: 0.54117
Time: 2018-07-15 08:29:51
TRAINING STATS: batch 432/486 in epoch 1038, batch loss: 1.61566, batch accuracy: 0.56650
Time: 2018-07-15 08:29:55
TRAINING STATS: batch 482/486 in epoch 1038, batch loss: 1.65551, batch accuracy: 0.55950
Time: 2018-07-15 08:30:00
TRAINING STATS: batch 46/486 in epoch 1039,  batch loss: 1.64621, batch accuracy: 0.56583
Time: 2018-07-15 08:30:03
TRAINING STATS: batch 96/486 in epoch 1039,  batch loss: 1.70666, batch accuracy: 0.54550
Time: 2018-07-15 08:30:07
TRAINING STATS: batch 146/486 in epoch 1039, batch loss: 1.73319, batch accuracy: 0.53817
Time: 2018-07-15 08:30:12
TRAINING STATS: batch 196/486 in epoch 1039, batch loss: 1.71722, batch accuracy: 0.54183
Time: 2018-07-15 08:30:16
TRAINING STATS: batch 246/486 in epoch 1039, batch loss: 1.63814, batch accuracy: 0.55917
Time: 2018-07-15 08:30:19
TRAINING STATS: batch 296/486 in epoch 1039, batch loss: 1.64284, batch accuracy: 0.55850
Time: 2018-07-15 08:30:24
TRAINING STATS: batch 346/486 in epoch 1039, batch loss: 1.60817, batch accuracy: 0.57667
Time: 2018-07-15 08:30:28
TRAINING STATS: batch 396/486 in epoch 1039, batch loss: 1.64703, batch accuracy: 0.56417
Time: 2018-07-15 08:30:31
TRAINING STATS: batch 446/486 in epoch 1039, batch loss: 1.69515, batch accuracy: 0.54517
Time: 2018-07-15 08:30:36
TRAINING STATS: batch 10/486 in epoch 1040,  batch loss: 1.71686, batch accuracy: 0.53500
Time: 2018-07-15 08:30:40
TRAINING STATS: batch 60/486 in epoch 1040,  batch loss: 1.66395, batch accuracy: 0.55217
Time: 2018-07-15 08:30:43
TRAINING STATS: batch 110/486 in epoch 1040, batch loss: 1.72295, batch accuracy: 0.54417
Time: 2018-07-15 08:30:48
TRAINING STATS: batch 160/486 in epoch 1040, batch loss: 1.65562, batch accuracy: 0.55083
Time: 2018-07-15 08:30:52
TRAINING STATS: batch 210/486 in epoch 1040, batch loss: 1.61926, batch accuracy: 0.56250
Time: 2018-07-15 08:30:56
TRAINING STATS: batch 260/486 in epoch 1040, batch loss: 1.70420, batch accuracy: 0.54367
Time: 2018-07-15 08:31:00
TRAINING STATS: batch 310/486 in epoch 1040, batch loss: 1.69725, batch accuracy: 0.54250
Time: 2018-07-15 08:31:04
TRAINING STATS: batch 360/486 in epoch 1040, batch loss: 1.72005, batch accuracy: 0.53800
Time: 2018-07-15 08:31:08
TRAINING STATS: batch 410/486 in epoch 1040, batch loss: 1.60999, batch accuracy: 0.57800
Time: 2018-07-15 08:31:12
TRAINING STATS: batch 460/486 in epoch 1040, batch loss: 1.80029, batch accuracy: 0.50783
Time: 2018-07-15 08:31:16
TRAINING STATS: batch 24/486 in epoch 1041,  batch loss: 1.73783, batch accuracy: 0.53233
Time: 2018-07-15 08:31:20
TRAINING STATS: batch 74/486 in epoch 1041,  batch loss: 1.71522, batch accuracy: 0.54333
Time: 2018-07-15 08:31:25
TRAINING STATS: batch 124/486 in epoch 1041, batch loss: 1.70141, batch accuracy: 0.55150
Time: 2018-07-15 08:31:28
TRAINING STATS: batch 174/486 in epoch 1041, batch loss: 1.76234, batch accuracy: 0.52883
Time: 2018-07-15 08:31:32
TRAINING STATS: batch 224/486 in epoch 1041, batch loss: 1.71453, batch accuracy: 0.54067
Time: 2018-07-15 08:31:37
TRAINING STATS: batch 274/486 in epoch 1041, batch loss: 1.69318, batch accuracy: 0.54600
Time: 2018-07-15 08:31:40
TRAINING STATS: batch 324/486 in epoch 1041, batch loss: 1.71862, batch accuracy: 0.54350
Time: 2018-07-15 08:31:44
TRAINING STATS: batch 374/486 in epoch 1041, batch loss: 1.72076, batch accuracy: 0.53583
Time: 2018-07-15 08:31:49
TRAINING STATS: batch 424/486 in epoch 1041, batch loss: 1.61704, batch accuracy: 0.56750
Time: 2018-07-15 08:31:52
TRAINING STATS: batch 474/486 in epoch 1041, batch loss: 1.68838, batch accuracy: 0.54950
Time: 2018-07-15 08:31:56
TRAINING STATS: batch 38/486 in epoch 1042,  batch loss: 1.70561, batch accuracy: 0.54283
Time: 2018-07-15 08:32:01
TRAINING STATS: batch 88/486 in epoch 1042,  batch loss: 1.74598, batch accuracy: 0.53667
Time: 2018-07-15 08:32:04
TRAINING STATS: batch 138/486 in epoch 1042, batch loss: 1.74061, batch accuracy: 0.54150
Time: 2018-07-15 08:32:08
TRAINING STATS: batch 188/486 in epoch 1042, batch loss: 1.63830, batch accuracy: 0.56117
Time: 2018-07-15 08:32:13
TRAINING STATS: batch 238/486 in epoch 1042, batch loss: 1.67616, batch accuracy: 0.55733
Time: 2018-07-15 08:32:17
TRAINING STATS: batch 288/486 in epoch 1042, batch loss: 1.71722, batch accuracy: 0.53267
Time: 2018-07-15 08:32:20
TRAINING STATS: batch 338/486 in epoch 1042, batch loss: 1.69277, batch accuracy: 0.54633
Time: 2018-07-15 08:32:25
TRAINING STATS: batch 388/486 in epoch 1042, batch loss: 1.64921, batch accuracy: 0.56050
Time: 2018-07-15 08:32:29
TRAINING STATS: batch 438/486 in epoch 1042, batch loss: 1.70091, batch accuracy: 0.54883
Time: 2018-07-15 08:32:32
TRAINING STATS: batch 2/486 in epoch 1043,   batch loss: 1.70913, batch accuracy: 0.54350
Time: 2018-07-15 08:32:37
TRAINING STATS: batch 52/486 in epoch 1043,  batch loss: 1.74528, batch accuracy: 0.52817
Time: 2018-07-15 08:32:41
TRAINING STATS: batch 102/486 in epoch 1043, batch loss: 1.71233, batch accuracy: 0.54117
Time: 2018-07-15 08:32:45
TRAINING STATS: batch 152/486 in epoch 1043, batch loss: 1.64339, batch accuracy: 0.56117
Time: 2018-07-15 08:32:49
TRAINING STATS: batch 202/486 in epoch 1043, batch loss: 1.67625, batch accuracy: 0.55050
Time: 2018-07-15 08:32:53
TRAINING STATS: batch 252/486 in epoch 1043, batch loss: 1.65051, batch accuracy: 0.55900
Time: 2018-07-15 08:32:57
TRAINING STATS: batch 302/486 in epoch 1043, batch loss: 1.64498, batch accuracy: 0.55667
Time: 2018-07-15 08:33:01
TRAINING STATS: batch 352/486 in epoch 1043, batch loss: 1.66375, batch accuracy: 0.55500
Time: 2018-07-15 08:33:05
TRAINING STATS: batch 402/486 in epoch 1043, batch loss: 1.54179, batch accuracy: 0.59217
Time: 2018-07-15 08:33:09
TRAINING STATS: batch 452/486 in epoch 1043, batch loss: 1.69113, batch accuracy: 0.54350
Time: 2018-07-15 08:33:13
TRAINING STATS: batch 16/486 in epoch 1044,  batch loss: 1.65047, batch accuracy: 0.55717
Time: 2018-07-15 08:33:17
TRAINING STATS: batch 66/486 in epoch 1044,  batch loss: 1.66243, batch accuracy: 0.55400
Time: 2018-07-15 08:33:21
TRAINING STATS: batch 116/486 in epoch 1044, batch loss: 1.64031, batch accuracy: 0.56733
Time: 2018-07-15 08:33:26
TRAINING STATS: batch 166/486 in epoch 1044, batch loss: 1.59716, batch accuracy: 0.57483
Time: 2018-07-15 08:33:29
TRAINING STATS: batch 216/486 in epoch 1044, batch loss: 1.69887, batch accuracy: 0.54967
Time: 2018-07-15 08:33:33
TRAINING STATS: batch 266/486 in epoch 1044, batch loss: 1.71791, batch accuracy: 0.53817
Time: 2018-07-15 08:33:38
TRAINING STATS: batch 316/486 in epoch 1044, batch loss: 1.69016, batch accuracy: 0.54833
Time: 2018-07-15 08:33:41
TRAINING STATS: batch 366/486 in epoch 1044, batch loss: 1.73291, batch accuracy: 0.53750
Time: 2018-07-15 08:33:45
TRAINING STATS: batch 416/486 in epoch 1044, batch loss: 1.70957, batch accuracy: 0.53833
Time: 2018-07-15 08:33:50
TRAINING STATS: batch 466/486 in epoch 1044, batch loss: 1.54687, batch accuracy: 0.58517
Time: 2018-07-15 08:33:53
TRAINING STATS: batch 30/486 in epoch 1045,  batch loss: 1.58000, batch accuracy: 0.57300
Time: 2018-07-15 08:33:57
TRAINING STATS: batch 80/486 in epoch 1045,  batch loss: 1.67956, batch accuracy: 0.54717
Time: 2018-07-15 08:34:02
TRAINING STATS: batch 130/486 in epoch 1045, batch loss: 1.66268, batch accuracy: 0.55933
Time: 2018-07-15 08:34:06
TRAINING STATS: batch 180/486 in epoch 1045, batch loss: 1.69797, batch accuracy: 0.54367
Time: 2018-07-15 08:34:09
TRAINING STATS: batch 230/486 in epoch 1045, batch loss: 1.71760, batch accuracy: 0.53617
Time: 2018-07-15 08:34:14
TRAINING STATS: batch 280/486 in epoch 1045, batch loss: 1.65837, batch accuracy: 0.55000
Time: 2018-07-15 08:34:18
TRAINING STATS: batch 330/486 in epoch 1045, batch loss: 1.64887, batch accuracy: 0.55933
Time: 2018-07-15 08:34:21
TRAINING STATS: batch 380/486 in epoch 1045, batch loss: 1.64184, batch accuracy: 0.57317
Time: 2018-07-15 08:34:26
TRAINING STATS: batch 430/486 in epoch 1045, batch loss: 1.60986, batch accuracy: 0.57350
Time: 2018-07-15 08:34:30
TRAINING STATS: batch 480/486 in epoch 1045, batch loss: 1.67937, batch accuracy: 0.55317
Time: 2018-07-15 08:34:33
TRAINING STATS: batch 44/486 in epoch 1046,  batch loss: 1.61538, batch accuracy: 0.56700
Time: 2018-07-15 08:34:38
TRAINING STATS: batch 94/486 in epoch 1046,  batch loss: 1.73507, batch accuracy: 0.53817
Time: 2018-07-15 08:34:42
TRAINING STATS: batch 144/486 in epoch 1046, batch loss: 1.72420, batch accuracy: 0.53583
Time: 2018-07-15 08:34:45
TRAINING STATS: batch 194/486 in epoch 1046, batch loss: 1.76189, batch accuracy: 0.52583
Time: 2018-07-15 08:34:50
TRAINING STATS: batch 244/486 in epoch 1046, batch loss: 1.66693, batch accuracy: 0.55050
Time: 2018-07-15 08:34:54
TRAINING STATS: batch 294/486 in epoch 1046, batch loss: 1.60114, batch accuracy: 0.57467
Time: 2018-07-15 08:34:58
TRAINING STATS: batch 344/486 in epoch 1046, batch loss: 1.66009, batch accuracy: 0.55800
Time: 2018-07-15 08:35:02
TRAINING STATS: batch 394/486 in epoch 1046, batch loss: 1.63120, batch accuracy: 0.56467
Time: 2018-07-15 08:35:06
TRAINING STATS: batch 444/486 in epoch 1046, batch loss: 1.61615, batch accuracy: 0.57050
Time: 2018-07-15 08:35:10
TRAINING STATS: batch 8/486 in epoch 1047,   batch loss: 1.67054, batch accuracy: 0.54900
Time: 2018-07-15 08:35:14
TRAINING STATS: batch 58/486 in epoch 1047,  batch loss: 1.64616, batch accuracy: 0.56100
Time: 2018-07-15 08:35:18
TRAINING STATS: batch 108/486 in epoch 1047, batch loss: 1.73308, batch accuracy: 0.53750
Time: 2018-07-15 08:35:22
TRAINING STATS: batch 158/486 in epoch 1047, batch loss: 1.71809, batch accuracy: 0.53600
Time: 2018-07-15 08:35:26
TRAINING STATS: batch 208/486 in epoch 1047, batch loss: 1.69377, batch accuracy: 0.54600
Time: 2018-07-15 08:35:30
TRAINING STATS: batch 258/486 in epoch 1047, batch loss: 1.62227, batch accuracy: 0.56600
Time: 2018-07-15 08:35:34
TRAINING STATS: batch 308/486 in epoch 1047, batch loss: 1.70854, batch accuracy: 0.54533
Time: 2018-07-15 08:35:39
TRAINING STATS: batch 358/486 in epoch 1047, batch loss: 1.68425, batch accuracy: 0.54683
Time: 2018-07-15 08:35:42
TRAINING STATS: batch 408/486 in epoch 1047, batch loss: 1.71522, batch accuracy: 0.54083
Time: 2018-07-15 08:35:46
TRAINING STATS: batch 458/486 in epoch 1047, batch loss: 1.68859, batch accuracy: 0.54800
Time: 2018-07-15 08:35:51
TRAINING STATS: batch 22/486 in epoch 1048,  batch loss: 1.72380, batch accuracy: 0.54500
Time: 2018-07-15 08:35:54
TRAINING STATS: batch 72/486 in epoch 1048,  batch loss: 1.70217, batch accuracy: 0.54150
Time: 2018-07-15 08:35:58
TRAINING STATS: batch 122/486 in epoch 1048, batch loss: 1.61975, batch accuracy: 0.56350
Time: 2018-07-15 08:36:03
TRAINING STATS: batch 172/486 in epoch 1048, batch loss: 1.74219, batch accuracy: 0.53117
Time: 2018-07-15 08:36:06
TRAINING STATS: batch 222/486 in epoch 1048, batch loss: 1.66575, batch accuracy: 0.54533
Time: 2018-07-15 08:36:10
TRAINING STATS: batch 272/486 in epoch 1048, batch loss: 1.70610, batch accuracy: 0.53817
Time: 2018-07-15 08:36:15
TRAINING STATS: batch 322/486 in epoch 1048, batch loss: 1.68189, batch accuracy: 0.54667
Time: 2018-07-15 08:36:19
TRAINING STATS: batch 372/486 in epoch 1048, batch loss: 1.61800, batch accuracy: 0.56600
Time: 2018-07-15 08:36:22
TRAINING STATS: batch 422/486 in epoch 1048, batch loss: 1.82053, batch accuracy: 0.50533
Time: 2018-07-15 08:36:27
TRAINING STATS: batch 472/486 in epoch 1048, batch loss: 1.87470, batch accuracy: 0.49450
Time: 2018-07-15 08:36:31
TRAINING STATS: batch 36/486 in epoch 1049,  batch loss: 1.79210, batch accuracy: 0.52033
Time: 2018-07-15 08:36:34
TRAINING STATS: batch 86/486 in epoch 1049,  batch loss: 1.75707, batch accuracy: 0.53150
Time: 2018-07-15 08:36:39
TRAINING STATS: batch 136/486 in epoch 1049, batch loss: 1.76468, batch accuracy: 0.52267
Time: 2018-07-15 08:36:43
TRAINING STATS: batch 186/486 in epoch 1049, batch loss: 1.70536, batch accuracy: 0.53800
Time: 2018-07-15 08:36:46
TRAINING STATS: batch 236/486 in epoch 1049, batch loss: 1.71959, batch accuracy: 0.53517
Time: 2018-07-15 08:36:51
TRAINING STATS: batch 286/486 in epoch 1049, batch loss: 1.71612, batch accuracy: 0.54517
Time: 2018-07-15 08:36:55
TRAINING STATS: batch 336/486 in epoch 1049, batch loss: 1.66704, batch accuracy: 0.54767
Time: 2018-07-15 08:36:59
TRAINING STATS: batch 386/486 in epoch 1049, batch loss: 1.73858, batch accuracy: 0.53250
Time: 2018-07-15 08:37:03
TRAINING STATS: batch 436/486 in epoch 1049, batch loss: 1.71429, batch accuracy: 0.54683
Time: 2018-07-15 08:37:07
TRAINING STATS: batch 0/486 in epoch 1050,   batch loss: 1.67428, batch accuracy: 0.55017
Time: 2018-07-15 08:37:11
TRAINING STATS: batch 50/486 in epoch 1050,  batch loss: 1.64301, batch accuracy: 0.55750
Time: 2018-07-15 08:37:15
TRAINING STATS: batch 100/486 in epoch 1050, batch loss: 1.68970, batch accuracy: 0.54883
Time: 2018-07-15 08:37:19
TRAINING STATS: batch 150/486 in epoch 1050, batch loss: 1.64711, batch accuracy: 0.56500
Time: 2018-07-15 08:37:23
TRAINING STATS: batch 200/486 in epoch 1050, batch loss: 1.54670, batch accuracy: 0.59083
Time: 2018-07-15 08:37:27
TRAINING STATS: batch 250/486 in epoch 1050, batch loss: 1.75479, batch accuracy: 0.52767
Time: 2018-07-15 08:37:31
TRAINING STATS: batch 300/486 in epoch 1050, batch loss: 1.72222, batch accuracy: 0.53100
Time: 2018-07-15 08:37:35
TRAINING STATS: batch 350/486 in epoch 1050, batch loss: 1.69578, batch accuracy: 0.54800
Time: 2018-07-15 08:37:40
TRAINING STATS: batch 400/486 in epoch 1050, batch loss: 1.58520, batch accuracy: 0.57333
Time: 2018-07-15 08:37:43
TRAINING STATS: batch 450/486 in epoch 1050, batch loss: 1.73497, batch accuracy: 0.52817
Time: 2018-07-15 08:37:47
TRAINING STATS: batch 14/486 in epoch 1051,  batch loss: 1.59748, batch accuracy: 0.57900
Time: 2018-07-15 08:37:52
TRAINING STATS: batch 64/486 in epoch 1051,  batch loss: 1.76500, batch accuracy: 0.52667
Time: 2018-07-15 08:37:55
TRAINING STATS: batch 114/486 in epoch 1051, batch loss: 1.73513, batch accuracy: 0.53450
Time: 2018-07-15 08:37:59
TRAINING STATS: batch 164/486 in epoch 1051, batch loss: 1.62327, batch accuracy: 0.57233
Time: 2018-07-15 08:38:04
TRAINING STATS: batch 214/486 in epoch 1051, batch loss: 1.67455, batch accuracy: 0.54717
Time: 2018-07-15 08:38:07
TRAINING STATS: batch 264/486 in epoch 1051, batch loss: 1.73872, batch accuracy: 0.52417
Time: 2018-07-15 08:38:11
TRAINING STATS: batch 314/486 in epoch 1051, batch loss: 1.73733, batch accuracy: 0.52717
Time: 2018-07-15 08:38:16
TRAINING STATS: batch 364/486 in epoch 1051, batch loss: 1.67289, batch accuracy: 0.55150
Time: 2018-07-15 08:38:20
TRAINING STATS: batch 414/486 in epoch 1051, batch loss: 1.61743, batch accuracy: 0.56417
Time: 2018-07-15 08:38:23
TRAINING STATS: batch 464/486 in epoch 1051, batch loss: 1.63721, batch accuracy: 0.56067
Time: 2018-07-15 08:38:28
TRAINING STATS: batch 28/486 in epoch 1052,  batch loss: 1.61823, batch accuracy: 0.56783
Time: 2018-07-15 08:38:32
TRAINING STATS: batch 78/486 in epoch 1052,  batch loss: 1.69257, batch accuracy: 0.54967
Time: 2018-07-15 08:38:35
TRAINING STATS: batch 128/486 in epoch 1052, batch loss: 1.65754, batch accuracy: 0.55700
Time: 2018-07-15 08:38:40
TRAINING STATS: batch 178/486 in epoch 1052, batch loss: 1.56799, batch accuracy: 0.57500
Time: 2018-07-15 08:38:44
TRAINING STATS: batch 228/486 in epoch 1052, batch loss: 1.62654, batch accuracy: 0.56183
Time: 2018-07-15 08:38:48
TRAINING STATS: batch 278/486 in epoch 1052, batch loss: 1.60164, batch accuracy: 0.57300
Time: 2018-07-15 08:38:52
TRAINING STATS: batch 328/486 in epoch 1052, batch loss: 1.63720, batch accuracy: 0.55717
Time: 2018-07-15 08:38:56
TRAINING STATS: batch 378/486 in epoch 1052, batch loss: 1.68404, batch accuracy: 0.55050
Time: 2018-07-15 08:39:00
TRAINING STATS: batch 428/486 in epoch 1052, batch loss: 1.71103, batch accuracy: 0.54383
Time: 2018-07-15 08:39:04
TRAINING STATS: batch 478/486 in epoch 1052, batch loss: 1.67917, batch accuracy: 0.54500
Time: 2018-07-15 08:39:08
TRAINING STATS: batch 42/486 in epoch 1053,  batch loss: 1.59687, batch accuracy: 0.57033
Time: 2018-07-15 08:39:12
TRAINING STATS: batch 92/486 in epoch 1053,  batch loss: 1.67876, batch accuracy: 0.54817
Time: 2018-07-15 08:39:17
TRAINING STATS: batch 142/486 in epoch 1053, batch loss: 1.63397, batch accuracy: 0.55867
Time: 2018-07-15 08:39:20
TRAINING STATS: batch 192/486 in epoch 1053, batch loss: 1.68188, batch accuracy: 0.55067
Time: 2018-07-15 08:39:24
TRAINING STATS: batch 242/486 in epoch 1053, batch loss: 1.64055, batch accuracy: 0.56433
Time: 2018-07-15 08:39:29
TRAINING STATS: batch 292/486 in epoch 1053, batch loss: 1.65890, batch accuracy: 0.55933
Time: 2018-07-15 08:39:32
TRAINING STATS: batch 342/486 in epoch 1053, batch loss: 1.62753, batch accuracy: 0.56167
Time: 2018-07-15 08:39:36
TRAINING STATS: batch 392/486 in epoch 1053, batch loss: 1.57097, batch accuracy: 0.57233
Time: 2018-07-15 08:39:41
TRAINING STATS: batch 442/486 in epoch 1053, batch loss: 1.57854, batch accuracy: 0.57600
Time: 2018-07-15 08:39:44
TRAINING STATS: batch 6/486 in epoch 1054,   batch loss: 1.71848, batch accuracy: 0.54000
Time: 2018-07-15 08:39:48
TRAINING STATS: batch 56/486 in epoch 1054,  batch loss: 1.64801, batch accuracy: 0.55467
Time: 2018-07-15 08:39:53
TRAINING STATS: batch 106/486 in epoch 1054, batch loss: 1.73508, batch accuracy: 0.53567
Time: 2018-07-15 08:39:57
TRAINING STATS: batch 156/486 in epoch 1054, batch loss: 1.70863, batch accuracy: 0.53950
Time: 2018-07-15 08:40:00
TRAINING STATS: batch 206/486 in epoch 1054, batch loss: 1.74618, batch accuracy: 0.52800
Time: 2018-07-15 08:40:05
TRAINING STATS: batch 256/486 in epoch 1054, batch loss: 1.61845, batch accuracy: 0.56550
Time: 2018-07-15 08:40:09
TRAINING STATS: batch 306/486 in epoch 1054, batch loss: 1.68164, batch accuracy: 0.54833
Time: 2018-07-15 08:40:12
TRAINING STATS: batch 356/486 in epoch 1054, batch loss: 1.71645, batch accuracy: 0.53100
Time: 2018-07-15 08:40:17
TRAINING STATS: batch 406/486 in epoch 1054, batch loss: 1.75128, batch accuracy: 0.52467
Time: 2018-07-15 08:40:21
TRAINING STATS: batch 456/486 in epoch 1054, batch loss: 1.55464, batch accuracy: 0.58833
Time: 2018-07-15 08:40:25
TRAINING STATS: batch 20/486 in epoch 1055,  batch loss: 1.67131, batch accuracy: 0.54967
Time: 2018-07-15 08:40:29
TRAINING STATS: batch 70/486 in epoch 1055,  batch loss: 1.56383, batch accuracy: 0.57983
Time: 2018-07-15 08:40:33
TRAINING STATS: batch 120/486 in epoch 1055, batch loss: 1.62126, batch accuracy: 0.55933
Time: 2018-07-15 08:40:37
TRAINING STATS: batch 170/486 in epoch 1055, batch loss: 1.64780, batch accuracy: 0.55267
Time: 2018-07-15 08:40:41
TRAINING STATS: batch 220/486 in epoch 1055, batch loss: 1.58770, batch accuracy: 0.57967
Time: 2018-07-15 08:40:45
TRAINING STATS: batch 270/486 in epoch 1055, batch loss: 1.69790, batch accuracy: 0.53833
Time: 2018-07-15 08:40:49
TRAINING STATS: batch 320/486 in epoch 1055, batch loss: 1.62029, batch accuracy: 0.56733
Time: 2018-07-15 08:40:54
TRAINING STATS: batch 370/486 in epoch 1055, batch loss: 1.67663, batch accuracy: 0.55567
Time: 2018-07-15 08:40:57
TRAINING STATS: batch 420/486 in epoch 1055, batch loss: 1.71138, batch accuracy: 0.53950
Time: 2018-07-15 08:41:01
TRAINING STATS: batch 470/486 in epoch 1055, batch loss: 1.75917, batch accuracy: 0.52367
Time: 2018-07-15 08:41:06
TRAINING STATS: batch 34/486 in epoch 1056,  batch loss: 1.71276, batch accuracy: 0.53967
Time: 2018-07-15 08:41:09
TRAINING STATS: batch 84/486 in epoch 1056,  batch loss: 1.69544, batch accuracy: 0.54050
Time: 2018-07-15 08:41:13
TRAINING STATS: batch 134/486 in epoch 1056, batch loss: 1.72606, batch accuracy: 0.54433
Time: 2018-07-15 08:41:18
TRAINING STATS: batch 184/486 in epoch 1056, batch loss: 1.70018, batch accuracy: 0.54383
Time: 2018-07-15 08:41:21
TRAINING STATS: batch 234/486 in epoch 1056, batch loss: 1.75103, batch accuracy: 0.52950
Time: 2018-07-15 08:41:25
TRAINING STATS: batch 284/486 in epoch 1056, batch loss: 1.74089, batch accuracy: 0.53000
Time: 2018-07-15 08:41:30
TRAINING STATS: batch 334/486 in epoch 1056, batch loss: 1.67287, batch accuracy: 0.55383
Time: 2018-07-15 08:41:34
TRAINING STATS: batch 384/486 in epoch 1056, batch loss: 1.65114, batch accuracy: 0.55717
Time: 2018-07-15 08:41:37
TRAINING STATS: batch 434/486 in epoch 1056, batch loss: 1.72712, batch accuracy: 0.53133
Time: 2018-07-15 08:41:42
TRAINING STATS: batch 484/486 in epoch 1056, batch loss: 1.69317, batch accuracy: 0.54200
Time: 2018-07-15 08:41:46
TRAINING STATS: batch 48/486 in epoch 1057,  batch loss: 1.66426, batch accuracy: 0.55417
Time: 2018-07-15 08:41:49
TRAINING STATS: batch 98/486 in epoch 1057,  batch loss: 1.63451, batch accuracy: 0.56600
Time: 2018-07-15 08:41:54
TRAINING STATS: batch 148/486 in epoch 1057, batch loss: 1.71815, batch accuracy: 0.54083
Time: 2018-07-15 08:41:58
TRAINING STATS: batch 198/486 in epoch 1057, batch loss: 1.66492, batch accuracy: 0.55300
Time: 2018-07-15 08:42:01
TRAINING STATS: batch 248/486 in epoch 1057, batch loss: 1.71118, batch accuracy: 0.53967
Time: 2018-07-15 08:42:06
TRAINING STATS: batch 298/486 in epoch 1057, batch loss: 1.69938, batch accuracy: 0.53300
Time: 2018-07-15 08:42:10
TRAINING STATS: batch 348/486 in epoch 1057, batch loss: 1.66561, batch accuracy: 0.55450
Time: 2018-07-15 08:42:13
TRAINING STATS: batch 398/486 in epoch 1057, batch loss: 1.68925, batch accuracy: 0.54600
Time: 2018-07-15 08:42:18
TRAINING STATS: batch 448/486 in epoch 1057, batch loss: 1.66461, batch accuracy: 0.55517
Time: 2018-07-15 08:42:22
TRAINING STATS: batch 12/486 in epoch 1058,  batch loss: 1.70695, batch accuracy: 0.53817
Time: 2018-07-15 08:42:26
TRAINING STATS: batch 62/486 in epoch 1058,  batch loss: 1.75050, batch accuracy: 0.52517
Time: 2018-07-15 08:42:30
TRAINING STATS: batch 112/486 in epoch 1058, batch loss: 1.67808, batch accuracy: 0.55200
Time: 2018-07-15 08:42:34
TRAINING STATS: batch 162/486 in epoch 1058, batch loss: 1.68533, batch accuracy: 0.54883
Time: 2018-07-15 08:42:38
TRAINING STATS: batch 212/486 in epoch 1058, batch loss: 1.58591, batch accuracy: 0.57067
Time: 2018-07-15 08:42:42
TRAINING STATS: batch 262/486 in epoch 1058, batch loss: 1.72028, batch accuracy: 0.53200
Time: 2018-07-15 08:42:46
TRAINING STATS: batch 312/486 in epoch 1058, batch loss: 1.68167, batch accuracy: 0.53950
Time: 2018-07-15 08:42:50
TRAINING STATS: batch 362/486 in epoch 1058, batch loss: 1.69322, batch accuracy: 0.54933
Time: 2018-07-15 08:42:55
TRAINING STATS: batch 412/486 in epoch 1058, batch loss: 1.61551, batch accuracy: 0.57150
Time: 2018-07-15 08:42:58
TRAINING STATS: batch 462/486 in epoch 1058, batch loss: 1.69636, batch accuracy: 0.54433
Time: 2018-07-15 08:43:02
TRAINING STATS: batch 26/486 in epoch 1059,  batch loss: 1.71624, batch accuracy: 0.54033
Time: 2018-07-15 08:43:07
TRAINING STATS: batch 76/486 in epoch 1059,  batch loss: 1.72409, batch accuracy: 0.53467
Time: 2018-07-15 08:43:10
TRAINING STATS: batch 126/486 in epoch 1059, batch loss: 1.73509, batch accuracy: 0.53067
Time: 2018-07-15 08:43:14
TRAINING STATS: batch 176/486 in epoch 1059, batch loss: 1.60954, batch accuracy: 0.56383
Time: 2018-07-15 08:43:19
TRAINING STATS: batch 226/486 in epoch 1059, batch loss: 1.67364, batch accuracy: 0.55450
Time: 2018-07-15 08:43:22
TRAINING STATS: batch 276/486 in epoch 1059, batch loss: 1.68918, batch accuracy: 0.54850
Time: 2018-07-15 08:43:26
TRAINING STATS: batch 326/486 in epoch 1059, batch loss: 1.70589, batch accuracy: 0.53983
Time: 2018-07-15 08:43:31
TRAINING STATS: batch 376/486 in epoch 1059, batch loss: 1.72658, batch accuracy: 0.53783
Time: 2018-07-15 08:43:35
TRAINING STATS: batch 426/486 in epoch 1059, batch loss: 1.65248, batch accuracy: 0.54633
Time: 2018-07-15 08:43:38
TRAINING STATS: batch 476/486 in epoch 1059, batch loss: 1.61787, batch accuracy: 0.56550
Time: 2018-07-15 08:43:43
TRAINING STATS: batch 40/486 in epoch 1060,  batch loss: 1.63676, batch accuracy: 0.56050
Time: 2018-07-15 08:43:47
TRAINING STATS: batch 90/486 in epoch 1060,  batch loss: 1.71407, batch accuracy: 0.54017
Time: 2018-07-15 08:43:50
TRAINING STATS: batch 140/486 in epoch 1060, batch loss: 1.60585, batch accuracy: 0.56850
Time: 2018-07-15 08:43:55
TRAINING STATS: batch 190/486 in epoch 1060, batch loss: 1.65141, batch accuracy: 0.55883
Time: 2018-07-15 08:43:59
TRAINING STATS: batch 240/486 in epoch 1060, batch loss: 1.63962, batch accuracy: 0.55317
Time: 2018-07-15 08:44:02
TRAINING STATS: batch 290/486 in epoch 1060, batch loss: 1.71073, batch accuracy: 0.53583
Time: 2018-07-15 08:44:07
TRAINING STATS: batch 340/486 in epoch 1060, batch loss: 1.78691, batch accuracy: 0.51383
Time: 2018-07-15 08:44:11
TRAINING STATS: batch 390/486 in epoch 1060, batch loss: 1.61681, batch accuracy: 0.56467
Time: 2018-07-15 08:44:15
TRAINING STATS: batch 440/486 in epoch 1060, batch loss: 1.67402, batch accuracy: 0.55133
Time: 2018-07-15 08:44:19
TRAINING STATS: batch 4/486 in epoch 1061,   batch loss: 1.63053, batch accuracy: 0.56450
Time: 2018-07-15 08:44:23
TRAINING STATS: batch 54/486 in epoch 1061,  batch loss: 1.67751, batch accuracy: 0.54417
Time: 2018-07-15 08:44:27
TRAINING STATS: batch 104/486 in epoch 1061, batch loss: 1.70590, batch accuracy: 0.53517
Time: 2018-07-15 08:44:31
TRAINING STATS: batch 154/486 in epoch 1061, batch loss: 1.67064, batch accuracy: 0.55267
Time: 2018-07-15 08:44:35
TRAINING STATS: batch 204/486 in epoch 1061, batch loss: 1.73857, batch accuracy: 0.53100
Time: 2018-07-15 08:44:39
TRAINING STATS: batch 254/486 in epoch 1061, batch loss: 1.59272, batch accuracy: 0.57033
Time: 2018-07-15 08:44:43
TRAINING STATS: batch 304/486 in epoch 1061, batch loss: 1.61986, batch accuracy: 0.56600
Time: 2018-07-15 08:44:47
TRAINING STATS: batch 354/486 in epoch 1061, batch loss: 1.69332, batch accuracy: 0.54333
Time: 2018-07-15 08:44:51
TRAINING STATS: batch 404/486 in epoch 1061, batch loss: 1.69169, batch accuracy: 0.54067
Time: 2018-07-15 08:44:56
TRAINING STATS: batch 454/486 in epoch 1061, batch loss: 1.53843, batch accuracy: 0.58467
Time: 2018-07-15 08:44:59
TRAINING STATS: batch 18/486 in epoch 1062,  batch loss: 1.69856, batch accuracy: 0.54650
Time: 2018-07-15 08:45:03
TRAINING STATS: batch 68/486 in epoch 1062,  batch loss: 1.52687, batch accuracy: 0.59083
Time: 2018-07-15 08:45:08
TRAINING STATS: batch 118/486 in epoch 1062, batch loss: 1.67579, batch accuracy: 0.54600
Time: 2018-07-15 08:45:11
TRAINING STATS: batch 168/486 in epoch 1062, batch loss: 1.58986, batch accuracy: 0.57767
Time: 2018-07-15 08:45:15
TRAINING STATS: batch 218/486 in epoch 1062, batch loss: 1.64435, batch accuracy: 0.55717
Time: 2018-07-15 08:45:20
TRAINING STATS: batch 268/486 in epoch 1062, batch loss: 1.61998, batch accuracy: 0.55983
Time: 2018-07-15 08:45:23
TRAINING STATS: batch 318/486 in epoch 1062, batch loss: 1.67185, batch accuracy: 0.54667
Time: 2018-07-15 08:45:27
TRAINING STATS: batch 368/486 in epoch 1062, batch loss: 1.69093, batch accuracy: 0.53750
Time: 2018-07-15 08:45:32
TRAINING STATS: batch 418/486 in epoch 1062, batch loss: 1.73094, batch accuracy: 0.52717
Time: 2018-07-15 08:45:36
TRAINING STATS: batch 468/486 in epoch 1062, batch loss: 1.68347, batch accuracy: 0.55283
Time: 2018-07-15 08:45:39
TRAINING STATS: batch 32/486 in epoch 1063,  batch loss: 1.61534, batch accuracy: 0.56467
Time: 2018-07-15 08:45:44
TRAINING STATS: batch 82/486 in epoch 1063,  batch loss: 1.70488, batch accuracy: 0.54183
Time: 2018-07-15 08:45:48
TRAINING STATS: batch 132/486 in epoch 1063, batch loss: 1.65054, batch accuracy: 0.55617
Time: 2018-07-15 08:45:51
TRAINING STATS: batch 182/486 in epoch 1063, batch loss: 1.72096, batch accuracy: 0.53233
Time: 2018-07-15 08:45:56
TRAINING STATS: batch 232/486 in epoch 1063, batch loss: 1.70271, batch accuracy: 0.54167
Time: 2018-07-15 08:46:00
TRAINING STATS: batch 282/486 in epoch 1063, batch loss: 1.62822, batch accuracy: 0.56100
Time: 2018-07-15 08:46:03
TRAINING STATS: batch 332/486 in epoch 1063, batch loss: 1.70379, batch accuracy: 0.54233
Time: 2018-07-15 08:46:08
TRAINING STATS: batch 382/486 in epoch 1063, batch loss: 1.69174, batch accuracy: 0.54283
Time: 2018-07-15 08:46:12
TRAINING STATS: batch 432/486 in epoch 1063, batch loss: 1.59518, batch accuracy: 0.57050
Time: 2018-07-15 08:46:16
TRAINING STATS: batch 482/486 in epoch 1063, batch loss: 1.65145, batch accuracy: 0.56117
Time: 2018-07-15 08:46:20
TRAINING STATS: batch 46/486 in epoch 1064,  batch loss: 1.63564, batch accuracy: 0.56583
Time: 2018-07-15 08:46:24
TRAINING STATS: batch 96/486 in epoch 1064,  batch loss: 1.72714, batch accuracy: 0.54317
Time: 2018-07-15 08:46:28
TRAINING STATS: batch 146/486 in epoch 1064, batch loss: 1.71200, batch accuracy: 0.54733
Time: 2018-07-15 08:46:32
TRAINING STATS: batch 196/486 in epoch 1064, batch loss: 1.71511, batch accuracy: 0.54050
Time: 2018-07-15 08:46:36
TRAINING STATS: batch 246/486 in epoch 1064, batch loss: 1.63323, batch accuracy: 0.55550
Time: 2018-07-15 08:46:40
TRAINING STATS: batch 296/486 in epoch 1064, batch loss: 1.65064, batch accuracy: 0.55483
Time: 2018-07-15 08:46:44
TRAINING STATS: batch 346/486 in epoch 1064, batch loss: 1.59919, batch accuracy: 0.56783
Time: 2018-07-15 08:46:48
TRAINING STATS: batch 396/486 in epoch 1064, batch loss: 1.65984, batch accuracy: 0.56417
Time: 2018-07-15 08:46:52
TRAINING STATS: batch 446/486 in epoch 1064, batch loss: 1.67979, batch accuracy: 0.54817
Time: 2018-07-15 08:46:57
TRAINING STATS: batch 10/486 in epoch 1065,  batch loss: 1.71343, batch accuracy: 0.53100
Time: 2018-07-15 08:47:00
TRAINING STATS: batch 60/486 in epoch 1065,  batch loss: 1.65192, batch accuracy: 0.55467
Time: 2018-07-15 08:47:04
TRAINING STATS: batch 110/486 in epoch 1065, batch loss: 1.73506, batch accuracy: 0.53200
Time: 2018-07-15 08:47:09
TRAINING STATS: batch 160/486 in epoch 1065, batch loss: 1.65226, batch accuracy: 0.55700
Time: 2018-07-15 08:47:12
TRAINING STATS: batch 210/486 in epoch 1065, batch loss: 1.61470, batch accuracy: 0.56850
Time: 2018-07-15 08:47:16
TRAINING STATS: batch 260/486 in epoch 1065, batch loss: 1.69548, batch accuracy: 0.54267
Time: 2018-07-15 08:47:21
TRAINING STATS: batch 310/486 in epoch 1065, batch loss: 1.67029, batch accuracy: 0.54800
Time: 2018-07-15 08:47:25
TRAINING STATS: batch 360/486 in epoch 1065, batch loss: 1.71703, batch accuracy: 0.53383
Time: 2018-07-15 08:47:28
TRAINING STATS: batch 410/486 in epoch 1065, batch loss: 1.59955, batch accuracy: 0.57200
Time: 2018-07-15 08:47:33
TRAINING STATS: batch 460/486 in epoch 1065, batch loss: 1.77801, batch accuracy: 0.51450
Time: 2018-07-15 08:47:37
TRAINING STATS: batch 24/486 in epoch 1066,  batch loss: 1.73501, batch accuracy: 0.53500
Time: 2018-07-15 08:47:40
TRAINING STATS: batch 74/486 in epoch 1066,  batch loss: 1.68179, batch accuracy: 0.54900
Time: 2018-07-15 08:47:45
TRAINING STATS: batch 124/486 in epoch 1066, batch loss: 1.69760, batch accuracy: 0.55267
Time: 2018-07-15 08:47:49
TRAINING STATS: batch 174/486 in epoch 1066, batch loss: 1.77102, batch accuracy: 0.52267
Time: 2018-07-15 08:47:52
TRAINING STATS: batch 224/486 in epoch 1066, batch loss: 1.68985, batch accuracy: 0.54483
Time: 2018-07-15 08:47:57
TRAINING STATS: batch 274/486 in epoch 1066, batch loss: 1.67909, batch accuracy: 0.55133
Time: 2018-07-15 08:48:01
TRAINING STATS: batch 324/486 in epoch 1066, batch loss: 1.70755, batch accuracy: 0.53817
Time: 2018-07-15 08:48:05
TRAINING STATS: batch 374/486 in epoch 1066, batch loss: 1.75209, batch accuracy: 0.52750
Time: 2018-07-15 08:48:09
TRAINING STATS: batch 424/486 in epoch 1066, batch loss: 1.61067, batch accuracy: 0.56367
Time: 2018-07-15 08:48:13
TRAINING STATS: batch 474/486 in epoch 1066, batch loss: 1.66811, batch accuracy: 0.54850
Time: 2018-07-15 08:48:17
TRAINING STATS: batch 38/486 in epoch 1067,  batch loss: 1.70914, batch accuracy: 0.53850
Time: 2018-07-15 08:48:21
TRAINING STATS: batch 88/486 in epoch 1067,  batch loss: 1.73386, batch accuracy: 0.53467
Time: 2018-07-15 08:48:25
TRAINING STATS: batch 138/486 in epoch 1067, batch loss: 1.73596, batch accuracy: 0.52400
Time: 2018-07-15 08:48:29
TRAINING STATS: batch 188/486 in epoch 1067, batch loss: 1.62698, batch accuracy: 0.56033
Time: 2018-07-15 08:48:34
TRAINING STATS: batch 238/486 in epoch 1067, batch loss: 1.65346, batch accuracy: 0.55717
Time: 2018-07-15 08:48:37
TRAINING STATS: batch 288/486 in epoch 1067, batch loss: 1.71882, batch accuracy: 0.53167
Time: 2018-07-15 08:48:41
TRAINING STATS: batch 338/486 in epoch 1067, batch loss: 1.68100, batch accuracy: 0.54117
Time: 2018-07-15 08:48:46
TRAINING STATS: batch 388/486 in epoch 1067, batch loss: 1.66454, batch accuracy: 0.55200
Time: 2018-07-15 08:48:49
TRAINING STATS: batch 438/486 in epoch 1067, batch loss: 1.68433, batch accuracy: 0.54367
Time: 2018-07-15 08:48:53
TRAINING STATS: batch 2/486 in epoch 1068,   batch loss: 1.68590, batch accuracy: 0.54783
Time: 2018-07-15 08:48:58
TRAINING STATS: batch 52/486 in epoch 1068,  batch loss: 1.74338, batch accuracy: 0.52533
Time: 2018-07-15 08:49:01
TRAINING STATS: batch 102/486 in epoch 1068, batch loss: 1.71038, batch accuracy: 0.54450
Time: 2018-07-15 08:49:05
TRAINING STATS: batch 152/486 in epoch 1068, batch loss: 1.63122, batch accuracy: 0.56050
Time: 2018-07-15 08:49:10
TRAINING STATS: batch 202/486 in epoch 1068, batch loss: 1.68859, batch accuracy: 0.54933
Time: 2018-07-15 08:49:13
TRAINING STATS: batch 252/486 in epoch 1068, batch loss: 1.63798, batch accuracy: 0.56133
Time: 2018-07-15 08:49:17
TRAINING STATS: batch 302/486 in epoch 1068, batch loss: 1.63035, batch accuracy: 0.56283
Time: 2018-07-15 08:49:22
TRAINING STATS: batch 352/486 in epoch 1068, batch loss: 1.65631, batch accuracy: 0.55800
Time: 2018-07-15 08:49:26
TRAINING STATS: batch 402/486 in epoch 1068, batch loss: 1.54163, batch accuracy: 0.59617
Time: 2018-07-15 08:49:29
TRAINING STATS: batch 452/486 in epoch 1068, batch loss: 1.69316, batch accuracy: 0.54733
Time: 2018-07-15 08:49:34
TRAINING STATS: batch 16/486 in epoch 1069,  batch loss: 1.65089, batch accuracy: 0.55850
Time: 2018-07-15 08:49:38
TRAINING STATS: batch 66/486 in epoch 1069,  batch loss: 1.67288, batch accuracy: 0.55683
Time: 2018-07-15 08:49:42
TRAINING STATS: batch 116/486 in epoch 1069, batch loss: 1.63301, batch accuracy: 0.55700
Time: 2018-07-15 08:49:46
TRAINING STATS: batch 166/486 in epoch 1069, batch loss: 1.59267, batch accuracy: 0.57917
Time: 2018-07-15 08:49:50
TRAINING STATS: batch 216/486 in epoch 1069, batch loss: 1.67707, batch accuracy: 0.54717
Time: 2018-07-15 08:49:54
TRAINING STATS: batch 266/486 in epoch 1069, batch loss: 1.66535, batch accuracy: 0.54733
Time: 2018-07-15 08:49:58
TRAINING STATS: batch 316/486 in epoch 1069, batch loss: 1.66695, batch accuracy: 0.54917
Time: 2018-07-15 08:50:02
TRAINING STATS: batch 366/486 in epoch 1069, batch loss: 1.72573, batch accuracy: 0.53650
Time: 2018-07-15 08:50:06
TRAINING STATS: batch 416/486 in epoch 1069, batch loss: 1.69946, batch accuracy: 0.54167
Time: 2018-07-15 08:50:10
TRAINING STATS: batch 466/486 in epoch 1069, batch loss: 1.53097, batch accuracy: 0.58700
Time: 2018-07-15 08:50:14
TRAINING STATS: batch 30/486 in epoch 1070,  batch loss: 1.56262, batch accuracy: 0.57933
Time: 2018-07-15 08:50:18
TRAINING STATS: batch 80/486 in epoch 1070,  batch loss: 1.66689, batch accuracy: 0.54383
Time: 2018-07-15 08:50:23
TRAINING STATS: batch 130/486 in epoch 1070, batch loss: 1.64856, batch accuracy: 0.56483
Time: 2018-07-15 08:50:26
TRAINING STATS: batch 180/486 in epoch 1070, batch loss: 1.71348, batch accuracy: 0.54183
Time: 2018-07-15 08:50:30
TRAINING STATS: batch 230/486 in epoch 1070, batch loss: 1.68878, batch accuracy: 0.54983
Time: 2018-07-15 08:50:35
TRAINING STATS: batch 280/486 in epoch 1070, batch loss: 1.65794, batch accuracy: 0.54850
Time: 2018-07-15 08:50:38
TRAINING STATS: batch 330/486 in epoch 1070, batch loss: 1.63531, batch accuracy: 0.55550
Time: 2018-07-15 08:50:42
TRAINING STATS: batch 380/486 in epoch 1070, batch loss: 1.64987, batch accuracy: 0.55817
Time: 2018-07-15 08:50:47
TRAINING STATS: batch 430/486 in epoch 1070, batch loss: 1.62558, batch accuracy: 0.56717
Time: 2018-07-15 08:50:50
TRAINING STATS: batch 480/486 in epoch 1070, batch loss: 1.67979, batch accuracy: 0.54283
Time: 2018-07-15 08:50:54
TRAINING STATS: batch 44/486 in epoch 1071,  batch loss: 1.61579, batch accuracy: 0.56517
Time: 2018-07-15 08:50:59
TRAINING STATS: batch 94/486 in epoch 1071,  batch loss: 1.72066, batch accuracy: 0.53317
Time: 2018-07-15 08:51:02
TRAINING STATS: batch 144/486 in epoch 1071, batch loss: 1.72734, batch accuracy: 0.53117
Time: 2018-07-15 08:51:06
TRAINING STATS: batch 194/486 in epoch 1071, batch loss: 1.76852, batch accuracy: 0.51217
Time: 2018-07-15 08:51:11
TRAINING STATS: batch 244/486 in epoch 1071, batch loss: 1.64854, batch accuracy: 0.55883
Time: 2018-07-15 08:51:15
TRAINING STATS: batch 294/486 in epoch 1071, batch loss: 1.59486, batch accuracy: 0.56950
Time: 2018-07-15 08:51:18
TRAINING STATS: batch 344/486 in epoch 1071, batch loss: 1.65495, batch accuracy: 0.55483
Time: 2018-07-15 08:51:23
TRAINING STATS: batch 394/486 in epoch 1071, batch loss: 1.64007, batch accuracy: 0.55333
Time: 2018-07-15 08:51:27
TRAINING STATS: batch 444/486 in epoch 1071, batch loss: 1.61084, batch accuracy: 0.56883
Time: 2018-07-15 08:51:30
TRAINING STATS: batch 8/486 in epoch 1072,   batch loss: 1.68171, batch accuracy: 0.54467
Time: 2018-07-15 08:51:35
TRAINING STATS: batch 58/486 in epoch 1072,  batch loss: 1.62495, batch accuracy: 0.56633
Time: 2018-07-15 08:51:39
TRAINING STATS: batch 108/486 in epoch 1072, batch loss: 1.85549, batch accuracy: 0.49883
Time: 2018-07-15 08:51:43
TRAINING STATS: batch 158/486 in epoch 1072, batch loss: 1.73495, batch accuracy: 0.53483
Time: 2018-07-15 08:51:47
TRAINING STATS: batch 208/486 in epoch 1072, batch loss: 1.69176, batch accuracy: 0.54133
Time: 2018-07-15 08:51:51
TRAINING STATS: batch 258/486 in epoch 1072, batch loss: 1.64700, batch accuracy: 0.56500
Time: 2018-07-15 08:51:55
TRAINING STATS: batch 308/486 in epoch 1072, batch loss: 1.68849, batch accuracy: 0.55017
Time: 2018-07-15 08:51:59
TRAINING STATS: batch 358/486 in epoch 1072, batch loss: 1.71887, batch accuracy: 0.53683
Time: 2018-07-15 08:52:03
TRAINING STATS: batch 408/486 in epoch 1072, batch loss: 1.71229, batch accuracy: 0.53217
Time: 2018-07-15 08:52:07
TRAINING STATS: batch 458/486 in epoch 1072, batch loss: 1.69229, batch accuracy: 0.54433
Time: 2018-07-15 08:52:11
TRAINING STATS: batch 22/486 in epoch 1073,  batch loss: 1.72064, batch accuracy: 0.54183
Time: 2018-07-15 08:52:15
TRAINING STATS: batch 72/486 in epoch 1073,  batch loss: 1.69715, batch accuracy: 0.53417
Time: 2018-07-15 08:52:19
TRAINING STATS: batch 122/486 in epoch 1073, batch loss: 1.61480, batch accuracy: 0.55967
Time: 2018-07-15 08:52:24
TRAINING STATS: batch 172/486 in epoch 1073, batch loss: 1.71802, batch accuracy: 0.52933
Time: 2018-07-15 08:52:27
TRAINING STATS: batch 222/486 in epoch 1073, batch loss: 1.67421, batch accuracy: 0.54300
Time: 2018-07-15 08:52:31
TRAINING STATS: batch 272/486 in epoch 1073, batch loss: 1.70567, batch accuracy: 0.54100
Time: 2018-07-15 08:52:36
TRAINING STATS: batch 322/486 in epoch 1073, batch loss: 1.66353, batch accuracy: 0.54050
Time: 2018-07-15 08:52:39
TRAINING STATS: batch 372/486 in epoch 1073, batch loss: 1.62960, batch accuracy: 0.55450
Time: 2018-07-15 08:52:43
TRAINING STATS: batch 422/486 in epoch 1073, batch loss: 1.68905, batch accuracy: 0.53550
Time: 2018-07-15 08:52:48
TRAINING STATS: batch 472/486 in epoch 1073, batch loss: 1.73532, batch accuracy: 0.53117
Time: 2018-07-15 08:52:51
TRAINING STATS: batch 36/486 in epoch 1074,  batch loss: 1.72800, batch accuracy: 0.53233
Time: 2018-07-15 08:52:55
TRAINING STATS: batch 86/486 in epoch 1074,  batch loss: 1.68054, batch accuracy: 0.55150
Time: 2018-07-15 08:53:00
TRAINING STATS: batch 136/486 in epoch 1074, batch loss: 1.72469, batch accuracy: 0.53417
Time: 2018-07-15 08:53:04
TRAINING STATS: batch 186/486 in epoch 1074, batch loss: 1.68271, batch accuracy: 0.55383
Time: 2018-07-15 08:53:07
TRAINING STATS: batch 236/486 in epoch 1074, batch loss: 1.70831, batch accuracy: 0.54367
Time: 2018-07-15 08:53:12
TRAINING STATS: batch 286/486 in epoch 1074, batch loss: 1.71214, batch accuracy: 0.54017
Time: 2018-07-15 08:53:16
TRAINING STATS: batch 336/486 in epoch 1074, batch loss: 1.65981, batch accuracy: 0.54783
Time: 2018-07-15 08:53:19
TRAINING STATS: batch 386/486 in epoch 1074, batch loss: 1.71720, batch accuracy: 0.53483
Time: 2018-07-15 08:53:24
TRAINING STATS: batch 436/486 in epoch 1074, batch loss: 1.69317, batch accuracy: 0.54167
Time: 2018-07-15 08:53:28
TRAINING STATS: batch 0/486 in epoch 1075,   batch loss: 1.66800, batch accuracy: 0.54883
Time: 2018-07-15 08:53:31
TRAINING STATS: batch 50/486 in epoch 1075,  batch loss: 1.69974, batch accuracy: 0.54600
Time: 2018-07-15 08:53:36
TRAINING STATS: batch 100/486 in epoch 1075, batch loss: 1.69817, batch accuracy: 0.54283
Time: 2018-07-15 08:53:40
TRAINING STATS: batch 150/486 in epoch 1075, batch loss: 1.63541, batch accuracy: 0.56533
Time: 2018-07-15 08:53:44
TRAINING STATS: batch 200/486 in epoch 1075, batch loss: 1.55225, batch accuracy: 0.58400
Time: 2018-07-15 08:53:48
TRAINING STATS: batch 250/486 in epoch 1075, batch loss: 1.74869, batch accuracy: 0.52217
Time: 2018-07-15 08:53:52
TRAINING STATS: batch 300/486 in epoch 1075, batch loss: 1.71503, batch accuracy: 0.53783
Time: 2018-07-15 08:53:56
TRAINING STATS: batch 350/486 in epoch 1075, batch loss: 1.70100, batch accuracy: 0.54367
Time: 2018-07-15 08:54:00
TRAINING STATS: batch 400/486 in epoch 1075, batch loss: 1.58078, batch accuracy: 0.57167
Time: 2018-07-15 08:54:04
TRAINING STATS: batch 450/486 in epoch 1075, batch loss: 1.74611, batch accuracy: 0.52817
Time: 2018-07-15 08:54:08
TRAINING STATS: batch 14/486 in epoch 1076,  batch loss: 1.59739, batch accuracy: 0.57067
Time: 2018-07-15 08:54:12
TRAINING STATS: batch 64/486 in epoch 1076,  batch loss: 1.76723, batch accuracy: 0.52750
Time: 2018-07-15 08:54:16
TRAINING STATS: batch 114/486 in epoch 1076, batch loss: 1.71412, batch accuracy: 0.54150
Time: 2018-07-15 08:54:20
TRAINING STATS: batch 164/486 in epoch 1076, batch loss: 1.62020, batch accuracy: 0.57217
Time: 2018-07-15 08:54:25
TRAINING STATS: batch 214/486 in epoch 1076, batch loss: 1.66836, batch accuracy: 0.54667
Time: 2018-07-15 08:54:28
TRAINING STATS: batch 264/486 in epoch 1076, batch loss: 1.72481, batch accuracy: 0.52300
Time: 2018-07-15 08:54:32
TRAINING STATS: batch 314/486 in epoch 1076, batch loss: 1.76320, batch accuracy: 0.51950
Time: 2018-07-15 08:54:37
TRAINING STATS: batch 364/486 in epoch 1076, batch loss: 1.67127, batch accuracy: 0.55350
Time: 2018-07-15 08:54:40
TRAINING STATS: batch 414/486 in epoch 1076, batch loss: 1.61399, batch accuracy: 0.56383
Time: 2018-07-15 08:54:44
TRAINING STATS: batch 464/486 in epoch 1076, batch loss: 1.68713, batch accuracy: 0.54433
Time: 2018-07-15 08:54:49
TRAINING STATS: batch 28/486 in epoch 1077,  batch loss: 1.59817, batch accuracy: 0.57150
Time: 2018-07-15 08:54:52
TRAINING STATS: batch 78/486 in epoch 1077,  batch loss: 1.67891, batch accuracy: 0.55000
Time: 2018-07-15 08:54:56
TRAINING STATS: batch 128/486 in epoch 1077, batch loss: 1.67317, batch accuracy: 0.55333
Time: 2018-07-15 08:55:01
TRAINING STATS: batch 178/486 in epoch 1077, batch loss: 1.57397, batch accuracy: 0.57517
Time: 2018-07-15 08:55:05
TRAINING STATS: batch 228/486 in epoch 1077, batch loss: 1.63620, batch accuracy: 0.56050
Time: 2018-07-15 08:55:08
TRAINING STATS: batch 278/486 in epoch 1077, batch loss: 1.60913, batch accuracy: 0.56367
Time: 2018-07-15 08:55:13
TRAINING STATS: batch 328/486 in epoch 1077, batch loss: 1.65954, batch accuracy: 0.55517
Time: 2018-07-15 08:55:17
TRAINING STATS: batch 378/486 in epoch 1077, batch loss: 1.66477, batch accuracy: 0.55850
Time: 2018-07-15 08:55:20
TRAINING STATS: batch 428/486 in epoch 1077, batch loss: 1.76515, batch accuracy: 0.52067
Time: 2018-07-15 08:55:25
TRAINING STATS: batch 478/486 in epoch 1077, batch loss: 1.69303, batch accuracy: 0.54183
Time: 2018-07-15 08:55:29
TRAINING STATS: batch 42/486 in epoch 1078,  batch loss: 1.58938, batch accuracy: 0.57617
Time: 2018-07-15 08:55:33
TRAINING STATS: batch 92/486 in epoch 1078,  batch loss: 1.66727, batch accuracy: 0.54783
Time: 2018-07-15 08:55:37
TRAINING STATS: batch 142/486 in epoch 1078, batch loss: 1.63807, batch accuracy: 0.55733
Time: 2018-07-15 08:55:41
TRAINING STATS: batch 192/486 in epoch 1078, batch loss: 1.67081, batch accuracy: 0.54400
Time: 2018-07-15 08:55:45
TRAINING STATS: batch 242/486 in epoch 1078, batch loss: 1.63383, batch accuracy: 0.55817
Time: 2018-07-15 08:55:49
TRAINING STATS: batch 292/486 in epoch 1078, batch loss: 1.66179, batch accuracy: 0.55067
Time: 2018-07-15 08:55:53
TRAINING STATS: batch 342/486 in epoch 1078, batch loss: 1.62920, batch accuracy: 0.55983
Time: 2018-07-15 08:55:57
TRAINING STATS: batch 392/486 in epoch 1078, batch loss: 1.56882, batch accuracy: 0.57483
Time: 2018-07-15 08:56:01
TRAINING STATS: batch 442/486 in epoch 1078, batch loss: 1.57608, batch accuracy: 0.58083
Time: 2018-07-15 08:56:05
TRAINING STATS: batch 6/486 in epoch 1079,   batch loss: 1.70685, batch accuracy: 0.54050
Time: 2018-07-15 08:56:09
TRAINING STATS: batch 56/486 in epoch 1079,  batch loss: 1.63694, batch accuracy: 0.55933
Time: 2018-07-15 08:56:14
TRAINING STATS: batch 106/486 in epoch 1079, batch loss: 1.75278, batch accuracy: 0.52600
Time: 2018-07-15 08:56:17
TRAINING STATS: batch 156/486 in epoch 1079, batch loss: 1.71799, batch accuracy: 0.52567
Time: 2018-07-15 08:56:21
TRAINING STATS: batch 206/486 in epoch 1079, batch loss: 1.74965, batch accuracy: 0.52550
Time: 2018-07-15 08:56:26
TRAINING STATS: batch 256/486 in epoch 1079, batch loss: 1.62078, batch accuracy: 0.56250
Time: 2018-07-15 08:56:29
TRAINING STATS: batch 306/486 in epoch 1079, batch loss: 1.66611, batch accuracy: 0.54417
Time: 2018-07-15 08:56:33
TRAINING STATS: batch 356/486 in epoch 1079, batch loss: 1.71737, batch accuracy: 0.53333
Time: 2018-07-15 08:56:38
TRAINING STATS: batch 406/486 in epoch 1079, batch loss: 1.74984, batch accuracy: 0.52133
Time: 2018-07-15 08:56:42
TRAINING STATS: batch 456/486 in epoch 1079, batch loss: 1.55657, batch accuracy: 0.58633
Time: 2018-07-15 08:56:45
TRAINING STATS: batch 20/486 in epoch 1080,  batch loss: 1.66738, batch accuracy: 0.55117
Time: 2018-07-15 08:56:50
TRAINING STATS: batch 70/486 in epoch 1080,  batch loss: 1.55922, batch accuracy: 0.58417
Time: 2018-07-15 08:56:54
TRAINING STATS: batch 120/486 in epoch 1080, batch loss: 1.61532, batch accuracy: 0.56383
Time: 2018-07-15 08:56:57
TRAINING STATS: batch 170/486 in epoch 1080, batch loss: 1.64911, batch accuracy: 0.55717
Time: 2018-07-15 08:57:02
TRAINING STATS: batch 220/486 in epoch 1080, batch loss: 1.59816, batch accuracy: 0.56150
Time: 2018-07-15 08:57:06
TRAINING STATS: batch 270/486 in epoch 1080, batch loss: 1.69307, batch accuracy: 0.53233
Time: 2018-07-15 08:57:10
TRAINING STATS: batch 320/486 in epoch 1080, batch loss: 1.61468, batch accuracy: 0.56217
Time: 2018-07-15 08:57:14
TRAINING STATS: batch 370/486 in epoch 1080, batch loss: 1.67804, batch accuracy: 0.54833
Time: 2018-07-15 08:57:18
TRAINING STATS: batch 420/486 in epoch 1080, batch loss: 1.70262, batch accuracy: 0.53933
Time: 2018-07-15 08:57:22
TRAINING STATS: batch 470/486 in epoch 1080, batch loss: 1.74958, batch accuracy: 0.51617
Time: 2018-07-15 08:57:26
TRAINING STATS: batch 34/486 in epoch 1081,  batch loss: 1.67830, batch accuracy: 0.54467
Time: 2018-07-15 08:57:30
TRAINING STATS: batch 84/486 in epoch 1081,  batch loss: 1.68309, batch accuracy: 0.53533
Time: 2018-07-15 08:57:34
TRAINING STATS: batch 134/486 in epoch 1081, batch loss: 1.69856, batch accuracy: 0.54650
Time: 2018-07-15 08:57:38
TRAINING STATS: batch 184/486 in epoch 1081, batch loss: 1.70159, batch accuracy: 0.53600
Time: 2018-07-15 08:57:42
TRAINING STATS: batch 234/486 in epoch 1081, batch loss: 1.72918, batch accuracy: 0.52717
Time: 2018-07-15 08:57:46
TRAINING STATS: batch 284/486 in epoch 1081, batch loss: 1.74072, batch accuracy: 0.53067
Time: 2018-07-15 08:57:51
TRAINING STATS: batch 334/486 in epoch 1081, batch loss: 1.65300, batch accuracy: 0.55833
Time: 2018-07-15 08:57:54
TRAINING STATS: batch 384/486 in epoch 1081, batch loss: 1.62914, batch accuracy: 0.55300
Time: 2018-07-15 08:57:58
TRAINING STATS: batch 434/486 in epoch 1081, batch loss: 1.73409, batch accuracy: 0.52667
Time: 2018-07-15 08:58:03
TRAINING STATS: batch 484/486 in epoch 1081, batch loss: 1.68274, batch accuracy: 0.54100
Time: 2018-07-15 08:58:06
TRAINING STATS: batch 48/486 in epoch 1082,  batch loss: 1.66669, batch accuracy: 0.54717
Time: 2018-07-15 08:58:10
TRAINING STATS: batch 98/486 in epoch 1082,  batch loss: 1.64270, batch accuracy: 0.56033
Time: 2018-07-15 08:58:15
TRAINING STATS: batch 148/486 in epoch 1082, batch loss: 1.70513, batch accuracy: 0.54600
Time: 2018-07-15 08:58:18
TRAINING STATS: batch 198/486 in epoch 1082, batch loss: 1.67087, batch accuracy: 0.55300
Time: 2018-07-15 08:58:22
TRAINING STATS: batch 248/486 in epoch 1082, batch loss: 1.72163, batch accuracy: 0.53250
Time: 2018-07-15 08:58:27
TRAINING STATS: batch 298/486 in epoch 1082, batch loss: 1.69613, batch accuracy: 0.53750
Time: 2018-07-15 08:58:31
TRAINING STATS: batch 348/486 in epoch 1082, batch loss: 1.67723, batch accuracy: 0.54933
Time: 2018-07-15 08:58:34
TRAINING STATS: batch 398/486 in epoch 1082, batch loss: 1.69422, batch accuracy: 0.53850
Time: 2018-07-15 08:58:39
TRAINING STATS: batch 448/486 in epoch 1082, batch loss: 1.65215, batch accuracy: 0.55433
Time: 2018-07-15 08:58:43
TRAINING STATS: batch 12/486 in epoch 1083,  batch loss: 1.69030, batch accuracy: 0.54317
Time: 2018-07-15 08:58:46
TRAINING STATS: batch 62/486 in epoch 1083,  batch loss: 1.75926, batch accuracy: 0.52017
Time: 2018-07-15 08:58:51
TRAINING STATS: batch 112/486 in epoch 1083, batch loss: 1.66159, batch accuracy: 0.55333
Time: 2018-07-15 08:58:55
TRAINING STATS: batch 162/486 in epoch 1083, batch loss: 1.69119, batch accuracy: 0.55133
Time: 2018-07-15 08:58:58
TRAINING STATS: batch 212/486 in epoch 1083, batch loss: 1.57582, batch accuracy: 0.57450
Time: 2018-07-15 08:59:03
TRAINING STATS: batch 262/486 in epoch 1083, batch loss: 1.72838, batch accuracy: 0.52817
Time: 2018-07-15 08:59:07
TRAINING STATS: batch 312/486 in epoch 1083, batch loss: 1.66726, batch accuracy: 0.54467
Time: 2018-07-15 08:59:11
TRAINING STATS: batch 362/486 in epoch 1083, batch loss: 1.67673, batch accuracy: 0.54650
Time: 2018-07-15 08:59:15
TRAINING STATS: batch 412/486 in epoch 1083, batch loss: 1.61039, batch accuracy: 0.56567
Time: 2018-07-15 08:59:19
TRAINING STATS: batch 462/486 in epoch 1083, batch loss: 1.67827, batch accuracy: 0.54667
Time: 2018-07-15 08:59:23
TRAINING STATS: batch 26/486 in epoch 1084,  batch loss: 1.77528, batch accuracy: 0.52383
Time: 2018-07-15 08:59:27
TRAINING STATS: batch 76/486 in epoch 1084,  batch loss: 1.73480, batch accuracy: 0.52917
Time: 2018-07-15 08:59:31
TRAINING STATS: batch 126/486 in epoch 1084, batch loss: 1.72526, batch accuracy: 0.53033
Time: 2018-07-15 08:59:35
TRAINING STATS: batch 176/486 in epoch 1084, batch loss: 1.59739, batch accuracy: 0.57217
Time: 2018-07-15 08:59:39
TRAINING STATS: batch 226/486 in epoch 1084, batch loss: 1.66060, batch accuracy: 0.55683
Time: 2018-07-15 08:59:43
TRAINING STATS: batch 276/486 in epoch 1084, batch loss: 1.66590, batch accuracy: 0.55417
Time: 2018-07-15 08:59:47
TRAINING STATS: batch 326/486 in epoch 1084, batch loss: 1.70011, batch accuracy: 0.54400
Time: 2018-07-15 08:59:52
TRAINING STATS: batch 376/486 in epoch 1084, batch loss: 1.69361, batch accuracy: 0.54583
Time: 2018-07-15 08:59:55
TRAINING STATS: batch 426/486 in epoch 1084, batch loss: 1.66476, batch accuracy: 0.53683
Time: 2018-07-15 08:59:59
TRAINING STATS: batch 476/486 in epoch 1084, batch loss: 1.62275, batch accuracy: 0.56283
Time: 2018-07-15 09:00:04
TRAINING STATS: batch 40/486 in epoch 1085,  batch loss: 1.64552, batch accuracy: 0.55850
Time: 2018-07-15 09:00:07
TRAINING STATS: batch 90/486 in epoch 1085,  batch loss: 1.71875, batch accuracy: 0.53650
Time: 2018-07-15 09:00:11
TRAINING STATS: batch 140/486 in epoch 1085, batch loss: 1.62195, batch accuracy: 0.56150
Time: 2018-07-15 09:00:16
TRAINING STATS: batch 190/486 in epoch 1085, batch loss: 1.66217, batch accuracy: 0.55167
Time: 2018-07-15 09:00:19
TRAINING STATS: batch 240/486 in epoch 1085, batch loss: 1.63941, batch accuracy: 0.54667
Time: 2018-07-15 09:00:23
TRAINING STATS: batch 290/486 in epoch 1085, batch loss: 1.69883, batch accuracy: 0.53333
Time: 2018-07-15 09:00:28
TRAINING STATS: batch 340/486 in epoch 1085, batch loss: 1.75017, batch accuracy: 0.52550
Time: 2018-07-15 09:00:32
TRAINING STATS: batch 390/486 in epoch 1085, batch loss: 1.60300, batch accuracy: 0.57183
Time: 2018-07-15 09:00:35
TRAINING STATS: batch 440/486 in epoch 1085, batch loss: 1.68664, batch accuracy: 0.54700
Time: 2018-07-15 09:00:40
TRAINING STATS: batch 4/486 in epoch 1086,   batch loss: 1.62577, batch accuracy: 0.56250
Time: 2018-07-15 09:00:44
TRAINING STATS: batch 54/486 in epoch 1086,  batch loss: 1.66944, batch accuracy: 0.54800
Time: 2018-07-15 09:00:47
TRAINING STATS: batch 104/486 in epoch 1086, batch loss: 1.68603, batch accuracy: 0.54767
Time: 2018-07-15 09:00:52
TRAINING STATS: batch 154/486 in epoch 1086, batch loss: 1.65406, batch accuracy: 0.55733
Time: 2018-07-15 09:00:56
TRAINING STATS: batch 204/486 in epoch 1086, batch loss: 1.75341, batch accuracy: 0.52767
Time: 2018-07-15 09:01:00
TRAINING STATS: batch 254/486 in epoch 1086, batch loss: 1.59953, batch accuracy: 0.56450
Time: 2018-07-15 09:01:04
TRAINING STATS: batch 304/486 in epoch 1086, batch loss: 1.61891, batch accuracy: 0.56650
Time: 2018-07-15 09:01:08
TRAINING STATS: batch 354/486 in epoch 1086, batch loss: 1.67781, batch accuracy: 0.54250
Time: 2018-07-15 09:01:12
TRAINING STATS: batch 404/486 in epoch 1086, batch loss: 1.80296, batch accuracy: 0.50650
Time: 2018-07-15 09:01:16
TRAINING STATS: batch 454/486 in epoch 1086, batch loss: 1.64184, batch accuracy: 0.55650
Time: 2018-07-15 09:01:20
TRAINING STATS: batch 18/486 in epoch 1087,  batch loss: 1.72282, batch accuracy: 0.54150
Time: 2018-07-15 09:01:24
TRAINING STATS: batch 68/486 in epoch 1087,  batch loss: 1.55129, batch accuracy: 0.58367
Time: 2018-07-15 09:01:29
TRAINING STATS: batch 118/486 in epoch 1087, batch loss: 1.67227, batch accuracy: 0.54767
Time: 2018-07-15 09:01:32
TRAINING STATS: batch 168/486 in epoch 1087, batch loss: 1.59729, batch accuracy: 0.57333
Time: 2018-07-15 09:01:36
TRAINING STATS: batch 218/486 in epoch 1087, batch loss: 1.66163, batch accuracy: 0.54900
Time: 2018-07-15 09:01:41
TRAINING STATS: batch 268/486 in epoch 1087, batch loss: 1.61152, batch accuracy: 0.55633
Time: 2018-07-15 09:01:44
TRAINING STATS: batch 318/486 in epoch 1087, batch loss: 1.65459, batch accuracy: 0.54817
Time: 2018-07-15 09:01:48
TRAINING STATS: batch 368/486 in epoch 1087, batch loss: 1.69053, batch accuracy: 0.54333
Time: 2018-07-15 09:01:53
TRAINING STATS: batch 418/486 in epoch 1087, batch loss: 1.72964, batch accuracy: 0.52950
Time: 2018-07-15 09:01:57
TRAINING STATS: batch 468/486 in epoch 1087, batch loss: 1.67573, batch accuracy: 0.54950
Time: 2018-07-15 09:02:00
TRAINING STATS: batch 32/486 in epoch 1088,  batch loss: 1.61797, batch accuracy: 0.55633
Time: 2018-07-15 09:02:05
TRAINING STATS: batch 82/486 in epoch 1088,  batch loss: 1.71249, batch accuracy: 0.53517
Time: 2018-07-15 09:02:08
TRAINING STATS: batch 132/486 in epoch 1088, batch loss: 1.64764, batch accuracy: 0.56083
Time: 2018-07-15 09:02:12
TRAINING STATS: batch 182/486 in epoch 1088, batch loss: 1.72806, batch accuracy: 0.52300
Time: 2018-07-15 09:02:17
TRAINING STATS: batch 232/486 in epoch 1088, batch loss: 1.69704, batch accuracy: 0.54133
Time: 2018-07-15 09:02:20
TRAINING STATS: batch 282/486 in epoch 1088, batch loss: 1.63653, batch accuracy: 0.56067
Time: 2018-07-15 09:02:24
TRAINING STATS: batch 332/486 in epoch 1088, batch loss: 1.70018, batch accuracy: 0.54350
Time: 2018-07-15 09:02:29
TRAINING STATS: batch 382/486 in epoch 1088, batch loss: 1.68464, batch accuracy: 0.54433
Time: 2018-07-15 09:02:33
TRAINING STATS: batch 432/486 in epoch 1088, batch loss: 1.61928, batch accuracy: 0.56400
Time: 2018-07-15 09:02:36
TRAINING STATS: batch 482/486 in epoch 1088, batch loss: 1.66511, batch accuracy: 0.54950
Time: 2018-07-15 09:02:41
TRAINING STATS: batch 46/486 in epoch 1089,  batch loss: 1.66487, batch accuracy: 0.54600
Time: 2018-07-15 09:02:45
TRAINING STATS: batch 96/486 in epoch 1089,  batch loss: 1.69606, batch accuracy: 0.53983
Time: 2018-07-15 09:02:48
TRAINING STATS: batch 146/486 in epoch 1089, batch loss: 1.71481, batch accuracy: 0.54217
Time: 2018-07-15 09:02:53
TRAINING STATS: batch 196/486 in epoch 1089, batch loss: 1.70842, batch accuracy: 0.53483
Time: 2018-07-15 09:02:57
TRAINING STATS: batch 246/486 in epoch 1089, batch loss: 1.63114, batch accuracy: 0.56083
Time: 2018-07-15 09:03:01
TRAINING STATS: batch 296/486 in epoch 1089, batch loss: 1.64359, batch accuracy: 0.54950
Time: 2018-07-15 09:03:05
TRAINING STATS: batch 346/486 in epoch 1089, batch loss: 1.58829, batch accuracy: 0.57317
Time: 2018-07-15 09:03:09
TRAINING STATS: batch 396/486 in epoch 1089, batch loss: 1.65216, batch accuracy: 0.55383
Time: 2018-07-15 09:03:13
TRAINING STATS: batch 446/486 in epoch 1089, batch loss: 1.67844, batch accuracy: 0.54500
Time: 2018-07-15 09:03:18
TRAINING STATS: batch 10/486 in epoch 1090,  batch loss: 1.70779, batch accuracy: 0.53250
Time: 2018-07-15 09:03:21
TRAINING STATS: batch 60/486 in epoch 1090,  batch loss: 1.66566, batch accuracy: 0.54850
Time: 2018-07-15 09:03:25
TRAINING STATS: batch 110/486 in epoch 1090, batch loss: 1.71983, batch accuracy: 0.53583
Time: 2018-07-15 09:03:30
TRAINING STATS: batch 160/486 in epoch 1090, batch loss: 1.63950, batch accuracy: 0.55117
Time: 2018-07-15 09:03:33
TRAINING STATS: batch 210/486 in epoch 1090, batch loss: 1.60994, batch accuracy: 0.56633
Time: 2018-07-15 09:03:37
TRAINING STATS: batch 260/486 in epoch 1090, batch loss: 1.69310, batch accuracy: 0.54333
Time: 2018-07-15 09:03:42
TRAINING STATS: batch 310/486 in epoch 1090, batch loss: 1.67458, batch accuracy: 0.54450
Time: 2018-07-15 09:03:45
TRAINING STATS: batch 360/486 in epoch 1090, batch loss: 1.70130, batch accuracy: 0.53583
Time: 2018-07-15 09:03:49
TRAINING STATS: batch 410/486 in epoch 1090, batch loss: 1.61300, batch accuracy: 0.56833
Time: 2018-07-15 09:03:54
TRAINING STATS: batch 460/486 in epoch 1090, batch loss: 1.78739, batch accuracy: 0.50850
Time: 2018-07-15 09:03:58
TRAINING STATS: batch 24/486 in epoch 1091,  batch loss: 1.72450, batch accuracy: 0.53717
Time: 2018-07-15 09:04:01
TRAINING STATS: batch 74/486 in epoch 1091,  batch loss: 1.69435, batch accuracy: 0.54433
Time: 2018-07-15 09:04:06
TRAINING STATS: batch 124/486 in epoch 1091, batch loss: 1.68356, batch accuracy: 0.55017
Time: 2018-07-15 09:04:10
TRAINING STATS: batch 174/486 in epoch 1091, batch loss: 1.74287, batch accuracy: 0.52600
Time: 2018-07-15 09:04:13
TRAINING STATS: batch 224/486 in epoch 1091, batch loss: 1.69045, batch accuracy: 0.54650
Time: 2018-07-15 09:04:18
TRAINING STATS: batch 274/486 in epoch 1091, batch loss: 1.67443, batch accuracy: 0.54517
Time: 2018-07-15 09:04:22
TRAINING STATS: batch 324/486 in epoch 1091, batch loss: 1.70031, batch accuracy: 0.54300
Time: 2018-07-15 09:04:26
TRAINING STATS: batch 374/486 in epoch 1091, batch loss: 1.72487, batch accuracy: 0.53900
Time: 2018-07-15 09:04:30
TRAINING STATS: batch 424/486 in epoch 1091, batch loss: 1.60769, batch accuracy: 0.56033
Time: 2018-07-15 09:04:34
TRAINING STATS: batch 474/486 in epoch 1091, batch loss: 1.67590, batch accuracy: 0.54817
Time: 2018-07-15 09:04:38
TRAINING STATS: batch 38/486 in epoch 1092,  batch loss: 1.69759, batch accuracy: 0.54500
Time: 2018-07-15 09:04:42
TRAINING STATS: batch 88/486 in epoch 1092,  batch loss: 1.80102, batch accuracy: 0.51500
Time: 2018-07-15 09:04:46
TRAINING STATS: batch 138/486 in epoch 1092, batch loss: 1.72442, batch accuracy: 0.53383
Time: 2018-07-15 09:04:50
TRAINING STATS: batch 188/486 in epoch 1092, batch loss: 1.65054, batch accuracy: 0.55683
Time: 2018-07-15 09:04:54
TRAINING STATS: batch 238/486 in epoch 1092, batch loss: 1.65387, batch accuracy: 0.56200
Time: 2018-07-15 09:04:58
TRAINING STATS: batch 288/486 in epoch 1092, batch loss: 1.71332, batch accuracy: 0.53150
Time: 2018-07-15 09:05:02
TRAINING STATS: batch 338/486 in epoch 1092, batch loss: 1.67100, batch accuracy: 0.53650
Time: 2018-07-15 09:05:07
TRAINING STATS: batch 388/486 in epoch 1092, batch loss: 1.63107, batch accuracy: 0.55867
Time: 2018-07-15 09:05:10
TRAINING STATS: batch 438/486 in epoch 1092, batch loss: 1.68519, batch accuracy: 0.54267
Time: 2018-07-15 09:05:14
TRAINING STATS: batch 2/486 in epoch 1093,   batch loss: 1.67412, batch accuracy: 0.54917
Time: 2018-07-15 09:05:19
TRAINING STATS: batch 52/486 in epoch 1093,  batch loss: 1.72897, batch accuracy: 0.52517
Time: 2018-07-15 09:05:22
TRAINING STATS: batch 102/486 in epoch 1093, batch loss: 1.70728, batch accuracy: 0.53900
Time: 2018-07-15 09:05:26
TRAINING STATS: batch 152/486 in epoch 1093, batch loss: 1.65817, batch accuracy: 0.54733
Time: 2018-07-15 09:05:31
TRAINING STATS: batch 202/486 in epoch 1093, batch loss: 1.66446, batch accuracy: 0.54700
Time: 2018-07-15 09:05:34
TRAINING STATS: batch 252/486 in epoch 1093, batch loss: 1.63416, batch accuracy: 0.56050
Time: 2018-07-15 09:05:38
TRAINING STATS: batch 302/486 in epoch 1093, batch loss: 1.63624, batch accuracy: 0.55367
Time: 2018-07-15 09:05:43
TRAINING STATS: batch 352/486 in epoch 1093, batch loss: 1.64665, batch accuracy: 0.55633
Time: 2018-07-15 09:05:47
TRAINING STATS: batch 402/486 in epoch 1093, batch loss: 1.51796, batch accuracy: 0.59067
Time: 2018-07-15 09:05:50
TRAINING STATS: batch 452/486 in epoch 1093, batch loss: 1.66568, batch accuracy: 0.54033
Time: 2018-07-15 09:05:55
TRAINING STATS: batch 16/486 in epoch 1094,  batch loss: 1.63431, batch accuracy: 0.55850
Time: 2018-07-15 09:05:58
TRAINING STATS: batch 66/486 in epoch 1094,  batch loss: 1.66479, batch accuracy: 0.55900
Time: 2018-07-15 09:06:02
TRAINING STATS: batch 116/486 in epoch 1094, batch loss: 1.62553, batch accuracy: 0.55833
Time: 2018-07-15 09:06:07
TRAINING STATS: batch 166/486 in epoch 1094, batch loss: 1.57521, batch accuracy: 0.58017
Time: 2018-07-15 09:06:10
TRAINING STATS: batch 216/486 in epoch 1094, batch loss: 1.68594, batch accuracy: 0.54750
Time: 2018-07-15 09:06:14
TRAINING STATS: batch 266/486 in epoch 1094, batch loss: 1.69251, batch accuracy: 0.54300
Time: 2018-07-15 09:06:19
TRAINING STATS: batch 316/486 in epoch 1094, batch loss: 1.66460, batch accuracy: 0.55150
Time: 2018-07-15 09:06:23
TRAINING STATS: batch 366/486 in epoch 1094, batch loss: 1.71448, batch accuracy: 0.54017
Time: 2018-07-15 09:06:26
TRAINING STATS: batch 416/486 in epoch 1094, batch loss: 1.70778, batch accuracy: 0.53333
Time: 2018-07-15 09:06:31
TRAINING STATS: batch 466/486 in epoch 1094, batch loss: 1.52572, batch accuracy: 0.58517
Time: 2018-07-15 09:06:35
TRAINING STATS: batch 30/486 in epoch 1095,  batch loss: 1.56180, batch accuracy: 0.57667
Time: 2018-07-15 09:06:39
TRAINING STATS: batch 80/486 in epoch 1095,  batch loss: 1.66196, batch accuracy: 0.55067
Time: 2018-07-15 09:06:43
TRAINING STATS: batch 130/486 in epoch 1095, batch loss: 1.64265, batch accuracy: 0.56433
Time: 2018-07-15 09:06:47
TRAINING STATS: batch 180/486 in epoch 1095, batch loss: 1.69401, batch accuracy: 0.54100
Time: 2018-07-15 09:06:51
TRAINING STATS: batch 230/486 in epoch 1095, batch loss: 1.69237, batch accuracy: 0.53817
Time: 2018-07-15 09:06:55
TRAINING STATS: batch 280/486 in epoch 1095, batch loss: 1.65428, batch accuracy: 0.54767
Time: 2018-07-15 09:06:59
TRAINING STATS: batch 330/486 in epoch 1095, batch loss: 1.63409, batch accuracy: 0.55317
Time: 2018-07-15 09:07:03
TRAINING STATS: batch 380/486 in epoch 1095, batch loss: 1.63130, batch accuracy: 0.55867
Time: 2018-07-15 09:07:07
TRAINING STATS: batch 430/486 in epoch 1095, batch loss: 1.61413, batch accuracy: 0.56750
Time: 2018-07-15 09:07:11
TRAINING STATS: batch 480/486 in epoch 1095, batch loss: 1.81518, batch accuracy: 0.51050
Time: 2018-07-15 09:07:15
TRAINING STATS: batch 44/486 in epoch 1096,  batch loss: 1.70114, batch accuracy: 0.54333
Time: 2018-07-15 09:07:19
TRAINING STATS: batch 94/486 in epoch 1096,  batch loss: 1.77892, batch accuracy: 0.52083
Time: 2018-07-15 09:07:23
TRAINING STATS: batch 144/486 in epoch 1096, batch loss: 1.75719, batch accuracy: 0.52417
Time: 2018-07-15 09:07:27
TRAINING STATS: batch 194/486 in epoch 1096, batch loss: 1.76940, batch accuracy: 0.51500
Time: 2018-07-15 09:07:31
TRAINING STATS: batch 244/486 in epoch 1096, batch loss: 1.65681, batch accuracy: 0.55067
Time: 2018-07-15 09:07:35
TRAINING STATS: batch 294/486 in epoch 1096, batch loss: 1.59052, batch accuracy: 0.56783
Time: 2018-07-15 09:07:39
TRAINING STATS: batch 344/486 in epoch 1096, batch loss: 1.65491, batch accuracy: 0.54983
Time: 2018-07-15 09:07:43
TRAINING STATS: batch 394/486 in epoch 1096, batch loss: 1.62607, batch accuracy: 0.56250
Time: 2018-07-15 09:07:47
TRAINING STATS: batch 444/486 in epoch 1096, batch loss: 1.60974, batch accuracy: 0.56633
Time: 2018-07-15 09:07:51
TRAINING STATS: batch 8/486 in epoch 1097,   batch loss: 1.64704, batch accuracy: 0.55433
Time: 2018-07-15 09:07:56
TRAINING STATS: batch 58/486 in epoch 1097,  batch loss: 1.64925, batch accuracy: 0.56200
Time: 2018-07-15 09:07:59
TRAINING STATS: batch 108/486 in epoch 1097, batch loss: 1.72898, batch accuracy: 0.53833
Time: 2018-07-15 09:08:03
TRAINING STATS: batch 158/486 in epoch 1097, batch loss: 1.71858, batch accuracy: 0.53733
Time: 2018-07-15 09:08:08
TRAINING STATS: batch 208/486 in epoch 1097, batch loss: 1.67439, batch accuracy: 0.54150
Time: 2018-07-15 09:08:11
TRAINING STATS: batch 258/486 in epoch 1097, batch loss: 1.61241, batch accuracy: 0.56400
Time: 2018-07-15 09:08:15
TRAINING STATS: batch 308/486 in epoch 1097, batch loss: 1.69015, batch accuracy: 0.55167
Time: 2018-07-15 09:08:20
TRAINING STATS: batch 358/486 in epoch 1097, batch loss: 1.80228, batch accuracy: 0.50417
Time: 2018-07-15 09:08:23
TRAINING STATS: batch 408/486 in epoch 1097, batch loss: 1.73033, batch accuracy: 0.52517
Time: 2018-07-15 09:08:27
TRAINING STATS: batch 458/486 in epoch 1097, batch loss: 1.69443, batch accuracy: 0.55350
Time: 2018-07-15 09:08:32
TRAINING STATS: batch 22/486 in epoch 1098,  batch loss: 1.71058, batch accuracy: 0.54417
Time: 2018-07-15 09:08:36
TRAINING STATS: batch 72/486 in epoch 1098,  batch loss: 1.69447, batch accuracy: 0.54133
Time: 2018-07-15 09:08:39
TRAINING STATS: batch 122/486 in epoch 1098, batch loss: 1.62328, batch accuracy: 0.55633
Time: 2018-07-15 09:08:44
TRAINING STATS: batch 172/486 in epoch 1098, batch loss: 1.76494, batch accuracy: 0.52083
Time: 2018-07-15 09:08:48
TRAINING STATS: batch 222/486 in epoch 1098, batch loss: 1.66434, batch accuracy: 0.54150
Time: 2018-07-15 09:08:51
TRAINING STATS: batch 272/486 in epoch 1098, batch loss: 1.70097, batch accuracy: 0.53150
Time: 2018-07-15 09:08:56
TRAINING STATS: batch 322/486 in epoch 1098, batch loss: 1.65834, batch accuracy: 0.54533
Time: 2018-07-15 09:09:00
TRAINING STATS: batch 372/486 in epoch 1098, batch loss: 1.60952, batch accuracy: 0.56217
Time: 2018-07-15 09:09:03
TRAINING STATS: batch 422/486 in epoch 1098, batch loss: 1.63461, batch accuracy: 0.55833
Time: 2018-07-15 09:09:08
TRAINING STATS: batch 472/486 in epoch 1098, batch loss: 1.72379, batch accuracy: 0.53300
Time: 2018-07-15 09:09:12
TRAINING STATS: batch 36/486 in epoch 1099,  batch loss: 1.72916, batch accuracy: 0.52783
Time: 2018-07-15 09:09:16
TRAINING STATS: batch 86/486 in epoch 1099,  batch loss: 1.66556, batch accuracy: 0.55050
Time: 2018-07-15 09:09:20
TRAINING STATS: batch 136/486 in epoch 1099, batch loss: 1.72424, batch accuracy: 0.53100
Time: 2018-07-15 09:09:24
TRAINING STATS: batch 186/486 in epoch 1099, batch loss: 1.68396, batch accuracy: 0.54800
Time: 2018-07-15 09:09:28
TRAINING STATS: batch 236/486 in epoch 1099, batch loss: 1.69775, batch accuracy: 0.54317
Time: 2018-07-15 09:09:32
TRAINING STATS: batch 286/486 in epoch 1099, batch loss: 1.69822, batch accuracy: 0.54017
Time: 2018-07-15 09:09:36
TRAINING STATS: batch 336/486 in epoch 1099, batch loss: 1.64744, batch accuracy: 0.55083
Time: 2018-07-15 09:09:40
TRAINING STATS: batch 386/486 in epoch 1099, batch loss: 1.70711, batch accuracy: 0.53567
Time: 2018-07-15 09:09:44
TRAINING STATS: batch 436/486 in epoch 1099, batch loss: 1.69008, batch accuracy: 0.54383
Time: 2018-07-15 09:09:48
TRAINING STATS: batch 0/486 in epoch 1100,   batch loss: 1.65434, batch accuracy: 0.54900
Time: 2018-07-15 09:09:52
TRAINING STATS: batch 50/486 in epoch 1100,  batch loss: 1.62578, batch accuracy: 0.56233
Time: 2018-07-15 09:09:57
TRAINING STATS: batch 100/486 in epoch 1100, batch loss: 1.68683, batch accuracy: 0.54583
Time: 2018-07-15 09:10:00
TRAINING STATS: batch 150/486 in epoch 1100, batch loss: 1.63286, batch accuracy: 0.56550
Time: 2018-07-15 09:10:04
TRAINING STATS: batch 200/486 in epoch 1100, batch loss: 1.54483, batch accuracy: 0.58183
Time: 2018-07-15 09:10:09
TRAINING STATS: batch 250/486 in epoch 1100, batch loss: 1.73204, batch accuracy: 0.52583
Time: 2018-07-15 09:10:12
TRAINING STATS: batch 300/486 in epoch 1100, batch loss: 1.70806, batch accuracy: 0.53400
Time: 2018-07-15 09:10:16
TRAINING STATS: batch 350/486 in epoch 1100, batch loss: 1.69662, batch accuracy: 0.54583
Time: 2018-07-15 09:10:21
TRAINING STATS: batch 400/486 in epoch 1100, batch loss: 1.56807, batch accuracy: 0.57017
Time: 2018-07-15 09:10:24
TRAINING STATS: batch 450/486 in epoch 1100, batch loss: 1.72039, batch accuracy: 0.53367
Time: 2018-07-15 09:10:28
TRAINING STATS: batch 14/486 in epoch 1101,  batch loss: 1.60594, batch accuracy: 0.57100
Time: 2018-07-15 09:10:33
TRAINING STATS: batch 64/486 in epoch 1101,  batch loss: 1.76537, batch accuracy: 0.52333
Time: 2018-07-15 09:10:37
TRAINING STATS: batch 114/486 in epoch 1101, batch loss: 1.70521, batch accuracy: 0.53783
Time: 2018-07-15 09:10:40
TRAINING STATS: batch 164/486 in epoch 1101, batch loss: 1.59647, batch accuracy: 0.57150
Time: 2018-07-15 09:10:45
TRAINING STATS: batch 214/486 in epoch 1101, batch loss: 1.66833, batch accuracy: 0.54667
Time: 2018-07-15 09:10:49
TRAINING STATS: batch 264/486 in epoch 1101, batch loss: 1.70870, batch accuracy: 0.53133
Time: 2018-07-15 09:10:53
TRAINING STATS: batch 314/486 in epoch 1101, batch loss: 1.74391, batch accuracy: 0.52317
Time: 2018-07-15 09:10:57
TRAINING STATS: batch 364/486 in epoch 1101, batch loss: 1.65611, batch accuracy: 0.54883
Time: 2018-07-15 09:11:01
TRAINING STATS: batch 414/486 in epoch 1101, batch loss: 1.59142, batch accuracy: 0.56883
Time: 2018-07-15 09:11:05
TRAINING STATS: batch 464/486 in epoch 1101, batch loss: 1.64166, batch accuracy: 0.55633
Time: 2018-07-15 09:11:09
TRAINING STATS: batch 28/486 in epoch 1102,  batch loss: 1.58772, batch accuracy: 0.57333
Time: 2018-07-15 09:11:13
TRAINING STATS: batch 78/486 in epoch 1102,  batch loss: 1.67729, batch accuracy: 0.54983
Time: 2018-07-15 09:11:17
TRAINING STATS: batch 128/486 in epoch 1102, batch loss: 1.65189, batch accuracy: 0.55383
Time: 2018-07-15 09:11:21
TRAINING STATS: batch 178/486 in epoch 1102, batch loss: 1.56362, batch accuracy: 0.57600
Time: 2018-07-15 09:11:25
TRAINING STATS: batch 228/486 in epoch 1102, batch loss: 1.60981, batch accuracy: 0.56200
Time: 2018-07-15 09:11:29
TRAINING STATS: batch 278/486 in epoch 1102, batch loss: 1.59770, batch accuracy: 0.57133
Time: 2018-07-15 09:11:33
TRAINING STATS: batch 328/486 in epoch 1102, batch loss: 1.62117, batch accuracy: 0.56117
Time: 2018-07-15 09:11:37
TRAINING STATS: batch 378/486 in epoch 1102, batch loss: 1.68562, batch accuracy: 0.54767
Time: 2018-07-15 09:11:41
TRAINING STATS: batch 428/486 in epoch 1102, batch loss: 1.69127, batch accuracy: 0.53667
Time: 2018-07-15 09:11:46
TRAINING STATS: batch 478/486 in epoch 1102, batch loss: 1.68324, batch accuracy: 0.53617
Time: 2018-07-15 09:11:49
TRAINING STATS: batch 42/486 in epoch 1103,  batch loss: 1.59468, batch accuracy: 0.57400
Time: 2018-07-15 09:11:53
TRAINING STATS: batch 92/486 in epoch 1103,  batch loss: 1.70137, batch accuracy: 0.53967
Time: 2018-07-15 09:11:58
TRAINING STATS: batch 142/486 in epoch 1103, batch loss: 1.63286, batch accuracy: 0.55983
Time: 2018-07-15 09:12:01
TRAINING STATS: batch 192/486 in epoch 1103, batch loss: 1.66245, batch accuracy: 0.54917
Time: 2018-07-15 09:12:05
TRAINING STATS: batch 242/486 in epoch 1103, batch loss: 1.63127, batch accuracy: 0.55400
Time: 2018-07-15 09:12:10
TRAINING STATS: batch 292/486 in epoch 1103, batch loss: 1.64662, batch accuracy: 0.55100
Time: 2018-07-15 09:12:13
TRAINING STATS: batch 342/486 in epoch 1103, batch loss: 1.61247, batch accuracy: 0.55717
Time: 2018-07-15 09:12:17
TRAINING STATS: batch 392/486 in epoch 1103, batch loss: 1.57056, batch accuracy: 0.56800
Time: 2018-07-15 09:12:22
TRAINING STATS: batch 442/486 in epoch 1103, batch loss: 1.57796, batch accuracy: 0.57833
Time: 2018-07-15 09:12:26
TRAINING STATS: batch 6/486 in epoch 1104,   batch loss: 1.70692, batch accuracy: 0.53567
Time: 2018-07-15 09:12:29
TRAINING STATS: batch 56/486 in epoch 1104,  batch loss: 1.62746, batch accuracy: 0.56200
Time: 2018-07-15 09:12:34
TRAINING STATS: batch 106/486 in epoch 1104, batch loss: 1.71394, batch accuracy: 0.53550
Time: 2018-07-15 09:12:38
TRAINING STATS: batch 156/486 in epoch 1104, batch loss: 1.69280, batch accuracy: 0.54400
Time: 2018-07-15 09:12:41
TRAINING STATS: batch 206/486 in epoch 1104, batch loss: 1.74078, batch accuracy: 0.52567
Time: 2018-07-15 09:12:46
TRAINING STATS: batch 256/486 in epoch 1104, batch loss: 1.59907, batch accuracy: 0.56850
Time: 2018-07-15 09:12:50
TRAINING STATS: batch 306/486 in epoch 1104, batch loss: 1.65459, batch accuracy: 0.54700
Time: 2018-07-15 09:12:53
TRAINING STATS: batch 356/486 in epoch 1104, batch loss: 1.70368, batch accuracy: 0.53333
Time: 2018-07-15 09:12:58
TRAINING STATS: batch 406/486 in epoch 1104, batch loss: 1.73706, batch accuracy: 0.51817
Time: 2018-07-15 09:13:02
TRAINING STATS: batch 456/486 in epoch 1104, batch loss: 1.54025, batch accuracy: 0.58300
Time: 2018-07-15 09:13:05
TRAINING STATS: batch 20/486 in epoch 1105,  batch loss: 1.68983, batch accuracy: 0.54150
Time: 2018-07-15 09:13:10
TRAINING STATS: batch 70/486 in epoch 1105,  batch loss: 1.56067, batch accuracy: 0.58000
Time: 2018-07-15 09:13:14
TRAINING STATS: batch 120/486 in epoch 1105, batch loss: 1.60104, batch accuracy: 0.56550
Time: 2018-07-15 09:13:18
TRAINING STATS: batch 170/486 in epoch 1105, batch loss: 1.63182, batch accuracy: 0.55917
Time: 2018-07-15 09:13:22
TRAINING STATS: batch 220/486 in epoch 1105, batch loss: 1.57071, batch accuracy: 0.57333
Time: 2018-07-15 09:13:26
TRAINING STATS: batch 270/486 in epoch 1105, batch loss: 1.66382, batch accuracy: 0.53617
Time: 2018-07-15 09:13:30
TRAINING STATS: batch 320/486 in epoch 1105, batch loss: 1.61381, batch accuracy: 0.55933
Time: 2018-07-15 09:13:34
TRAINING STATS: batch 370/486 in epoch 1105, batch loss: 1.66447, batch accuracy: 0.55300
Time: 2018-07-15 09:13:38
TRAINING STATS: batch 420/486 in epoch 1105, batch loss: 1.69893, batch accuracy: 0.54067
Time: 2018-07-15 09:13:42
TRAINING STATS: batch 470/486 in epoch 1105, batch loss: 1.74407, batch accuracy: 0.52083
Time: 2018-07-15 09:13:46
TRAINING STATS: batch 34/486 in epoch 1106,  batch loss: 1.67053, batch accuracy: 0.54267
Time: 2018-07-15 09:13:50
TRAINING STATS: batch 84/486 in epoch 1106,  batch loss: 1.67414, batch accuracy: 0.54317
Time: 2018-07-15 09:13:54
TRAINING STATS: batch 134/486 in epoch 1106, batch loss: 1.68613, batch accuracy: 0.54833
Time: 2018-07-15 09:13:59
TRAINING STATS: batch 184/486 in epoch 1106, batch loss: 1.70036, batch accuracy: 0.53667
Time: 2018-07-15 09:14:02
TRAINING STATS: batch 234/486 in epoch 1106, batch loss: 1.73557, batch accuracy: 0.53217
Time: 2018-07-15 09:14:06
TRAINING STATS: batch 284/486 in epoch 1106, batch loss: 1.71786, batch accuracy: 0.53667
Time: 2018-07-15 09:14:11
TRAINING STATS: batch 334/486 in epoch 1106, batch loss: 1.64051, batch accuracy: 0.55917
Time: 2018-07-15 09:14:14
TRAINING STATS: batch 384/486 in epoch 1106, batch loss: 1.62663, batch accuracy: 0.56050
Time: 2018-07-15 09:14:18
TRAINING STATS: batch 434/486 in epoch 1106, batch loss: 1.71743, batch accuracy: 0.52867
Time: 2018-07-15 09:14:23
TRAINING STATS: batch 484/486 in epoch 1106, batch loss: 1.68333, batch accuracy: 0.54233
Time: 2018-07-15 09:14:26
TRAINING STATS: batch 48/486 in epoch 1107,  batch loss: 1.66304, batch accuracy: 0.54783
Time: 2018-07-15 09:14:30
TRAINING STATS: batch 98/486 in epoch 1107,  batch loss: 1.64134, batch accuracy: 0.55917
Time: 2018-07-15 09:14:35
TRAINING STATS: batch 148/486 in epoch 1107, batch loss: 1.69811, batch accuracy: 0.54467
Time: 2018-07-15 09:14:39
TRAINING STATS: batch 198/486 in epoch 1107, batch loss: 1.65581, batch accuracy: 0.55333
Time: 2018-07-15 09:14:42
TRAINING STATS: batch 248/486 in epoch 1107, batch loss: 1.71178, batch accuracy: 0.53867
Time: 2018-07-15 09:14:47
TRAINING STATS: batch 298/486 in epoch 1107, batch loss: 1.68577, batch accuracy: 0.53500
Time: 2018-07-15 09:14:51
TRAINING STATS: batch 348/486 in epoch 1107, batch loss: 1.66619, batch accuracy: 0.55583
Time: 2018-07-15 09:14:54
TRAINING STATS: batch 398/486 in epoch 1107, batch loss: 1.66643, batch accuracy: 0.54850
Time: 2018-07-15 09:14:59
TRAINING STATS: batch 448/486 in epoch 1107, batch loss: 1.65471, batch accuracy: 0.55617
Time: 2018-07-15 09:15:03
TRAINING STATS: batch 12/486 in epoch 1108,  batch loss: 1.70173, batch accuracy: 0.53967
Time: 2018-07-15 09:15:06
TRAINING STATS: batch 62/486 in epoch 1108,  batch loss: 1.73227, batch accuracy: 0.52417
Time: 2018-07-15 09:15:11
TRAINING STATS: batch 112/486 in epoch 1108, batch loss: 1.64473, batch accuracy: 0.55367
Time: 2018-07-15 09:15:15
TRAINING STATS: batch 162/486 in epoch 1108, batch loss: 1.67846, batch accuracy: 0.54467
Time: 2018-07-15 09:15:19
TRAINING STATS: batch 212/486 in epoch 1108, batch loss: 1.58582, batch accuracy: 0.57067
Time: 2018-07-15 09:15:23
TRAINING STATS: batch 262/486 in epoch 1108, batch loss: 1.75368, batch accuracy: 0.52367
Time: 2018-07-15 09:15:27
TRAINING STATS: batch 312/486 in epoch 1108, batch loss: 1.67404, batch accuracy: 0.53683
Time: 2018-07-15 09:15:31
TRAINING STATS: batch 362/486 in epoch 1108, batch loss: 1.68539, batch accuracy: 0.54250
Time: 2018-07-15 09:15:35
TRAINING STATS: batch 412/486 in epoch 1108, batch loss: 1.58489, batch accuracy: 0.57483
Time: 2018-07-15 09:15:39
TRAINING STATS: batch 462/486 in epoch 1108, batch loss: 1.68091, batch accuracy: 0.54117
Time: 2018-07-15 09:15:43
TRAINING STATS: batch 26/486 in epoch 1109,  batch loss: 1.69838, batch accuracy: 0.53833
Time: 2018-07-15 09:15:48
TRAINING STATS: batch 76/486 in epoch 1109,  batch loss: 1.75163, batch accuracy: 0.53067
Time: 2018-07-15 09:15:51
TRAINING STATS: batch 126/486 in epoch 1109, batch loss: 1.71201, batch accuracy: 0.53517
Time: 2018-07-15 09:15:55
TRAINING STATS: batch 176/486 in epoch 1109, batch loss: 1.58051, batch accuracy: 0.57317
Time: 2018-07-15 09:16:00
TRAINING STATS: batch 226/486 in epoch 1109, batch loss: 1.66779, batch accuracy: 0.55067
Time: 2018-07-15 09:16:03
TRAINING STATS: batch 276/486 in epoch 1109, batch loss: 1.66536, batch accuracy: 0.54733
Time: 2018-07-15 09:16:07
TRAINING STATS: batch 326/486 in epoch 1109, batch loss: 1.70059, batch accuracy: 0.53817
Time: 2018-07-15 09:16:12
TRAINING STATS: batch 376/486 in epoch 1109, batch loss: 1.68254, batch accuracy: 0.54583
Time: 2018-07-15 09:16:15
TRAINING STATS: batch 426/486 in epoch 1109, batch loss: 1.67769, batch accuracy: 0.53983
Time: 2018-07-15 09:16:19
TRAINING STATS: batch 476/486 in epoch 1109, batch loss: 1.59365, batch accuracy: 0.57267
Time: 2018-07-15 09:16:24
TRAINING STATS: batch 40/486 in epoch 1110,  batch loss: 1.63514, batch accuracy: 0.56233
Time: 2018-07-15 09:16:27
TRAINING STATS: batch 90/486 in epoch 1110,  batch loss: 1.69415, batch accuracy: 0.54350
Time: 2018-07-15 09:16:31
TRAINING STATS: batch 140/486 in epoch 1110, batch loss: 1.58408, batch accuracy: 0.57283
Time: 2018-07-15 09:16:36
TRAINING STATS: batch 190/486 in epoch 1110, batch loss: 1.63472, batch accuracy: 0.55500
Time: 2018-07-15 09:16:40
TRAINING STATS: batch 240/486 in epoch 1110, batch loss: 1.71322, batch accuracy: 0.53650
Time: 2018-07-15 09:16:43
TRAINING STATS: batch 290/486 in epoch 1110, batch loss: 1.72274, batch accuracy: 0.52717
Time: 2018-07-15 09:16:48
TRAINING STATS: batch 340/486 in epoch 1110, batch loss: 1.72226, batch accuracy: 0.52650
Time: 2018-07-15 09:16:52
TRAINING STATS: batch 390/486 in epoch 1110, batch loss: 1.59540, batch accuracy: 0.56800
Time: 2018-07-15 09:16:55
TRAINING STATS: batch 440/486 in epoch 1110, batch loss: 1.66607, batch accuracy: 0.55417
Time: 2018-07-15 09:17:00
TRAINING STATS: batch 4/486 in epoch 1111,   batch loss: 1.63741, batch accuracy: 0.55800
Time: 2018-07-15 09:17:04
TRAINING STATS: batch 54/486 in epoch 1111,  batch loss: 1.68346, batch accuracy: 0.53833
Time: 2018-07-15 09:17:07
TRAINING STATS: batch 104/486 in epoch 1111, batch loss: 1.68591, batch accuracy: 0.54683
Time: 2018-07-15 09:17:12
TRAINING STATS: batch 154/486 in epoch 1111, batch loss: 1.65318, batch accuracy: 0.55050
Time: 2018-07-15 09:17:16
TRAINING STATS: batch 204/486 in epoch 1111, batch loss: 1.72480, batch accuracy: 0.53317
Time: 2018-07-15 09:17:19
TRAINING STATS: batch 254/486 in epoch 1111, batch loss: 1.59857, batch accuracy: 0.56750
Time: 2018-07-15 09:17:24
TRAINING STATS: batch 304/486 in epoch 1111, batch loss: 1.61553, batch accuracy: 0.55833
Time: 2018-07-15 09:17:28
TRAINING STATS: batch 354/486 in epoch 1111, batch loss: 1.67947, batch accuracy: 0.53967
Time: 2018-07-15 09:17:31
TRAINING STATS: batch 404/486 in epoch 1111, batch loss: 1.64034, batch accuracy: 0.55833
Time: 2018-07-15 09:17:36
TRAINING STATS: batch 454/486 in epoch 1111, batch loss: 1.52107, batch accuracy: 0.59283
Time: 2018-07-15 09:17:40
TRAINING STATS: batch 18/486 in epoch 1112,  batch loss: 1.69754, batch accuracy: 0.54250
Time: 2018-07-15 09:17:43
TRAINING STATS: batch 68/486 in epoch 1112,  batch loss: 1.51942, batch accuracy: 0.59317
Time: 2018-07-15 09:17:48
TRAINING STATS: batch 118/486 in epoch 1112, batch loss: 1.64866, batch accuracy: 0.55333
Time: 2018-07-15 09:17:52
TRAINING STATS: batch 168/486 in epoch 1112, batch loss: 1.58145, batch accuracy: 0.57633
Time: 2018-07-15 09:17:56
TRAINING STATS: batch 218/486 in epoch 1112, batch loss: 1.65579, batch accuracy: 0.55283
Time: 2018-07-15 09:18:00
TRAINING STATS: batch 268/486 in epoch 1112, batch loss: 1.59751, batch accuracy: 0.56550
Time: 2018-07-15 09:18:04
TRAINING STATS: batch 318/486 in epoch 1112, batch loss: 1.66107, batch accuracy: 0.55017
Time: 2018-07-15 09:18:08
TRAINING STATS: batch 368/486 in epoch 1112, batch loss: 1.67466, batch accuracy: 0.53683
Time: 2018-07-15 09:18:13
TRAINING STATS: batch 418/486 in epoch 1112, batch loss: 1.70913, batch accuracy: 0.52567
Time: 2018-07-15 09:18:16
TRAINING STATS: batch 468/486 in epoch 1112, batch loss: 1.68142, batch accuracy: 0.54300
Time: 2018-07-15 09:18:20
TRAINING STATS: batch 32/486 in epoch 1113,  batch loss: 1.61611, batch accuracy: 0.55417
Time: 2018-07-15 09:18:25
TRAINING STATS: batch 82/486 in epoch 1113,  batch loss: 1.70276, batch accuracy: 0.53117
Time: 2018-07-15 09:18:28
TRAINING STATS: batch 132/486 in epoch 1113, batch loss: 1.65095, batch accuracy: 0.56267
Time: 2018-07-15 09:18:32
TRAINING STATS: batch 182/486 in epoch 1113, batch loss: 1.70303, batch accuracy: 0.53250
Time: 2018-07-15 09:18:37
TRAINING STATS: batch 232/486 in epoch 1113, batch loss: 1.69670, batch accuracy: 0.53933
Time: 2018-07-15 09:18:40
TRAINING STATS: batch 282/486 in epoch 1113, batch loss: 1.61282, batch accuracy: 0.55483
Time: 2018-07-15 09:18:44
TRAINING STATS: batch 332/486 in epoch 1113, batch loss: 1.69654, batch accuracy: 0.54300
Time: 2018-07-15 09:18:49
TRAINING STATS: batch 382/486 in epoch 1113, batch loss: 1.68112, batch accuracy: 0.54267
Time: 2018-07-15 09:18:53
TRAINING STATS: batch 432/486 in epoch 1113, batch loss: 1.59562, batch accuracy: 0.56817
Time: 2018-07-15 09:18:56
TRAINING STATS: batch 482/486 in epoch 1113, batch loss: 1.65665, batch accuracy: 0.55183
Time: 2018-07-15 09:19:01
TRAINING STATS: batch 46/486 in epoch 1114,  batch loss: 1.64779, batch accuracy: 0.55883
Time: 2018-07-15 09:19:05
TRAINING STATS: batch 96/486 in epoch 1114,  batch loss: 1.68875, batch accuracy: 0.54267
Time: 2018-07-15 09:19:08
TRAINING STATS: batch 146/486 in epoch 1114, batch loss: 1.71518, batch accuracy: 0.53650
Time: 2018-07-15 09:19:13
TRAINING STATS: batch 196/486 in epoch 1114, batch loss: 1.71570, batch accuracy: 0.52583
Time: 2018-07-15 09:19:17
TRAINING STATS: batch 246/486 in epoch 1114, batch loss: 1.64130, batch accuracy: 0.55683
Time: 2018-07-15 09:19:20
TRAINING STATS: batch 296/486 in epoch 1114, batch loss: 1.63455, batch accuracy: 0.55317
Time: 2018-07-15 09:19:25
TRAINING STATS: batch 346/486 in epoch 1114, batch loss: 1.56796, batch accuracy: 0.57583
Time: 2018-07-15 09:19:29
TRAINING STATS: batch 396/486 in epoch 1114, batch loss: 1.65592, batch accuracy: 0.55533
Time: 2018-07-15 09:19:33
TRAINING STATS: batch 446/486 in epoch 1114, batch loss: 1.67947, batch accuracy: 0.53983
Time: 2018-07-15 09:19:37
TRAINING STATS: batch 10/486 in epoch 1115,  batch loss: 1.69508, batch accuracy: 0.53483
Time: 2018-07-15 09:19:41
TRAINING STATS: batch 60/486 in epoch 1115,  batch loss: 1.65238, batch accuracy: 0.55300
Time: 2018-07-15 09:19:45
TRAINING STATS: batch 110/486 in epoch 1115, batch loss: 1.71337, batch accuracy: 0.53817
Time: 2018-07-15 09:19:49
TRAINING STATS: batch 160/486 in epoch 1115, batch loss: 1.64295, batch accuracy: 0.54983
Time: 2018-07-15 09:19:53
TRAINING STATS: batch 210/486 in epoch 1115, batch loss: 1.61181, batch accuracy: 0.56283
Time: 2018-07-15 09:19:57
TRAINING STATS: batch 260/486 in epoch 1115, batch loss: 1.68854, batch accuracy: 0.54067
Time: 2018-07-15 09:20:02
TRAINING STATS: batch 310/486 in epoch 1115, batch loss: 1.67854, batch accuracy: 0.54433
Time: 2018-07-15 09:20:05
TRAINING STATS: batch 360/486 in epoch 1115, batch loss: 1.69916, batch accuracy: 0.54100
Time: 2018-07-15 09:20:09
TRAINING STATS: batch 410/486 in epoch 1115, batch loss: 1.60172, batch accuracy: 0.56683
Time: 2018-07-15 09:20:14
TRAINING STATS: batch 460/486 in epoch 1115, batch loss: 1.81325, batch accuracy: 0.49783
Time: 2018-07-15 09:20:17
TRAINING STATS: batch 24/486 in epoch 1116,  batch loss: 1.72831, batch accuracy: 0.53833
Time: 2018-07-15 09:20:21
TRAINING STATS: batch 74/486 in epoch 1116,  batch loss: 1.68225, batch accuracy: 0.54900
Time: 2018-07-15 09:20:26
TRAINING STATS: batch 124/486 in epoch 1116, batch loss: 1.68508, batch accuracy: 0.54867
Time: 2018-07-15 09:20:29
TRAINING STATS: batch 174/486 in epoch 1116, batch loss: 1.74032, batch accuracy: 0.53567
Time: 2018-07-15 09:20:33
TRAINING STATS: batch 224/486 in epoch 1116, batch loss: 1.68863, batch accuracy: 0.53850
Time: 2018-07-15 09:20:38
TRAINING STATS: batch 274/486 in epoch 1116, batch loss: 1.66124, batch accuracy: 0.54217
Time: 2018-07-15 09:20:42
TRAINING STATS: batch 324/486 in epoch 1116, batch loss: 1.70236, batch accuracy: 0.54150
Time: 2018-07-15 09:20:45
TRAINING STATS: batch 374/486 in epoch 1116, batch loss: 1.74230, batch accuracy: 0.52967
Time: 2018-07-15 09:20:50
TRAINING STATS: batch 424/486 in epoch 1116, batch loss: 1.60197, batch accuracy: 0.56767
Time: 2018-07-15 09:20:54
TRAINING STATS: batch 474/486 in epoch 1116, batch loss: 1.67250, batch accuracy: 0.54500
Time: 2018-07-15 09:20:57
TRAINING STATS: batch 38/486 in epoch 1117,  batch loss: 1.69306, batch accuracy: 0.54550
Time: 2018-07-15 09:21:02
TRAINING STATS: batch 88/486 in epoch 1117,  batch loss: 1.72799, batch accuracy: 0.53300
Time: 2018-07-15 09:21:06
TRAINING STATS: batch 138/486 in epoch 1117, batch loss: 1.71227, batch accuracy: 0.53483
Time: 2018-07-15 09:21:09
TRAINING STATS: batch 188/486 in epoch 1117, batch loss: 1.62082, batch accuracy: 0.55900
Time: 2018-07-15 09:21:14
TRAINING STATS: batch 238/486 in epoch 1117, batch loss: 1.64504, batch accuracy: 0.55533
Time: 2018-07-15 09:21:18
TRAINING STATS: batch 288/486 in epoch 1117, batch loss: 1.69047, batch accuracy: 0.53400
Time: 2018-07-15 09:21:22
TRAINING STATS: batch 338/486 in epoch 1117, batch loss: 1.66502, batch accuracy: 0.54433
Time: 2018-07-15 09:21:26
TRAINING STATS: batch 388/486 in epoch 1117, batch loss: 1.62906, batch accuracy: 0.55967
Time: 2018-07-15 09:21:30
TRAINING STATS: batch 438/486 in epoch 1117, batch loss: 1.69584, batch accuracy: 0.54183
Time: 2018-07-15 09:21:34
TRAINING STATS: batch 2/486 in epoch 1118,   batch loss: 1.68513, batch accuracy: 0.54600
Time: 2018-07-15 09:21:38
TRAINING STATS: batch 52/486 in epoch 1118,  batch loss: 1.73082, batch accuracy: 0.52567
Time: 2018-07-15 09:21:42
TRAINING STATS: batch 102/486 in epoch 1118, batch loss: 1.68670, batch accuracy: 0.54717
Time: 2018-07-15 09:21:46
TRAINING STATS: batch 152/486 in epoch 1118, batch loss: 1.64344, batch accuracy: 0.55200
Time: 2018-07-15 09:21:50
TRAINING STATS: batch 202/486 in epoch 1118, batch loss: 1.66394, batch accuracy: 0.54533
Time: 2018-07-15 09:21:54
TRAINING STATS: batch 252/486 in epoch 1118, batch loss: 1.64420, batch accuracy: 0.55767
Time: 2018-07-15 09:21:58
TRAINING STATS: batch 302/486 in epoch 1118, batch loss: 1.63937, batch accuracy: 0.54983
Time: 2018-07-15 09:22:03
TRAINING STATS: batch 352/486 in epoch 1118, batch loss: 1.65929, batch accuracy: 0.54933
Time: 2018-07-15 09:22:06
TRAINING STATS: batch 402/486 in epoch 1118, batch loss: 1.53777, batch accuracy: 0.59333
Time: 2018-07-15 09:22:10
TRAINING STATS: batch 452/486 in epoch 1118, batch loss: 1.67067, batch accuracy: 0.53817
Time: 2018-07-15 09:22:15
TRAINING STATS: batch 16/486 in epoch 1119,  batch loss: 1.62996, batch accuracy: 0.55433
Time: 2018-07-15 09:22:18
TRAINING STATS: batch 66/486 in epoch 1119,  batch loss: 1.65354, batch accuracy: 0.55500
Time: 2018-07-15 09:22:22
TRAINING STATS: batch 116/486 in epoch 1119, batch loss: 1.62577, batch accuracy: 0.55683
Time: 2018-07-15 09:22:27
TRAINING STATS: batch 166/486 in epoch 1119, batch loss: 1.56489, batch accuracy: 0.57783
Time: 2018-07-15 09:22:30
TRAINING STATS: batch 216/486 in epoch 1119, batch loss: 1.67611, batch accuracy: 0.54400
Time: 2018-07-15 09:22:34
TRAINING STATS: batch 266/486 in epoch 1119, batch loss: 1.65856, batch accuracy: 0.54583
Time: 2018-07-15 09:22:39
TRAINING STATS: batch 316/486 in epoch 1119, batch loss: 1.64976, batch accuracy: 0.54967
Time: 2018-07-15 09:22:43
TRAINING STATS: batch 366/486 in epoch 1119, batch loss: 1.71014, batch accuracy: 0.53733
Time: 2018-07-15 09:22:46
TRAINING STATS: batch 416/486 in epoch 1119, batch loss: 1.69147, batch accuracy: 0.53733
Time: 2018-07-15 09:22:51
TRAINING STATS: batch 466/486 in epoch 1119, batch loss: 1.52161, batch accuracy: 0.58683
Time: 2018-07-15 09:22:55
TRAINING STATS: batch 30/486 in epoch 1120,  batch loss: 1.55043, batch accuracy: 0.57750
Time: 2018-07-15 09:22:58
TRAINING STATS: batch 80/486 in epoch 1120,  batch loss: 1.64967, batch accuracy: 0.55233
Time: 2018-07-15 09:23:03
TRAINING STATS: batch 130/486 in epoch 1120, batch loss: 1.63430, batch accuracy: 0.56333
Time: 2018-07-15 09:23:07
TRAINING STATS: batch 180/486 in epoch 1120, batch loss: 1.69846, batch accuracy: 0.54100
Time: 2018-07-15 09:23:10
TRAINING STATS: batch 230/486 in epoch 1120, batch loss: 1.68179, batch accuracy: 0.54450
Time: 2018-07-15 09:23:15
TRAINING STATS: batch 280/486 in epoch 1120, batch loss: 1.66045, batch accuracy: 0.54400
Time: 2018-07-15 09:23:19
TRAINING STATS: batch 330/486 in epoch 1120, batch loss: 1.63908, batch accuracy: 0.55517
Time: 2018-07-15 09:23:23
TRAINING STATS: batch 380/486 in epoch 1120, batch loss: 1.63425, batch accuracy: 0.55367
Time: 2018-07-15 09:23:27
TRAINING STATS: batch 430/486 in epoch 1120, batch loss: 1.63053, batch accuracy: 0.55867
Time: 2018-07-15 09:23:31
TRAINING STATS: batch 480/486 in epoch 1120, batch loss: 1.67943, batch accuracy: 0.55233
Time: 2018-07-15 09:23:35
TRAINING STATS: batch 44/486 in epoch 1121,  batch loss: 1.61347, batch accuracy: 0.56100
Time: 2018-07-15 09:23:39
TRAINING STATS: batch 94/486 in epoch 1121,  batch loss: 1.71428, batch accuracy: 0.53550
Time: 2018-07-15 09:23:43
TRAINING STATS: batch 144/486 in epoch 1121, batch loss: 1.72788, batch accuracy: 0.52433
Time: 2018-07-15 09:23:47
TRAINING STATS: batch 194/486 in epoch 1121, batch loss: 1.75187, batch accuracy: 0.51633
Time: 2018-07-15 09:23:51
TRAINING STATS: batch 244/486 in epoch 1121, batch loss: 1.64877, batch accuracy: 0.55433
Time: 2018-07-15 09:23:55
TRAINING STATS: batch 294/486 in epoch 1121, batch loss: 1.58020, batch accuracy: 0.57483
Time: 2018-07-15 09:23:59
TRAINING STATS: batch 344/486 in epoch 1121, batch loss: 1.64614, batch accuracy: 0.55083
Time: 2018-07-15 09:24:04
TRAINING STATS: batch 394/486 in epoch 1121, batch loss: 1.61626, batch accuracy: 0.56050
Time: 2018-07-15 09:24:07
TRAINING STATS: batch 444/486 in epoch 1121, batch loss: 1.61899, batch accuracy: 0.56450
Time: 2018-07-15 09:24:11
TRAINING STATS: batch 8/486 in epoch 1122,   batch loss: 1.64373, batch accuracy: 0.55383
Time: 2018-07-15 09:24:16
TRAINING STATS: batch 58/486 in epoch 1122,  batch loss: 1.61358, batch accuracy: 0.56917
Time: 2018-07-15 09:24:19
TRAINING STATS: batch 108/486 in epoch 1122, batch loss: 1.72868, batch accuracy: 0.54017
Time: 2018-07-15 09:24:23
TRAINING STATS: batch 158/486 in epoch 1122, batch loss: 1.70148, batch accuracy: 0.53817
Time: 2018-07-15 09:24:28
TRAINING STATS: batch 208/486 in epoch 1122, batch loss: 1.68553, batch accuracy: 0.53983
Time: 2018-07-15 09:24:31
TRAINING STATS: batch 258/486 in epoch 1122, batch loss: 1.62651, batch accuracy: 0.55667
Time: 2018-07-15 09:24:35
TRAINING STATS: batch 308/486 in epoch 1122, batch loss: 1.68350, batch accuracy: 0.55283
Time: 2018-07-15 09:24:40
TRAINING STATS: batch 358/486 in epoch 1122, batch loss: 1.69032, batch accuracy: 0.53967
Time: 2018-07-15 09:24:44
TRAINING STATS: batch 408/486 in epoch 1122, batch loss: 1.70698, batch accuracy: 0.52650
Time: 2018-07-15 09:24:47
TRAINING STATS: batch 458/486 in epoch 1122, batch loss: 1.68500, batch accuracy: 0.54817
Time: 2018-07-15 09:24:52
TRAINING STATS: batch 22/486 in epoch 1123,  batch loss: 1.70250, batch accuracy: 0.54733
Time: 2018-07-15 09:24:56
TRAINING STATS: batch 72/486 in epoch 1123,  batch loss: 1.68800, batch accuracy: 0.53917
Time: 2018-07-15 09:24:59
TRAINING STATS: batch 122/486 in epoch 1123, batch loss: 1.61647, batch accuracy: 0.56250
Time: 2018-07-15 09:25:04
TRAINING STATS: batch 172/486 in epoch 1123, batch loss: 1.73077, batch accuracy: 0.53133
Time: 2018-07-15 09:25:08
TRAINING STATS: batch 222/486 in epoch 1123, batch loss: 1.66195, batch accuracy: 0.54150
Time: 2018-07-15 09:25:11
TRAINING STATS: batch 272/486 in epoch 1123, batch loss: 1.70680, batch accuracy: 0.53250
Time: 2018-07-15 09:25:16
TRAINING STATS: batch 322/486 in epoch 1123, batch loss: 1.66471, batch accuracy: 0.54950
Time: 2018-07-15 09:25:20
TRAINING STATS: batch 372/486 in epoch 1123, batch loss: 1.61707, batch accuracy: 0.56517
Time: 2018-07-15 09:25:24
TRAINING STATS: batch 422/486 in epoch 1123, batch loss: 1.64534, batch accuracy: 0.55333
Time: 2018-07-15 09:25:28
TRAINING STATS: batch 472/486 in epoch 1123, batch loss: 1.72153, batch accuracy: 0.53450
Time: 2018-07-15 09:25:32
TRAINING STATS: batch 36/486 in epoch 1124,  batch loss: 1.73224, batch accuracy: 0.52900
Time: 2018-07-15 09:25:36
TRAINING STATS: batch 86/486 in epoch 1124,  batch loss: 1.67029, batch accuracy: 0.55167
Time: 2018-07-15 09:25:40
TRAINING STATS: batch 136/486 in epoch 1124, batch loss: 1.72186, batch accuracy: 0.53167
Time: 2018-07-15 09:25:44
TRAINING STATS: batch 186/486 in epoch 1124, batch loss: 1.67865, batch accuracy: 0.55050
Time: 2018-07-15 09:25:48
TRAINING STATS: batch 236/486 in epoch 1124, batch loss: 1.71994, batch accuracy: 0.52700
Time: 2018-07-15 09:25:52
TRAINING STATS: batch 286/486 in epoch 1124, batch loss: 1.70326, batch accuracy: 0.54333
Time: 2018-07-15 09:25:56
TRAINING STATS: batch 336/486 in epoch 1124, batch loss: 1.65012, batch accuracy: 0.54667
Time: 2018-07-15 09:26:00
TRAINING STATS: batch 386/486 in epoch 1124, batch loss: 1.70547, batch accuracy: 0.53183
Time: 2018-07-15 09:26:05
TRAINING STATS: batch 436/486 in epoch 1124, batch loss: 1.67909, batch accuracy: 0.54633
Time: 2018-07-15 09:26:08
TRAINING STATS: batch 0/486 in epoch 1125,   batch loss: 1.65693, batch accuracy: 0.54467
Time: 2018-07-15 09:26:12
TRAINING STATS: batch 50/486 in epoch 1125,  batch loss: 1.63815, batch accuracy: 0.56267
Time: 2018-07-15 09:26:17
TRAINING STATS: batch 100/486 in epoch 1125, batch loss: 1.68996, batch accuracy: 0.54200
Time: 2018-07-15 09:26:20
TRAINING STATS: batch 150/486 in epoch 1125, batch loss: 1.63265, batch accuracy: 0.56633
Time: 2018-07-15 09:26:24
TRAINING STATS: batch 200/486 in epoch 1125, batch loss: 1.57165, batch accuracy: 0.57967
Time: 2018-07-15 09:26:29
TRAINING STATS: batch 250/486 in epoch 1125, batch loss: 1.72584, batch accuracy: 0.52050
Time: 2018-07-15 09:26:32
TRAINING STATS: batch 300/486 in epoch 1125, batch loss: 1.70228, batch accuracy: 0.53433
Time: 2018-07-15 09:26:36
TRAINING STATS: batch 350/486 in epoch 1125, batch loss: 1.68263, batch accuracy: 0.54650
Time: 2018-07-15 09:26:41
TRAINING STATS: batch 400/486 in epoch 1125, batch loss: 1.56397, batch accuracy: 0.57183
Time: 2018-07-15 09:26:45
TRAINING STATS: batch 450/486 in epoch 1125, batch loss: 1.74752, batch accuracy: 0.52567
Time: 2018-07-15 09:26:48
TRAINING STATS: batch 14/486 in epoch 1126,  batch loss: 1.57955, batch accuracy: 0.57300
Time: 2018-07-15 09:26:53
TRAINING STATS: batch 64/486 in epoch 1126,  batch loss: 1.77265, batch accuracy: 0.51517
Time: 2018-07-15 09:26:57
TRAINING STATS: batch 114/486 in epoch 1126, batch loss: 1.71156, batch accuracy: 0.53967
Time: 2018-07-15 09:27:00
TRAINING STATS: batch 164/486 in epoch 1126, batch loss: 1.59786, batch accuracy: 0.57283
Time: 2018-07-15 09:27:05
TRAINING STATS: batch 214/486 in epoch 1126, batch loss: 1.65924, batch accuracy: 0.54917
Time: 2018-07-15 09:27:09
TRAINING STATS: batch 264/486 in epoch 1126, batch loss: 1.70258, batch accuracy: 0.53400
Time: 2018-07-15 09:27:12
TRAINING STATS: batch 314/486 in epoch 1126, batch loss: 1.74472, batch accuracy: 0.52233
Time: 2018-07-15 09:27:17
TRAINING STATS: batch 364/486 in epoch 1126, batch loss: 1.64526, batch accuracy: 0.55133
Time: 2018-07-15 09:27:21
TRAINING STATS: batch 414/486 in epoch 1126, batch loss: 1.63610, batch accuracy: 0.56117
Time: 2018-07-15 09:27:24
TRAINING STATS: batch 464/486 in epoch 1126, batch loss: 1.65027, batch accuracy: 0.55533
Time: 2018-07-15 09:27:29
TRAINING STATS: batch 28/486 in epoch 1127,  batch loss: 1.60499, batch accuracy: 0.57133
Time: 2018-07-15 09:27:33
TRAINING STATS: batch 78/486 in epoch 1127,  batch loss: 1.67986, batch accuracy: 0.55200
Time: 2018-07-15 09:27:37
TRAINING STATS: batch 128/486 in epoch 1127, batch loss: 1.65022, batch accuracy: 0.55367
Time: 2018-07-15 09:27:41
TRAINING STATS: batch 178/486 in epoch 1127, batch loss: 1.81988, batch accuracy: 0.50483
Time: 2018-07-15 09:27:45
TRAINING STATS: batch 228/486 in epoch 1127, batch loss: 1.75756, batch accuracy: 0.52833
Time: 2018-07-15 09:27:49
TRAINING STATS: batch 278/486 in epoch 1127, batch loss: 1.70551, batch accuracy: 0.54700
Time: 2018-07-15 09:27:53
TRAINING STATS: batch 328/486 in epoch 1127, batch loss: 1.74352, batch accuracy: 0.53050
Time: 2018-07-15 09:27:57
TRAINING STATS: batch 378/486 in epoch 1127, batch loss: 1.80444, batch accuracy: 0.51217
Time: 2018-07-15 09:28:01
TRAINING STATS: batch 428/486 in epoch 1127, batch loss: 1.77436, batch accuracy: 0.52200
Time: 2018-07-15 09:28:06
TRAINING STATS: batch 478/486 in epoch 1127, batch loss: 1.72576, batch accuracy: 0.53000
Time: 2018-07-15 09:28:09
TRAINING STATS: batch 42/486 in epoch 1128,  batch loss: 1.61083, batch accuracy: 0.56783
Time: 2018-07-15 09:28:13
TRAINING STATS: batch 92/486 in epoch 1128,  batch loss: 1.69614, batch accuracy: 0.53917
Time: 2018-07-15 09:28:18
TRAINING STATS: batch 142/486 in epoch 1128, batch loss: 1.66458, batch accuracy: 0.55000
Time: 2018-07-15 09:28:21
TRAINING STATS: batch 192/486 in epoch 1128, batch loss: 1.67694, batch accuracy: 0.54833
Time: 2018-07-15 09:28:25
TRAINING STATS: batch 242/486 in epoch 1128, batch loss: 1.64832, batch accuracy: 0.55717
Time: 2018-07-15 09:28:30
TRAINING STATS: batch 292/486 in epoch 1128, batch loss: 1.67253, batch accuracy: 0.54833
Time: 2018-07-15 09:28:33
TRAINING STATS: batch 342/486 in epoch 1128, batch loss: 1.64279, batch accuracy: 0.55050
Time: 2018-07-15 09:28:37
TRAINING STATS: batch 392/486 in epoch 1128, batch loss: 1.58246, batch accuracy: 0.57250
Time: 2018-07-15 09:28:42
TRAINING STATS: batch 442/486 in epoch 1128, batch loss: 1.58918, batch accuracy: 0.57550
Time: 2018-07-15 09:28:46
TRAINING STATS: batch 6/486 in epoch 1129,   batch loss: 1.70007, batch accuracy: 0.54050
Time: 2018-07-15 09:28:49
TRAINING STATS: batch 56/486 in epoch 1129,  batch loss: 1.63545, batch accuracy: 0.55583
Time: 2018-07-15 09:28:54
TRAINING STATS: batch 106/486 in epoch 1129, batch loss: 1.73205, batch accuracy: 0.53033
Time: 2018-07-15 09:28:58
TRAINING STATS: batch 156/486 in epoch 1129, batch loss: 1.73703, batch accuracy: 0.52617
Time: 2018-07-15 09:29:01
TRAINING STATS: batch 206/486 in epoch 1129, batch loss: 1.77521, batch accuracy: 0.51683
Time: 2018-07-15 09:29:06
TRAINING STATS: batch 256/486 in epoch 1129, batch loss: 1.59891, batch accuracy: 0.56417
Time: 2018-07-15 09:29:10
TRAINING STATS: batch 306/486 in epoch 1129, batch loss: 1.65739, batch accuracy: 0.55250
Time: 2018-07-15 09:29:13
TRAINING STATS: batch 356/486 in epoch 1129, batch loss: 1.69304, batch accuracy: 0.53767
Time: 2018-07-15 09:29:18
TRAINING STATS: batch 406/486 in epoch 1129, batch loss: 1.73962, batch accuracy: 0.51933
Time: 2018-07-15 09:29:22
TRAINING STATS: batch 456/486 in epoch 1129, batch loss: 1.54675, batch accuracy: 0.58533
Time: 2018-07-15 09:29:26
TRAINING STATS: batch 20/486 in epoch 1130,  batch loss: 1.66232, batch accuracy: 0.55083
Time: 2018-07-15 09:29:30
TRAINING STATS: batch 70/486 in epoch 1130,  batch loss: 1.54999, batch accuracy: 0.58183
Time: 2018-07-15 09:29:34
TRAINING STATS: batch 120/486 in epoch 1130, batch loss: 1.62583, batch accuracy: 0.55467
Time: 2018-07-15 09:29:38
TRAINING STATS: batch 170/486 in epoch 1130, batch loss: 1.66977, batch accuracy: 0.54433
Time: 2018-07-15 09:29:42
TRAINING STATS: batch 220/486 in epoch 1130, batch loss: 1.58536, batch accuracy: 0.56800
Time: 2018-07-15 09:29:46
TRAINING STATS: batch 270/486 in epoch 1130, batch loss: 1.67617, batch accuracy: 0.53450
Time: 2018-07-15 09:29:50
TRAINING STATS: batch 320/486 in epoch 1130, batch loss: 1.60862, batch accuracy: 0.55667
Time: 2018-07-15 09:29:54
TRAINING STATS: batch 370/486 in epoch 1130, batch loss: 1.67035, batch accuracy: 0.55567
Time: 2018-07-15 09:29:58
TRAINING STATS: batch 420/486 in epoch 1130, batch loss: 1.71350, batch accuracy: 0.53500
Time: 2018-07-15 09:30:02
TRAINING STATS: batch 470/486 in epoch 1130, batch loss: 1.74428, batch accuracy: 0.52150
Time: 2018-07-15 09:30:07
TRAINING STATS: batch 34/486 in epoch 1131,  batch loss: 1.67961, batch accuracy: 0.54683
Time: 2018-07-15 09:30:10
TRAINING STATS: batch 84/486 in epoch 1131,  batch loss: 1.69077, batch accuracy: 0.53367
Time: 2018-07-15 09:30:14
TRAINING STATS: batch 134/486 in epoch 1131, batch loss: 1.87844, batch accuracy: 0.49550
Time: 2018-07-15 09:30:19
TRAINING STATS: batch 184/486 in epoch 1131, batch loss: 1.77765, batch accuracy: 0.51467
Time: 2018-07-15 09:30:22
TRAINING STATS: batch 234/486 in epoch 1131, batch loss: 1.74975, batch accuracy: 0.52933
Time: 2018-07-15 09:30:26
TRAINING STATS: batch 284/486 in epoch 1131, batch loss: 1.73140, batch accuracy: 0.52900
Time: 2018-07-15 09:30:31
TRAINING STATS: batch 334/486 in epoch 1131, batch loss: 1.65708, batch accuracy: 0.54967
Time: 2018-07-15 09:30:34
TRAINING STATS: batch 384/486 in epoch 1131, batch loss: 1.63440, batch accuracy: 0.55533
Time: 2018-07-15 09:30:38
TRAINING STATS: batch 434/486 in epoch 1131, batch loss: 1.72254, batch accuracy: 0.52650
Time: 2018-07-15 09:30:43
TRAINING STATS: batch 484/486 in epoch 1131, batch loss: 1.68453, batch accuracy: 0.53683
Time: 2018-07-15 09:30:47
TRAINING STATS: batch 48/486 in epoch 1132,  batch loss: 1.67113, batch accuracy: 0.53850
Time: 2018-07-15 09:30:50
TRAINING STATS: batch 98/486 in epoch 1132,  batch loss: 1.65921, batch accuracy: 0.55550
Time: 2018-07-15 09:30:55
TRAINING STATS: batch 148/486 in epoch 1132, batch loss: 1.69376, batch accuracy: 0.54367
Time: 2018-07-15 09:30:59
TRAINING STATS: batch 198/486 in epoch 1132, batch loss: 1.64654, batch accuracy: 0.55117
Time: 2018-07-15 09:31:02
TRAINING STATS: batch 248/486 in epoch 1132, batch loss: 1.69160, batch accuracy: 0.53900
Time: 2018-07-15 09:31:07
TRAINING STATS: batch 298/486 in epoch 1132, batch loss: 1.68948, batch accuracy: 0.53767
Time: 2018-07-15 09:31:11
TRAINING STATS: batch 348/486 in epoch 1132, batch loss: 1.66829, batch accuracy: 0.54967
Time: 2018-07-15 09:31:14
TRAINING STATS: batch 398/486 in epoch 1132, batch loss: 1.67755, batch accuracy: 0.54033
Time: 2018-07-15 09:31:19
TRAINING STATS: batch 448/486 in epoch 1132, batch loss: 1.65551, batch accuracy: 0.55217
Time: 2018-07-15 09:31:23
TRAINING STATS: batch 12/486 in epoch 1133,  batch loss: 1.67301, batch accuracy: 0.54400
Time: 2018-07-15 09:31:27
TRAINING STATS: batch 62/486 in epoch 1133,  batch loss: 1.79135, batch accuracy: 0.50667
Time: 2018-07-15 09:31:31
TRAINING STATS: batch 112/486 in epoch 1133, batch loss: 1.68029, batch accuracy: 0.54533
Time: 2018-07-15 09:31:35
TRAINING STATS: batch 162/486 in epoch 1133, batch loss: 1.68057, batch accuracy: 0.54517
Time: 2018-07-15 09:31:39
TRAINING STATS: batch 212/486 in epoch 1133, batch loss: 1.57880, batch accuracy: 0.57017
Time: 2018-07-15 09:31:43
TRAINING STATS: batch 262/486 in epoch 1133, batch loss: 1.81664, batch accuracy: 0.50833
Time: 2018-07-15 09:31:47
TRAINING STATS: batch 312/486 in epoch 1133, batch loss: 1.67681, batch accuracy: 0.53467
Time: 2018-07-15 09:31:51
TRAINING STATS: batch 362/486 in epoch 1133, batch loss: 1.66360, batch accuracy: 0.54417
Time: 2018-07-15 09:31:55
TRAINING STATS: batch 412/486 in epoch 1133, batch loss: 1.60452, batch accuracy: 0.56750
Time: 2018-07-15 09:31:59
TRAINING STATS: batch 462/486 in epoch 1133, batch loss: 1.66468, batch accuracy: 0.54533
Time: 2018-07-15 09:32:03
TRAINING STATS: batch 26/486 in epoch 1134,  batch loss: 1.70724, batch accuracy: 0.53600
Time: 2018-07-15 09:32:08
TRAINING STATS: batch 76/486 in epoch 1134,  batch loss: 1.72441, batch accuracy: 0.53533
Time: 2018-07-15 09:32:11
TRAINING STATS: batch 126/486 in epoch 1134, batch loss: 1.70268, batch accuracy: 0.53583
Time: 2018-07-15 09:32:15
TRAINING STATS: batch 176/486 in epoch 1134, batch loss: 1.59017, batch accuracy: 0.56617
Time: 2018-07-15 09:32:20
TRAINING STATS: batch 226/486 in epoch 1134, batch loss: 1.65601, batch accuracy: 0.55317
Time: 2018-07-15 09:32:23
TRAINING STATS: batch 276/486 in epoch 1134, batch loss: 1.66215, batch accuracy: 0.55150
Time: 2018-07-15 09:32:27
TRAINING STATS: batch 326/486 in epoch 1134, batch loss: 1.69655, batch accuracy: 0.54283
Time: 2018-07-15 09:32:32
TRAINING STATS: batch 376/486 in epoch 1134, batch loss: 1.69234, batch accuracy: 0.54200
Time: 2018-07-15 09:32:35
TRAINING STATS: batch 426/486 in epoch 1134, batch loss: 1.64322, batch accuracy: 0.54100
Time: 2018-07-15 09:32:39
TRAINING STATS: batch 476/486 in epoch 1134, batch loss: 1.59191, batch accuracy: 0.56800
Time: 2018-07-15 09:32:44
TRAINING STATS: batch 40/486 in epoch 1135,  batch loss: 1.63280, batch accuracy: 0.55650
Time: 2018-07-15 09:32:48
TRAINING STATS: batch 90/486 in epoch 1135,  batch loss: 1.70340, batch accuracy: 0.54117
Time: 2018-07-15 09:32:51
TRAINING STATS: batch 140/486 in epoch 1135, batch loss: 1.61930, batch accuracy: 0.55867
Time: 2018-07-15 09:32:56
TRAINING STATS: batch 190/486 in epoch 1135, batch loss: 1.65152, batch accuracy: 0.55217
Time: 2018-07-15 09:32:59
TRAINING STATS: batch 240/486 in epoch 1135, batch loss: 1.62350, batch accuracy: 0.55600
Time: 2018-07-15 09:33:03
TRAINING STATS: batch 290/486 in epoch 1135, batch loss: 1.69629, batch accuracy: 0.53550
Time: 2018-07-15 09:33:08
TRAINING STATS: batch 340/486 in epoch 1135, batch loss: 1.74410, batch accuracy: 0.52200
Time: 2018-07-15 09:33:12
TRAINING STATS: batch 390/486 in epoch 1135, batch loss: 1.58797, batch accuracy: 0.57250
Time: 2018-07-15 09:33:15
TRAINING STATS: batch 440/486 in epoch 1135, batch loss: 1.66313, batch accuracy: 0.55117
Time: 2018-07-15 09:33:20
TRAINING STATS: batch 4/486 in epoch 1136,   batch loss: 1.61769, batch accuracy: 0.55967
Time: 2018-07-15 09:33:24
TRAINING STATS: batch 54/486 in epoch 1136,  batch loss: 1.68726, batch accuracy: 0.54517
Time: 2018-07-15 09:33:27
TRAINING STATS: batch 104/486 in epoch 1136, batch loss: 1.68360, batch accuracy: 0.54600
Time: 2018-07-15 09:33:32
TRAINING STATS: batch 154/486 in epoch 1136, batch loss: 1.64766, batch accuracy: 0.55867
Time: 2018-07-15 09:33:36
TRAINING STATS: batch 204/486 in epoch 1136, batch loss: 1.74549, batch accuracy: 0.52667
Time: 2018-07-15 09:33:40
TRAINING STATS: batch 254/486 in epoch 1136, batch loss: 1.58849, batch accuracy: 0.56883
Time: 2018-07-15 09:33:44
TRAINING STATS: batch 304/486 in epoch 1136, batch loss: 1.60798, batch accuracy: 0.56733
Time: 2018-07-15 09:33:48
TRAINING STATS: batch 354/486 in epoch 1136, batch loss: 1.66270, batch accuracy: 0.54867
Time: 2018-07-15 09:33:51
TRAINING STATS: batch 404/486 in epoch 1136, batch loss: 1.64880, batch accuracy: 0.55117
Time: 2018-07-15 09:33:56
TRAINING STATS: batch 454/486 in epoch 1136, batch loss: 1.51638, batch accuracy: 0.59217
Time: 2018-07-15 09:34:00
TRAINING STATS: batch 18/486 in epoch 1137,  batch loss: 1.68815, batch accuracy: 0.54133
Time: 2018-07-15 09:34:04
TRAINING STATS: batch 68/486 in epoch 1137,  batch loss: 1.50331, batch accuracy: 0.59583
Time: 2018-07-15 09:34:08
TRAINING STATS: batch 118/486 in epoch 1137, batch loss: 1.64378, batch accuracy: 0.55617
Time: 2018-07-15 09:34:12
TRAINING STATS: batch 168/486 in epoch 1137, batch loss: 1.57045, batch accuracy: 0.58150
Time: 2018-07-15 09:34:16
TRAINING STATS: batch 218/486 in epoch 1137, batch loss: 1.66653, batch accuracy: 0.55067
Time: 2018-07-15 09:34:21
TRAINING STATS: batch 268/486 in epoch 1137, batch loss: 2.00058, batch accuracy: 0.44650
Time: 2018-07-15 09:34:24
TRAINING STATS: batch 318/486 in epoch 1137, batch loss: 1.92713, batch accuracy: 0.47317
Time: 2018-07-15 09:34:28
TRAINING STATS: batch 368/486 in epoch 1137, batch loss: 1.91516, batch accuracy: 0.49450
Time: 2018-07-15 09:34:33
TRAINING STATS: batch 418/486 in epoch 1137, batch loss: 1.89756, batch accuracy: 0.48600
Time: 2018-07-15 09:34:36
TRAINING STATS: batch 468/486 in epoch 1137, batch loss: 1.79414, batch accuracy: 0.51933
Time: 2018-07-15 09:34:40
TRAINING STATS: batch 32/486 in epoch 1138,  batch loss: 1.69849, batch accuracy: 0.54200
Time: 2018-07-15 09:34:45
TRAINING STATS: batch 82/486 in epoch 1138,  batch loss: 1.79376, batch accuracy: 0.52400
Time: 2018-07-15 09:34:48
TRAINING STATS: batch 132/486 in epoch 1138, batch loss: 1.75498, batch accuracy: 0.54000
Time: 2018-07-15 09:34:52
TRAINING STATS: batch 182/486 in epoch 1138, batch loss: 1.80439, batch accuracy: 0.51933
Time: 2018-07-15 09:34:57
TRAINING STATS: batch 232/486 in epoch 1138, batch loss: 1.76619, batch accuracy: 0.53017
Time: 2018-07-15 09:35:01
TRAINING STATS: batch 282/486 in epoch 1138, batch loss: 1.74311, batch accuracy: 0.52583
Time: 2018-07-15 09:35:04
TRAINING STATS: batch 332/486 in epoch 1138, batch loss: 1.78589, batch accuracy: 0.51600
Time: 2018-07-15 09:35:09
TRAINING STATS: batch 382/486 in epoch 1138, batch loss: 1.75036, batch accuracy: 0.52750
Time: 2018-07-15 09:35:13
TRAINING STATS: batch 432/486 in epoch 1138, batch loss: 1.68824, batch accuracy: 0.54433
Time: 2018-07-15 09:35:16
TRAINING STATS: batch 482/486 in epoch 1138, batch loss: 1.72995, batch accuracy: 0.53317
Time: 2018-07-15 09:35:21
TRAINING STATS: batch 46/486 in epoch 1139,  batch loss: 1.70041, batch accuracy: 0.54767
Time: 2018-07-15 09:35:25
TRAINING STATS: batch 96/486 in epoch 1139,  batch loss: 1.77295, batch accuracy: 0.52183
Time: 2018-07-15 09:35:28
TRAINING STATS: batch 146/486 in epoch 1139, batch loss: 1.77389, batch accuracy: 0.52533
Time: 2018-07-15 09:35:33
TRAINING STATS: batch 196/486 in epoch 1139, batch loss: 1.76152, batch accuracy: 0.52200
Time: 2018-07-15 09:35:37
TRAINING STATS: batch 246/486 in epoch 1139, batch loss: 1.69686, batch accuracy: 0.54850
Time: 2018-07-15 09:35:40
TRAINING STATS: batch 296/486 in epoch 1139, batch loss: 1.68704, batch accuracy: 0.54417
Time: 2018-07-15 09:35:45
TRAINING STATS: batch 346/486 in epoch 1139, batch loss: 1.64725, batch accuracy: 0.56217
Time: 2018-07-15 09:35:49
TRAINING STATS: batch 396/486 in epoch 1139, batch loss: 1.72306, batch accuracy: 0.54200
Time: 2018-07-15 09:35:52
TRAINING STATS: batch 446/486 in epoch 1139, batch loss: 1.73278, batch accuracy: 0.53933
Time: 2018-07-15 09:35:57
TRAINING STATS: batch 10/486 in epoch 1140,  batch loss: 1.76096, batch accuracy: 0.52483
Time: 2018-07-15 09:36:01
TRAINING STATS: batch 60/486 in epoch 1140,  batch loss: 1.72042, batch accuracy: 0.53400
Time: 2018-07-15 09:36:05
TRAINING STATS: batch 110/486 in epoch 1140, batch loss: 1.77767, batch accuracy: 0.52067
Time: 2018-07-15 09:36:09
TRAINING STATS: batch 160/486 in epoch 1140, batch loss: 1.68158, batch accuracy: 0.53933
Time: 2018-07-15 09:36:13
TRAINING STATS: batch 210/486 in epoch 1140, batch loss: 1.66452, batch accuracy: 0.55533
Time: 2018-07-15 09:36:17
TRAINING STATS: batch 260/486 in epoch 1140, batch loss: 1.75619, batch accuracy: 0.52933
Time: 2018-07-15 09:36:21
TRAINING STATS: batch 310/486 in epoch 1140, batch loss: 1.76774, batch accuracy: 0.52567
Time: 2018-07-15 09:36:25
TRAINING STATS: batch 360/486 in epoch 1140, batch loss: 1.74277, batch accuracy: 0.53233
Time: 2018-07-15 09:36:29
TRAINING STATS: batch 410/486 in epoch 1140, batch loss: 1.68722, batch accuracy: 0.54483
Time: 2018-07-15 09:36:34
TRAINING STATS: batch 460/486 in epoch 1140, batch loss: 1.86113, batch accuracy: 0.48983
Time: 2018-07-15 09:36:37
TRAINING STATS: batch 24/486 in epoch 1141,  batch loss: 1.77966, batch accuracy: 0.53000
Time: 2018-07-15 09:36:41
TRAINING STATS: batch 74/486 in epoch 1141,  batch loss: 1.75478, batch accuracy: 0.53617
Time: 2018-07-15 09:36:46
TRAINING STATS: batch 124/486 in epoch 1141, batch loss: 1.75937, batch accuracy: 0.53383
Time: 2018-07-15 09:36:49
TRAINING STATS: batch 174/486 in epoch 1141, batch loss: 1.78998, batch accuracy: 0.51800
Time: 2018-07-15 09:36:53
TRAINING STATS: batch 224/486 in epoch 1141, batch loss: 1.75746, batch accuracy: 0.52850
Time: 2018-07-15 09:36:58
TRAINING STATS: batch 274/486 in epoch 1141, batch loss: 1.72143, batch accuracy: 0.53683
Time: 2018-07-15 09:37:01
TRAINING STATS: batch 324/486 in epoch 1141, batch loss: 1.76143, batch accuracy: 0.53167
Time: 2018-07-15 09:37:05
TRAINING STATS: batch 374/486 in epoch 1141, batch loss: 1.76129, batch accuracy: 0.52800
Time: 2018-07-15 09:37:10
TRAINING STATS: batch 424/486 in epoch 1141, batch loss: 1.67013, batch accuracy: 0.55133
Time: 2018-07-15 09:37:14
TRAINING STATS: batch 474/486 in epoch 1141, batch loss: 1.81386, batch accuracy: 0.51883
Time: 2018-07-15 09:37:17
TRAINING STATS: batch 38/486 in epoch 1142,  batch loss: 1.79083, batch accuracy: 0.52183
Time: 2018-07-15 09:37:22
TRAINING STATS: batch 88/486 in epoch 1142,  batch loss: 1.79269, batch accuracy: 0.51500
Time: 2018-07-15 09:37:26
TRAINING STATS: batch 138/486 in epoch 1142, batch loss: 1.76622, batch accuracy: 0.52217
Time: 2018-07-15 09:37:30
TRAINING STATS: batch 188/486 in epoch 1142, batch loss: 1.66086, batch accuracy: 0.55633
Time: 2018-07-15 09:37:34
TRAINING STATS: batch 238/486 in epoch 1142, batch loss: 1.70944, batch accuracy: 0.54400
Time: 2018-07-15 09:37:38
TRAINING STATS: batch 288/486 in epoch 1142, batch loss: 1.72614, batch accuracy: 0.53383
Time: 2018-07-15 09:37:42
TRAINING STATS: batch 338/486 in epoch 1142, batch loss: 1.71873, batch accuracy: 0.53533
Time: 2018-07-15 09:37:46
TRAINING STATS: batch 388/486 in epoch 1142, batch loss: 1.69659, batch accuracy: 0.54883
Time: 2018-07-15 09:37:50
TRAINING STATS: batch 438/486 in epoch 1142, batch loss: 1.73349, batch accuracy: 0.53717
Time: 2018-07-15 09:37:54
TRAINING STATS: batch 2/486 in epoch 1143,   batch loss: 1.73295, batch accuracy: 0.53583
Time: 2018-07-15 09:37:58
TRAINING STATS: batch 52/486 in epoch 1143,  batch loss: 1.81988, batch accuracy: 0.50600
Time: 2018-07-15 09:38:02
TRAINING STATS: batch 102/486 in epoch 1143, batch loss: 1.75395, batch accuracy: 0.52883
Time: 2018-07-15 09:38:06
TRAINING STATS: batch 152/486 in epoch 1143, batch loss: 1.70129, batch accuracy: 0.54383
Time: 2018-07-15 09:38:11
TRAINING STATS: batch 202/486 in epoch 1143, batch loss: 1.73042, batch accuracy: 0.52883
Time: 2018-07-15 09:38:14
TRAINING STATS: batch 252/486 in epoch 1143, batch loss: 1.70333, batch accuracy: 0.53750
Time: 2018-07-15 09:38:18
TRAINING STATS: batch 302/486 in epoch 1143, batch loss: 1.71151, batch accuracy: 0.53433
Time: 2018-07-15 09:38:23
TRAINING STATS: batch 352/486 in epoch 1143, batch loss: 1.73762, batch accuracy: 0.53383
Time: 2018-07-15 09:38:26
TRAINING STATS: batch 402/486 in epoch 1143, batch loss: 1.60618, batch accuracy: 0.57600
Time: 2018-07-15 09:38:30
TRAINING STATS: batch 452/486 in epoch 1143, batch loss: 1.74140, batch accuracy: 0.52767
Time: 2018-07-15 09:38:35
TRAINING STATS: batch 16/486 in epoch 1144,  batch loss: 1.68034, batch accuracy: 0.55650
Time: 2018-07-15 09:38:38
TRAINING STATS: batch 66/486 in epoch 1144,  batch loss: 1.75456, batch accuracy: 0.52517
Time: 2018-07-15 09:38:42
TRAINING STATS: batch 116/486 in epoch 1144, batch loss: 1.70317, batch accuracy: 0.54133
Time: 2018-07-15 09:38:47
TRAINING STATS: batch 166/486 in epoch 1144, batch loss: 1.67047, batch accuracy: 0.54567
Time: 2018-07-15 09:38:50
TRAINING STATS: batch 216/486 in epoch 1144, batch loss: 1.73534, batch accuracy: 0.53433
Time: 2018-07-15 09:38:54
TRAINING STATS: batch 266/486 in epoch 1144, batch loss: 1.75838, batch accuracy: 0.52117
Time: 2018-07-15 09:38:59
TRAINING STATS: batch 316/486 in epoch 1144, batch loss: 1.74322, batch accuracy: 0.53717
Time: 2018-07-15 09:39:02
TRAINING STATS: batch 366/486 in epoch 1144, batch loss: 1.80701, batch accuracy: 0.51683
Time: 2018-07-15 09:39:06
TRAINING STATS: batch 416/486 in epoch 1144, batch loss: 1.78822, batch accuracy: 0.51150
Time: 2018-07-15 09:39:11
TRAINING STATS: batch 466/486 in epoch 1144, batch loss: 1.56935, batch accuracy: 0.57667
Time: 2018-07-15 09:39:14
TRAINING STATS: batch 30/486 in epoch 1145,  batch loss: 1.59664, batch accuracy: 0.56700
Time: 2018-07-15 09:39:18
TRAINING STATS: batch 80/486 in epoch 1145,  batch loss: 1.70031, batch accuracy: 0.53083
Time: 2018-07-15 09:39:23
TRAINING STATS: batch 130/486 in epoch 1145, batch loss: 1.68971, batch accuracy: 0.54900
Time: 2018-07-15 09:39:27
TRAINING STATS: batch 180/486 in epoch 1145, batch loss: 1.73311, batch accuracy: 0.53400
Time: 2018-07-15 09:39:30
TRAINING STATS: batch 230/486 in epoch 1145, batch loss: 1.71535, batch accuracy: 0.53250
Time: 2018-07-15 09:39:35
TRAINING STATS: batch 280/486 in epoch 1145, batch loss: 1.67157, batch accuracy: 0.54100
Time: 2018-07-15 09:39:39
TRAINING STATS: batch 330/486 in epoch 1145, batch loss: 1.68702, batch accuracy: 0.54383
Time: 2018-07-15 09:39:42
TRAINING STATS: batch 380/486 in epoch 1145, batch loss: 1.65365, batch accuracy: 0.54900
Time: 2018-07-15 09:39:47
TRAINING STATS: batch 430/486 in epoch 1145, batch loss: 1.63602, batch accuracy: 0.55850
Time: 2018-07-15 09:39:51
TRAINING STATS: batch 480/486 in epoch 1145, batch loss: 1.67887, batch accuracy: 0.54750
Time: 2018-07-15 09:39:54
TRAINING STATS: batch 44/486 in epoch 1146,  batch loss: 1.61647, batch accuracy: 0.55567
Time: 2018-07-15 09:39:59
TRAINING STATS: batch 94/486 in epoch 1146,  batch loss: 1.72797, batch accuracy: 0.53233
Time: 2018-07-15 09:40:03
TRAINING STATS: batch 144/486 in epoch 1146, batch loss: 1.74304, batch accuracy: 0.52900
Time: 2018-07-15 09:40:07
TRAINING STATS: batch 194/486 in epoch 1146, batch loss: 1.77233, batch accuracy: 0.50850
Time: 2018-07-15 09:40:11
TRAINING STATS: batch 244/486 in epoch 1146, batch loss: 1.65961, batch accuracy: 0.55267
Time: 2018-07-15 09:40:15
TRAINING STATS: batch 294/486 in epoch 1146, batch loss: 1.58227, batch accuracy: 0.57183
Time: 2018-07-15 09:40:19
TRAINING STATS: batch 344/486 in epoch 1146, batch loss: 1.66898, batch accuracy: 0.54917
Time: 2018-07-15 09:40:23
TRAINING STATS: batch 394/486 in epoch 1146, batch loss: 1.62867, batch accuracy: 0.56700
Time: 2018-07-15 09:40:27
TRAINING STATS: batch 444/486 in epoch 1146, batch loss: 1.61386, batch accuracy: 0.57133
Time: 2018-07-15 09:40:31
TRAINING STATS: batch 8/486 in epoch 1147,   batch loss: 1.69192, batch accuracy: 0.54033
Time: 2018-07-15 09:40:35
TRAINING STATS: batch 58/486 in epoch 1147,  batch loss: 1.63856, batch accuracy: 0.55617
Time: 2018-07-15 09:40:39
TRAINING STATS: batch 108/486 in epoch 1147, batch loss: 1.75353, batch accuracy: 0.52700
Time: 2018-07-15 09:40:43
TRAINING STATS: batch 158/486 in epoch 1147, batch loss: 1.73318, batch accuracy: 0.53233
Time: 2018-07-15 09:40:48
TRAINING STATS: batch 208/486 in epoch 1147, batch loss: 1.69242, batch accuracy: 0.53667
Time: 2018-07-15 09:40:51
TRAINING STATS: batch 258/486 in epoch 1147, batch loss: 1.61747, batch accuracy: 0.56550
Time: 2018-07-15 09:40:55
TRAINING STATS: batch 308/486 in epoch 1147, batch loss: 1.67972, batch accuracy: 0.55133
Time: 2018-07-15 09:41:00
TRAINING STATS: batch 358/486 in epoch 1147, batch loss: 1.68401, batch accuracy: 0.54433
Time: 2018-07-15 09:41:03
TRAINING STATS: batch 408/486 in epoch 1147, batch loss: 1.73508, batch accuracy: 0.52117
Time: 2018-07-15 09:41:07
TRAINING STATS: batch 458/486 in epoch 1147, batch loss: 1.71023, batch accuracy: 0.54017
Time: 2018-07-15 09:41:12
TRAINING STATS: batch 22/486 in epoch 1148,  batch loss: 1.71288, batch accuracy: 0.54683
Time: 2018-07-15 09:41:15
TRAINING STATS: batch 72/486 in epoch 1148,  batch loss: 1.68860, batch accuracy: 0.54567
Time: 2018-07-15 09:41:19
TRAINING STATS: batch 122/486 in epoch 1148, batch loss: 1.62942, batch accuracy: 0.55867
Time: 2018-07-15 09:41:24
TRAINING STATS: batch 172/486 in epoch 1148, batch loss: 1.73319, batch accuracy: 0.53133
Time: 2018-07-15 09:41:27
TRAINING STATS: batch 222/486 in epoch 1148, batch loss: 1.70065, batch accuracy: 0.53033
Time: 2018-07-15 09:41:31
TRAINING STATS: batch 272/486 in epoch 1148, batch loss: 1.71034, batch accuracy: 0.53150
Time: 2018-07-15 09:41:36
TRAINING STATS: batch 322/486 in epoch 1148, batch loss: 1.66131, batch accuracy: 0.54717
Time: 2018-07-15 09:41:40
TRAINING STATS: batch 372/486 in epoch 1148, batch loss: 1.63771, batch accuracy: 0.55350
Time: 2018-07-15 09:41:43
TRAINING STATS: batch 422/486 in epoch 1148, batch loss: 1.65031, batch accuracy: 0.54833
Time: 2018-07-15 09:41:48
TRAINING STATS: batch 472/486 in epoch 1148, batch loss: 1.72185, batch accuracy: 0.53733
Time: 2018-07-15 09:41:51
TRAINING STATS: batch 36/486 in epoch 1149,  batch loss: 1.90425, batch accuracy: 0.48033
Time: 2018-07-15 09:41:55
TRAINING STATS: batch 86/486 in epoch 1149,  batch loss: 1.70752, batch accuracy: 0.53950
Time: 2018-07-15 09:42:00
TRAINING STATS: batch 136/486 in epoch 1149, batch loss: 1.73156, batch accuracy: 0.52500
Time: 2018-07-15 09:42:04
TRAINING STATS: batch 186/486 in epoch 1149, batch loss: 1.68521, batch accuracy: 0.54483
Time: 2018-07-15 09:42:07
TRAINING STATS: batch 236/486 in epoch 1149, batch loss: 1.71164, batch accuracy: 0.52983
Time: 2018-07-15 09:42:12
TRAINING STATS: batch 286/486 in epoch 1149, batch loss: 1.72094, batch accuracy: 0.53600
Time: 2018-07-15 09:42:16
TRAINING STATS: batch 336/486 in epoch 1149, batch loss: 1.66690, batch accuracy: 0.54767
Time: 2018-07-15 09:42:19
TRAINING STATS: batch 386/486 in epoch 1149, batch loss: 1.71071, batch accuracy: 0.53200
Time: 2018-07-15 09:42:24
TRAINING STATS: batch 436/486 in epoch 1149, batch loss: 1.69147, batch accuracy: 0.53800
Time: 2018-07-15 09:42:28
TRAINING STATS: batch 0/486 in epoch 1150,   batch loss: 1.65727, batch accuracy: 0.54833
Time: 2018-07-15 09:42:31
TRAINING STATS: batch 50/486 in epoch 1150,  batch loss: 1.64968, batch accuracy: 0.55467
Time: 2018-07-15 09:42:36
TRAINING STATS: batch 100/486 in epoch 1150, batch loss: 1.68519, batch accuracy: 0.54600
Time: 2018-07-15 09:42:40
TRAINING STATS: batch 150/486 in epoch 1150, batch loss: 1.63350, batch accuracy: 0.56817
Time: 2018-07-15 09:42:44
TRAINING STATS: batch 200/486 in epoch 1150, batch loss: 1.56553, batch accuracy: 0.57283
Time: 2018-07-15 09:42:48
TRAINING STATS: batch 250/486 in epoch 1150, batch loss: 1.71597, batch accuracy: 0.52517
Time: 2018-07-15 09:42:52
TRAINING STATS: batch 300/486 in epoch 1150, batch loss: 1.71669, batch accuracy: 0.53417
Time: 2018-07-15 09:42:56
TRAINING STATS: batch 350/486 in epoch 1150, batch loss: 1.67829, batch accuracy: 0.55083
Time: 2018-07-15 09:43:00
TRAINING STATS: batch 400/486 in epoch 1150, batch loss: 1.55664, batch accuracy: 0.57650
Time: 2018-07-15 09:43:04
TRAINING STATS: batch 450/486 in epoch 1150, batch loss: 1.73106, batch accuracy: 0.52283
Time: 2018-07-15 09:43:08
TRAINING STATS: batch 14/486 in epoch 1151,  batch loss: 1.59608, batch accuracy: 0.57250
Time: 2018-07-15 09:43:12
TRAINING STATS: batch 64/486 in epoch 1151,  batch loss: 1.76157, batch accuracy: 0.52533
Time: 2018-07-15 09:43:16
TRAINING STATS: batch 114/486 in epoch 1151, batch loss: 1.70169, batch accuracy: 0.54267
Time: 2018-07-15 09:43:20
TRAINING STATS: batch 164/486 in epoch 1151, batch loss: 1.61172, batch accuracy: 0.56833
Time: 2018-07-15 09:43:25
TRAINING STATS: batch 214/486 in epoch 1151, batch loss: 1.67248, batch accuracy: 0.54100
Time: 2018-07-15 09:43:28
TRAINING STATS: batch 264/486 in epoch 1151, batch loss: 1.70961, batch accuracy: 0.53433
Time: 2018-07-15 09:43:32
TRAINING STATS: batch 314/486 in epoch 1151, batch loss: 1.74641, batch accuracy: 0.52517
Time: 2018-07-15 09:43:37
TRAINING STATS: batch 364/486 in epoch 1151, batch loss: 1.64546, batch accuracy: 0.55733
Time: 2018-07-15 09:43:40
TRAINING STATS: batch 414/486 in epoch 1151, batch loss: 1.60824, batch accuracy: 0.56350
Time: 2018-07-15 09:43:44
TRAINING STATS: batch 464/486 in epoch 1151, batch loss: 1.64818, batch accuracy: 0.55500
Time: 2018-07-15 09:43:49
TRAINING STATS: batch 28/486 in epoch 1152,  batch loss: 1.61024, batch accuracy: 0.56433
Time: 2018-07-15 09:43:52
TRAINING STATS: batch 78/486 in epoch 1152,  batch loss: 1.71860, batch accuracy: 0.53833
Time: 2018-07-15 09:43:56
TRAINING STATS: batch 128/486 in epoch 1152, batch loss: 1.65496, batch accuracy: 0.55300
Time: 2018-07-15 09:44:01
TRAINING STATS: batch 178/486 in epoch 1152, batch loss: 1.57897, batch accuracy: 0.56967
Time: 2018-07-15 09:44:05
TRAINING STATS: batch 228/486 in epoch 1152, batch loss: 1.62089, batch accuracy: 0.55750
Time: 2018-07-15 09:44:08
TRAINING STATS: batch 278/486 in epoch 1152, batch loss: 1.59390, batch accuracy: 0.56867
Time: 2018-07-15 09:44:13
TRAINING STATS: batch 328/486 in epoch 1152, batch loss: 1.63664, batch accuracy: 0.55733
Time: 2018-07-15 09:44:17
TRAINING STATS: batch 378/486 in epoch 1152, batch loss: 1.64960, batch accuracy: 0.55367
Time: 2018-07-15 09:44:20
TRAINING STATS: batch 428/486 in epoch 1152, batch loss: 1.70136, batch accuracy: 0.53617
Time: 2018-07-15 09:44:25
TRAINING STATS: batch 478/486 in epoch 1152, batch loss: 1.72060, batch accuracy: 0.53233
Time: 2018-07-15 09:44:29
TRAINING STATS: batch 42/486 in epoch 1153,  batch loss: 1.58950, batch accuracy: 0.56600
Time: 2018-07-15 09:44:32
TRAINING STATS: batch 92/486 in epoch 1153,  batch loss: 1.67527, batch accuracy: 0.54567
Time: 2018-07-15 09:44:37
TRAINING STATS: batch 142/486 in epoch 1153, batch loss: 1.63247, batch accuracy: 0.56050
Time: 2018-07-15 09:44:41
TRAINING STATS: batch 192/486 in epoch 1153, batch loss: 1.68177, batch accuracy: 0.54567
Time: 2018-07-15 09:44:45
TRAINING STATS: batch 242/486 in epoch 1153, batch loss: 1.63370, batch accuracy: 0.55800
Time: 2018-07-15 09:44:49
TRAINING STATS: batch 292/486 in epoch 1153, batch loss: 1.66024, batch accuracy: 0.54467
Time: 2018-07-15 09:44:53
TRAINING STATS: batch 342/486 in epoch 1153, batch loss: 1.62318, batch accuracy: 0.55350
Time: 2018-07-15 09:44:57
TRAINING STATS: batch 392/486 in epoch 1153, batch loss: 1.57426, batch accuracy: 0.57400
Time: 2018-07-15 09:45:01
TRAINING STATS: batch 442/486 in epoch 1153, batch loss: 1.57095, batch accuracy: 0.57667
Time: 2018-07-15 09:45:05
TRAINING STATS: batch 6/486 in epoch 1154,   batch loss: 1.71431, batch accuracy: 0.54133
Time: 2018-07-15 09:45:09
TRAINING STATS: batch 56/486 in epoch 1154,  batch loss: 1.63491, batch accuracy: 0.54917
Time: 2018-07-15 09:45:13
TRAINING STATS: batch 106/486 in epoch 1154, batch loss: 1.72096, batch accuracy: 0.53233
Time: 2018-07-15 09:45:17
TRAINING STATS: batch 156/486 in epoch 1154, batch loss: 1.72221, batch accuracy: 0.53567
Time: 2018-07-15 09:45:21
TRAINING STATS: batch 206/486 in epoch 1154, batch loss: 1.74837, batch accuracy: 0.52283
Time: 2018-07-15 09:45:26
TRAINING STATS: batch 256/486 in epoch 1154, batch loss: 1.61922, batch accuracy: 0.55600
Time: 2018-07-15 09:45:29
TRAINING STATS: batch 306/486 in epoch 1154, batch loss: 1.67648, batch accuracy: 0.54200
Time: 2018-07-15 09:45:33
TRAINING STATS: batch 356/486 in epoch 1154, batch loss: 1.69972, batch accuracy: 0.53283
Time: 2018-07-15 09:45:38
TRAINING STATS: batch 406/486 in epoch 1154, batch loss: 1.73919, batch accuracy: 0.51900
Time: 2018-07-15 09:45:41
TRAINING STATS: batch 456/486 in epoch 1154, batch loss: 1.55669, batch accuracy: 0.58717
Time: 2018-07-15 09:45:45
TRAINING STATS: batch 20/486 in epoch 1155,  batch loss: 1.68450, batch accuracy: 0.54150
Time: 2018-07-15 09:45:50
TRAINING STATS: batch 70/486 in epoch 1155,  batch loss: 1.55698, batch accuracy: 0.58417
Time: 2018-07-15 09:45:53
TRAINING STATS: batch 120/486 in epoch 1155, batch loss: 1.60495, batch accuracy: 0.56267
Time: 2018-07-15 09:45:57
TRAINING STATS: batch 170/486 in epoch 1155, batch loss: 1.68580, batch accuracy: 0.54650
Time: 2018-07-15 09:46:02
TRAINING STATS: batch 220/486 in epoch 1155, batch loss: 1.58286, batch accuracy: 0.57700
Time: 2018-07-15 09:46:06
TRAINING STATS: batch 270/486 in epoch 1155, batch loss: 1.67745, batch accuracy: 0.54083
Time: 2018-07-15 09:46:09
TRAINING STATS: batch 320/486 in epoch 1155, batch loss: 1.61572, batch accuracy: 0.55983
Time: 2018-07-15 09:46:14
TRAINING STATS: batch 370/486 in epoch 1155, batch loss: 1.68082, batch accuracy: 0.54950
Time: 2018-07-15 09:46:18
TRAINING STATS: batch 420/486 in epoch 1155, batch loss: 1.69618, batch accuracy: 0.54450
Time: 2018-07-15 09:46:21
TRAINING STATS: batch 470/486 in epoch 1155, batch loss: 1.74931, batch accuracy: 0.51850
Time: 2018-07-15 09:46:26
TRAINING STATS: batch 34/486 in epoch 1156,  batch loss: 1.67083, batch accuracy: 0.54633
Time: 2018-07-15 09:46:30
TRAINING STATS: batch 84/486 in epoch 1156,  batch loss: 1.68403, batch accuracy: 0.53650
Time: 2018-07-15 09:46:33
TRAINING STATS: batch 134/486 in epoch 1156, batch loss: 1.74287, batch accuracy: 0.52967
Time: 2018-07-15 09:46:38
TRAINING STATS: batch 184/486 in epoch 1156, batch loss: 1.68275, batch accuracy: 0.54450
Time: 2018-07-15 09:46:42
TRAINING STATS: batch 234/486 in epoch 1156, batch loss: 1.73519, batch accuracy: 0.52883
Time: 2018-07-15 09:46:46
TRAINING STATS: batch 284/486 in epoch 1156, batch loss: 1.70903, batch accuracy: 0.53467
Time: 2018-07-15 09:46:50
TRAINING STATS: batch 334/486 in epoch 1156, batch loss: 1.64932, batch accuracy: 0.55167
Time: 2018-07-15 09:46:54
TRAINING STATS: batch 384/486 in epoch 1156, batch loss: 1.62753, batch accuracy: 0.55533
Time: 2018-07-15 09:46:58
TRAINING STATS: batch 434/486 in epoch 1156, batch loss: 1.73231, batch accuracy: 0.52967
Time: 2018-07-15 09:47:02
TRAINING STATS: batch 484/486 in epoch 1156, batch loss: 1.67159, batch accuracy: 0.54217
Time: 2018-07-15 09:47:06
TRAINING STATS: batch 48/486 in epoch 1157,  batch loss: 1.66784, batch accuracy: 0.54367
Time: 2018-07-15 09:47:10
TRAINING STATS: batch 98/486 in epoch 1157,  batch loss: 1.63356, batch accuracy: 0.55633
Time: 2018-07-15 09:47:14
TRAINING STATS: batch 148/486 in epoch 1157, batch loss: 1.70561, batch accuracy: 0.53867
Time: 2018-07-15 09:47:18
TRAINING STATS: batch 198/486 in epoch 1157, batch loss: 1.65478, batch accuracy: 0.55133
Time: 2018-07-15 09:47:22
TRAINING STATS: batch 248/486 in epoch 1157, batch loss: 1.70420, batch accuracy: 0.54000
Time: 2018-07-15 09:47:27
TRAINING STATS: batch 298/486 in epoch 1157, batch loss: 1.68771, batch accuracy: 0.53750
Time: 2018-07-15 09:47:30
TRAINING STATS: batch 348/486 in epoch 1157, batch loss: 1.69007, batch accuracy: 0.54600
Time: 2018-07-15 09:47:34
TRAINING STATS: batch 398/486 in epoch 1157, batch loss: 1.68784, batch accuracy: 0.54250
Time: 2018-07-15 09:47:39
TRAINING STATS: batch 448/486 in epoch 1157, batch loss: 1.66221, batch accuracy: 0.54617
Time: 2018-07-15 09:47:42
TRAINING STATS: batch 12/486 in epoch 1158,  batch loss: 1.68286, batch accuracy: 0.54333
Time: 2018-07-15 09:47:46
TRAINING STATS: batch 62/486 in epoch 1158,  batch loss: 1.73077, batch accuracy: 0.52583
Time: 2018-07-15 09:47:51
TRAINING STATS: batch 112/486 in epoch 1158, batch loss: 1.65112, batch accuracy: 0.54850
Time: 2018-07-15 09:47:54
TRAINING STATS: batch 162/486 in epoch 1158, batch loss: 1.67987, batch accuracy: 0.54450
Time: 2018-07-15 09:47:58
TRAINING STATS: batch 212/486 in epoch 1158, batch loss: 1.57617, batch accuracy: 0.57167
Time: 2018-07-15 09:48:03
TRAINING STATS: batch 262/486 in epoch 1158, batch loss: 1.71478, batch accuracy: 0.53717
Time: 2018-07-15 09:48:07
TRAINING STATS: batch 312/486 in epoch 1158, batch loss: 1.66929, batch accuracy: 0.53583
Time: 2018-07-15 09:48:10
TRAINING STATS: batch 362/486 in epoch 1158, batch loss: 1.68856, batch accuracy: 0.53867
Time: 2018-07-15 09:48:15
TRAINING STATS: batch 412/486 in epoch 1158, batch loss: 1.61484, batch accuracy: 0.56483
Time: 2018-07-15 09:48:19
TRAINING STATS: batch 462/486 in epoch 1158, batch loss: 1.70277, batch accuracy: 0.53567
Time: 2018-07-15 09:48:22
TRAINING STATS: batch 26/486 in epoch 1159,  batch loss: 1.70657, batch accuracy: 0.53250
Time: 2018-07-15 09:48:27
TRAINING STATS: batch 76/486 in epoch 1159,  batch loss: 1.73207, batch accuracy: 0.52667
Time: 2018-07-15 09:48:31
TRAINING STATS: batch 126/486 in epoch 1159, batch loss: 1.70011, batch accuracy: 0.53817
Time: 2018-07-15 09:48:34
TRAINING STATS: batch 176/486 in epoch 1159, batch loss: 1.59787, batch accuracy: 0.57200
Time: 2018-07-15 09:48:39
TRAINING STATS: batch 226/486 in epoch 1159, batch loss: 1.65707, batch accuracy: 0.55550
Time: 2018-07-15 09:48:43
TRAINING STATS: batch 276/486 in epoch 1159, batch loss: 1.66834, batch accuracy: 0.54467
Time: 2018-07-15 09:48:47
TRAINING STATS: batch 326/486 in epoch 1159, batch loss: 1.72017, batch accuracy: 0.52950
Time: 2018-07-15 09:48:51
TRAINING STATS: batch 376/486 in epoch 1159, batch loss: 1.69174, batch accuracy: 0.53967
Time: 2018-07-15 09:48:55
TRAINING STATS: batch 426/486 in epoch 1159, batch loss: 1.69548, batch accuracy: 0.53117
Time: 2018-07-15 09:48:59
TRAINING STATS: batch 476/486 in epoch 1159, batch loss: 1.59249, batch accuracy: 0.56683
Time: 2018-07-15 09:49:03
TRAINING STATS: batch 40/486 in epoch 1160,  batch loss: 1.62811, batch accuracy: 0.56283
Time: 2018-07-15 09:49:07
TRAINING STATS: batch 90/486 in epoch 1160,  batch loss: 1.70537, batch accuracy: 0.54133
Time: 2018-07-15 09:49:11
TRAINING STATS: batch 140/486 in epoch 1160, batch loss: 1.60799, batch accuracy: 0.56567
Time: 2018-07-15 09:49:16
TRAINING STATS: batch 190/486 in epoch 1160, batch loss: 1.65518, batch accuracy: 0.55033
Time: 2018-07-15 09:49:19
TRAINING STATS: batch 240/486 in epoch 1160, batch loss: 1.63877, batch accuracy: 0.55300
Time: 2018-07-15 09:49:23
TRAINING STATS: batch 290/486 in epoch 1160, batch loss: 1.70258, batch accuracy: 0.53300
Time: 2018-07-15 09:49:28
TRAINING STATS: batch 340/486 in epoch 1160, batch loss: 1.75228, batch accuracy: 0.52150
Time: 2018-07-15 09:49:31
TRAINING STATS: batch 390/486 in epoch 1160, batch loss: 1.58603, batch accuracy: 0.57400
Time: 2018-07-15 09:49:35
TRAINING STATS: batch 440/486 in epoch 1160, batch loss: 1.67475, batch accuracy: 0.54083
Time: 2018-07-15 09:49:40
TRAINING STATS: batch 4/486 in epoch 1161,   batch loss: 1.63618, batch accuracy: 0.55233
Time: 2018-07-15 09:49:44
TRAINING STATS: batch 54/486 in epoch 1161,  batch loss: 1.72108, batch accuracy: 0.53217
Time: 2018-07-15 09:49:47
TRAINING STATS: batch 104/486 in epoch 1161, batch loss: 1.74676, batch accuracy: 0.52250
Time: 2018-07-15 09:49:52
TRAINING STATS: batch 154/486 in epoch 1161, batch loss: 1.66640, batch accuracy: 0.54733
Time: 2018-07-15 09:49:56
TRAINING STATS: batch 204/486 in epoch 1161, batch loss: 1.73832, batch accuracy: 0.52917
Time: 2018-07-15 09:49:59
TRAINING STATS: batch 254/486 in epoch 1161, batch loss: 1.57828, batch accuracy: 0.57500
Time: 2018-07-15 09:50:04
TRAINING STATS: batch 304/486 in epoch 1161, batch loss: 1.62539, batch accuracy: 0.56333
Time: 2018-07-15 09:50:08
TRAINING STATS: batch 354/486 in epoch 1161, batch loss: 1.66272, batch accuracy: 0.54933
Time: 2018-07-15 09:50:11
TRAINING STATS: batch 404/486 in epoch 1161, batch loss: 1.64565, batch accuracy: 0.55217
Time: 2018-07-15 09:50:16
TRAINING STATS: batch 454/486 in epoch 1161, batch loss: 1.53325, batch accuracy: 0.58300
Time: 2018-07-15 09:50:20
TRAINING STATS: batch 18/486 in epoch 1162,  batch loss: 1.69223, batch accuracy: 0.53917
Time: 2018-07-15 09:50:23
TRAINING STATS: batch 68/486 in epoch 1162,  batch loss: 1.51982, batch accuracy: 0.58817
Time: 2018-07-15 09:50:28
TRAINING STATS: batch 118/486 in epoch 1162, batch loss: 1.65721, batch accuracy: 0.54550
Time: 2018-07-15 09:50:32
TRAINING STATS: batch 168/486 in epoch 1162, batch loss: 1.57580, batch accuracy: 0.57667
Time: 2018-07-15 09:50:35
TRAINING STATS: batch 218/486 in epoch 1162, batch loss: 1.64984, batch accuracy: 0.55183
Time: 2018-07-15 09:50:40
TRAINING STATS: batch 268/486 in epoch 1162, batch loss: 1.59650, batch accuracy: 0.56733
Time: 2018-07-15 09:50:44
TRAINING STATS: batch 318/486 in epoch 1162, batch loss: 1.65079, batch accuracy: 0.54533
Time: 2018-07-15 09:50:48
TRAINING STATS: batch 368/486 in epoch 1162, batch loss: 1.67576, batch accuracy: 0.54200
Time: 2018-07-15 09:50:52
TRAINING STATS: batch 418/486 in epoch 1162, batch loss: 1.74217, batch accuracy: 0.52183
Time: 2018-07-15 09:50:56
TRAINING STATS: batch 468/486 in epoch 1162, batch loss: 1.65856, batch accuracy: 0.54417
Time: 2018-07-15 09:51:00
TRAINING STATS: batch 32/486 in epoch 1163,  batch loss: 1.59690, batch accuracy: 0.56383
Time: 2018-07-15 09:51:05
TRAINING STATS: batch 82/486 in epoch 1163,  batch loss: 1.76434, batch accuracy: 0.51583
Time: 2018-07-15 09:51:08
TRAINING STATS: batch 132/486 in epoch 1163, batch loss: 1.66435, batch accuracy: 0.55050
Time: 2018-07-15 09:51:12
TRAINING STATS: batch 182/486 in epoch 1163, batch loss: 1.70975, batch accuracy: 0.53133
Time: 2018-07-15 09:51:17
TRAINING STATS: batch 232/486 in epoch 1163, batch loss: 1.69333, batch accuracy: 0.53383
Time: 2018-07-15 09:51:20
TRAINING STATS: batch 282/486 in epoch 1163, batch loss: 1.61291, batch accuracy: 0.55550
Time: 2018-07-15 09:51:24
TRAINING STATS: batch 332/486 in epoch 1163, batch loss: 1.71553, batch accuracy: 0.53250
Time: 2018-07-15 09:51:29
TRAINING STATS: batch 382/486 in epoch 1163, batch loss: 1.67022, batch accuracy: 0.55050
Time: 2018-07-15 09:51:32
TRAINING STATS: batch 432/486 in epoch 1163, batch loss: 1.59239, batch accuracy: 0.56750
Time: 2018-07-15 09:51:36
TRAINING STATS: batch 482/486 in epoch 1163, batch loss: 1.64937, batch accuracy: 0.54983
Time: 2018-07-15 09:51:41
TRAINING STATS: batch 46/486 in epoch 1164,  batch loss: 1.64311, batch accuracy: 0.55517
Time: 2018-07-15 09:51:44
TRAINING STATS: batch 96/486 in epoch 1164,  batch loss: 1.73192, batch accuracy: 0.52683
Time: 2018-07-15 09:51:48
TRAINING STATS: batch 146/486 in epoch 1164, batch loss: 1.73223, batch accuracy: 0.52950
Time: 2018-07-15 09:51:53
TRAINING STATS: batch 196/486 in epoch 1164, batch loss: 1.71610, batch accuracy: 0.52100
Time: 2018-07-15 09:51:57
TRAINING STATS: batch 246/486 in epoch 1164, batch loss: 1.65114, batch accuracy: 0.55833
Time: 2018-07-15 09:52:00
TRAINING STATS: batch 296/486 in epoch 1164, batch loss: 1.65057, batch accuracy: 0.54033
Time: 2018-07-15 09:52:05
TRAINING STATS: batch 346/486 in epoch 1164, batch loss: 1.59597, batch accuracy: 0.56867
Time: 2018-07-15 09:52:09
TRAINING STATS: batch 396/486 in epoch 1164, batch loss: 1.65681, batch accuracy: 0.55000
Time: 2018-07-15 09:52:12
TRAINING STATS: batch 446/486 in epoch 1164, batch loss: 1.68929, batch accuracy: 0.53883
Time: 2018-07-15 09:52:17
TRAINING STATS: batch 10/486 in epoch 1165,  batch loss: 1.68910, batch accuracy: 0.53883
Time: 2018-07-15 09:52:21
TRAINING STATS: batch 60/486 in epoch 1165,  batch loss: 1.64915, batch accuracy: 0.54633
Time: 2018-07-15 09:52:24
TRAINING STATS: batch 110/486 in epoch 1165, batch loss: 1.72311, batch accuracy: 0.53017
Time: 2018-07-15 09:52:29
TRAINING STATS: batch 160/486 in epoch 1165, batch loss: 1.62726, batch accuracy: 0.55050
Time: 2018-07-15 09:52:33
TRAINING STATS: batch 210/486 in epoch 1165, batch loss: 1.62315, batch accuracy: 0.55833
Time: 2018-07-15 09:52:37
TRAINING STATS: batch 260/486 in epoch 1165, batch loss: 1.69705, batch accuracy: 0.53550
Time: 2018-07-15 09:52:41
TRAINING STATS: batch 310/486 in epoch 1165, batch loss: 1.67637, batch accuracy: 0.54300
Time: 2018-07-15 09:52:45
TRAINING STATS: batch 360/486 in epoch 1165, batch loss: 1.69869, batch accuracy: 0.53517
Time: 2018-07-15 09:52:49
TRAINING STATS: batch 410/486 in epoch 1165, batch loss: 1.59450, batch accuracy: 0.56717
Time: 2018-07-15 09:52:53
TRAINING STATS: batch 460/486 in epoch 1165, batch loss: 1.77000, batch accuracy: 0.51500
Time: 2018-07-15 09:52:57
TRAINING STATS: batch 24/486 in epoch 1166,  batch loss: 1.73193, batch accuracy: 0.52767
Time: 2018-07-15 09:53:01
TRAINING STATS: batch 74/486 in epoch 1166,  batch loss: 1.70797, batch accuracy: 0.53667
Time: 2018-07-15 09:53:06
TRAINING STATS: batch 124/486 in epoch 1166, batch loss: 1.69684, batch accuracy: 0.54450
Time: 2018-07-15 09:53:09
TRAINING STATS: batch 174/486 in epoch 1166, batch loss: 1.74171, batch accuracy: 0.52583
Time: 2018-07-15 09:53:13
TRAINING STATS: batch 224/486 in epoch 1166, batch loss: 1.69216, batch accuracy: 0.53433
Time: 2018-07-15 09:53:18
TRAINING STATS: batch 274/486 in epoch 1166, batch loss: 1.68789, batch accuracy: 0.53633
Time: 2018-07-15 09:53:21
TRAINING STATS: batch 324/486 in epoch 1166, batch loss: 1.70406, batch accuracy: 0.54067
Time: 2018-07-15 09:53:25
TRAINING STATS: batch 374/486 in epoch 1166, batch loss: 1.71448, batch accuracy: 0.53733
Time: 2018-07-15 09:53:30
TRAINING STATS: batch 424/486 in epoch 1166, batch loss: 1.61458, batch accuracy: 0.55850
Time: 2018-07-15 09:53:33
TRAINING STATS: batch 474/486 in epoch 1166, batch loss: 1.67719, batch accuracy: 0.54667
Time: 2018-07-15 09:53:37
TRAINING STATS: batch 38/486 in epoch 1167,  batch loss: 1.70032, batch accuracy: 0.53650
Time: 2018-07-15 09:53:42
TRAINING STATS: batch 88/486 in epoch 1167,  batch loss: 1.71474, batch accuracy: 0.53367
Time: 2018-07-15 09:53:45
TRAINING STATS: batch 138/486 in epoch 1167, batch loss: 1.74392, batch accuracy: 0.52483
Time: 2018-07-15 09:53:49
TRAINING STATS: batch 188/486 in epoch 1167, batch loss: 1.61984, batch accuracy: 0.56167
Time: 2018-07-15 09:53:54
TRAINING STATS: batch 238/486 in epoch 1167, batch loss: 1.65242, batch accuracy: 0.55683
Time: 2018-07-15 09:53:58
TRAINING STATS: batch 288/486 in epoch 1167, batch loss: 1.69922, batch accuracy: 0.53267
Time: 2018-07-15 09:54:01
TRAINING STATS: batch 338/486 in epoch 1167, batch loss: 1.67384, batch accuracy: 0.53750
Time: 2018-07-15 09:54:06
TRAINING STATS: batch 388/486 in epoch 1167, batch loss: 1.62556, batch accuracy: 0.55633
Time: 2018-07-15 09:54:10
TRAINING STATS: batch 438/486 in epoch 1167, batch loss: 1.68355, batch accuracy: 0.54300
Time: 2018-07-15 09:54:13
TRAINING STATS: batch 2/486 in epoch 1168,   batch loss: 1.67145, batch accuracy: 0.54567
Time: 2018-07-15 09:54:18
TRAINING STATS: batch 52/486 in epoch 1168,  batch loss: 1.72285, batch accuracy: 0.52650
Time: 2018-07-15 09:54:22
TRAINING STATS: batch 102/486 in epoch 1168, batch loss: 1.68868, batch accuracy: 0.54017
Time: 2018-07-15 09:54:26
TRAINING STATS: batch 152/486 in epoch 1168, batch loss: 1.62153, batch accuracy: 0.56133
Time: 2018-07-15 09:54:30
TRAINING STATS: batch 202/486 in epoch 1168, batch loss: 1.65599, batch accuracy: 0.55133
Time: 2018-07-15 09:54:34
TRAINING STATS: batch 252/486 in epoch 1168, batch loss: 1.63097, batch accuracy: 0.56167
Time: 2018-07-15 09:54:38
TRAINING STATS: batch 302/486 in epoch 1168, batch loss: 1.61970, batch accuracy: 0.55817
Time: 2018-07-15 09:54:42
TRAINING STATS: batch 352/486 in epoch 1168, batch loss: 1.65137, batch accuracy: 0.54633
Time: 2018-07-15 09:54:46
TRAINING STATS: batch 402/486 in epoch 1168, batch loss: 1.53077, batch accuracy: 0.58917
Time: 2018-07-15 09:54:50
TRAINING STATS: batch 452/486 in epoch 1168, batch loss: 1.66340, batch accuracy: 0.54450
Time: 2018-07-15 09:54:55
TRAINING STATS: batch 16/486 in epoch 1169,  batch loss: 1.62331, batch accuracy: 0.56000
Time: 2018-07-15 09:54:58
TRAINING STATS: batch 66/486 in epoch 1169,  batch loss: 1.67688, batch accuracy: 0.54767
Time: 2018-07-15 09:55:02
TRAINING STATS: batch 116/486 in epoch 1169, batch loss: 1.63418, batch accuracy: 0.55283
Time: 2018-07-15 09:55:07
TRAINING STATS: batch 166/486 in epoch 1169, batch loss: 1.56008, batch accuracy: 0.57883
Time: 2018-07-15 09:55:10
TRAINING STATS: batch 216/486 in epoch 1169, batch loss: 1.72257, batch accuracy: 0.53583
Time: 2018-07-15 09:55:14
TRAINING STATS: batch 266/486 in epoch 1169, batch loss: 1.70358, batch accuracy: 0.53617
Time: 2018-07-15 09:55:19
TRAINING STATS: batch 316/486 in epoch 1169, batch loss: 1.70465, batch accuracy: 0.54017
Time: 2018-07-15 09:55:22
TRAINING STATS: batch 366/486 in epoch 1169, batch loss: 1.71245, batch accuracy: 0.53917
Time: 2018-07-15 09:55:26
TRAINING STATS: batch 416/486 in epoch 1169, batch loss: 1.70662, batch accuracy: 0.53183
Time: 2018-07-15 09:55:31
TRAINING STATS: batch 466/486 in epoch 1169, batch loss: 1.53357, batch accuracy: 0.57767
Time: 2018-07-15 09:55:35
TRAINING STATS: batch 30/486 in epoch 1170,  batch loss: 1.56122, batch accuracy: 0.57100
Time: 2018-07-15 09:55:38
TRAINING STATS: batch 80/486 in epoch 1170,  batch loss: 1.69718, batch accuracy: 0.53283
Time: 2018-07-15 09:55:43
TRAINING STATS: batch 130/486 in epoch 1170, batch loss: 1.67163, batch accuracy: 0.54667
Time: 2018-07-15 09:55:47
TRAINING STATS: batch 180/486 in epoch 1170, batch loss: 1.69055, batch accuracy: 0.54533
Time: 2018-07-15 09:55:50
TRAINING STATS: batch 230/486 in epoch 1170, batch loss: 1.67130, batch accuracy: 0.54717
Time: 2018-07-15 09:55:55
TRAINING STATS: batch 280/486 in epoch 1170, batch loss: 1.64306, batch accuracy: 0.55517
Time: 2018-07-15 09:55:59
TRAINING STATS: batch 330/486 in epoch 1170, batch loss: 1.64033, batch accuracy: 0.55417
Time: 2018-07-15 09:56:02
TRAINING STATS: batch 380/486 in epoch 1170, batch loss: 1.63966, batch accuracy: 0.55567
Time: 2018-07-15 09:56:07
TRAINING STATS: batch 430/486 in epoch 1170, batch loss: 1.60038, batch accuracy: 0.57150
Time: 2018-07-15 09:56:11
TRAINING STATS: batch 480/486 in epoch 1170, batch loss: 1.66832, batch accuracy: 0.55217
Time: 2018-07-15 09:56:14
TRAINING STATS: batch 44/486 in epoch 1171,  batch loss: 1.66564, batch accuracy: 0.54717
Time: 2018-07-15 09:56:19
TRAINING STATS: batch 94/486 in epoch 1171,  batch loss: 1.72306, batch accuracy: 0.53417
Time: 2018-07-15 09:56:23
TRAINING STATS: batch 144/486 in epoch 1171, batch loss: 1.72247, batch accuracy: 0.52967
Time: 2018-07-15 09:56:27
TRAINING STATS: batch 194/486 in epoch 1171, batch loss: 1.75709, batch accuracy: 0.51650
Time: 2018-07-15 09:56:31
TRAINING STATS: batch 244/486 in epoch 1171, batch loss: 1.64603, batch accuracy: 0.55483
Time: 2018-07-15 09:56:35
TRAINING STATS: batch 294/486 in epoch 1171, batch loss: 1.57883, batch accuracy: 0.57033
Time: 2018-07-15 09:56:39
TRAINING STATS: batch 344/486 in epoch 1171, batch loss: 1.64078, batch accuracy: 0.55333
Time: 2018-07-15 09:56:43
TRAINING STATS: batch 394/486 in epoch 1171, batch loss: 1.61797, batch accuracy: 0.55983
Time: 2018-07-15 09:56:47
TRAINING STATS: batch 444/486 in epoch 1171, batch loss: 1.61070, batch accuracy: 0.56533
Time: 2018-07-15 09:56:51
TRAINING STATS: batch 8/486 in epoch 1172,   batch loss: 1.65946, batch accuracy: 0.55167
Time: 2018-07-15 09:56:56
TRAINING STATS: batch 58/486 in epoch 1172,  batch loss: 1.63089, batch accuracy: 0.56250
Time: 2018-07-15 09:56:59
TRAINING STATS: batch 108/486 in epoch 1172, batch loss: 1.79080, batch accuracy: 0.51983
Time: 2018-07-15 09:57:03
TRAINING STATS: batch 158/486 in epoch 1172, batch loss: 1.73506, batch accuracy: 0.53350
Time: 2018-07-15 09:57:08
TRAINING STATS: batch 208/486 in epoch 1172, batch loss: 1.68304, batch accuracy: 0.54117
Time: 2018-07-15 09:57:11
TRAINING STATS: batch 258/486 in epoch 1172, batch loss: 1.61088, batch accuracy: 0.56217
Time: 2018-07-15 09:57:15
TRAINING STATS: batch 308/486 in epoch 1172, batch loss: 1.68159, batch accuracy: 0.55367
Time: 2018-07-15 09:57:20
TRAINING STATS: batch 358/486 in epoch 1172, batch loss: 1.68656, batch accuracy: 0.54500
Time: 2018-07-15 09:57:23
TRAINING STATS: batch 408/486 in epoch 1172, batch loss: 1.79456, batch accuracy: 0.50817
Time: 2018-07-15 09:57:27
TRAINING STATS: batch 458/486 in epoch 1172, batch loss: 1.69388, batch accuracy: 0.54400
Time: 2018-07-15 09:57:32
TRAINING STATS: batch 22/486 in epoch 1173,  batch loss: 1.70798, batch accuracy: 0.54117
Time: 2018-07-15 09:57:36
TRAINING STATS: batch 72/486 in epoch 1173,  batch loss: 1.68649, batch accuracy: 0.53567
Time: 2018-07-15 09:57:39
TRAINING STATS: batch 122/486 in epoch 1173, batch loss: 1.60176, batch accuracy: 0.56133
Time: 2018-07-15 09:57:44
TRAINING STATS: batch 172/486 in epoch 1173, batch loss: 1.72944, batch accuracy: 0.52950
Time: 2018-07-15 09:57:48
TRAINING STATS: batch 222/486 in epoch 1173, batch loss: 1.66965, batch accuracy: 0.53867
Time: 2018-07-15 09:57:51
TRAINING STATS: batch 272/486 in epoch 1173, batch loss: 1.70367, batch accuracy: 0.52317
Time: 2018-07-15 09:57:56
TRAINING STATS: batch 322/486 in epoch 1173, batch loss: 1.66573, batch accuracy: 0.53800
Time: 2018-07-15 09:58:00
TRAINING STATS: batch 372/486 in epoch 1173, batch loss: 1.62025, batch accuracy: 0.55967
Time: 2018-07-15 09:58:03
TRAINING STATS: batch 422/486 in epoch 1173, batch loss: 1.65081, batch accuracy: 0.55017
Time: 2018-07-15 09:58:08
TRAINING STATS: batch 472/486 in epoch 1173, batch loss: 1.76993, batch accuracy: 0.52200
Time: 2018-07-15 09:58:12
TRAINING STATS: batch 36/486 in epoch 1174,  batch loss: 1.72176, batch accuracy: 0.53300
Time: 2018-07-15 09:58:15
TRAINING STATS: batch 86/486 in epoch 1174,  batch loss: 1.69479, batch accuracy: 0.54983
Time: 2018-07-15 09:58:20
TRAINING STATS: batch 136/486 in epoch 1174, batch loss: 1.73190, batch accuracy: 0.52917
Time: 2018-07-15 09:58:24
TRAINING STATS: batch 186/486 in epoch 1174, batch loss: 1.88403, batch accuracy: 0.48700
Time: 2018-07-15 09:58:28
TRAINING STATS: batch 236/486 in epoch 1174, batch loss: 1.80089, batch accuracy: 0.50700
Time: 2018-07-15 09:58:32
TRAINING STATS: batch 286/486 in epoch 1174, batch loss: 1.77008, batch accuracy: 0.52317
Time: 2018-07-15 09:58:36
TRAINING STATS: batch 336/486 in epoch 1174, batch loss: 1.69510, batch accuracy: 0.53383
Time: 2018-07-15 09:58:40
TRAINING STATS: batch 386/486 in epoch 1174, batch loss: 1.73830, batch accuracy: 0.52783
Time: 2018-07-15 09:58:44
TRAINING STATS: batch 436/486 in epoch 1174, batch loss: 1.68787, batch accuracy: 0.54083
Time: 2018-07-15 09:58:48
TRAINING STATS: batch 0/486 in epoch 1175,   batch loss: 1.66724, batch accuracy: 0.54817
Time: 2018-07-15 09:58:52
TRAINING STATS: batch 50/486 in epoch 1175,  batch loss: 1.64205, batch accuracy: 0.55500
Time: 2018-07-15 09:58:57
TRAINING STATS: batch 100/486 in epoch 1175, batch loss: 1.70919, batch accuracy: 0.54133
Time: 2018-07-15 09:59:00
TRAINING STATS: batch 150/486 in epoch 1175, batch loss: 1.63211, batch accuracy: 0.56217
Time: 2018-07-15 09:59:04
TRAINING STATS: batch 200/486 in epoch 1175, batch loss: 1.56684, batch accuracy: 0.57817
Time: 2018-07-15 09:59:09
TRAINING STATS: batch 250/486 in epoch 1175, batch loss: 1.73689, batch accuracy: 0.52567
Time: 2018-07-15 09:59:12
TRAINING STATS: batch 300/486 in epoch 1175, batch loss: 1.71129, batch accuracy: 0.52767
Time: 2018-07-15 09:59:16
TRAINING STATS: batch 350/486 in epoch 1175, batch loss: 1.74230, batch accuracy: 0.53283
Time: 2018-07-15 09:59:21
TRAINING STATS: batch 400/486 in epoch 1175, batch loss: 1.56491, batch accuracy: 0.56950
Time: 2018-07-15 09:59:24
TRAINING STATS: batch 450/486 in epoch 1175, batch loss: 1.74914, batch accuracy: 0.52483
Time: 2018-07-15 09:59:28
TRAINING STATS: batch 14/486 in epoch 1176,  batch loss: 1.59522, batch accuracy: 0.56633
Time: 2018-07-15 09:59:33
TRAINING STATS: batch 64/486 in epoch 1176,  batch loss: 1.75512, batch accuracy: 0.52600
Time: 2018-07-15 09:59:37
TRAINING STATS: batch 114/486 in epoch 1176, batch loss: 1.71613, batch accuracy: 0.53867
Time: 2018-07-15 09:59:40
TRAINING STATS: batch 164/486 in epoch 1176, batch loss: 1.63240, batch accuracy: 0.56317
Time: 2018-07-15 09:59:45
TRAINING STATS: batch 214/486 in epoch 1176, batch loss: 1.66821, batch accuracy: 0.54200
Time: 2018-07-15 09:59:49
TRAINING STATS: batch 264/486 in epoch 1176, batch loss: 1.71591, batch accuracy: 0.53517
Time: 2018-07-15 09:59:52
TRAINING STATS: batch 314/486 in epoch 1176, batch loss: 1.73620, batch accuracy: 0.52433
Time: 2018-07-15 09:59:57
TRAINING STATS: batch 364/486 in epoch 1176, batch loss: 1.64678, batch accuracy: 0.55033
Time: 2018-07-15 10:00:01
TRAINING STATS: batch 414/486 in epoch 1176, batch loss: 1.60023, batch accuracy: 0.56650
Time: 2018-07-15 10:00:04
TRAINING STATS: batch 464/486 in epoch 1176, batch loss: 1.63398, batch accuracy: 0.55767
Time: 2018-07-15 10:00:09
TRAINING STATS: batch 28/486 in epoch 1177,  batch loss: 1.60977, batch accuracy: 0.56517
Time: 2018-07-15 10:00:13
TRAINING STATS: batch 78/486 in epoch 1177,  batch loss: 1.69705, batch accuracy: 0.54350
Time: 2018-07-15 10:00:17
TRAINING STATS: batch 128/486 in epoch 1177, batch loss: 1.65736, batch accuracy: 0.55367
Time: 2018-07-15 10:00:21
TRAINING STATS: batch 178/486 in epoch 1177, batch loss: 1.54813, batch accuracy: 0.58117
Time: 2018-07-15 10:00:25
TRAINING STATS: batch 228/486 in epoch 1177, batch loss: 1.60661, batch accuracy: 0.56600
Time: 2018-07-15 10:00:29
TRAINING STATS: batch 278/486 in epoch 1177, batch loss: 1.58931, batch accuracy: 0.56867
Time: 2018-07-15 10:00:33
TRAINING STATS: batch 328/486 in epoch 1177, batch loss: 1.64120, batch accuracy: 0.55000
Time: 2018-07-15 10:00:37
TRAINING STATS: batch 378/486 in epoch 1177, batch loss: 1.64768, batch accuracy: 0.55433
Time: 2018-07-15 10:00:41
TRAINING STATS: batch 428/486 in epoch 1177, batch loss: 1.69913, batch accuracy: 0.54467
Time: 2018-07-15 10:00:46
TRAINING STATS: batch 478/486 in epoch 1177, batch loss: 1.67750, batch accuracy: 0.53983
Time: 2018-07-15 10:00:49
TRAINING STATS: batch 42/486 in epoch 1178,  batch loss: 1.57012, batch accuracy: 0.57250
Time: 2018-07-15 10:00:53
TRAINING STATS: batch 92/486 in epoch 1178,  batch loss: 1.69251, batch accuracy: 0.53567
Time: 2018-07-15 10:00:58
TRAINING STATS: batch 142/486 in epoch 1178, batch loss: 1.63379, batch accuracy: 0.55533
Time: 2018-07-15 10:01:01
TRAINING STATS: batch 192/486 in epoch 1178, batch loss: 1.66642, batch accuracy: 0.54900
Time: 2018-07-15 10:01:05
TRAINING STATS: batch 242/486 in epoch 1178, batch loss: 1.64231, batch accuracy: 0.55567
Time: 2018-07-15 10:01:10
TRAINING STATS: batch 292/486 in epoch 1178, batch loss: 1.67108, batch accuracy: 0.54783
Time: 2018-07-15 10:01:14
TRAINING STATS: batch 342/486 in epoch 1178, batch loss: 1.62196, batch accuracy: 0.55483
Time: 2018-07-15 10:01:17
TRAINING STATS: batch 392/486 in epoch 1178, batch loss: 1.57263, batch accuracy: 0.57967
Time: 2018-07-15 10:01:22
TRAINING STATS: batch 442/486 in epoch 1178, batch loss: 1.57561, batch accuracy: 0.57450
Time: 2018-07-15 10:01:26
TRAINING STATS: batch 6/486 in epoch 1179,   batch loss: 1.69108, batch accuracy: 0.54517
Time: 2018-07-15 10:01:29
TRAINING STATS: batch 56/486 in epoch 1179,  batch loss: 1.65045, batch accuracy: 0.54183
Time: 2018-07-15 10:01:34
TRAINING STATS: batch 106/486 in epoch 1179, batch loss: 1.71690, batch accuracy: 0.53050
Time: 2018-07-15 10:01:38
TRAINING STATS: batch 156/486 in epoch 1179, batch loss: 1.70013, batch accuracy: 0.53950
Time: 2018-07-15 10:01:42
TRAINING STATS: batch 206/486 in epoch 1179, batch loss: 1.76139, batch accuracy: 0.51583
Time: 2018-07-15 10:01:46
TRAINING STATS: batch 256/486 in epoch 1179, batch loss: 1.60130, batch accuracy: 0.56117
Time: 2018-07-15 10:01:50
TRAINING STATS: batch 306/486 in epoch 1179, batch loss: 1.65160, batch accuracy: 0.54850
Time: 2018-07-15 10:01:54
TRAINING STATS: batch 356/486 in epoch 1179, batch loss: 1.70797, batch accuracy: 0.53083
Time: 2018-07-15 10:01:58
TRAINING STATS: batch 406/486 in epoch 1179, batch loss: 1.74738, batch accuracy: 0.52333
Time: 2018-07-15 10:02:02
TRAINING STATS: batch 456/486 in epoch 1179, batch loss: 1.55103, batch accuracy: 0.58333
Time: 2018-07-15 10:02:06
TRAINING STATS: batch 20/486 in epoch 1180,  batch loss: 1.66334, batch accuracy: 0.54817
Time: 2018-07-15 10:02:10
TRAINING STATS: batch 70/486 in epoch 1180,  batch loss: 1.55856, batch accuracy: 0.58033
Time: 2018-07-15 10:02:14
TRAINING STATS: batch 120/486 in epoch 1180, batch loss: 1.59301, batch accuracy: 0.56650
Time: 2018-07-15 10:02:18
TRAINING STATS: batch 170/486 in epoch 1180, batch loss: 1.64326, batch accuracy: 0.55683
Time: 2018-07-15 10:02:23
TRAINING STATS: batch 220/486 in epoch 1180, batch loss: 1.57408, batch accuracy: 0.57733
Time: 2018-07-15 10:02:26
TRAINING STATS: batch 270/486 in epoch 1180, batch loss: 1.69204, batch accuracy: 0.53233
Time: 2018-07-15 10:02:30
TRAINING STATS: batch 320/486 in epoch 1180, batch loss: 1.60610, batch accuracy: 0.56133
Time: 2018-07-15 10:02:35
TRAINING STATS: batch 370/486 in epoch 1180, batch loss: 1.66574, batch accuracy: 0.55283
Time: 2018-07-15 10:02:38
TRAINING STATS: batch 420/486 in epoch 1180, batch loss: 1.72229, batch accuracy: 0.53650
Time: 2018-07-15 10:02:42
TRAINING STATS: batch 470/486 in epoch 1180, batch loss: 1.74120, batch accuracy: 0.52517
Time: 2018-07-15 10:02:47
TRAINING STATS: batch 34/486 in epoch 1181,  batch loss: 1.67732, batch accuracy: 0.53900
Time: 2018-07-15 10:02:50
TRAINING STATS: batch 84/486 in epoch 1181,  batch loss: 1.67746, batch accuracy: 0.53683
Time: 2018-07-15 10:02:54
TRAINING STATS: batch 134/486 in epoch 1181, batch loss: 1.69898, batch accuracy: 0.53700
Time: 2018-07-15 10:02:59
TRAINING STATS: batch 184/486 in epoch 1181, batch loss: 1.68040, batch accuracy: 0.54050
Time: 2018-07-15 10:03:03
TRAINING STATS: batch 234/486 in epoch 1181, batch loss: 1.72679, batch accuracy: 0.52733
Time: 2018-07-15 10:03:06
TRAINING STATS: batch 284/486 in epoch 1181, batch loss: 1.69989, batch accuracy: 0.53883
Time: 2018-07-15 10:03:11
TRAINING STATS: batch 334/486 in epoch 1181, batch loss: 1.65818, batch accuracy: 0.55350
Time: 2018-07-15 10:03:15
TRAINING STATS: batch 384/486 in epoch 1181, batch loss: 1.63016, batch accuracy: 0.55183
Time: 2018-07-15 10:03:18
TRAINING STATS: batch 434/486 in epoch 1181, batch loss: 1.74256, batch accuracy: 0.51833
Time: 2018-07-15 10:03:23
TRAINING STATS: batch 484/486 in epoch 1181, batch loss: 1.67584, batch accuracy: 0.53817
Time: 2018-07-15 10:03:27
TRAINING STATS: batch 48/486 in epoch 1182,  batch loss: 1.66721, batch accuracy: 0.54683
Time: 2018-07-15 10:03:30
TRAINING STATS: batch 98/486 in epoch 1182,  batch loss: 1.62870, batch accuracy: 0.56083
Time: 2018-07-15 10:03:35
TRAINING STATS: batch 148/486 in epoch 1182, batch loss: 1.69608, batch accuracy: 0.54217
Time: 2018-07-15 10:03:39
TRAINING STATS: batch 198/486 in epoch 1182, batch loss: 1.64317, batch accuracy: 0.55033
Time: 2018-07-15 10:03:43
TRAINING STATS: batch 248/486 in epoch 1182, batch loss: 1.72493, batch accuracy: 0.53033
Time: 2018-07-15 10:03:47
TRAINING STATS: batch 298/486 in epoch 1182, batch loss: 1.69123, batch accuracy: 0.53600
Time: 2018-07-15 10:03:51
TRAINING STATS: batch 348/486 in epoch 1182, batch loss: 1.67850, batch accuracy: 0.54383
Time: 2018-07-15 10:03:55
TRAINING STATS: batch 398/486 in epoch 1182, batch loss: 1.72692, batch accuracy: 0.51900
Time: 2018-07-15 10:03:59
TRAINING STATS: batch 448/486 in epoch 1182, batch loss: 1.66744, batch accuracy: 0.54717
Time: 2018-07-15 10:04:03
TRAINING STATS: batch 12/486 in epoch 1183,  batch loss: 1.68881, batch accuracy: 0.54067
Time: 2018-07-15 10:04:07
TRAINING STATS: batch 62/486 in epoch 1183,  batch loss: 1.80969, batch accuracy: 0.49467
Time: 2018-07-15 10:04:12
TRAINING STATS: batch 112/486 in epoch 1183, batch loss: 1.69977, batch accuracy: 0.53483
Time: 2018-07-15 10:04:15
TRAINING STATS: batch 162/486 in epoch 1183, batch loss: 1.69975, batch accuracy: 0.53450
Time: 2018-07-15 10:04:19
TRAINING STATS: batch 212/486 in epoch 1183, batch loss: 1.61160, batch accuracy: 0.56400
Time: 2018-07-15 10:04:24
TRAINING STATS: batch 262/486 in epoch 1183, batch loss: 1.73109, batch accuracy: 0.52850
Time: 2018-07-15 10:04:27
TRAINING STATS: batch 312/486 in epoch 1183, batch loss: 1.67933, batch accuracy: 0.53467
Time: 2018-07-15 10:04:31
TRAINING STATS: batch 362/486 in epoch 1183, batch loss: 1.67871, batch accuracy: 0.54400
Time: 2018-07-15 10:04:36
TRAINING STATS: batch 412/486 in epoch 1183, batch loss: 1.60011, batch accuracy: 0.57483
Time: 2018-07-15 10:04:40
TRAINING STATS: batch 462/486 in epoch 1183, batch loss: 1.70322, batch accuracy: 0.52500
Time: 2018-07-15 10:04:43
TRAINING STATS: batch 26/486 in epoch 1184,  batch loss: 1.73774, batch accuracy: 0.52883
Time: 2018-07-15 10:04:48
TRAINING STATS: batch 76/486 in epoch 1184,  batch loss: 1.72954, batch accuracy: 0.52567
Time: 2018-07-15 10:04:52
TRAINING STATS: batch 126/486 in epoch 1184, batch loss: 1.89902, batch accuracy: 0.48150
Time: 2018-07-15 10:04:55
TRAINING STATS: batch 176/486 in epoch 1184, batch loss: 1.69510, batch accuracy: 0.53950
Time: 2018-07-15 10:05:00
TRAINING STATS: batch 226/486 in epoch 1184, batch loss: 1.73185, batch accuracy: 0.53500
Time: 2018-07-15 10:05:04
TRAINING STATS: batch 276/486 in epoch 1184, batch loss: 1.74754, batch accuracy: 0.51683
Time: 2018-07-15 10:05:08
TRAINING STATS: batch 326/486 in epoch 1184, batch loss: 1.78883, batch accuracy: 0.50767
Time: 2018-07-15 10:05:12
TRAINING STATS: batch 376/486 in epoch 1184, batch loss: 1.76533, batch accuracy: 0.52000
Time: 2018-07-15 10:05:16
TRAINING STATS: batch 426/486 in epoch 1184, batch loss: 1.72722, batch accuracy: 0.52267
Time: 2018-07-15 10:05:20
TRAINING STATS: batch 476/486 in epoch 1184, batch loss: 1.63781, batch accuracy: 0.55600
Time: 2018-07-15 10:05:24
TRAINING STATS: batch 40/486 in epoch 1185,  batch loss: 1.68020, batch accuracy: 0.54550
Time: 2018-07-15 10:05:28
TRAINING STATS: batch 90/486 in epoch 1185,  batch loss: 1.74306, batch accuracy: 0.53100
Time: 2018-07-15 10:05:32
TRAINING STATS: batch 140/486 in epoch 1185, batch loss: 1.62236, batch accuracy: 0.56167
Time: 2018-07-15 10:05:37
TRAINING STATS: batch 190/486 in epoch 1185, batch loss: 1.67459, batch accuracy: 0.54550
Time: 2018-07-15 10:05:40
TRAINING STATS: batch 240/486 in epoch 1185, batch loss: 1.66369, batch accuracy: 0.54217
Time: 2018-07-15 10:05:44
TRAINING STATS: batch 290/486 in epoch 1185, batch loss: 1.73108, batch accuracy: 0.52250
Time: 2018-07-15 10:05:49
TRAINING STATS: batch 340/486 in epoch 1185, batch loss: 1.74546, batch accuracy: 0.52483
Time: 2018-07-15 10:05:52
TRAINING STATS: batch 390/486 in epoch 1185, batch loss: 1.60650, batch accuracy: 0.56700
Time: 2018-07-15 10:05:56
TRAINING STATS: batch 440/486 in epoch 1185, batch loss: 1.69563, batch accuracy: 0.53967
Time: 2018-07-15 10:06:01
TRAINING STATS: batch 4/486 in epoch 1186,   batch loss: 1.64060, batch accuracy: 0.55233
Time: 2018-07-15 10:06:04
TRAINING STATS: batch 54/486 in epoch 1186,  batch loss: 1.68329, batch accuracy: 0.53833
Time: 2018-07-15 10:06:08
TRAINING STATS: batch 104/486 in epoch 1186, batch loss: 1.68665, batch accuracy: 0.54333
Time: 2018-07-15 10:06:13
TRAINING STATS: batch 154/486 in epoch 1186, batch loss: 1.66353, batch accuracy: 0.54267
Time: 2018-07-15 10:06:17
TRAINING STATS: batch 204/486 in epoch 1186, batch loss: 1.74583, batch accuracy: 0.52083
Time: 2018-07-15 10:06:20
TRAINING STATS: batch 254/486 in epoch 1186, batch loss: 1.60636, batch accuracy: 0.56000
Time: 2018-07-15 10:06:25
TRAINING STATS: batch 304/486 in epoch 1186, batch loss: 1.62060, batch accuracy: 0.56283
Time: 2018-07-15 10:06:29
TRAINING STATS: batch 354/486 in epoch 1186, batch loss: 1.67074, batch accuracy: 0.54783
Time: 2018-07-15 10:06:32
TRAINING STATS: batch 404/486 in epoch 1186, batch loss: 1.65901, batch accuracy: 0.54667
Time: 2018-07-15 10:06:37
TRAINING STATS: batch 454/486 in epoch 1186, batch loss: 1.51928, batch accuracy: 0.59100
Time: 2018-07-15 10:06:41
TRAINING STATS: batch 18/486 in epoch 1187,  batch loss: 1.70227, batch accuracy: 0.53683
Time: 2018-07-15 10:06:44
TRAINING STATS: batch 68/486 in epoch 1187,  batch loss: 1.51548, batch accuracy: 0.59183
Time: 2018-07-15 10:06:49
TRAINING STATS: batch 118/486 in epoch 1187, batch loss: 1.66004, batch accuracy: 0.55283
Time: 2018-07-15 10:06:53
TRAINING STATS: batch 168/486 in epoch 1187, batch loss: 1.58454, batch accuracy: 0.57250
Time: 2018-07-15 10:06:57
TRAINING STATS: batch 218/486 in epoch 1187, batch loss: 1.64483, batch accuracy: 0.55517
Time: 2018-07-15 10:07:01
TRAINING STATS: batch 268/486 in epoch 1187, batch loss: 1.62660, batch accuracy: 0.55300
Time: 2018-07-15 10:07:05
TRAINING STATS: batch 318/486 in epoch 1187, batch loss: 1.65482, batch accuracy: 0.54283
Time: 2018-07-15 10:07:09
TRAINING STATS: batch 368/486 in epoch 1187, batch loss: 1.67972, batch accuracy: 0.54350
Time: 2018-07-15 10:07:14
TRAINING STATS: batch 418/486 in epoch 1187, batch loss: 1.77127, batch accuracy: 0.51733
Time: 2018-07-15 10:07:17
TRAINING STATS: batch 468/486 in epoch 1187, batch loss: 1.67598, batch accuracy: 0.54333
Time: 2018-07-15 10:07:21
TRAINING STATS: batch 32/486 in epoch 1188,  batch loss: 1.61560, batch accuracy: 0.55467
Time: 2018-07-15 10:07:26
TRAINING STATS: batch 82/486 in epoch 1188,  batch loss: 1.68869, batch accuracy: 0.53700
Time: 2018-07-15 10:07:29
TRAINING STATS: batch 132/486 in epoch 1188, batch loss: 1.64579, batch accuracy: 0.55733
Time: 2018-07-15 10:07:33
TRAINING STATS: batch 182/486 in epoch 1188, batch loss: 1.71802, batch accuracy: 0.53100
Time: 2018-07-15 10:07:38
TRAINING STATS: batch 232/486 in epoch 1188, batch loss: 1.69519, batch accuracy: 0.53883
Time: 2018-07-15 10:07:41
TRAINING STATS: batch 282/486 in epoch 1188, batch loss: 1.61651, batch accuracy: 0.55950
Time: 2018-07-15 10:07:45
TRAINING STATS: batch 332/486 in epoch 1188, batch loss: 1.79323, batch accuracy: 0.50917
Time: 2018-07-15 10:07:50
TRAINING STATS: batch 382/486 in epoch 1188, batch loss: 1.68053, batch accuracy: 0.53883
Time: 2018-07-15 10:07:54
TRAINING STATS: batch 432/486 in epoch 1188, batch loss: 1.62573, batch accuracy: 0.55500
Time: 2018-07-15 10:07:57
TRAINING STATS: batch 482/486 in epoch 1188, batch loss: 1.65852, batch accuracy: 0.54633
Time: 2018-07-15 10:08:02
TRAINING STATS: batch 46/486 in epoch 1189,  batch loss: 1.63217, batch accuracy: 0.55550
Time: 2018-07-15 10:08:06
TRAINING STATS: batch 96/486 in epoch 1189,  batch loss: 1.69393, batch accuracy: 0.54183
Time: 2018-07-15 10:08:09
TRAINING STATS: batch 146/486 in epoch 1189, batch loss: 1.70766, batch accuracy: 0.54217
Time: 2018-07-15 10:08:14
TRAINING STATS: batch 196/486 in epoch 1189, batch loss: 1.69698, batch accuracy: 0.53533
Time: 2018-07-15 10:08:18
TRAINING STATS: batch 246/486 in epoch 1189, batch loss: 1.64967, batch accuracy: 0.54867
Time: 2018-07-15 10:08:22
TRAINING STATS: batch 296/486 in epoch 1189, batch loss: 1.64989, batch accuracy: 0.54633
Time: 2018-07-15 10:08:26
TRAINING STATS: batch 346/486 in epoch 1189, batch loss: 1.58184, batch accuracy: 0.57150
Time: 2018-07-15 10:08:30
TRAINING STATS: batch 396/486 in epoch 1189, batch loss: 1.64039, batch accuracy: 0.56367
Time: 2018-07-15 10:08:34
TRAINING STATS: batch 446/486 in epoch 1189, batch loss: 1.67440, batch accuracy: 0.54717
Time: 2018-07-15 10:08:38
TRAINING STATS: batch 10/486 in epoch 1190,  batch loss: 1.69180, batch accuracy: 0.53217
Time: 2018-07-15 10:08:42
TRAINING STATS: batch 60/486 in epoch 1190,  batch loss: 1.67488, batch accuracy: 0.54517
Time: 2018-07-15 10:08:46
TRAINING STATS: batch 110/486 in epoch 1190, batch loss: 1.73135, batch accuracy: 0.53083
Time: 2018-07-15 10:08:50
TRAINING STATS: batch 160/486 in epoch 1190, batch loss: 1.64005, batch accuracy: 0.54733
Time: 2018-07-15 10:08:54
TRAINING STATS: batch 210/486 in epoch 1190, batch loss: 1.60547, batch accuracy: 0.56750
Time: 2018-07-15 10:08:58
TRAINING STATS: batch 260/486 in epoch 1190, batch loss: 1.68509, batch accuracy: 0.53967
Time: 2018-07-15 10:09:03
TRAINING STATS: batch 310/486 in epoch 1190, batch loss: 1.75665, batch accuracy: 0.52400
Time: 2018-07-15 10:09:06
TRAINING STATS: batch 360/486 in epoch 1190, batch loss: 1.69210, batch accuracy: 0.54167
Time: 2018-07-15 10:09:10
TRAINING STATS: batch 410/486 in epoch 1190, batch loss: 1.60843, batch accuracy: 0.56933
Time: 2018-07-15 10:09:15
TRAINING STATS: batch 460/486 in epoch 1190, batch loss: 1.77504, batch accuracy: 0.51317
Time: 2018-07-15 10:09:18
TRAINING STATS: batch 24/486 in epoch 1191,  batch loss: 1.73583, batch accuracy: 0.53200
Time: 2018-07-15 10:09:22
TRAINING STATS: batch 74/486 in epoch 1191,  batch loss: 1.69777, batch accuracy: 0.53850
Time: 2018-07-15 10:09:27
TRAINING STATS: batch 124/486 in epoch 1191, batch loss: 1.68476, batch accuracy: 0.54900
Time: 2018-07-15 10:09:30
TRAINING STATS: batch 174/486 in epoch 1191, batch loss: 1.73954, batch accuracy: 0.53000
Time: 2018-07-15 10:09:34
TRAINING STATS: batch 224/486 in epoch 1191, batch loss: 1.68553, batch accuracy: 0.54083
Time: 2018-07-15 10:09:39
TRAINING STATS: batch 274/486 in epoch 1191, batch loss: 1.66841, batch accuracy: 0.54883
Time: 2018-07-15 10:09:43
TRAINING STATS: batch 324/486 in epoch 1191, batch loss: 1.70338, batch accuracy: 0.54533
Time: 2018-07-15 10:09:46
TRAINING STATS: batch 374/486 in epoch 1191, batch loss: 1.70515, batch accuracy: 0.54017
Time: 2018-07-15 10:09:51
TRAINING STATS: batch 424/486 in epoch 1191, batch loss: 1.59642, batch accuracy: 0.57017
Time: 2018-07-15 10:09:55
TRAINING STATS: batch 474/486 in epoch 1191, batch loss: 1.68270, batch accuracy: 0.53717
Time: 2018-07-15 10:09:58
TRAINING STATS: batch 38/486 in epoch 1192,  batch loss: 1.70529, batch accuracy: 0.53683
Time: 2018-07-15 10:10:03
TRAINING STATS: batch 88/486 in epoch 1192,  batch loss: 1.71935, batch accuracy: 0.53867
Time: 2018-07-15 10:10:07
TRAINING STATS: batch 138/486 in epoch 1192, batch loss: 1.72911, batch accuracy: 0.53650
Time: 2018-07-15 10:10:10
TRAINING STATS: batch 188/486 in epoch 1192, batch loss: 1.62197, batch accuracy: 0.55950
Time: 2018-07-15 10:10:15
TRAINING STATS: batch 238/486 in epoch 1192, batch loss: 1.67003, batch accuracy: 0.55733
Time: 2018-07-15 10:10:19
TRAINING STATS: batch 288/486 in epoch 1192, batch loss: 1.68560, batch accuracy: 0.53900
Time: 2018-07-15 10:10:23
TRAINING STATS: batch 338/486 in epoch 1192, batch loss: 1.66638, batch accuracy: 0.54083
Time: 2018-07-15 10:10:27
TRAINING STATS: batch 388/486 in epoch 1192, batch loss: 1.62842, batch accuracy: 0.55550
Time: 2018-07-15 10:10:31
TRAINING STATS: batch 438/486 in epoch 1192, batch loss: 1.69727, batch accuracy: 0.53883
Time: 2018-07-15 10:10:35
TRAINING STATS: batch 2/486 in epoch 1193,   batch loss: 1.66484, batch accuracy: 0.54817
Time: 2018-07-15 10:10:40
TRAINING STATS: batch 52/486 in epoch 1193,  batch loss: 1.74828, batch accuracy: 0.51583
Time: 2018-07-15 10:10:43
TRAINING STATS: batch 102/486 in epoch 1193, batch loss: 1.69292, batch accuracy: 0.54550
Time: 2018-07-15 10:10:47
TRAINING STATS: batch 152/486 in epoch 1193, batch loss: 1.62192, batch accuracy: 0.56367
Time: 2018-07-15 10:10:52
TRAINING STATS: batch 202/486 in epoch 1193, batch loss: 1.65920, batch accuracy: 0.55167
Time: 2018-07-15 10:10:55
TRAINING STATS: batch 252/486 in epoch 1193, batch loss: 1.63171, batch accuracy: 0.56000
Time: 2018-07-15 10:10:59
TRAINING STATS: batch 302/486 in epoch 1193, batch loss: 1.62903, batch accuracy: 0.55733
Time: 2018-07-15 10:11:04
TRAINING STATS: batch 352/486 in epoch 1193, batch loss: 1.65731, batch accuracy: 0.55333
Time: 2018-07-15 10:11:07
TRAINING STATS: batch 402/486 in epoch 1193, batch loss: 1.53516, batch accuracy: 0.59033
Time: 2018-07-15 10:11:11
TRAINING STATS: batch 452/486 in epoch 1193, batch loss: 1.66660, batch accuracy: 0.54700
Time: 2018-07-15 10:11:16
TRAINING STATS: batch 16/486 in epoch 1194,  batch loss: 1.61837, batch accuracy: 0.56033
Time: 2018-07-15 10:11:20
TRAINING STATS: batch 66/486 in epoch 1194,  batch loss: 1.67020, batch accuracy: 0.54800
Time: 2018-07-15 10:11:23
TRAINING STATS: batch 116/486 in epoch 1194, batch loss: 1.62286, batch accuracy: 0.55967
Time: 2018-07-15 10:11:28
TRAINING STATS: batch 166/486 in epoch 1194, batch loss: 1.57731, batch accuracy: 0.57283
Time: 2018-07-15 10:11:32
TRAINING STATS: batch 216/486 in epoch 1194, batch loss: 1.67273, batch accuracy: 0.55267
Time: 2018-07-15 10:11:35
TRAINING STATS: batch 266/486 in epoch 1194, batch loss: 1.65269, batch accuracy: 0.54033
Time: 2018-07-15 10:11:40
TRAINING STATS: batch 316/486 in epoch 1194, batch loss: 1.64749, batch accuracy: 0.55050
Time: 2018-07-15 10:11:44
TRAINING STATS: batch 366/486 in epoch 1194, batch loss: 1.70132, batch accuracy: 0.54333
Time: 2018-07-15 10:11:48
TRAINING STATS: batch 416/486 in epoch 1194, batch loss: 1.69231, batch accuracy: 0.54117
Time: 2018-07-15 10:11:52
TRAINING STATS: batch 466/486 in epoch 1194, batch loss: 1.51991, batch accuracy: 0.58900
Time: 2018-07-15 10:11:56
TRAINING STATS: batch 30/486 in epoch 1195,  batch loss: 1.56791, batch accuracy: 0.57183
Time: 2018-07-15 10:12:00
TRAINING STATS: batch 80/486 in epoch 1195,  batch loss: 1.67113, batch accuracy: 0.53550
Time: 2018-07-15 10:12:04
TRAINING STATS: batch 130/486 in epoch 1195, batch loss: 1.63598, batch accuracy: 0.56383
Time: 2018-07-15 10:12:08
TRAINING STATS: batch 180/486 in epoch 1195, batch loss: 1.68565, batch accuracy: 0.54483
Time: 2018-07-15 10:12:12
TRAINING STATS: batch 230/486 in epoch 1195, batch loss: 1.68694, batch accuracy: 0.54150
Time: 2018-07-15 10:12:16
TRAINING STATS: batch 280/486 in epoch 1195, batch loss: 1.64455, batch accuracy: 0.55000
Time: 2018-07-15 10:12:20
TRAINING STATS: batch 330/486 in epoch 1195, batch loss: 1.62258, batch accuracy: 0.55750
Time: 2018-07-15 10:12:24
TRAINING STATS: batch 380/486 in epoch 1195, batch loss: 1.62979, batch accuracy: 0.56167
Time: 2018-07-15 10:12:29
TRAINING STATS: batch 430/486 in epoch 1195, batch loss: 1.61366, batch accuracy: 0.56583
Time: 2018-07-15 10:12:32
TRAINING STATS: batch 480/486 in epoch 1195, batch loss: 1.68508, batch accuracy: 0.54200
Time: 2018-07-15 10:12:36
TRAINING STATS: batch 44/486 in epoch 1196,  batch loss: 1.61160, batch accuracy: 0.56883
Time: 2018-07-15 10:12:41
TRAINING STATS: batch 94/486 in epoch 1196,  batch loss: 1.71927, batch accuracy: 0.52667
Time: 2018-07-15 10:12:44
TRAINING STATS: batch 144/486 in epoch 1196, batch loss: 1.72975, batch accuracy: 0.52517
Time: 2018-07-15 10:12:48
TRAINING STATS: batch 194/486 in epoch 1196, batch loss: 1.76118, batch accuracy: 0.52000
Time: 2018-07-15 10:12:53
TRAINING STATS: batch 244/486 in epoch 1196, batch loss: 1.63495, batch accuracy: 0.56033
Time: 2018-07-15 10:12:56
TRAINING STATS: batch 294/486 in epoch 1196, batch loss: 1.57280, batch accuracy: 0.57300
Time: 2018-07-15 10:13:00
TRAINING STATS: batch 344/486 in epoch 1196, batch loss: 1.63395, batch accuracy: 0.55367
Time: 2018-07-15 10:13:05
TRAINING STATS: batch 394/486 in epoch 1196, batch loss: 1.62116, batch accuracy: 0.56567
Time: 2018-07-15 10:13:09
TRAINING STATS: batch 444/486 in epoch 1196, batch loss: 1.61355, batch accuracy: 0.56583
Time: 2018-07-15 10:13:12
TRAINING STATS: batch 8/486 in epoch 1197,   batch loss: 1.65213, batch accuracy: 0.55367
Time: 2018-07-15 10:13:17
TRAINING STATS: batch 58/486 in epoch 1197,  batch loss: 1.62885, batch accuracy: 0.56383
Time: 2018-07-15 10:13:21
TRAINING STATS: batch 108/486 in epoch 1197, batch loss: 1.72873, batch accuracy: 0.54200
Time: 2018-07-15 10:13:24
TRAINING STATS: batch 158/486 in epoch 1197, batch loss: 1.73311, batch accuracy: 0.53083
Time: 2018-07-15 10:13:29
TRAINING STATS: batch 208/486 in epoch 1197, batch loss: 1.68303, batch accuracy: 0.54783
Time: 2018-07-15 10:13:33
TRAINING STATS: batch 258/486 in epoch 1197, batch loss: 1.60907, batch accuracy: 0.56900
Time: 2018-07-15 10:13:36
TRAINING STATS: batch 308/486 in epoch 1197, batch loss: 1.68216, batch accuracy: 0.54767
Time: 2018-07-15 10:13:41
TRAINING STATS: batch 358/486 in epoch 1197, batch loss: 1.69417, batch accuracy: 0.53283
Time: 2018-07-15 10:13:45
TRAINING STATS: batch 408/486 in epoch 1197, batch loss: 1.71887, batch accuracy: 0.52650
Time: 2018-07-15 10:13:49
TRAINING STATS: batch 458/486 in epoch 1197, batch loss: 1.67528, batch accuracy: 0.55033
Time: 2018-07-15 10:13:53
TRAINING STATS: batch 22/486 in epoch 1198,  batch loss: 1.78928, batch accuracy: 0.51583
Time: 2018-07-15 10:13:57
TRAINING STATS: batch 72/486 in epoch 1198,  batch loss: 1.68290, batch accuracy: 0.54250
Time: 2018-07-15 10:14:01
TRAINING STATS: batch 122/486 in epoch 1198, batch loss: 1.63231, batch accuracy: 0.55317
Time: 2018-07-15 10:14:06
TRAINING STATS: batch 172/486 in epoch 1198, batch loss: 1.71548, batch accuracy: 0.53217
Time: 2018-07-15 10:14:09
TRAINING STATS: batch 222/486 in epoch 1198, batch loss: 1.67772, batch accuracy: 0.53083
Time: 2018-07-15 10:14:13
TRAINING STATS: batch 272/486 in epoch 1198, batch loss: 1.68472, batch accuracy: 0.53217
Time: 2018-07-15 10:14:18
TRAINING STATS: batch 322/486 in epoch 1198, batch loss: 1.65565, batch accuracy: 0.54683
Time: 2018-07-15 10:14:21
TRAINING STATS: batch 372/486 in epoch 1198, batch loss: 1.59957, batch accuracy: 0.56817
Time: 2018-07-15 10:14:25
TRAINING STATS: batch 422/486 in epoch 1198, batch loss: 1.62559, batch accuracy: 0.55567
Time: 2018-07-15 10:14:30
TRAINING STATS: batch 472/486 in epoch 1198, batch loss: 1.70956, batch accuracy: 0.53817
Time: 2018-07-15 10:14:33
TRAINING STATS: batch 36/486 in epoch 1199,  batch loss: 1.71745, batch accuracy: 0.53467
Time: 2018-07-15 10:14:37
TRAINING STATS: batch 86/486 in epoch 1199,  batch loss: 1.69635, batch accuracy: 0.54433
Time: 2018-07-15 10:14:42
TRAINING STATS: batch 136/486 in epoch 1199, batch loss: 1.73297, batch accuracy: 0.53367
Time: 2018-07-15 10:14:46
TRAINING STATS: batch 186/486 in epoch 1199, batch loss: 1.68045, batch accuracy: 0.54967
Time: 2018-07-15 10:14:49
TRAINING STATS: batch 236/486 in epoch 1199, batch loss: 1.69612, batch accuracy: 0.54033
Time: 2018-07-15 10:14:54
TRAINING STATS: batch 286/486 in epoch 1199, batch loss: 1.68835, batch accuracy: 0.55000
Time: 2018-07-15 10:14:58
TRAINING STATS: batch 336/486 in epoch 1199, batch loss: 1.65656, batch accuracy: 0.55300
Time: 2018-07-15 10:15:02
TRAINING STATS: batch 386/486 in epoch 1199, batch loss: 1.70410, batch accuracy: 0.53650
Time: 2018-07-15 10:15:06
TRAINING STATS: batch 436/486 in epoch 1199, batch loss: 1.70048, batch accuracy: 0.53667
Time: 2018-07-15 10:15:10
TRAINING STATS: batch 0/486 in epoch 1200,   batch loss: 1.64763, batch accuracy: 0.55200
Time: 2018-07-15 10:15:14
TRAINING STATS: batch 50/486 in epoch 1200,  batch loss: 1.62153, batch accuracy: 0.56483
Time: 2018-07-15 10:15:18
TRAINING STATS: batch 100/486 in epoch 1200, batch loss: 1.68150, batch accuracy: 0.55500
Time: 2018-07-15 10:15:22
TRAINING STATS: batch 150/486 in epoch 1200, batch loss: 1.63513, batch accuracy: 0.56317
Time: 2018-07-15 10:15:26
TRAINING STATS: batch 200/486 in epoch 1200, batch loss: 1.54888, batch accuracy: 0.58850
Time: 2018-07-15 10:15:30
TRAINING STATS: batch 250/486 in epoch 1200, batch loss: 1.71536, batch accuracy: 0.53333
Time: 2018-07-15 10:15:34
TRAINING STATS: batch 300/486 in epoch 1200, batch loss: 1.70709, batch accuracy: 0.52517
Time: 2018-07-15 10:15:38
TRAINING STATS: batch 350/486 in epoch 1200, batch loss: 1.70985, batch accuracy: 0.54683
Time: 2018-07-15 10:15:43
TRAINING STATS: batch 400/486 in epoch 1200, batch loss: 1.54167, batch accuracy: 0.58117
Time: 2018-07-15 10:15:46
TRAINING STATS: batch 450/486 in epoch 1200, batch loss: 1.73414, batch accuracy: 0.52500
Time: 2018-07-15 10:15:50
TRAINING STATS: batch 14/486 in epoch 1201,  batch loss: 1.59674, batch accuracy: 0.57467
Time: 2018-07-15 10:15:55
TRAINING STATS: batch 64/486 in epoch 1201,  batch loss: 1.73665, batch accuracy: 0.53167
Time: 2018-07-15 10:15:58
TRAINING STATS: batch 114/486 in epoch 1201, batch loss: 1.71610, batch accuracy: 0.54183
Time: 2018-07-15 10:16:02
TRAINING STATS: batch 164/486 in epoch 1201, batch loss: 1.60086, batch accuracy: 0.57317
Time: 2018-07-15 10:16:07
TRAINING STATS: batch 214/486 in epoch 1201, batch loss: 1.69955, batch accuracy: 0.53600
Time: 2018-07-15 10:16:10
TRAINING STATS: batch 264/486 in epoch 1201, batch loss: 1.71660, batch accuracy: 0.52483
Time: 2018-07-15 10:16:14
TRAINING STATS: batch 314/486 in epoch 1201, batch loss: 1.73647, batch accuracy: 0.52900
Time: 2018-07-15 10:16:19
TRAINING STATS: batch 364/486 in epoch 1201, batch loss: 1.65013, batch accuracy: 0.55100
Time: 2018-07-15 10:16:23
TRAINING STATS: batch 414/486 in epoch 1201, batch loss: 1.61345, batch accuracy: 0.56867
Time: 2018-07-15 10:16:26
TRAINING STATS: batch 464/486 in epoch 1201, batch loss: 1.62648, batch accuracy: 0.55967
Time: 2018-07-15 10:16:31
TRAINING STATS: batch 28/486 in epoch 1202,  batch loss: 1.60828, batch accuracy: 0.57033
Time: 2018-07-15 10:16:35
TRAINING STATS: batch 78/486 in epoch 1202,  batch loss: 1.67107, batch accuracy: 0.54717
Time: 2018-07-15 10:16:38
TRAINING STATS: batch 128/486 in epoch 1202, batch loss: 1.67611, batch accuracy: 0.54450
Time: 2018-07-15 10:16:43
TRAINING STATS: batch 178/486 in epoch 1202, batch loss: 1.55709, batch accuracy: 0.57783
Time: 2018-07-15 10:16:47
TRAINING STATS: batch 228/486 in epoch 1202, batch loss: 1.59886, batch accuracy: 0.57283
Time: 2018-07-15 10:16:50
TRAINING STATS: batch 278/486 in epoch 1202, batch loss: 1.57738, batch accuracy: 0.57833
Time: 2018-07-15 10:16:55
TRAINING STATS: batch 328/486 in epoch 1202, batch loss: 1.61909, batch accuracy: 0.55650
Time: 2018-07-15 10:16:59
TRAINING STATS: batch 378/486 in epoch 1202, batch loss: 1.65406, batch accuracy: 0.55417
Time: 2018-07-15 10:17:03
TRAINING STATS: batch 428/486 in epoch 1202, batch loss: 1.72537, batch accuracy: 0.53033
Time: 2018-07-15 10:17:07
TRAINING STATS: batch 478/486 in epoch 1202, batch loss: 1.66016, batch accuracy: 0.54967
Time: 2018-07-15 10:17:11
TRAINING STATS: batch 42/486 in epoch 1203,  batch loss: 1.57150, batch accuracy: 0.57983
Time: 2018-07-15 10:17:15
TRAINING STATS: batch 92/486 in epoch 1203,  batch loss: 1.66545, batch accuracy: 0.55450
Time: 2018-07-15 10:17:20
TRAINING STATS: batch 142/486 in epoch 1203, batch loss: 1.61112, batch accuracy: 0.56333
Time: 2018-07-15 10:17:23
TRAINING STATS: batch 192/486 in epoch 1203, batch loss: 1.66440, batch accuracy: 0.55200
Time: 2018-07-15 10:17:27
TRAINING STATS: batch 242/486 in epoch 1203, batch loss: 1.64977, batch accuracy: 0.55250
Time: 2018-07-15 10:17:32
TRAINING STATS: batch 292/486 in epoch 1203, batch loss: 1.62651, batch accuracy: 0.55233
Time: 2018-07-15 10:17:35
TRAINING STATS: batch 342/486 in epoch 1203, batch loss: 1.60802, batch accuracy: 0.56617
Time: 2018-07-15 10:17:39
TRAINING STATS: batch 392/486 in epoch 1203, batch loss: 1.57036, batch accuracy: 0.57867
Time: 2018-07-15 10:17:44
TRAINING STATS: batch 442/486 in epoch 1203, batch loss: 1.55747, batch accuracy: 0.58200
Time: 2018-07-15 10:17:48
TRAINING STATS: batch 6/486 in epoch 1204,   batch loss: 1.71008, batch accuracy: 0.53750
Time: 2018-07-15 10:17:51
TRAINING STATS: batch 56/486 in epoch 1204,  batch loss: 1.61046, batch accuracy: 0.55400
Time: 2018-07-15 10:17:56
TRAINING STATS: batch 106/486 in epoch 1204, batch loss: 1.72609, batch accuracy: 0.53533
Time: 2018-07-15 10:18:00
TRAINING STATS: batch 156/486 in epoch 1204, batch loss: 1.68491, batch accuracy: 0.55067
Time: 2018-07-15 10:18:03
TRAINING STATS: batch 206/486 in epoch 1204, batch loss: 1.73563, batch accuracy: 0.53017
Time: 2018-07-15 10:18:08
TRAINING STATS: batch 256/486 in epoch 1204, batch loss: 1.59594, batch accuracy: 0.57167
Time: 2018-07-15 10:18:12
TRAINING STATS: batch 306/486 in epoch 1204, batch loss: 1.65330, batch accuracy: 0.55383
Time: 2018-07-15 10:18:15
TRAINING STATS: batch 356/486 in epoch 1204, batch loss: 1.69877, batch accuracy: 0.54217
Time: 2018-07-15 10:18:20
TRAINING STATS: batch 406/486 in epoch 1204, batch loss: 1.73159, batch accuracy: 0.52400
Time: 2018-07-15 10:18:24
TRAINING STATS: batch 456/486 in epoch 1204, batch loss: 1.53762, batch accuracy: 0.58533
Time: 2018-07-15 10:18:28
TRAINING STATS: batch 20/486 in epoch 1205,  batch loss: 1.65229, batch accuracy: 0.55850
Time: 2018-07-15 10:18:32
TRAINING STATS: batch 70/486 in epoch 1205,  batch loss: 1.55264, batch accuracy: 0.58017
Time: 2018-07-15 10:18:36
TRAINING STATS: batch 120/486 in epoch 1205, batch loss: 1.62820, batch accuracy: 0.55850
Time: 2018-07-15 10:18:40
TRAINING STATS: batch 170/486 in epoch 1205, batch loss: 1.62163, batch accuracy: 0.56433
Time: 2018-07-15 10:18:44
TRAINING STATS: batch 220/486 in epoch 1205, batch loss: 1.56416, batch accuracy: 0.58333
Time: 2018-07-15 10:18:48
TRAINING STATS: batch 270/486 in epoch 1205, batch loss: 1.66281, batch accuracy: 0.54967
Time: 2018-07-15 10:18:52
TRAINING STATS: batch 320/486 in epoch 1205, batch loss: 1.59565, batch accuracy: 0.56450
Time: 2018-07-15 10:18:56
TRAINING STATS: batch 370/486 in epoch 1205, batch loss: 1.65682, batch accuracy: 0.55533
Time: 2018-07-15 10:19:00
TRAINING STATS: batch 420/486 in epoch 1205, batch loss: 1.70071, batch accuracy: 0.53933
Time: 2018-07-15 10:19:04
TRAINING STATS: batch 470/486 in epoch 1205, batch loss: 1.73356, batch accuracy: 0.52700
Time: 2018-07-15 10:19:09
TRAINING STATS: batch 34/486 in epoch 1206,  batch loss: 1.67935, batch accuracy: 0.53967
Time: 2018-07-15 10:19:12
TRAINING STATS: batch 84/486 in epoch 1206,  batch loss: 1.70416, batch accuracy: 0.53467
Time: 2018-07-15 10:19:16
TRAINING STATS: batch 134/486 in epoch 1206, batch loss: 1.69418, batch accuracy: 0.54533
Time: 2018-07-15 10:19:21
TRAINING STATS: batch 184/486 in epoch 1206, batch loss: 1.66971, batch accuracy: 0.55100
Time: 2018-07-15 10:19:24
TRAINING STATS: batch 234/486 in epoch 1206, batch loss: 1.74129, batch accuracy: 0.52117
Time: 2018-07-15 10:19:28
TRAINING STATS: batch 284/486 in epoch 1206, batch loss: 1.71460, batch accuracy: 0.53500
Time: 2018-07-15 10:19:33
TRAINING STATS: batch 334/486 in epoch 1206, batch loss: 1.65981, batch accuracy: 0.55017
Time: 2018-07-15 10:19:37
TRAINING STATS: batch 384/486 in epoch 1206, batch loss: 1.67258, batch accuracy: 0.54600
Time: 2018-07-15 10:19:40
TRAINING STATS: batch 434/486 in epoch 1206, batch loss: 1.71403, batch accuracy: 0.53250
Time: 2018-07-15 10:19:45
TRAINING STATS: batch 484/486 in epoch 1206, batch loss: 1.67013, batch accuracy: 0.54317
Time: 2018-07-15 10:19:49
TRAINING STATS: batch 48/486 in epoch 1207,  batch loss: 1.63703, batch accuracy: 0.55133
Time: 2018-07-15 10:19:52
TRAINING STATS: batch 98/486 in epoch 1207,  batch loss: 1.60503, batch accuracy: 0.56783
Time: 2018-07-15 10:19:57
TRAINING STATS: batch 148/486 in epoch 1207, batch loss: 1.69546, batch accuracy: 0.54733
Time: 2018-07-15 10:20:01
TRAINING STATS: batch 198/486 in epoch 1207, batch loss: 1.64277, batch accuracy: 0.55550
Time: 2018-07-15 10:20:04
TRAINING STATS: batch 248/486 in epoch 1207, batch loss: 1.71281, batch accuracy: 0.54433
Time: 2018-07-15 10:20:09
TRAINING STATS: batch 298/486 in epoch 1207, batch loss: 1.74589, batch accuracy: 0.51867
Time: 2018-07-15 10:20:13
TRAINING STATS: batch 348/486 in epoch 1207, batch loss: 1.66442, batch accuracy: 0.55650
Time: 2018-07-15 10:20:16
TRAINING STATS: batch 398/486 in epoch 1207, batch loss: 1.67954, batch accuracy: 0.53950
Time: 2018-07-15 10:20:21
TRAINING STATS: batch 448/486 in epoch 1207, batch loss: 1.64708, batch accuracy: 0.55633
Time: 2018-07-15 10:20:25
TRAINING STATS: batch 12/486 in epoch 1208,  batch loss: 1.66903, batch accuracy: 0.55133
Time: 2018-07-15 10:20:29
TRAINING STATS: batch 62/486 in epoch 1208,  batch loss: 1.74111, batch accuracy: 0.52067
Time: 2018-07-15 10:20:33
TRAINING STATS: batch 112/486 in epoch 1208, batch loss: 1.67734, batch accuracy: 0.54067
Time: 2018-07-15 10:20:37
TRAINING STATS: batch 162/486 in epoch 1208, batch loss: 1.66696, batch accuracy: 0.55067
Time: 2018-07-15 10:20:41
TRAINING STATS: batch 212/486 in epoch 1208, batch loss: 1.58782, batch accuracy: 0.56783
Time: 2018-07-15 10:20:46
TRAINING STATS: batch 262/486 in epoch 1208, batch loss: 1.72262, batch accuracy: 0.53750
Time: 2018-07-15 10:20:49
TRAINING STATS: batch 312/486 in epoch 1208, batch loss: 1.67987, batch accuracy: 0.53800
Time: 2018-07-15 10:20:53
TRAINING STATS: batch 362/486 in epoch 1208, batch loss: 1.68601, batch accuracy: 0.53617
Time: 2018-07-15 10:20:58
TRAINING STATS: batch 412/486 in epoch 1208, batch loss: 1.59189, batch accuracy: 0.57783
Time: 2018-07-15 10:21:01
TRAINING STATS: batch 462/486 in epoch 1208, batch loss: 1.66580, batch accuracy: 0.54317
Time: 2018-07-15 10:21:05
TRAINING STATS: batch 26/486 in epoch 1209,  batch loss: 1.81559, batch accuracy: 0.51883
Time: 2018-07-15 10:21:10
TRAINING STATS: batch 76/486 in epoch 1209,  batch loss: 1.83329, batch accuracy: 0.49550
Time: 2018-07-15 10:21:14
TRAINING STATS: batch 126/486 in epoch 1209, batch loss: 1.72549, batch accuracy: 0.53017
Time: 2018-07-15 10:21:17
TRAINING STATS: batch 176/486 in epoch 1209, batch loss: 1.60532, batch accuracy: 0.56533
Time: 2018-07-15 10:21:22
TRAINING STATS: batch 226/486 in epoch 1209, batch loss: 1.65019, batch accuracy: 0.55050
Time: 2018-07-15 10:21:26
TRAINING STATS: batch 276/486 in epoch 1209, batch loss: 1.66927, batch accuracy: 0.54700
Time: 2018-07-15 10:21:29
TRAINING STATS: batch 326/486 in epoch 1209, batch loss: 1.71277, batch accuracy: 0.52983
Time: 2018-07-15 10:21:34
TRAINING STATS: batch 376/486 in epoch 1209, batch loss: 1.71831, batch accuracy: 0.53333
Time: 2018-07-15 10:21:38
TRAINING STATS: batch 426/486 in epoch 1209, batch loss: 1.65169, batch accuracy: 0.54850
Time: 2018-07-15 10:21:41
TRAINING STATS: batch 476/486 in epoch 1209, batch loss: 1.60191, batch accuracy: 0.57083
Time: 2018-07-15 10:21:46
TRAINING STATS: batch 40/486 in epoch 1210,  batch loss: 1.64375, batch accuracy: 0.55983
Time: 2018-07-15 10:21:50
TRAINING STATS: batch 90/486 in epoch 1210,  batch loss: 1.69654, batch accuracy: 0.54450
Time: 2018-07-15 10:21:54
TRAINING STATS: batch 140/486 in epoch 1210, batch loss: 1.58926, batch accuracy: 0.56983
Time: 2018-07-15 10:21:58
TRAINING STATS: batch 190/486 in epoch 1210, batch loss: 1.63300, batch accuracy: 0.56167
Time: 2018-07-15 10:22:02
TRAINING STATS: batch 240/486 in epoch 1210, batch loss: 1.64228, batch accuracy: 0.55083
Time: 2018-07-15 10:22:06
TRAINING STATS: batch 290/486 in epoch 1210, batch loss: 1.67642, batch accuracy: 0.54450
Time: 2018-07-15 10:22:10
TRAINING STATS: batch 340/486 in epoch 1210, batch loss: 1.80790, batch accuracy: 0.50983
Time: 2018-07-15 10:22:14
TRAINING STATS: batch 390/486 in epoch 1210, batch loss: 1.60889, batch accuracy: 0.56400
Time: 2018-07-15 10:22:18
TRAINING STATS: batch 440/486 in epoch 1210, batch loss: 1.66915, batch accuracy: 0.55417
Time: 2018-07-15 10:22:22
TRAINING STATS: batch 4/486 in epoch 1211,   batch loss: 1.59894, batch accuracy: 0.56817
Time: 2018-07-15 10:22:26
TRAINING STATS: batch 54/486 in epoch 1211,  batch loss: 1.66843, batch accuracy: 0.54167
Time: 2018-07-15 10:22:30
TRAINING STATS: batch 104/486 in epoch 1211, batch loss: 1.68324, batch accuracy: 0.55167
Time: 2018-07-15 10:22:35
TRAINING STATS: batch 154/486 in epoch 1211, batch loss: 1.64478, batch accuracy: 0.55717
Time: 2018-07-15 10:22:38
TRAINING STATS: batch 204/486 in epoch 1211, batch loss: 1.71748, batch accuracy: 0.53933
Time: 2018-07-15 10:22:42
TRAINING STATS: batch 254/486 in epoch 1211, batch loss: 1.58327, batch accuracy: 0.56733
Time: 2018-07-15 10:22:47
TRAINING STATS: batch 304/486 in epoch 1211, batch loss: 1.65222, batch accuracy: 0.55600
Time: 2018-07-15 10:22:50
TRAINING STATS: batch 354/486 in epoch 1211, batch loss: 1.71169, batch accuracy: 0.53100
Time: 2018-07-15 10:22:54
TRAINING STATS: batch 404/486 in epoch 1211, batch loss: 1.66460, batch accuracy: 0.55450
Time: 2018-07-15 10:22:59
TRAINING STATS: batch 454/486 in epoch 1211, batch loss: 1.54703, batch accuracy: 0.58300
Time: 2018-07-15 10:23:03
TRAINING STATS: batch 18/486 in epoch 1212,  batch loss: 1.70347, batch accuracy: 0.53533
Time: 2018-07-15 10:23:06
TRAINING STATS: batch 68/486 in epoch 1212,  batch loss: 1.94980, batch accuracy: 0.47233
Time: 2018-07-15 10:23:11
TRAINING STATS: batch 118/486 in epoch 1212, batch loss: 1.97571, batch accuracy: 0.47983
Time: 2018-07-15 10:23:15
TRAINING STATS: batch 168/486 in epoch 1212, batch loss: 1.90974, batch accuracy: 0.49067
Time: 2018-07-15 10:23:18
TRAINING STATS: batch 218/486 in epoch 1212, batch loss: 1.91444, batch accuracy: 0.49133
Time: 2018-07-15 10:23:23
TRAINING STATS: batch 268/486 in epoch 1212, batch loss: 1.86574, batch accuracy: 0.50450
Time: 2018-07-15 10:23:27
TRAINING STATS: batch 318/486 in epoch 1212, batch loss: 1.92685, batch accuracy: 0.48117
Time: 2018-07-15 10:23:31
TRAINING STATS: batch 368/486 in epoch 1212, batch loss: 1.92478, batch accuracy: 0.48283
Time: 2018-07-15 10:23:35
TRAINING STATS: batch 418/486 in epoch 1212, batch loss: 1.96143, batch accuracy: 0.46033
Time: 2018-07-15 10:23:39
TRAINING STATS: batch 468/486 in epoch 1212, batch loss: 1.84786, batch accuracy: 0.50350
Time: 2018-07-15 10:23:43
TRAINING STATS: batch 32/486 in epoch 1213,  batch loss: 1.82995, batch accuracy: 0.50333
Time: 2018-07-15 10:23:48
TRAINING STATS: batch 82/486 in epoch 1213,  batch loss: 1.86395, batch accuracy: 0.49967
Time: 2018-07-15 10:23:51
TRAINING STATS: batch 132/486 in epoch 1213, batch loss: 1.80741, batch accuracy: 0.51650
Time: 2018-07-15 10:23:55
TRAINING STATS: batch 182/486 in epoch 1213, batch loss: 1.83435, batch accuracy: 0.51417
Time: 2018-07-15 10:24:00
TRAINING STATS: batch 232/486 in epoch 1213, batch loss: 1.81717, batch accuracy: 0.50883
Time: 2018-07-15 10:24:03
TRAINING STATS: batch 282/486 in epoch 1213, batch loss: 1.75510, batch accuracy: 0.53217
Time: 2018-07-15 10:24:07
TRAINING STATS: batch 332/486 in epoch 1213, batch loss: 1.82826, batch accuracy: 0.51000
Time: 2018-07-15 10:24:12
TRAINING STATS: batch 382/486 in epoch 1213, batch loss: 1.78328, batch accuracy: 0.52117
Time: 2018-07-15 10:24:15
TRAINING STATS: batch 432/486 in epoch 1213, batch loss: 1.71668, batch accuracy: 0.53783
Time: 2018-07-15 10:24:19
TRAINING STATS: batch 482/486 in epoch 1213, batch loss: 1.77566, batch accuracy: 0.51733
Time: 2018-07-15 10:24:24
TRAINING STATS: batch 46/486 in epoch 1214,  batch loss: 1.72415, batch accuracy: 0.53800
Time: 2018-07-15 10:24:28
TRAINING STATS: batch 96/486 in epoch 1214,  batch loss: 1.77839, batch accuracy: 0.52217
Time: 2018-07-15 10:24:31
TRAINING STATS: batch 146/486 in epoch 1214, batch loss: 1.79131, batch accuracy: 0.52750
Time: 2018-07-15 10:24:36
TRAINING STATS: batch 196/486 in epoch 1214, batch loss: 1.77089, batch accuracy: 0.52433
Time: 2018-07-15 10:24:40
TRAINING STATS: batch 246/486 in epoch 1214, batch loss: 1.70204, batch accuracy: 0.54600
Time: 2018-07-15 10:24:43
TRAINING STATS: batch 296/486 in epoch 1214, batch loss: 1.71889, batch accuracy: 0.52683
Time: 2018-07-15 10:24:48
TRAINING STATS: batch 346/486 in epoch 1214, batch loss: 1.64212, batch accuracy: 0.55933
Time: 2018-07-15 10:24:52
TRAINING STATS: batch 396/486 in epoch 1214, batch loss: 1.73001, batch accuracy: 0.53750
Time: 2018-07-15 10:24:55
TRAINING STATS: batch 446/486 in epoch 1214, batch loss: 1.74518, batch accuracy: 0.53617
Time: 2018-07-15 10:25:00
TRAINING STATS: batch 10/486 in epoch 1215,  batch loss: 1.75951, batch accuracy: 0.51933
Time: 2018-07-15 10:25:04
TRAINING STATS: batch 60/486 in epoch 1215,  batch loss: 1.72481, batch accuracy: 0.53550
Time: 2018-07-15 10:25:08
TRAINING STATS: batch 110/486 in epoch 1215, batch loss: 1.76980, batch accuracy: 0.52767
Time: 2018-07-15 10:25:12
TRAINING STATS: batch 160/486 in epoch 1215, batch loss: 1.69265, batch accuracy: 0.54117
Time: 2018-07-15 10:25:16
TRAINING STATS: batch 210/486 in epoch 1215, batch loss: 1.71210, batch accuracy: 0.53600
Time: 2018-07-15 10:25:20
TRAINING STATS: batch 260/486 in epoch 1215, batch loss: 1.74191, batch accuracy: 0.53683
Time: 2018-07-15 10:25:24
TRAINING STATS: batch 310/486 in epoch 1215, batch loss: 1.73656, batch accuracy: 0.53183
Time: 2018-07-15 10:25:28
TRAINING STATS: batch 360/486 in epoch 1215, batch loss: 1.74005, batch accuracy: 0.52750
Time: 2018-07-15 10:25:32
TRAINING STATS: batch 410/486 in epoch 1215, batch loss: 1.66703, batch accuracy: 0.55767
Time: 2018-07-15 10:25:36
TRAINING STATS: batch 460/486 in epoch 1215, batch loss: 1.82946, batch accuracy: 0.50450
Time: 2018-07-15 10:25:40
TRAINING STATS: batch 24/486 in epoch 1216,  batch loss: 1.77540, batch accuracy: 0.52617
Time: 2018-07-15 10:25:44
TRAINING STATS: batch 74/486 in epoch 1216,  batch loss: 1.76051, batch accuracy: 0.52050
Time: 2018-07-15 10:25:49
TRAINING STATS: batch 124/486 in epoch 1216, batch loss: 1.74889, batch accuracy: 0.52783
Time: 2018-07-15 10:25:52
TRAINING STATS: batch 174/486 in epoch 1216, batch loss: 1.79253, batch accuracy: 0.51867
Time: 2018-07-15 10:25:56
TRAINING STATS: batch 224/486 in epoch 1216, batch loss: 1.74408, batch accuracy: 0.53017
Time: 2018-07-15 10:26:01
TRAINING STATS: batch 274/486 in epoch 1216, batch loss: 1.73036, batch accuracy: 0.53000
Time: 2018-07-15 10:26:04
TRAINING STATS: batch 324/486 in epoch 1216, batch loss: 1.74587, batch accuracy: 0.52733
Time: 2018-07-15 10:26:08
TRAINING STATS: batch 374/486 in epoch 1216, batch loss: 1.73750, batch accuracy: 0.53450
Time: 2018-07-15 10:26:13
TRAINING STATS: batch 424/486 in epoch 1216, batch loss: 1.66758, batch accuracy: 0.54967
Time: 2018-07-15 10:26:16
TRAINING STATS: batch 474/486 in epoch 1216, batch loss: 1.84788, batch accuracy: 0.49350
Time: 2018-07-15 10:26:20
TRAINING STATS: batch 38/486 in epoch 1217,  batch loss: 1.80273, batch accuracy: 0.51167
Time: 2018-07-15 10:26:25
TRAINING STATS: batch 88/486 in epoch 1217,  batch loss: 1.81379, batch accuracy: 0.50017
Time: 2018-07-15 10:26:29
TRAINING STATS: batch 138/486 in epoch 1217, batch loss: 1.77820, batch accuracy: 0.52233
Time: 2018-07-15 10:26:32
TRAINING STATS: batch 188/486 in epoch 1217, batch loss: 1.68179, batch accuracy: 0.54683
Time: 2018-07-15 10:26:37
TRAINING STATS: batch 238/486 in epoch 1217, batch loss: 1.72998, batch accuracy: 0.53850
Time: 2018-07-15 10:26:41
TRAINING STATS: batch 288/486 in epoch 1217, batch loss: 1.76202, batch accuracy: 0.51750
Time: 2018-07-15 10:26:44
TRAINING STATS: batch 338/486 in epoch 1217, batch loss: 1.73152, batch accuracy: 0.52800
Time: 2018-07-15 10:26:49
TRAINING STATS: batch 388/486 in epoch 1217, batch loss: 1.68307, batch accuracy: 0.54833
Time: 2018-07-15 10:26:53
TRAINING STATS: batch 438/486 in epoch 1217, batch loss: 1.76696, batch accuracy: 0.52883
Time: 2018-07-15 10:26:57
TRAINING STATS: batch 2/486 in epoch 1218,   batch loss: 1.73149, batch accuracy: 0.53450
Time: 2018-07-15 10:27:01
TRAINING STATS: batch 52/486 in epoch 1218,  batch loss: 1.77887, batch accuracy: 0.50950
Time: 2018-07-15 10:27:05
TRAINING STATS: batch 102/486 in epoch 1218, batch loss: 1.74693, batch accuracy: 0.52867
Time: 2018-07-15 10:27:09
TRAINING STATS: batch 152/486 in epoch 1218, batch loss: 1.67164, batch accuracy: 0.55117
Time: 2018-07-15 10:27:13
TRAINING STATS: batch 202/486 in epoch 1218, batch loss: 1.71463, batch accuracy: 0.54500
Time: 2018-07-15 10:27:17
TRAINING STATS: batch 252/486 in epoch 1218, batch loss: 1.71254, batch accuracy: 0.53350
Time: 2018-07-15 10:27:21
TRAINING STATS: batch 302/486 in epoch 1218, batch loss: 1.68209, batch accuracy: 0.54483
Time: 2018-07-15 10:27:26
TRAINING STATS: batch 352/486 in epoch 1218, batch loss: 1.71371, batch accuracy: 0.53617
Time: 2018-07-15 10:27:29
TRAINING STATS: batch 402/486 in epoch 1218, batch loss: 1.58930, batch accuracy: 0.57483
Time: 2018-07-15 10:27:33
TRAINING STATS: batch 452/486 in epoch 1218, batch loss: 1.75799, batch accuracy: 0.52333
Time: 2018-07-15 10:27:38
TRAINING STATS: batch 16/486 in epoch 1219,  batch loss: 1.69747, batch accuracy: 0.55217
Time: 2018-07-15 10:27:41
TRAINING STATS: batch 66/486 in epoch 1219,  batch loss: 1.70715, batch accuracy: 0.53667
Time: 2018-07-15 10:27:45
TRAINING STATS: batch 116/486 in epoch 1219, batch loss: 1.68258, batch accuracy: 0.54783
Time: 2018-07-15 10:27:50
TRAINING STATS: batch 166/486 in epoch 1219, batch loss: 1.64561, batch accuracy: 0.55550
Time: 2018-07-15 10:27:54
TRAINING STATS: batch 216/486 in epoch 1219, batch loss: 1.76349, batch accuracy: 0.51783
Time: 2018-07-15 10:27:57
TRAINING STATS: batch 266/486 in epoch 1219, batch loss: 1.69982, batch accuracy: 0.53783
Time: 2018-07-15 10:28:02
TRAINING STATS: batch 316/486 in epoch 1219, batch loss: 1.70790, batch accuracy: 0.53767
Time: 2018-07-15 10:28:06
TRAINING STATS: batch 366/486 in epoch 1219, batch loss: 1.76624, batch accuracy: 0.52500
Time: 2018-07-15 10:28:09
TRAINING STATS: batch 416/486 in epoch 1219, batch loss: 1.77011, batch accuracy: 0.51983
Time: 2018-07-15 10:28:14
TRAINING STATS: batch 466/486 in epoch 1219, batch loss: 1.58669, batch accuracy: 0.56433
Time: 2018-07-15 10:28:18
TRAINING STATS: batch 30/486 in epoch 1220,  batch loss: 1.62196, batch accuracy: 0.56300
Time: 2018-07-15 10:28:21
TRAINING STATS: batch 80/486 in epoch 1220,  batch loss: 1.70181, batch accuracy: 0.53700
Time: 2018-07-15 10:28:26
TRAINING STATS: batch 130/486 in epoch 1220, batch loss: 1.70767, batch accuracy: 0.53683
Time: 2018-07-15 10:28:30
TRAINING STATS: batch 180/486 in epoch 1220, batch loss: 1.75186, batch accuracy: 0.53633
Time: 2018-07-15 10:28:34
TRAINING STATS: batch 230/486 in epoch 1220, batch loss: 1.72164, batch accuracy: 0.52783
Time: 2018-07-15 10:28:38
TRAINING STATS: batch 280/486 in epoch 1220, batch loss: 1.70195, batch accuracy: 0.53017
Time: 2018-07-15 10:28:42
TRAINING STATS: batch 330/486 in epoch 1220, batch loss: 1.68919, batch accuracy: 0.55250
Time: 2018-07-15 10:28:46
TRAINING STATS: batch 380/486 in epoch 1220, batch loss: 1.67346, batch accuracy: 0.54450
Time: 2018-07-15 10:28:50
TRAINING STATS: batch 430/486 in epoch 1220, batch loss: 1.64742, batch accuracy: 0.55467
Time: 2018-07-15 10:28:54
TRAINING STATS: batch 480/486 in epoch 1220, batch loss: 1.72377, batch accuracy: 0.53567
Time: 2018-07-15 10:28:58
TRAINING STATS: batch 44/486 in epoch 1221,  batch loss: 1.65274, batch accuracy: 0.55183
Time: 2018-07-15 10:29:02
TRAINING STATS: batch 94/486 in epoch 1221,  batch loss: 1.76354, batch accuracy: 0.52567
Time: 2018-07-15 10:29:06
TRAINING STATS: batch 144/486 in epoch 1221, batch loss: 1.75576, batch accuracy: 0.52467
Time: 2018-07-15 10:29:10
TRAINING STATS: batch 194/486 in epoch 1221, batch loss: 1.80723, batch accuracy: 0.51033
Time: 2018-07-15 10:29:15
TRAINING STATS: batch 244/486 in epoch 1221, batch loss: 1.67982, batch accuracy: 0.55333
Time: 2018-07-15 10:29:18
TRAINING STATS: batch 294/486 in epoch 1221, batch loss: 1.62560, batch accuracy: 0.56183
Time: 2018-07-15 10:29:22
TRAINING STATS: batch 344/486 in epoch 1221, batch loss: 1.67906, batch accuracy: 0.54200
Time: 2018-07-15 10:29:27
TRAINING STATS: batch 394/486 in epoch 1221, batch loss: 1.74584, batch accuracy: 0.52750
Time: 2018-07-15 10:29:30
TRAINING STATS: batch 444/486 in epoch 1221, batch loss: 1.67688, batch accuracy: 0.55333
Time: 2018-07-15 10:29:34
TRAINING STATS: batch 8/486 in epoch 1222,   batch loss: 1.73933, batch accuracy: 0.53550
Time: 2018-07-15 10:29:39
TRAINING STATS: batch 58/486 in epoch 1222,  batch loss: 1.67961, batch accuracy: 0.55500
Time: 2018-07-15 10:29:42
TRAINING STATS: batch 108/486 in epoch 1222, batch loss: 1.80933, batch accuracy: 0.51200
Time: 2018-07-15 10:29:46
TRAINING STATS: batch 158/486 in epoch 1222, batch loss: 1.75645, batch accuracy: 0.52350
Time: 2018-07-15 10:29:51
TRAINING STATS: batch 208/486 in epoch 1222, batch loss: 1.73017, batch accuracy: 0.53317
Time: 2018-07-15 10:29:55
TRAINING STATS: batch 258/486 in epoch 1222, batch loss: 1.66418, batch accuracy: 0.55783
Time: 2018-07-15 10:29:58
TRAINING STATS: batch 308/486 in epoch 1222, batch loss: 1.72993, batch accuracy: 0.53983
Time: 2018-07-15 10:30:03
TRAINING STATS: batch 358/486 in epoch 1222, batch loss: 1.74347, batch accuracy: 0.51900
Time: 2018-07-15 10:30:07
TRAINING STATS: batch 408/486 in epoch 1222, batch loss: 1.75698, batch accuracy: 0.52383
Time: 2018-07-15 10:30:10
TRAINING STATS: batch 458/486 in epoch 1222, batch loss: 1.75603, batch accuracy: 0.52883
Time: 2018-07-15 10:30:15
TRAINING STATS: batch 22/486 in epoch 1223,  batch loss: 1.80820, batch accuracy: 0.51283
Time: 2018-07-15 10:30:19
TRAINING STATS: batch 72/486 in epoch 1223,  batch loss: 1.76261, batch accuracy: 0.52167
Time: 2018-07-15 10:30:23
TRAINING STATS: batch 122/486 in epoch 1223, batch loss: 1.71585, batch accuracy: 0.53217
Time: 2018-07-15 10:30:27
TRAINING STATS: batch 172/486 in epoch 1223, batch loss: 1.81066, batch accuracy: 0.51333
Time: 2018-07-15 10:30:31
TRAINING STATS: batch 222/486 in epoch 1223, batch loss: 1.71765, batch accuracy: 0.52550
Time: 2018-07-15 10:30:35
TRAINING STATS: batch 272/486 in epoch 1223, batch loss: 1.77427, batch accuracy: 0.51817
Time: 2018-07-15 10:30:40
TRAINING STATS: batch 322/486 in epoch 1223, batch loss: 1.72298, batch accuracy: 0.52350
Time: 2018-07-15 10:30:43
TRAINING STATS: batch 372/486 in epoch 1223, batch loss: 1.65305, batch accuracy: 0.54883
Time: 2018-07-15 10:30:47
TRAINING STATS: batch 422/486 in epoch 1223, batch loss: 1.66502, batch accuracy: 0.54950
Time: 2018-07-15 10:30:52
TRAINING STATS: batch 472/486 in epoch 1223, batch loss: 1.75947, batch accuracy: 0.52967
Time: 2018-07-15 10:30:55
TRAINING STATS: batch 36/486 in epoch 1224,  batch loss: 1.75912, batch accuracy: 0.52567
Time: 2018-07-15 10:30:59
TRAINING STATS: batch 86/486 in epoch 1224,  batch loss: 1.70218, batch accuracy: 0.54250
Time: 2018-07-15 10:31:04
TRAINING STATS: batch 136/486 in epoch 1224, batch loss: 1.73561, batch accuracy: 0.53050
Time: 2018-07-15 10:31:08
TRAINING STATS: batch 186/486 in epoch 1224, batch loss: 1.70481, batch accuracy: 0.54083
Time: 2018-07-15 10:31:11
TRAINING STATS: batch 236/486 in epoch 1224, batch loss: 1.70664, batch accuracy: 0.53500
Time: 2018-07-15 10:31:16
TRAINING STATS: batch 286/486 in epoch 1224, batch loss: 1.71187, batch accuracy: 0.53717
Time: 2018-07-15 10:31:20
TRAINING STATS: batch 336/486 in epoch 1224, batch loss: 1.68502, batch accuracy: 0.54117
Time: 2018-07-15 10:31:23
TRAINING STATS: batch 386/486 in epoch 1224, batch loss: 1.72963, batch accuracy: 0.52333
Time: 2018-07-15 10:31:28
TRAINING STATS: batch 436/486 in epoch 1224, batch loss: 1.72919, batch accuracy: 0.52983
Time: 2018-07-15 10:31:32
TRAINING STATS: batch 0/486 in epoch 1225,   batch loss: 1.67261, batch accuracy: 0.54483
Time: 2018-07-15 10:31:35
TRAINING STATS: batch 50/486 in epoch 1225,  batch loss: 1.65064, batch accuracy: 0.55517
Time: 2018-07-15 10:31:40
TRAINING STATS: batch 100/486 in epoch 1225, batch loss: 1.72027, batch accuracy: 0.54383
Time: 2018-07-15 10:31:44
TRAINING STATS: batch 150/486 in epoch 1225, batch loss: 1.66227, batch accuracy: 0.55767
Time: 2018-07-15 10:31:48
TRAINING STATS: batch 200/486 in epoch 1225, batch loss: 1.63081, batch accuracy: 0.55717
Time: 2018-07-15 10:31:52
TRAINING STATS: batch 250/486 in epoch 1225, batch loss: 1.78217, batch accuracy: 0.51733
Time: 2018-07-15 10:31:56
TRAINING STATS: batch 300/486 in epoch 1225, batch loss: 1.76168, batch accuracy: 0.51233
Time: 2018-07-15 10:32:00
TRAINING STATS: batch 350/486 in epoch 1225, batch loss: 1.76367, batch accuracy: 0.53000
Time: 2018-07-15 10:32:05
TRAINING STATS: batch 400/486 in epoch 1225, batch loss: 1.62702, batch accuracy: 0.55983
Time: 2018-07-15 10:32:08
TRAINING STATS: batch 450/486 in epoch 1225, batch loss: 1.83544, batch accuracy: 0.50050
Time: 2018-07-15 10:32:12
TRAINING STATS: batch 14/486 in epoch 1226,  batch loss: 1.65015, batch accuracy: 0.55367
Time: 2018-07-15 10:32:17
TRAINING STATS: batch 64/486 in epoch 1226,  batch loss: 1.88411, batch accuracy: 0.49017
Time: 2018-07-15 10:32:20
TRAINING STATS: batch 114/486 in epoch 1226, batch loss: 1.76777, batch accuracy: 0.52100
Time: 2018-07-15 10:32:24
TRAINING STATS: batch 164/486 in epoch 1226, batch loss: 1.64682, batch accuracy: 0.55683
Time: 2018-07-15 10:32:29
TRAINING STATS: batch 214/486 in epoch 1226, batch loss: 1.78851, batch accuracy: 0.51300
Time: 2018-07-15 10:32:32
TRAINING STATS: batch 264/486 in epoch 1226, batch loss: 1.77161, batch accuracy: 0.52433
Time: 2018-07-15 10:32:36
TRAINING STATS: batch 314/486 in epoch 1226, batch loss: 1.79150, batch accuracy: 0.50800
Time: 2018-07-15 10:32:41
TRAINING STATS: batch 364/486 in epoch 1226, batch loss: 1.69833, batch accuracy: 0.54067
Time: 2018-07-15 10:32:45
TRAINING STATS: batch 414/486 in epoch 1226, batch loss: 1.65124, batch accuracy: 0.56333
Time: 2018-07-15 10:32:48
TRAINING STATS: batch 464/486 in epoch 1226, batch loss: 1.68530, batch accuracy: 0.54967
Time: 2018-07-15 10:32:53
TRAINING STATS: batch 28/486 in epoch 1227,  batch loss: 1.64050, batch accuracy: 0.55650
Time: 2018-07-15 10:32:57
TRAINING STATS: batch 78/486 in epoch 1227,  batch loss: 1.72222, batch accuracy: 0.54333
Time: 2018-07-15 10:33:00
TRAINING STATS: batch 128/486 in epoch 1227, batch loss: 1.69979, batch accuracy: 0.54300
Time: 2018-07-15 10:33:05
TRAINING STATS: batch 178/486 in epoch 1227, batch loss: 1.66121, batch accuracy: 0.55550
Time: 2018-07-15 10:33:09
TRAINING STATS: batch 228/486 in epoch 1227, batch loss: 1.66248, batch accuracy: 0.56033
Time: 2018-07-15 10:33:13
TRAINING STATS: batch 278/486 in epoch 1227, batch loss: 1.64581, batch accuracy: 0.55717
Time: 2018-07-15 10:33:17
TRAINING STATS: batch 328/486 in epoch 1227, batch loss: 1.68885, batch accuracy: 0.54483
Time: 2018-07-15 10:33:21
TRAINING STATS: batch 378/486 in epoch 1227, batch loss: 1.68895, batch accuracy: 0.54617
Time: 2018-07-15 10:33:25
TRAINING STATS: batch 428/486 in epoch 1227, batch loss: 1.75535, batch accuracy: 0.52583
Time: 2018-07-15 10:33:29
TRAINING STATS: batch 478/486 in epoch 1227, batch loss: 1.71679, batch accuracy: 0.53267
Time: 2018-07-15 10:33:33
TRAINING STATS: batch 42/486 in epoch 1228,  batch loss: 1.62651, batch accuracy: 0.56500
Time: 2018-07-15 10:33:37
TRAINING STATS: batch 92/486 in epoch 1228,  batch loss: 1.73713, batch accuracy: 0.52817
Time: 2018-07-15 10:33:41
TRAINING STATS: batch 142/486 in epoch 1228, batch loss: 1.65842, batch accuracy: 0.55833
Time: 2018-07-15 10:33:45
TRAINING STATS: batch 192/486 in epoch 1228, batch loss: 1.68937, batch accuracy: 0.54550
Time: 2018-07-15 10:33:49
TRAINING STATS: batch 242/486 in epoch 1228, batch loss: 1.66309, batch accuracy: 0.55317
Time: 2018-07-15 10:33:54
TRAINING STATS: batch 292/486 in epoch 1228, batch loss: 1.68184, batch accuracy: 0.53983
Time: 2018-07-15 10:33:57
TRAINING STATS: batch 342/486 in epoch 1228, batch loss: 1.64104, batch accuracy: 0.55250
Time: 2018-07-15 10:34:01
TRAINING STATS: batch 392/486 in epoch 1228, batch loss: 1.58083, batch accuracy: 0.57900
Time: 2018-07-15 10:34:06
TRAINING STATS: batch 442/486 in epoch 1228, batch loss: 1.56973, batch accuracy: 0.57350
Time: 2018-07-15 10:34:09
TRAINING STATS: batch 6/486 in epoch 1229,   batch loss: 1.71746, batch accuracy: 0.54400
Time: 2018-07-15 10:34:13
TRAINING STATS: batch 56/486 in epoch 1229,  batch loss: 1.66825, batch accuracy: 0.54250
Time: 2018-07-15 10:34:18
TRAINING STATS: batch 106/486 in epoch 1229, batch loss: 1.73961, batch accuracy: 0.53583
Time: 2018-07-15 10:34:21
TRAINING STATS: batch 156/486 in epoch 1229, batch loss: 1.71087, batch accuracy: 0.53800
Time: 2018-07-15 10:34:25
TRAINING STATS: batch 206/486 in epoch 1229, batch loss: 1.74389, batch accuracy: 0.52600
Time: 2018-07-15 10:34:30
TRAINING STATS: batch 256/486 in epoch 1229, batch loss: 1.61671, batch accuracy: 0.56450
Time: 2018-07-15 10:34:34
TRAINING STATS: batch 306/486 in epoch 1229, batch loss: 1.67938, batch accuracy: 0.54600
Time: 2018-07-15 10:34:37
TRAINING STATS: batch 356/486 in epoch 1229, batch loss: 1.71457, batch accuracy: 0.53833
Time: 2018-07-15 10:34:42
TRAINING STATS: batch 406/486 in epoch 1229, batch loss: 1.75503, batch accuracy: 0.52100
Time: 2018-07-15 10:34:46
TRAINING STATS: batch 456/486 in epoch 1229, batch loss: 1.59362, batch accuracy: 0.57133
Time: 2018-07-15 10:34:50
TRAINING STATS: batch 20/486 in epoch 1230,  batch loss: 1.67876, batch accuracy: 0.54967
Time: 2018-07-15 10:34:54
TRAINING STATS: batch 70/486 in epoch 1230,  batch loss: 1.57812, batch accuracy: 0.57667
Time: 2018-07-15 10:34:58
TRAINING STATS: batch 120/486 in epoch 1230, batch loss: 1.60644, batch accuracy: 0.56400
Time: 2018-07-15 10:35:02
TRAINING STATS: batch 170/486 in epoch 1230, batch loss: 1.65863, batch accuracy: 0.55283
Time: 2018-07-15 10:35:06
TRAINING STATS: batch 220/486 in epoch 1230, batch loss: 1.59107, batch accuracy: 0.57167
Time: 2018-07-15 10:35:10
TRAINING STATS: batch 270/486 in epoch 1230, batch loss: 1.67621, batch accuracy: 0.54167
Time: 2018-07-15 10:35:14
TRAINING STATS: batch 320/486 in epoch 1230, batch loss: 1.59820, batch accuracy: 0.56400
Time: 2018-07-15 10:35:19
TRAINING STATS: batch 370/486 in epoch 1230, batch loss: 1.66556, batch accuracy: 0.55167
Time: 2018-07-15 10:35:22
TRAINING STATS: batch 420/486 in epoch 1230, batch loss: 1.71136, batch accuracy: 0.53983
Time: 2018-07-15 10:35:26
TRAINING STATS: batch 470/486 in epoch 1230, batch loss: 1.76539, batch accuracy: 0.51700
Time: 2018-07-15 10:35:31
TRAINING STATS: batch 34/486 in epoch 1231,  batch loss: 1.74321, batch accuracy: 0.53533
Time: 2018-07-15 10:35:34
TRAINING STATS: batch 84/486 in epoch 1231,  batch loss: 1.71681, batch accuracy: 0.53283
Time: 2018-07-15 10:35:38
TRAINING STATS: batch 134/486 in epoch 1231, batch loss: 1.71797, batch accuracy: 0.54133
Time: 2018-07-15 10:35:43
TRAINING STATS: batch 184/486 in epoch 1231, batch loss: 1.69402, batch accuracy: 0.53850
Time: 2018-07-15 10:35:46
TRAINING STATS: batch 234/486 in epoch 1231, batch loss: 1.73069, batch accuracy: 0.53417
Time: 2018-07-15 10:35:50
TRAINING STATS: batch 284/486 in epoch 1231, batch loss: 1.73008, batch accuracy: 0.53450
Time: 2018-07-15 10:35:55
TRAINING STATS: batch 334/486 in epoch 1231, batch loss: 1.66697, batch accuracy: 0.55117
Time: 2018-07-15 10:35:59
TRAINING STATS: batch 384/486 in epoch 1231, batch loss: 1.65124, batch accuracy: 0.55500
Time: 2018-07-15 10:36:02
TRAINING STATS: batch 434/486 in epoch 1231, batch loss: 1.71752, batch accuracy: 0.53383
Time: 2018-07-15 10:36:07
TRAINING STATS: batch 484/486 in epoch 1231, batch loss: 1.70126, batch accuracy: 0.53617
Time: 2018-07-15 10:36:11
TRAINING STATS: batch 48/486 in epoch 1232,  batch loss: 1.66585, batch accuracy: 0.54483
Time: 2018-07-15 10:36:14
TRAINING STATS: batch 98/486 in epoch 1232,  batch loss: 1.63250, batch accuracy: 0.56167
Time: 2018-07-15 10:36:19
TRAINING STATS: batch 148/486 in epoch 1232, batch loss: 1.71585, batch accuracy: 0.54317
Time: 2018-07-15 10:36:23
TRAINING STATS: batch 198/486 in epoch 1232, batch loss: 1.64239, batch accuracy: 0.55800
Time: 2018-07-15 10:36:26
TRAINING STATS: batch 248/486 in epoch 1232, batch loss: 1.74659, batch accuracy: 0.52000
Time: 2018-07-15 10:36:31
TRAINING STATS: batch 298/486 in epoch 1232, batch loss: 1.71956, batch accuracy: 0.52867
Time: 2018-07-15 10:36:35
TRAINING STATS: batch 348/486 in epoch 1232, batch loss: 1.67610, batch accuracy: 0.55133
Time: 2018-07-15 10:36:39
TRAINING STATS: batch 398/486 in epoch 1232, batch loss: 1.71087, batch accuracy: 0.53983
Time: 2018-07-15 10:36:43
TRAINING STATS: batch 448/486 in epoch 1232, batch loss: 1.70059, batch accuracy: 0.53317
Time: 2018-07-15 10:36:47
TRAINING STATS: batch 12/486 in epoch 1233,  batch loss: 1.70190, batch accuracy: 0.54067
Time: 2018-07-15 10:36:51
TRAINING STATS: batch 62/486 in epoch 1233,  batch loss: 1.75684, batch accuracy: 0.52300
Time: 2018-07-15 10:36:56
TRAINING STATS: batch 112/486 in epoch 1233, batch loss: 1.68515, batch accuracy: 0.53750
Time: 2018-07-15 10:36:59
TRAINING STATS: batch 162/486 in epoch 1233, batch loss: 1.69594, batch accuracy: 0.54717
Time: 2018-07-15 10:37:03
TRAINING STATS: batch 212/486 in epoch 1233, batch loss: 1.59956, batch accuracy: 0.57417
Time: 2018-07-15 10:37:08
TRAINING STATS: batch 262/486 in epoch 1233, batch loss: 1.72509, batch accuracy: 0.52733
Time: 2018-07-15 10:37:11
TRAINING STATS: batch 312/486 in epoch 1233, batch loss: 1.68008, batch accuracy: 0.53383
Time: 2018-07-15 10:37:15
TRAINING STATS: batch 362/486 in epoch 1233, batch loss: 1.66428, batch accuracy: 0.55000
Time: 2018-07-15 10:37:20
TRAINING STATS: batch 412/486 in epoch 1233, batch loss: 1.60644, batch accuracy: 0.57367
Time: 2018-07-15 10:37:24
TRAINING STATS: batch 462/486 in epoch 1233, batch loss: 1.67236, batch accuracy: 0.54350
Time: 2018-07-15 10:37:27
TRAINING STATS: batch 26/486 in epoch 1234,  batch loss: 1.71273, batch accuracy: 0.54233
Time: 2018-07-15 10:37:32
TRAINING STATS: batch 76/486 in epoch 1234,  batch loss: 1.72617, batch accuracy: 0.53067
Time: 2018-07-15 10:37:36
TRAINING STATS: batch 126/486 in epoch 1234, batch loss: 1.70219, batch accuracy: 0.53867
Time: 2018-07-15 10:37:39
TRAINING STATS: batch 176/486 in epoch 1234, batch loss: 1.62408, batch accuracy: 0.56400
Time: 2018-07-15 10:37:44
TRAINING STATS: batch 226/486 in epoch 1234, batch loss: 1.63863, batch accuracy: 0.55733
Time: 2018-07-15 10:37:48
TRAINING STATS: batch 276/486 in epoch 1234, batch loss: 1.65779, batch accuracy: 0.54700
Time: 2018-07-15 10:37:51
TRAINING STATS: batch 326/486 in epoch 1234, batch loss: 1.72476, batch accuracy: 0.52950
Time: 2018-07-15 10:37:56
TRAINING STATS: batch 376/486 in epoch 1234, batch loss: 1.71260, batch accuracy: 0.53350
Time: 2018-07-15 10:38:00
TRAINING STATS: batch 426/486 in epoch 1234, batch loss: 1.67870, batch accuracy: 0.54200
Time: 2018-07-15 10:38:04
TRAINING STATS: batch 476/486 in epoch 1234, batch loss: 1.63362, batch accuracy: 0.55700
Time: 2018-07-15 10:38:08
TRAINING STATS: batch 40/486 in epoch 1235,  batch loss: 1.66668, batch accuracy: 0.54917
Time: 2018-07-15 10:38:12
TRAINING STATS: batch 90/486 in epoch 1235,  batch loss: 1.71166, batch accuracy: 0.54217
Time: 2018-07-15 10:38:16
TRAINING STATS: batch 140/486 in epoch 1235, batch loss: 1.59728, batch accuracy: 0.56417
Time: 2018-07-15 10:38:20
TRAINING STATS: batch 190/486 in epoch 1235, batch loss: 1.63677, batch accuracy: 0.56150
Time: 2018-07-15 10:38:24
TRAINING STATS: batch 240/486 in epoch 1235, batch loss: 1.65549, batch accuracy: 0.54717
Time: 2018-07-15 10:38:28
TRAINING STATS: batch 290/486 in epoch 1235, batch loss: 1.69051, batch accuracy: 0.54017
Time: 2018-07-15 10:38:33
TRAINING STATS: batch 340/486 in epoch 1235, batch loss: 1.73119, batch accuracy: 0.52733
Time: 2018-07-15 10:38:36
TRAINING STATS: batch 390/486 in epoch 1235, batch loss: 1.59346, batch accuracy: 0.57317
Time: 2018-07-15 10:38:40
TRAINING STATS: batch 440/486 in epoch 1235, batch loss: 1.67660, batch accuracy: 0.54100
Time: 2018-07-15 10:38:45
TRAINING STATS: batch 4/486 in epoch 1236,   batch loss: 1.61812, batch accuracy: 0.56650
Time: 2018-07-15 10:38:48
TRAINING STATS: batch 54/486 in epoch 1236,  batch loss: 1.66422, batch accuracy: 0.54833
Time: 2018-07-15 10:38:52
TRAINING STATS: batch 104/486 in epoch 1236, batch loss: 1.68677, batch accuracy: 0.54517
Time: 2018-07-15 10:38:57
TRAINING STATS: batch 154/486 in epoch 1236, batch loss: 1.65753, batch accuracy: 0.55100
Time: 2018-07-15 10:39:00
TRAINING STATS: batch 204/486 in epoch 1236, batch loss: 1.78991, batch accuracy: 0.50850
Time: 2018-07-15 10:39:04
TRAINING STATS: batch 254/486 in epoch 1236, batch loss: 1.60467, batch accuracy: 0.56733
Time: 2018-07-15 10:39:09
TRAINING STATS: batch 304/486 in epoch 1236, batch loss: 1.60420, batch accuracy: 0.57633
Time: 2018-07-15 10:39:13
TRAINING STATS: batch 354/486 in epoch 1236, batch loss: 1.69831, batch accuracy: 0.53517
Time: 2018-07-15 10:39:16
TRAINING STATS: batch 404/486 in epoch 1236, batch loss: 1.67292, batch accuracy: 0.54667
Time: 2018-07-15 10:39:21
TRAINING STATS: batch 454/486 in epoch 1236, batch loss: 1.58248, batch accuracy: 0.57367
Time: 2018-07-15 10:39:25
TRAINING STATS: batch 18/486 in epoch 1237,  batch loss: 1.73127, batch accuracy: 0.53050
Time: 2018-07-15 10:39:29
TRAINING STATS: batch 68/486 in epoch 1237,  batch loss: 1.55116, batch accuracy: 0.57950
Time: 2018-07-15 10:39:33
TRAINING STATS: batch 118/486 in epoch 1237, batch loss: 1.66190, batch accuracy: 0.55433
Time: 2018-07-15 10:39:37
TRAINING STATS: batch 168/486 in epoch 1237, batch loss: 1.58765, batch accuracy: 0.58033
Time: 2018-07-15 10:39:41
TRAINING STATS: batch 218/486 in epoch 1237, batch loss: 1.66965, batch accuracy: 0.54633
Time: 2018-07-15 10:39:45
TRAINING STATS: batch 268/486 in epoch 1237, batch loss: 1.61084, batch accuracy: 0.56517
Time: 2018-07-15 10:39:49
TRAINING STATS: batch 318/486 in epoch 1237, batch loss: 1.72005, batch accuracy: 0.52900
Time: 2018-07-15 10:39:53
TRAINING STATS: batch 368/486 in epoch 1237, batch loss: 1.70436, batch accuracy: 0.53417
Time: 2018-07-15 10:39:58
TRAINING STATS: batch 418/486 in epoch 1237, batch loss: 1.73819, batch accuracy: 0.51833
Time: 2018-07-15 10:40:01
TRAINING STATS: batch 468/486 in epoch 1237, batch loss: 1.67594, batch accuracy: 0.54750
Time: 2018-07-15 10:40:05
TRAINING STATS: batch 32/486 in epoch 1238,  batch loss: 1.63272, batch accuracy: 0.56083
Time: 2018-07-15 10:40:10
TRAINING STATS: batch 82/486 in epoch 1238,  batch loss: 1.72009, batch accuracy: 0.52733
Time: 2018-07-15 10:40:13
TRAINING STATS: batch 132/486 in epoch 1238, batch loss: 1.65371, batch accuracy: 0.56000
Time: 2018-07-15 10:40:17
TRAINING STATS: batch 182/486 in epoch 1238, batch loss: 1.70203, batch accuracy: 0.54000
Time: 2018-07-15 10:40:22
TRAINING STATS: batch 232/486 in epoch 1238, batch loss: 1.70632, batch accuracy: 0.53567
Time: 2018-07-15 10:40:25
TRAINING STATS: batch 282/486 in epoch 1238, batch loss: 1.62293, batch accuracy: 0.56333
Time: 2018-07-15 10:40:29
TRAINING STATS: batch 332/486 in epoch 1238, batch loss: 1.69895, batch accuracy: 0.53600
Time: 2018-07-15 10:40:34
TRAINING STATS: batch 382/486 in epoch 1238, batch loss: 1.67341, batch accuracy: 0.54650
Time: 2018-07-15 10:40:38
TRAINING STATS: batch 432/486 in epoch 1238, batch loss: 1.60362, batch accuracy: 0.56700
Time: 2018-07-15 10:40:41
TRAINING STATS: batch 482/486 in epoch 1238, batch loss: 1.66528, batch accuracy: 0.55667
Time: 2018-07-15 10:40:46
TRAINING STATS: batch 46/486 in epoch 1239,  batch loss: 1.63307, batch accuracy: 0.55900
Time: 2018-07-15 10:40:50
TRAINING STATS: batch 96/486 in epoch 1239,  batch loss: 1.71082, batch accuracy: 0.53233
Time: 2018-07-15 10:40:53
TRAINING STATS: batch 146/486 in epoch 1239, batch loss: 1.71604, batch accuracy: 0.54067
Time: 2018-07-15 10:40:58
TRAINING STATS: batch 196/486 in epoch 1239, batch loss: 1.70687, batch accuracy: 0.53083
Time: 2018-07-15 10:41:02
TRAINING STATS: batch 246/486 in epoch 1239, batch loss: 1.65198, batch accuracy: 0.56200
Time: 2018-07-15 10:41:06
TRAINING STATS: batch 296/486 in epoch 1239, batch loss: 1.64661, batch accuracy: 0.54850
Time: 2018-07-15 10:41:10
TRAINING STATS: batch 346/486 in epoch 1239, batch loss: 1.59384, batch accuracy: 0.56350
Time: 2018-07-15 10:41:14
TRAINING STATS: batch 396/486 in epoch 1239, batch loss: 1.65284, batch accuracy: 0.55250
Time: 2018-07-15 10:41:18
TRAINING STATS: batch 446/486 in epoch 1239, batch loss: 1.70671, batch accuracy: 0.53967
Time: 2018-07-15 10:41:23
TRAINING STATS: batch 10/486 in epoch 1240,  batch loss: 1.73167, batch accuracy: 0.52800
Time: 2018-07-15 10:41:26
TRAINING STATS: batch 60/486 in epoch 1240,  batch loss: 1.64698, batch accuracy: 0.56133
Time: 2018-07-15 10:41:30
TRAINING STATS: batch 110/486 in epoch 1240, batch loss: 1.72955, batch accuracy: 0.53333
Time: 2018-07-15 10:41:35
TRAINING STATS: batch 160/486 in epoch 1240, batch loss: 1.64935, batch accuracy: 0.54350
Time: 2018-07-15 10:41:38
TRAINING STATS: batch 210/486 in epoch 1240, batch loss: 1.60669, batch accuracy: 0.56550
Time: 2018-07-15 10:41:42
TRAINING STATS: batch 260/486 in epoch 1240, batch loss: 1.70615, batch accuracy: 0.53517
Time: 2018-07-15 10:41:47
TRAINING STATS: batch 310/486 in epoch 1240, batch loss: 1.68989, batch accuracy: 0.55283
Time: 2018-07-15 10:41:50
TRAINING STATS: batch 360/486 in epoch 1240, batch loss: 1.68864, batch accuracy: 0.54217
Time: 2018-07-15 10:41:54
TRAINING STATS: batch 410/486 in epoch 1240, batch loss: 1.62459, batch accuracy: 0.56483
Time: 2018-07-15 10:41:59
TRAINING STATS: batch 460/486 in epoch 1240, batch loss: 1.80326, batch accuracy: 0.50317
Time: 2018-07-15 10:42:03
TRAINING STATS: batch 24/486 in epoch 1241,  batch loss: 1.74531, batch accuracy: 0.52517
Time: 2018-07-15 10:42:06
TRAINING STATS: batch 74/486 in epoch 1241,  batch loss: 1.70667, batch accuracy: 0.53967
Time: 2018-07-15 10:42:11
TRAINING STATS: batch 124/486 in epoch 1241, batch loss: 1.70570, batch accuracy: 0.54050
Time: 2018-07-15 10:42:15
TRAINING STATS: batch 174/486 in epoch 1241, batch loss: 1.73921, batch accuracy: 0.52783
Time: 2018-07-15 10:42:18
TRAINING STATS: batch 224/486 in epoch 1241, batch loss: 1.69253, batch accuracy: 0.53900
Time: 2018-07-15 10:42:23
TRAINING STATS: batch 274/486 in epoch 1241, batch loss: 1.67264, batch accuracy: 0.54467
Time: 2018-07-15 10:42:27
TRAINING STATS: batch 324/486 in epoch 1241, batch loss: 1.72880, batch accuracy: 0.53850
Time: 2018-07-15 10:42:31
TRAINING STATS: batch 374/486 in epoch 1241, batch loss: 1.75097, batch accuracy: 0.52750
Time: 2018-07-15 10:42:35
TRAINING STATS: batch 424/486 in epoch 1241, batch loss: 1.62678, batch accuracy: 0.55667
Time: 2018-07-15 10:42:39
TRAINING STATS: batch 474/486 in epoch 1241, batch loss: 1.67809, batch accuracy: 0.54483
Time: 2018-07-15 10:42:43
TRAINING STATS: batch 38/486 in epoch 1242,  batch loss: 1.69707, batch accuracy: 0.53933
Time: 2018-07-15 10:42:48
TRAINING STATS: batch 88/486 in epoch 1242,  batch loss: 1.73908, batch accuracy: 0.53283
Time: 2018-07-15 10:42:51
TRAINING STATS: batch 138/486 in epoch 1242, batch loss: 1.74170, batch accuracy: 0.52717
Time: 2018-07-15 10:42:55
TRAINING STATS: batch 188/486 in epoch 1242, batch loss: 1.69813, batch accuracy: 0.54183
Time: 2018-07-15 10:43:00
TRAINING STATS: batch 238/486 in epoch 1242, batch loss: 1.69265, batch accuracy: 0.54800
Time: 2018-07-15 10:43:03
TRAINING STATS: batch 288/486 in epoch 1242, batch loss: 1.70305, batch accuracy: 0.53167
Time: 2018-07-15 10:43:07
TRAINING STATS: batch 338/486 in epoch 1242, batch loss: 1.66682, batch accuracy: 0.54400
Time: 2018-07-15 10:43:12
TRAINING STATS: batch 388/486 in epoch 1242, batch loss: 1.64080, batch accuracy: 0.54717
Time: 2018-07-15 10:43:15
TRAINING STATS: batch 438/486 in epoch 1242, batch loss: 1.69028, batch accuracy: 0.54883
Time: 2018-07-15 10:43:19
TRAINING STATS: batch 2/486 in epoch 1243,   batch loss: 1.66946, batch accuracy: 0.55483
Time: 2018-07-15 10:43:24
TRAINING STATS: batch 52/486 in epoch 1243,  batch loss: 1.74083, batch accuracy: 0.52500
Time: 2018-07-15 10:43:28
TRAINING STATS: batch 102/486 in epoch 1243, batch loss: 1.69656, batch accuracy: 0.53833
Time: 2018-07-15 10:43:31
TRAINING STATS: batch 152/486 in epoch 1243, batch loss: 1.71948, batch accuracy: 0.53583
Time: 2018-07-15 10:43:36
TRAINING STATS: batch 202/486 in epoch 1243, batch loss: 1.68005, batch accuracy: 0.54383
Time: 2018-07-15 10:43:40
TRAINING STATS: batch 252/486 in epoch 1243, batch loss: 1.65333, batch accuracy: 0.55433
Time: 2018-07-15 10:43:43
TRAINING STATS: batch 302/486 in epoch 1243, batch loss: 1.62878, batch accuracy: 0.54783
Time: 2018-07-15 10:43:48
TRAINING STATS: batch 352/486 in epoch 1243, batch loss: 1.65574, batch accuracy: 0.55300
Time: 2018-07-15 10:43:52
TRAINING STATS: batch 402/486 in epoch 1243, batch loss: 1.53991, batch accuracy: 0.59033
Time: 2018-07-15 10:43:55
TRAINING STATS: batch 452/486 in epoch 1243, batch loss: 1.66898, batch accuracy: 0.54417
Time: 2018-07-15 10:44:00
TRAINING STATS: batch 16/486 in epoch 1244,  batch loss: 1.62457, batch accuracy: 0.55950
Time: 2018-07-15 10:44:04
TRAINING STATS: batch 66/486 in epoch 1244,  batch loss: 1.64491, batch accuracy: 0.55883
Time: 2018-07-15 10:44:08
TRAINING STATS: batch 116/486 in epoch 1244, batch loss: 1.64183, batch accuracy: 0.54833
Time: 2018-07-15 10:44:12
TRAINING STATS: batch 166/486 in epoch 1244, batch loss: 2.06848, batch accuracy: 0.42583
Time: 2018-07-15 10:44:16
TRAINING STATS: batch 216/486 in epoch 1244, batch loss: 2.04850, batch accuracy: 0.44300
Time: 2018-07-15 10:44:20
TRAINING STATS: batch 266/486 in epoch 1244, batch loss: 1.93103, batch accuracy: 0.47467
Time: 2018-07-15 10:44:25
TRAINING STATS: batch 316/486 in epoch 1244, batch loss: 1.91651, batch accuracy: 0.47817
Time: 2018-07-15 10:44:28
TRAINING STATS: batch 366/486 in epoch 1244, batch loss: 1.93770, batch accuracy: 0.47950
Time: 2018-07-15 10:44:32
TRAINING STATS: batch 416/486 in epoch 1244, batch loss: 1.92937, batch accuracy: 0.47567
Time: 2018-07-15 10:44:37
TRAINING STATS: batch 466/486 in epoch 1244, batch loss: 1.72454, batch accuracy: 0.54300
Time: 2018-07-15 10:44:41
TRAINING STATS: batch 30/486 in epoch 1245,  batch loss: 1.74550, batch accuracy: 0.53000
Time: 2018-07-15 10:44:44
TRAINING STATS: batch 80/486 in epoch 1245,  batch loss: 1.90491, batch accuracy: 0.47483
Time: 2018-07-15 10:44:49
TRAINING STATS: batch 130/486 in epoch 1245, batch loss: 1.86842, batch accuracy: 0.49533
Time: 2018-07-15 10:44:53
TRAINING STATS: batch 180/486 in epoch 1245, batch loss: 1.94208, batch accuracy: 0.47600
Time: 2018-07-15 10:44:56
TRAINING STATS: batch 230/486 in epoch 1245, batch loss: 1.84804, batch accuracy: 0.49150
Time: 2018-07-15 10:45:01
TRAINING STATS: batch 280/486 in epoch 1245, batch loss: 1.80800, batch accuracy: 0.50600
Time: 2018-07-15 10:45:05
TRAINING STATS: batch 330/486 in epoch 1245, batch loss: 1.78935, batch accuracy: 0.51833
Time: 2018-07-15 10:45:08
TRAINING STATS: batch 380/486 in epoch 1245, batch loss: 1.79917, batch accuracy: 0.50967
Time: 2018-07-15 10:45:13
TRAINING STATS: batch 430/486 in epoch 1245, batch loss: 1.77536, batch accuracy: 0.51117
Time: 2018-07-15 10:45:17
TRAINING STATS: batch 480/486 in epoch 1245, batch loss: 1.82667, batch accuracy: 0.51367
Time: 2018-07-15 10:45:21
TRAINING STATS: batch 44/486 in epoch 1246,  batch loss: 1.75813, batch accuracy: 0.51683
Time: 2018-07-15 10:45:25
TRAINING STATS: batch 94/486 in epoch 1246,  batch loss: 1.85263, batch accuracy: 0.49367
Time: 2018-07-15 10:45:29
TRAINING STATS: batch 144/486 in epoch 1246, batch loss: 1.88004, batch accuracy: 0.48467
Time: 2018-07-15 10:45:33
TRAINING STATS: batch 194/486 in epoch 1246, batch loss: 1.92772, batch accuracy: 0.47750
Time: 2018-07-15 10:45:37
TRAINING STATS: batch 244/486 in epoch 1246, batch loss: 1.77090, batch accuracy: 0.51750
Time: 2018-07-15 10:45:41
TRAINING STATS: batch 294/486 in epoch 1246, batch loss: 1.70007, batch accuracy: 0.54000
Time: 2018-07-15 10:45:45
TRAINING STATS: batch 344/486 in epoch 1246, batch loss: 1.75262, batch accuracy: 0.53083
Time: 2018-07-15 10:45:50
TRAINING STATS: batch 394/486 in epoch 1246, batch loss: 1.74185, batch accuracy: 0.52667
Time: 2018-07-15 10:45:53
TRAINING STATS: batch 444/486 in epoch 1246, batch loss: 1.73175, batch accuracy: 0.53717
Time: 2018-07-15 10:45:57
TRAINING STATS: batch 8/486 in epoch 1247,   batch loss: 1.79598, batch accuracy: 0.51950
Time: 2018-07-15 10:46:02
TRAINING STATS: batch 58/486 in epoch 1247,  batch loss: 1.75509, batch accuracy: 0.53083
Time: 2018-07-15 10:46:06
TRAINING STATS: batch 108/486 in epoch 1247, batch loss: 1.85649, batch accuracy: 0.50433
Time: 2018-07-15 10:46:09
TRAINING STATS: batch 158/486 in epoch 1247, batch loss: 1.82738, batch accuracy: 0.51050
Time: 2018-07-15 10:46:14
TRAINING STATS: batch 208/486 in epoch 1247, batch loss: 1.85533, batch accuracy: 0.49533
Time: 2018-07-15 10:46:18
TRAINING STATS: batch 258/486 in epoch 1247, batch loss: 1.76280, batch accuracy: 0.53283
Time: 2018-07-15 10:46:21
TRAINING STATS: batch 308/486 in epoch 1247, batch loss: 1.79937, batch accuracy: 0.51083
Time: 2018-07-15 10:46:26
TRAINING STATS: batch 358/486 in epoch 1247, batch loss: 1.79290, batch accuracy: 0.51200
Time: 2018-07-15 10:46:30
TRAINING STATS: batch 408/486 in epoch 1247, batch loss: 1.84840, batch accuracy: 0.49650
Time: 2018-07-15 10:46:33
TRAINING STATS: batch 458/486 in epoch 1247, batch loss: 1.79552, batch accuracy: 0.52033
Time: 2018-07-15 10:46:38
TRAINING STATS: batch 22/486 in epoch 1248,  batch loss: 1.85201, batch accuracy: 0.50367
Time: 2018-07-15 10:46:42
TRAINING STATS: batch 72/486 in epoch 1248,  batch loss: 1.78217, batch accuracy: 0.51967
Time: 2018-07-15 10:46:46
TRAINING STATS: batch 122/486 in epoch 1248, batch loss: 1.72282, batch accuracy: 0.53617
Time: 2018-07-15 10:46:50
TRAINING STATS: batch 172/486 in epoch 1248, batch loss: 1.86984, batch accuracy: 0.48917
Time: 2018-07-15 10:46:54
TRAINING STATS: batch 222/486 in epoch 1248, batch loss: 1.75805, batch accuracy: 0.52050
Time: 2018-07-15 10:46:58
TRAINING STATS: batch 272/486 in epoch 1248, batch loss: 1.80968, batch accuracy: 0.50267
Time: 2018-07-15 10:47:02
TRAINING STATS: batch 322/486 in epoch 1248, batch loss: 1.77538, batch accuracy: 0.51417
Time: 2018-07-15 10:47:06
TRAINING STATS: batch 372/486 in epoch 1248, batch loss: 1.77953, batch accuracy: 0.52067
Time: 2018-07-15 10:47:10
TRAINING STATS: batch 422/486 in epoch 1248, batch loss: 1.77924, batch accuracy: 0.51550
Time: 2018-07-15 10:47:14
TRAINING STATS: batch 472/486 in epoch 1248, batch loss: 1.86867, batch accuracy: 0.49350
Time: 2018-07-15 10:47:18
TRAINING STATS: batch 36/486 in epoch 1249,  batch loss: 1.83271, batch accuracy: 0.50733
Time: 2018-07-15 10:47:22
TRAINING STATS: batch 86/486 in epoch 1249,  batch loss: 1.77774, batch accuracy: 0.52517
Time: 2018-07-15 10:47:27
TRAINING STATS: batch 136/486 in epoch 1249, batch loss: 1.82661, batch accuracy: 0.50083
Time: 2018-07-15 10:47:30
TRAINING STATS: batch 186/486 in epoch 1249, batch loss: 1.79745, batch accuracy: 0.51267
Time: 2018-07-15 10:47:34
TRAINING STATS: batch 236/486 in epoch 1249, batch loss: 1.80001, batch accuracy: 0.50983
Time: 2018-07-15 10:47:39
TRAINING STATS: batch 286/486 in epoch 1249, batch loss: 1.81001, batch accuracy: 0.51133
Time: 2018-07-15 10:47:43
TRAINING STATS: batch 336/486 in epoch 1249, batch loss: 1.77773, batch accuracy: 0.51350
Time: 2018-07-15 10:47:46
TRAINING STATS: batch 386/486 in epoch 1249, batch loss: 1.92881, batch accuracy: 0.47417
Time: 2018-07-15 10:47:51
TRAINING STATS: batch 436/486 in epoch 1249, batch loss: 1.83373, batch accuracy: 0.50100
Time: 2018-07-15 10:47:55
TRAINING STATS: batch 0/486 in epoch 1250,   batch loss: 1.78274, batch accuracy: 0.51800
Time: 2018-07-15 10:47:58
TRAINING STATS: batch 50/486 in epoch 1250,  batch loss: 1.75186, batch accuracy: 0.52983
Time: 2018-07-15 10:48:03
TRAINING STATS: batch 100/486 in epoch 1250, batch loss: 1.81700, batch accuracy: 0.51000
Time: 2018-07-15 10:48:07
TRAINING STATS: batch 150/486 in epoch 1250, batch loss: 1.73823, batch accuracy: 0.53467
Time: 2018-07-15 10:48:11
TRAINING STATS: batch 200/486 in epoch 1250, batch loss: 1.65794, batch accuracy: 0.56000
Time: 2018-07-15 10:48:15
TRAINING STATS: batch 250/486 in epoch 1250, batch loss: 1.83129, batch accuracy: 0.50217
Time: 2018-07-15 10:48:19
TRAINING STATS: batch 300/486 in epoch 1250, batch loss: 1.81863, batch accuracy: 0.50350
Time: 2018-07-15 10:48:23
TRAINING STATS: batch 350/486 in epoch 1250, batch loss: 1.77885, batch accuracy: 0.52300
Time: 2018-07-15 10:48:27
TRAINING STATS: batch 400/486 in epoch 1250, batch loss: 1.67742, batch accuracy: 0.54500
Time: 2018-07-15 10:48:31
TRAINING STATS: batch 450/486 in epoch 1250, batch loss: 1.81846, batch accuracy: 0.49967
Time: 2018-07-15 10:48:35
TRAINING STATS: batch 14/486 in epoch 1251,  batch loss: 1.73597, batch accuracy: 0.52717
Time: 2018-07-15 10:48:40
TRAINING STATS: batch 64/486 in epoch 1251,  batch loss: 1.89255, batch accuracy: 0.48500
Time: 2018-07-15 10:48:43
TRAINING STATS: batch 114/486 in epoch 1251, batch loss: 1.82949, batch accuracy: 0.50450
Time: 2018-07-15 10:48:47
TRAINING STATS: batch 164/486 in epoch 1251, batch loss: 1.72594, batch accuracy: 0.53600
Time: 2018-07-15 10:48:52
TRAINING STATS: batch 214/486 in epoch 1251, batch loss: 1.78497, batch accuracy: 0.51233
Time: 2018-07-15 10:48:55
TRAINING STATS: batch 264/486 in epoch 1251, batch loss: 1.81016, batch accuracy: 0.50717
Time: 2018-07-15 10:48:59
TRAINING STATS: batch 314/486 in epoch 1251, batch loss: 1.82283, batch accuracy: 0.50333
Time: 2018-07-15 10:49:04
TRAINING STATS: batch 364/486 in epoch 1251, batch loss: 1.73399, batch accuracy: 0.53767
Time: 2018-07-15 10:49:07
TRAINING STATS: batch 414/486 in epoch 1251, batch loss: 1.67456, batch accuracy: 0.55083
Time: 2018-07-15 10:49:11
TRAINING STATS: batch 464/486 in epoch 1251, batch loss: 1.74302, batch accuracy: 0.52467
Time: 2018-07-15 10:49:16
TRAINING STATS: batch 28/486 in epoch 1252,  batch loss: 1.70572, batch accuracy: 0.53533
Time: 2018-07-15 10:49:20
TRAINING STATS: batch 78/486 in epoch 1252,  batch loss: 1.73386, batch accuracy: 0.53767
Time: 2018-07-15 10:49:23
TRAINING STATS: batch 128/486 in epoch 1252, batch loss: 1.73163, batch accuracy: 0.52783
Time: 2018-07-15 10:49:28
TRAINING STATS: batch 178/486 in epoch 1252, batch loss: 1.64291, batch accuracy: 0.55550
Time: 2018-07-15 10:49:32
TRAINING STATS: batch 228/486 in epoch 1252, batch loss: 1.69808, batch accuracy: 0.53533
Time: 2018-07-15 10:49:36
TRAINING STATS: batch 278/486 in epoch 1252, batch loss: 1.64884, batch accuracy: 0.55567
Time: 2018-07-15 10:49:40
TRAINING STATS: batch 328/486 in epoch 1252, batch loss: 1.70511, batch accuracy: 0.54167
Time: 2018-07-15 10:49:44
TRAINING STATS: batch 378/486 in epoch 1252, batch loss: 1.73329, batch accuracy: 0.53550
Time: 2018-07-15 10:49:48
TRAINING STATS: batch 428/486 in epoch 1252, batch loss: 1.76725, batch accuracy: 0.52567
Time: 2018-07-15 10:49:52
TRAINING STATS: batch 478/486 in epoch 1252, batch loss: 1.74142, batch accuracy: 0.52883
Time: 2018-07-15 10:49:56
TRAINING STATS: batch 42/486 in epoch 1253,  batch loss: 1.64084, batch accuracy: 0.56000
Time: 2018-07-15 10:50:00
TRAINING STATS: batch 92/486 in epoch 1253,  batch loss: 1.71766, batch accuracy: 0.53800
Time: 2018-07-15 10:50:05
TRAINING STATS: batch 142/486 in epoch 1253, batch loss: 1.67615, batch accuracy: 0.53867
Time: 2018-07-15 10:50:08
TRAINING STATS: batch 192/486 in epoch 1253, batch loss: 1.73500, batch accuracy: 0.53100
Time: 2018-07-15 10:50:12
TRAINING STATS: batch 242/486 in epoch 1253, batch loss: 1.69037, batch accuracy: 0.54567
Time: 2018-07-15 10:50:17
TRAINING STATS: batch 292/486 in epoch 1253, batch loss: 1.70131, batch accuracy: 0.54267
Time: 2018-07-15 10:50:20
TRAINING STATS: batch 342/486 in epoch 1253, batch loss: 1.66554, batch accuracy: 0.55433
Time: 2018-07-15 10:50:24
TRAINING STATS: batch 392/486 in epoch 1253, batch loss: 1.63060, batch accuracy: 0.56833
Time: 2018-07-15 10:50:29
TRAINING STATS: batch 442/486 in epoch 1253, batch loss: 1.61076, batch accuracy: 0.56183
Time: 2018-07-15 10:50:33
TRAINING STATS: batch 6/486 in epoch 1254,   batch loss: 1.74762, batch accuracy: 0.53100
Time: 2018-07-15 10:50:36
TRAINING STATS: batch 56/486 in epoch 1254,  batch loss: 1.66423, batch accuracy: 0.54483
Time: 2018-07-15 10:50:41
TRAINING STATS: batch 106/486 in epoch 1254, batch loss: 1.79641, batch accuracy: 0.51500
Time: 2018-07-15 10:50:45
TRAINING STATS: batch 156/486 in epoch 1254, batch loss: 1.74471, batch accuracy: 0.53067
Time: 2018-07-15 10:50:49
TRAINING STATS: batch 206/486 in epoch 1254, batch loss: 1.84087, batch accuracy: 0.50233
Time: 2018-07-15 10:50:53
TRAINING STATS: batch 256/486 in epoch 1254, batch loss: 1.66140, batch accuracy: 0.54583
Time: 2018-07-15 10:50:57
TRAINING STATS: batch 306/486 in epoch 1254, batch loss: 1.70696, batch accuracy: 0.53833
Time: 2018-07-15 10:51:01
TRAINING STATS: batch 356/486 in epoch 1254, batch loss: 1.75463, batch accuracy: 0.52133
Time: 2018-07-15 10:51:05
TRAINING STATS: batch 406/486 in epoch 1254, batch loss: 1.79596, batch accuracy: 0.50767
Time: 2018-07-15 10:51:09
TRAINING STATS: batch 456/486 in epoch 1254, batch loss: 1.61221, batch accuracy: 0.57417
Time: 2018-07-15 10:51:13
TRAINING STATS: batch 20/486 in epoch 1255,  batch loss: 1.73089, batch accuracy: 0.53450
Time: 2018-07-15 10:51:17
TRAINING STATS: batch 70/486 in epoch 1255,  batch loss: 1.62138, batch accuracy: 0.56000
Time: 2018-07-15 10:51:21
TRAINING STATS: batch 120/486 in epoch 1255, batch loss: 1.66123, batch accuracy: 0.55167
Time: 2018-07-15 10:51:25
TRAINING STATS: batch 170/486 in epoch 1255, batch loss: 1.70764, batch accuracy: 0.54633
Time: 2018-07-15 10:51:30
TRAINING STATS: batch 220/486 in epoch 1255, batch loss: 1.61938, batch accuracy: 0.56650
Time: 2018-07-15 10:51:33
TRAINING STATS: batch 270/486 in epoch 1255, batch loss: 1.71228, batch accuracy: 0.52433
Time: 2018-07-15 10:51:37
TRAINING STATS: batch 320/486 in epoch 1255, batch loss: 1.65196, batch accuracy: 0.54567
Time: 2018-07-15 10:51:42
TRAINING STATS: batch 370/486 in epoch 1255, batch loss: 1.70023, batch accuracy: 0.54167
Time: 2018-07-15 10:51:45
TRAINING STATS: batch 420/486 in epoch 1255, batch loss: 1.73830, batch accuracy: 0.52733
Time: 2018-07-15 10:51:49
TRAINING STATS: batch 470/486 in epoch 1255, batch loss: 1.76628, batch accuracy: 0.51850
Time: 2018-07-15 10:51:54
TRAINING STATS: batch 34/486 in epoch 1256,  batch loss: 1.72024, batch accuracy: 0.52667
Time: 2018-07-15 10:51:58
TRAINING STATS: batch 84/486 in epoch 1256,  batch loss: 1.72253, batch accuracy: 0.53300
Time: 2018-07-15 10:52:01
TRAINING STATS: batch 134/486 in epoch 1256, batch loss: 1.71988, batch accuracy: 0.54450
Time: 2018-07-15 10:52:06
TRAINING STATS: batch 184/486 in epoch 1256, batch loss: 1.70855, batch accuracy: 0.53783
Time: 2018-07-15 10:52:10
TRAINING STATS: batch 234/486 in epoch 1256, batch loss: 1.74508, batch accuracy: 0.52817
Time: 2018-07-15 10:52:14
TRAINING STATS: batch 284/486 in epoch 1256, batch loss: 1.74677, batch accuracy: 0.52267
Time: 2018-07-15 10:52:18
TRAINING STATS: batch 334/486 in epoch 1256, batch loss: 1.66838, batch accuracy: 0.55167
Time: 2018-07-15 10:52:22
TRAINING STATS: batch 384/486 in epoch 1256, batch loss: 1.65298, batch accuracy: 0.55067
Time: 2018-07-15 10:52:26
TRAINING STATS: batch 434/486 in epoch 1256, batch loss: 1.75706, batch accuracy: 0.51917
Time: 2018-07-15 10:52:30
TRAINING STATS: batch 484/486 in epoch 1256, batch loss: 1.70057, batch accuracy: 0.54200
Time: 2018-07-15 10:52:34
TRAINING STATS: batch 48/486 in epoch 1257,  batch loss: 1.68222, batch accuracy: 0.54433
Time: 2018-07-15 10:52:38
TRAINING STATS: batch 98/486 in epoch 1257,  batch loss: 1.63703, batch accuracy: 0.56067
Time: 2018-07-15 10:52:43
TRAINING STATS: batch 148/486 in epoch 1257, batch loss: 1.74358, batch accuracy: 0.53083
Time: 2018-07-15 10:52:46
TRAINING STATS: batch 198/486 in epoch 1257, batch loss: 1.68790, batch accuracy: 0.53433
Time: 2018-07-15 10:52:50
TRAINING STATS: batch 248/486 in epoch 1257, batch loss: 1.72181, batch accuracy: 0.53117
Time: 2018-07-15 10:52:55
TRAINING STATS: batch 298/486 in epoch 1257, batch loss: 1.86208, batch accuracy: 0.47967
Time: 2018-07-15 10:52:59
TRAINING STATS: batch 348/486 in epoch 1257, batch loss: 1.79858, batch accuracy: 0.50983
Time: 2018-07-15 10:53:02
TRAINING STATS: batch 398/486 in epoch 1257, batch loss: 1.79478, batch accuracy: 0.51667
Time: 2018-07-15 10:53:07
TRAINING STATS: batch 448/486 in epoch 1257, batch loss: 1.79597, batch accuracy: 0.52267
Time: 2018-07-15 10:53:11
TRAINING STATS: batch 12/486 in epoch 1258,  batch loss: 1.81509, batch accuracy: 0.51133
Time: 2018-07-15 10:53:14
TRAINING STATS: batch 62/486 in epoch 1258,  batch loss: 1.86876, batch accuracy: 0.49117
Time: 2018-07-15 10:53:19
TRAINING STATS: batch 112/486 in epoch 1258, batch loss: 1.79115, batch accuracy: 0.50817
Time: 2018-07-15 10:53:23
TRAINING STATS: batch 162/486 in epoch 1258, batch loss: 1.78296, batch accuracy: 0.52400
Time: 2018-07-15 10:53:27
TRAINING STATS: batch 212/486 in epoch 1258, batch loss: 1.75507, batch accuracy: 0.52567
Time: 2018-07-15 10:53:31
TRAINING STATS: batch 262/486 in epoch 1258, batch loss: 1.83384, batch accuracy: 0.50967
Time: 2018-07-15 10:53:35
TRAINING STATS: batch 312/486 in epoch 1258, batch loss: 1.77292, batch accuracy: 0.51567
Time: 2018-07-15 10:53:39
TRAINING STATS: batch 362/486 in epoch 1258, batch loss: 1.77600, batch accuracy: 0.52083
Time: 2018-07-15 10:53:43
TRAINING STATS: batch 412/486 in epoch 1258, batch loss: 1.75346, batch accuracy: 0.53133
Time: 2018-07-15 10:53:47
TRAINING STATS: batch 462/486 in epoch 1258, batch loss: 1.92895, batch accuracy: 0.47083
Time: 2018-07-15 10:53:51
TRAINING STATS: batch 26/486 in epoch 1259,  batch loss: 1.82237, batch accuracy: 0.50617
Time: 2018-07-15 10:53:56
TRAINING STATS: batch 76/486 in epoch 1259,  batch loss: 1.82417, batch accuracy: 0.50617
Time: 2018-07-15 10:53:59
TRAINING STATS: batch 126/486 in epoch 1259, batch loss: 1.80701, batch accuracy: 0.51600
Time: 2018-07-15 10:54:03
TRAINING STATS: batch 176/486 in epoch 1259, batch loss: 1.68420, batch accuracy: 0.54567
Time: 2018-07-15 10:54:08
TRAINING STATS: batch 226/486 in epoch 1259, batch loss: 1.79176, batch accuracy: 0.52133
Time: 2018-07-15 10:54:11
TRAINING STATS: batch 276/486 in epoch 1259, batch loss: 1.77032, batch accuracy: 0.51833
Time: 2018-07-15 10:54:15
TRAINING STATS: batch 326/486 in epoch 1259, batch loss: 1.80246, batch accuracy: 0.50983
Time: 2018-07-15 10:54:20
TRAINING STATS: batch 376/486 in epoch 1259, batch loss: 1.75379, batch accuracy: 0.52417
Time: 2018-07-15 10:54:24
TRAINING STATS: batch 426/486 in epoch 1259, batch loss: 1.69817, batch accuracy: 0.54233
Time: 2018-07-15 10:54:27
TRAINING STATS: batch 476/486 in epoch 1259, batch loss: 1.63803, batch accuracy: 0.55367
Time: 2018-07-15 10:54:32
TRAINING STATS: batch 40/486 in epoch 1260,  batch loss: 1.66609, batch accuracy: 0.55600
Time: 2018-07-15 10:54:36
TRAINING STATS: batch 90/486 in epoch 1260,  batch loss: 1.73655, batch accuracy: 0.53100
Time: 2018-07-15 10:54:39
TRAINING STATS: batch 140/486 in epoch 1260, batch loss: 1.61575, batch accuracy: 0.56633
Time: 2018-07-15 10:54:44
TRAINING STATS: batch 190/486 in epoch 1260, batch loss: 1.66009, batch accuracy: 0.55383
Time: 2018-07-15 10:54:48
TRAINING STATS: batch 240/486 in epoch 1260, batch loss: 1.66568, batch accuracy: 0.54817
Time: 2018-07-15 10:54:52
TRAINING STATS: batch 290/486 in epoch 1260, batch loss: 1.72245, batch accuracy: 0.52533
Time: 2018-07-15 10:54:56
TRAINING STATS: batch 340/486 in epoch 1260, batch loss: 1.74923, batch accuracy: 0.51883
Time: 2018-07-15 10:55:00
TRAINING STATS: batch 390/486 in epoch 1260, batch loss: 1.62285, batch accuracy: 0.56017
Time: 2018-07-15 10:55:04
TRAINING STATS: batch 440/486 in epoch 1260, batch loss: 1.69983, batch accuracy: 0.53617
Time: 2018-07-15 10:55:08
TRAINING STATS: batch 4/486 in epoch 1261,   batch loss: 1.63406, batch accuracy: 0.55217
Time: 2018-07-15 10:55:12
TRAINING STATS: batch 54/486 in epoch 1261,  batch loss: 1.69404, batch accuracy: 0.53433
Time: 2018-07-15 10:55:16
TRAINING STATS: batch 104/486 in epoch 1261, batch loss: 1.73185, batch accuracy: 0.53667
Time: 2018-07-15 10:55:20
TRAINING STATS: batch 154/486 in epoch 1261, batch loss: 1.66507, batch accuracy: 0.55000
Time: 2018-07-15 10:55:24
TRAINING STATS: batch 204/486 in epoch 1261, batch loss: 1.75512, batch accuracy: 0.52817
Time: 2018-07-15 10:55:28
TRAINING STATS: batch 254/486 in epoch 1261, batch loss: 1.62633, batch accuracy: 0.55483
Time: 2018-07-15 10:55:33
TRAINING STATS: batch 304/486 in epoch 1261, batch loss: 1.63000, batch accuracy: 0.56017
Time: 2018-07-15 10:55:36
TRAINING STATS: batch 354/486 in epoch 1261, batch loss: 1.67604, batch accuracy: 0.54700
Time: 2018-07-15 10:55:40
TRAINING STATS: batch 404/486 in epoch 1261, batch loss: 1.71543, batch accuracy: 0.53650
Time: 2018-07-15 10:55:45
TRAINING STATS: batch 454/486 in epoch 1261, batch loss: 1.59115, batch accuracy: 0.57400
Time: 2018-07-15 10:55:48
TRAINING STATS: batch 18/486 in epoch 1262,  batch loss: 1.77666, batch accuracy: 0.51433
Time: 2018-07-15 10:55:52
TRAINING STATS: batch 68/486 in epoch 1262,  batch loss: 1.58629, batch accuracy: 0.56650
Time: 2018-07-15 10:55:57
TRAINING STATS: batch 118/486 in epoch 1262, batch loss: 1.72176, batch accuracy: 0.53333
Time: 2018-07-15 10:56:01
TRAINING STATS: batch 168/486 in epoch 1262, batch loss: 1.62391, batch accuracy: 0.55933
Time: 2018-07-15 10:56:04
TRAINING STATS: batch 218/486 in epoch 1262, batch loss: 1.67240, batch accuracy: 0.54450
Time: 2018-07-15 10:56:09
TRAINING STATS: batch 268/486 in epoch 1262, batch loss: 1.62930, batch accuracy: 0.55667
Time: 2018-07-15 10:56:13
TRAINING STATS: batch 318/486 in epoch 1262, batch loss: 1.69909, batch accuracy: 0.53250
Time: 2018-07-15 10:56:17
TRAINING STATS: batch 368/486 in epoch 1262, batch loss: 1.69023, batch accuracy: 0.53667
Time: 2018-07-15 10:56:21
TRAINING STATS: batch 418/486 in epoch 1262, batch loss: 1.74351, batch accuracy: 0.52317
Time: 2018-07-15 10:56:25
TRAINING STATS: batch 468/486 in epoch 1262, batch loss: 1.68611, batch accuracy: 0.54383
Time: 2018-07-15 10:56:29
TRAINING STATS: batch 32/486 in epoch 1263,  batch loss: 1.62723, batch accuracy: 0.55700
Time: 2018-07-15 10:56:33
TRAINING STATS: batch 82/486 in epoch 1263,  batch loss: 1.71654, batch accuracy: 0.52883
Time: 2018-07-15 10:56:37
TRAINING STATS: batch 132/486 in epoch 1263, batch loss: 1.65567, batch accuracy: 0.55650
Time: 2018-07-15 10:56:41
TRAINING STATS: batch 182/486 in epoch 1263, batch loss: 1.71805, batch accuracy: 0.53000
Time: 2018-07-15 10:56:45
TRAINING STATS: batch 232/486 in epoch 1263, batch loss: 1.69025, batch accuracy: 0.54383
Time: 2018-07-15 10:56:49
TRAINING STATS: batch 282/486 in epoch 1263, batch loss: 1.64036, batch accuracy: 0.55533
Time: 2018-07-15 10:56:53
TRAINING STATS: batch 332/486 in epoch 1263, batch loss: 1.70843, batch accuracy: 0.53883
Time: 2018-07-15 10:56:58
TRAINING STATS: batch 382/486 in epoch 1263, batch loss: 1.67979, batch accuracy: 0.54783
Time: 2018-07-15 10:57:01
TRAINING STATS: batch 432/486 in epoch 1263, batch loss: 1.63527, batch accuracy: 0.55117
Time: 2018-07-15 10:57:05
TRAINING STATS: batch 482/486 in epoch 1263, batch loss: 1.66467, batch accuracy: 0.55317
Time: 2018-07-15 10:57:10
TRAINING STATS: batch 46/486 in epoch 1264,  batch loss: 1.64459, batch accuracy: 0.55967
Time: 2018-07-15 10:57:13
TRAINING STATS: batch 96/486 in epoch 1264,  batch loss: 1.71253, batch accuracy: 0.53800
Time: 2018-07-15 10:57:17
TRAINING STATS: batch 146/486 in epoch 1264, batch loss: 1.73128, batch accuracy: 0.53633
Time: 2018-07-15 10:57:22
TRAINING STATS: batch 196/486 in epoch 1264, batch loss: 1.72113, batch accuracy: 0.52500
Time: 2018-07-15 10:57:25
TRAINING STATS: batch 246/486 in epoch 1264, batch loss: 1.65518, batch accuracy: 0.55300
Time: 2018-07-15 10:57:29
TRAINING STATS: batch 296/486 in epoch 1264, batch loss: 1.65824, batch accuracy: 0.54350
Time: 2018-07-15 10:57:34
TRAINING STATS: batch 346/486 in epoch 1264, batch loss: 1.58408, batch accuracy: 0.57183
Time: 2018-07-15 10:57:38
TRAINING STATS: batch 396/486 in epoch 1264, batch loss: 1.69990, batch accuracy: 0.54250
Time: 2018-07-15 10:57:41
TRAINING STATS: batch 446/486 in epoch 1264, batch loss: 1.69968, batch accuracy: 0.54617
Time: 2018-07-15 10:57:46
TRAINING STATS: batch 10/486 in epoch 1265,  batch loss: 1.72073, batch accuracy: 0.53183
Time: 2018-07-15 10:57:50
TRAINING STATS: batch 60/486 in epoch 1265,  batch loss: 1.66480, batch accuracy: 0.54900
Time: 2018-07-15 10:57:53
TRAINING STATS: batch 110/486 in epoch 1265, batch loss: 1.76045, batch accuracy: 0.52583
Time: 2018-07-15 10:57:58
TRAINING STATS: batch 160/486 in epoch 1265, batch loss: 1.66018, batch accuracy: 0.54267
Time: 2018-07-15 10:58:02
TRAINING STATS: batch 210/486 in epoch 1265, batch loss: 1.62751, batch accuracy: 0.56550
Time: 2018-07-15 10:58:05
TRAINING STATS: batch 260/486 in epoch 1265, batch loss: 1.70232, batch accuracy: 0.53983
Time: 2018-07-15 10:58:10
TRAINING STATS: batch 310/486 in epoch 1265, batch loss: 1.67968, batch accuracy: 0.54600
Time: 2018-07-15 10:58:14
TRAINING STATS: batch 360/486 in epoch 1265, batch loss: 1.70772, batch accuracy: 0.52733
Time: 2018-07-15 10:58:18
TRAINING STATS: batch 410/486 in epoch 1265, batch loss: 1.61046, batch accuracy: 0.56667
Time: 2018-07-15 10:58:22
TRAINING STATS: batch 460/486 in epoch 1265, batch loss: 1.80648, batch accuracy: 0.50483
Time: 2018-07-15 10:58:26
TRAINING STATS: batch 24/486 in epoch 1266,  batch loss: 1.76448, batch accuracy: 0.52583
Time: 2018-07-15 10:58:30
TRAINING STATS: batch 74/486 in epoch 1266,  batch loss: 1.71593, batch accuracy: 0.53933
Time: 2018-07-15 10:58:35
TRAINING STATS: batch 124/486 in epoch 1266, batch loss: 1.68449, batch accuracy: 0.54733
Time: 2018-07-15 10:58:38
TRAINING STATS: batch 174/486 in epoch 1266, batch loss: 1.74745, batch accuracy: 0.53017
Time: 2018-07-15 10:58:42
TRAINING STATS: batch 224/486 in epoch 1266, batch loss: 1.70636, batch accuracy: 0.53833
Time: 2018-07-15 10:58:47
TRAINING STATS: batch 274/486 in epoch 1266, batch loss: 1.70784, batch accuracy: 0.53667
Time: 2018-07-15 10:58:50
TRAINING STATS: batch 324/486 in epoch 1266, batch loss: 1.72404, batch accuracy: 0.53283
Time: 2018-07-15 10:58:54
TRAINING STATS: batch 374/486 in epoch 1266, batch loss: 1.73621, batch accuracy: 0.52850
Time: 2018-07-15 10:58:59
TRAINING STATS: batch 424/486 in epoch 1266, batch loss: 1.61254, batch accuracy: 0.56483
Time: 2018-07-15 10:59:03
TRAINING STATS: batch 474/486 in epoch 1266, batch loss: 1.67141, batch accuracy: 0.54500
Time: 2018-07-15 10:59:06
TRAINING STATS: batch 38/486 in epoch 1267,  batch loss: 1.71289, batch accuracy: 0.53650
Time: 2018-07-15 10:59:11
TRAINING STATS: batch 88/486 in epoch 1267,  batch loss: 1.73616, batch accuracy: 0.52867
Time: 2018-07-15 10:59:15
TRAINING STATS: batch 138/486 in epoch 1267, batch loss: 1.72544, batch accuracy: 0.52833
Time: 2018-07-15 10:59:18
TRAINING STATS: batch 188/486 in epoch 1267, batch loss: 1.61309, batch accuracy: 0.56117
Time: 2018-07-15 10:59:23
TRAINING STATS: batch 238/486 in epoch 1267, batch loss: 1.65907, batch accuracy: 0.56150
Time: 2018-07-15 10:59:27
TRAINING STATS: batch 288/486 in epoch 1267, batch loss: 1.71670, batch accuracy: 0.52833
Time: 2018-07-15 10:59:31
TRAINING STATS: batch 338/486 in epoch 1267, batch loss: 1.67678, batch accuracy: 0.53900
Time: 2018-07-15 10:59:35
TRAINING STATS: batch 388/486 in epoch 1267, batch loss: 1.65416, batch accuracy: 0.55067
Time: 2018-07-15 10:59:39
TRAINING STATS: batch 438/486 in epoch 1267, batch loss: 1.70662, batch accuracy: 0.54183
Time: 2018-07-15 10:59:43
TRAINING STATS: batch 2/486 in epoch 1268,   batch loss: 1.69184, batch accuracy: 0.53883
Time: 2018-07-15 10:59:47
TRAINING STATS: batch 52/486 in epoch 1268,  batch loss: 1.76513, batch accuracy: 0.52000
Time: 2018-07-15 10:59:51
TRAINING STATS: batch 102/486 in epoch 1268, batch loss: 1.71424, batch accuracy: 0.53533
Time: 2018-07-15 10:59:55
TRAINING STATS: batch 152/486 in epoch 1268, batch loss: 1.63075, batch accuracy: 0.56183
Time: 2018-07-15 10:59:59
TRAINING STATS: batch 202/486 in epoch 1268, batch loss: 1.67623, batch accuracy: 0.54567
Time: 2018-07-15 11:00:03
TRAINING STATS: batch 252/486 in epoch 1268, batch loss: 1.63695, batch accuracy: 0.56367
Time: 2018-07-15 11:00:07
TRAINING STATS: batch 302/486 in epoch 1268, batch loss: 1.63581, batch accuracy: 0.55533
Time: 2018-07-15 11:00:12
TRAINING STATS: batch 352/486 in epoch 1268, batch loss: 1.92556, batch accuracy: 0.46317
Time: 2018-07-15 11:00:15
TRAINING STATS: batch 402/486 in epoch 1268, batch loss: 1.58801, batch accuracy: 0.57883
Time: 2018-07-15 11:00:19
TRAINING STATS: batch 452/486 in epoch 1268, batch loss: 1.68917, batch accuracy: 0.54083
Time: 2018-07-15 11:00:24
TRAINING STATS: batch 16/486 in epoch 1269,  batch loss: 1.64465, batch accuracy: 0.55500
Time: 2018-07-15 11:00:27
TRAINING STATS: batch 66/486 in epoch 1269,  batch loss: 1.66978, batch accuracy: 0.54950
Time: 2018-07-15 11:00:31
TRAINING STATS: batch 116/486 in epoch 1269, batch loss: 1.63067, batch accuracy: 0.55883
Time: 2018-07-15 11:00:36
TRAINING STATS: batch 166/486 in epoch 1269, batch loss: 1.57903, batch accuracy: 0.57883
Time: 2018-07-15 11:00:39
TRAINING STATS: batch 216/486 in epoch 1269, batch loss: 1.69058, batch accuracy: 0.54483
Time: 2018-07-15 11:00:43
TRAINING STATS: batch 266/486 in epoch 1269, batch loss: 1.70959, batch accuracy: 0.52850
Time: 2018-07-15 11:00:48
TRAINING STATS: batch 316/486 in epoch 1269, batch loss: 1.69833, batch accuracy: 0.54000
Time: 2018-07-15 11:00:52
TRAINING STATS: batch 366/486 in epoch 1269, batch loss: 1.72845, batch accuracy: 0.53133
Time: 2018-07-15 11:00:55
TRAINING STATS: batch 416/486 in epoch 1269, batch loss: 1.70578, batch accuracy: 0.53533
Time: 2018-07-15 11:01:00
TRAINING STATS: batch 466/486 in epoch 1269, batch loss: 1.55354, batch accuracy: 0.57583
Time: 2018-07-15 11:01:04
TRAINING STATS: batch 30/486 in epoch 1270,  batch loss: 1.58091, batch accuracy: 0.56933
Time: 2018-07-15 11:01:07
TRAINING STATS: batch 80/486 in epoch 1270,  batch loss: 1.67971, batch accuracy: 0.53783
Time: 2018-07-15 11:01:12
TRAINING STATS: batch 130/486 in epoch 1270, batch loss: 1.65760, batch accuracy: 0.55500
Time: 2018-07-15 11:01:16
TRAINING STATS: batch 180/486 in epoch 1270, batch loss: 1.70859, batch accuracy: 0.54383
Time: 2018-07-15 11:01:20
TRAINING STATS: batch 230/486 in epoch 1270, batch loss: 1.69073, batch accuracy: 0.53233
Time: 2018-07-15 11:01:24
TRAINING STATS: batch 280/486 in epoch 1270, batch loss: 1.65098, batch accuracy: 0.55000
Time: 2018-07-15 11:01:28
TRAINING STATS: batch 330/486 in epoch 1270, batch loss: 1.64705, batch accuracy: 0.55333
Time: 2018-07-15 11:01:32
TRAINING STATS: batch 380/486 in epoch 1270, batch loss: 1.64944, batch accuracy: 0.55467
Time: 2018-07-15 11:01:36
TRAINING STATS: batch 430/486 in epoch 1270, batch loss: 1.62290, batch accuracy: 0.55750
Time: 2018-07-15 11:01:40
TRAINING STATS: batch 480/486 in epoch 1270, batch loss: 1.68897, batch accuracy: 0.54817
Time: 2018-07-15 11:01:44
TRAINING STATS: batch 44/486 in epoch 1271,  batch loss: 1.61747, batch accuracy: 0.56267
Time: 2018-07-15 11:01:49
TRAINING STATS: batch 94/486 in epoch 1271,  batch loss: 1.72869, batch accuracy: 0.52867
Time: 2018-07-15 11:01:52
TRAINING STATS: batch 144/486 in epoch 1271, batch loss: 1.73428, batch accuracy: 0.52850
Time: 2018-07-15 11:01:56
TRAINING STATS: batch 194/486 in epoch 1271, batch loss: 1.75673, batch accuracy: 0.52517
Time: 2018-07-15 11:02:01
TRAINING STATS: batch 244/486 in epoch 1271, batch loss: 1.65395, batch accuracy: 0.55050
Time: 2018-07-15 11:02:04
TRAINING STATS: batch 294/486 in epoch 1271, batch loss: 1.60238, batch accuracy: 0.56767
Time: 2018-07-15 11:02:08
TRAINING STATS: batch 344/486 in epoch 1271, batch loss: 1.64441, batch accuracy: 0.54967
Time: 2018-07-15 11:02:13
TRAINING STATS: batch 394/486 in epoch 1271, batch loss: 1.61990, batch accuracy: 0.56233
Time: 2018-07-15 11:02:17
TRAINING STATS: batch 444/486 in epoch 1271, batch loss: 1.61871, batch accuracy: 0.56700
Time: 2018-07-15 11:02:20
TRAINING STATS: batch 8/486 in epoch 1272,   batch loss: 1.68374, batch accuracy: 0.54650
Time: 2018-07-15 11:02:25
TRAINING STATS: batch 58/486 in epoch 1272,  batch loss: 1.64172, batch accuracy: 0.55650
Time: 2018-07-15 11:02:29
TRAINING STATS: batch 108/486 in epoch 1272, batch loss: 1.75129, batch accuracy: 0.52750
Time: 2018-07-15 11:02:32
TRAINING STATS: batch 158/486 in epoch 1272, batch loss: 1.73534, batch accuracy: 0.52850
Time: 2018-07-15 11:02:37
TRAINING STATS: batch 208/486 in epoch 1272, batch loss: 1.69702, batch accuracy: 0.53867
Time: 2018-07-15 11:02:41
TRAINING STATS: batch 258/486 in epoch 1272, batch loss: 1.62493, batch accuracy: 0.56483
Time: 2018-07-15 11:02:45
TRAINING STATS: batch 308/486 in epoch 1272, batch loss: 1.68938, batch accuracy: 0.55217
Time: 2018-07-15 11:02:49
TRAINING STATS: batch 358/486 in epoch 1272, batch loss: 1.68050, batch accuracy: 0.54417
Time: 2018-07-15 11:02:53
TRAINING STATS: batch 408/486 in epoch 1272, batch loss: 1.75003, batch accuracy: 0.51650
Time: 2018-07-15 11:02:57
TRAINING STATS: batch 458/486 in epoch 1272, batch loss: 1.70986, batch accuracy: 0.54900
Time: 2018-07-15 11:03:01
TRAINING STATS: batch 22/486 in epoch 1273,  batch loss: 1.71999, batch accuracy: 0.53783
Time: 2018-07-15 11:03:05
TRAINING STATS: batch 72/486 in epoch 1273,  batch loss: 1.70019, batch accuracy: 0.53733
Time: 2018-07-15 11:03:09
TRAINING STATS: batch 122/486 in epoch 1273, batch loss: 1.62863, batch accuracy: 0.55750
Time: 2018-07-15 11:03:14
TRAINING STATS: batch 172/486 in epoch 1273, batch loss: 1.73270, batch accuracy: 0.52700
Time: 2018-07-15 11:03:17
TRAINING STATS: batch 222/486 in epoch 1273, batch loss: 1.70585, batch accuracy: 0.53150
Time: 2018-07-15 11:03:21
TRAINING STATS: batch 272/486 in epoch 1273, batch loss: 1.73060, batch accuracy: 0.51650
Time: 2018-07-15 11:03:26
TRAINING STATS: batch 322/486 in epoch 1273, batch loss: 1.69741, batch accuracy: 0.53850
Time: 2018-07-15 11:03:29
TRAINING STATS: batch 372/486 in epoch 1273, batch loss: 1.62947, batch accuracy: 0.55150
Time: 2018-07-15 11:03:33
TRAINING STATS: batch 422/486 in epoch 1273, batch loss: 1.65928, batch accuracy: 0.54933
Time: 2018-07-15 11:03:38
TRAINING STATS: batch 472/486 in epoch 1273, batch loss: 1.75647, batch accuracy: 0.51933
Time: 2018-07-15 11:03:42
TRAINING STATS: batch 36/486 in epoch 1274,  batch loss: 1.74101, batch accuracy: 0.52717
Time: 2018-07-15 11:03:45
TRAINING STATS: batch 86/486 in epoch 1274,  batch loss: 1.70648, batch accuracy: 0.54350
Time: 2018-07-15 11:03:50
TRAINING STATS: batch 136/486 in epoch 1274, batch loss: 1.73632, batch accuracy: 0.52167
Time: 2018-07-15 11:03:54
TRAINING STATS: batch 186/486 in epoch 1274, batch loss: 1.68716, batch accuracy: 0.54033
Time: 2018-07-15 11:03:57
TRAINING STATS: batch 236/486 in epoch 1274, batch loss: 1.71766, batch accuracy: 0.52633
Time: 2018-07-15 11:04:02
TRAINING STATS: batch 286/486 in epoch 1274, batch loss: 1.72060, batch accuracy: 0.54017
Time: 2018-07-15 11:04:06
TRAINING STATS: batch 336/486 in epoch 1274, batch loss: 1.68118, batch accuracy: 0.54417
Time: 2018-07-15 11:04:10
TRAINING STATS: batch 386/486 in epoch 1274, batch loss: 1.72555, batch accuracy: 0.52550
Time: 2018-07-15 11:04:14
TRAINING STATS: batch 436/486 in epoch 1274, batch loss: 1.70017, batch accuracy: 0.54067
Time: 2018-07-15 11:04:18
TRAINING STATS: batch 0/486 in epoch 1275,   batch loss: 1.67164, batch accuracy: 0.54617
Time: 2018-07-15 11:04:22
TRAINING STATS: batch 50/486 in epoch 1275,  batch loss: 1.67286, batch accuracy: 0.55017
Time: 2018-07-15 11:04:27
TRAINING STATS: batch 100/486 in epoch 1275, batch loss: 1.73661, batch accuracy: 0.52817
Time: 2018-07-15 11:04:30
TRAINING STATS: batch 150/486 in epoch 1275, batch loss: 1.78907, batch accuracy: 0.51450
Time: 2018-07-15 11:04:34
TRAINING STATS: batch 200/486 in epoch 1275, batch loss: 1.57485, batch accuracy: 0.57650
Time: 2018-07-15 11:04:39
TRAINING STATS: batch 250/486 in epoch 1275, batch loss: 1.75103, batch accuracy: 0.52250
Time: 2018-07-15 11:04:42
TRAINING STATS: batch 300/486 in epoch 1275, batch loss: 1.71603, batch accuracy: 0.53100
Time: 2018-07-15 11:04:46
TRAINING STATS: batch 350/486 in epoch 1275, batch loss: 1.69589, batch accuracy: 0.54183
Time: 2018-07-15 11:04:51
TRAINING STATS: batch 400/486 in epoch 1275, batch loss: 1.59005, batch accuracy: 0.56800
Time: 2018-07-15 11:04:55
TRAINING STATS: batch 450/486 in epoch 1275, batch loss: 1.72749, batch accuracy: 0.52767
Time: 2018-07-15 11:04:58
TRAINING STATS: batch 14/486 in epoch 1276,  batch loss: 1.59726, batch accuracy: 0.56917
Time: 2018-07-15 11:05:03
TRAINING STATS: batch 64/486 in epoch 1276,  batch loss: 1.78683, batch accuracy: 0.51283
Time: 2018-07-15 11:05:07
TRAINING STATS: batch 114/486 in epoch 1276, batch loss: 2.00997, batch accuracy: 0.44500
Time: 2018-07-15 11:05:10
TRAINING STATS: batch 164/486 in epoch 1276, batch loss: 1.75048, batch accuracy: 0.52683
Time: 2018-07-15 11:05:15
TRAINING STATS: batch 214/486 in epoch 1276, batch loss: 1.76589, batch accuracy: 0.51483
Time: 2018-07-15 11:05:19
TRAINING STATS: batch 264/486 in epoch 1276, batch loss: 1.76034, batch accuracy: 0.51833
Time: 2018-07-15 11:05:22
TRAINING STATS: batch 314/486 in epoch 1276, batch loss: 1.85436, batch accuracy: 0.49467
Time: 2018-07-15 11:05:27
TRAINING STATS: batch 364/486 in epoch 1276, batch loss: 1.84794, batch accuracy: 0.50833
Time: 2018-07-15 11:05:31
TRAINING STATS: batch 414/486 in epoch 1276, batch loss: 1.74943, batch accuracy: 0.52417
Time: 2018-07-15 11:05:35
TRAINING STATS: batch 464/486 in epoch 1276, batch loss: 1.81244, batch accuracy: 0.49917
Time: 2018-07-15 11:05:39
TRAINING STATS: batch 28/486 in epoch 1277,  batch loss: 1.75341, batch accuracy: 0.52250
Time: 2018-07-15 11:05:43
TRAINING STATS: batch 78/486 in epoch 1277,  batch loss: 1.81190, batch accuracy: 0.51233
Time: 2018-07-15 11:05:47
TRAINING STATS: batch 128/486 in epoch 1277, batch loss: 1.83014, batch accuracy: 0.50033
Time: 2018-07-15 11:05:52
TRAINING STATS: batch 178/486 in epoch 1277, batch loss: 1.69056, batch accuracy: 0.54567
Time: 2018-07-15 11:05:55
TRAINING STATS: batch 228/486 in epoch 1277, batch loss: 1.75154, batch accuracy: 0.52567
Time: 2018-07-15 11:05:59
TRAINING STATS: batch 278/486 in epoch 1277, batch loss: 1.70734, batch accuracy: 0.54550
Time: 2018-07-15 11:06:04
TRAINING STATS: batch 328/486 in epoch 1277, batch loss: 1.73734, batch accuracy: 0.53067
Time: 2018-07-15 11:06:07
TRAINING STATS: batch 378/486 in epoch 1277, batch loss: 1.77775, batch accuracy: 0.52800
Time: 2018-07-15 11:06:11
TRAINING STATS: batch 428/486 in epoch 1277, batch loss: 1.82456, batch accuracy: 0.50733
Time: 2018-07-15 11:06:16
TRAINING STATS: batch 478/486 in epoch 1277, batch loss: 1.77582, batch accuracy: 0.52000
Time: 2018-07-15 11:06:20
TRAINING STATS: batch 42/486 in epoch 1278,  batch loss: 1.70939, batch accuracy: 0.54167
Time: 2018-07-15 11:06:23
TRAINING STATS: batch 92/486 in epoch 1278,  batch loss: 1.79669, batch accuracy: 0.51133
Time: 2018-07-15 11:06:28
TRAINING STATS: batch 142/486 in epoch 1278, batch loss: 1.75451, batch accuracy: 0.52583
Time: 2018-07-15 11:06:32
TRAINING STATS: batch 192/486 in epoch 1278, batch loss: 1.82245, batch accuracy: 0.51250
Time: 2018-07-15 11:06:35
TRAINING STATS: batch 242/486 in epoch 1278, batch loss: 1.87419, batch accuracy: 0.49833
Time: 2018-07-15 11:06:40
TRAINING STATS: batch 292/486 in epoch 1278, batch loss: 1.93999, batch accuracy: 0.47517
Time: 2018-07-15 11:06:44
TRAINING STATS: batch 342/486 in epoch 1278, batch loss: 1.85544, batch accuracy: 0.49583
Time: 2018-07-15 11:06:48
TRAINING STATS: batch 392/486 in epoch 1278, batch loss: 1.83440, batch accuracy: 0.50033
Time: 2018-07-15 11:06:52
TRAINING STATS: batch 442/486 in epoch 1278, batch loss: 1.77986, batch accuracy: 0.51800
Time: 2018-07-15 11:06:56
TRAINING STATS: batch 6/486 in epoch 1279,   batch loss: 1.90785, batch accuracy: 0.48333
Time: 2018-07-15 11:07:00
TRAINING STATS: batch 56/486 in epoch 1279,  batch loss: 1.82488, batch accuracy: 0.50417
Time: 2018-07-15 11:07:05
TRAINING STATS: batch 106/486 in epoch 1279, batch loss: 1.87760, batch accuracy: 0.49283
Time: 2018-07-15 11:07:08
TRAINING STATS: batch 156/486 in epoch 1279, batch loss: 1.82716, batch accuracy: 0.51267
Time: 2018-07-15 11:07:12
TRAINING STATS: batch 206/486 in epoch 1279, batch loss: 1.85999, batch accuracy: 0.49650
Time: 2018-07-15 11:07:17
TRAINING STATS: batch 256/486 in epoch 1279, batch loss: 1.73056, batch accuracy: 0.53283
Time: 2018-07-15 11:07:20
TRAINING STATS: batch 306/486 in epoch 1279, batch loss: 1.77599, batch accuracy: 0.52000
Time: 2018-07-15 11:07:24
TRAINING STATS: batch 356/486 in epoch 1279, batch loss: 1.83120, batch accuracy: 0.49967
Time: 2018-07-15 11:07:29
TRAINING STATS: batch 406/486 in epoch 1279, batch loss: 1.87998, batch accuracy: 0.49383
Time: 2018-07-15 11:07:33
TRAINING STATS: batch 456/486 in epoch 1279, batch loss: 1.68047, batch accuracy: 0.55350
Time: 2018-07-15 11:07:36
TRAINING STATS: batch 20/486 in epoch 1280,  batch loss: 1.76125, batch accuracy: 0.52517
Time: 2018-07-15 11:07:41
TRAINING STATS: batch 70/486 in epoch 1280,  batch loss: 1.67195, batch accuracy: 0.55867
Time: 2018-07-15 11:07:45
TRAINING STATS: batch 120/486 in epoch 1280, batch loss: 1.70002, batch accuracy: 0.54750
Time: 2018-07-15 11:07:48
TRAINING STATS: batch 170/486 in epoch 1280, batch loss: 1.74560, batch accuracy: 0.52817
Time: 2018-07-15 11:07:53
TRAINING STATS: batch 220/486 in epoch 1280, batch loss: 1.69068, batch accuracy: 0.55033
Time: 2018-07-15 11:07:57
TRAINING STATS: batch 270/486 in epoch 1280, batch loss: 1.78495, batch accuracy: 0.51267
Time: 2018-07-15 11:08:00
TRAINING STATS: batch 320/486 in epoch 1280, batch loss: 1.69744, batch accuracy: 0.53983
Time: 2018-07-15 11:08:05
TRAINING STATS: batch 370/486 in epoch 1280, batch loss: 1.77127, batch accuracy: 0.52033
Time: 2018-07-15 11:08:09
TRAINING STATS: batch 420/486 in epoch 1280, batch loss: 1.81400, batch accuracy: 0.51333
Time: 2018-07-15 11:08:13
TRAINING STATS: batch 470/486 in epoch 1280, batch loss: 1.87278, batch accuracy: 0.48983
Time: 2018-07-15 11:08:17
TRAINING STATS: batch 34/486 in epoch 1281,  batch loss: 1.78188, batch accuracy: 0.52500
Time: 2018-07-15 11:08:21
TRAINING STATS: batch 84/486 in epoch 1281,  batch loss: 1.77432, batch accuracy: 0.51733
Time: 2018-07-15 11:08:25
TRAINING STATS: batch 134/486 in epoch 1281, batch loss: 1.81036, batch accuracy: 0.52050
Time: 2018-07-15 11:08:30
TRAINING STATS: batch 184/486 in epoch 1281, batch loss: 1.79533, batch accuracy: 0.52483
Time: 2018-07-15 11:08:33
TRAINING STATS: batch 234/486 in epoch 1281, batch loss: 1.83084, batch accuracy: 0.50867
Time: 2018-07-15 11:08:37
TRAINING STATS: batch 284/486 in epoch 1281, batch loss: 1.84403, batch accuracy: 0.50317
Time: 2018-07-15 11:08:42
TRAINING STATS: batch 334/486 in epoch 1281, batch loss: 1.76240, batch accuracy: 0.52850
Time: 2018-07-15 11:08:45
TRAINING STATS: batch 384/486 in epoch 1281, batch loss: 1.72079, batch accuracy: 0.53300
Time: 2018-07-15 11:08:49
TRAINING STATS: batch 434/486 in epoch 1281, batch loss: 1.83480, batch accuracy: 0.49617
Time: 2018-07-15 11:08:54
TRAINING STATS: batch 484/486 in epoch 1281, batch loss: 1.85391, batch accuracy: 0.49467
Time: 2018-07-15 11:08:58
TRAINING STATS: batch 48/486 in epoch 1282,  batch loss: 1.81404, batch accuracy: 0.51550
Time: 2018-07-15 11:09:01
TRAINING STATS: batch 98/486 in epoch 1282,  batch loss: 1.77276, batch accuracy: 0.52183
Time: 2018-07-15 11:09:06
TRAINING STATS: batch 148/486 in epoch 1282, batch loss: 1.83976, batch accuracy: 0.50983
Time: 2018-07-15 11:09:10
TRAINING STATS: batch 198/486 in epoch 1282, batch loss: 1.74623, batch accuracy: 0.52367
Time: 2018-07-15 11:09:13
TRAINING STATS: batch 248/486 in epoch 1282, batch loss: 1.81724, batch accuracy: 0.51233
Time: 2018-07-15 11:09:18
TRAINING STATS: batch 298/486 in epoch 1282, batch loss: 1.80380, batch accuracy: 0.50433
Time: 2018-07-15 11:09:22
TRAINING STATS: batch 348/486 in epoch 1282, batch loss: 1.77520, batch accuracy: 0.52483
Time: 2018-07-15 11:09:25
TRAINING STATS: batch 398/486 in epoch 1282, batch loss: 1.79291, batch accuracy: 0.51783
Time: 2018-07-15 11:09:30
TRAINING STATS: batch 448/486 in epoch 1282, batch loss: 1.76856, batch accuracy: 0.52783
Time: 2018-07-15 11:09:34
TRAINING STATS: batch 12/486 in epoch 1283,  batch loss: 1.80673, batch accuracy: 0.50400
Time: 2018-07-15 11:09:38
TRAINING STATS: batch 62/486 in epoch 1283,  batch loss: 1.84798, batch accuracy: 0.49300
Time: 2018-07-15 11:09:42
TRAINING STATS: batch 112/486 in epoch 1283, batch loss: 1.75273, batch accuracy: 0.52117
Time: 2018-07-15 11:09:46
TRAINING STATS: batch 162/486 in epoch 1283, batch loss: 1.79050, batch accuracy: 0.52633
Time: 2018-07-15 11:09:50
TRAINING STATS: batch 212/486 in epoch 1283, batch loss: 1.66042, batch accuracy: 0.55467
Time: 2018-07-15 11:09:54
TRAINING STATS: batch 262/486 in epoch 1283, batch loss: 1.83662, batch accuracy: 0.50583
Time: 2018-07-15 11:09:58
TRAINING STATS: batch 312/486 in epoch 1283, batch loss: 1.78985, batch accuracy: 0.50917
Time: 2018-07-15 11:10:02
TRAINING STATS: batch 362/486 in epoch 1283, batch loss: 1.77043, batch accuracy: 0.51800
Time: 2018-07-15 11:10:07
TRAINING STATS: batch 412/486 in epoch 1283, batch loss: 1.71703, batch accuracy: 0.54167
Time: 2018-07-15 11:10:10
TRAINING STATS: batch 462/486 in epoch 1283, batch loss: 1.76819, batch accuracy: 0.52467
Time: 2018-07-15 11:10:14
TRAINING STATS: batch 26/486 in epoch 1284,  batch loss: 1.84487, batch accuracy: 0.49433
Time: 2018-07-15 11:10:19
TRAINING STATS: batch 76/486 in epoch 1284,  batch loss: 2.68002, batch accuracy: 0.21883
Time: 2018-07-15 11:10:23
TRAINING STATS: batch 126/486 in epoch 1284, batch loss: 2.62061, batch accuracy: 0.22633
Time: 2018-07-15 11:10:26
TRAINING STATS: batch 176/486 in epoch 1284, batch loss: 2.56996, batch accuracy: 0.22500
Time: 2018-07-15 11:10:31
TRAINING STATS: batch 226/486 in epoch 1284, batch loss: 2.54593, batch accuracy: 0.25300
Time: 2018-07-15 11:10:35
TRAINING STATS: batch 276/486 in epoch 1284, batch loss: 2.52483, batch accuracy: 0.26333
Time: 2018-07-15 11:10:38
TRAINING STATS: batch 326/486 in epoch 1284, batch loss: 2.51672, batch accuracy: 0.26550
Time: 2018-07-15 11:10:43
TRAINING STATS: batch 376/486 in epoch 1284, batch loss: 2.48316, batch accuracy: 0.28200
Time: 2018-07-15 11:10:47
TRAINING STATS: batch 426/486 in epoch 1284, batch loss: 2.47667, batch accuracy: 0.27150
Time: 2018-07-15 11:10:50
TRAINING STATS: batch 476/486 in epoch 1284, batch loss: 2.48416, batch accuracy: 0.26917
Time: 2018-07-15 11:10:55
TRAINING STATS: batch 40/486 in epoch 1285,  batch loss: 2.46030, batch accuracy: 0.28000
Time: 2018-07-15 11:10:59
TRAINING STATS: batch 90/486 in epoch 1285,  batch loss: 2.47314, batch accuracy: 0.28667
Time: 2018-07-15 11:11:03
TRAINING STATS: batch 140/486 in epoch 1285, batch loss: 2.42808, batch accuracy: 0.28800
Time: 2018-07-15 11:11:07
TRAINING STATS: batch 190/486 in epoch 1285, batch loss: 2.45619, batch accuracy: 0.27600
Time: 2018-07-15 11:11:11
TRAINING STATS: batch 240/486 in epoch 1285, batch loss: 2.44044, batch accuracy: 0.28083
Time: 2018-07-15 11:11:15
TRAINING STATS: batch 290/486 in epoch 1285, batch loss: 2.43722, batch accuracy: 0.29350
Time: 2018-07-15 11:11:20
TRAINING STATS: batch 340/486 in epoch 1285, batch loss: 2.44421, batch accuracy: 0.29200
Time: 2018-07-15 11:11:23
TRAINING STATS: batch 390/486 in epoch 1285, batch loss: 2.40352, batch accuracy: 0.30800
Time: 2018-07-15 11:11:27
TRAINING STATS: batch 440/486 in epoch 1285, batch loss: 2.38871, batch accuracy: 0.31617
Time: 2018-07-15 11:11:32
TRAINING STATS: batch 4/486 in epoch 1286,   batch loss: 2.37755, batch accuracy: 0.31333
Time: 2018-07-15 11:11:35
TRAINING STATS: batch 54/486 in epoch 1286,  batch loss: 2.39131, batch accuracy: 0.31767
Time: 2018-07-15 11:11:39
TRAINING STATS: batch 104/486 in epoch 1286, batch loss: 2.38131, batch accuracy: 0.33183
Time: 2018-07-15 11:11:44
TRAINING STATS: batch 154/486 in epoch 1286, batch loss: 2.34923, batch accuracy: 0.34017
Time: 2018-07-15 11:11:48
TRAINING STATS: batch 204/486 in epoch 1286, batch loss: 2.38026, batch accuracy: 0.32583
Time: 2018-07-15 11:11:51
TRAINING STATS: batch 254/486 in epoch 1286, batch loss: 2.33032, batch accuracy: 0.34050
Time: 2018-07-15 11:11:56
TRAINING STATS: batch 304/486 in epoch 1286, batch loss: 2.33370, batch accuracy: 0.33983
Time: 2018-07-15 11:12:00
TRAINING STATS: batch 354/486 in epoch 1286, batch loss: 2.33851, batch accuracy: 0.34083
Time: 2018-07-15 11:12:03
TRAINING STATS: batch 404/486 in epoch 1286, batch loss: 2.32223, batch accuracy: 0.34700
Time: 2018-07-15 11:12:08
TRAINING STATS: batch 454/486 in epoch 1286, batch loss: 2.27517, batch accuracy: 0.35033
Time: 2018-07-15 11:12:12
TRAINING STATS: batch 18/486 in epoch 1287,  batch loss: 2.32632, batch accuracy: 0.34533
Time: 2018-07-15 11:12:16
TRAINING STATS: batch 68/486 in epoch 1287,  batch loss: 2.26533, batch accuracy: 0.36733
Time: 2018-07-15 11:12:20
TRAINING STATS: batch 118/486 in epoch 1287, batch loss: 2.32570, batch accuracy: 0.34833
Time: 2018-07-15 11:12:24
TRAINING STATS: batch 168/486 in epoch 1287, batch loss: 2.29337, batch accuracy: 0.35567
Time: 2018-07-15 11:12:28
TRAINING STATS: batch 218/486 in epoch 1287, batch loss: 2.30145, batch accuracy: 0.34583
Time: 2018-07-15 11:12:32
TRAINING STATS: batch 268/486 in epoch 1287, batch loss: 2.27762, batch accuracy: 0.35617
Time: 2018-07-15 11:12:36
TRAINING STATS: batch 318/486 in epoch 1287, batch loss: 2.28608, batch accuracy: 0.35550
Time: 2018-07-15 11:12:40
TRAINING STATS: batch 368/486 in epoch 1287, batch loss: 2.29382, batch accuracy: 0.35300
Time: 2018-07-15 11:12:45
TRAINING STATS: batch 418/486 in epoch 1287, batch loss: 2.32221, batch accuracy: 0.35083
Time: 2018-07-15 11:12:48
TRAINING STATS: batch 468/486 in epoch 1287, batch loss: 2.30058, batch accuracy: 0.36217
Time: 2018-07-15 11:12:52
TRAINING STATS: batch 32/486 in epoch 1288,  batch loss: 2.26454, batch accuracy: 0.36817
Time: 2018-07-15 11:12:57
TRAINING STATS: batch 82/486 in epoch 1288,  batch loss: 2.29878, batch accuracy: 0.36367
Time: 2018-07-15 11:13:01
TRAINING STATS: batch 132/486 in epoch 1288, batch loss: 2.26935, batch accuracy: 0.36567
Time: 2018-07-15 11:13:04
TRAINING STATS: batch 182/486 in epoch 1288, batch loss: 2.31588, batch accuracy: 0.34850
Time: 2018-07-15 11:13:09
TRAINING STATS: batch 232/486 in epoch 1288, batch loss: 2.29388, batch accuracy: 0.35967
Time: 2018-07-15 11:13:13
TRAINING STATS: batch 282/486 in epoch 1288, batch loss: 2.24909, batch accuracy: 0.37500
Time: 2018-07-15 11:13:16
TRAINING STATS: batch 332/486 in epoch 1288, batch loss: 2.28224, batch accuracy: 0.35783
Time: 2018-07-15 11:13:21
TRAINING STATS: batch 382/486 in epoch 1288, batch loss: 2.27812, batch accuracy: 0.36650
Time: 2018-07-15 11:13:25
TRAINING STATS: batch 432/486 in epoch 1288, batch loss: 2.24436, batch accuracy: 0.36167
Time: 2018-07-15 11:13:28
TRAINING STATS: batch 482/486 in epoch 1288, batch loss: 2.28491, batch accuracy: 0.35450
Time: 2018-07-15 11:13:33
TRAINING STATS: batch 46/486 in epoch 1289,  batch loss: 2.25649, batch accuracy: 0.36683
Time: 2018-07-15 11:13:37
TRAINING STATS: batch 96/486 in epoch 1289,  batch loss: 2.26687, batch accuracy: 0.36633
Time: 2018-07-15 11:13:41
TRAINING STATS: batch 146/486 in epoch 1289, batch loss: 2.28517, batch accuracy: 0.37367
Time: 2018-07-15 11:13:45
TRAINING STATS: batch 196/486 in epoch 1289, batch loss: 2.26058, batch accuracy: 0.36100
Time: 2018-07-15 11:13:49
TRAINING STATS: batch 246/486 in epoch 1289, batch loss: 2.25247, batch accuracy: 0.36800
Time: 2018-07-15 11:13:53
TRAINING STATS: batch 296/486 in epoch 1289, batch loss: 2.23280, batch accuracy: 0.38333
Time: 2018-07-15 11:13:58
TRAINING STATS: batch 346/486 in epoch 1289, batch loss: 2.29110, batch accuracy: 0.36967
Time: 2018-07-15 11:14:01
TRAINING STATS: batch 396/486 in epoch 1289, batch loss: 2.26628, batch accuracy: 0.38117
Time: 2018-07-15 11:14:05
TRAINING STATS: batch 446/486 in epoch 1289, batch loss: 2.27117, batch accuracy: 0.37317
Time: 2018-07-15 11:14:10
TRAINING STATS: batch 10/486 in epoch 1290,  batch loss: 2.28193, batch accuracy: 0.37517
Time: 2018-07-15 11:14:13
TRAINING STATS: batch 60/486 in epoch 1290,  batch loss: 2.25255, batch accuracy: 0.36383
Time: 2018-07-15 11:14:17
TRAINING STATS: batch 110/486 in epoch 1290, batch loss: 2.27968, batch accuracy: 0.38483
Time: 2018-07-15 11:14:22
TRAINING STATS: batch 160/486 in epoch 1290, batch loss: 2.23658, batch accuracy: 0.37900
Time: 2018-07-15 11:14:26
TRAINING STATS: batch 210/486 in epoch 1290, batch loss: 2.24443, batch accuracy: 0.37550
Time: 2018-07-15 11:14:29
TRAINING STATS: batch 260/486 in epoch 1290, batch loss: 2.25064, batch accuracy: 0.37667
Time: 2018-07-15 11:14:34
TRAINING STATS: batch 310/486 in epoch 1290, batch loss: 2.25292, batch accuracy: 0.37283
Time: 2018-07-15 11:14:38
TRAINING STATS: batch 360/486 in epoch 1290, batch loss: 2.24924, batch accuracy: 0.36383
Time: 2018-07-15 11:14:41
TRAINING STATS: batch 410/486 in epoch 1290, batch loss: 2.20272, batch accuracy: 0.38400
Time: 2018-07-15 11:14:46
TRAINING STATS: batch 460/486 in epoch 1290, batch loss: 2.34304, batch accuracy: 0.33833
Time: 2018-07-15 11:14:50
TRAINING STATS: batch 24/486 in epoch 1291,  batch loss: 2.27812, batch accuracy: 0.37267
Time: 2018-07-15 11:14:53
TRAINING STATS: batch 74/486 in epoch 1291,  batch loss: 2.24939, batch accuracy: 0.37517
Time: 2018-07-15 11:14:58
TRAINING STATS: batch 124/486 in epoch 1291, batch loss: 2.24634, batch accuracy: 0.38867
Time: 2018-07-15 11:15:02
TRAINING STATS: batch 174/486 in epoch 1291, batch loss: 2.25763, batch accuracy: 0.36383
Time: 2018-07-15 11:15:06
TRAINING STATS: batch 224/486 in epoch 1291, batch loss: 2.23834, batch accuracy: 0.39133
Time: 2018-07-15 11:15:11
TRAINING STATS: batch 274/486 in epoch 1291, batch loss: 2.21994, batch accuracy: 0.38567
Time: 2018-07-15 11:15:14
TRAINING STATS: batch 324/486 in epoch 1291, batch loss: 2.26092, batch accuracy: 0.36333
Time: 2018-07-15 11:15:18
TRAINING STATS: batch 374/486 in epoch 1291, batch loss: 2.26599, batch accuracy: 0.36550
Time: 2018-07-15 11:15:23
TRAINING STATS: batch 424/486 in epoch 1291, batch loss: 2.20277, batch accuracy: 0.38867
Time: 2018-07-15 11:15:26
TRAINING STATS: batch 474/486 in epoch 1291, batch loss: 2.23920, batch accuracy: 0.36517
Time: 2018-07-15 11:15:30
TRAINING STATS: batch 38/486 in epoch 1292,  batch loss: 2.25172, batch accuracy: 0.37700
Time: 2018-07-15 11:15:35
TRAINING STATS: batch 88/486 in epoch 1292,  batch loss: 2.24633, batch accuracy: 0.38267
Time: 2018-07-15 11:15:38
TRAINING STATS: batch 138/486 in epoch 1292, batch loss: 2.24497, batch accuracy: 0.38650
Time: 2018-07-15 11:15:42
TRAINING STATS: batch 188/486 in epoch 1292, batch loss: 2.21430, batch accuracy: 0.38667
Time: 2018-07-15 11:15:47
TRAINING STATS: batch 238/486 in epoch 1292, batch loss: 2.22077, batch accuracy: 0.40117
Time: 2018-07-15 11:15:51
TRAINING STATS: batch 288/486 in epoch 1292, batch loss: 2.22049, batch accuracy: 0.39133
Time: 2018-07-15 11:15:54
TRAINING STATS: batch 338/486 in epoch 1292, batch loss: 2.20564, batch accuracy: 0.38750
Time: 2018-07-15 11:15:59
TRAINING STATS: batch 388/486 in epoch 1292, batch loss: 2.20044, batch accuracy: 0.37567
Time: 2018-07-15 11:16:03
TRAINING STATS: batch 438/486 in epoch 1292, batch loss: 2.21657, batch accuracy: 0.38533
Time: 2018-07-15 11:16:06
TRAINING STATS: batch 2/486 in epoch 1293,   batch loss: 2.23230, batch accuracy: 0.38233
Time: 2018-07-15 11:16:11
TRAINING STATS: batch 52/486 in epoch 1293,  batch loss: 2.25015, batch accuracy: 0.37283
Time: 2018-07-15 11:16:15
TRAINING STATS: batch 102/486 in epoch 1293, batch loss: 2.22731, batch accuracy: 0.38700
Time: 2018-07-15 11:16:19
TRAINING STATS: batch 152/486 in epoch 1293, batch loss: 2.27157, batch accuracy: 0.36083
Time: 2018-07-15 11:16:23
TRAINING STATS: batch 202/486 in epoch 1293, batch loss: 2.25121, batch accuracy: 0.35850
Time: 2018-07-15 11:16:27
TRAINING STATS: batch 252/486 in epoch 1293, batch loss: 2.21200, batch accuracy: 0.38833
Time: 2018-07-15 11:16:31
TRAINING STATS: batch 302/486 in epoch 1293, batch loss: 2.19534, batch accuracy: 0.38833
Time: 2018-07-15 11:16:35
TRAINING STATS: batch 352/486 in epoch 1293, batch loss: 2.20933, batch accuracy: 0.38633
Time: 2018-07-15 11:16:39
TRAINING STATS: batch 402/486 in epoch 1293, batch loss: 2.14097, batch accuracy: 0.40867
Time: 2018-07-15 11:16:43
TRAINING STATS: batch 452/486 in epoch 1293, batch loss: 2.19782, batch accuracy: 0.40000
Time: 2018-07-15 11:16:48
TRAINING STATS: batch 16/486 in epoch 1294,  batch loss: 2.18439, batch accuracy: 0.38767
Time: 2018-07-15 11:16:51
TRAINING STATS: batch 66/486 in epoch 1294,  batch loss: 2.20327, batch accuracy: 0.40317
Time: 2018-07-15 11:16:55
TRAINING STATS: batch 116/486 in epoch 1294, batch loss: 2.20646, batch accuracy: 0.39000
Time: 2018-07-15 11:17:00
TRAINING STATS: batch 166/486 in epoch 1294, batch loss: 2.17920, batch accuracy: 0.39700
Time: 2018-07-15 11:17:04
TRAINING STATS: batch 216/486 in epoch 1294, batch loss: 2.22332, batch accuracy: 0.38283
Time: 2018-07-15 11:17:07
TRAINING STATS: batch 266/486 in epoch 1294, batch loss: 2.21603, batch accuracy: 0.37900
Time: 2018-07-15 11:17:12
TRAINING STATS: batch 316/486 in epoch 1294, batch loss: 2.19973, batch accuracy: 0.39050
Time: 2018-07-15 11:17:16
TRAINING STATS: batch 366/486 in epoch 1294, batch loss: 2.24766, batch accuracy: 0.36483
Time: 2018-07-15 11:17:19
TRAINING STATS: batch 416/486 in epoch 1294, batch loss: 2.25049, batch accuracy: 0.36300
Time: 2018-07-15 11:17:24
TRAINING STATS: batch 466/486 in epoch 1294, batch loss: 2.16905, batch accuracy: 0.39383
Time: 2018-07-15 11:17:28
TRAINING STATS: batch 30/486 in epoch 1295,  batch loss: 2.16615, batch accuracy: 0.40467
Time: 2018-07-15 11:17:32
TRAINING STATS: batch 80/486 in epoch 1295,  batch loss: 2.20484, batch accuracy: 0.39333
Time: 2018-07-15 11:17:36
TRAINING STATS: batch 130/486 in epoch 1295, batch loss: 2.21286, batch accuracy: 0.38433
Time: 2018-07-15 11:17:40
TRAINING STATS: batch 180/486 in epoch 1295, batch loss: 2.23795, batch accuracy: 0.37917
Time: 2018-07-15 11:17:44
TRAINING STATS: batch 230/486 in epoch 1295, batch loss: 2.22558, batch accuracy: 0.36767
Time: 2018-07-15 11:17:49
TRAINING STATS: batch 280/486 in epoch 1295, batch loss: 2.19403, batch accuracy: 0.39550
Time: 2018-07-15 11:17:52
TRAINING STATS: batch 330/486 in epoch 1295, batch loss: 2.19758, batch accuracy: 0.38967
Time: 2018-07-15 11:17:56
TRAINING STATS: batch 380/486 in epoch 1295, batch loss: 2.20577, batch accuracy: 0.38267
Time: 2018-07-15 11:18:01
TRAINING STATS: batch 430/486 in epoch 1295, batch loss: 2.14940, batch accuracy: 0.40467
Time: 2018-07-15 11:18:04
TRAINING STATS: batch 480/486 in epoch 1295, batch loss: 2.20787, batch accuracy: 0.39017
Time: 2018-07-15 11:18:08
TRAINING STATS: batch 44/486 in epoch 1296,  batch loss: 2.20721, batch accuracy: 0.36933
Time: 2018-07-15 11:18:13
TRAINING STATS: batch 94/486 in epoch 1296,  batch loss: 2.22465, batch accuracy: 0.38667
Time: 2018-07-15 11:18:16
TRAINING STATS: batch 144/486 in epoch 1296, batch loss: 2.21666, batch accuracy: 0.37750
Time: 2018-07-15 11:18:20
TRAINING STATS: batch 194/486 in epoch 1296, batch loss: 2.24332, batch accuracy: 0.35783
Time: 2018-07-15 11:18:25
TRAINING STATS: batch 244/486 in epoch 1296, batch loss: 2.19354, batch accuracy: 0.38367
Time: 2018-07-15 11:18:29
TRAINING STATS: batch 294/486 in epoch 1296, batch loss: 2.14768, batch accuracy: 0.40067
Time: 2018-07-15 11:18:32
TRAINING STATS: batch 344/486 in epoch 1296, batch loss: 2.18038, batch accuracy: 0.38150
Time: 2018-07-15 11:18:37
TRAINING STATS: batch 394/486 in epoch 1296, batch loss: 2.17987, batch accuracy: 0.37300
Time: 2018-07-15 11:18:41
TRAINING STATS: batch 444/486 in epoch 1296, batch loss: 2.17581, batch accuracy: 0.38133
Time: 2018-07-15 11:18:44
TRAINING STATS: batch 8/486 in epoch 1297,   batch loss: 2.17204, batch accuracy: 0.37700
Time: 2018-07-15 11:18:49
TRAINING STATS: batch 58/486 in epoch 1297,  batch loss: 2.15653, batch accuracy: 0.40250
Time: 2018-07-15 11:18:53
TRAINING STATS: batch 108/486 in epoch 1297, batch loss: 2.26235, batch accuracy: 0.36317
Time: 2018-07-15 11:18:57
TRAINING STATS: batch 158/486 in epoch 1297, batch loss: 2.29639, batch accuracy: 0.34850
Time: 2018-07-15 11:19:01
TRAINING STATS: batch 208/486 in epoch 1297, batch loss: 2.26073, batch accuracy: 0.36633
Time: 2018-07-15 11:19:05
TRAINING STATS: batch 258/486 in epoch 1297, batch loss: 2.22054, batch accuracy: 0.36133
Time: 2018-07-15 11:19:09
TRAINING STATS: batch 308/486 in epoch 1297, batch loss: 2.23579, batch accuracy: 0.37367
Time: 2018-07-15 11:19:14
TRAINING STATS: batch 358/486 in epoch 1297, batch loss: 2.20818, batch accuracy: 0.38217
Time: 2018-07-15 11:19:17
TRAINING STATS: batch 408/486 in epoch 1297, batch loss: 2.19873, batch accuracy: 0.39733
Time: 2018-07-15 11:19:21
TRAINING STATS: batch 458/486 in epoch 1297, batch loss: 2.18804, batch accuracy: 0.39433
Time: 2018-07-15 11:19:26
TRAINING STATS: batch 22/486 in epoch 1298,  batch loss: 2.22686, batch accuracy: 0.37383
Time: 2018-07-15 11:19:29
TRAINING STATS: batch 72/486 in epoch 1298,  batch loss: 2.22744, batch accuracy: 0.38050
Time: 2018-07-15 11:19:33
TRAINING STATS: batch 122/486 in epoch 1298, batch loss: 2.17204, batch accuracy: 0.39033
Time: 2018-07-15 11:19:38
TRAINING STATS: batch 172/486 in epoch 1298, batch loss: 2.22129, batch accuracy: 0.37817
Time: 2018-07-15 11:19:41
TRAINING STATS: batch 222/486 in epoch 1298, batch loss: 2.18138, batch accuracy: 0.38167
Time: 2018-07-15 11:19:45
TRAINING STATS: batch 272/486 in epoch 1298, batch loss: 2.21294, batch accuracy: 0.37200
Time: 2018-07-15 11:19:50
TRAINING STATS: batch 322/486 in epoch 1298, batch loss: 2.18441, batch accuracy: 0.37883
Time: 2018-07-15 11:19:54
TRAINING STATS: batch 372/486 in epoch 1298, batch loss: 2.16015, batch accuracy: 0.40200
Time: 2018-07-15 11:19:57
TRAINING STATS: batch 422/486 in epoch 1298, batch loss: 2.14698, batch accuracy: 0.39417
Time: 2018-07-15 11:20:02
TRAINING STATS: batch 472/486 in epoch 1298, batch loss: 2.22841, batch accuracy: 0.37650
Time: 2018-07-15 11:20:06
TRAINING STATS: batch 36/486 in epoch 1299,  batch loss: 2.23307, batch accuracy: 0.36983
Time: 2018-07-15 11:20:09
TRAINING STATS: batch 86/486 in epoch 1299,  batch loss: 2.20316, batch accuracy: 0.38183
Time: 2018-07-15 11:20:14
TRAINING STATS: batch 136/486 in epoch 1299, batch loss: 2.23619, batch accuracy: 0.37650
Time: 2018-07-15 11:20:18
TRAINING STATS: batch 186/486 in epoch 1299, batch loss: 2.20160, batch accuracy: 0.38483
Time: 2018-07-15 11:20:21
TRAINING STATS: batch 236/486 in epoch 1299, batch loss: 2.21271, batch accuracy: 0.38133
Time: 2018-07-15 11:20:26
TRAINING STATS: batch 286/486 in epoch 1299, batch loss: 2.22530, batch accuracy: 0.36900
Time: 2018-07-15 11:20:30
TRAINING STATS: batch 336/486 in epoch 1299, batch loss: 2.16118, batch accuracy: 0.39333
Time: 2018-07-15 11:20:34
TRAINING STATS: batch 386/486 in epoch 1299, batch loss: 2.21247, batch accuracy: 0.37583
Time: 2018-07-15 11:20:39
TRAINING STATS: batch 436/486 in epoch 1299, batch loss: 2.19876, batch accuracy: 0.38133
Time: 2018-07-15 11:20:42
TRAINING STATS: batch 0/486 in epoch 1300,   batch loss: 2.17815, batch accuracy: 0.38583
Time: 2018-07-15 11:20:46
TRAINING STATS: batch 50/486 in epoch 1300,  batch loss: 2.18432, batch accuracy: 0.39033
Time: 2018-07-15 11:20:51
TRAINING STATS: batch 100/486 in epoch 1300, batch loss: 2.20849, batch accuracy: 0.37533
Time: 2018-07-15 11:20:54
TRAINING STATS: batch 150/486 in epoch 1300, batch loss: 2.19006, batch accuracy: 0.37633
Time: 2018-07-15 11:20:58
TRAINING STATS: batch 200/486 in epoch 1300, batch loss: 2.13595, batch accuracy: 0.41017
Time: 2018-07-15 11:21:03
TRAINING STATS: batch 250/486 in epoch 1300, batch loss: 2.21485, batch accuracy: 0.38667
Time: 2018-07-15 11:21:07
TRAINING STATS: batch 300/486 in epoch 1300, batch loss: 2.21172, batch accuracy: 0.37000
Time: 2018-07-15 11:21:10
TRAINING STATS: batch 350/486 in epoch 1300, batch loss: 2.20056, batch accuracy: 0.38667
Time: 2018-07-15 11:21:15
TRAINING STATS: batch 400/486 in epoch 1300, batch loss: 2.11929, batch accuracy: 0.39650
Time: 2018-07-15 11:21:19
TRAINING STATS: batch 450/486 in epoch 1300, batch loss: 2.21336, batch accuracy: 0.37267
Time: 2018-07-15 11:21:22
TRAINING STATS: batch 14/486 in epoch 1301,  batch loss: 2.14096, batch accuracy: 0.40183
Time: 2018-07-15 11:21:27
TRAINING STATS: batch 64/486 in epoch 1301,  batch loss: 2.22754, batch accuracy: 0.38700
Time: 2018-07-15 11:21:31
TRAINING STATS: batch 114/486 in epoch 1301, batch loss: 2.20463, batch accuracy: 0.38667
Time: 2018-07-15 11:21:35
TRAINING STATS: batch 164/486 in epoch 1301, batch loss: 2.13866, batch accuracy: 0.40417
Time: 2018-07-15 11:21:39
TRAINING STATS: batch 214/486 in epoch 1301, batch loss: 2.16996, batch accuracy: 0.38750
Time: 2018-07-15 11:21:43
TRAINING STATS: batch 264/486 in epoch 1301, batch loss: 2.20105, batch accuracy: 0.38017
Time: 2018-07-15 11:21:47
TRAINING STATS: batch 314/486 in epoch 1301, batch loss: 2.23208, batch accuracy: 0.35900
Time: 2018-07-15 11:21:51
TRAINING STATS: batch 364/486 in epoch 1301, batch loss: 2.18207, batch accuracy: 0.38550
Time: 2018-07-15 11:21:55
TRAINING STATS: batch 414/486 in epoch 1301, batch loss: 2.17049, batch accuracy: 0.38183
Time: 2018-07-15 11:21:59
TRAINING STATS: batch 464/486 in epoch 1301, batch loss: 2.16184, batch accuracy: 0.38950
Time: 2018-07-15 11:22:04
TRAINING STATS: batch 28/486 in epoch 1302,  batch loss: 2.14040, batch accuracy: 0.39017
Time: 2018-07-15 11:22:07
TRAINING STATS: batch 78/486 in epoch 1302,  batch loss: 2.17290, batch accuracy: 0.39283
Time: 2018-07-15 11:22:11
TRAINING STATS: batch 128/486 in epoch 1302, batch loss: 2.16880, batch accuracy: 0.37850
Time: 2018-07-15 11:22:16
TRAINING STATS: batch 178/486 in epoch 1302, batch loss: 2.12881, batch accuracy: 0.37933
Time: 2018-07-15 11:22:19
TRAINING STATS: batch 228/486 in epoch 1302, batch loss: 2.14497, batch accuracy: 0.38433
Time: 2018-07-15 11:22:23
TRAINING STATS: batch 278/486 in epoch 1302, batch loss: 2.14412, batch accuracy: 0.39433
Time: 2018-07-15 11:22:28
TRAINING STATS: batch 328/486 in epoch 1302, batch loss: 2.16016, batch accuracy: 0.37550
Time: 2018-07-15 11:22:32
TRAINING STATS: batch 378/486 in epoch 1302, batch loss: 2.18292, batch accuracy: 0.39517
Time: 2018-07-15 11:22:35
TRAINING STATS: batch 428/486 in epoch 1302, batch loss: 2.20077, batch accuracy: 0.37550
Time: 2018-07-15 11:22:40
TRAINING STATS: batch 478/486 in epoch 1302, batch loss: 2.18950, batch accuracy: 0.38217
Time: 2018-07-15 11:22:44
TRAINING STATS: batch 42/486 in epoch 1303,  batch loss: 2.13168, batch accuracy: 0.38300
Time: 2018-07-15 11:22:47
TRAINING STATS: batch 92/486 in epoch 1303,  batch loss: 2.18361, batch accuracy: 0.37583
Time: 2018-07-15 11:22:52
TRAINING STATS: batch 142/486 in epoch 1303, batch loss: 2.14327, batch accuracy: 0.38917
Time: 2018-07-15 11:22:56
TRAINING STATS: batch 192/486 in epoch 1303, batch loss: 2.18548, batch accuracy: 0.38300
Time: 2018-07-15 11:23:00
TRAINING STATS: batch 242/486 in epoch 1303, batch loss: 2.15342, batch accuracy: 0.39567
Time: 2018-07-15 11:23:04
TRAINING STATS: batch 292/486 in epoch 1303, batch loss: 2.17204, batch accuracy: 0.38000
Time: 2018-07-15 11:23:08
TRAINING STATS: batch 342/486 in epoch 1303, batch loss: 2.15380, batch accuracy: 0.39067
Time: 2018-07-15 11:23:12
TRAINING STATS: batch 392/486 in epoch 1303, batch loss: 2.28546, batch accuracy: 0.32983
Time: 2018-07-15 11:23:16
TRAINING STATS: batch 442/486 in epoch 1303, batch loss: 2.23817, batch accuracy: 0.34783
Time: 2018-07-15 11:23:20
TRAINING STATS: batch 6/486 in epoch 1304,   batch loss: 2.23806, batch accuracy: 0.37750
Time: 2018-07-15 11:23:24
TRAINING STATS: batch 56/486 in epoch 1304,  batch loss: 2.20433, batch accuracy: 0.36417
Time: 2018-07-15 11:23:29
TRAINING STATS: batch 106/486 in epoch 1304, batch loss: 2.21894, batch accuracy: 0.38067
Time: 2018-07-15 11:23:32
TRAINING STATS: batch 156/486 in epoch 1304, batch loss: 2.20779, batch accuracy: 0.38317
Time: 2018-07-15 11:23:36
TRAINING STATS: batch 206/486 in epoch 1304, batch loss: 2.21180, batch accuracy: 0.37633
Time: 2018-07-15 11:23:41
TRAINING STATS: batch 256/486 in epoch 1304, batch loss: 2.14640, batch accuracy: 0.39067
Time: 2018-07-15 11:23:44
TRAINING STATS: batch 306/486 in epoch 1304, batch loss: 2.16613, batch accuracy: 0.38933
Time: 2018-07-15 11:23:48
TRAINING STATS: batch 356/486 in epoch 1304, batch loss: 2.18984, batch accuracy: 0.38067
Time: 2018-07-15 11:23:53
TRAINING STATS: batch 406/486 in epoch 1304, batch loss: 2.24532, batch accuracy: 0.35817
Time: 2018-07-15 11:23:57
TRAINING STATS: batch 456/486 in epoch 1304, batch loss: 2.16798, batch accuracy: 0.37883
Time: 2018-07-15 11:24:00
TRAINING STATS: batch 20/486 in epoch 1305,  batch loss: 2.22288, batch accuracy: 0.36633
Time: 2018-07-15 11:24:05
TRAINING STATS: batch 70/486 in epoch 1305,  batch loss: 2.16496, batch accuracy: 0.37883
Time: 2018-07-15 11:24:09
TRAINING STATS: batch 120/486 in epoch 1305, batch loss: 2.17619, batch accuracy: 0.38233
Time: 2018-07-15 11:24:12
TRAINING STATS: batch 170/486 in epoch 1305, batch loss: 2.20797, batch accuracy: 0.36683
Time: 2018-07-15 11:24:17
TRAINING STATS: batch 220/486 in epoch 1305, batch loss: 2.17031, batch accuracy: 0.37350
Time: 2018-07-15 11:24:21
TRAINING STATS: batch 270/486 in epoch 1305, batch loss: 2.18758, batch accuracy: 0.36833
Time: 2018-07-15 11:24:25
TRAINING STATS: batch 320/486 in epoch 1305, batch loss: 2.17830, batch accuracy: 0.36433
Time: 2018-07-15 11:24:29
TRAINING STATS: batch 370/486 in epoch 1305, batch loss: 2.19637, batch accuracy: 0.36550
Time: 2018-07-15 11:24:33
TRAINING STATS: batch 420/486 in epoch 1305, batch loss: 2.22782, batch accuracy: 0.36633
Time: 2018-07-15 11:24:37
TRAINING STATS: batch 470/486 in epoch 1305, batch loss: 2.24545, batch accuracy: 0.35933
Time: 2018-07-15 11:24:41
TRAINING STATS: batch 34/486 in epoch 1306,  batch loss: 2.21303, batch accuracy: 0.38700
Time: 2018-07-15 11:24:45
TRAINING STATS: batch 84/486 in epoch 1306,  batch loss: 2.18946, batch accuracy: 0.38350
Time: 2018-07-15 11:24:49
TRAINING STATS: batch 134/486 in epoch 1306, batch loss: 2.22164, batch accuracy: 0.38650
Time: 2018-07-15 11:24:54
TRAINING STATS: batch 184/486 in epoch 1306, batch loss: 2.19489, batch accuracy: 0.38467
Time: 2018-07-15 11:24:57
TRAINING STATS: batch 234/486 in epoch 1306, batch loss: 2.21869, batch accuracy: 0.37883
Time: 2018-07-15 11:25:01
TRAINING STATS: batch 284/486 in epoch 1306, batch loss: 2.20755, batch accuracy: 0.38083
Time: 2018-07-15 11:25:06
TRAINING STATS: batch 334/486 in epoch 1306, batch loss: 2.16496, batch accuracy: 0.38450
Time: 2018-07-15 11:25:09
TRAINING STATS: batch 384/486 in epoch 1306, batch loss: 2.15935, batch accuracy: 0.39217
Time: 2018-07-15 11:25:13
TRAINING STATS: batch 434/486 in epoch 1306, batch loss: 2.22628, batch accuracy: 0.37217
Time: 2018-07-15 11:25:18
TRAINING STATS: batch 484/486 in epoch 1306, batch loss: 2.17462, batch accuracy: 0.38617
Time: 2018-07-15 11:25:21
TRAINING STATS: batch 48/486 in epoch 1307,  batch loss: 2.16121, batch accuracy: 0.38567
Time: 2018-07-15 11:25:25
TRAINING STATS: batch 98/486 in epoch 1307,  batch loss: 2.15118, batch accuracy: 0.39050
Time: 2018-07-15 11:25:30
TRAINING STATS: batch 148/486 in epoch 1307, batch loss: 2.21675, batch accuracy: 0.38317
Time: 2018-07-15 11:25:33
TRAINING STATS: batch 198/486 in epoch 1307, batch loss: 2.14958, batch accuracy: 0.40017
Time: 2018-07-15 11:25:37
TRAINING STATS: batch 248/486 in epoch 1307, batch loss: 2.18328, batch accuracy: 0.38617
Time: 2018-07-15 11:25:42
TRAINING STATS: batch 298/486 in epoch 1307, batch loss: 2.17040, batch accuracy: 0.38400
Time: 2018-07-15 11:25:46
TRAINING STATS: batch 348/486 in epoch 1307, batch loss: 2.18973, batch accuracy: 0.37483
Time: 2018-07-15 11:25:49
TRAINING STATS: batch 398/486 in epoch 1307, batch loss: 2.17385, batch accuracy: 0.38683
Time: 2018-07-15 11:25:54
TRAINING STATS: batch 448/486 in epoch 1307, batch loss: 2.16651, batch accuracy: 0.38600
Time: 2018-07-15 11:25:58
TRAINING STATS: batch 12/486 in epoch 1308,  batch loss: 2.17876, batch accuracy: 0.38017
Time: 2018-07-15 11:26:02
TRAINING STATS: batch 62/486 in epoch 1308,  batch loss: 2.21519, batch accuracy: 0.38517
Time: 2018-07-15 11:26:06
TRAINING STATS: batch 112/486 in epoch 1308, batch loss: 2.17183, batch accuracy: 0.38817
Time: 2018-07-15 11:26:10
TRAINING STATS: batch 162/486 in epoch 1308, batch loss: 2.18754, batch accuracy: 0.39433
Time: 2018-07-15 11:26:14
TRAINING STATS: batch 212/486 in epoch 1308, batch loss: 2.13687, batch accuracy: 0.38067
Time: 2018-07-15 11:26:18
TRAINING STATS: batch 262/486 in epoch 1308, batch loss: 2.21179, batch accuracy: 0.38700
Time: 2018-07-15 11:26:22
TRAINING STATS: batch 312/486 in epoch 1308, batch loss: 2.21719, batch accuracy: 0.36150
Time: 2018-07-15 11:26:26
TRAINING STATS: batch 362/486 in epoch 1308, batch loss: 2.20361, batch accuracy: 0.36083
Time: 2018-07-15 11:26:31
TRAINING STATS: batch 412/486 in epoch 1308, batch loss: 2.19581, batch accuracy: 0.37217
Time: 2018-07-15 11:26:34
TRAINING STATS: batch 462/486 in epoch 1308, batch loss: 2.19325, batch accuracy: 0.37700
Time: 2018-07-15 11:26:38
TRAINING STATS: batch 26/486 in epoch 1309,  batch loss: 2.18469, batch accuracy: 0.37383
Time: 2018-07-15 11:26:43
TRAINING STATS: batch 76/486 in epoch 1309,  batch loss: 2.19836, batch accuracy: 0.37283
Time: 2018-07-15 11:26:46
TRAINING STATS: batch 126/486 in epoch 1309, batch loss: 2.19574, batch accuracy: 0.37617
Time: 2018-07-15 11:26:50
TRAINING STATS: batch 176/486 in epoch 1309, batch loss: 2.12921, batch accuracy: 0.39133
Time: 2018-07-15 11:26:55
TRAINING STATS: batch 226/486 in epoch 1309, batch loss: 2.16087, batch accuracy: 0.38333
Time: 2018-07-15 11:26:58
TRAINING STATS: batch 276/486 in epoch 1309, batch loss: 2.16985, batch accuracy: 0.37733
Time: 2018-07-15 11:27:02
TRAINING STATS: batch 326/486 in epoch 1309, batch loss: 2.18870, batch accuracy: 0.37567
Time: 2018-07-15 11:27:07
TRAINING STATS: batch 376/486 in epoch 1309, batch loss: 2.17255, batch accuracy: 0.37717
Time: 2018-07-15 11:27:11
TRAINING STATS: batch 426/486 in epoch 1309, batch loss: 2.16737, batch accuracy: 0.37167
Time: 2018-07-15 11:27:14
TRAINING STATS: batch 476/486 in epoch 1309, batch loss: 2.13907, batch accuracy: 0.39567
Time: 2018-07-15 11:27:19
TRAINING STATS: batch 40/486 in epoch 1310,  batch loss: 2.17483, batch accuracy: 0.38867
Time: 2018-07-15 11:27:23
TRAINING STATS: batch 90/486 in epoch 1310,  batch loss: 2.18623, batch accuracy: 0.39867
Time: 2018-07-15 11:27:27
TRAINING STATS: batch 140/486 in epoch 1310, batch loss: 2.14446, batch accuracy: 0.37983
Time: 2018-07-15 11:27:31
TRAINING STATS: batch 190/486 in epoch 1310, batch loss: 2.17855, batch accuracy: 0.38000
Time: 2018-07-15 11:27:35
TRAINING STATS: batch 240/486 in epoch 1310, batch loss: 2.17526, batch accuracy: 0.39033
Time: 2018-07-15 11:27:39
TRAINING STATS: batch 290/486 in epoch 1310, batch loss: 2.18366, batch accuracy: 0.37100
Time: 2018-07-15 11:27:43
TRAINING STATS: batch 340/486 in epoch 1310, batch loss: 2.20303, batch accuracy: 0.38650
Time: 2018-07-15 11:27:47
TRAINING STATS: batch 390/486 in epoch 1310, batch loss: 2.12773, batch accuracy: 0.39550
Time: 2018-07-15 11:27:51
TRAINING STATS: batch 440/486 in epoch 1310, batch loss: 2.17251, batch accuracy: 0.39850
Time: 2018-07-15 11:27:56
TRAINING STATS: batch 4/486 in epoch 1311,   batch loss: 2.16238, batch accuracy: 0.39433
Time: 2018-07-15 11:27:59
TRAINING STATS: batch 54/486 in epoch 1311,  batch loss: 2.16622, batch accuracy: 0.39283
Time: 2018-07-15 11:28:03
TRAINING STATS: batch 104/486 in epoch 1311, batch loss: 2.18543, batch accuracy: 0.38033
Time: 2018-07-15 11:28:08
TRAINING STATS: batch 154/486 in epoch 1311, batch loss: 2.16488, batch accuracy: 0.38217
Time: 2018-07-15 11:28:11
TRAINING STATS: batch 204/486 in epoch 1311, batch loss: 2.21540, batch accuracy: 0.36383
Time: 2018-07-15 11:28:15
TRAINING STATS: batch 254/486 in epoch 1311, batch loss: 2.13472, batch accuracy: 0.40400
Time: 2018-07-15 11:28:20
TRAINING STATS: batch 304/486 in epoch 1311, batch loss: 2.15785, batch accuracy: 0.39017
Time: 2018-07-15 11:28:23
TRAINING STATS: batch 354/486 in epoch 1311, batch loss: 2.17697, batch accuracy: 0.38133
Time: 2018-07-15 11:28:27
TRAINING STATS: batch 404/486 in epoch 1311, batch loss: 2.17879, batch accuracy: 0.36783
Time: 2018-07-15 11:28:32
TRAINING STATS: batch 454/486 in epoch 1311, batch loss: 2.10127, batch accuracy: 0.39217
Time: 2018-07-15 11:28:36
TRAINING STATS: batch 18/486 in epoch 1312,  batch loss: 2.18077, batch accuracy: 0.38583
Time: 2018-07-15 11:28:39
TRAINING STATS: batch 68/486 in epoch 1312,  batch loss: 2.08314, batch accuracy: 0.40033
Time: 2018-07-15 11:28:44
TRAINING STATS: batch 118/486 in epoch 1312, batch loss: 2.17069, batch accuracy: 0.38500
Time: 2018-07-15 11:28:48
TRAINING STATS: batch 168/486 in epoch 1312, batch loss: 2.12205, batch accuracy: 0.40350
Time: 2018-07-15 11:28:51
TRAINING STATS: batch 218/486 in epoch 1312, batch loss: 2.14890, batch accuracy: 0.38083
Time: 2018-07-15 11:28:56
TRAINING STATS: batch 268/486 in epoch 1312, batch loss: 2.14211, batch accuracy: 0.38833
Time: 2018-07-15 11:29:00
TRAINING STATS: batch 318/486 in epoch 1312, batch loss: 2.13816, batch accuracy: 0.39950
Time: 2018-07-15 11:29:04
TRAINING STATS: batch 368/486 in epoch 1312, batch loss: 2.16973, batch accuracy: 0.39367
Time: 2018-07-15 11:29:08
TRAINING STATS: batch 418/486 in epoch 1312, batch loss: 2.20657, batch accuracy: 0.37083
Time: 2018-07-15 11:29:12
TRAINING STATS: batch 468/486 in epoch 1312, batch loss: 2.18198, batch accuracy: 0.38467
Time: 2018-07-15 11:29:16
TRAINING STATS: batch 32/486 in epoch 1313,  batch loss: 2.13139, batch accuracy: 0.39117
Time: 2018-07-15 11:29:21
TRAINING STATS: batch 82/486 in epoch 1313,  batch loss: 2.18654, batch accuracy: 0.38850
Time: 2018-07-15 11:29:24
TRAINING STATS: batch 132/486 in epoch 1313, batch loss: 2.16310, batch accuracy: 0.37350
Time: 2018-07-15 11:29:28
TRAINING STATS: batch 182/486 in epoch 1313, batch loss: 2.20599, batch accuracy: 0.36583
Time: 2018-07-15 11:29:33
TRAINING STATS: batch 232/486 in epoch 1313, batch loss: 2.18613, batch accuracy: 0.39583
Time: 2018-07-15 11:29:36
TRAINING STATS: batch 282/486 in epoch 1313, batch loss: 2.13461, batch accuracy: 0.38467
Time: 2018-07-15 11:29:40
TRAINING STATS: batch 332/486 in epoch 1313, batch loss: 2.17595, batch accuracy: 0.38583
Time: 2018-07-15 11:29:45
TRAINING STATS: batch 382/486 in epoch 1313, batch loss: 2.18221, batch accuracy: 0.38933
Time: 2018-07-15 11:29:48
TRAINING STATS: batch 432/486 in epoch 1313, batch loss: 2.13642, batch accuracy: 0.38217
Time: 2018-07-15 11:29:52
TRAINING STATS: batch 482/486 in epoch 1313, batch loss: 2.16789, batch accuracy: 0.38350
Time: 2018-07-15 11:29:57
TRAINING STATS: batch 46/486 in epoch 1314,  batch loss: 2.15299, batch accuracy: 0.38733
Time: 2018-07-15 11:30:01
TRAINING STATS: batch 96/486 in epoch 1314,  batch loss: 2.18078, batch accuracy: 0.37633
Time: 2018-07-15 11:30:04
TRAINING STATS: batch 146/486 in epoch 1314, batch loss: 2.18659, batch accuracy: 0.38783
Time: 2018-07-15 11:30:09
TRAINING STATS: batch 196/486 in epoch 1314, batch loss: 2.17677, batch accuracy: 0.37983
Time: 2018-07-15 11:30:13
TRAINING STATS: batch 246/486 in epoch 1314, batch loss: 2.14490, batch accuracy: 0.38500
Time: 2018-07-15 11:30:16
TRAINING STATS: batch 296/486 in epoch 1314, batch loss: 2.13935, batch accuracy: 0.38733
Time: 2018-07-15 11:30:21
TRAINING STATS: batch 346/486 in epoch 1314, batch loss: 2.12311, batch accuracy: 0.38867
Time: 2018-07-15 11:30:25
TRAINING STATS: batch 396/486 in epoch 1314, batch loss: 2.16090, batch accuracy: 0.38867
Time: 2018-07-15 11:30:29
TRAINING STATS: batch 446/486 in epoch 1314, batch loss: 2.16662, batch accuracy: 0.37433
Time: 2018-07-15 11:30:33
TRAINING STATS: batch 10/486 in epoch 1315,  batch loss: 2.19485, batch accuracy: 0.37683
Time: 2018-07-15 11:30:37
TRAINING STATS: batch 60/486 in epoch 1315,  batch loss: 2.15188, batch accuracy: 0.38633
Time: 2018-07-15 11:30:41
TRAINING STATS: batch 110/486 in epoch 1315, batch loss: 2.19879, batch accuracy: 0.37833
Time: 2018-07-15 11:30:46
TRAINING STATS: batch 160/486 in epoch 1315, batch loss: 2.14910, batch accuracy: 0.38967
Time: 2018-07-15 11:30:49
TRAINING STATS: batch 210/486 in epoch 1315, batch loss: 2.14598, batch accuracy: 0.38833
Time: 2018-07-15 11:30:53
TRAINING STATS: batch 260/486 in epoch 1315, batch loss: 2.18577, batch accuracy: 0.38900
Time: 2018-07-15 11:30:58
TRAINING STATS: batch 310/486 in epoch 1315, batch loss: 2.17338, batch accuracy: 0.37517
Time: 2018-07-15 11:31:01
TRAINING STATS: batch 360/486 in epoch 1315, batch loss: 2.18097, batch accuracy: 0.38083
Time: 2018-07-15 11:31:05
TRAINING STATS: batch 410/486 in epoch 1315, batch loss: 2.12332, batch accuracy: 0.40717
Time: 2018-07-15 11:31:10
TRAINING STATS: batch 460/486 in epoch 1315, batch loss: 2.24563, batch accuracy: 0.35950
Time: 2018-07-15 11:31:14
TRAINING STATS: batch 24/486 in epoch 1316,  batch loss: 2.20427, batch accuracy: 0.37283
Time: 2018-07-15 11:31:17
TRAINING STATS: batch 74/486 in epoch 1316,  batch loss: 2.16976, batch accuracy: 0.37217
Time: 2018-07-15 11:31:22
TRAINING STATS: batch 124/486 in epoch 1316, batch loss: 2.18695, batch accuracy: 0.38017
Time: 2018-07-15 11:31:26
TRAINING STATS: batch 174/486 in epoch 1316, batch loss: 2.18683, batch accuracy: 0.37917
Time: 2018-07-15 11:31:29
TRAINING STATS: batch 224/486 in epoch 1316, batch loss: 2.23287, batch accuracy: 0.36200
Time: 2018-07-15 11:31:34
TRAINING STATS: batch 274/486 in epoch 1316, batch loss: 2.19224, batch accuracy: 0.36800
Time: 2018-07-15 11:31:38
TRAINING STATS: batch 324/486 in epoch 1316, batch loss: 2.20850, batch accuracy: 0.37017
Time: 2018-07-15 11:31:42
TRAINING STATS: batch 374/486 in epoch 1316, batch loss: 2.19879, batch accuracy: 0.37867
Time: 2018-07-15 11:31:46
TRAINING STATS: batch 424/486 in epoch 1316, batch loss: 2.16002, batch accuracy: 0.38550
Time: 2018-07-15 11:31:50
TRAINING STATS: batch 474/486 in epoch 1316, batch loss: 2.16391, batch accuracy: 0.38683
Time: 2018-07-15 11:31:54
TRAINING STATS: batch 38/486 in epoch 1317,  batch loss: 2.20449, batch accuracy: 0.38317
Time: 2018-07-15 11:31:59
TRAINING STATS: batch 88/486 in epoch 1317,  batch loss: 2.24033, batch accuracy: 0.37233
Time: 2018-07-15 11:32:02
TRAINING STATS: batch 138/486 in epoch 1317, batch loss: 2.21664, batch accuracy: 0.38667
Time: 2018-07-15 11:32:06
TRAINING STATS: batch 188/486 in epoch 1317, batch loss: 2.18271, batch accuracy: 0.38667
Time: 2018-07-15 11:32:11
TRAINING STATS: batch 238/486 in epoch 1317, batch loss: 2.18444, batch accuracy: 0.38333
Time: 2018-07-15 11:32:14
TRAINING STATS: batch 288/486 in epoch 1317, batch loss: 2.19378, batch accuracy: 0.38367
Time: 2018-07-15 11:32:18
TRAINING STATS: batch 338/486 in epoch 1317, batch loss: 2.17191, batch accuracy: 0.38417
Time: 2018-07-15 11:32:23
TRAINING STATS: batch 388/486 in epoch 1317, batch loss: 2.14806, batch accuracy: 0.37833
Time: 2018-07-15 11:32:27
TRAINING STATS: batch 438/486 in epoch 1317, batch loss: 2.18251, batch accuracy: 0.37633
Time: 2018-07-15 11:32:30
TRAINING STATS: batch 2/486 in epoch 1318,   batch loss: 2.17818, batch accuracy: 0.37567
Time: 2018-07-15 11:32:35
TRAINING STATS: batch 52/486 in epoch 1318,  batch loss: 2.20216, batch accuracy: 0.38017
Time: 2018-07-15 11:32:39
TRAINING STATS: batch 102/486 in epoch 1318, batch loss: 2.18780, batch accuracy: 0.38883
Time: 2018-07-15 11:32:42
TRAINING STATS: batch 152/486 in epoch 1318, batch loss: 2.15563, batch accuracy: 0.39533
Time: 2018-07-15 11:32:47
TRAINING STATS: batch 202/486 in epoch 1318, batch loss: 2.17794, batch accuracy: 0.37533
Time: 2018-07-15 11:32:51
TRAINING STATS: batch 252/486 in epoch 1318, batch loss: 2.14983, batch accuracy: 0.39000
Time: 2018-07-15 11:32:55
TRAINING STATS: batch 302/486 in epoch 1318, batch loss: 2.14341, batch accuracy: 0.39650
Time: 2018-07-15 11:32:59
TRAINING STATS: batch 352/486 in epoch 1318, batch loss: 2.15893, batch accuracy: 0.39267
Time: 2018-07-15 11:33:03
TRAINING STATS: batch 402/486 in epoch 1318, batch loss: 2.08336, batch accuracy: 0.41483
Time: 2018-07-15 11:33:07
TRAINING STATS: batch 452/486 in epoch 1318, batch loss: 2.14449, batch accuracy: 0.40250
Time: 2018-07-15 11:33:11
TRAINING STATS: batch 16/486 in epoch 1319,  batch loss: 2.14203, batch accuracy: 0.39567
Time: 2018-07-15 11:33:15
TRAINING STATS: batch 66/486 in epoch 1319,  batch loss: 2.15515, batch accuracy: 0.41050
Time: 2018-07-15 11:33:19
TRAINING STATS: batch 116/486 in epoch 1319, batch loss: 2.14852, batch accuracy: 0.40000
Time: 2018-07-15 11:33:24
TRAINING STATS: batch 166/486 in epoch 1319, batch loss: 2.12263, batch accuracy: 0.40833
Time: 2018-07-15 11:33:27
TRAINING STATS: batch 216/486 in epoch 1319, batch loss: 2.17663, batch accuracy: 0.38833
Time: 2018-07-15 11:33:31
TRAINING STATS: batch 266/486 in epoch 1319, batch loss: 2.17290, batch accuracy: 0.39533
Time: 2018-07-15 11:33:36
TRAINING STATS: batch 316/486 in epoch 1319, batch loss: 2.16063, batch accuracy: 0.39350
Time: 2018-07-15 11:33:39
TRAINING STATS: batch 366/486 in epoch 1319, batch loss: 2.19352, batch accuracy: 0.37733
Time: 2018-07-15 11:33:43
TRAINING STATS: batch 416/486 in epoch 1319, batch loss: 2.19798, batch accuracy: 0.37600
Time: 2018-07-15 11:33:48
TRAINING STATS: batch 466/486 in epoch 1319, batch loss: 2.09879, batch accuracy: 0.39583
Time: 2018-07-15 11:33:51
TRAINING STATS: batch 30/486 in epoch 1320,  batch loss: 2.10091, batch accuracy: 0.41167
Time: 2018-07-15 11:33:55
TRAINING STATS: batch 80/486 in epoch 1320,  batch loss: 2.17866, batch accuracy: 0.38817
Time: 2018-07-15 11:34:00
TRAINING STATS: batch 130/486 in epoch 1320, batch loss: 2.18822, batch accuracy: 0.38633
Time: 2018-07-15 11:34:04
TRAINING STATS: batch 180/486 in epoch 1320, batch loss: 2.21558, batch accuracy: 0.37617
Time: 2018-07-15 11:34:07
TRAINING STATS: batch 230/486 in epoch 1320, batch loss: 2.19182, batch accuracy: 0.37383
Time: 2018-07-15 11:34:12
TRAINING STATS: batch 280/486 in epoch 1320, batch loss: 2.17211, batch accuracy: 0.39200
Time: 2018-07-15 11:34:16
TRAINING STATS: batch 330/486 in epoch 1320, batch loss: 2.16716, batch accuracy: 0.38683
Time: 2018-07-15 11:34:20
TRAINING STATS: batch 380/486 in epoch 1320, batch loss: 2.19617, batch accuracy: 0.38250
Time: 2018-07-15 11:34:24
TRAINING STATS: batch 430/486 in epoch 1320, batch loss: 2.12826, batch accuracy: 0.41100
Time: 2018-07-15 11:34:28
TRAINING STATS: batch 480/486 in epoch 1320, batch loss: 2.17840, batch accuracy: 0.38917
Time: 2018-07-15 11:34:32
TRAINING STATS: batch 44/486 in epoch 1321,  batch loss: 2.13778, batch accuracy: 0.39933
Time: 2018-07-15 11:34:37
TRAINING STATS: batch 94/486 in epoch 1321,  batch loss: 2.20291, batch accuracy: 0.37900
Time: 2018-07-15 11:34:40
TRAINING STATS: batch 144/486 in epoch 1321, batch loss: 2.19180, batch accuracy: 0.37400
Time: 2018-07-15 11:34:44
TRAINING STATS: batch 194/486 in epoch 1321, batch loss: 2.20412, batch accuracy: 0.37733
Time: 2018-07-15 11:34:49
TRAINING STATS: batch 244/486 in epoch 1321, batch loss: 2.14769, batch accuracy: 0.40617
Time: 2018-07-15 11:34:52
TRAINING STATS: batch 294/486 in epoch 1321, batch loss: 2.11128, batch accuracy: 0.40267
Time: 2018-07-15 11:34:56
TRAINING STATS: batch 344/486 in epoch 1321, batch loss: 2.16290, batch accuracy: 0.39700
Time: 2018-07-15 11:35:01
TRAINING STATS: batch 394/486 in epoch 1321, batch loss: 2.15136, batch accuracy: 0.39300
Time: 2018-07-15 11:35:04
TRAINING STATS: batch 444/486 in epoch 1321, batch loss: 2.13877, batch accuracy: 0.38950
Time: 2018-07-15 11:35:08
TRAINING STATS: batch 8/486 in epoch 1322,   batch loss: 2.14597, batch accuracy: 0.39167
Time: 2018-07-15 11:35:13
TRAINING STATS: batch 58/486 in epoch 1322,  batch loss: 2.13540, batch accuracy: 0.40400
Time: 2018-07-15 11:35:17
TRAINING STATS: batch 108/486 in epoch 1322, batch loss: 2.20807, batch accuracy: 0.37900
Time: 2018-07-15 11:35:20
TRAINING STATS: batch 158/486 in epoch 1322, batch loss: 2.25051, batch accuracy: 0.35600
Time: 2018-07-15 11:35:25
TRAINING STATS: batch 208/486 in epoch 1322, batch loss: 2.27193, batch accuracy: 0.36800
Time: 2018-07-15 11:35:29
TRAINING STATS: batch 258/486 in epoch 1322, batch loss: 2.20462, batch accuracy: 0.38733
Time: 2018-07-15 11:35:33
TRAINING STATS: batch 308/486 in epoch 1322, batch loss: 2.21048, batch accuracy: 0.39250
Time: 2018-07-15 11:35:37
TRAINING STATS: batch 358/486 in epoch 1322, batch loss: 2.18685, batch accuracy: 0.38533
Time: 2018-07-15 11:35:41
TRAINING STATS: batch 408/486 in epoch 1322, batch loss: 2.20199, batch accuracy: 0.39217
Time: 2018-07-15 11:35:45
TRAINING STATS: batch 458/486 in epoch 1322, batch loss: 2.18727, batch accuracy: 0.39033
Time: 2018-07-15 11:35:49
TRAINING STATS: batch 22/486 in epoch 1323,  batch loss: 2.20122, batch accuracy: 0.39267
Time: 2018-07-15 11:35:53
TRAINING STATS: batch 72/486 in epoch 1323,  batch loss: 2.18607, batch accuracy: 0.37167
Time: 2018-07-15 11:35:57
TRAINING STATS: batch 122/486 in epoch 1323, batch loss: 2.14776, batch accuracy: 0.39667
Time: 2018-07-15 11:36:02
TRAINING STATS: batch 172/486 in epoch 1323, batch loss: 2.20594, batch accuracy: 0.38100
Time: 2018-07-15 11:36:05
TRAINING STATS: batch 222/486 in epoch 1323, batch loss: 2.14723, batch accuracy: 0.39333
Time: 2018-07-15 11:36:09
TRAINING STATS: batch 272/486 in epoch 1323, batch loss: 2.18244, batch accuracy: 0.38183
Time: 2018-07-15 11:36:14
TRAINING STATS: batch 322/486 in epoch 1323, batch loss: 2.16959, batch accuracy: 0.38683
Time: 2018-07-15 11:36:18
TRAINING STATS: batch 372/486 in epoch 1323, batch loss: 2.13742, batch accuracy: 0.40033
Time: 2018-07-15 11:36:21
TRAINING STATS: batch 422/486 in epoch 1323, batch loss: 2.14657, batch accuracy: 0.40367
Time: 2018-07-15 11:36:26
TRAINING STATS: batch 472/486 in epoch 1323, batch loss: 2.19550, batch accuracy: 0.37550
Time: 2018-07-15 11:36:30
TRAINING STATS: batch 36/486 in epoch 1324,  batch loss: 2.19799, batch accuracy: 0.38583
Time: 2018-07-15 11:36:33
TRAINING STATS: batch 86/486 in epoch 1324,  batch loss: 2.19917, batch accuracy: 0.38867
Time: 2018-07-15 11:36:38
TRAINING STATS: batch 136/486 in epoch 1324, batch loss: 2.22485, batch accuracy: 0.37067
Time: 2018-07-15 11:36:42
TRAINING STATS: batch 186/486 in epoch 1324, batch loss: 2.18188, batch accuracy: 0.38650
Time: 2018-07-15 11:36:46
TRAINING STATS: batch 236/486 in epoch 1324, batch loss: 2.18837, batch accuracy: 0.37767
Time: 2018-07-15 11:36:50
TRAINING STATS: batch 286/486 in epoch 1324, batch loss: 2.18728, batch accuracy: 0.38633
Time: 2018-07-15 11:36:54
TRAINING STATS: batch 336/486 in epoch 1324, batch loss: 2.13002, batch accuracy: 0.39650
Time: 2018-07-15 11:36:58
TRAINING STATS: batch 386/486 in epoch 1324, batch loss: 2.18461, batch accuracy: 0.38483
Time: 2018-07-15 11:37:02
TRAINING STATS: batch 436/486 in epoch 1324, batch loss: 2.20334, batch accuracy: 0.37700
Time: 2018-07-15 11:37:06
TRAINING STATS: batch 0/486 in epoch 1325,   batch loss: 2.19179, batch accuracy: 0.36900
Time: 2018-07-15 11:37:10
TRAINING STATS: batch 50/486 in epoch 1325,  batch loss: 2.15866, batch accuracy: 0.39483
Time: 2018-07-15 11:37:15
TRAINING STATS: batch 100/486 in epoch 1325, batch loss: 2.19881, batch accuracy: 0.38200
Time: 2018-07-15 11:37:18
TRAINING STATS: batch 150/486 in epoch 1325, batch loss: 2.18693, batch accuracy: 0.37033
Time: 2018-07-15 11:37:22
TRAINING STATS: batch 200/486 in epoch 1325, batch loss: 2.16241, batch accuracy: 0.38850
Time: 2018-07-15 11:37:27
TRAINING STATS: batch 250/486 in epoch 1325, batch loss: 2.23278, batch accuracy: 0.36950
Time: 2018-07-15 11:37:30
TRAINING STATS: batch 300/486 in epoch 1325, batch loss: 2.20115, batch accuracy: 0.36583
Time: 2018-07-15 11:37:34
TRAINING STATS: batch 350/486 in epoch 1325, batch loss: 2.19128, batch accuracy: 0.38500
Time: 2018-07-15 11:37:39
TRAINING STATS: batch 400/486 in epoch 1325, batch loss: 2.10477, batch accuracy: 0.40550
Time: 2018-07-15 11:37:43
TRAINING STATS: batch 450/486 in epoch 1325, batch loss: 2.19765, batch accuracy: 0.38217
Time: 2018-07-15 11:37:46
TRAINING STATS: batch 14/486 in epoch 1326,  batch loss: 2.12442, batch accuracy: 0.40333
Time: 2018-07-15 11:37:51
TRAINING STATS: batch 64/486 in epoch 1326,  batch loss: 2.37426, batch accuracy: 0.33050
Time: 2018-07-15 11:37:55
TRAINING STATS: batch 114/486 in epoch 1326, batch loss: 2.31169, batch accuracy: 0.34850
Time: 2018-07-15 11:37:59
TRAINING STATS: batch 164/486 in epoch 1326, batch loss: 2.18358, batch accuracy: 0.38350
Time: 2018-07-15 11:38:03
TRAINING STATS: batch 214/486 in epoch 1326, batch loss: 2.20116, batch accuracy: 0.36883
Time: 2018-07-15 11:38:07
TRAINING STATS: batch 264/486 in epoch 1326, batch loss: 2.21130, batch accuracy: 0.38100
Time: 2018-07-15 11:38:11
TRAINING STATS: batch 314/486 in epoch 1326, batch loss: 2.21760, batch accuracy: 0.37433
Time: 2018-07-15 11:38:15
TRAINING STATS: batch 364/486 in epoch 1326, batch loss: 2.16807, batch accuracy: 0.38433
Time: 2018-07-15 11:38:19
TRAINING STATS: batch 414/486 in epoch 1326, batch loss: 2.19825, batch accuracy: 0.38433
Time: 2018-07-15 11:38:23
TRAINING STATS: batch 464/486 in epoch 1326, batch loss: 2.17839, batch accuracy: 0.40300
Time: 2018-07-15 11:38:28
TRAINING STATS: batch 28/486 in epoch 1327,  batch loss: 2.16097, batch accuracy: 0.39200
Time: 2018-07-15 11:38:31
TRAINING STATS: batch 78/486 in epoch 1327,  batch loss: 2.19544, batch accuracy: 0.39150
Time: 2018-07-15 11:38:35
TRAINING STATS: batch 128/486 in epoch 1327, batch loss: 2.17510, batch accuracy: 0.38717
Time: 2018-07-15 11:38:40
TRAINING STATS: batch 178/486 in epoch 1327, batch loss: 2.11681, batch accuracy: 0.40583
Time: 2018-07-15 11:38:43
TRAINING STATS: batch 228/486 in epoch 1327, batch loss: 2.12931, batch accuracy: 0.39517
Time: 2018-07-15 11:38:47
TRAINING STATS: batch 278/486 in epoch 1327, batch loss: 2.12733, batch accuracy: 0.40083
Time: 2018-07-15 11:38:52
TRAINING STATS: batch 328/486 in epoch 1327, batch loss: 2.13230, batch accuracy: 0.39700
Time: 2018-07-15 11:38:56
TRAINING STATS: batch 378/486 in epoch 1327, batch loss: 2.17060, batch accuracy: 0.39183
Time: 2018-07-15 11:38:59
TRAINING STATS: batch 428/486 in epoch 1327, batch loss: 2.20725, batch accuracy: 0.37767
Time: 2018-07-15 11:39:04
TRAINING STATS: batch 478/486 in epoch 1327, batch loss: 2.16786, batch accuracy: 0.38550
Time: 2018-07-15 11:39:08
TRAINING STATS: batch 42/486 in epoch 1328,  batch loss: 2.11573, batch accuracy: 0.40050
Time: 2018-07-15 11:39:11
TRAINING STATS: batch 92/486 in epoch 1328,  batch loss: 2.17305, batch accuracy: 0.38017
Time: 2018-07-15 11:39:16
TRAINING STATS: batch 142/486 in epoch 1328, batch loss: 2.13552, batch accuracy: 0.39367
Time: 2018-07-15 11:39:20
TRAINING STATS: batch 192/486 in epoch 1328, batch loss: 2.16942, batch accuracy: 0.36967
Time: 2018-07-15 11:39:24
TRAINING STATS: batch 242/486 in epoch 1328, batch loss: 2.16302, batch accuracy: 0.38933
Time: 2018-07-15 11:39:28
TRAINING STATS: batch 292/486 in epoch 1328, batch loss: 2.15523, batch accuracy: 0.39850
Time: 2018-07-15 11:39:32
TRAINING STATS: batch 342/486 in epoch 1328, batch loss: 2.15613, batch accuracy: 0.38500
Time: 2018-07-15 11:39:36
TRAINING STATS: batch 392/486 in epoch 1328, batch loss: 2.13301, batch accuracy: 0.39250
Time: 2018-07-15 11:39:40
TRAINING STATS: batch 442/486 in epoch 1328, batch loss: 2.12562, batch accuracy: 0.40683
Time: 2018-07-15 11:39:44
TRAINING STATS: batch 6/486 in epoch 1329,   batch loss: 2.18230, batch accuracy: 0.38350
Time: 2018-07-15 11:39:48
TRAINING STATS: batch 56/486 in epoch 1329,  batch loss: 2.14145, batch accuracy: 0.39550
Time: 2018-07-15 11:39:53
TRAINING STATS: batch 106/486 in epoch 1329, batch loss: 2.19099, batch accuracy: 0.39450
Time: 2018-07-15 11:39:56
TRAINING STATS: batch 156/486 in epoch 1329, batch loss: 2.18084, batch accuracy: 0.37133
Time: 2018-07-15 11:40:00
TRAINING STATS: batch 206/486 in epoch 1329, batch loss: 2.21098, batch accuracy: 0.36933
Time: 2018-07-15 11:40:05
TRAINING STATS: batch 256/486 in epoch 1329, batch loss: 2.12609, batch accuracy: 0.40183
Time: 2018-07-15 11:40:08
TRAINING STATS: batch 306/486 in epoch 1329, batch loss: 2.15075, batch accuracy: 0.39533
Time: 2018-07-15 11:40:12
TRAINING STATS: batch 356/486 in epoch 1329, batch loss: 2.19727, batch accuracy: 0.37517
Time: 2018-07-15 11:40:17
TRAINING STATS: batch 406/486 in epoch 1329, batch loss: 2.18604, batch accuracy: 0.37850
Time: 2018-07-15 11:40:21
TRAINING STATS: batch 456/486 in epoch 1329, batch loss: 2.11392, batch accuracy: 0.40350
Time: 2018-07-15 11:40:24
TRAINING STATS: batch 20/486 in epoch 1330,  batch loss: 2.15764, batch accuracy: 0.38367
Time: 2018-07-15 11:40:29
TRAINING STATS: batch 70/486 in epoch 1330,  batch loss: 2.12010, batch accuracy: 0.40217
Time: 2018-07-15 11:40:33
TRAINING STATS: batch 120/486 in epoch 1330, batch loss: 2.13235, batch accuracy: 0.39350
Time: 2018-07-15 11:40:36
TRAINING STATS: batch 170/486 in epoch 1330, batch loss: 2.13680, batch accuracy: 0.40150
Time: 2018-07-15 11:40:41
TRAINING STATS: batch 220/486 in epoch 1330, batch loss: 2.17600, batch accuracy: 0.39350
Time: 2018-07-15 11:40:45
TRAINING STATS: batch 270/486 in epoch 1330, batch loss: 2.19039, batch accuracy: 0.38400
Time: 2018-07-15 11:40:49
TRAINING STATS: batch 320/486 in epoch 1330, batch loss: 2.13906, batch accuracy: 0.38683
Time: 2018-07-15 11:40:53
TRAINING STATS: batch 370/486 in epoch 1330, batch loss: 2.17758, batch accuracy: 0.39283
Time: 2018-07-15 11:40:57
TRAINING STATS: batch 420/486 in epoch 1330, batch loss: 2.21549, batch accuracy: 0.36983
Time: 2018-07-15 11:41:01
TRAINING STATS: batch 470/486 in epoch 1330, batch loss: 2.23699, batch accuracy: 0.35667
Time: 2018-07-15 11:41:05
TRAINING STATS: batch 34/486 in epoch 1331,  batch loss: 2.19735, batch accuracy: 0.38133
Time: 2018-07-15 11:41:09
TRAINING STATS: batch 84/486 in epoch 1331,  batch loss: 2.17046, batch accuracy: 0.36917
Time: 2018-07-15 11:41:13
TRAINING STATS: batch 134/486 in epoch 1331, batch loss: 2.23074, batch accuracy: 0.37433
Time: 2018-07-15 11:41:18
TRAINING STATS: batch 184/486 in epoch 1331, batch loss: 2.20245, batch accuracy: 0.36367
Time: 2018-07-15 11:41:21
TRAINING STATS: batch 234/486 in epoch 1331, batch loss: 2.23044, batch accuracy: 0.35717
Time: 2018-07-15 11:41:25
TRAINING STATS: batch 284/486 in epoch 1331, batch loss: 2.19945, batch accuracy: 0.37717
Time: 2018-07-15 11:41:30
TRAINING STATS: batch 334/486 in epoch 1331, batch loss: 2.15100, batch accuracy: 0.38117
Time: 2018-07-15 11:41:33
TRAINING STATS: batch 384/486 in epoch 1331, batch loss: 2.14726, batch accuracy: 0.38917
Time: 2018-07-15 11:41:37
TRAINING STATS: batch 434/486 in epoch 1331, batch loss: 2.19005, batch accuracy: 0.37900
Time: 2018-07-15 11:41:42
TRAINING STATS: batch 484/486 in epoch 1331, batch loss: 2.15723, batch accuracy: 0.38883
Time: 2018-07-15 11:41:46
TRAINING STATS: batch 48/486 in epoch 1332,  batch loss: 2.14872, batch accuracy: 0.39900
Time: 2018-07-15 11:41:49
TRAINING STATS: batch 98/486 in epoch 1332,  batch loss: 2.14089, batch accuracy: 0.39233
Time: 2018-07-15 11:41:54
TRAINING STATS: batch 148/486 in epoch 1332, batch loss: 2.18787, batch accuracy: 0.38783
Time: 2018-07-15 11:41:58
TRAINING STATS: batch 198/486 in epoch 1332, batch loss: 2.13300, batch accuracy: 0.40483
Time: 2018-07-15 11:42:02
TRAINING STATS: batch 248/486 in epoch 1332, batch loss: 2.15919, batch accuracy: 0.39633
Time: 2018-07-15 11:42:06
TRAINING STATS: batch 298/486 in epoch 1332, batch loss: 2.17003, batch accuracy: 0.37617
Time: 2018-07-15 11:42:10
TRAINING STATS: batch 348/486 in epoch 1332, batch loss: 2.18289, batch accuracy: 0.39050
Time: 2018-07-15 11:42:14
TRAINING STATS: batch 398/486 in epoch 1332, batch loss: 2.14660, batch accuracy: 0.39567
Time: 2018-07-15 11:42:18
TRAINING STATS: batch 448/486 in epoch 1332, batch loss: 2.13864, batch accuracy: 0.39200
Time: 2018-07-15 11:42:22
TRAINING STATS: batch 12/486 in epoch 1333,  batch loss: 2.16383, batch accuracy: 0.39300
Time: 2018-07-15 11:42:26
TRAINING STATS: batch 62/486 in epoch 1333,  batch loss: 2.20135, batch accuracy: 0.39367
Time: 2018-07-15 11:42:31
TRAINING STATS: batch 112/486 in epoch 1333, batch loss: 2.15074, batch accuracy: 0.40183
Time: 2018-07-15 11:42:34
TRAINING STATS: batch 162/486 in epoch 1333, batch loss: 2.16430, batch accuracy: 0.39550
Time: 2018-07-15 11:42:38
TRAINING STATS: batch 212/486 in epoch 1333, batch loss: 2.12926, batch accuracy: 0.39967
Time: 2018-07-15 11:42:43
TRAINING STATS: batch 262/486 in epoch 1333, batch loss: 2.19297, batch accuracy: 0.37150
Time: 2018-07-15 11:42:46
TRAINING STATS: batch 312/486 in epoch 1333, batch loss: 2.16041, batch accuracy: 0.38900
Time: 2018-07-15 11:42:50
TRAINING STATS: batch 362/486 in epoch 1333, batch loss: 2.17687, batch accuracy: 0.37067
Time: 2018-07-15 11:42:55
TRAINING STATS: batch 412/486 in epoch 1333, batch loss: 2.12860, batch accuracy: 0.40017
Time: 2018-07-15 11:42:59
TRAINING STATS: batch 462/486 in epoch 1333, batch loss: 2.16461, batch accuracy: 0.38333
Time: 2018-07-15 11:43:02
TRAINING STATS: batch 26/486 in epoch 1334,  batch loss: 2.15683, batch accuracy: 0.38583
Time: 2018-07-15 11:43:07
TRAINING STATS: batch 76/486 in epoch 1334,  batch loss: 2.19070, batch accuracy: 0.39317
Time: 2018-07-15 11:43:11
TRAINING STATS: batch 126/486 in epoch 1334, batch loss: 2.19694, batch accuracy: 0.37050
Time: 2018-07-15 11:43:14
TRAINING STATS: batch 176/486 in epoch 1334, batch loss: 2.11359, batch accuracy: 0.40933
Time: 2018-07-15 11:43:19
TRAINING STATS: batch 226/486 in epoch 1334, batch loss: 2.14609, batch accuracy: 0.38817
Time: 2018-07-15 11:43:23
TRAINING STATS: batch 276/486 in epoch 1334, batch loss: 2.17084, batch accuracy: 0.37783
Time: 2018-07-15 11:43:27
TRAINING STATS: batch 326/486 in epoch 1334, batch loss: 2.17300, batch accuracy: 0.39433
Time: 2018-07-15 11:43:31
TRAINING STATS: batch 376/486 in epoch 1334, batch loss: 2.15959, batch accuracy: 0.39683
Time: 2018-07-15 11:43:35
TRAINING STATS: batch 426/486 in epoch 1334, batch loss: 2.16000, batch accuracy: 0.37367
Time: 2018-07-15 11:43:39
TRAINING STATS: batch 476/486 in epoch 1334, batch loss: 2.13373, batch accuracy: 0.39700
Time: 2018-07-15 11:43:44
TRAINING STATS: batch 40/486 in epoch 1335,  batch loss: 2.14102, batch accuracy: 0.38700
Time: 2018-07-15 11:43:47
TRAINING STATS: batch 90/486 in epoch 1335,  batch loss: 2.15821, batch accuracy: 0.39867
Time: 2018-07-15 11:43:51
TRAINING STATS: batch 140/486 in epoch 1335, batch loss: 2.10677, batch accuracy: 0.40833
Time: 2018-07-15 11:43:56
TRAINING STATS: batch 190/486 in epoch 1335, batch loss: 2.14234, batch accuracy: 0.40017
Time: 2018-07-15 11:43:59
TRAINING STATS: batch 240/486 in epoch 1335, batch loss: 2.15204, batch accuracy: 0.38950
Time: 2018-07-15 11:44:03
TRAINING STATS: batch 290/486 in epoch 1335, batch loss: 2.17275, batch accuracy: 0.38817
Time: 2018-07-15 11:44:08
TRAINING STATS: batch 340/486 in epoch 1335, batch loss: 2.18760, batch accuracy: 0.38533
Time: 2018-07-15 11:44:11
TRAINING STATS: batch 390/486 in epoch 1335, batch loss: 2.11368, batch accuracy: 0.40383
Time: 2018-07-15 11:44:15
TRAINING STATS: batch 440/486 in epoch 1335, batch loss: 2.15174, batch accuracy: 0.39217
Time: 2018-07-15 11:44:20
TRAINING STATS: batch 4/486 in epoch 1336,   batch loss: 2.11600, batch accuracy: 0.40017
Time: 2018-07-15 11:44:24
TRAINING STATS: batch 54/486 in epoch 1336,  batch loss: 2.14772, batch accuracy: 0.39833
Time: 2018-07-15 11:44:27
TRAINING STATS: batch 104/486 in epoch 1336, batch loss: 2.16494, batch accuracy: 0.38350
Time: 2018-07-15 11:44:32
TRAINING STATS: batch 154/486 in epoch 1336, batch loss: 2.14215, batch accuracy: 0.40450
Time: 2018-07-15 11:44:36
TRAINING STATS: batch 204/486 in epoch 1336, batch loss: 2.20103, batch accuracy: 0.38183
Time: 2018-07-15 11:44:39
TRAINING STATS: batch 254/486 in epoch 1336, batch loss: 2.12278, batch accuracy: 0.41150
Time: 2018-07-15 11:44:44
TRAINING STATS: batch 304/486 in epoch 1336, batch loss: 2.12315, batch accuracy: 0.41633
Time: 2018-07-15 11:44:48
TRAINING STATS: batch 354/486 in epoch 1336, batch loss: 2.15651, batch accuracy: 0.37183
Time: 2018-07-15 11:44:52
TRAINING STATS: batch 404/486 in epoch 1336, batch loss: 2.13733, batch accuracy: 0.38583
Time: 2018-07-15 11:44:56
TRAINING STATS: batch 454/486 in epoch 1336, batch loss: 2.07042, batch accuracy: 0.41800
Time: 2018-07-15 11:45:00
TRAINING STATS: batch 18/486 in epoch 1337,  batch loss: 2.17635, batch accuracy: 0.38000
Time: 2018-07-15 11:45:04
TRAINING STATS: batch 68/486 in epoch 1337,  batch loss: 2.06325, batch accuracy: 0.42817
Time: 2018-07-15 11:45:08
TRAINING STATS: batch 118/486 in epoch 1337, batch loss: 2.16452, batch accuracy: 0.38050
Time: 2018-07-15 11:45:12
TRAINING STATS: batch 168/486 in epoch 1337, batch loss: 2.10894, batch accuracy: 0.39433
Time: 2018-07-15 11:45:16
TRAINING STATS: batch 218/486 in epoch 1337, batch loss: 2.15353, batch accuracy: 0.38333
Time: 2018-07-15 11:45:21
TRAINING STATS: batch 268/486 in epoch 1337, batch loss: 2.12024, batch accuracy: 0.38500
Time: 2018-07-15 11:45:24
TRAINING STATS: batch 318/486 in epoch 1337, batch loss: 2.12683, batch accuracy: 0.39383
Time: 2018-07-15 11:45:28
TRAINING STATS: batch 368/486 in epoch 1337, batch loss: 2.16187, batch accuracy: 0.39233
Time: 2018-07-15 11:45:33
TRAINING STATS: batch 418/486 in epoch 1337, batch loss: 2.19937, batch accuracy: 0.36417
Time: 2018-07-15 11:45:37
