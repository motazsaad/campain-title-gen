0/758000 (epoch 0), train_loss = 9.535, time/batch = 0.218, All_Time = 0.218
model saved to NER/polyglot/model.ckpt
50/758000 (epoch 0), train_loss = 5.019, time/batch = 0.029, All_Time = 1.661
100/758000 (epoch 0), train_loss = 4.882, time/batch = 0.029, All_Time = 3.092
150/758000 (epoch 0), train_loss = 4.838, time/batch = 0.028, All_Time = 4.527
200/758000 (epoch 0), train_loss = 5.030, time/batch = 0.029, All_Time = 5.949
250/758000 (epoch 0), train_loss = 4.912, time/batch = 0.029, All_Time = 7.394
300/758000 (epoch 0), train_loss = 4.993, time/batch = 0.029, All_Time = 8.818
350/758000 (epoch 0), train_loss = 4.831, time/batch = 0.028, All_Time = 10.247
400/758000 (epoch 1), train_loss = 4.828, time/batch = 0.029, All_Time = 11.685
450/758000 (epoch 1), train_loss = 4.754, time/batch = 0.028, All_Time = 13.116
500/758000 (epoch 1), train_loss = 4.938, time/batch = 0.028, All_Time = 14.551
550/758000 (epoch 1), train_loss = 4.791, time/batch = 0.028, All_Time = 15.980
600/758000 (epoch 1), train_loss = 4.746, time/batch = 0.029, All_Time = 17.416
650/758000 (epoch 1), train_loss = 4.741, time/batch = 0.029, All_Time = 18.840
700/758000 (epoch 1), train_loss = 4.926, time/batch = 0.027, All_Time = 20.272
750/758000 (epoch 1), train_loss = 4.950, time/batch = 0.028, All_Time = 21.708
800/758000 (epoch 2), train_loss = 4.909, time/batch = 0.028, All_Time = 23.156
850/758000 (epoch 2), train_loss = 4.410, time/batch = 0.029, All_Time = 24.582
900/758000 (epoch 2), train_loss = 3.377, time/batch = 0.029, All_Time = 26.014
950/758000 (epoch 2), train_loss = 2.675, time/batch = 0.029, All_Time = 27.453
1000/758000 (epoch 2), train_loss = 2.085, time/batch = 0.028, All_Time = 28.882
model saved to NER/polyglot/model.ckpt
1050/758000 (epoch 2), train_loss = 2.149, time/batch = 0.029, All_Time = 30.311
1100/758000 (epoch 2), train_loss = 2.027, time/batch = 0.028, All_Time = 31.734
1150/758000 (epoch 3), train_loss = 2.159, time/batch = 0.030, All_Time = 33.167
1200/758000 (epoch 3), train_loss = 1.774, time/batch = 0.028, All_Time = 34.601
1250/758000 (epoch 3), train_loss = 1.976, time/batch = 0.028, All_Time = 36.031
1300/758000 (epoch 3), train_loss = 1.770, time/batch = 0.030, All_Time = 37.455
1350/758000 (epoch 3), train_loss = 1.778, time/batch = 0.028, All_Time = 38.892
1400/758000 (epoch 3), train_loss = 1.448, time/batch = 0.030, All_Time = 40.316
1450/758000 (epoch 3), train_loss = 1.873, time/batch = 0.029, All_Time = 41.742
1500/758000 (epoch 3), train_loss = 1.629, time/batch = 0.028, All_Time = 43.176
1550/758000 (epoch 4), train_loss = 1.602, time/batch = 0.029, All_Time = 44.615
1600/758000 (epoch 4), train_loss = 1.596, time/batch = 0.029, All_Time = 46.048
1650/758000 (epoch 4), train_loss = 1.368, time/batch = 0.030, All_Time = 47.485
1700/758000 (epoch 4), train_loss = 1.501, time/batch = 0.029, All_Time = 48.917
1750/758000 (epoch 4), train_loss = 1.413, time/batch = 0.029, All_Time = 50.352
1800/758000 (epoch 4), train_loss = 1.446, time/batch = 0.028, All_Time = 51.796
1850/758000 (epoch 4), train_loss = 1.353, time/batch = 0.028, All_Time = 53.233
1900/758000 (epoch 5), train_loss = 1.459, time/batch = 0.030, All_Time = 54.669
1950/758000 (epoch 5), train_loss = 1.361, time/batch = 0.028, All_Time = 56.101
2000/758000 (epoch 5), train_loss = 1.500, time/batch = 0.030, All_Time = 57.536
model saved to NER/polyglot/model.ckpt
2050/758000 (epoch 5), train_loss = 1.329, time/batch = 0.029, All_Time = 58.981
2100/758000 (epoch 5), train_loss = 1.221, time/batch = 0.029, All_Time = 60.422
2150/758000 (epoch 5), train_loss = 1.114, time/batch = 0.029, All_Time = 61.849
2200/758000 (epoch 5), train_loss = 1.497, time/batch = 0.029, All_Time = 63.286
2250/758000 (epoch 5), train_loss = 1.350, time/batch = 0.028, All_Time = 64.718
2300/758000 (epoch 6), train_loss = 1.523, time/batch = 0.030, All_Time = 66.157
2350/758000 (epoch 6), train_loss = 1.154, time/batch = 0.030, All_Time = 67.591
2400/758000 (epoch 6), train_loss = 1.309, time/batch = 0.028, All_Time = 69.026
2450/758000 (epoch 6), train_loss = 1.223, time/batch = 0.029, All_Time = 70.450
2500/758000 (epoch 6), train_loss = 1.333, time/batch = 0.028, All_Time = 71.885
2550/758000 (epoch 6), train_loss = 1.248, time/batch = 0.029, All_Time = 73.303
2600/758000 (epoch 6), train_loss = 1.380, time/batch = 0.028, All_Time = 74.735
2650/758000 (epoch 6), train_loss = 1.172, time/batch = 0.029, All_Time = 76.173
2700/758000 (epoch 7), train_loss = 1.273, time/batch = 0.028, All_Time = 77.602
2750/758000 (epoch 7), train_loss = 1.355, time/batch = 0.028, All_Time = 79.040
2800/758000 (epoch 7), train_loss = 1.094, time/batch = 0.030, All_Time = 80.471
2850/758000 (epoch 7), train_loss = 1.137, time/batch = 0.029, All_Time = 81.904
2900/758000 (epoch 7), train_loss = 1.074, time/batch = 0.029, All_Time = 83.341
2950/758000 (epoch 7), train_loss = 1.080, time/batch = 0.027, All_Time = 84.773
3000/758000 (epoch 7), train_loss = 1.217, time/batch = 0.028, All_Time = 86.207
model saved to NER/polyglot/model.ckpt
3050/758000 (epoch 8), train_loss = 1.234, time/batch = 0.029, All_Time = 87.645
3100/758000 (epoch 8), train_loss = 1.153, time/batch = 0.028, All_Time = 89.071
3150/758000 (epoch 8), train_loss = 1.190, time/batch = 0.030, All_Time = 90.518
3200/758000 (epoch 8), train_loss = 1.191, time/batch = 0.030, All_Time = 91.954
3250/758000 (epoch 8), train_loss = 0.944, time/batch = 0.029, All_Time = 93.387
3300/758000 (epoch 8), train_loss = 1.014, time/batch = 0.030, All_Time = 94.828
3350/758000 (epoch 8), train_loss = 1.222, time/batch = 0.028, All_Time = 96.257
3400/758000 (epoch 8), train_loss = 1.019, time/batch = 0.028, All_Time = 97.690
3450/758000 (epoch 9), train_loss = 1.059, time/batch = 0.030, All_Time = 99.124
3500/758000 (epoch 9), train_loss = 1.172, time/batch = 0.028, All_Time = 100.558
3550/758000 (epoch 9), train_loss = 0.974, time/batch = 0.028, All_Time = 101.986
3600/758000 (epoch 9), train_loss = 1.043, time/batch = 0.028, All_Time = 103.421
3650/758000 (epoch 9), train_loss = 0.982, time/batch = 0.029, All_Time = 104.852
3700/758000 (epoch 9), train_loss = 1.229, time/batch = 0.028, All_Time = 106.277
3750/758000 (epoch 9), train_loss = 1.063, time/batch = 0.030, All_Time = 107.713
3800/758000 (epoch 10), train_loss = 0.970, time/batch = 0.028, All_Time = 109.150
3850/758000 (epoch 10), train_loss = 1.082, time/batch = 0.029, All_Time = 110.588
3900/758000 (epoch 10), train_loss = 1.062, time/batch = 0.028, All_Time = 112.077
3950/758000 (epoch 10), train_loss = 0.910, time/batch = 0.030, All_Time = 113.552
4000/758000 (epoch 10), train_loss = 0.891, time/batch = 0.028, All_Time = 115.012
model saved to NER/polyglot/model.ckpt
4050/758000 (epoch 10), train_loss = 0.911, time/batch = 0.029, All_Time = 116.470
4100/758000 (epoch 10), train_loss = 0.895, time/batch = 0.029, All_Time = 117.911
4150/758000 (epoch 10), train_loss = 1.020, time/batch = 0.029, All_Time = 119.372
4200/758000 (epoch 11), train_loss = 1.131, time/batch = 0.029, All_Time = 120.815
4250/758000 (epoch 11), train_loss = 0.963, time/batch = 0.028, All_Time = 122.261
4300/758000 (epoch 11), train_loss = 0.931, time/batch = 0.029, All_Time = 123.704
4350/758000 (epoch 11), train_loss = 0.964, time/batch = 0.029, All_Time = 125.312
4400/758000 (epoch 11), train_loss = 0.988, time/batch = 0.028, All_Time = 126.787
4450/758000 (epoch 11), train_loss = 1.000, time/batch = 0.028, All_Time = 128.241
4500/758000 (epoch 11), train_loss = 0.997, time/batch = 0.028, All_Time = 129.684
4550/758000 (epoch 12), train_loss = 0.869, time/batch = 0.028, All_Time = 131.128
4600/758000 (epoch 12), train_loss = 0.925, time/batch = 0.028, All_Time = 132.573
4650/758000 (epoch 12), train_loss = 0.976, time/batch = 0.029, All_Time = 134.026
4700/758000 (epoch 12), train_loss = 0.867, time/batch = 0.030, All_Time = 135.516
4750/758000 (epoch 12), train_loss = 0.797, time/batch = 0.028, All_Time = 137.023
4800/758000 (epoch 12), train_loss = 0.839, time/batch = 0.032, All_Time = 138.491
4850/758000 (epoch 12), train_loss = 0.867, time/batch = 0.029, All_Time = 139.979
4900/758000 (epoch 12), train_loss = 0.832, time/batch = 0.030, All_Time = 141.434
4950/758000 (epoch 13), train_loss = 0.907, time/batch = 0.029, All_Time = 142.893
5000/758000 (epoch 13), train_loss = 0.831, time/batch = 0.028, All_Time = 144.353
model saved to NER/polyglot/model.ckpt
5050/758000 (epoch 13), train_loss = 0.924, time/batch = 0.028, All_Time = 145.807
5100/758000 (epoch 13), train_loss = 0.895, time/batch = 0.030, All_Time = 147.264
5150/758000 (epoch 13), train_loss = 0.737, time/batch = 0.028, All_Time = 148.715
5200/758000 (epoch 13), train_loss = 0.797, time/batch = 0.028, All_Time = 150.169
5250/758000 (epoch 13), train_loss = 0.870, time/batch = 0.030, All_Time = 151.626
5300/758000 (epoch 13), train_loss = 0.833, time/batch = 0.029, All_Time = 153.078
5350/758000 (epoch 14), train_loss = 0.840, time/batch = 0.029, All_Time = 154.544
5400/758000 (epoch 14), train_loss = 0.924, time/batch = 0.030, All_Time = 155.994
5450/758000 (epoch 14), train_loss = 0.843, time/batch = 0.029, All_Time = 157.465
5500/758000 (epoch 14), train_loss = 0.734, time/batch = 0.028, All_Time = 158.929
5550/758000 (epoch 14), train_loss = 0.774, time/batch = 0.028, All_Time = 160.382
5600/758000 (epoch 14), train_loss = 0.842, time/batch = 0.029, All_Time = 161.843
5650/758000 (epoch 14), train_loss = 0.826, time/batch = 0.030, All_Time = 163.307
5700/758000 (epoch 15), train_loss = 0.817, time/batch = 0.029, All_Time = 164.773
5750/758000 (epoch 15), train_loss = 0.865, time/batch = 0.029, All_Time = 166.235
5800/758000 (epoch 15), train_loss = 0.830, time/batch = 0.029, All_Time = 167.694
5850/758000 (epoch 15), train_loss = 0.712, time/batch = 0.031, All_Time = 169.150
5900/758000 (epoch 15), train_loss = 0.656, time/batch = 0.028, All_Time = 170.601
5950/758000 (epoch 15), train_loss = 0.694, time/batch = 0.031, All_Time = 172.062
6000/758000 (epoch 15), train_loss = 0.743, time/batch = 0.028, All_Time = 173.524
model saved to NER/polyglot/model.ckpt
6050/758000 (epoch 15), train_loss = 0.793, time/batch = 0.029, All_Time = 174.980
6100/758000 (epoch 16), train_loss = 0.860, time/batch = 0.029, All_Time = 176.444
6150/758000 (epoch 16), train_loss = 0.756, time/batch = 0.030, All_Time = 177.893
6200/758000 (epoch 16), train_loss = 0.724, time/batch = 0.031, All_Time = 179.372
6250/758000 (epoch 16), train_loss = 0.716, time/batch = 0.030, All_Time = 180.850
6300/758000 (epoch 16), train_loss = 0.794, time/batch = 0.030, All_Time = 182.309
6350/758000 (epoch 16), train_loss = 0.829, time/batch = 0.030, All_Time = 183.781
6400/758000 (epoch 16), train_loss = 0.746, time/batch = 0.028, All_Time = 185.243
6450/758000 (epoch 17), train_loss = 0.690, time/batch = 0.030, All_Time = 186.721
6500/758000 (epoch 17), train_loss = 0.689, time/batch = 0.029, All_Time = 188.170
6550/758000 (epoch 17), train_loss = 0.852, time/batch = 0.029, All_Time = 189.638
6600/758000 (epoch 17), train_loss = 0.696, time/batch = 0.028, All_Time = 191.098
6650/758000 (epoch 17), train_loss = 0.683, time/batch = 0.030, All_Time = 192.543
6700/758000 (epoch 17), train_loss = 0.661, time/batch = 0.028, All_Time = 193.992
6750/758000 (epoch 17), train_loss = 0.731, time/batch = 0.030, All_Time = 195.447
6800/758000 (epoch 17), train_loss = 0.680, time/batch = 0.029, All_Time = 196.910
6850/758000 (epoch 18), train_loss = 0.695, time/batch = 0.028, All_Time = 198.363
6900/758000 (epoch 18), train_loss = 0.691, time/batch = 0.031, All_Time = 199.843
6950/758000 (epoch 18), train_loss = 0.644, time/batch = 0.030, All_Time = 201.328
7000/758000 (epoch 18), train_loss = 0.722, time/batch = 0.028, All_Time = 202.784
model saved to NER/polyglot/model.ckpt
7050/758000 (epoch 18), train_loss = 0.653, time/batch = 0.030, All_Time = 204.245
7100/758000 (epoch 18), train_loss = 0.616, time/batch = 0.030, All_Time = 205.689
7150/758000 (epoch 18), train_loss = 0.754, time/batch = 0.029, All_Time = 207.137
7200/758000 (epoch 18), train_loss = 0.686, time/batch = 0.030, All_Time = 208.586
7250/758000 (epoch 19), train_loss = 0.668, time/batch = 0.030, All_Time = 210.049
7300/758000 (epoch 19), train_loss = 0.785, time/batch = 0.030, All_Time = 211.507
7350/758000 (epoch 19), train_loss = 0.607, time/batch = 0.029, All_Time = 212.971
7400/758000 (epoch 19), train_loss = 0.594, time/batch = 0.030, All_Time = 214.437
7450/758000 (epoch 19), train_loss = 0.713, time/batch = 0.029, All_Time = 215.889
7500/758000 (epoch 19), train_loss = 0.686, time/batch = 0.030, All_Time = 217.343
7550/758000 (epoch 19), train_loss = 0.649, time/batch = 0.028, All_Time = 218.791
7600/758000 (epoch 20), train_loss = 0.653, time/batch = 0.028, All_Time = 220.241
7650/758000 (epoch 20), train_loss = 0.595, time/batch = 0.030, All_Time = 221.691
7700/758000 (epoch 20), train_loss = 0.604, time/batch = 0.031, All_Time = 223.140
7750/758000 (epoch 20), train_loss = 0.600, time/batch = 0.029, All_Time = 224.610
7800/758000 (epoch 20), train_loss = 0.553, time/batch = 0.030, All_Time = 226.096
7850/758000 (epoch 20), train_loss = 0.626, time/batch = 0.029, All_Time = 227.561
7900/758000 (epoch 20), train_loss = 0.750, time/batch = 0.029, All_Time = 229.028
7950/758000 (epoch 20), train_loss = 0.638, time/batch = 0.029, All_Time = 230.496
8000/758000 (epoch 21), train_loss = 0.642, time/batch = 0.029, All_Time = 231.952
model saved to NER/polyglot/model.ckpt
8050/758000 (epoch 21), train_loss = 0.683, time/batch = 0.029, All_Time = 233.409
8100/758000 (epoch 21), train_loss = 0.608, time/batch = 0.029, All_Time = 234.847
8150/758000 (epoch 21), train_loss = 0.627, time/batch = 0.029, All_Time = 236.293
8200/758000 (epoch 21), train_loss = 0.533, time/batch = 0.029, All_Time = 237.737
8250/758000 (epoch 21), train_loss = 0.629, time/batch = 0.030, All_Time = 239.192
8300/758000 (epoch 21), train_loss = 0.650, time/batch = 0.029, All_Time = 240.657
8350/758000 (epoch 22), train_loss = 0.636, time/batch = 0.029, All_Time = 242.127
8400/758000 (epoch 22), train_loss = 0.568, time/batch = 0.029, All_Time = 243.578
8450/758000 (epoch 22), train_loss = 0.627, time/batch = 0.030, All_Time = 245.043
8500/758000 (epoch 22), train_loss = 0.591, time/batch = 0.031, All_Time = 246.508
8550/758000 (epoch 22), train_loss = 0.585, time/batch = 0.028, All_Time = 247.964
8600/758000 (epoch 22), train_loss = 0.540, time/batch = 0.029, All_Time = 249.428
8650/758000 (epoch 22), train_loss = 0.568, time/batch = 0.029, All_Time = 250.888
8700/758000 (epoch 22), train_loss = 0.623, time/batch = 0.031, All_Time = 252.352
8750/758000 (epoch 23), train_loss = 0.604, time/batch = 0.029, All_Time = 253.799
8800/758000 (epoch 23), train_loss = 0.531, time/batch = 0.028, All_Time = 255.249
8850/758000 (epoch 23), train_loss = 0.661, time/batch = 0.027, All_Time = 256.710
8900/758000 (epoch 23), train_loss = 0.613, time/batch = 0.028, All_Time = 258.166
8950/758000 (epoch 23), train_loss = 0.542, time/batch = 0.029, All_Time = 259.643
9000/758000 (epoch 23), train_loss = 0.595, time/batch = 0.030, All_Time = 261.129
model saved to NER/polyglot/model.ckpt
9050/758000 (epoch 23), train_loss = 0.586, time/batch = 0.030, All_Time = 262.593
9100/758000 (epoch 24), train_loss = 0.545, time/batch = 0.030, All_Time = 264.033
9150/758000 (epoch 24), train_loss = 0.603, time/batch = 0.030, All_Time = 265.481
9200/758000 (epoch 24), train_loss = 0.591, time/batch = 0.029, All_Time = 266.925
9250/758000 (epoch 24), train_loss = 0.566, time/batch = 0.029, All_Time = 268.377
9300/758000 (epoch 24), train_loss = 0.528, time/batch = 0.029, All_Time = 269.837
9350/758000 (epoch 24), train_loss = 0.535, time/batch = 0.029, All_Time = 271.291
9400/758000 (epoch 24), train_loss = 0.550, time/batch = 0.030, All_Time = 272.743
9450/758000 (epoch 24), train_loss = 0.531, time/batch = 0.030, All_Time = 274.204
9500/758000 (epoch 25), train_loss = 0.598, time/batch = 0.029, All_Time = 275.657
9550/758000 (epoch 25), train_loss = 0.518, time/batch = 0.030, All_Time = 277.118
9600/758000 (epoch 25), train_loss = 0.591, time/batch = 0.028, All_Time = 278.575
9650/758000 (epoch 25), train_loss = 0.544, time/batch = 0.030, All_Time = 280.055
9700/758000 (epoch 25), train_loss = 0.546, time/batch = 0.029, All_Time = 281.533
9750/758000 (epoch 25), train_loss = 0.546, time/batch = 0.030, All_Time = 283.005
9800/758000 (epoch 25), train_loss = 0.566, time/batch = 0.029, All_Time = 284.458
9850/758000 (epoch 25), train_loss = 0.536, time/batch = 0.029, All_Time = 285.923
9900/758000 (epoch 26), train_loss = 0.508, time/batch = 0.031, All_Time = 287.386
9950/758000 (epoch 26), train_loss = 0.548, time/batch = 0.029, All_Time = 288.843
10000/758000 (epoch 26), train_loss = 0.416, time/batch = 0.028, All_Time = 290.301
model saved to NER/polyglot/model.ckpt
10050/758000 (epoch 26), train_loss = 0.532, time/batch = 0.029, All_Time = 291.768
10100/758000 (epoch 26), train_loss = 0.482, time/batch = 0.028, All_Time = 293.217
10150/758000 (epoch 26), train_loss = 0.603, time/batch = 0.029, All_Time = 294.676
10200/758000 (epoch 26), train_loss = 0.564, time/batch = 0.028, All_Time = 296.124
10250/758000 (epoch 27), train_loss = 0.533, time/batch = 0.029, All_Time = 297.574
10300/758000 (epoch 27), train_loss = 0.480, time/batch = 0.029, All_Time = 299.048
10350/758000 (epoch 27), train_loss = 0.515, time/batch = 0.030, All_Time = 300.498
10400/758000 (epoch 27), train_loss = 0.497, time/batch = 0.029, All_Time = 301.942
10450/758000 (epoch 27), train_loss = 0.455, time/batch = 0.028, All_Time = 303.387
10500/758000 (epoch 27), train_loss = 0.535, time/batch = 0.028, All_Time = 304.836
10550/758000 (epoch 27), train_loss = 0.468, time/batch = 0.031, All_Time = 306.288
10600/758000 (epoch 27), train_loss = 0.532, time/batch = 0.030, All_Time = 307.746
10650/758000 (epoch 28), train_loss = 0.526, time/batch = 0.030, All_Time = 309.199
10700/758000 (epoch 28), train_loss = 0.511, time/batch = 0.029, All_Time = 310.805
10750/758000 (epoch 28), train_loss = 0.465, time/batch = 0.030, All_Time = 312.306
10800/758000 (epoch 28), train_loss = 0.496, time/batch = 0.029, All_Time = 313.814
10850/758000 (epoch 28), train_loss = 0.480, time/batch = 0.029, All_Time = 315.303
10900/758000 (epoch 28), train_loss = 0.493, time/batch = 0.028, All_Time = 316.776
10950/758000 (epoch 28), train_loss = 0.536, time/batch = 0.028, All_Time = 318.234
11000/758000 (epoch 29), train_loss = 0.559, time/batch = 0.028, All_Time = 319.703
model saved to NER/polyglot/model.ckpt
11050/758000 (epoch 29), train_loss = 0.515, time/batch = 0.029, All_Time = 321.156
11100/758000 (epoch 29), train_loss = 0.535, time/batch = 0.029, All_Time = 322.617
11150/758000 (epoch 29), train_loss = 0.457, time/batch = 0.030, All_Time = 324.080
11200/758000 (epoch 29), train_loss = 0.526, time/batch = 0.029, All_Time = 325.535
11250/758000 (epoch 29), train_loss = 0.536, time/batch = 0.031, All_Time = 326.998
11300/758000 (epoch 29), train_loss = 0.443, time/batch = 0.030, All_Time = 328.483
11350/758000 (epoch 29), train_loss = 0.532, time/batch = 0.030, All_Time = 329.953
11400/758000 (epoch 30), train_loss = 0.472, time/batch = 0.029, All_Time = 331.415
11450/758000 (epoch 30), train_loss = 0.449, time/batch = 0.029, All_Time = 332.865
11500/758000 (epoch 30), train_loss = 0.532, time/batch = 0.029, All_Time = 334.312
11550/758000 (epoch 30), train_loss = 0.474, time/batch = 0.030, All_Time = 335.765
11600/758000 (epoch 30), train_loss = 0.495, time/batch = 0.030, All_Time = 337.218
11650/758000 (epoch 30), train_loss = 0.468, time/batch = 0.029, All_Time = 338.678
11700/758000 (epoch 30), train_loss = 0.444, time/batch = 0.031, All_Time = 340.131
11750/758000 (epoch 31), train_loss = 0.463, time/batch = 0.030, All_Time = 341.596
11800/758000 (epoch 31), train_loss = 0.489, time/batch = 0.029, All_Time = 343.047
11850/758000 (epoch 31), train_loss = 0.485, time/batch = 0.029, All_Time = 344.503
11900/758000 (epoch 31), train_loss = 0.448, time/batch = 0.030, All_Time = 345.961
11950/758000 (epoch 31), train_loss = 0.428, time/batch = 0.029, All_Time = 347.415
12000/758000 (epoch 31), train_loss = 0.417, time/batch = 0.031, All_Time = 348.880
model saved to NER/polyglot/model.ckpt
12050/758000 (epoch 31), train_loss = 0.481, time/batch = 0.029, All_Time = 350.347
12100/758000 (epoch 31), train_loss = 0.511, time/batch = 0.029, All_Time = 351.806
12150/758000 (epoch 32), train_loss = 0.431, time/batch = 0.028, All_Time = 353.265
12200/758000 (epoch 32), train_loss = 0.443, time/batch = 0.029, All_Time = 354.718
12250/758000 (epoch 32), train_loss = 0.495, time/batch = 0.029, All_Time = 356.164
12300/758000 (epoch 32), train_loss = 0.485, time/batch = 0.029, All_Time = 357.614
12350/758000 (epoch 32), train_loss = 0.424, time/batch = 0.031, All_Time = 359.072
12400/758000 (epoch 32), train_loss = 0.389, time/batch = 0.030, All_Time = 360.569
12450/758000 (epoch 32), train_loss = 0.441, time/batch = 0.029, All_Time = 362.038
12500/758000 (epoch 32), train_loss = 0.536, time/batch = 0.031, All_Time = 363.503
12550/758000 (epoch 33), train_loss = 0.502, time/batch = 0.029, All_Time = 364.965
12600/758000 (epoch 33), train_loss = 0.479, time/batch = 0.031, All_Time = 366.433
12650/758000 (epoch 33), train_loss = 0.502, time/batch = 0.027, All_Time = 367.890
12700/758000 (epoch 33), train_loss = 0.507, time/batch = 0.029, All_Time = 369.346
12750/758000 (epoch 33), train_loss = 0.396, time/batch = 0.031, All_Time = 370.805
12800/758000 (epoch 33), train_loss = 0.447, time/batch = 0.029, All_Time = 372.263
12850/758000 (epoch 33), train_loss = 0.431, time/batch = 0.030, All_Time = 373.724
12900/758000 (epoch 34), train_loss = 0.443, time/batch = 0.030, All_Time = 375.183
12950/758000 (epoch 34), train_loss = 0.438, time/batch = 0.030, All_Time = 376.646
13000/758000 (epoch 34), train_loss = 0.407, time/batch = 0.028, All_Time = 378.098
model saved to NER/polyglot/model.ckpt
13050/758000 (epoch 34), train_loss = 0.405, time/batch = 0.029, All_Time = 379.545
13100/758000 (epoch 34), train_loss = 0.400, time/batch = 0.028, All_Time = 380.993
13150/758000 (epoch 34), train_loss = 0.374, time/batch = 0.028, All_Time = 382.434
13200/758000 (epoch 34), train_loss = 0.425, time/batch = 0.029, All_Time = 383.877
13250/758000 (epoch 34), train_loss = 0.394, time/batch = 0.029, All_Time = 385.365
13300/758000 (epoch 35), train_loss = 0.490, time/batch = 0.030, All_Time = 386.834
13350/758000 (epoch 35), train_loss = 0.455, time/batch = 0.029, All_Time = 388.293
13400/758000 (epoch 35), train_loss = 0.454, time/batch = 0.029, All_Time = 389.759
13450/758000 (epoch 35), train_loss = 0.433, time/batch = 0.029, All_Time = 391.221
13500/758000 (epoch 35), train_loss = 0.407, time/batch = 0.029, All_Time = 392.678
13550/758000 (epoch 35), train_loss = 0.447, time/batch = 0.029, All_Time = 394.145
13600/758000 (epoch 35), train_loss = 0.457, time/batch = 0.029, All_Time = 395.605
13650/758000 (epoch 36), train_loss = 0.429, time/batch = 0.029, All_Time = 397.064
13700/758000 (epoch 36), train_loss = 0.383, time/batch = 0.029, All_Time = 398.522
13750/758000 (epoch 36), train_loss = 0.392, time/batch = 0.031, All_Time = 399.982
13800/758000 (epoch 36), train_loss = 0.379, time/batch = 0.029, All_Time = 401.449
13850/758000 (epoch 36), train_loss = 0.419, time/batch = 0.030, All_Time = 402.913
13900/758000 (epoch 36), train_loss = 0.382, time/batch = 0.028, All_Time = 404.366
13950/758000 (epoch 36), train_loss = 0.403, time/batch = 0.029, All_Time = 405.827
14000/758000 (epoch 36), train_loss = 0.445, time/batch = 0.028, All_Time = 407.283
model saved to NER/polyglot/model.ckpt
14050/758000 (epoch 37), train_loss = 0.405, time/batch = 0.029, All_Time = 408.735
14100/758000 (epoch 37), train_loss = 0.418, time/batch = 0.029, All_Time = 410.181
14150/758000 (epoch 37), train_loss = 0.482, time/batch = 0.029, All_Time = 411.627
14200/758000 (epoch 37), train_loss = 0.428, time/batch = 0.030, All_Time = 413.081
14250/758000 (epoch 37), train_loss = 0.378, time/batch = 0.031, All_Time = 414.540
14300/758000 (epoch 37), train_loss = 0.439, time/batch = 0.030, All_Time = 416.018
14350/758000 (epoch 37), train_loss = 0.380, time/batch = 0.029, All_Time = 417.474
14400/758000 (epoch 37), train_loss = 0.424, time/batch = 0.028, All_Time = 418.924
14450/758000 (epoch 38), train_loss = 0.455, time/batch = 0.029, All_Time = 420.388
14500/758000 (epoch 38), train_loss = 0.460, time/batch = 0.030, All_Time = 421.840
14550/758000 (epoch 38), train_loss = 0.436, time/batch = 0.030, All_Time = 423.296
14600/758000 (epoch 38), train_loss = 0.414, time/batch = 0.029, All_Time = 424.756
14650/758000 (epoch 38), train_loss = 0.384, time/batch = 0.031, All_Time = 426.224
14700/758000 (epoch 38), train_loss = 0.386, time/batch = 0.029, All_Time = 427.681
14750/758000 (epoch 38), train_loss = 0.415, time/batch = 0.029, All_Time = 429.130
14800/758000 (epoch 39), train_loss = 0.378, time/batch = 0.030, All_Time = 430.581
14850/758000 (epoch 39), train_loss = 0.367, time/batch = 0.028, All_Time = 432.028
14900/758000 (epoch 39), train_loss = 0.389, time/batch = 0.029, All_Time = 433.480
14950/758000 (epoch 39), train_loss = 0.444, time/batch = 0.030, All_Time = 434.926
15000/758000 (epoch 39), train_loss = 0.386, time/batch = 0.028, All_Time = 436.377
model saved to NER/polyglot/model.ckpt
15050/758000 (epoch 39), train_loss = 0.414, time/batch = 0.029, All_Time = 437.827
15100/758000 (epoch 39), train_loss = 0.343, time/batch = 0.028, All_Time = 439.270
15150/758000 (epoch 39), train_loss = 0.416, time/batch = 0.028, All_Time = 440.714
15200/758000 (epoch 40), train_loss = 0.391, time/batch = 0.030, All_Time = 442.187
15250/758000 (epoch 40), train_loss = 0.386, time/batch = 0.030, All_Time = 443.670
15300/758000 (epoch 40), train_loss = 0.391, time/batch = 0.030, All_Time = 445.144
15350/758000 (epoch 40), train_loss = 0.391, time/batch = 0.029, All_Time = 446.621
15400/758000 (epoch 40), train_loss = 0.390, time/batch = 0.030, All_Time = 448.073
15450/758000 (epoch 40), train_loss = 0.371, time/batch = 0.030, All_Time = 449.527
15500/758000 (epoch 40), train_loss = 0.372, time/batch = 0.029, All_Time = 451.003
15550/758000 (epoch 41), train_loss = 0.381, time/batch = 0.029, All_Time = 452.470
15600/758000 (epoch 41), train_loss = 0.386, time/batch = 0.028, All_Time = 453.916
15650/758000 (epoch 41), train_loss = 0.401, time/batch = 0.030, All_Time = 455.367
15700/758000 (epoch 41), train_loss = 0.367, time/batch = 0.028, All_Time = 456.819
15750/758000 (epoch 41), train_loss = 0.399, time/batch = 0.030, All_Time = 458.274
15800/758000 (epoch 41), train_loss = 0.356, time/batch = 0.029, All_Time = 459.725
15850/758000 (epoch 41), train_loss = 0.342, time/batch = 0.030, All_Time = 461.213
15900/758000 (epoch 41), train_loss = 0.408, time/batch = 0.029, All_Time = 462.684
15950/758000 (epoch 42), train_loss = 0.420, time/batch = 0.031, All_Time = 464.163
16000/758000 (epoch 42), train_loss = 0.373, time/batch = 0.029, All_Time = 465.636
model saved to NER/polyglot/model.ckpt
16050/758000 (epoch 42), train_loss = 0.395, time/batch = 0.029, All_Time = 467.092
16100/758000 (epoch 42), train_loss = 0.374, time/batch = 0.030, All_Time = 468.542
16150/758000 (epoch 42), train_loss = 0.370, time/batch = 0.028, All_Time = 469.995
16200/758000 (epoch 42), train_loss = 0.365, time/batch = 0.028, All_Time = 471.451
16250/758000 (epoch 42), train_loss = 0.359, time/batch = 0.032, All_Time = 472.908
16300/758000 (epoch 43), train_loss = 0.423, time/batch = 0.030, All_Time = 474.381
16350/758000 (epoch 43), train_loss = 0.388, time/batch = 0.028, All_Time = 475.842
16400/758000 (epoch 43), train_loss = 0.392, time/batch = 0.029, All_Time = 477.293
16450/758000 (epoch 43), train_loss = 0.398, time/batch = 0.029, All_Time = 478.755
16500/758000 (epoch 43), train_loss = 0.338, time/batch = 0.029, All_Time = 480.211
16550/758000 (epoch 43), train_loss = 0.320, time/batch = 0.029, All_Time = 481.673
16600/758000 (epoch 43), train_loss = 0.376, time/batch = 0.030, All_Time = 483.135
16650/758000 (epoch 43), train_loss = 0.344, time/batch = 0.028, All_Time = 484.587
16700/758000 (epoch 44), train_loss = 0.380, time/batch = 0.029, All_Time = 486.050
16750/758000 (epoch 44), train_loss = 0.358, time/batch = 0.029, All_Time = 487.505
16800/758000 (epoch 44), train_loss = 0.428, time/batch = 0.029, All_Time = 488.972
16850/758000 (epoch 44), train_loss = 0.411, time/batch = 0.029, All_Time = 490.431
16900/758000 (epoch 44), train_loss = 0.302, time/batch = 0.028, All_Time = 491.907
16950/758000 (epoch 44), train_loss = 0.335, time/batch = 0.029, All_Time = 493.379
17000/758000 (epoch 44), train_loss = 0.372, time/batch = 0.028, All_Time = 494.841
model saved to NER/polyglot/model.ckpt
17050/758000 (epoch 44), train_loss = 0.391, time/batch = 0.029, All_Time = 496.307
17100/758000 (epoch 45), train_loss = 0.334, time/batch = 0.028, All_Time = 497.765
17150/758000 (epoch 45), train_loss = 0.384, time/batch = 0.028, All_Time = 499.216
17200/758000 (epoch 45), train_loss = 0.349, time/batch = 0.029, All_Time = 500.664
17250/758000 (epoch 45), train_loss = 0.372, time/batch = 0.028, All_Time = 502.115
17300/758000 (epoch 45), train_loss = 0.337, time/batch = 0.028, All_Time = 503.567
17350/758000 (epoch 45), train_loss = 0.379, time/batch = 0.028, All_Time = 505.022
17400/758000 (epoch 45), train_loss = 0.336, time/batch = 0.028, All_Time = 506.475
17450/758000 (epoch 46), train_loss = 0.337, time/batch = 0.029, All_Time = 507.940
17500/758000 (epoch 46), train_loss = 0.353, time/batch = 0.030, All_Time = 509.393
17550/758000 (epoch 46), train_loss = 0.373, time/batch = 0.029, All_Time = 510.876
17600/758000 (epoch 46), train_loss = 0.337, time/batch = 0.030, All_Time = 512.335
17650/758000 (epoch 46), train_loss = 0.347, time/batch = 0.029, All_Time = 513.795
17700/758000 (epoch 46), train_loss = 0.367, time/batch = 0.030, All_Time = 515.262
17750/758000 (epoch 46), train_loss = 0.314, time/batch = 0.029, All_Time = 516.729
17800/758000 (epoch 46), train_loss = 0.396, time/batch = 0.030, All_Time = 518.192
17850/758000 (epoch 47), train_loss = 0.372, time/batch = 0.029, All_Time = 519.652
17900/758000 (epoch 47), train_loss = 0.347, time/batch = 0.030, All_Time = 521.115
17950/758000 (epoch 47), train_loss = 0.350, time/batch = 0.030, All_Time = 522.570
18000/758000 (epoch 47), train_loss = 0.337, time/batch = 0.029, All_Time = 524.041
model saved to NER/polyglot/model.ckpt
18050/758000 (epoch 47), train_loss = 0.351, time/batch = 0.027, All_Time = 525.495
18100/758000 (epoch 47), train_loss = 0.376, time/batch = 0.029, All_Time = 526.953
18150/758000 (epoch 47), train_loss = 0.344, time/batch = 0.030, All_Time = 528.417
18200/758000 (epoch 48), train_loss = 0.364, time/batch = 0.029, All_Time = 529.873
18250/758000 (epoch 48), train_loss = 0.371, time/batch = 0.029, All_Time = 531.332
18300/758000 (epoch 48), train_loss = 0.367, time/batch = 0.030, All_Time = 532.837
18350/758000 (epoch 48), train_loss = 0.335, time/batch = 0.029, All_Time = 534.318
18400/758000 (epoch 48), train_loss = 0.292, time/batch = 0.031, All_Time = 535.795
18450/758000 (epoch 48), train_loss = 0.337, time/batch = 0.029, All_Time = 537.266
18500/758000 (epoch 48), train_loss = 0.341, time/batch = 0.029, All_Time = 538.744
18550/758000 (epoch 48), train_loss = 0.351, time/batch = 0.030, All_Time = 540.205
18600/758000 (epoch 49), train_loss = 0.329, time/batch = 0.030, All_Time = 541.674
18650/758000 (epoch 49), train_loss = 0.339, time/batch = 0.028, All_Time = 543.128
18700/758000 (epoch 49), train_loss = 0.370, time/batch = 0.028, All_Time = 544.586
18750/758000 (epoch 49), train_loss = 0.325, time/batch = 0.029, All_Time = 546.050
18800/758000 (epoch 49), train_loss = 0.359, time/batch = 0.030, All_Time = 547.514
18850/758000 (epoch 49), train_loss = 0.313, time/batch = 0.029, All_Time = 548.978
18900/758000 (epoch 49), train_loss = 0.351, time/batch = 0.030, All_Time = 550.443
18950/758000 (epoch 50), train_loss = 0.152, time/batch = 0.031, All_Time = 551.910
19000/758000 (epoch 50), train_loss = 0.333, time/batch = 0.028, All_Time = 553.367
model saved to NER/polyglot/model.ckpt
19050/758000 (epoch 50), train_loss = 0.310, time/batch = 0.028, All_Time = 554.831
19100/758000 (epoch 50), train_loss = 0.334, time/batch = 0.030, All_Time = 556.284
19150/758000 (epoch 50), train_loss = 0.348, time/batch = 0.030, All_Time = 557.734
19200/758000 (epoch 50), train_loss = 0.338, time/batch = 0.029, All_Time = 559.185
19250/758000 (epoch 50), train_loss = 0.332, time/batch = 0.028, All_Time = 560.637
19300/758000 (epoch 50), train_loss = 0.303, time/batch = 0.030, All_Time = 562.092
19350/758000 (epoch 51), train_loss = 0.327, time/batch = 0.030, All_Time = 563.545
19400/758000 (epoch 51), train_loss = 0.327, time/batch = 0.028, All_Time = 564.989
19450/758000 (epoch 51), train_loss = 0.316, time/batch = 0.028, All_Time = 566.449
19500/758000 (epoch 51), train_loss = 0.339, time/batch = 0.028, All_Time = 567.902
19550/758000 (epoch 51), train_loss = 0.281, time/batch = 0.028, All_Time = 569.353
19600/758000 (epoch 51), train_loss = 0.315, time/batch = 0.028, All_Time = 570.806
19650/758000 (epoch 51), train_loss = 0.368, time/batch = 0.028, All_Time = 572.267
19700/758000 (epoch 51), train_loss = 0.360, time/batch = 0.030, All_Time = 573.725
19750/758000 (epoch 52), train_loss = 0.319, time/batch = 0.028, All_Time = 575.168
19800/758000 (epoch 52), train_loss = 0.296, time/batch = 0.031, All_Time = 576.636
19850/758000 (epoch 52), train_loss = 0.310, time/batch = 0.028, All_Time = 578.119
19900/758000 (epoch 52), train_loss = 0.351, time/batch = 0.029, All_Time = 579.579
19950/758000 (epoch 52), train_loss = 0.320, time/batch = 0.028, All_Time = 581.052
20000/758000 (epoch 52), train_loss = 0.333, time/batch = 0.029, All_Time = 582.521
model saved to NER/polyglot/model.ckpt
20050/758000 (epoch 52), train_loss = 0.286, time/batch = 0.029, All_Time = 583.977
20100/758000 (epoch 53), train_loss = 0.325, time/batch = 0.028, All_Time = 585.443
20150/758000 (epoch 53), train_loss = 0.382, time/batch = 0.029, All_Time = 586.893
20200/758000 (epoch 53), train_loss = 0.308, time/batch = 0.028, All_Time = 588.352
20250/758000 (epoch 53), train_loss = 0.381, time/batch = 0.029, All_Time = 589.811
20300/758000 (epoch 53), train_loss = 0.287, time/batch = 0.028, All_Time = 591.271
20350/758000 (epoch 53), train_loss = 0.298, time/batch = 0.029, All_Time = 592.723
20400/758000 (epoch 53), train_loss = 0.323, time/batch = 0.029, All_Time = 594.186
20450/758000 (epoch 53), train_loss = 0.314, time/batch = 0.028, All_Time = 595.655
20500/758000 (epoch 54), train_loss = 0.332, time/batch = 0.029, All_Time = 597.115
20550/758000 (epoch 54), train_loss = 0.282, time/batch = 0.029, All_Time = 598.583
20600/758000 (epoch 54), train_loss = 0.336, time/batch = 0.029, All_Time = 600.035
20650/758000 (epoch 54), train_loss = 0.342, time/batch = 0.030, All_Time = 601.489
20700/758000 (epoch 54), train_loss = 0.316, time/batch = 0.029, All_Time = 602.938
20750/758000 (epoch 54), train_loss = 0.291, time/batch = 0.029, All_Time = 604.397
20800/758000 (epoch 54), train_loss = 0.323, time/batch = 0.029, All_Time = 605.859
20850/758000 (epoch 55), train_loss = 0.298, time/batch = 0.028, All_Time = 607.310
20900/758000 (epoch 55), train_loss = 0.298, time/batch = 0.029, All_Time = 608.771
20950/758000 (epoch 55), train_loss = 0.348, time/batch = 0.029, All_Time = 610.256
21000/758000 (epoch 55), train_loss = 0.272, time/batch = 0.029, All_Time = 611.729
model saved to NER/polyglot/model.ckpt
21050/758000 (epoch 55), train_loss = 0.299, time/batch = 0.031, All_Time = 613.198
21100/758000 (epoch 55), train_loss = 0.319, time/batch = 0.030, All_Time = 614.658
21150/758000 (epoch 55), train_loss = 0.323, time/batch = 0.029, All_Time = 616.114
21200/758000 (epoch 55), train_loss = 0.315, time/batch = 0.030, All_Time = 617.568
21250/758000 (epoch 56), train_loss = 0.331, time/batch = 0.030, All_Time = 619.024
21300/758000 (epoch 56), train_loss = 0.314, time/batch = 0.029, All_Time = 620.473
21350/758000 (epoch 56), train_loss = 0.291, time/batch = 0.032, All_Time = 621.939
21400/758000 (epoch 56), train_loss = 0.328, time/batch = 0.029, All_Time = 623.422
21450/758000 (epoch 56), train_loss = 0.293, time/batch = 0.031, All_Time = 624.883
21500/758000 (epoch 56), train_loss = 0.285, time/batch = 0.028, All_Time = 626.350
21550/758000 (epoch 56), train_loss = 0.343, time/batch = 0.027, All_Time = 627.825
21600/758000 (epoch 56), train_loss = 0.305, time/batch = 0.030, All_Time = 629.283
21650/758000 (epoch 57), train_loss = 0.359, time/batch = 0.029, All_Time = 630.753
21700/758000 (epoch 57), train_loss = 0.312, time/batch = 0.029, All_Time = 632.208
21750/758000 (epoch 57), train_loss = 0.295, time/batch = 0.028, All_Time = 633.663
21800/758000 (epoch 57), train_loss = 0.305, time/batch = 0.028, All_Time = 635.121
21850/758000 (epoch 57), train_loss = 0.276, time/batch = 0.028, All_Time = 636.577
21900/758000 (epoch 57), train_loss = 0.277, time/batch = 0.029, All_Time = 638.037
21950/758000 (epoch 57), train_loss = 0.287, time/batch = 0.030, All_Time = 639.495
22000/758000 (epoch 58), train_loss = 0.330, time/batch = 0.028, All_Time = 640.968
model saved to NER/polyglot/model.ckpt
22050/758000 (epoch 58), train_loss = 0.275, time/batch = 0.030, All_Time = 642.425
22100/758000 (epoch 58), train_loss = 0.307, time/batch = 0.030, All_Time = 643.876
22150/758000 (epoch 58), train_loss = 0.289, time/batch = 0.028, All_Time = 645.334
22200/758000 (epoch 58), train_loss = 0.297, time/batch = 0.029, All_Time = 646.780
22250/758000 (epoch 58), train_loss = 0.280, time/batch = 0.028, All_Time = 648.263
22300/758000 (epoch 58), train_loss = 0.282, time/batch = 0.030, All_Time = 649.740
22350/758000 (epoch 58), train_loss = 0.289, time/batch = 0.029, All_Time = 651.208
22400/758000 (epoch 59), train_loss = 0.267, time/batch = 0.030, All_Time = 652.678
22450/758000 (epoch 59), train_loss = 0.316, time/batch = 0.029, All_Time = 654.143
22500/758000 (epoch 59), train_loss = 0.261, time/batch = 0.031, All_Time = 655.598
22550/758000 (epoch 59), train_loss = 0.329, time/batch = 0.031, All_Time = 657.041
22600/758000 (epoch 59), train_loss = 0.308, time/batch = 0.029, All_Time = 658.498
22650/758000 (epoch 59), train_loss = 0.300, time/batch = 0.030, All_Time = 659.957
22700/758000 (epoch 59), train_loss = 0.301, time/batch = 0.028, All_Time = 661.423
22750/758000 (epoch 60), train_loss = 0.338, time/batch = 0.029, All_Time = 662.888
22800/758000 (epoch 60), train_loss = 0.337, time/batch = 0.028, All_Time = 664.352
22850/758000 (epoch 60), train_loss = 0.300, time/batch = 0.028, All_Time = 665.813
22900/758000 (epoch 60), train_loss = 0.273, time/batch = 0.030, All_Time = 667.265
22950/758000 (epoch 60), train_loss = 0.251, time/batch = 0.028, All_Time = 668.721
23000/758000 (epoch 60), train_loss = 0.321, time/batch = 0.030, All_Time = 670.182
model saved to NER/polyglot/model.ckpt
23050/758000 (epoch 60), train_loss = 0.289, time/batch = 0.027, All_Time = 671.630
23100/758000 (epoch 60), train_loss = 0.298, time/batch = 0.028, All_Time = 673.077
23150/758000 (epoch 61), train_loss = 0.268, time/batch = 0.030, All_Time = 674.570
23200/758000 (epoch 61), train_loss = 0.291, time/batch = 0.029, All_Time = 676.044
23250/758000 (epoch 61), train_loss = 0.271, time/batch = 0.029, All_Time = 677.515
23300/758000 (epoch 61), train_loss = 0.306, time/batch = 0.029, All_Time = 678.978
23350/758000 (epoch 61), train_loss = 0.285, time/batch = 0.030, All_Time = 680.454
23400/758000 (epoch 61), train_loss = 0.300, time/batch = 0.028, All_Time = 681.917
23450/758000 (epoch 61), train_loss = 0.269, time/batch = 0.030, All_Time = 683.384
23500/758000 (epoch 62), train_loss = 0.266, time/batch = 0.030, All_Time = 684.844
23550/758000 (epoch 62), train_loss = 0.308, time/batch = 0.029, All_Time = 686.299
23600/758000 (epoch 62), train_loss = 0.315, time/batch = 0.029, All_Time = 687.749
23650/758000 (epoch 62), train_loss = 0.281, time/batch = 0.028, All_Time = 689.226
23700/758000 (epoch 62), train_loss = 0.309, time/batch = 0.027, All_Time = 690.680
23750/758000 (epoch 62), train_loss = 0.304, time/batch = 0.028, All_Time = 692.137
23800/758000 (epoch 62), train_loss = 0.277, time/batch = 0.029, All_Time = 693.598
23850/758000 (epoch 62), train_loss = 0.277, time/batch = 0.028, All_Time = 695.056
23900/758000 (epoch 63), train_loss = 0.289, time/batch = 0.028, All_Time = 696.520
23950/758000 (epoch 63), train_loss = 0.287, time/batch = 0.029, All_Time = 697.984
24000/758000 (epoch 63), train_loss = 0.328, time/batch = 0.029, All_Time = 699.447
model saved to NER/polyglot/model.ckpt
24050/758000 (epoch 63), train_loss = 0.300, time/batch = 0.030, All_Time = 700.904
24100/758000 (epoch 63), train_loss = 0.273, time/batch = 0.029, All_Time = 702.357
24150/758000 (epoch 63), train_loss = 0.298, time/batch = 0.030, All_Time = 703.825
24200/758000 (epoch 63), train_loss = 0.273, time/batch = 0.030, All_Time = 705.287
24250/758000 (epoch 63), train_loss = 0.294, time/batch = 0.029, All_Time = 706.754
24300/758000 (epoch 64), train_loss = 0.259, time/batch = 0.028, All_Time = 708.230
24350/758000 (epoch 64), train_loss = 0.288, time/batch = 0.028, All_Time = 709.692
24400/758000 (epoch 64), train_loss = 0.260, time/batch = 0.028, All_Time = 711.154
24450/758000 (epoch 64), train_loss = 0.273, time/batch = 0.031, All_Time = 712.628
24500/758000 (epoch 64), train_loss = 0.304, time/batch = 0.029, All_Time = 714.111
24550/758000 (epoch 64), train_loss = 0.290, time/batch = 0.028, All_Time = 715.597
24600/758000 (epoch 64), train_loss = 0.270, time/batch = 0.029, All_Time = 717.060
24650/758000 (epoch 65), train_loss = 0.276, time/batch = 0.030, All_Time = 718.533
24700/758000 (epoch 65), train_loss = 0.276, time/batch = 0.028, All_Time = 719.992
24750/758000 (epoch 65), train_loss = 0.281, time/batch = 0.028, All_Time = 721.456
24800/758000 (epoch 65), train_loss = 0.279, time/batch = 0.029, All_Time = 722.904
24850/758000 (epoch 65), train_loss = 0.281, time/batch = 0.030, All_Time = 724.369
24900/758000 (epoch 65), train_loss = 0.277, time/batch = 0.029, All_Time = 725.836
24950/758000 (epoch 65), train_loss = 0.296, time/batch = 0.029, All_Time = 727.296
25000/758000 (epoch 65), train_loss = 0.308, time/batch = 0.029, All_Time = 728.757
model saved to NER/polyglot/model.ckpt
25050/758000 (epoch 66), train_loss = 0.321, time/batch = 0.029, All_Time = 730.227
25100/758000 (epoch 66), train_loss = 0.258, time/batch = 0.028, All_Time = 731.686
25150/758000 (epoch 66), train_loss = 0.285, time/batch = 0.030, All_Time = 733.140
25200/758000 (epoch 66), train_loss = 0.259, time/batch = 0.029, All_Time = 734.635
25250/758000 (epoch 66), train_loss = 0.301, time/batch = 0.030, All_Time = 736.112
25300/758000 (epoch 66), train_loss = 0.299, time/batch = 0.029, All_Time = 737.587
25350/758000 (epoch 66), train_loss = 0.298, time/batch = 0.029, All_Time = 739.054
25400/758000 (epoch 67), train_loss = 0.267, time/batch = 0.031, All_Time = 740.520
25450/758000 (epoch 67), train_loss = 0.281, time/batch = 0.029, All_Time = 741.986
25500/758000 (epoch 67), train_loss = 0.309, time/batch = 0.028, All_Time = 743.443
25550/758000 (epoch 67), train_loss = 0.261, time/batch = 0.029, All_Time = 744.917
25600/758000 (epoch 67), train_loss = 0.267, time/batch = 0.029, All_Time = 746.382
25650/758000 (epoch 67), train_loss = 0.255, time/batch = 0.028, All_Time = 747.839
25700/758000 (epoch 67), train_loss = 0.282, time/batch = 0.029, All_Time = 749.302
25750/758000 (epoch 67), train_loss = 0.272, time/batch = 0.029, All_Time = 750.756
25800/758000 (epoch 68), train_loss = 0.288, time/batch = 0.028, All_Time = 752.218
25850/758000 (epoch 68), train_loss = 0.251, time/batch = 0.029, All_Time = 753.674
25900/758000 (epoch 68), train_loss = 0.271, time/batch = 0.030, All_Time = 755.161
25950/758000 (epoch 68), train_loss = 0.281, time/batch = 0.028, All_Time = 756.625
26000/758000 (epoch 68), train_loss = 0.251, time/batch = 0.030, All_Time = 758.108
model saved to NER/polyglot/model.ckpt
26050/758000 (epoch 68), train_loss = 0.269, time/batch = 0.029, All_Time = 759.563
26100/758000 (epoch 68), train_loss = 0.296, time/batch = 0.029, All_Time = 761.027
26150/758000 (epoch 68), train_loss = 0.293, time/batch = 0.029, All_Time = 762.486
26200/758000 (epoch 69), train_loss = 0.295, time/batch = 0.029, All_Time = 763.957
26250/758000 (epoch 69), train_loss = 0.331, time/batch = 0.028, All_Time = 765.416
26300/758000 (epoch 69), train_loss = 0.256, time/batch = 0.029, All_Time = 766.883
26350/758000 (epoch 69), train_loss = 0.266, time/batch = 0.029, All_Time = 768.356
26400/758000 (epoch 69), train_loss = 0.306, time/batch = 0.030, All_Time = 769.825
26450/758000 (epoch 69), train_loss = 0.277, time/batch = 0.030, All_Time = 771.294
26500/758000 (epoch 69), train_loss = 0.267, time/batch = 0.029, All_Time = 772.757
26550/758000 (epoch 70), train_loss = 0.249, time/batch = 0.029, All_Time = 774.232
26600/758000 (epoch 70), train_loss = 0.282, time/batch = 0.030, All_Time = 775.697
26650/758000 (epoch 70), train_loss = 0.268, time/batch = 0.030, All_Time = 777.154
26700/758000 (epoch 70), train_loss = 0.264, time/batch = 0.029, All_Time = 778.610
26750/758000 (epoch 70), train_loss = 0.237, time/batch = 0.029, All_Time = 780.085
26800/758000 (epoch 70), train_loss = 0.272, time/batch = 0.030, All_Time = 781.557
26850/758000 (epoch 70), train_loss = 0.284, time/batch = 0.030, All_Time = 783.036
26900/758000 (epoch 70), train_loss = 0.263, time/batch = 0.029, All_Time = 784.507
26950/758000 (epoch 71), train_loss = 0.272, time/batch = 0.028, All_Time = 785.969
27000/758000 (epoch 71), train_loss = 0.315, time/batch = 0.030, All_Time = 787.441
model saved to NER/polyglot/model.ckpt
27050/758000 (epoch 71), train_loss = 0.272, time/batch = 0.029, All_Time = 788.890
27100/758000 (epoch 71), train_loss = 0.295, time/batch = 0.030, All_Time = 790.340
27150/758000 (epoch 71), train_loss = 0.244, time/batch = 0.031, All_Time = 791.818
27200/758000 (epoch 71), train_loss = 0.261, time/batch = 0.029, All_Time = 793.287
27250/758000 (epoch 71), train_loss = 0.296, time/batch = 0.030, All_Time = 794.760
27300/758000 (epoch 72), train_loss = 0.270, time/batch = 0.030, All_Time = 796.230
27350/758000 (epoch 72), train_loss = 0.235, time/batch = 0.028, All_Time = 797.680
27400/758000 (epoch 72), train_loss = 0.262, time/batch = 0.029, All_Time = 799.129
27450/758000 (epoch 72), train_loss = 0.257, time/batch = 0.028, All_Time = 800.586
27500/758000 (epoch 72), train_loss = 0.271, time/batch = 0.030, All_Time = 802.046
27550/758000 (epoch 72), train_loss = 0.285, time/batch = 0.030, All_Time = 803.501
27600/758000 (epoch 72), train_loss = 0.281, time/batch = 0.029, All_Time = 804.963
27650/758000 (epoch 72), train_loss = 0.296, time/batch = 0.029, All_Time = 806.424
27700/758000 (epoch 73), train_loss = 0.267, time/batch = 0.028, All_Time = 807.877
27750/758000 (epoch 73), train_loss = 0.255, time/batch = 0.030, All_Time = 809.338
27800/758000 (epoch 73), train_loss = 0.306, time/batch = 0.030, All_Time = 810.821
27850/758000 (epoch 73), train_loss = 0.254, time/batch = 0.029, All_Time = 812.296
27900/758000 (epoch 73), train_loss = 0.222, time/batch = 0.029, All_Time = 813.762
27950/758000 (epoch 73), train_loss = 0.263, time/batch = 0.029, All_Time = 815.238
28000/758000 (epoch 73), train_loss = 0.269, time/batch = 0.029, All_Time = 816.712
model saved to NER/polyglot/model.ckpt
28050/758000 (epoch 74), train_loss = 0.232, time/batch = 0.029, All_Time = 818.172
28100/758000 (epoch 74), train_loss = 0.282, time/batch = 0.030, All_Time = 819.626
28150/758000 (epoch 74), train_loss = 0.269, time/batch = 0.029, All_Time = 821.063
28200/758000 (epoch 74), train_loss = 0.259, time/batch = 0.028, All_Time = 822.519
28250/758000 (epoch 74), train_loss = 0.265, time/batch = 0.029, All_Time = 823.977
28300/758000 (epoch 74), train_loss = 0.239, time/batch = 0.029, All_Time = 825.430
28350/758000 (epoch 74), train_loss = 0.259, time/batch = 0.029, All_Time = 826.911
28400/758000 (epoch 74), train_loss = 0.257, time/batch = 0.030, All_Time = 828.376
28450/758000 (epoch 75), train_loss = 0.273, time/batch = 0.031, All_Time = 829.853
28500/758000 (epoch 75), train_loss = 0.280, time/batch = 0.028, All_Time = 831.328
28550/758000 (epoch 75), train_loss = 0.293, time/batch = 0.028, All_Time = 832.790
28600/758000 (epoch 75), train_loss = 0.252, time/batch = 0.028, All_Time = 834.251
28650/758000 (epoch 75), train_loss = 0.249, time/batch = 0.029, All_Time = 835.716
28700/758000 (epoch 75), train_loss = 0.272, time/batch = 0.029, All_Time = 837.195
28750/758000 (epoch 75), train_loss = 0.276, time/batch = 0.030, All_Time = 838.670
28800/758000 (epoch 75), train_loss = 0.273, time/batch = 0.030, All_Time = 840.138
28850/758000 (epoch 76), train_loss = 0.251, time/batch = 0.029, All_Time = 841.605
28900/758000 (epoch 76), train_loss = 0.247, time/batch = 0.030, All_Time = 843.092
28950/758000 (epoch 76), train_loss = 0.226, time/batch = 0.030, All_Time = 844.570
29000/758000 (epoch 76), train_loss = 0.276, time/batch = 0.030, All_Time = 846.042
model saved to NER/polyglot/model.ckpt
29050/758000 (epoch 76), train_loss = 0.230, time/batch = 0.030, All_Time = 847.509
29100/758000 (epoch 76), train_loss = 0.288, time/batch = 0.029, All_Time = 848.956
29150/758000 (epoch 76), train_loss = 0.248, time/batch = 0.030, All_Time = 850.413
29200/758000 (epoch 77), train_loss = 0.249, time/batch = 0.030, All_Time = 851.877
29250/758000 (epoch 77), train_loss = 0.246, time/batch = 0.030, All_Time = 853.329
29300/758000 (epoch 77), train_loss = 0.242, time/batch = 0.031, All_Time = 854.790
29350/758000 (epoch 77), train_loss = 0.282, time/batch = 0.030, All_Time = 856.250
29400/758000 (epoch 77), train_loss = 0.220, time/batch = 0.030, All_Time = 857.695
29450/758000 (epoch 77), train_loss = 0.295, time/batch = 0.030, All_Time = 859.146
29500/758000 (epoch 77), train_loss = 0.228, time/batch = 0.029, All_Time = 860.626
29550/758000 (epoch 77), train_loss = 0.266, time/batch = 0.029, All_Time = 862.108
29600/758000 (epoch 78), train_loss = 0.259, time/batch = 0.031, All_Time = 863.579
29650/758000 (epoch 78), train_loss = 0.252, time/batch = 0.030, All_Time = 865.029
29700/758000 (epoch 78), train_loss = 0.226, time/batch = 0.030, All_Time = 866.489
29750/758000 (epoch 78), train_loss = 0.233, time/batch = 0.030, All_Time = 867.945
29800/758000 (epoch 78), train_loss = 0.278, time/batch = 0.028, All_Time = 869.391
29850/758000 (epoch 78), train_loss = 0.228, time/batch = 0.029, All_Time = 870.864
29900/758000 (epoch 78), train_loss = 0.257, time/batch = 0.030, All_Time = 872.334
29950/758000 (epoch 79), train_loss = 0.293, time/batch = 0.031, All_Time = 873.810
30000/758000 (epoch 79), train_loss = 0.289, time/batch = 0.030, All_Time = 875.276
model saved to NER/polyglot/model.ckpt
30050/758000 (epoch 79), train_loss = 0.268, time/batch = 0.031, All_Time = 876.746
30100/758000 (epoch 79), train_loss = 0.244, time/batch = 0.029, All_Time = 878.208
30150/758000 (epoch 79), train_loss = 0.268, time/batch = 0.030, All_Time = 879.672
30200/758000 (epoch 79), train_loss = 0.253, time/batch = 0.029, All_Time = 881.127
30250/758000 (epoch 79), train_loss = 0.233, time/batch = 0.029, All_Time = 882.588
30300/758000 (epoch 79), train_loss = 0.290, time/batch = 0.029, All_Time = 884.054
30350/758000 (epoch 80), train_loss = 0.240, time/batch = 0.030, All_Time = 885.510
30400/758000 (epoch 80), train_loss = 0.235, time/batch = 0.027, All_Time = 886.968
30450/758000 (epoch 80), train_loss = 0.282, time/batch = 0.031, All_Time = 888.429
30500/758000 (epoch 80), train_loss = 0.257, time/batch = 0.030, All_Time = 889.920
30550/758000 (epoch 80), train_loss = 0.261, time/batch = 0.030, All_Time = 891.411
30600/758000 (epoch 80), train_loss = 0.252, time/batch = 0.028, All_Time = 892.878
30650/758000 (epoch 80), train_loss = 0.237, time/batch = 0.032, All_Time = 894.357
30700/758000 (epoch 81), train_loss = 0.228, time/batch = 0.029, All_Time = 895.825
30750/758000 (epoch 81), train_loss = 0.281, time/batch = 0.030, All_Time = 897.297
30800/758000 (epoch 81), train_loss = 0.243, time/batch = 0.029, All_Time = 898.752
30850/758000 (epoch 81), train_loss = 0.241, time/batch = 0.029, All_Time = 900.221
30900/758000 (epoch 81), train_loss = 0.239, time/batch = 0.030, All_Time = 901.682
30950/758000 (epoch 81), train_loss = 0.246, time/batch = 0.030, All_Time = 903.150
31000/758000 (epoch 81), train_loss = 0.268, time/batch = 0.031, All_Time = 904.618
model saved to NER/polyglot/model.ckpt
31050/758000 (epoch 81), train_loss = 0.273, time/batch = 0.029, All_Time = 906.086
31100/758000 (epoch 82), train_loss = 0.237, time/batch = 0.030, All_Time = 907.547
31150/758000 (epoch 82), train_loss = 0.277, time/batch = 0.029, All_Time = 908.994
31200/758000 (epoch 82), train_loss = 0.237, time/batch = 0.029, All_Time = 910.455
31250/758000 (epoch 82), train_loss = 0.285, time/batch = 0.029, All_Time = 911.897
31300/758000 (epoch 82), train_loss = 0.260, time/batch = 0.029, All_Time = 913.400
31350/758000 (epoch 82), train_loss = 0.213, time/batch = 0.029, All_Time = 914.870
31400/758000 (epoch 82), train_loss = 0.236, time/batch = 0.030, All_Time = 916.343
31450/758000 (epoch 82), train_loss = 0.283, time/batch = 0.030, All_Time = 917.809
31500/758000 (epoch 83), train_loss = 0.282, time/batch = 0.029, All_Time = 919.278
31550/758000 (epoch 83), train_loss = 0.234, time/batch = 0.028, All_Time = 920.747
31600/758000 (epoch 83), train_loss = 0.259, time/batch = 0.029, All_Time = 922.209
31650/758000 (epoch 83), train_loss = 0.294, time/batch = 0.029, All_Time = 923.666
31700/758000 (epoch 83), train_loss = 0.207, time/batch = 0.029, All_Time = 925.142
31750/758000 (epoch 83), train_loss = 0.228, time/batch = 0.028, All_Time = 926.589
31800/758000 (epoch 83), train_loss = 0.260, time/batch = 0.030, All_Time = 928.049
31850/758000 (epoch 84), train_loss = 0.246, time/batch = 0.029, All_Time = 929.512
31900/758000 (epoch 84), train_loss = 0.264, time/batch = 0.030, All_Time = 930.975
31950/758000 (epoch 84), train_loss = 0.236, time/batch = 0.029, All_Time = 932.436
32000/758000 (epoch 84), train_loss = 0.222, time/batch = 0.030, All_Time = 933.889
model saved to NER/polyglot/model.ckpt
32050/758000 (epoch 84), train_loss = 0.235, time/batch = 0.029, All_Time = 935.333
32100/758000 (epoch 84), train_loss = 0.219, time/batch = 0.030, All_Time = 936.794
32150/758000 (epoch 84), train_loss = 0.231, time/batch = 0.029, All_Time = 938.253
32200/758000 (epoch 84), train_loss = 0.227, time/batch = 0.030, All_Time = 939.713
32250/758000 (epoch 85), train_loss = 0.290, time/batch = 0.029, All_Time = 941.175
32300/758000 (epoch 85), train_loss = 0.236, time/batch = 0.030, All_Time = 942.638
32350/758000 (epoch 85), train_loss = 0.270, time/batch = 0.030, All_Time = 944.093
32400/758000 (epoch 85), train_loss = 0.273, time/batch = 0.030, All_Time = 945.607
32450/758000 (epoch 85), train_loss = 0.240, time/batch = 0.031, All_Time = 947.083
32500/758000 (epoch 85), train_loss = 0.255, time/batch = 0.030, All_Time = 948.566
32550/758000 (epoch 85), train_loss = 0.260, time/batch = 0.030, All_Time = 950.025
32600/758000 (epoch 86), train_loss = 0.246, time/batch = 0.029, All_Time = 951.492
32650/758000 (epoch 86), train_loss = 0.239, time/batch = 0.028, All_Time = 952.967
32700/758000 (epoch 86), train_loss = 0.235, time/batch = 0.029, All_Time = 954.420
32750/758000 (epoch 86), train_loss = 0.244, time/batch = 0.029, All_Time = 955.882
32800/758000 (epoch 86), train_loss = 0.249, time/batch = 0.030, All_Time = 957.348
32850/758000 (epoch 86), train_loss = 0.238, time/batch = 0.030, All_Time = 958.806
32900/758000 (epoch 86), train_loss = 0.215, time/batch = 0.029, All_Time = 960.272
32950/758000 (epoch 86), train_loss = 0.292, time/batch = 0.029, All_Time = 961.734
33000/758000 (epoch 87), train_loss = 0.250, time/batch = 0.030, All_Time = 963.207
model saved to NER/polyglot/model.ckpt
33050/758000 (epoch 87), train_loss = 0.251, time/batch = 0.030, All_Time = 964.671
33100/758000 (epoch 87), train_loss = 0.309, time/batch = 0.029, All_Time = 966.128
33150/758000 (epoch 87), train_loss = 0.265, time/batch = 0.029, All_Time = 967.599
33200/758000 (epoch 87), train_loss = 0.226, time/batch = 0.031, All_Time = 969.068
33250/758000 (epoch 87), train_loss = 0.244, time/batch = 0.030, All_Time = 970.532
33300/758000 (epoch 87), train_loss = 0.230, time/batch = 0.029, All_Time = 972.000
33350/758000 (epoch 87), train_loss = 0.259, time/batch = 0.027, All_Time = 973.454
33400/758000 (epoch 88), train_loss = 0.281, time/batch = 0.029, All_Time = 974.914
33450/758000 (epoch 88), train_loss = 0.263, time/batch = 0.029, All_Time = 976.407
33500/758000 (epoch 88), train_loss = 0.250, time/batch = 0.029, All_Time = 977.886
33550/758000 (epoch 88), train_loss = 0.269, time/batch = 0.030, All_Time = 979.350
33600/758000 (epoch 88), train_loss = 0.262, time/batch = 0.027, All_Time = 980.803
33650/758000 (epoch 88), train_loss = 0.245, time/batch = 0.031, All_Time = 982.275
33700/758000 (epoch 88), train_loss = 0.225, time/batch = 0.028, All_Time = 983.735
33750/758000 (epoch 89), train_loss = 0.218, time/batch = 0.029, All_Time = 985.204
33800/758000 (epoch 89), train_loss = 0.233, time/batch = 0.028, All_Time = 986.664
33850/758000 (epoch 89), train_loss = 0.232, time/batch = 0.028, All_Time = 988.128
33900/758000 (epoch 89), train_loss = 0.278, time/batch = 0.028, All_Time = 989.587
33950/758000 (epoch 89), train_loss = 0.255, time/batch = 0.030, All_Time = 991.069
34000/758000 (epoch 89), train_loss = 0.256, time/batch = 0.029, All_Time = 992.536
model saved to NER/polyglot/model.ckpt
34050/758000 (epoch 89), train_loss = 0.203, time/batch = 0.032, All_Time = 994.002
34100/758000 (epoch 89), train_loss = 0.245, time/batch = 0.028, All_Time = 995.454
34150/758000 (epoch 90), train_loss = 0.245, time/batch = 0.030, All_Time = 996.915
34200/758000 (epoch 90), train_loss = 0.246, time/batch = 0.030, All_Time = 998.363
34250/758000 (epoch 90), train_loss = 0.245, time/batch = 0.029, All_Time = 999.812
34300/758000 (epoch 90), train_loss = 0.235, time/batch = 0.029, All_Time = 1001.290
34350/758000 (epoch 90), train_loss = 0.275, time/batch = 0.028, All_Time = 1002.765
34400/758000 (epoch 90), train_loss = 0.240, time/batch = 0.029, All_Time = 1004.227
34450/758000 (epoch 90), train_loss = 0.235, time/batch = 0.029, All_Time = 1005.697
34500/758000 (epoch 91), train_loss = 0.226, time/batch = 0.029, All_Time = 1007.164
34550/758000 (epoch 91), train_loss = 0.227, time/batch = 0.028, All_Time = 1008.619
34600/758000 (epoch 91), train_loss = 0.240, time/batch = 0.028, All_Time = 1010.093
34650/758000 (epoch 91), train_loss = 0.215, time/batch = 0.030, All_Time = 1011.555
34700/758000 (epoch 91), train_loss = 0.256, time/batch = 0.030, All_Time = 1013.016
34750/758000 (epoch 91), train_loss = 0.251, time/batch = 0.029, All_Time = 1014.487
34800/758000 (epoch 91), train_loss = 0.229, time/batch = 0.028, All_Time = 1015.981
34850/758000 (epoch 91), train_loss = 0.244, time/batch = 0.028, All_Time = 1017.444
34900/758000 (epoch 92), train_loss = 0.276, time/batch = 0.030, All_Time = 1018.909
34950/758000 (epoch 92), train_loss = 0.255, time/batch = 0.029, All_Time = 1020.363
35000/758000 (epoch 92), train_loss = 0.246, time/batch = 0.030, All_Time = 1021.827
model saved to NER/polyglot/model.ckpt
35050/758000 (epoch 92), train_loss = 0.242, time/batch = 0.030, All_Time = 1023.288
35100/758000 (epoch 92), train_loss = 0.243, time/batch = 0.028, All_Time = 1024.735
35150/758000 (epoch 92), train_loss = 0.244, time/batch = 0.030, All_Time = 1026.210
35200/758000 (epoch 92), train_loss = 0.229, time/batch = 0.030, All_Time = 1027.693
35250/758000 (epoch 93), train_loss = 0.268, time/batch = 0.029, All_Time = 1029.169
35300/758000 (epoch 93), train_loss = 0.275, time/batch = 0.031, All_Time = 1030.652
35350/758000 (epoch 93), train_loss = 0.247, time/batch = 0.029, All_Time = 1032.107
35400/758000 (epoch 93), train_loss = 0.259, time/batch = 0.030, All_Time = 1033.557
35450/758000 (epoch 93), train_loss = 0.254, time/batch = 0.029, All_Time = 1035.021
35500/758000 (epoch 93), train_loss = 0.245, time/batch = 0.029, All_Time = 1036.486
35550/758000 (epoch 93), train_loss = 0.221, time/batch = 0.028, All_Time = 1037.953
35600/758000 (epoch 93), train_loss = 0.212, time/batch = 0.028, All_Time = 1039.417
35650/758000 (epoch 94), train_loss = 0.255, time/batch = 0.029, All_Time = 1040.867
35700/758000 (epoch 94), train_loss = 0.259, time/batch = 0.028, All_Time = 1042.328
35750/758000 (epoch 94), train_loss = 0.313, time/batch = 0.029, All_Time = 1043.791
35800/758000 (epoch 94), train_loss = 0.291, time/batch = 0.029, All_Time = 1045.259
35850/758000 (epoch 94), train_loss = 0.211, time/batch = 0.029, All_Time = 1046.721
35900/758000 (epoch 94), train_loss = 0.230, time/batch = 0.028, All_Time = 1048.175
35950/758000 (epoch 94), train_loss = 0.258, time/batch = 0.030, All_Time = 1049.645
36000/758000 (epoch 94), train_loss = 0.276, time/batch = 0.028, All_Time = 1051.102
model saved to NER/polyglot/model.ckpt
36050/758000 (epoch 95), train_loss = 0.214, time/batch = 0.029, All_Time = 1052.567
36100/758000 (epoch 95), train_loss = 0.237, time/batch = 0.028, All_Time = 1054.019
36150/758000 (epoch 95), train_loss = 0.223, time/batch = 0.030, All_Time = 1055.515
36200/758000 (epoch 95), train_loss = 0.248, time/batch = 0.031, All_Time = 1056.995
36250/758000 (epoch 95), train_loss = 0.216, time/batch = 0.029, All_Time = 1058.464
36300/758000 (epoch 95), train_loss = 0.251, time/batch = 0.031, All_Time = 1059.925
36350/758000 (epoch 95), train_loss = 0.203, time/batch = 0.030, All_Time = 1061.400
36400/758000 (epoch 96), train_loss = 0.221, time/batch = 0.028, All_Time = 1062.864
36450/758000 (epoch 96), train_loss = 0.255, time/batch = 0.038, All_Time = 1064.375
36500/758000 (epoch 96), train_loss = 0.236, time/batch = 0.031, All_Time = 1065.960
36550/758000 (epoch 96), train_loss = 0.224, time/batch = 0.029, All_Time = 1067.471
36600/758000 (epoch 96), train_loss = 0.232, time/batch = 0.029, All_Time = 1068.958
36650/758000 (epoch 96), train_loss = 0.295, time/batch = 0.030, All_Time = 1070.443
36700/758000 (epoch 96), train_loss = 0.212, time/batch = 0.029, All_Time = 1071.908
36750/758000 (epoch 96), train_loss = 0.253, time/batch = 0.030, All_Time = 1073.361
36800/758000 (epoch 97), train_loss = 0.257, time/batch = 0.029, All_Time = 1074.812
36850/758000 (epoch 97), train_loss = 0.241, time/batch = 0.029, All_Time = 1076.285
36900/758000 (epoch 97), train_loss = 0.236, time/batch = 0.030, All_Time = 1077.750
36950/758000 (epoch 97), train_loss = 0.245, time/batch = 0.029, All_Time = 1079.218
37000/758000 (epoch 97), train_loss = 0.252, time/batch = 0.030, All_Time = 1080.692
model saved to NER/polyglot/model.ckpt
37050/758000 (epoch 97), train_loss = 0.241, time/batch = 0.031, All_Time = 1082.171
37100/758000 (epoch 97), train_loss = 0.243, time/batch = 0.030, All_Time = 1083.636
37150/758000 (epoch 98), train_loss = 0.242, time/batch = 0.029, All_Time = 1085.113
37200/758000 (epoch 98), train_loss = 0.272, time/batch = 0.029, All_Time = 1086.575
37250/758000 (epoch 98), train_loss = 0.260, time/batch = 0.029, All_Time = 1088.033
37300/758000 (epoch 98), train_loss = 0.259, time/batch = 0.030, All_Time = 1089.486
37350/758000 (epoch 98), train_loss = 0.218, time/batch = 0.029, All_Time = 1090.982
37400/758000 (epoch 98), train_loss = 0.253, time/batch = 0.029, All_Time = 1092.448
37450/758000 (epoch 98), train_loss = 0.233, time/batch = 0.029, All_Time = 1093.916
37500/758000 (epoch 98), train_loss = 0.252, time/batch = 0.029, All_Time = 1095.385
37550/758000 (epoch 99), train_loss = 0.231, time/batch = 0.030, All_Time = 1096.851
37600/758000 (epoch 99), train_loss = 0.266, time/batch = 0.031, All_Time = 1098.328
37650/758000 (epoch 99), train_loss = 0.254, time/batch = 0.028, All_Time = 1099.802
37700/758000 (epoch 99), train_loss = 0.235, time/batch = 0.030, All_Time = 1101.271
37750/758000 (epoch 99), train_loss = 0.277, time/batch = 0.028, All_Time = 1102.753
37800/758000 (epoch 99), train_loss = 0.233, time/batch = 0.030, All_Time = 1104.228
37850/758000 (epoch 99), train_loss = 0.241, time/batch = 0.030, All_Time = 1105.700
37900/758000 (epoch 100), train_loss = 0.074, time/batch = 0.033, All_Time = 1107.183
37950/758000 (epoch 100), train_loss = 0.243, time/batch = 0.030, All_Time = 1108.660
38000/758000 (epoch 100), train_loss = 0.226, time/batch = 0.030, All_Time = 1110.121
model saved to NER/polyglot/model.ckpt
38050/758000 (epoch 100), train_loss = 0.226, time/batch = 0.028, All_Time = 1111.582
38100/758000 (epoch 100), train_loss = 0.238, time/batch = 0.029, All_Time = 1113.030
38150/758000 (epoch 100), train_loss = 0.276, time/batch = 0.029, All_Time = 1114.499
38200/758000 (epoch 100), train_loss = 0.237, time/batch = 0.029, All_Time = 1115.955
38250/758000 (epoch 100), train_loss = 0.202, time/batch = 0.031, All_Time = 1117.420
38300/758000 (epoch 101), train_loss = 0.235, time/batch = 0.029, All_Time = 1118.878
38350/758000 (epoch 101), train_loss = 0.227, time/batch = 0.028, All_Time = 1120.333
38400/758000 (epoch 101), train_loss = 0.233, time/batch = 0.029, All_Time = 1121.830
38450/758000 (epoch 101), train_loss = 0.270, time/batch = 0.030, All_Time = 1123.317
38500/758000 (epoch 101), train_loss = 0.219, time/batch = 0.029, All_Time = 1124.786
38550/758000 (epoch 101), train_loss = 0.267, time/batch = 0.029, All_Time = 1126.263
38600/758000 (epoch 101), train_loss = 0.264, time/batch = 0.029, All_Time = 1127.736
38650/758000 (epoch 101), train_loss = 0.273, time/batch = 0.030, All_Time = 1129.217
38700/758000 (epoch 102), train_loss = 0.234, time/batch = 0.028, All_Time = 1130.680
38750/758000 (epoch 102), train_loss = 0.244, time/batch = 0.028, All_Time = 1132.143
38800/758000 (epoch 102), train_loss = 0.205, time/batch = 0.030, All_Time = 1133.611
38850/758000 (epoch 102), train_loss = 0.281, time/batch = 0.030, All_Time = 1135.087
38900/758000 (epoch 102), train_loss = 0.269, time/batch = 0.030, All_Time = 1136.555
38950/758000 (epoch 102), train_loss = 0.231, time/batch = 0.029, All_Time = 1138.014
39000/758000 (epoch 102), train_loss = 0.208, time/batch = 0.030, All_Time = 1139.476
model saved to NER/polyglot/model.ckpt
39050/758000 (epoch 103), train_loss = 0.232, time/batch = 0.028, All_Time = 1140.938
39100/758000 (epoch 103), train_loss = 0.330, time/batch = 0.029, All_Time = 1142.399
39150/758000 (epoch 103), train_loss = 0.241, time/batch = 0.031, All_Time = 1143.864
39200/758000 (epoch 103), train_loss = 0.297, time/batch = 0.030, All_Time = 1145.327
39250/758000 (epoch 103), train_loss = 0.221, time/batch = 0.029, All_Time = 1146.834
39300/758000 (epoch 103), train_loss = 0.229, time/batch = 0.030, All_Time = 1148.316
39350/758000 (epoch 103), train_loss = 0.234, time/batch = 0.031, All_Time = 1149.793
39400/758000 (epoch 103), train_loss = 0.248, time/batch = 0.029, All_Time = 1151.262
39450/758000 (epoch 104), train_loss = 0.295, time/batch = 0.030, All_Time = 1152.790
39500/758000 (epoch 104), train_loss = 0.241, time/batch = 0.029, All_Time = 1154.309
39550/758000 (epoch 104), train_loss = 0.240, time/batch = 0.030, All_Time = 1155.811
39600/758000 (epoch 104), train_loss = 0.261, time/batch = 0.029, All_Time = 1157.315
39650/758000 (epoch 104), train_loss = 0.245, time/batch = 0.029, All_Time = 1158.782
39700/758000 (epoch 104), train_loss = 0.246, time/batch = 0.030, All_Time = 1160.242
39750/758000 (epoch 104), train_loss = 0.242, time/batch = 0.030, All_Time = 1161.713
39800/758000 (epoch 105), train_loss = 0.240, time/batch = 0.029, All_Time = 1163.179
39850/758000 (epoch 105), train_loss = 0.246, time/batch = 0.028, All_Time = 1164.646
39900/758000 (epoch 105), train_loss = 0.280, time/batch = 0.030, All_Time = 1166.111
39950/758000 (epoch 105), train_loss = 0.209, time/batch = 0.029, All_Time = 1167.585
40000/758000 (epoch 105), train_loss = 0.233, time/batch = 0.031, All_Time = 1169.043
model saved to NER/polyglot/model.ckpt
40050/758000 (epoch 105), train_loss = 0.254, time/batch = 0.029, All_Time = 1170.493
40100/758000 (epoch 105), train_loss = 0.247, time/batch = 0.029, All_Time = 1171.945
40150/758000 (epoch 105), train_loss = 0.243, time/batch = 0.028, All_Time = 1173.395
40200/758000 (epoch 106), train_loss = 0.246, time/batch = 0.029, All_Time = 1174.854
40250/758000 (epoch 106), train_loss = 0.294, time/batch = 0.029, All_Time = 1176.311
40300/758000 (epoch 106), train_loss = 0.251, time/batch = 0.030, All_Time = 1177.768
40350/758000 (epoch 106), train_loss = 0.267, time/batch = 0.030, All_Time = 1179.244
40400/758000 (epoch 106), train_loss = 0.246, time/batch = 0.029, All_Time = 1180.736
40450/758000 (epoch 106), train_loss = 0.239, time/batch = 0.029, All_Time = 1182.203
40500/758000 (epoch 106), train_loss = 0.285, time/batch = 0.029, All_Time = 1183.690
40550/758000 (epoch 106), train_loss = 0.244, time/batch = 0.029, All_Time = 1185.152
40600/758000 (epoch 107), train_loss = 0.321, time/batch = 0.029, All_Time = 1186.615
40650/758000 (epoch 107), train_loss = 0.277, time/batch = 0.029, All_Time = 1188.087
40700/758000 (epoch 107), train_loss = 0.250, time/batch = 0.030, All_Time = 1189.555
40750/758000 (epoch 107), train_loss = 0.251, time/batch = 0.029, All_Time = 1191.015
40800/758000 (epoch 107), train_loss = 0.224, time/batch = 0.028, All_Time = 1192.478
40850/758000 (epoch 107), train_loss = 0.236, time/batch = 0.029, All_Time = 1193.950
40900/758000 (epoch 107), train_loss = 0.202, time/batch = 0.029, All_Time = 1195.410
40950/758000 (epoch 108), train_loss = 0.255, time/batch = 0.028, All_Time = 1196.878
41000/758000 (epoch 108), train_loss = 0.245, time/batch = 0.030, All_Time = 1198.332
model saved to NER/polyglot/model.ckpt
41050/758000 (epoch 108), train_loss = 0.260, time/batch = 0.028, All_Time = 1199.793
41100/758000 (epoch 108), train_loss = 0.218, time/batch = 0.031, All_Time = 1201.260
41150/758000 (epoch 108), train_loss = 0.250, time/batch = 0.031, All_Time = 1202.760
41200/758000 (epoch 108), train_loss = 0.248, time/batch = 0.028, All_Time = 1204.227
41250/758000 (epoch 108), train_loss = 0.255, time/batch = 0.029, All_Time = 1205.702
41300/758000 (epoch 108), train_loss = 0.235, time/batch = 0.029, All_Time = 1207.173
41350/758000 (epoch 109), train_loss = 0.243, time/batch = 0.030, All_Time = 1208.643
41400/758000 (epoch 109), train_loss = 0.271, time/batch = 0.028, All_Time = 1210.125
41450/758000 (epoch 109), train_loss = 0.246, time/batch = 0.029, All_Time = 1211.595
41500/758000 (epoch 109), train_loss = 0.282, time/batch = 0.030, All_Time = 1213.061
41550/758000 (epoch 109), train_loss = 0.258, time/batch = 0.028, All_Time = 1214.530
41600/758000 (epoch 109), train_loss = 0.260, time/batch = 0.029, All_Time = 1215.995
41650/758000 (epoch 109), train_loss = 0.252, time/batch = 0.029, All_Time = 1217.461
41700/758000 (epoch 110), train_loss = 0.281, time/batch = 0.031, All_Time = 1218.936
41750/758000 (epoch 110), train_loss = 0.331, time/batch = 0.029, All_Time = 1220.408
41800/758000 (epoch 110), train_loss = 0.251, time/batch = 0.031, All_Time = 1221.877
41850/758000 (epoch 110), train_loss = 0.217, time/batch = 0.030, All_Time = 1223.345
41900/758000 (epoch 110), train_loss = 0.214, time/batch = 0.030, All_Time = 1224.807
41950/758000 (epoch 110), train_loss = 0.266, time/batch = 0.033, All_Time = 1226.280
42000/758000 (epoch 110), train_loss = 0.245, time/batch = 0.028, All_Time = 1227.740
model saved to NER/polyglot/model.ckpt
42050/758000 (epoch 110), train_loss = 0.223, time/batch = 0.030, All_Time = 1229.205
42100/758000 (epoch 111), train_loss = 0.219, time/batch = 0.031, All_Time = 1230.672
42150/758000 (epoch 111), train_loss = 0.305, time/batch = 0.030, All_Time = 1232.130
42200/758000 (epoch 111), train_loss = 0.258, time/batch = 0.030, All_Time = 1233.591
42250/758000 (epoch 111), train_loss = 0.244, time/batch = 0.030, All_Time = 1235.051
42300/758000 (epoch 111), train_loss = 0.230, time/batch = 0.030, All_Time = 1236.512
42350/758000 (epoch 111), train_loss = 0.270, time/batch = 0.030, All_Time = 1237.972
42400/758000 (epoch 111), train_loss = 0.257, time/batch = 0.028, All_Time = 1239.443
42450/758000 (epoch 112), train_loss = 0.208, time/batch = 0.029, All_Time = 1240.916
42500/758000 (epoch 112), train_loss = 0.272, time/batch = 0.028, All_Time = 1242.379
42550/758000 (epoch 112), train_loss = 0.286, time/batch = 0.031, All_Time = 1243.849
42600/758000 (epoch 112), train_loss = 0.268, time/batch = 0.029, All_Time = 1245.323
42650/758000 (epoch 112), train_loss = 0.233, time/batch = 0.029, All_Time = 1246.807
42700/758000 (epoch 112), train_loss = 0.260, time/batch = 0.029, All_Time = 1248.279
42750/758000 (epoch 112), train_loss = 0.236, time/batch = 0.031, All_Time = 1249.740
42800/758000 (epoch 112), train_loss = 0.253, time/batch = 0.029, All_Time = 1251.213
42850/758000 (epoch 113), train_loss = 0.240, time/batch = 0.029, All_Time = 1252.685
42900/758000 (epoch 113), train_loss = 0.267, time/batch = 0.029, All_Time = 1254.142
42950/758000 (epoch 113), train_loss = 0.258, time/batch = 0.031, All_Time = 1255.595
43000/758000 (epoch 113), train_loss = 0.241, time/batch = 0.031, All_Time = 1257.084
model saved to NER/polyglot/model.ckpt
43050/758000 (epoch 113), train_loss = 0.249, time/batch = 0.029, All_Time = 1258.550
43100/758000 (epoch 113), train_loss = 0.270, time/batch = 0.028, All_Time = 1260.020
43150/758000 (epoch 113), train_loss = 0.242, time/batch = 0.030, All_Time = 1261.491
43200/758000 (epoch 113), train_loss = 0.245, time/batch = 0.030, All_Time = 1262.948
43250/758000 (epoch 114), train_loss = 0.221, time/batch = 0.030, All_Time = 1264.426
43300/758000 (epoch 114), train_loss = 0.275, time/batch = 0.029, All_Time = 1265.885
43350/758000 (epoch 114), train_loss = 0.261, time/batch = 0.030, All_Time = 1267.349
43400/758000 (epoch 114), train_loss = 0.254, time/batch = 0.029, All_Time = 1268.806
43450/758000 (epoch 114), train_loss = 0.272, time/batch = 0.029, All_Time = 1270.273
43500/758000 (epoch 114), train_loss = 0.263, time/batch = 0.033, All_Time = 1271.756
43550/758000 (epoch 114), train_loss = 0.229, time/batch = 0.030, All_Time = 1273.254
43600/758000 (epoch 115), train_loss = 0.238, time/batch = 0.031, All_Time = 1274.726
43650/758000 (epoch 115), train_loss = 0.259, time/batch = 0.030, All_Time = 1276.199
43700/758000 (epoch 115), train_loss = 0.254, time/batch = 0.029, All_Time = 1277.667
43750/758000 (epoch 115), train_loss = 0.231, time/batch = 0.029, All_Time = 1279.132
43800/758000 (epoch 115), train_loss = 0.244, time/batch = 0.029, All_Time = 1280.599
43850/758000 (epoch 115), train_loss = 0.252, time/batch = 0.030, All_Time = 1282.071
43900/758000 (epoch 115), train_loss = 0.282, time/batch = 0.030, All_Time = 1283.538
43950/758000 (epoch 115), train_loss = 0.252, time/batch = 0.030, All_Time = 1285.019
44000/758000 (epoch 116), train_loss = 0.273, time/batch = 0.029, All_Time = 1286.487
model saved to NER/polyglot/model.ckpt
44050/758000 (epoch 116), train_loss = 0.269, time/batch = 0.029, All_Time = 1287.948
44100/758000 (epoch 116), train_loss = 0.269, time/batch = 0.029, All_Time = 1289.397
44150/758000 (epoch 116), train_loss = 0.208, time/batch = 0.029, All_Time = 1290.856
44200/758000 (epoch 116), train_loss = 0.279, time/batch = 0.030, All_Time = 1292.315
44250/758000 (epoch 116), train_loss = 0.279, time/batch = 0.030, All_Time = 1293.775
44300/758000 (epoch 116), train_loss = 0.269, time/batch = 0.028, All_Time = 1295.235
44350/758000 (epoch 117), train_loss = 0.245, time/batch = 0.030, All_Time = 1296.708
44400/758000 (epoch 117), train_loss = 0.270, time/batch = 0.031, All_Time = 1298.180
44450/758000 (epoch 117), train_loss = 0.303, time/batch = 0.029, All_Time = 1299.680
44500/758000 (epoch 117), train_loss = 0.260, time/batch = 0.031, All_Time = 1301.167
44550/758000 (epoch 117), train_loss = 0.232, time/batch = 0.030, All_Time = 1302.643
44600/758000 (epoch 117), train_loss = 0.218, time/batch = 0.031, All_Time = 1304.114
44650/758000 (epoch 117), train_loss = 0.265, time/batch = 0.029, All_Time = 1305.577
44700/758000 (epoch 117), train_loss = 0.227, time/batch = 0.028, All_Time = 1307.045
44750/758000 (epoch 118), train_loss = 0.258, time/batch = 0.030, All_Time = 1308.518
44800/758000 (epoch 118), train_loss = 0.283, time/batch = 0.028, All_Time = 1309.973
44850/758000 (epoch 118), train_loss = 0.278, time/batch = 0.029, All_Time = 1311.426
44900/758000 (epoch 118), train_loss = 0.252, time/batch = 0.031, All_Time = 1312.894
44950/758000 (epoch 118), train_loss = 0.222, time/batch = 0.029, All_Time = 1314.404
45000/758000 (epoch 118), train_loss = 0.241, time/batch = 0.028, All_Time = 1315.868
model saved to NER/polyglot/model.ckpt
45050/758000 (epoch 118), train_loss = 0.279, time/batch = 0.030, All_Time = 1317.333
45100/758000 (epoch 118), train_loss = 0.258, time/batch = 0.028, All_Time = 1318.787
45150/758000 (epoch 119), train_loss = 0.267, time/batch = 0.029, All_Time = 1320.246
45200/758000 (epoch 119), train_loss = 0.316, time/batch = 0.031, All_Time = 1321.706
45250/758000 (epoch 119), train_loss = 0.255, time/batch = 0.031, All_Time = 1323.164
45300/758000 (epoch 119), train_loss = 0.216, time/batch = 0.030, All_Time = 1324.619
45350/758000 (epoch 119), train_loss = 0.284, time/batch = 0.029, All_Time = 1326.077
45400/758000 (epoch 119), train_loss = 0.261, time/batch = 0.029, All_Time = 1327.547
45450/758000 (epoch 119), train_loss = 0.231, time/batch = 0.032, All_Time = 1329.022
45500/758000 (epoch 120), train_loss = 0.224, time/batch = 0.029, All_Time = 1330.484
45550/758000 (epoch 120), train_loss = 0.244, time/batch = 0.029, All_Time = 1331.942
45600/758000 (epoch 120), train_loss = 0.273, time/batch = 0.029, All_Time = 1333.416
45650/758000 (epoch 120), train_loss = 0.234, time/batch = 0.030, All_Time = 1334.877
45700/758000 (epoch 120), train_loss = 0.208, time/batch = 0.029, All_Time = 1336.350
45750/758000 (epoch 120), train_loss = 0.265, time/batch = 0.030, All_Time = 1337.825
45800/758000 (epoch 120), train_loss = 0.286, time/batch = 0.027, All_Time = 1339.294
45850/758000 (epoch 120), train_loss = 0.235, time/batch = 0.031, All_Time = 1340.763
45900/758000 (epoch 121), train_loss = 0.267, time/batch = 0.029, All_Time = 1342.224
45950/758000 (epoch 121), train_loss = 0.310, time/batch = 0.029, All_Time = 1343.679
46000/758000 (epoch 121), train_loss = 0.285, time/batch = 0.032, All_Time = 1345.136
model saved to NER/polyglot/model.ckpt
46050/758000 (epoch 121), train_loss = 0.279, time/batch = 0.029, All_Time = 1346.603
46100/758000 (epoch 121), train_loss = 0.216, time/batch = 0.029, All_Time = 1348.074
46150/758000 (epoch 121), train_loss = 0.259, time/batch = 0.032, All_Time = 1349.536
46200/758000 (epoch 121), train_loss = 0.291, time/batch = 0.030, All_Time = 1351.032
46250/758000 (epoch 122), train_loss = 0.252, time/batch = 0.029, All_Time = 1352.515
46300/758000 (epoch 122), train_loss = 0.237, time/batch = 0.028, All_Time = 1353.978
46350/758000 (epoch 122), train_loss = 0.288, time/batch = 0.029, All_Time = 1355.446
46400/758000 (epoch 122), train_loss = 0.263, time/batch = 0.029, All_Time = 1356.906
46450/758000 (epoch 122), train_loss = 0.228, time/batch = 0.028, All_Time = 1358.370
46500/758000 (epoch 122), train_loss = 0.243, time/batch = 0.031, All_Time = 1359.837
46550/758000 (epoch 122), train_loss = 0.285, time/batch = 0.030, All_Time = 1361.296
46600/758000 (epoch 122), train_loss = 0.257, time/batch = 0.029, All_Time = 1362.766
46650/758000 (epoch 123), train_loss = 0.256, time/batch = 0.029, All_Time = 1364.238
46700/758000 (epoch 123), train_loss = 0.242, time/batch = 0.030, All_Time = 1365.704
46750/758000 (epoch 123), train_loss = 0.292, time/batch = 0.031, All_Time = 1367.174
46800/758000 (epoch 123), train_loss = 0.239, time/batch = 0.029, All_Time = 1368.635
46850/758000 (epoch 123), train_loss = 0.209, time/batch = 0.031, All_Time = 1370.100
46900/758000 (epoch 123), train_loss = 0.268, time/batch = 0.029, All_Time = 1371.561
46950/758000 (epoch 123), train_loss = 0.273, time/batch = 0.030, All_Time = 1373.025
47000/758000 (epoch 124), train_loss = 0.232, time/batch = 0.030, All_Time = 1374.501
model saved to NER/polyglot/model.ckpt
47050/758000 (epoch 124), train_loss = 0.277, time/batch = 0.030, All_Time = 1375.983
47100/758000 (epoch 124), train_loss = 0.263, time/batch = 0.029, All_Time = 1377.457
47150/758000 (epoch 124), train_loss = 0.273, time/batch = 0.029, All_Time = 1378.925
47200/758000 (epoch 124), train_loss = 0.261, time/batch = 0.029, All_Time = 1380.391
47250/758000 (epoch 124), train_loss = 0.226, time/batch = 0.031, All_Time = 1381.857
47300/758000 (epoch 124), train_loss = 0.231, time/batch = 0.030, All_Time = 1383.325
47350/758000 (epoch 124), train_loss = 0.248, time/batch = 0.029, All_Time = 1384.793
47400/758000 (epoch 125), train_loss = 0.256, time/batch = 0.030, All_Time = 1386.272
47450/758000 (epoch 125), train_loss = 0.268, time/batch = 0.030, All_Time = 1387.742
47500/758000 (epoch 125), train_loss = 0.268, time/batch = 0.029, All_Time = 1389.208
47550/758000 (epoch 125), train_loss = 0.233, time/batch = 0.029, All_Time = 1390.676
47600/758000 (epoch 125), train_loss = 0.240, time/batch = 0.029, All_Time = 1392.148
47650/758000 (epoch 125), train_loss = 0.253, time/batch = 0.029, All_Time = 1393.618
47700/758000 (epoch 125), train_loss = 0.291, time/batch = 0.028, All_Time = 1395.078
47750/758000 (epoch 125), train_loss = 0.235, time/batch = 0.030, All_Time = 1396.545
47800/758000 (epoch 126), train_loss = 0.233, time/batch = 0.030, All_Time = 1398.004
47850/758000 (epoch 126), train_loss = 0.240, time/batch = 0.030, All_Time = 1399.470
47900/758000 (epoch 126), train_loss = 0.258, time/batch = 0.029, All_Time = 1400.952
47950/758000 (epoch 126), train_loss = 0.290, time/batch = 0.029, All_Time = 1402.422
48000/758000 (epoch 126), train_loss = 0.208, time/batch = 0.031, All_Time = 1403.888
model saved to NER/polyglot/model.ckpt
48050/758000 (epoch 126), train_loss = 0.271, time/batch = 0.030, All_Time = 1405.368
48100/758000 (epoch 126), train_loss = 0.231, time/batch = 0.030, All_Time = 1406.832
48150/758000 (epoch 127), train_loss = 0.253, time/batch = 0.029, All_Time = 1408.310
48200/758000 (epoch 127), train_loss = 0.233, time/batch = 0.029, All_Time = 1409.780
48250/758000 (epoch 127), train_loss = 0.256, time/batch = 0.031, All_Time = 1411.250
48300/758000 (epoch 127), train_loss = 0.270, time/batch = 0.030, All_Time = 1412.715
48350/758000 (epoch 127), train_loss = 0.225, time/batch = 0.028, All_Time = 1414.177
48400/758000 (epoch 127), train_loss = 0.277, time/batch = 0.029, All_Time = 1415.643
48450/758000 (epoch 127), train_loss = 0.233, time/batch = 0.030, All_Time = 1417.115
48500/758000 (epoch 127), train_loss = 0.248, time/batch = 0.030, All_Time = 1418.575
48550/758000 (epoch 128), train_loss = 0.248, time/batch = 0.029, All_Time = 1420.045
48600/758000 (epoch 128), train_loss = 0.242, time/batch = 0.029, All_Time = 1421.514
48650/758000 (epoch 128), train_loss = 0.225, time/batch = 0.030, All_Time = 1422.993
48700/758000 (epoch 128), train_loss = 0.255, time/batch = 0.029, All_Time = 1424.460
48750/758000 (epoch 128), train_loss = 0.254, time/batch = 0.028, All_Time = 1425.928
48800/758000 (epoch 128), train_loss = 0.231, time/batch = 0.029, All_Time = 1427.394
48850/758000 (epoch 128), train_loss = 0.247, time/batch = 0.029, All_Time = 1428.854
48900/758000 (epoch 129), train_loss = 0.262, time/batch = 0.029, All_Time = 1430.333
48950/758000 (epoch 129), train_loss = 0.268, time/batch = 0.030, All_Time = 1431.784
49000/758000 (epoch 129), train_loss = 0.278, time/batch = 0.027, All_Time = 1433.246
model saved to NER/polyglot/model.ckpt
49050/758000 (epoch 129), train_loss = 0.248, time/batch = 0.029, All_Time = 1434.703
49100/758000 (epoch 129), train_loss = 0.267, time/batch = 0.028, All_Time = 1436.153
49150/758000 (epoch 129), train_loss = 0.255, time/batch = 0.032, All_Time = 1437.635
49200/758000 (epoch 129), train_loss = 0.230, time/batch = 0.029, All_Time = 1439.127
49250/758000 (epoch 129), train_loss = 0.263, time/batch = 0.029, All_Time = 1440.606
49300/758000 (epoch 130), train_loss = 0.228, time/batch = 0.030, All_Time = 1442.075
49350/758000 (epoch 130), train_loss = 0.230, time/batch = 0.030, All_Time = 1443.551
49400/758000 (epoch 130), train_loss = 0.270, time/batch = 0.029, All_Time = 1445.029
49450/758000 (epoch 130), train_loss = 0.270, time/batch = 0.028, All_Time = 1446.496
49500/758000 (epoch 130), train_loss = 0.249, time/batch = 0.029, All_Time = 1447.971
49550/758000 (epoch 130), train_loss = 0.279, time/batch = 0.029, All_Time = 1449.436
49600/758000 (epoch 130), train_loss = 0.272, time/batch = 0.031, All_Time = 1450.909
49650/758000 (epoch 131), train_loss = 0.222, time/batch = 0.029, All_Time = 1452.379
49700/758000 (epoch 131), train_loss = 0.274, time/batch = 0.029, All_Time = 1453.845
49750/758000 (epoch 131), train_loss = 0.228, time/batch = 0.029, All_Time = 1455.315
49800/758000 (epoch 131), train_loss = 0.280, time/batch = 0.029, All_Time = 1456.781
49850/758000 (epoch 131), train_loss = 0.247, time/batch = 0.029, All_Time = 1458.271
49900/758000 (epoch 131), train_loss = 0.230, time/batch = 0.030, All_Time = 1459.748
49950/758000 (epoch 131), train_loss = 0.264, time/batch = 0.029, All_Time = 1461.217
50000/758000 (epoch 131), train_loss = 0.276, time/batch = 0.029, All_Time = 1462.691
model saved to NER/polyglot/model.ckpt
50050/758000 (epoch 132), train_loss = 0.225, time/batch = 0.031, All_Time = 1464.160
50100/758000 (epoch 132), train_loss = 0.272, time/batch = 0.028, All_Time = 1465.622
50150/758000 (epoch 132), train_loss = 0.231, time/batch = 0.028, All_Time = 1467.094
50200/758000 (epoch 132), train_loss = 0.288, time/batch = 0.030, All_Time = 1468.560
50250/758000 (epoch 132), train_loss = 0.262, time/batch = 0.028, All_Time = 1470.021
50300/758000 (epoch 132), train_loss = 0.238, time/batch = 0.029, All_Time = 1471.485
50350/758000 (epoch 132), train_loss = 0.259, time/batch = 0.030, All_Time = 1472.945
50400/758000 (epoch 132), train_loss = 0.296, time/batch = 0.029, All_Time = 1474.427
50450/758000 (epoch 133), train_loss = 0.256, time/batch = 0.030, All_Time = 1475.920
50500/758000 (epoch 133), train_loss = 0.219, time/batch = 0.031, All_Time = 1477.393
50550/758000 (epoch 133), train_loss = 0.259, time/batch = 0.031, All_Time = 1478.880
50600/758000 (epoch 133), train_loss = 0.292, time/batch = 0.029, All_Time = 1480.352
50650/758000 (epoch 133), train_loss = 0.205, time/batch = 0.029, All_Time = 1481.823
50700/758000 (epoch 133), train_loss = 0.235, time/batch = 0.029, All_Time = 1483.285
50750/758000 (epoch 133), train_loss = 0.267, time/batch = 0.030, All_Time = 1484.765
50800/758000 (epoch 134), train_loss = 0.229, time/batch = 0.029, All_Time = 1486.242
50850/758000 (epoch 134), train_loss = 0.269, time/batch = 0.031, All_Time = 1487.709
50900/758000 (epoch 134), train_loss = 0.242, time/batch = 0.029, All_Time = 1489.180
50950/758000 (epoch 134), train_loss = 0.228, time/batch = 0.030, All_Time = 1490.653
51000/758000 (epoch 134), train_loss = 0.235, time/batch = 0.031, All_Time = 1492.116
model saved to NER/polyglot/model.ckpt
51050/758000 (epoch 134), train_loss = 0.221, time/batch = 0.028, All_Time = 1493.573
51100/758000 (epoch 134), train_loss = 0.251, time/batch = 0.029, All_Time = 1495.030
51150/758000 (epoch 134), train_loss = 0.226, time/batch = 0.029, All_Time = 1496.483
51200/758000 (epoch 135), train_loss = 0.294, time/batch = 0.029, All_Time = 1497.941
51250/758000 (epoch 135), train_loss = 0.239, time/batch = 0.028, All_Time = 1499.414
51300/758000 (epoch 135), train_loss = 0.295, time/batch = 0.030, All_Time = 1500.896
51350/758000 (epoch 135), train_loss = 0.289, time/batch = 0.029, All_Time = 1502.395
51400/758000 (epoch 135), train_loss = 0.240, time/batch = 0.029, All_Time = 1503.869
51450/758000 (epoch 135), train_loss = 0.290, time/batch = 0.029, All_Time = 1505.336
51500/758000 (epoch 135), train_loss = 0.292, time/batch = 0.029, All_Time = 1506.816
51550/758000 (epoch 136), train_loss = 0.258, time/batch = 0.029, All_Time = 1508.287
51600/758000 (epoch 136), train_loss = 0.229, time/batch = 0.030, All_Time = 1509.752
51650/758000 (epoch 136), train_loss = 0.236, time/batch = 0.029, All_Time = 1511.223
51700/758000 (epoch 136), train_loss = 0.252, time/batch = 0.030, All_Time = 1512.696
51750/758000 (epoch 136), train_loss = 0.252, time/batch = 0.029, All_Time = 1514.166
51800/758000 (epoch 136), train_loss = 0.244, time/batch = 0.028, All_Time = 1515.631
51850/758000 (epoch 136), train_loss = 0.211, time/batch = 0.029, All_Time = 1517.089
51900/758000 (epoch 136), train_loss = 0.278, time/batch = 0.030, All_Time = 1518.563
51950/758000 (epoch 137), train_loss = 0.255, time/batch = 0.030, All_Time = 1520.027
52000/758000 (epoch 137), train_loss = 0.269, time/batch = 0.028, All_Time = 1521.483
model saved to NER/polyglot/model.ckpt
52050/758000 (epoch 137), train_loss = 0.283, time/batch = 0.028, All_Time = 1522.950
52100/758000 (epoch 137), train_loss = 0.280, time/batch = 0.030, All_Time = 1524.405
52150/758000 (epoch 137), train_loss = 0.230, time/batch = 0.030, All_Time = 1525.862
52200/758000 (epoch 137), train_loss = 0.238, time/batch = 0.030, All_Time = 1527.322
52250/758000 (epoch 137), train_loss = 0.261, time/batch = 0.029, All_Time = 1528.778
52300/758000 (epoch 137), train_loss = 0.261, time/batch = 0.028, All_Time = 1530.248
52350/758000 (epoch 138), train_loss = 0.262, time/batch = 0.028, All_Time = 1531.717
52400/758000 (epoch 138), train_loss = 0.293, time/batch = 0.029, All_Time = 1533.182
52450/758000 (epoch 138), train_loss = 0.269, time/batch = 0.030, All_Time = 1534.656
52500/758000 (epoch 138), train_loss = 0.264, time/batch = 0.030, All_Time = 1536.149
52550/758000 (epoch 138), train_loss = 0.255, time/batch = 0.030, All_Time = 1537.645
52600/758000 (epoch 138), train_loss = 0.269, time/batch = 0.029, All_Time = 1539.108
52650/758000 (epoch 138), train_loss = 0.272, time/batch = 0.029, All_Time = 1540.578
52700/758000 (epoch 139), train_loss = 0.227, time/batch = 0.028, All_Time = 1542.052
52750/758000 (epoch 139), train_loss = 0.220, time/batch = 0.029, All_Time = 1543.519
52800/758000 (epoch 139), train_loss = 0.248, time/batch = 0.029, All_Time = 1544.991
52850/758000 (epoch 139), train_loss = 0.277, time/batch = 0.029, All_Time = 1546.450
52900/758000 (epoch 139), train_loss = 0.261, time/batch = 0.029, All_Time = 1547.914
52950/758000 (epoch 139), train_loss = 0.245, time/batch = 0.029, All_Time = 1549.381
53000/758000 (epoch 139), train_loss = 0.245, time/batch = 0.028, All_Time = 1550.843
model saved to NER/polyglot/model.ckpt
53050/758000 (epoch 139), train_loss = 0.235, time/batch = 0.029, All_Time = 1552.298
53100/758000 (epoch 140), train_loss = 0.253, time/batch = 0.030, All_Time = 1553.755
53150/758000 (epoch 140), train_loss = 0.272, time/batch = 0.030, All_Time = 1555.210
53200/758000 (epoch 140), train_loss = 0.282, time/batch = 0.029, All_Time = 1556.676
53250/758000 (epoch 140), train_loss = 0.252, time/batch = 0.029, All_Time = 1558.147
53300/758000 (epoch 140), train_loss = 0.264, time/batch = 0.030, All_Time = 1559.614
53350/758000 (epoch 140), train_loss = 0.275, time/batch = 0.030, All_Time = 1561.083
53400/758000 (epoch 140), train_loss = 0.269, time/batch = 0.030, All_Time = 1562.543
53450/758000 (epoch 141), train_loss = 0.226, time/batch = 0.030, All_Time = 1564.021
53500/758000 (epoch 141), train_loss = 0.247, time/batch = 0.029, All_Time = 1565.498
53550/758000 (epoch 141), train_loss = 0.245, time/batch = 0.030, All_Time = 1566.973
53600/758000 (epoch 141), train_loss = 0.250, time/batch = 0.031, All_Time = 1568.441
53650/758000 (epoch 141), train_loss = 0.254, time/batch = 0.030, All_Time = 1569.907
53700/758000 (epoch 141), train_loss = 0.244, time/batch = 0.029, All_Time = 1571.375
53750/758000 (epoch 141), train_loss = 0.251, time/batch = 0.029, All_Time = 1572.850
53800/758000 (epoch 141), train_loss = 0.267, time/batch = 0.029, All_Time = 1574.319
53850/758000 (epoch 142), train_loss = 0.253, time/batch = 0.030, All_Time = 1575.789
53900/758000 (epoch 142), train_loss = 0.273, time/batch = 0.030, All_Time = 1577.248
53950/758000 (epoch 142), train_loss = 0.251, time/batch = 0.028, All_Time = 1578.715
54000/758000 (epoch 142), train_loss = 0.261, time/batch = 0.030, All_Time = 1580.207
model saved to NER/polyglot/model.ckpt
54050/758000 (epoch 142), train_loss = 0.244, time/batch = 0.029, All_Time = 1581.700
54100/758000 (epoch 142), train_loss = 0.243, time/batch = 0.029, All_Time = 1583.177
54150/758000 (epoch 142), train_loss = 0.292, time/batch = 0.029, All_Time = 1584.647
54200/758000 (epoch 143), train_loss = 0.276, time/batch = 0.029, All_Time = 1586.112
54250/758000 (epoch 143), train_loss = 0.281, time/batch = 0.029, All_Time = 1587.584
54300/758000 (epoch 143), train_loss = 0.262, time/batch = 0.029, All_Time = 1589.063
54350/758000 (epoch 143), train_loss = 0.282, time/batch = 0.030, All_Time = 1590.541
54400/758000 (epoch 143), train_loss = 0.232, time/batch = 0.030, All_Time = 1592.018
54450/758000 (epoch 143), train_loss = 0.256, time/batch = 0.031, All_Time = 1593.491
54500/758000 (epoch 143), train_loss = 0.232, time/batch = 0.029, All_Time = 1594.945
54550/758000 (epoch 143), train_loss = 0.248, time/batch = 0.030, All_Time = 1596.419
54600/758000 (epoch 144), train_loss = 0.259, time/batch = 0.029, All_Time = 1597.911
54650/758000 (epoch 144), train_loss = 0.260, time/batch = 0.029, All_Time = 1599.378
54700/758000 (epoch 144), train_loss = 0.307, time/batch = 0.029, All_Time = 1600.839
54750/758000 (epoch 144), train_loss = 0.334, time/batch = 0.027, All_Time = 1602.305
54800/758000 (epoch 144), train_loss = 0.223, time/batch = 0.029, All_Time = 1603.778
54850/758000 (epoch 144), train_loss = 0.225, time/batch = 0.029, All_Time = 1605.244
54900/758000 (epoch 144), train_loss = 0.261, time/batch = 0.030, All_Time = 1606.703
54950/758000 (epoch 144), train_loss = 0.310, time/batch = 0.029, All_Time = 1608.157
55000/758000 (epoch 145), train_loss = 0.229, time/batch = 0.029, All_Time = 1609.619
model saved to NER/polyglot/model.ckpt
55050/758000 (epoch 145), train_loss = 0.274, time/batch = 0.030, All_Time = 1611.077
55100/758000 (epoch 145), train_loss = 0.249, time/batch = 0.028, All_Time = 1612.542
55150/758000 (epoch 145), train_loss = 0.283, time/batch = 0.029, All_Time = 1613.998
55200/758000 (epoch 145), train_loss = 0.236, time/batch = 0.030, All_Time = 1615.474
55250/758000 (epoch 145), train_loss = 0.260, time/batch = 0.028, All_Time = 1616.928
55300/758000 (epoch 145), train_loss = 0.225, time/batch = 0.032, All_Time = 1618.407
55350/758000 (epoch 146), train_loss = 0.255, time/batch = 0.029, All_Time = 1619.892
55400/758000 (epoch 146), train_loss = 0.249, time/batch = 0.030, All_Time = 1621.367
55450/758000 (epoch 146), train_loss = 0.273, time/batch = 0.029, All_Time = 1622.832
55500/758000 (epoch 146), train_loss = 0.246, time/batch = 0.030, All_Time = 1624.298
55550/758000 (epoch 146), train_loss = 0.245, time/batch = 0.029, All_Time = 1625.767
55600/758000 (epoch 146), train_loss = 0.287, time/batch = 0.029, All_Time = 1627.241
55650/758000 (epoch 146), train_loss = 0.239, time/batch = 0.029, All_Time = 1628.712
55700/758000 (epoch 146), train_loss = 0.296, time/batch = 0.029, All_Time = 1630.176
55750/758000 (epoch 147), train_loss = 0.255, time/batch = 0.031, All_Time = 1631.641
55800/758000 (epoch 147), train_loss = 0.267, time/batch = 0.030, All_Time = 1633.109
55850/758000 (epoch 147), train_loss = 0.253, time/batch = 0.029, All_Time = 1634.591
55900/758000 (epoch 147), train_loss = 0.283, time/batch = 0.030, All_Time = 1636.065
55950/758000 (epoch 147), train_loss = 0.251, time/batch = 0.030, All_Time = 1637.531
56000/758000 (epoch 147), train_loss = 0.266, time/batch = 0.029, All_Time = 1639.001
model saved to NER/polyglot/model.ckpt
56050/758000 (epoch 147), train_loss = 0.263, time/batch = 0.029, All_Time = 1640.468
56100/758000 (epoch 148), train_loss = 0.264, time/batch = 0.031, All_Time = 1641.928
56150/758000 (epoch 148), train_loss = 0.280, time/batch = 0.028, All_Time = 1643.384
56200/758000 (epoch 148), train_loss = 0.269, time/batch = 0.029, All_Time = 1644.863
56250/758000 (epoch 148), train_loss = 0.273, time/batch = 0.031, All_Time = 1646.369
56300/758000 (epoch 148), train_loss = 0.239, time/batch = 0.030, All_Time = 1647.841
56350/758000 (epoch 148), train_loss = 0.258, time/batch = 0.029, All_Time = 1649.311
56400/758000 (epoch 148), train_loss = 0.259, time/batch = 0.030, All_Time = 1650.789
56450/758000 (epoch 148), train_loss = 0.262, time/batch = 0.029, All_Time = 1652.267
56500/758000 (epoch 149), train_loss = 0.243, time/batch = 0.028, All_Time = 1653.743
56550/758000 (epoch 149), train_loss = 0.274, time/batch = 0.029, All_Time = 1655.220
56600/758000 (epoch 149), train_loss = 0.271, time/batch = 0.031, All_Time = 1656.691
56650/758000 (epoch 149), train_loss = 0.279, time/batch = 0.031, All_Time = 1658.156
56700/758000 (epoch 149), train_loss = 0.314, time/batch = 0.029, All_Time = 1659.636
56750/758000 (epoch 149), train_loss = 0.231, time/batch = 0.030, All_Time = 1661.105
56800/758000 (epoch 149), train_loss = 0.270, time/batch = 0.030, All_Time = 1662.567
56850/758000 (epoch 150), train_loss = 0.065, time/batch = 0.031, All_Time = 1664.042
56900/758000 (epoch 150), train_loss = 0.263, time/batch = 0.029, All_Time = 1665.516
56950/758000 (epoch 150), train_loss = 0.233, time/batch = 0.030, All_Time = 1666.981
57000/758000 (epoch 150), train_loss = 0.260, time/batch = 0.030, All_Time = 1668.466
model saved to NER/polyglot/model.ckpt
57050/758000 (epoch 150), train_loss = 0.255, time/batch = 0.029, All_Time = 1669.947
57100/758000 (epoch 150), train_loss = 0.288, time/batch = 0.030, All_Time = 1671.418
57150/758000 (epoch 150), train_loss = 0.241, time/batch = 0.029, All_Time = 1672.893
57200/758000 (epoch 150), train_loss = 0.250, time/batch = 0.029, All_Time = 1674.356
57250/758000 (epoch 151), train_loss = 0.268, time/batch = 0.030, All_Time = 1675.821
57300/758000 (epoch 151), train_loss = 0.248, time/batch = 0.031, All_Time = 1677.287
57350/758000 (epoch 151), train_loss = 0.250, time/batch = 0.030, All_Time = 1678.758
57400/758000 (epoch 151), train_loss = 0.273, time/batch = 0.030, All_Time = 1680.236
57450/758000 (epoch 151), train_loss = 0.243, time/batch = 0.029, All_Time = 1681.706
57500/758000 (epoch 151), train_loss = 0.241, time/batch = 0.030, All_Time = 1683.180
57550/758000 (epoch 151), train_loss = 0.305, time/batch = 0.030, All_Time = 1684.653
57600/758000 (epoch 151), train_loss = 0.296, time/batch = 0.029, All_Time = 1686.113
57650/758000 (epoch 152), train_loss = 0.255, time/batch = 0.029, All_Time = 1687.588
57700/758000 (epoch 152), train_loss = 0.239, time/batch = 0.030, All_Time = 1689.053
57750/758000 (epoch 152), train_loss = 0.214, time/batch = 0.029, All_Time = 1690.522
57800/758000 (epoch 152), train_loss = 0.290, time/batch = 0.030, All_Time = 1691.986
57850/758000 (epoch 152), train_loss = 0.266, time/batch = 0.028, All_Time = 1693.444
57900/758000 (epoch 152), train_loss = 0.233, time/batch = 0.030, All_Time = 1694.934
57950/758000 (epoch 152), train_loss = 0.231, time/batch = 0.029, All_Time = 1696.405
58000/758000 (epoch 153), train_loss = 0.249, time/batch = 0.030, All_Time = 1697.885
model saved to NER/polyglot/model.ckpt
58050/758000 (epoch 153), train_loss = 0.304, time/batch = 0.029, All_Time = 1699.359
58100/758000 (epoch 153), train_loss = 0.243, time/batch = 0.030, All_Time = 1700.841
58150/758000 (epoch 153), train_loss = 0.306, time/batch = 0.028, All_Time = 1702.326
58200/758000 (epoch 153), train_loss = 0.246, time/batch = 0.029, All_Time = 1703.791
58250/758000 (epoch 153), train_loss = 0.233, time/batch = 0.029, All_Time = 1705.270
58300/758000 (epoch 153), train_loss = 0.268, time/batch = 0.027, All_Time = 1706.757
58350/758000 (epoch 153), train_loss = 0.262, time/batch = 0.030, All_Time = 1708.231
58400/758000 (epoch 154), train_loss = 0.289, time/batch = 0.030, All_Time = 1709.704
58450/758000 (epoch 154), train_loss = 0.230, time/batch = 0.030, All_Time = 1711.171
58500/758000 (epoch 154), train_loss = 0.243, time/batch = 0.028, All_Time = 1712.636
58550/758000 (epoch 154), train_loss = 0.287, time/batch = 0.030, All_Time = 1714.099
58600/758000 (epoch 154), train_loss = 0.272, time/batch = 0.032, All_Time = 1715.598
58650/758000 (epoch 154), train_loss = 0.254, time/batch = 0.031, All_Time = 1717.091
58700/758000 (epoch 154), train_loss = 0.293, time/batch = 0.030, All_Time = 1718.565
58750/758000 (epoch 155), train_loss = 0.266, time/batch = 0.031, All_Time = 1720.044
58800/758000 (epoch 155), train_loss = 0.229, time/batch = 0.029, All_Time = 1721.512
58850/758000 (epoch 155), train_loss = 0.292, time/batch = 0.029, All_Time = 1722.973
58900/758000 (epoch 155), train_loss = 0.231, time/batch = 0.028, All_Time = 1724.440
58950/758000 (epoch 155), train_loss = 0.245, time/batch = 0.030, All_Time = 1725.900
59000/758000 (epoch 155), train_loss = 0.290, time/batch = 0.030, All_Time = 1727.381
model saved to NER/polyglot/model.ckpt
59050/758000 (epoch 155), train_loss = 0.242, time/batch = 0.031, All_Time = 1728.854
59100/758000 (epoch 155), train_loss = 0.283, time/batch = 0.029, All_Time = 1730.319
59150/758000 (epoch 156), train_loss = 0.262, time/batch = 0.029, All_Time = 1731.783
59200/758000 (epoch 156), train_loss = 0.260, time/batch = 0.031, All_Time = 1733.257
59250/758000 (epoch 156), train_loss = 0.238, time/batch = 0.029, All_Time = 1734.728
59300/758000 (epoch 156), train_loss = 0.273, time/batch = 0.029, All_Time = 1736.186
59350/758000 (epoch 156), train_loss = 0.270, time/batch = 0.029, All_Time = 1737.646
59400/758000 (epoch 156), train_loss = 0.239, time/batch = 0.029, All_Time = 1739.115
59450/758000 (epoch 156), train_loss = 0.282, time/batch = 0.029, All_Time = 1740.583
59500/758000 (epoch 156), train_loss = 0.251, time/batch = 0.030, All_Time = 1742.047
59550/758000 (epoch 157), train_loss = 0.309, time/batch = 0.030, All_Time = 1743.511
59600/758000 (epoch 157), train_loss = 0.266, time/batch = 0.029, All_Time = 1744.977
59650/758000 (epoch 157), train_loss = 0.258, time/batch = 0.028, All_Time = 1746.447
59700/758000 (epoch 157), train_loss = 0.252, time/batch = 0.029, All_Time = 1747.921
59750/758000 (epoch 157), train_loss = 0.235, time/batch = 0.029, All_Time = 1749.391
59800/758000 (epoch 157), train_loss = 0.243, time/batch = 0.031, All_Time = 1750.856
59850/758000 (epoch 157), train_loss = 0.250, time/batch = 0.028, All_Time = 1752.341
59900/758000 (epoch 158), train_loss = 0.265, time/batch = 0.030, All_Time = 1753.806
59950/758000 (epoch 158), train_loss = 0.226, time/batch = 0.029, All_Time = 1755.278
60000/758000 (epoch 158), train_loss = 0.248, time/batch = 0.030, All_Time = 1756.747
model saved to NER/polyglot/model.ckpt
60050/758000 (epoch 158), train_loss = 0.235, time/batch = 0.029, All_Time = 1758.213
60100/758000 (epoch 158), train_loss = 0.244, time/batch = 0.029, All_Time = 1759.681
60150/758000 (epoch 158), train_loss = 0.234, time/batch = 0.029, All_Time = 1761.167
60200/758000 (epoch 158), train_loss = 0.271, time/batch = 0.029, All_Time = 1762.643
60250/758000 (epoch 158), train_loss = 0.247, time/batch = 0.029, All_Time = 1764.127
60300/758000 (epoch 159), train_loss = 0.254, time/batch = 0.030, All_Time = 1765.598
60350/758000 (epoch 159), train_loss = 0.248, time/batch = 0.029, All_Time = 1767.065
60400/758000 (epoch 159), train_loss = 0.225, time/batch = 0.031, All_Time = 1768.539
60450/758000 (epoch 159), train_loss = 0.293, time/batch = 0.028, All_Time = 1770.006
60500/758000 (epoch 159), train_loss = 0.289, time/batch = 0.029, All_Time = 1771.460
60550/758000 (epoch 159), train_loss = 0.245, time/batch = 0.030, All_Time = 1772.921
60600/758000 (epoch 159), train_loss = 0.274, time/batch = 0.030, All_Time = 1774.386
60650/758000 (epoch 160), train_loss = 0.294, time/batch = 0.029, All_Time = 1775.865
60700/758000 (epoch 160), train_loss = 0.318, time/batch = 0.031, All_Time = 1777.332
60750/758000 (epoch 160), train_loss = 0.250, time/batch = 0.030, All_Time = 1778.799
60800/758000 (epoch 160), train_loss = 0.221, time/batch = 0.031, All_Time = 1780.311
60850/758000 (epoch 160), train_loss = 0.231, time/batch = 0.032, All_Time = 1781.790
60900/758000 (epoch 160), train_loss = 0.269, time/batch = 0.027, All_Time = 1783.254
60950/758000 (epoch 160), train_loss = 0.252, time/batch = 0.029, All_Time = 1784.715
61000/758000 (epoch 160), train_loss = 0.256, time/batch = 0.029, All_Time = 1786.173
model saved to NER/polyglot/model.ckpt
61050/758000 (epoch 161), train_loss = 0.234, time/batch = 0.029, All_Time = 1787.629
61100/758000 (epoch 161), train_loss = 0.289, time/batch = 0.030, All_Time = 1789.096
61150/758000 (epoch 161), train_loss = 0.253, time/batch = 0.030, All_Time = 1790.566
61200/758000 (epoch 161), train_loss = 0.247, time/batch = 0.031, All_Time = 1792.049
61250/758000 (epoch 161), train_loss = 0.239, time/batch = 0.028, All_Time = 1793.543
61300/758000 (epoch 161), train_loss = 0.271, time/batch = 0.031, All_Time = 1795.029
61350/758000 (epoch 161), train_loss = 0.278, time/batch = 0.029, All_Time = 1796.491
61400/758000 (epoch 162), train_loss = 0.216, time/batch = 0.031, All_Time = 1797.966
61450/758000 (epoch 162), train_loss = 0.277, time/batch = 0.028, All_Time = 1799.446
61500/758000 (epoch 162), train_loss = 0.288, time/batch = 0.029, All_Time = 1800.901
61550/758000 (epoch 162), train_loss = 0.249, time/batch = 0.028, All_Time = 1802.367
61600/758000 (epoch 162), train_loss = 0.262, time/batch = 0.030, All_Time = 1803.835
61650/758000 (epoch 162), train_loss = 0.262, time/batch = 0.029, All_Time = 1805.310
61700/758000 (epoch 162), train_loss = 0.216, time/batch = 0.030, All_Time = 1806.776
61750/758000 (epoch 162), train_loss = 0.275, time/batch = 0.031, All_Time = 1808.232
61800/758000 (epoch 163), train_loss = 0.258, time/batch = 0.029, All_Time = 1809.692
61850/758000 (epoch 163), train_loss = 0.269, time/batch = 0.029, All_Time = 1811.152
61900/758000 (epoch 163), train_loss = 0.254, time/batch = 0.031, All_Time = 1812.623
61950/758000 (epoch 163), train_loss = 0.277, time/batch = 0.029, All_Time = 1814.096
62000/758000 (epoch 163), train_loss = 0.266, time/batch = 0.029, All_Time = 1815.560
model saved to NER/polyglot/model.ckpt
62050/758000 (epoch 163), train_loss = 0.260, time/batch = 0.030, All_Time = 1817.023
62100/758000 (epoch 163), train_loss = 0.253, time/batch = 0.031, All_Time = 1818.532
62150/758000 (epoch 163), train_loss = 0.300, time/batch = 0.028, All_Time = 1820.010
62200/758000 (epoch 164), train_loss = 0.225, time/batch = 0.030, All_Time = 1821.495
62250/758000 (epoch 164), train_loss = 0.266, time/batch = 0.030, All_Time = 1822.976
62300/758000 (epoch 164), train_loss = 0.232, time/batch = 0.029, All_Time = 1824.458
62350/758000 (epoch 164), train_loss = 0.258, time/batch = 0.029, All_Time = 1825.936
62400/758000 (epoch 164), train_loss = 0.288, time/batch = 0.030, All_Time = 1827.409
62450/758000 (epoch 164), train_loss = 0.272, time/batch = 0.029, All_Time = 1828.873
62500/758000 (epoch 164), train_loss = 0.232, time/batch = 0.030, All_Time = 1830.337
62550/758000 (epoch 165), train_loss = 0.237, time/batch = 0.028, All_Time = 1831.813
62600/758000 (epoch 165), train_loss = 0.274, time/batch = 0.030, All_Time = 1833.286
62650/758000 (epoch 165), train_loss = 0.250, time/batch = 0.029, All_Time = 1834.759
62700/758000 (epoch 165), train_loss = 0.239, time/batch = 0.027, All_Time = 1836.224
62750/758000 (epoch 165), train_loss = 0.256, time/batch = 0.032, All_Time = 1837.715
62800/758000 (epoch 165), train_loss = 0.262, time/batch = 0.028, All_Time = 1839.202
62850/758000 (epoch 165), train_loss = 0.261, time/batch = 0.030, All_Time = 1840.683
62900/758000 (epoch 165), train_loss = 0.269, time/batch = 0.030, All_Time = 1842.149
62950/758000 (epoch 166), train_loss = 0.298, time/batch = 0.028, All_Time = 1843.608
63000/758000 (epoch 166), train_loss = 0.231, time/batch = 0.030, All_Time = 1845.083
model saved to NER/polyglot/model.ckpt
63050/758000 (epoch 166), train_loss = 0.260, time/batch = 0.029, All_Time = 1846.554
63100/758000 (epoch 166), train_loss = 0.239, time/batch = 0.029, All_Time = 1848.004
63150/758000 (epoch 166), train_loss = 0.298, time/batch = 0.031, All_Time = 1849.489
63200/758000 (epoch 166), train_loss = 0.271, time/batch = 0.033, All_Time = 1850.983
63250/758000 (epoch 166), train_loss = 0.265, time/batch = 0.029, All_Time = 1852.464
63300/758000 (epoch 167), train_loss = 0.258, time/batch = 0.029, All_Time = 1853.946
63350/758000 (epoch 167), train_loss = 0.267, time/batch = 0.031, All_Time = 1855.423
63400/758000 (epoch 167), train_loss = 0.284, time/batch = 0.029, All_Time = 1856.891
63450/758000 (epoch 167), train_loss = 0.260, time/batch = 0.029, All_Time = 1858.357
63500/758000 (epoch 167), train_loss = 0.255, time/batch = 0.029, All_Time = 1859.826
63550/758000 (epoch 167), train_loss = 0.241, time/batch = 0.029, All_Time = 1861.293
63600/758000 (epoch 167), train_loss = 0.242, time/batch = 0.030, All_Time = 1862.756
63650/758000 (epoch 167), train_loss = 0.249, time/batch = 0.028, All_Time = 1864.243
63700/758000 (epoch 168), train_loss = 0.266, time/batch = 0.029, All_Time = 1865.714
63750/758000 (epoch 168), train_loss = 0.289, time/batch = 0.031, All_Time = 1867.174
63800/758000 (epoch 168), train_loss = 0.252, time/batch = 0.029, All_Time = 1868.636
63850/758000 (epoch 168), train_loss = 0.281, time/batch = 0.030, All_Time = 1870.099
63900/758000 (epoch 168), train_loss = 0.245, time/batch = 0.031, All_Time = 1871.564
63950/758000 (epoch 168), train_loss = 0.231, time/batch = 0.031, All_Time = 1873.023
64000/758000 (epoch 168), train_loss = 0.285, time/batch = 0.030, All_Time = 1874.487
model saved to NER/polyglot/model.ckpt
64050/758000 (epoch 168), train_loss = 0.274, time/batch = 0.030, All_Time = 1875.949
64100/758000 (epoch 169), train_loss = 0.288, time/batch = 0.029, All_Time = 1877.459
64150/758000 (epoch 169), train_loss = 0.297, time/batch = 0.030, All_Time = 1878.933
64200/758000 (epoch 169), train_loss = 0.238, time/batch = 0.030, All_Time = 1880.395
64250/758000 (epoch 169), train_loss = 0.233, time/batch = 0.031, All_Time = 1881.873
64300/758000 (epoch 169), train_loss = 0.291, time/batch = 0.031, All_Time = 1883.349
64350/758000 (epoch 169), train_loss = 0.285, time/batch = 0.028, All_Time = 1884.820
64400/758000 (epoch 169), train_loss = 0.255, time/batch = 0.029, All_Time = 1886.290
64450/758000 (epoch 170), train_loss = 0.241, time/batch = 0.030, All_Time = 1887.764
64500/758000 (epoch 170), train_loss = 0.253, time/batch = 0.029, All_Time = 1889.242
64550/758000 (epoch 170), train_loss = 0.251, time/batch = 0.030, All_Time = 1890.722
64600/758000 (epoch 170), train_loss = 0.243, time/batch = 0.028, All_Time = 1892.207
64650/758000 (epoch 170), train_loss = 0.243, time/batch = 0.031, All_Time = 1893.676
64700/758000 (epoch 170), train_loss = 0.261, time/batch = 0.029, All_Time = 1895.149
64750/758000 (epoch 170), train_loss = 0.284, time/batch = 0.030, All_Time = 1896.622
64800/758000 (epoch 170), train_loss = 0.255, time/batch = 0.030, All_Time = 1898.090
64850/758000 (epoch 171), train_loss = 0.275, time/batch = 0.028, All_Time = 1899.563
64900/758000 (epoch 171), train_loss = 0.308, time/batch = 0.029, All_Time = 1901.041
64950/758000 (epoch 171), train_loss = 0.275, time/batch = 0.030, All_Time = 1902.511
65000/758000 (epoch 171), train_loss = 0.272, time/batch = 0.031, All_Time = 1903.989
model saved to NER/polyglot/model.ckpt
65050/758000 (epoch 171), train_loss = 0.237, time/batch = 0.029, All_Time = 1905.452
65100/758000 (epoch 171), train_loss = 0.244, time/batch = 0.029, All_Time = 1906.920
65150/758000 (epoch 171), train_loss = 0.290, time/batch = 0.030, All_Time = 1908.386
65200/758000 (epoch 172), train_loss = 0.273, time/batch = 0.029, All_Time = 1909.847
65250/758000 (epoch 172), train_loss = 0.251, time/batch = 0.031, All_Time = 1911.305
65300/758000 (epoch 172), train_loss = 0.278, time/batch = 0.028, All_Time = 1912.770
65350/758000 (epoch 172), train_loss = 0.261, time/batch = 0.028, All_Time = 1914.239
65400/758000 (epoch 172), train_loss = 0.267, time/batch = 0.028, All_Time = 1915.699
65450/758000 (epoch 172), train_loss = 0.254, time/batch = 0.030, All_Time = 1917.157
65500/758000 (epoch 172), train_loss = 0.281, time/batch = 0.029, All_Time = 1918.648
65550/758000 (epoch 172), train_loss = 0.289, time/batch = 0.028, All_Time = 1920.124
65600/758000 (epoch 173), train_loss = 0.255, time/batch = 0.028, All_Time = 1921.600
65650/758000 (epoch 173), train_loss = 0.253, time/batch = 0.028, All_Time = 1923.079
65700/758000 (epoch 173), train_loss = 0.301, time/batch = 0.030, All_Time = 1924.562
65750/758000 (epoch 173), train_loss = 0.240, time/batch = 0.030, All_Time = 1926.033
65800/758000 (epoch 173), train_loss = 0.225, time/batch = 0.030, All_Time = 1927.507
65850/758000 (epoch 173), train_loss = 0.261, time/batch = 0.029, All_Time = 1928.976
65900/758000 (epoch 173), train_loss = 0.297, time/batch = 0.030, All_Time = 1930.447
65950/758000 (epoch 174), train_loss = 0.227, time/batch = 0.029, All_Time = 1931.924
66000/758000 (epoch 174), train_loss = 0.271, time/batch = 0.028, All_Time = 1933.394
model saved to NER/polyglot/model.ckpt
66050/758000 (epoch 174), train_loss = 0.260, time/batch = 0.031, All_Time = 1934.859
66100/758000 (epoch 174), train_loss = 0.250, time/batch = 0.028, All_Time = 1936.328
66150/758000 (epoch 174), train_loss = 0.267, time/batch = 0.029, All_Time = 1937.797
66200/758000 (epoch 174), train_loss = 0.241, time/batch = 0.030, All_Time = 1939.272
66250/758000 (epoch 174), train_loss = 0.241, time/batch = 0.029, All_Time = 1940.767
66300/758000 (epoch 174), train_loss = 0.274, time/batch = 0.029, All_Time = 1942.253
66350/758000 (epoch 175), train_loss = 0.274, time/batch = 0.030, All_Time = 1943.729
66400/758000 (epoch 175), train_loss = 0.277, time/batch = 0.028, All_Time = 1945.195
66450/758000 (epoch 175), train_loss = 0.287, time/batch = 0.030, All_Time = 1946.665
66500/758000 (epoch 175), train_loss = 0.233, time/batch = 0.030, All_Time = 1948.126
66550/758000 (epoch 175), train_loss = 0.248, time/batch = 0.030, All_Time = 1949.597
66600/758000 (epoch 175), train_loss = 0.260, time/batch = 0.029, All_Time = 1951.054
66650/758000 (epoch 175), train_loss = 0.298, time/batch = 0.029, All_Time = 1952.517
66700/758000 (epoch 175), train_loss = 0.252, time/batch = 0.028, All_Time = 1953.974
66750/758000 (epoch 176), train_loss = 0.248, time/batch = 0.030, All_Time = 1955.435
66800/758000 (epoch 176), train_loss = 0.248, time/batch = 0.033, All_Time = 1956.922
66850/758000 (epoch 176), train_loss = 0.252, time/batch = 0.030, All_Time = 1958.415
66900/758000 (epoch 176), train_loss = 0.285, time/batch = 0.031, All_Time = 1959.895
66950/758000 (epoch 176), train_loss = 0.232, time/batch = 0.029, All_Time = 1961.377
67000/758000 (epoch 176), train_loss = 0.279, time/batch = 0.031, All_Time = 1962.838
model saved to NER/polyglot/model.ckpt
67050/758000 (epoch 176), train_loss = 0.252, time/batch = 0.030, All_Time = 1964.305
67100/758000 (epoch 177), train_loss = 0.258, time/batch = 0.029, All_Time = 1965.775
67150/758000 (epoch 177), train_loss = 0.237, time/batch = 0.030, All_Time = 1967.240
67200/758000 (epoch 177), train_loss = 0.255, time/batch = 0.029, All_Time = 1968.702
67250/758000 (epoch 177), train_loss = 0.257, time/batch = 0.031, All_Time = 1970.161
67300/758000 (epoch 177), train_loss = 0.228, time/batch = 0.029, All_Time = 1971.622
67350/758000 (epoch 177), train_loss = 0.280, time/batch = 0.028, All_Time = 1973.092
67400/758000 (epoch 177), train_loss = 0.221, time/batch = 0.028, All_Time = 1974.558
67450/758000 (epoch 177), train_loss = 0.268, time/batch = 0.029, All_Time = 1976.025
67500/758000 (epoch 178), train_loss = 0.275, time/batch = 0.028, All_Time = 1977.490
67550/758000 (epoch 178), train_loss = 0.246, time/batch = 0.029, All_Time = 1978.955
67600/758000 (epoch 178), train_loss = 0.224, time/batch = 0.030, All_Time = 1980.418
67650/758000 (epoch 178), train_loss = 0.232, time/batch = 0.030, All_Time = 1981.894
67700/758000 (epoch 178), train_loss = 0.275, time/batch = 0.029, All_Time = 1983.363
67750/758000 (epoch 178), train_loss = 0.219, time/batch = 0.030, All_Time = 1984.854
67800/758000 (epoch 178), train_loss = 0.278, time/batch = 0.030, All_Time = 1986.350
67850/758000 (epoch 179), train_loss = 0.264, time/batch = 0.030, All_Time = 1987.838
67900/758000 (epoch 179), train_loss = 0.274, time/batch = 0.029, All_Time = 1989.316
67950/758000 (epoch 179), train_loss = 0.290, time/batch = 0.029, All_Time = 1990.796
68000/758000 (epoch 179), train_loss = 0.244, time/batch = 0.031, All_Time = 1992.277
model saved to NER/polyglot/model.ckpt
68050/758000 (epoch 179), train_loss = 0.282, time/batch = 0.030, All_Time = 1993.740
68100/758000 (epoch 179), train_loss = 0.268, time/batch = 0.029, All_Time = 1995.209
68150/758000 (epoch 179), train_loss = 0.249, time/batch = 0.029, All_Time = 1996.681
68200/758000 (epoch 179), train_loss = 0.280, time/batch = 0.031, All_Time = 1998.157
68250/758000 (epoch 180), train_loss = 0.237, time/batch = 0.028, All_Time = 1999.625
68300/758000 (epoch 180), train_loss = 0.228, time/batch = 0.031, All_Time = 2001.104
68350/758000 (epoch 180), train_loss = 0.270, time/batch = 0.029, All_Time = 2002.578
68400/758000 (epoch 180), train_loss = 0.270, time/batch = 0.029, All_Time = 2004.053
68450/758000 (epoch 180), train_loss = 0.243, time/batch = 0.029, All_Time = 2005.536
68500/758000 (epoch 180), train_loss = 0.258, time/batch = 0.029, All_Time = 2006.993
68550/758000 (epoch 180), train_loss = 0.266, time/batch = 0.030, All_Time = 2008.470
68600/758000 (epoch 181), train_loss = 0.201, time/batch = 0.030, All_Time = 2009.935
68650/758000 (epoch 181), train_loss = 0.292, time/batch = 0.029, All_Time = 2011.405
68700/758000 (epoch 181), train_loss = 0.232, time/batch = 0.033, All_Time = 2012.872
68750/758000 (epoch 181), train_loss = 0.265, time/batch = 0.029, All_Time = 2014.335
68800/758000 (epoch 181), train_loss = 0.235, time/batch = 0.030, All_Time = 2015.804
68850/758000 (epoch 181), train_loss = 0.234, time/batch = 0.030, All_Time = 2017.278
68900/758000 (epoch 181), train_loss = 0.265, time/batch = 0.029, All_Time = 2018.747
68950/758000 (epoch 181), train_loss = 0.292, time/batch = 0.028, All_Time = 2020.214
69000/758000 (epoch 182), train_loss = 0.230, time/batch = 0.030, All_Time = 2021.687
model saved to NER/polyglot/model.ckpt
69050/758000 (epoch 182), train_loss = 0.286, time/batch = 0.029, All_Time = 2023.141
69100/758000 (epoch 182), train_loss = 0.253, time/batch = 0.029, All_Time = 2024.601
69150/758000 (epoch 182), train_loss = 0.281, time/batch = 0.029, All_Time = 2026.076
69200/758000 (epoch 182), train_loss = 0.270, time/batch = 0.029, All_Time = 2027.551
69250/758000 (epoch 182), train_loss = 0.208, time/batch = 0.030, All_Time = 2029.025
69300/758000 (epoch 182), train_loss = 0.243, time/batch = 0.030, All_Time = 2030.506
69350/758000 (epoch 182), train_loss = 0.293, time/batch = 0.028, All_Time = 2031.988
69400/758000 (epoch 183), train_loss = 0.258, time/batch = 0.030, All_Time = 2033.470
69450/758000 (epoch 183), train_loss = 0.226, time/batch = 0.030, All_Time = 2034.948
69500/758000 (epoch 183), train_loss = 0.269, time/batch = 0.029, All_Time = 2036.407
69550/758000 (epoch 183), train_loss = 0.283, time/batch = 0.028, All_Time = 2037.882
69600/758000 (epoch 183), train_loss = 0.210, time/batch = 0.031, All_Time = 2039.360
69650/758000 (epoch 183), train_loss = 0.241, time/batch = 0.029, All_Time = 2040.833
69700/758000 (epoch 183), train_loss = 0.262, time/batch = 0.028, All_Time = 2042.307
69750/758000 (epoch 184), train_loss = 0.229, time/batch = 0.029, All_Time = 2043.795
69800/758000 (epoch 184), train_loss = 0.295, time/batch = 0.029, All_Time = 2045.286
69850/758000 (epoch 184), train_loss = 0.233, time/batch = 0.029, All_Time = 2046.760
69900/758000 (epoch 184), train_loss = 0.221, time/batch = 0.030, All_Time = 2048.237
69950/758000 (epoch 184), train_loss = 0.234, time/batch = 0.030, All_Time = 2049.713
70000/758000 (epoch 184), train_loss = 0.224, time/batch = 0.030, All_Time = 2051.176
model saved to NER/polyglot/model.ckpt
70050/758000 (epoch 184), train_loss = 0.244, time/batch = 0.030, All_Time = 2052.641
70100/758000 (epoch 184), train_loss = 0.235, time/batch = 0.031, All_Time = 2054.111
70150/758000 (epoch 185), train_loss = 0.292, time/batch = 0.028, All_Time = 2055.584
70200/758000 (epoch 185), train_loss = 0.234, time/batch = 0.029, All_Time = 2057.052
70250/758000 (epoch 185), train_loss = 0.282, time/batch = 0.031, All_Time = 2058.526
70300/758000 (epoch 185), train_loss = 0.280, time/batch = 0.030, All_Time = 2060.014
70350/758000 (epoch 185), train_loss = 0.241, time/batch = 0.029, All_Time = 2061.499
70400/758000 (epoch 185), train_loss = 0.280, time/batch = 0.031, All_Time = 2062.978
70450/758000 (epoch 185), train_loss = 0.284, time/batch = 0.030, All_Time = 2064.460
70500/758000 (epoch 186), train_loss = 0.248, time/batch = 0.029, All_Time = 2065.938
70550/758000 (epoch 186), train_loss = 0.233, time/batch = 0.031, All_Time = 2067.409
70600/758000 (epoch 186), train_loss = 0.253, time/batch = 0.029, All_Time = 2068.890
70650/758000 (epoch 186), train_loss = 0.252, time/batch = 0.030, All_Time = 2070.366
70700/758000 (epoch 186), train_loss = 0.252, time/batch = 0.031, All_Time = 2071.841
70750/758000 (epoch 186), train_loss = 0.253, time/batch = 0.029, All_Time = 2073.318
70800/758000 (epoch 186), train_loss = 0.219, time/batch = 0.030, All_Time = 2074.784
70850/758000 (epoch 186), train_loss = 0.301, time/batch = 0.030, All_Time = 2076.246
70900/758000 (epoch 187), train_loss = 0.249, time/batch = 0.030, All_Time = 2077.720
70950/758000 (epoch 187), train_loss = 0.259, time/batch = 0.029, All_Time = 2079.192
71000/758000 (epoch 187), train_loss = 0.293, time/batch = 0.029, All_Time = 2080.653
model saved to NER/polyglot/model.ckpt
71050/758000 (epoch 187), train_loss = 0.270, time/batch = 0.028, All_Time = 2082.114
71100/758000 (epoch 187), train_loss = 0.230, time/batch = 0.029, All_Time = 2083.569
71150/758000 (epoch 187), train_loss = 0.247, time/batch = 0.029, All_Time = 2085.028
71200/758000 (epoch 187), train_loss = 0.259, time/batch = 0.030, All_Time = 2086.482
71250/758000 (epoch 187), train_loss = 0.257, time/batch = 0.029, All_Time = 2087.942
71300/758000 (epoch 188), train_loss = 0.269, time/batch = 0.029, All_Time = 2089.407
71350/758000 (epoch 188), train_loss = 0.291, time/batch = 0.029, All_Time = 2090.905
71400/758000 (epoch 188), train_loss = 0.251, time/batch = 0.030, All_Time = 2092.380
71450/758000 (epoch 188), train_loss = 0.265, time/batch = 0.029, All_Time = 2093.869
71500/758000 (epoch 188), train_loss = 0.255, time/batch = 0.030, All_Time = 2095.355
71550/758000 (epoch 188), train_loss = 0.251, time/batch = 0.029, All_Time = 2096.838
71600/758000 (epoch 188), train_loss = 0.264, time/batch = 0.029, All_Time = 2098.309
71650/758000 (epoch 189), train_loss = 0.232, time/batch = 0.031, All_Time = 2099.779
71700/758000 (epoch 189), train_loss = 0.230, time/batch = 0.029, All_Time = 2101.247
71750/758000 (epoch 189), train_loss = 0.249, time/batch = 0.030, All_Time = 2102.708
71800/758000 (epoch 189), train_loss = 0.265, time/batch = 0.029, All_Time = 2104.170
71850/758000 (epoch 189), train_loss = 0.270, time/batch = 0.030, All_Time = 2105.735
71900/758000 (epoch 189), train_loss = 0.249, time/batch = 0.030, All_Time = 2107.240
71950/758000 (epoch 189), train_loss = 0.219, time/batch = 0.028, All_Time = 2108.729
72000/758000 (epoch 189), train_loss = 0.247, time/batch = 0.029, All_Time = 2110.211
model saved to NER/polyglot/model.ckpt
72050/758000 (epoch 190), train_loss = 0.247, time/batch = 0.030, All_Time = 2111.667
72100/758000 (epoch 190), train_loss = 0.236, time/batch = 0.029, All_Time = 2113.127
72150/758000 (epoch 190), train_loss = 0.274, time/batch = 0.029, All_Time = 2114.587
72200/758000 (epoch 190), train_loss = 0.252, time/batch = 0.028, All_Time = 2116.082
72250/758000 (epoch 190), train_loss = 0.260, time/batch = 0.031, All_Time = 2117.561
72300/758000 (epoch 190), train_loss = 0.262, time/batch = 0.030, All_Time = 2119.025
72350/758000 (epoch 190), train_loss = 0.256, time/batch = 0.029, All_Time = 2120.503
72400/758000 (epoch 191), train_loss = 0.222, time/batch = 0.029, All_Time = 2121.976
72450/758000 (epoch 191), train_loss = 0.251, time/batch = 0.031, All_Time = 2123.452
72500/758000 (epoch 191), train_loss = 0.258, time/batch = 0.029, All_Time = 2124.925
72550/758000 (epoch 191), train_loss = 0.250, time/batch = 0.030, All_Time = 2126.388
72600/758000 (epoch 191), train_loss = 0.252, time/batch = 0.029, All_Time = 2127.854
72650/758000 (epoch 191), train_loss = 0.247, time/batch = 0.028, All_Time = 2129.314
72700/758000 (epoch 191), train_loss = 0.242, time/batch = 0.028, All_Time = 2130.773
72750/758000 (epoch 191), train_loss = 0.266, time/batch = 0.029, All_Time = 2132.250
72800/758000 (epoch 192), train_loss = 0.262, time/batch = 0.029, All_Time = 2133.711
72850/758000 (epoch 192), train_loss = 0.265, time/batch = 0.030, All_Time = 2135.164
72900/758000 (epoch 192), train_loss = 0.255, time/batch = 0.031, All_Time = 2136.635
72950/758000 (epoch 192), train_loss = 0.237, time/batch = 0.030, All_Time = 2138.123
73000/758000 (epoch 192), train_loss = 0.235, time/batch = 0.029, All_Time = 2139.606
model saved to NER/polyglot/model.ckpt
73050/758000 (epoch 192), train_loss = 0.244, time/batch = 0.030, All_Time = 2141.079
73100/758000 (epoch 192), train_loss = 0.274, time/batch = 0.028, All_Time = 2142.543
73150/758000 (epoch 193), train_loss = 0.255, time/batch = 0.031, All_Time = 2144.019
73200/758000 (epoch 193), train_loss = 0.287, time/batch = 0.028, All_Time = 2145.484
73250/758000 (epoch 193), train_loss = 0.251, time/batch = 0.029, All_Time = 2146.940
73300/758000 (epoch 193), train_loss = 0.265, time/batch = 0.029, All_Time = 2148.408
73350/758000 (epoch 193), train_loss = 0.234, time/batch = 0.030, All_Time = 2149.892
73400/758000 (epoch 193), train_loss = 0.256, time/batch = 0.030, All_Time = 2151.390
73450/758000 (epoch 193), train_loss = 0.223, time/batch = 0.028, All_Time = 2152.859
73500/758000 (epoch 193), train_loss = 0.250, time/batch = 0.031, All_Time = 2154.330
73550/758000 (epoch 194), train_loss = 0.246, time/batch = 0.029, All_Time = 2155.815
73600/758000 (epoch 194), train_loss = 0.254, time/batch = 0.030, All_Time = 2157.282
73650/758000 (epoch 194), train_loss = 0.298, time/batch = 0.031, All_Time = 2158.770
73700/758000 (epoch 194), train_loss = 0.324, time/batch = 0.030, All_Time = 2160.251
73750/758000 (epoch 194), train_loss = 0.205, time/batch = 0.029, All_Time = 2161.743
73800/758000 (epoch 194), train_loss = 0.220, time/batch = 0.029, All_Time = 2163.234
73850/758000 (epoch 194), train_loss = 0.253, time/batch = 0.030, All_Time = 2164.706
73900/758000 (epoch 194), train_loss = 0.305, time/batch = 0.029, All_Time = 2166.189
73950/758000 (epoch 195), train_loss = 0.239, time/batch = 0.030, All_Time = 2167.665
74000/758000 (epoch 195), train_loss = 0.269, time/batch = 0.031, All_Time = 2169.126
model saved to NER/polyglot/model.ckpt
74050/758000 (epoch 195), train_loss = 0.229, time/batch = 0.030, All_Time = 2170.588
74100/758000 (epoch 195), train_loss = 0.253, time/batch = 0.030, All_Time = 2172.052
74150/758000 (epoch 195), train_loss = 0.224, time/batch = 0.030, All_Time = 2173.512
74200/758000 (epoch 195), train_loss = 0.251, time/batch = 0.030, All_Time = 2174.973
74250/758000 (epoch 195), train_loss = 0.225, time/batch = 0.029, All_Time = 2176.444
74300/758000 (epoch 196), train_loss = 0.237, time/batch = 0.028, All_Time = 2177.909
74350/758000 (epoch 196), train_loss = 0.261, time/batch = 0.030, All_Time = 2179.379
74400/758000 (epoch 196), train_loss = 0.272, time/batch = 0.034, All_Time = 2180.856
74450/758000 (epoch 196), train_loss = 0.227, time/batch = 0.030, All_Time = 2182.329
74500/758000 (epoch 196), train_loss = 0.238, time/batch = 0.031, All_Time = 2183.798
74550/758000 (epoch 196), train_loss = 0.281, time/batch = 0.032, All_Time = 2185.287
74600/758000 (epoch 196), train_loss = 0.244, time/batch = 0.031, All_Time = 2186.795
74650/758000 (epoch 196), train_loss = 0.278, time/batch = 0.030, All_Time = 2188.283
74700/758000 (epoch 197), train_loss = 0.259, time/batch = 0.031, All_Time = 2189.769
74750/758000 (epoch 197), train_loss = 0.257, time/batch = 0.028, All_Time = 2191.238
74800/758000 (epoch 197), train_loss = 0.247, time/batch = 0.029, All_Time = 2192.702
74850/758000 (epoch 197), train_loss = 0.257, time/batch = 0.029, All_Time = 2194.160
74900/758000 (epoch 197), train_loss = 0.245, time/batch = 0.033, All_Time = 2195.637
74950/758000 (epoch 197), train_loss = 0.259, time/batch = 0.030, All_Time = 2197.115
75000/758000 (epoch 197), train_loss = 0.255, time/batch = 0.028, All_Time = 2198.582
model saved to NER/polyglot/model.ckpt
75050/758000 (epoch 198), train_loss = 0.250, time/batch = 0.030, All_Time = 2200.056
75100/758000 (epoch 198), train_loss = 0.286, time/batch = 0.030, All_Time = 2201.529
75150/758000 (epoch 198), train_loss = 0.268, time/batch = 0.029, All_Time = 2203.009
75200/758000 (epoch 198), train_loss = 0.266, time/batch = 0.028, All_Time = 2204.494
75250/758000 (epoch 198), train_loss = 0.222, time/batch = 0.029, All_Time = 2205.959
75300/758000 (epoch 198), train_loss = 0.246, time/batch = 0.032, All_Time = 2207.515
75350/758000 (epoch 198), train_loss = 0.255, time/batch = 0.032, All_Time = 2209.068
75400/758000 (epoch 198), train_loss = 0.260, time/batch = 0.030, All_Time = 2210.576
75450/758000 (epoch 199), train_loss = 0.237, time/batch = 0.030, All_Time = 2212.046
75500/758000 (epoch 199), train_loss = 0.268, time/batch = 0.029, All_Time = 2213.507
75550/758000 (epoch 199), train_loss = 0.270, time/batch = 0.028, All_Time = 2214.978
75600/758000 (epoch 199), train_loss = 0.239, time/batch = 0.028, All_Time = 2216.448
75650/758000 (epoch 199), train_loss = 0.271, time/batch = 0.030, All_Time = 2217.927
75700/758000 (epoch 199), train_loss = 0.225, time/batch = 0.030, All_Time = 2219.404
75750/758000 (epoch 199), train_loss = 0.254, time/batch = 0.029, All_Time = 2220.882
75800/758000 (epoch 200), train_loss = 0.061, time/batch = 0.032, All_Time = 2222.355
75850/758000 (epoch 200), train_loss = 0.265, time/batch = 0.029, All_Time = 2223.826
75900/758000 (epoch 200), train_loss = 0.226, time/batch = 0.029, All_Time = 2225.292
75950/758000 (epoch 200), train_loss = 0.259, time/batch = 0.030, All_Time = 2226.758
76000/758000 (epoch 200), train_loss = 0.242, time/batch = 0.028, All_Time = 2228.229
model saved to NER/polyglot/model.ckpt
76050/758000 (epoch 200), train_loss = 0.264, time/batch = 0.028, All_Time = 2229.709
76100/758000 (epoch 200), train_loss = 0.241, time/batch = 0.030, All_Time = 2231.166
76150/758000 (epoch 200), train_loss = 0.241, time/batch = 0.028, All_Time = 2232.639
76200/758000 (epoch 201), train_loss = 0.237, time/batch = 0.029, All_Time = 2234.113
76250/758000 (epoch 201), train_loss = 0.239, time/batch = 0.029, All_Time = 2235.580
76300/758000 (epoch 201), train_loss = 0.231, time/batch = 0.029, All_Time = 2237.055
76350/758000 (epoch 201), train_loss = 0.264, time/batch = 0.029, All_Time = 2238.530
76400/758000 (epoch 201), train_loss = 0.228, time/batch = 0.030, All_Time = 2240.009
76450/758000 (epoch 201), train_loss = 0.235, time/batch = 0.029, All_Time = 2241.472
76500/758000 (epoch 201), train_loss = 0.290, time/batch = 0.029, All_Time = 2242.979
76550/758000 (epoch 201), train_loss = 0.281, time/batch = 0.030, All_Time = 2244.475
76600/758000 (epoch 202), train_loss = 0.239, time/batch = 0.029, All_Time = 2245.956
76650/758000 (epoch 202), train_loss = 0.231, time/batch = 0.030, All_Time = 2247.430
76700/758000 (epoch 202), train_loss = 0.208, time/batch = 0.030, All_Time = 2248.959
76750/758000 (epoch 202), train_loss = 0.276, time/batch = 0.030, All_Time = 2250.462
76800/758000 (epoch 202), train_loss = 0.266, time/batch = 0.029, All_Time = 2251.947
76850/758000 (epoch 202), train_loss = 0.217, time/batch = 0.030, All_Time = 2253.406
76900/758000 (epoch 202), train_loss = 0.225, time/batch = 0.030, All_Time = 2254.862
76950/758000 (epoch 203), train_loss = 0.233, time/batch = 0.029, All_Time = 2256.334
77000/758000 (epoch 203), train_loss = 0.293, time/batch = 0.031, All_Time = 2257.800
model saved to NER/polyglot/model.ckpt
77050/758000 (epoch 203), train_loss = 0.237, time/batch = 0.030, All_Time = 2259.277
77100/758000 (epoch 203), train_loss = 0.318, time/batch = 0.028, All_Time = 2260.743
77150/758000 (epoch 203), train_loss = 0.228, time/batch = 0.030, All_Time = 2262.197
77200/758000 (epoch 203), train_loss = 0.220, time/batch = 0.029, All_Time = 2263.675
77250/758000 (epoch 203), train_loss = 0.256, time/batch = 0.030, All_Time = 2265.171
77300/758000 (epoch 203), train_loss = 0.259, time/batch = 0.030, All_Time = 2266.645
77350/758000 (epoch 204), train_loss = 0.271, time/batch = 0.031, All_Time = 2268.131
77400/758000 (epoch 204), train_loss = 0.236, time/batch = 0.031, All_Time = 2269.602
77450/758000 (epoch 204), train_loss = 0.245, time/batch = 0.031, All_Time = 2271.059
77500/758000 (epoch 204), train_loss = 0.274, time/batch = 0.029, All_Time = 2272.527
77550/758000 (epoch 204), train_loss = 0.255, time/batch = 0.029, All_Time = 2274.003
77600/758000 (epoch 204), train_loss = 0.241, time/batch = 0.029, All_Time = 2275.472
77650/758000 (epoch 204), train_loss = 0.285, time/batch = 0.029, All_Time = 2276.943
77700/758000 (epoch 205), train_loss = 0.260, time/batch = 0.029, All_Time = 2278.423
77750/758000 (epoch 205), train_loss = 0.228, time/batch = 0.030, All_Time = 2279.897
77800/758000 (epoch 205), train_loss = 0.275, time/batch = 0.028, All_Time = 2281.399
77850/758000 (epoch 205), train_loss = 0.222, time/batch = 0.030, All_Time = 2282.881
77900/758000 (epoch 205), train_loss = 0.230, time/batch = 0.028, All_Time = 2284.350
77950/758000 (epoch 205), train_loss = 0.267, time/batch = 0.029, All_Time = 2285.824
78000/758000 (epoch 205), train_loss = 0.243, time/batch = 0.029, All_Time = 2287.294
model saved to NER/polyglot/model.ckpt
78050/758000 (epoch 205), train_loss = 0.274, time/batch = 0.030, All_Time = 2288.757
78100/758000 (epoch 206), train_loss = 0.230, time/batch = 0.030, All_Time = 2290.233
78150/758000 (epoch 206), train_loss = 0.239, time/batch = 0.028, All_Time = 2291.699
78200/758000 (epoch 206), train_loss = 0.241, time/batch = 0.030, All_Time = 2293.158
78250/758000 (epoch 206), train_loss = 0.268, time/batch = 0.031, All_Time = 2294.639
78300/758000 (epoch 206), train_loss = 0.246, time/batch = 0.030, All_Time = 2296.130
78350/758000 (epoch 206), train_loss = 0.231, time/batch = 0.029, All_Time = 2297.607
78400/758000 (epoch 206), train_loss = 0.280, time/batch = 0.029, All_Time = 2299.068
78450/758000 (epoch 206), train_loss = 0.244, time/batch = 0.029, All_Time = 2300.542
78500/758000 (epoch 207), train_loss = 0.292, time/batch = 0.029, All_Time = 2302.011
78550/758000 (epoch 207), train_loss = 0.264, time/batch = 0.030, All_Time = 2303.499
78600/758000 (epoch 207), train_loss = 0.250, time/batch = 0.030, All_Time = 2304.970
78650/758000 (epoch 207), train_loss = 0.237, time/batch = 0.030, All_Time = 2306.492
78700/758000 (epoch 207), train_loss = 0.224, time/batch = 0.031, All_Time = 2307.975
78750/758000 (epoch 207), train_loss = 0.232, time/batch = 0.030, All_Time = 2309.460
78800/758000 (epoch 207), train_loss = 0.227, time/batch = 0.029, All_Time = 2310.932
78850/758000 (epoch 208), train_loss = 0.253, time/batch = 0.029, All_Time = 2312.419
78900/758000 (epoch 208), train_loss = 0.217, time/batch = 0.034, All_Time = 2313.888
78950/758000 (epoch 208), train_loss = 0.251, time/batch = 0.029, All_Time = 2315.352
79000/758000 (epoch 208), train_loss = 0.221, time/batch = 0.029, All_Time = 2316.826
model saved to NER/polyglot/model.ckpt
79050/758000 (epoch 208), train_loss = 0.239, time/batch = 0.029, All_Time = 2318.296
79100/758000 (epoch 208), train_loss = 0.233, time/batch = 0.030, All_Time = 2319.763
79150/758000 (epoch 208), train_loss = 0.255, time/batch = 0.030, All_Time = 2321.230
79200/758000 (epoch 208), train_loss = 0.234, time/batch = 0.029, All_Time = 2322.705
79250/758000 (epoch 209), train_loss = 0.230, time/batch = 0.030, All_Time = 2324.203
79300/758000 (epoch 209), train_loss = 0.241, time/batch = 0.029, All_Time = 2325.677
79350/758000 (epoch 209), train_loss = 0.217, time/batch = 0.029, All_Time = 2327.152
79400/758000 (epoch 209), train_loss = 0.275, time/batch = 0.032, All_Time = 2328.618
79450/758000 (epoch 209), train_loss = 0.261, time/batch = 0.029, All_Time = 2330.097
79500/758000 (epoch 209), train_loss = 0.237, time/batch = 0.029, All_Time = 2331.562
79550/758000 (epoch 209), train_loss = 0.269, time/batch = 0.029, All_Time = 2333.026
79600/758000 (epoch 210), train_loss = 0.283, time/batch = 0.028, All_Time = 2334.478
79650/758000 (epoch 210), train_loss = 0.299, time/batch = 0.030, All_Time = 2335.948
79700/758000 (epoch 210), train_loss = 0.263, time/batch = 0.029, All_Time = 2337.452
79750/758000 (epoch 210), train_loss = 0.222, time/batch = 0.031, All_Time = 2338.927
79800/758000 (epoch 210), train_loss = 0.226, time/batch = 0.031, All_Time = 2340.407
79850/758000 (epoch 210), train_loss = 0.264, time/batch = 0.031, All_Time = 2341.877
79900/758000 (epoch 210), train_loss = 0.248, time/batch = 0.029, All_Time = 2343.351
79950/758000 (epoch 210), train_loss = 0.249, time/batch = 0.028, All_Time = 2344.820
80000/758000 (epoch 211), train_loss = 0.214, time/batch = 0.031, All_Time = 2346.298
model saved to NER/polyglot/model.ckpt
80050/758000 (epoch 211), train_loss = 0.278, time/batch = 0.030, All_Time = 2347.764
80100/758000 (epoch 211), train_loss = 0.235, time/batch = 0.030, All_Time = 2349.237
80150/758000 (epoch 211), train_loss = 0.240, time/batch = 0.029, All_Time = 2351.101
80200/758000 (epoch 211), train_loss = 0.235, time/batch = 0.029, All_Time = 2352.563
80250/758000 (epoch 211), train_loss = 0.261, time/batch = 0.031, All_Time = 2354.023
80300/758000 (epoch 211), train_loss = 0.267, time/batch = 0.029, All_Time = 2355.525
80350/758000 (epoch 212), train_loss = 0.200, time/batch = 0.030, All_Time = 2357.009
80400/758000 (epoch 212), train_loss = 0.262, time/batch = 0.029, All_Time = 2358.481
80450/758000 (epoch 212), train_loss = 0.285, time/batch = 0.029, All_Time = 2359.948
80500/758000 (epoch 212), train_loss = 0.243, time/batch = 0.029, All_Time = 2361.413
80550/758000 (epoch 212), train_loss = 0.253, time/batch = 0.030, All_Time = 2362.873
80600/758000 (epoch 212), train_loss = 0.253, time/batch = 0.029, All_Time = 2364.332
80650/758000 (epoch 212), train_loss = 0.206, time/batch = 0.029, All_Time = 2365.830
80700/758000 (epoch 212), train_loss = 0.278, time/batch = 0.029, All_Time = 2367.327
80750/758000 (epoch 213), train_loss = 0.238, time/batch = 0.029, All_Time = 2368.860
80800/758000 (epoch 213), train_loss = 0.245, time/batch = 0.030, All_Time = 2370.331
80850/758000 (epoch 213), train_loss = 0.254, time/batch = 0.031, All_Time = 2371.797
80900/758000 (epoch 213), train_loss = 0.263, time/batch = 0.029, All_Time = 2373.258
80950/758000 (epoch 213), train_loss = 0.249, time/batch = 0.028, All_Time = 2374.723
81000/758000 (epoch 213), train_loss = 0.247, time/batch = 0.030, All_Time = 2376.182
model saved to NER/polyglot/model.ckpt
81050/758000 (epoch 213), train_loss = 0.250, time/batch = 0.031, All_Time = 2377.655
81100/758000 (epoch 213), train_loss = 0.292, time/batch = 0.029, All_Time = 2379.147
81150/758000 (epoch 214), train_loss = 0.211, time/batch = 0.030, All_Time = 2380.631
81200/758000 (epoch 214), train_loss = 0.251, time/batch = 0.029, All_Time = 2382.111
81250/758000 (epoch 214), train_loss = 0.222, time/batch = 0.030, All_Time = 2383.593
81300/758000 (epoch 214), train_loss = 0.241, time/batch = 0.030, All_Time = 2385.068
81350/758000 (epoch 214), train_loss = 0.265, time/batch = 0.030, All_Time = 2386.533
81400/758000 (epoch 214), train_loss = 0.258, time/batch = 0.031, All_Time = 2388.010
81450/758000 (epoch 214), train_loss = 0.241, time/batch = 0.029, All_Time = 2389.480
81500/758000 (epoch 215), train_loss = 0.230, time/batch = 0.029, All_Time = 2390.954
81550/758000 (epoch 215), train_loss = 0.255, time/batch = 0.030, All_Time = 2392.427
81600/758000 (epoch 215), train_loss = 0.251, time/batch = 0.029, All_Time = 2393.897
81650/758000 (epoch 215), train_loss = 0.228, time/batch = 0.030, All_Time = 2395.375
81700/758000 (epoch 215), train_loss = 0.243, time/batch = 0.029, All_Time = 2396.847
81750/758000 (epoch 215), train_loss = 0.252, time/batch = 0.029, All_Time = 2398.319
81800/758000 (epoch 215), train_loss = 0.249, time/batch = 0.030, All_Time = 2399.784
81850/758000 (epoch 215), train_loss = 0.262, time/batch = 0.031, All_Time = 2401.274
81900/758000 (epoch 216), train_loss = 0.270, time/batch = 0.029, All_Time = 2402.760
81950/758000 (epoch 216), train_loss = 0.227, time/batch = 0.029, All_Time = 2404.230
82000/758000 (epoch 216), train_loss = 0.256, time/batch = 0.030, All_Time = 2405.703
model saved to NER/polyglot/model.ckpt
82050/758000 (epoch 216), train_loss = 0.231, time/batch = 0.028, All_Time = 2407.170
82100/758000 (epoch 216), train_loss = 0.284, time/batch = 0.029, All_Time = 2408.632
82150/758000 (epoch 216), train_loss = 0.262, time/batch = 0.030, All_Time = 2410.100
82200/758000 (epoch 216), train_loss = 0.258, time/batch = 0.029, All_Time = 2411.561
82250/758000 (epoch 217), train_loss = 0.247, time/batch = 0.028, All_Time = 2413.062
82300/758000 (epoch 217), train_loss = 0.253, time/batch = 0.029, All_Time = 2414.556
82350/758000 (epoch 217), train_loss = 0.278, time/batch = 0.031, All_Time = 2416.034
82400/758000 (epoch 217), train_loss = 0.252, time/batch = 0.029, All_Time = 2417.504
82450/758000 (epoch 217), train_loss = 0.243, time/batch = 0.030, All_Time = 2418.979
82500/758000 (epoch 217), train_loss = 0.228, time/batch = 0.028, All_Time = 2420.451
82550/758000 (epoch 217), train_loss = 0.232, time/batch = 0.029, All_Time = 2421.919
82600/758000 (epoch 217), train_loss = 0.251, time/batch = 0.030, All_Time = 2423.391
82650/758000 (epoch 218), train_loss = 0.253, time/batch = 0.031, All_Time = 2424.863
82700/758000 (epoch 218), train_loss = 0.267, time/batch = 0.029, All_Time = 2426.316
82750/758000 (epoch 218), train_loss = 0.243, time/batch = 0.029, All_Time = 2427.780
82800/758000 (epoch 218), train_loss = 0.259, time/batch = 0.030, All_Time = 2429.279
82850/758000 (epoch 218), train_loss = 0.230, time/batch = 0.029, All_Time = 2430.760
82900/758000 (epoch 218), train_loss = 0.220, time/batch = 0.029, All_Time = 2432.235
82950/758000 (epoch 218), train_loss = 0.281, time/batch = 0.029, All_Time = 2433.712
83000/758000 (epoch 218), train_loss = 0.266, time/batch = 0.030, All_Time = 2435.197
model saved to NER/polyglot/model.ckpt
83050/758000 (epoch 219), train_loss = 0.276, time/batch = 0.029, All_Time = 2436.666
83100/758000 (epoch 219), train_loss = 0.300, time/batch = 0.030, All_Time = 2438.123
83150/758000 (epoch 219), train_loss = 0.231, time/batch = 0.029, All_Time = 2439.581
83200/758000 (epoch 219), train_loss = 0.226, time/batch = 0.030, All_Time = 2441.033
83250/758000 (epoch 219), train_loss = 0.264, time/batch = 0.030, All_Time = 2442.493
83300/758000 (epoch 219), train_loss = 0.261, time/batch = 0.032, All_Time = 2443.974
83350/758000 (epoch 219), train_loss = 0.244, time/batch = 0.029, All_Time = 2445.432
83400/758000 (epoch 220), train_loss = 0.229, time/batch = 0.030, All_Time = 2446.912
83450/758000 (epoch 220), train_loss = 0.238, time/batch = 0.029, All_Time = 2448.386
83500/758000 (epoch 220), train_loss = 0.247, time/batch = 0.028, All_Time = 2449.846
83550/758000 (epoch 220), train_loss = 0.236, time/batch = 0.030, All_Time = 2451.315
83600/758000 (epoch 220), train_loss = 0.227, time/batch = 0.030, All_Time = 2452.794
83650/758000 (epoch 220), train_loss = 0.243, time/batch = 0.030, All_Time = 2454.266
83700/758000 (epoch 220), train_loss = 0.270, time/batch = 0.032, All_Time = 2455.744
83750/758000 (epoch 220), train_loss = 0.246, time/batch = 0.031, All_Time = 2457.216
83800/758000 (epoch 221), train_loss = 0.260, time/batch = 0.030, All_Time = 2458.699
83850/758000 (epoch 221), train_loss = 0.293, time/batch = 0.030, All_Time = 2460.170
83900/758000 (epoch 221), train_loss = 0.263, time/batch = 0.030, All_Time = 2461.642
83950/758000 (epoch 221), train_loss = 0.254, time/batch = 0.030, All_Time = 2463.111
84000/758000 (epoch 221), train_loss = 0.216, time/batch = 0.029, All_Time = 2464.580
model saved to NER/polyglot/model.ckpt
84050/758000 (epoch 221), train_loss = 0.233, time/batch = 0.031, All_Time = 2466.053
84100/758000 (epoch 221), train_loss = 0.275, time/batch = 0.029, All_Time = 2467.510
84150/758000 (epoch 222), train_loss = 0.253, time/batch = 0.030, All_Time = 2468.994
84200/758000 (epoch 222), train_loss = 0.232, time/batch = 0.029, All_Time = 2470.469
84250/758000 (epoch 222), train_loss = 0.276, time/batch = 0.030, All_Time = 2471.941
84300/758000 (epoch 222), train_loss = 0.246, time/batch = 0.029, All_Time = 2473.419
84350/758000 (epoch 222), train_loss = 0.251, time/batch = 0.029, All_Time = 2474.880
84400/758000 (epoch 222), train_loss = 0.243, time/batch = 0.030, All_Time = 2476.352
84450/758000 (epoch 222), train_loss = 0.280, time/batch = 0.029, All_Time = 2477.830
84500/758000 (epoch 222), train_loss = 0.284, time/batch = 0.030, All_Time = 2479.305
84550/758000 (epoch 223), train_loss = 0.242, time/batch = 0.028, All_Time = 2480.778
84600/758000 (epoch 223), train_loss = 0.249, time/batch = 0.030, All_Time = 2482.236
84650/758000 (epoch 223), train_loss = 0.300, time/batch = 0.029, All_Time = 2483.702
84700/758000 (epoch 223), train_loss = 0.234, time/batch = 0.030, All_Time = 2485.176
84750/758000 (epoch 223), train_loss = 0.218, time/batch = 0.029, All_Time = 2486.635
84800/758000 (epoch 223), train_loss = 0.247, time/batch = 0.029, All_Time = 2488.096
84850/758000 (epoch 223), train_loss = 0.279, time/batch = 0.028, All_Time = 2489.571
84900/758000 (epoch 224), train_loss = 0.222, time/batch = 0.030, All_Time = 2491.062
84950/758000 (epoch 224), train_loss = 0.260, time/batch = 0.029, All_Time = 2492.539
85000/758000 (epoch 224), train_loss = 0.247, time/batch = 0.028, All_Time = 2494.010
model saved to NER/polyglot/model.ckpt
85050/758000 (epoch 224), train_loss = 0.243, time/batch = 0.029, All_Time = 2495.485
85100/758000 (epoch 224), train_loss = 0.258, time/batch = 0.029, All_Time = 2496.960
85150/758000 (epoch 224), train_loss = 0.224, time/batch = 0.030, All_Time = 2498.415
85200/758000 (epoch 224), train_loss = 0.228, time/batch = 0.030, All_Time = 2499.879
85250/758000 (epoch 224), train_loss = 0.262, time/batch = 0.029, All_Time = 2501.351
85300/758000 (epoch 225), train_loss = 0.260, time/batch = 0.029, All_Time = 2502.835
85350/758000 (epoch 225), train_loss = 0.271, time/batch = 0.029, All_Time = 2504.289
85400/758000 (epoch 225), train_loss = 0.274, time/batch = 0.029, All_Time = 2505.736
85450/758000 (epoch 225), train_loss = 0.230, time/batch = 0.029, All_Time = 2507.212
85500/758000 (epoch 225), train_loss = 0.237, time/batch = 0.030, All_Time = 2508.715
85550/758000 (epoch 225), train_loss = 0.248, time/batch = 0.030, All_Time = 2510.176
85600/758000 (epoch 225), train_loss = 0.284, time/batch = 0.029, All_Time = 2511.641
85650/758000 (epoch 225), train_loss = 0.243, time/batch = 0.029, All_Time = 2513.121
85700/758000 (epoch 226), train_loss = 0.239, time/batch = 0.029, All_Time = 2514.586
85750/758000 (epoch 226), train_loss = 0.238, time/batch = 0.033, All_Time = 2516.063
85800/758000 (epoch 226), train_loss = 0.237, time/batch = 0.032, All_Time = 2517.659
85850/758000 (epoch 226), train_loss = 0.277, time/batch = 0.029, All_Time = 2519.195
85900/758000 (epoch 226), train_loss = 0.210, time/batch = 0.030, All_Time = 2520.706
85950/758000 (epoch 226), train_loss = 0.267, time/batch = 0.030, All_Time = 2522.226
86000/758000 (epoch 226), train_loss = 0.239, time/batch = 0.029, All_Time = 2523.720
model saved to NER/polyglot/model.ckpt
86050/758000 (epoch 227), train_loss = 0.247, time/batch = 0.030, All_Time = 2525.197
86100/758000 (epoch 227), train_loss = 0.228, time/batch = 0.031, All_Time = 2526.655
86150/758000 (epoch 227), train_loss = 0.244, time/batch = 0.032, All_Time = 2528.119
86200/758000 (epoch 227), train_loss = 0.256, time/batch = 0.030, All_Time = 2529.568
86250/758000 (epoch 227), train_loss = 0.217, time/batch = 0.029, All_Time = 2531.024
86300/758000 (epoch 227), train_loss = 0.274, time/batch = 0.029, All_Time = 2532.501
86350/758000 (epoch 227), train_loss = 0.214, time/batch = 0.030, All_Time = 2533.976
86400/758000 (epoch 227), train_loss = 0.256, time/batch = 0.030, All_Time = 2535.453
86450/758000 (epoch 228), train_loss = 0.253, time/batch = 0.029, All_Time = 2536.941
86500/758000 (epoch 228), train_loss = 0.234, time/batch = 0.029, All_Time = 2538.422
86550/758000 (epoch 228), train_loss = 0.222, time/batch = 0.029, All_Time = 2539.901
86600/758000 (epoch 228), train_loss = 0.222, time/batch = 0.030, All_Time = 2541.367
86650/758000 (epoch 228), train_loss = 0.252, time/batch = 0.029, All_Time = 2542.847
86700/758000 (epoch 228), train_loss = 0.210, time/batch = 0.028, All_Time = 2544.327
86750/758000 (epoch 228), train_loss = 0.271, time/batch = 0.029, All_Time = 2545.795
86800/758000 (epoch 229), train_loss = 0.258, time/batch = 0.030, All_Time = 2547.283
86850/758000 (epoch 229), train_loss = 0.267, time/batch = 0.030, All_Time = 2548.762
86900/758000 (epoch 229), train_loss = 0.285, time/batch = 0.030, All_Time = 2550.252
86950/758000 (epoch 229), train_loss = 0.241, time/batch = 0.028, All_Time = 2551.731
87000/758000 (epoch 229), train_loss = 0.270, time/batch = 0.028, All_Time = 2553.195
model saved to NER/polyglot/model.ckpt
87050/758000 (epoch 229), train_loss = 0.260, time/batch = 0.029, All_Time = 2554.658
87100/758000 (epoch 229), train_loss = 0.239, time/batch = 0.030, All_Time = 2556.127
87150/758000 (epoch 229), train_loss = 0.275, time/batch = 0.030, All_Time = 2557.601
87200/758000 (epoch 230), train_loss = 0.230, time/batch = 0.030, All_Time = 2559.075
87250/758000 (epoch 230), train_loss = 0.224, time/batch = 0.030, All_Time = 2560.558
87300/758000 (epoch 230), train_loss = 0.264, time/batch = 0.029, All_Time = 2562.079
87350/758000 (epoch 230), train_loss = 0.257, time/batch = 0.030, All_Time = 2563.567
87400/758000 (epoch 230), train_loss = 0.227, time/batch = 0.029, All_Time = 2565.042
87450/758000 (epoch 230), train_loss = 0.245, time/batch = 0.030, All_Time = 2566.517
87500/758000 (epoch 230), train_loss = 0.255, time/batch = 0.031, All_Time = 2567.995
87550/758000 (epoch 231), train_loss = 0.194, time/batch = 0.030, All_Time = 2569.475
87600/758000 (epoch 231), train_loss = 0.278, time/batch = 0.028, All_Time = 2570.947
87650/758000 (epoch 231), train_loss = 0.220, time/batch = 0.030, All_Time = 2572.417
87700/758000 (epoch 231), train_loss = 0.245, time/batch = 0.030, All_Time = 2573.889
87750/758000 (epoch 231), train_loss = 0.224, time/batch = 0.030, All_Time = 2575.424
87800/758000 (epoch 231), train_loss = 0.223, time/batch = 0.030, All_Time = 2576.911
87850/758000 (epoch 231), train_loss = 0.255, time/batch = 0.029, All_Time = 2578.404
87900/758000 (epoch 231), train_loss = 0.275, time/batch = 0.030, All_Time = 2579.877
87950/758000 (epoch 232), train_loss = 0.224, time/batch = 0.030, All_Time = 2581.351
88000/758000 (epoch 232), train_loss = 0.282, time/batch = 0.029, All_Time = 2582.812
model saved to NER/polyglot/model.ckpt
88050/758000 (epoch 232), train_loss = 0.243, time/batch = 0.029, All_Time = 2584.282
88100/758000 (epoch 232), train_loss = 0.275, time/batch = 0.027, All_Time = 2585.749
88150/758000 (epoch 232), train_loss = 0.265, time/batch = 0.030, All_Time = 2587.239
88200/758000 (epoch 232), train_loss = 0.200, time/batch = 0.029, All_Time = 2588.731
88250/758000 (epoch 232), train_loss = 0.236, time/batch = 0.029, All_Time = 2590.196
88300/758000 (epoch 232), train_loss = 0.285, time/batch = 0.030, All_Time = 2591.679
88350/758000 (epoch 233), train_loss = 0.249, time/batch = 0.029, All_Time = 2593.159
88400/758000 (epoch 233), train_loss = 0.214, time/batch = 0.028, All_Time = 2594.626
88450/758000 (epoch 233), train_loss = 0.259, time/batch = 0.030, All_Time = 2596.093
88500/758000 (epoch 233), train_loss = 0.274, time/batch = 0.030, All_Time = 2597.564
88550/758000 (epoch 233), train_loss = 0.205, time/batch = 0.029, All_Time = 2599.074
88600/758000 (epoch 233), train_loss = 0.229, time/batch = 0.029, All_Time = 2600.550
88650/758000 (epoch 233), train_loss = 0.257, time/batch = 0.030, All_Time = 2602.023
88700/758000 (epoch 234), train_loss = 0.221, time/batch = 0.031, All_Time = 2603.498
88750/758000 (epoch 234), train_loss = 0.271, time/batch = 0.030, All_Time = 2604.961
88800/758000 (epoch 234), train_loss = 0.231, time/batch = 0.029, All_Time = 2606.435
88850/758000 (epoch 234), train_loss = 0.215, time/batch = 0.029, All_Time = 2607.901
88900/758000 (epoch 234), train_loss = 0.225, time/batch = 0.029, All_Time = 2609.367
88950/758000 (epoch 234), train_loss = 0.215, time/batch = 0.029, All_Time = 2610.845
89000/758000 (epoch 234), train_loss = 0.233, time/batch = 0.028, All_Time = 2612.314
model saved to NER/polyglot/model.ckpt
89050/758000 (epoch 234), train_loss = 0.225, time/batch = 0.029, All_Time = 2613.785
89100/758000 (epoch 235), train_loss = 0.278, time/batch = 0.029, All_Time = 2615.254
89150/758000 (epoch 235), train_loss = 0.231, time/batch = 0.031, All_Time = 2616.730
89200/758000 (epoch 235), train_loss = 0.274, time/batch = 0.029, All_Time = 2618.194
89250/758000 (epoch 235), train_loss = 0.275, time/batch = 0.029, All_Time = 2619.648
89300/758000 (epoch 235), train_loss = 0.235, time/batch = 0.031, All_Time = 2621.139
89350/758000 (epoch 235), train_loss = 0.269, time/batch = 0.029, All_Time = 2622.629
89400/758000 (epoch 235), train_loss = 0.280, time/batch = 0.029, All_Time = 2624.119
89450/758000 (epoch 236), train_loss = 0.240, time/batch = 0.029, All_Time = 2625.612
89500/758000 (epoch 236), train_loss = 0.221, time/batch = 0.029, All_Time = 2627.088
89550/758000 (epoch 236), train_loss = 0.246, time/batch = 0.030, All_Time = 2628.566
89600/758000 (epoch 236), train_loss = 0.246, time/batch = 0.030, All_Time = 2630.045
89650/758000 (epoch 236), train_loss = 0.245, time/batch = 0.029, All_Time = 2631.522
89700/758000 (epoch 236), train_loss = 0.248, time/batch = 0.031, All_Time = 2632.983
89750/758000 (epoch 236), train_loss = 0.215, time/batch = 0.029, All_Time = 2634.453
89800/758000 (epoch 236), train_loss = 0.293, time/batch = 0.033, All_Time = 2635.931
89850/758000 (epoch 237), train_loss = 0.240, time/batch = 0.029, All_Time = 2637.404
89900/758000 (epoch 237), train_loss = 0.249, time/batch = 0.028, All_Time = 2638.874
89950/758000 (epoch 237), train_loss = 0.289, time/batch = 0.030, All_Time = 2640.340
90000/758000 (epoch 237), train_loss = 0.261, time/batch = 0.029, All_Time = 2641.818
model saved to NER/polyglot/model.ckpt
90050/758000 (epoch 237), train_loss = 0.221, time/batch = 0.030, All_Time = 2643.280
90100/758000 (epoch 237), train_loss = 0.240, time/batch = 0.029, All_Time = 2644.746
90150/758000 (epoch 237), train_loss = 0.253, time/batch = 0.030, All_Time = 2646.219
90200/758000 (epoch 237), train_loss = 0.253, time/batch = 0.031, All_Time = 2647.708
90250/758000 (epoch 238), train_loss = 0.255, time/batch = 0.031, All_Time = 2649.196
90300/758000 (epoch 238), train_loss = 0.282, time/batch = 0.029, All_Time = 2650.688
90350/758000 (epoch 238), train_loss = 0.244, time/batch = 0.030, All_Time = 2652.150
90400/758000 (epoch 238), train_loss = 0.253, time/batch = 0.031, All_Time = 2653.626
90450/758000 (epoch 238), train_loss = 0.242, time/batch = 0.029, All_Time = 2655.099
90500/758000 (epoch 238), train_loss = 0.243, time/batch = 0.031, All_Time = 2656.560
90550/758000 (epoch 238), train_loss = 0.255, time/batch = 0.032, All_Time = 2658.034
90600/758000 (epoch 239), train_loss = 0.223, time/batch = 0.032, All_Time = 2659.519
90650/758000 (epoch 239), train_loss = 0.221, time/batch = 0.029, All_Time = 2660.984
90700/758000 (epoch 239), train_loss = 0.247, time/batch = 0.031, All_Time = 2662.451
90750/758000 (epoch 239), train_loss = 0.263, time/batch = 0.029, All_Time = 2663.924
90800/758000 (epoch 239), train_loss = 0.262, time/batch = 0.030, All_Time = 2665.389
90850/758000 (epoch 239), train_loss = 0.243, time/batch = 0.031, All_Time = 2666.857
90900/758000 (epoch 239), train_loss = 0.212, time/batch = 0.031, All_Time = 2668.320
90950/758000 (epoch 239), train_loss = 0.241, time/batch = 0.029, All_Time = 2669.799
91000/758000 (epoch 240), train_loss = 0.232, time/batch = 0.030, All_Time = 2671.277
model saved to NER/polyglot/model.ckpt
91050/758000 (epoch 240), train_loss = 0.228, time/batch = 0.028, All_Time = 2672.736
91100/758000 (epoch 240), train_loss = 0.267, time/batch = 0.032, All_Time = 2674.198
91150/758000 (epoch 240), train_loss = 0.243, time/batch = 0.030, All_Time = 2675.659
91200/758000 (epoch 240), train_loss = 0.255, time/batch = 0.031, All_Time = 2677.126
91250/758000 (epoch 240), train_loss = 0.253, time/batch = 0.028, All_Time = 2678.599
91300/758000 (epoch 240), train_loss = 0.252, time/batch = 0.029, All_Time = 2680.066
91350/758000 (epoch 241), train_loss = 0.217, time/batch = 0.029, All_Time = 2681.536
91400/758000 (epoch 241), train_loss = 0.237, time/batch = 0.029, All_Time = 2683.010
91450/758000 (epoch 241), train_loss = 0.253, time/batch = 0.032, All_Time = 2684.481
91500/758000 (epoch 241), train_loss = 0.243, time/batch = 0.029, All_Time = 2685.951
91550/758000 (epoch 241), train_loss = 0.245, time/batch = 0.028, All_Time = 2687.420
91600/758000 (epoch 241), train_loss = 0.242, time/batch = 0.030, All_Time = 2688.895
91650/758000 (epoch 241), train_loss = 0.233, time/batch = 0.030, All_Time = 2690.373
91700/758000 (epoch 241), train_loss = 0.261, time/batch = 0.031, All_Time = 2691.860
91750/758000 (epoch 242), train_loss = 0.252, time/batch = 0.030, All_Time = 2693.366
91800/758000 (epoch 242), train_loss = 0.255, time/batch = 0.028, All_Time = 2694.841
91850/758000 (epoch 242), train_loss = 0.247, time/batch = 0.029, All_Time = 2696.318
91900/758000 (epoch 242), train_loss = 0.233, time/batch = 0.030, All_Time = 2697.787
91950/758000 (epoch 242), train_loss = 0.230, time/batch = 0.030, All_Time = 2699.265
92000/758000 (epoch 242), train_loss = 0.239, time/batch = 0.031, All_Time = 2700.735
model saved to NER/polyglot/model.ckpt
92050/758000 (epoch 242), train_loss = 0.269, time/batch = 0.029, All_Time = 2702.199
92100/758000 (epoch 243), train_loss = 0.250, time/batch = 0.030, All_Time = 2703.671
92150/758000 (epoch 243), train_loss = 0.282, time/batch = 0.030, All_Time = 2705.146
92200/758000 (epoch 243), train_loss = 0.244, time/batch = 0.030, All_Time = 2706.635
92250/758000 (epoch 243), train_loss = 0.260, time/batch = 0.029, All_Time = 2708.131
92300/758000 (epoch 243), train_loss = 0.226, time/batch = 0.031, All_Time = 2709.615
92350/758000 (epoch 243), train_loss = 0.247, time/batch = 0.030, All_Time = 2711.116
92400/758000 (epoch 243), train_loss = 0.219, time/batch = 0.030, All_Time = 2712.603
92450/758000 (epoch 243), train_loss = 0.237, time/batch = 0.030, All_Time = 2714.087
92500/758000 (epoch 244), train_loss = 0.239, time/batch = 0.030, All_Time = 2715.570
92550/758000 (epoch 244), train_loss = 0.242, time/batch = 0.030, All_Time = 2717.042
92600/758000 (epoch 244), train_loss = 0.294, time/batch = 0.031, All_Time = 2718.521
92650/758000 (epoch 244), train_loss = 0.320, time/batch = 0.029, All_Time = 2719.990
92700/758000 (epoch 244), train_loss = 0.198, time/batch = 0.029, All_Time = 2721.467
92750/758000 (epoch 244), train_loss = 0.215, time/batch = 0.028, All_Time = 2722.940
92800/758000 (epoch 244), train_loss = 0.251, time/batch = 0.028, All_Time = 2724.414
92850/758000 (epoch 244), train_loss = 0.299, time/batch = 0.029, All_Time = 2725.898
92900/758000 (epoch 245), train_loss = 0.229, time/batch = 0.030, All_Time = 2727.381
92950/758000 (epoch 245), train_loss = 0.261, time/batch = 0.030, All_Time = 2728.845
93000/758000 (epoch 245), train_loss = 0.225, time/batch = 0.030, All_Time = 2730.306
model saved to NER/polyglot/model.ckpt
93050/758000 (epoch 245), train_loss = 0.242, time/batch = 0.030, All_Time = 2731.761
93100/758000 (epoch 245), train_loss = 0.214, time/batch = 0.028, All_Time = 2733.229
93150/758000 (epoch 245), train_loss = 0.245, time/batch = 0.029, All_Time = 2734.708
93200/758000 (epoch 245), train_loss = 0.218, time/batch = 0.030, All_Time = 2736.210
93250/758000 (epoch 246), train_loss = 0.229, time/batch = 0.029, All_Time = 2737.709
93300/758000 (epoch 246), train_loss = 0.254, time/batch = 0.029, All_Time = 2739.173
93350/758000 (epoch 246), train_loss = 0.262, time/batch = 0.028, All_Time = 2740.643
93400/758000 (epoch 246), train_loss = 0.228, time/batch = 0.029, All_Time = 2742.114
93450/758000 (epoch 246), train_loss = 0.237, time/batch = 0.030, All_Time = 2743.581
93500/758000 (epoch 246), train_loss = 0.274, time/batch = 0.030, All_Time = 2745.045
93550/758000 (epoch 246), train_loss = 0.239, time/batch = 0.031, All_Time = 2746.515
93600/758000 (epoch 246), train_loss = 0.271, time/batch = 0.029, All_Time = 2747.980
93650/758000 (epoch 247), train_loss = 0.250, time/batch = 0.028, All_Time = 2749.445
93700/758000 (epoch 247), train_loss = 0.250, time/batch = 0.030, All_Time = 2750.917
93750/758000 (epoch 247), train_loss = 0.242, time/batch = 0.029, All_Time = 2752.418
93800/758000 (epoch 247), train_loss = 0.249, time/batch = 0.031, All_Time = 2753.898
93850/758000 (epoch 247), train_loss = 0.237, time/batch = 0.031, All_Time = 2755.394
93900/758000 (epoch 247), train_loss = 0.250, time/batch = 0.029, All_Time = 2756.885
93950/758000 (epoch 247), train_loss = 0.253, time/batch = 0.029, All_Time = 2758.340
94000/758000 (epoch 248), train_loss = 0.244, time/batch = 0.028, All_Time = 2759.797
model saved to NER/polyglot/model.ckpt
94050/758000 (epoch 248), train_loss = 0.278, time/batch = 0.030, All_Time = 2761.263
94100/758000 (epoch 248), train_loss = 0.259, time/batch = 0.028, All_Time = 2762.725
94150/758000 (epoch 248), train_loss = 0.260, time/batch = 0.028, All_Time = 2764.180
94200/758000 (epoch 248), train_loss = 0.215, time/batch = 0.031, All_Time = 2765.699
94250/758000 (epoch 248), train_loss = 0.239, time/batch = 0.029, All_Time = 2767.187
94300/758000 (epoch 248), train_loss = 0.251, time/batch = 0.029, All_Time = 2768.672
94350/758000 (epoch 248), train_loss = 0.252, time/batch = 0.028, All_Time = 2770.140
94400/758000 (epoch 249), train_loss = 0.233, time/batch = 0.029, All_Time = 2771.619
94450/758000 (epoch 249), train_loss = 0.258, time/batch = 0.031, All_Time = 2773.090
94500/758000 (epoch 249), train_loss = 0.266, time/batch = 0.028, All_Time = 2774.558
94550/758000 (epoch 249), train_loss = 0.231, time/batch = 0.029, All_Time = 2776.026
94600/758000 (epoch 249), train_loss = 0.265, time/batch = 0.030, All_Time = 2777.494
94650/758000 (epoch 249), train_loss = 0.218, time/batch = 0.029, All_Time = 2778.965
94700/758000 (epoch 249), train_loss = 0.250, time/batch = 0.028, All_Time = 2780.432
94750/758000 (epoch 250), train_loss = 0.059, time/batch = 0.032, All_Time = 2781.902
94800/758000 (epoch 250), train_loss = 0.254, time/batch = 0.030, All_Time = 2783.377
94850/758000 (epoch 250), train_loss = 0.223, time/batch = 0.029, All_Time = 2784.856
94900/758000 (epoch 250), train_loss = 0.252, time/batch = 0.031, All_Time = 2786.335
94950/758000 (epoch 250), train_loss = 0.234, time/batch = 0.029, All_Time = 2787.809
95000/758000 (epoch 250), train_loss = 0.253, time/batch = 0.029, All_Time = 2789.277
model saved to NER/polyglot/model.ckpt
95050/758000 (epoch 250), train_loss = 0.233, time/batch = 0.030, All_Time = 2790.752
95100/758000 (epoch 250), train_loss = 0.233, time/batch = 0.029, All_Time = 2792.223
95150/758000 (epoch 251), train_loss = 0.227, time/batch = 0.030, All_Time = 2793.691
95200/758000 (epoch 251), train_loss = 0.234, time/batch = 0.029, All_Time = 2795.181
95250/758000 (epoch 251), train_loss = 0.225, time/batch = 0.030, All_Time = 2796.674
95300/758000 (epoch 251), train_loss = 0.262, time/batch = 0.029, All_Time = 2798.154
95350/758000 (epoch 251), train_loss = 0.222, time/batch = 0.030, All_Time = 2799.625
95400/758000 (epoch 251), train_loss = 0.229, time/batch = 0.031, All_Time = 2801.096
95450/758000 (epoch 251), train_loss = 0.282, time/batch = 0.028, All_Time = 2802.569
95500/758000 (epoch 251), train_loss = 0.274, time/batch = 0.028, All_Time = 2804.040
95550/758000 (epoch 252), train_loss = 0.231, time/batch = 0.030, All_Time = 2805.511
95600/758000 (epoch 252), train_loss = 0.225, time/batch = 0.029, All_Time = 2806.981
95650/758000 (epoch 252), train_loss = 0.203, time/batch = 0.029, All_Time = 2808.445
95700/758000 (epoch 252), train_loss = 0.271, time/batch = 0.030, All_Time = 2809.948
95750/758000 (epoch 252), train_loss = 0.261, time/batch = 0.031, All_Time = 2811.433
95800/758000 (epoch 252), train_loss = 0.211, time/batch = 0.029, All_Time = 2812.910
95850/758000 (epoch 252), train_loss = 0.220, time/batch = 0.030, All_Time = 2814.386
95900/758000 (epoch 253), train_loss = 0.231, time/batch = 0.029, All_Time = 2815.866
95950/758000 (epoch 253), train_loss = 0.284, time/batch = 0.029, All_Time = 2817.323
96000/758000 (epoch 253), train_loss = 0.233, time/batch = 0.030, All_Time = 2818.783
model saved to NER/polyglot/model.ckpt
96050/758000 (epoch 253), train_loss = 0.310, time/batch = 0.030, All_Time = 2820.250
96100/758000 (epoch 253), train_loss = 0.223, time/batch = 0.030, All_Time = 2821.714
96150/758000 (epoch 253), train_loss = 0.211, time/batch = 0.029, All_Time = 2823.200
96200/758000 (epoch 253), train_loss = 0.249, time/batch = 0.029, All_Time = 2824.692
96250/758000 (epoch 253), train_loss = 0.254, time/batch = 0.029, All_Time = 2826.164
96300/758000 (epoch 254), train_loss = 0.265, time/batch = 0.030, All_Time = 2827.647
96350/758000 (epoch 254), train_loss = 0.231, time/batch = 0.030, All_Time = 2829.116
96400/758000 (epoch 254), train_loss = 0.243, time/batch = 0.028, All_Time = 2830.585
96450/758000 (epoch 254), train_loss = 0.269, time/batch = 0.028, All_Time = 2832.038
96500/758000 (epoch 254), train_loss = 0.250, time/batch = 0.029, All_Time = 2833.515
96550/758000 (epoch 254), train_loss = 0.238, time/batch = 0.029, All_Time = 2834.992
96600/758000 (epoch 254), train_loss = 0.278, time/batch = 0.030, All_Time = 2836.469
96650/758000 (epoch 255), train_loss = 0.257, time/batch = 0.029, All_Time = 2837.939
96700/758000 (epoch 255), train_loss = 0.223, time/batch = 0.030, All_Time = 2839.409
96750/758000 (epoch 255), train_loss = 0.268, time/batch = 0.028, All_Time = 2840.883
96800/758000 (epoch 255), train_loss = 0.218, time/batch = 0.029, All_Time = 2842.357
96850/758000 (epoch 255), train_loss = 0.224, time/batch = 0.029, All_Time = 2843.827
96900/758000 (epoch 255), train_loss = 0.263, time/batch = 0.029, All_Time = 2845.298
96950/758000 (epoch 255), train_loss = 0.239, time/batch = 0.030, All_Time = 2846.760
97000/758000 (epoch 255), train_loss = 0.266, time/batch = 0.030, All_Time = 2848.244
model saved to NER/polyglot/model.ckpt
97050/758000 (epoch 256), train_loss = 0.225, time/batch = 0.029, All_Time = 2849.722
97100/758000 (epoch 256), train_loss = 0.232, time/batch = 0.030, All_Time = 2851.192
97150/758000 (epoch 256), train_loss = 0.238, time/batch = 0.029, All_Time = 2852.652
97200/758000 (epoch 256), train_loss = 0.267, time/batch = 0.029, All_Time = 2854.112
97250/758000 (epoch 256), train_loss = 0.240, time/batch = 0.028, All_Time = 2855.578
97300/758000 (epoch 256), train_loss = 0.227, time/batch = 0.029, All_Time = 2857.047
97350/758000 (epoch 256), train_loss = 0.276, time/batch = 0.029, All_Time = 2858.529
97400/758000 (epoch 256), train_loss = 0.241, time/batch = 0.030, All_Time = 2860.030
97450/758000 (epoch 257), train_loss = 0.284, time/batch = 0.029, All_Time = 2861.512
97500/758000 (epoch 257), train_loss = 0.259, time/batch = 0.028, All_Time = 2863.005
97550/758000 (epoch 257), train_loss = 0.242, time/batch = 0.030, All_Time = 2864.491
97600/758000 (epoch 257), train_loss = 0.232, time/batch = 0.031, All_Time = 2865.970
97650/758000 (epoch 257), train_loss = 0.218, time/batch = 0.028, All_Time = 2867.452
97700/758000 (epoch 257), train_loss = 0.226, time/batch = 0.030, All_Time = 2868.922
97750/758000 (epoch 257), train_loss = 0.218, time/batch = 0.029, All_Time = 2870.404
97800/758000 (epoch 258), train_loss = 0.250, time/batch = 0.029, All_Time = 2871.887
97850/758000 (epoch 258), train_loss = 0.212, time/batch = 0.028, All_Time = 2873.371
97900/758000 (epoch 258), train_loss = 0.246, time/batch = 0.029, All_Time = 2874.842
97950/758000 (epoch 258), train_loss = 0.218, time/batch = 0.028, All_Time = 2876.319
98000/758000 (epoch 258), train_loss = 0.234, time/batch = 0.029, All_Time = 2877.786
model saved to NER/polyglot/model.ckpt
98050/758000 (epoch 258), train_loss = 0.229, time/batch = 0.029, All_Time = 2879.261
98100/758000 (epoch 258), train_loss = 0.249, time/batch = 0.030, All_Time = 2880.745
98150/758000 (epoch 258), train_loss = 0.230, time/batch = 0.028, All_Time = 2882.237
98200/758000 (epoch 259), train_loss = 0.220, time/batch = 0.034, All_Time = 2883.724
98250/758000 (epoch 259), train_loss = 0.238, time/batch = 0.029, All_Time = 2885.199
98300/758000 (epoch 259), train_loss = 0.213, time/batch = 0.028, All_Time = 2886.670
98350/758000 (epoch 259), train_loss = 0.268, time/batch = 0.028, All_Time = 2888.134
98400/758000 (epoch 259), train_loss = 0.256, time/batch = 0.030, All_Time = 2889.612
98450/758000 (epoch 259), train_loss = 0.233, time/batch = 0.030, All_Time = 2891.079
98500/758000 (epoch 259), train_loss = 0.264, time/batch = 0.029, All_Time = 2892.553
98550/758000 (epoch 260), train_loss = 0.282, time/batch = 0.030, All_Time = 2894.024
98600/758000 (epoch 260), train_loss = 0.294, time/batch = 0.032, All_Time = 2895.501
98650/758000 (epoch 260), train_loss = 0.256, time/batch = 0.031, All_Time = 2897.014
98700/758000 (epoch 260), train_loss = 0.222, time/batch = 0.028, All_Time = 2898.487
98750/758000 (epoch 260), train_loss = 0.222, time/batch = 0.029, All_Time = 2899.966
98800/758000 (epoch 260), train_loss = 0.261, time/batch = 0.030, All_Time = 2901.437
98850/758000 (epoch 260), train_loss = 0.245, time/batch = 0.030, All_Time = 2902.921
98900/758000 (epoch 260), train_loss = 0.248, time/batch = 0.029, All_Time = 2904.406
98950/758000 (epoch 261), train_loss = 0.211, time/batch = 0.029, All_Time = 2905.890
99000/758000 (epoch 261), train_loss = 0.267, time/batch = 0.030, All_Time = 2907.351
model saved to NER/polyglot/model.ckpt
99050/758000 (epoch 261), train_loss = 0.230, time/batch = 0.030, All_Time = 2908.808
99100/758000 (epoch 261), train_loss = 0.233, time/batch = 0.030, All_Time = 2910.283
99150/758000 (epoch 261), train_loss = 0.231, time/batch = 0.031, All_Time = 2911.765
99200/758000 (epoch 261), train_loss = 0.254, time/batch = 0.030, All_Time = 2913.237
99250/758000 (epoch 261), train_loss = 0.260, time/batch = 0.030, All_Time = 2914.713
99300/758000 (epoch 262), train_loss = 0.197, time/batch = 0.030, All_Time = 2916.190
99350/758000 (epoch 262), train_loss = 0.256, time/batch = 0.030, All_Time = 2917.658
99400/758000 (epoch 262), train_loss = 0.282, time/batch = 0.030, All_Time = 2919.125
99450/758000 (epoch 262), train_loss = 0.237, time/batch = 0.028, All_Time = 2920.598
99500/758000 (epoch 262), train_loss = 0.248, time/batch = 0.028, All_Time = 2922.063
99550/758000 (epoch 262), train_loss = 0.252, time/batch = 0.030, All_Time = 2923.530
99600/758000 (epoch 262), train_loss = 0.204, time/batch = 0.032, All_Time = 2925.007
99650/758000 (epoch 262), train_loss = 0.270, time/batch = 0.030, All_Time = 2926.477
99700/758000 (epoch 263), train_loss = 0.234, time/batch = 0.029, All_Time = 2927.949
99750/758000 (epoch 263), train_loss = 0.242, time/batch = 0.033, All_Time = 2929.417
99800/758000 (epoch 263), train_loss = 0.252, time/batch = 0.029, All_Time = 2930.907
99850/758000 (epoch 263), train_loss = 0.259, time/batch = 0.030, All_Time = 2932.402
99900/758000 (epoch 263), train_loss = 0.244, time/batch = 0.030, All_Time = 2933.879
99950/758000 (epoch 263), train_loss = 0.244, time/batch = 0.029, All_Time = 2935.369
100000/758000 (epoch 263), train_loss = 0.246, time/batch = 0.029, All_Time = 2936.853
model saved to NER/polyglot/model.ckpt
100050/758000 (epoch 263), train_loss = 0.287, time/batch = 0.030, All_Time = 2938.322
100100/758000 (epoch 264), train_loss = 0.208, time/batch = 0.031, All_Time = 2939.785
100150/758000 (epoch 264), train_loss = 0.245, time/batch = 0.030, All_Time = 2941.257
100200/758000 (epoch 264), train_loss = 0.218, time/batch = 0.030, All_Time = 2942.720
100250/758000 (epoch 264), train_loss = 0.235, time/batch = 0.029, All_Time = 2944.221
100300/758000 (epoch 264), train_loss = 0.261, time/batch = 0.029, All_Time = 2945.719
100350/758000 (epoch 264), train_loss = 0.254, time/batch = 0.031, All_Time = 2947.197
100400/758000 (epoch 264), train_loss = 0.239, time/batch = 0.029, All_Time = 2948.664
100450/758000 (epoch 265), train_loss = 0.228, time/batch = 0.030, All_Time = 2950.137
100500/758000 (epoch 265), train_loss = 0.251, time/batch = 0.030, All_Time = 2951.604
100550/758000 (epoch 265), train_loss = 0.250, time/batch = 0.030, All_Time = 2953.067
100600/758000 (epoch 265), train_loss = 0.224, time/batch = 0.029, All_Time = 2954.543
100650/758000 (epoch 265), train_loss = 0.241, time/batch = 0.031, All_Time = 2956.011
100700/758000 (epoch 265), train_loss = 0.248, time/batch = 0.030, All_Time = 2957.481
100750/758000 (epoch 265), train_loss = 0.247, time/batch = 0.030, All_Time = 2958.954
100800/758000 (epoch 265), train_loss = 0.258, time/batch = 0.029, All_Time = 2960.423
100850/758000 (epoch 266), train_loss = 0.266, time/batch = 0.030, All_Time = 2961.894
100900/758000 (epoch 266), train_loss = 0.225, time/batch = 0.029, All_Time = 2963.355
100950/758000 (epoch 266), train_loss = 0.250, time/batch = 0.029, All_Time = 2964.837
101000/758000 (epoch 266), train_loss = 0.228, time/batch = 0.029, All_Time = 2966.313
model saved to NER/polyglot/model.ckpt
101050/758000 (epoch 266), train_loss = 0.280, time/batch = 0.031, All_Time = 2967.786
101100/758000 (epoch 266), train_loss = 0.257, time/batch = 0.029, All_Time = 2969.256
101150/758000 (epoch 266), train_loss = 0.255, time/batch = 0.030, All_Time = 2970.731
101200/758000 (epoch 267), train_loss = 0.245, time/batch = 0.031, All_Time = 2972.212
101250/758000 (epoch 267), train_loss = 0.249, time/batch = 0.029, All_Time = 2973.684
101300/758000 (epoch 267), train_loss = 0.271, time/batch = 0.030, All_Time = 2975.155
101350/758000 (epoch 267), train_loss = 0.247, time/batch = 0.029, All_Time = 2976.614
101400/758000 (epoch 267), train_loss = 0.238, time/batch = 0.029, All_Time = 2978.082
101450/758000 (epoch 267), train_loss = 0.225, time/batch = 0.030, All_Time = 2979.559
101500/758000 (epoch 267), train_loss = 0.230, time/batch = 0.031, All_Time = 2981.071
101550/758000 (epoch 267), train_loss = 0.247, time/batch = 0.030, All_Time = 2982.553
101600/758000 (epoch 268), train_loss = 0.250, time/batch = 0.031, All_Time = 2984.030
101650/758000 (epoch 268), train_loss = 0.264, time/batch = 0.032, All_Time = 2985.494
101700/758000 (epoch 268), train_loss = 0.241, time/batch = 0.031, All_Time = 2986.956
101750/758000 (epoch 268), train_loss = 0.252, time/batch = 0.028, All_Time = 2988.425
101800/758000 (epoch 268), train_loss = 0.228, time/batch = 0.029, All_Time = 2989.910
101850/758000 (epoch 268), train_loss = 0.218, time/batch = 0.030, All_Time = 2991.375
101900/758000 (epoch 268), train_loss = 0.278, time/batch = 0.029, All_Time = 2992.844
101950/758000 (epoch 268), train_loss = 0.260, time/batch = 0.029, All_Time = 2994.310
102000/758000 (epoch 269), train_loss = 0.270, time/batch = 0.029, All_Time = 2995.786
model saved to NER/polyglot/model.ckpt
102050/758000 (epoch 269), train_loss = 0.297, time/batch = 0.029, All_Time = 2997.234
102100/758000 (epoch 269), train_loss = 0.229, time/batch = 0.029, All_Time = 2998.704
102150/758000 (epoch 269), train_loss = 0.221, time/batch = 0.031, All_Time = 3000.176
102200/758000 (epoch 269), train_loss = 0.259, time/batch = 0.030, All_Time = 3001.655
102250/758000 (epoch 269), train_loss = 0.256, time/batch = 0.029, All_Time = 3003.128
102300/758000 (epoch 269), train_loss = 0.238, time/batch = 0.029, All_Time = 3004.597
102350/758000 (epoch 270), train_loss = 0.226, time/batch = 0.029, All_Time = 3006.074
102400/758000 (epoch 270), train_loss = 0.234, time/batch = 0.031, All_Time = 3007.539
102450/758000 (epoch 270), train_loss = 0.244, time/batch = 0.030, All_Time = 3009.004
102500/758000 (epoch 270), train_loss = 0.234, time/batch = 0.030, All_Time = 3010.471
102550/758000 (epoch 270), train_loss = 0.224, time/batch = 0.029, All_Time = 3011.935
102600/758000 (epoch 270), train_loss = 0.239, time/batch = 0.031, All_Time = 3013.428
102650/758000 (epoch 270), train_loss = 0.265, time/batch = 0.030, All_Time = 3014.943
102700/758000 (epoch 270), train_loss = 0.244, time/batch = 0.029, All_Time = 3016.427
102750/758000 (epoch 271), train_loss = 0.258, time/batch = 0.030, All_Time = 3017.895
102800/758000 (epoch 271), train_loss = 0.289, time/batch = 0.030, All_Time = 3019.366
102850/758000 (epoch 271), train_loss = 0.257, time/batch = 0.030, All_Time = 3020.834
102900/758000 (epoch 271), train_loss = 0.250, time/batch = 0.030, All_Time = 3022.414
102950/758000 (epoch 271), train_loss = 0.213, time/batch = 0.030, All_Time = 3023.907
103000/758000 (epoch 271), train_loss = 0.230, time/batch = 0.029, All_Time = 3025.408
model saved to NER/polyglot/model.ckpt
103050/758000 (epoch 271), train_loss = 0.273, time/batch = 0.028, All_Time = 3026.866
103100/758000 (epoch 272), train_loss = 0.250, time/batch = 0.030, All_Time = 3028.336
103150/758000 (epoch 272), train_loss = 0.228, time/batch = 0.029, All_Time = 3029.821
103200/758000 (epoch 272), train_loss = 0.269, time/batch = 0.030, All_Time = 3031.294
103250/758000 (epoch 272), train_loss = 0.240, time/batch = 0.029, All_Time = 3032.771
103300/758000 (epoch 272), train_loss = 0.248, time/batch = 0.030, All_Time = 3034.253
103350/758000 (epoch 272), train_loss = 0.241, time/batch = 0.029, All_Time = 3035.729
103400/758000 (epoch 272), train_loss = 0.275, time/batch = 0.028, All_Time = 3037.207
103450/758000 (epoch 272), train_loss = 0.280, time/batch = 0.030, All_Time = 3038.686
103500/758000 (epoch 273), train_loss = 0.239, time/batch = 0.029, All_Time = 3040.159
103550/758000 (epoch 273), train_loss = 0.248, time/batch = 0.031, All_Time = 3041.631
103600/758000 (epoch 273), train_loss = 0.299, time/batch = 0.029, All_Time = 3043.101
103650/758000 (epoch 273), train_loss = 0.231, time/batch = 0.030, All_Time = 3044.574
103700/758000 (epoch 273), train_loss = 0.216, time/batch = 0.029, All_Time = 3046.039
103750/758000 (epoch 273), train_loss = 0.245, time/batch = 0.030, All_Time = 3047.510
103800/758000 (epoch 273), train_loss = 0.275, time/batch = 0.029, All_Time = 3048.976
103850/758000 (epoch 274), train_loss = 0.221, time/batch = 0.030, All_Time = 3050.459
103900/758000 (epoch 274), train_loss = 0.257, time/batch = 0.029, All_Time = 3051.934
103950/758000 (epoch 274), train_loss = 0.243, time/batch = 0.029, All_Time = 3053.404
104000/758000 (epoch 274), train_loss = 0.241, time/batch = 0.029, All_Time = 3054.872
model saved to NER/polyglot/model.ckpt
104050/758000 (epoch 274), train_loss = 0.256, time/batch = 0.030, All_Time = 3056.346
104100/758000 (epoch 274), train_loss = 0.220, time/batch = 0.029, All_Time = 3057.812
104150/758000 (epoch 274), train_loss = 0.225, time/batch = 0.030, All_Time = 3059.279
104200/758000 (epoch 274), train_loss = 0.258, time/batch = 0.028, All_Time = 3060.742
104250/758000 (epoch 275), train_loss = 0.256, time/batch = 0.030, All_Time = 3062.211
104300/758000 (epoch 275), train_loss = 0.268, time/batch = 0.029, All_Time = 3063.671
104350/758000 (epoch 275), train_loss = 0.270, time/batch = 0.031, All_Time = 3065.142
104400/758000 (epoch 275), train_loss = 0.229, time/batch = 0.029, All_Time = 3066.650
104450/758000 (epoch 275), train_loss = 0.234, time/batch = 0.029, All_Time = 3068.142
104500/758000 (epoch 275), train_loss = 0.246, time/batch = 0.029, All_Time = 3069.625
104550/758000 (epoch 275), train_loss = 0.280, time/batch = 0.029, All_Time = 3071.106
104600/758000 (epoch 275), train_loss = 0.241, time/batch = 0.030, All_Time = 3072.587
104650/758000 (epoch 276), train_loss = 0.237, time/batch = 0.029, All_Time = 3074.069
104700/758000 (epoch 276), train_loss = 0.235, time/batch = 0.028, All_Time = 3075.542
104750/758000 (epoch 276), train_loss = 0.234, time/batch = 0.030, All_Time = 3077.018
104800/758000 (epoch 276), train_loss = 0.276, time/batch = 0.030, All_Time = 3078.499
104850/758000 (epoch 276), train_loss = 0.207, time/batch = 0.030, All_Time = 3079.964
104900/758000 (epoch 276), train_loss = 0.261, time/batch = 0.030, All_Time = 3081.444
104950/758000 (epoch 276), train_loss = 0.235, time/batch = 0.029, All_Time = 3082.918
105000/758000 (epoch 277), train_loss = 0.246, time/batch = 0.030, All_Time = 3084.402
model saved to NER/polyglot/model.ckpt
105050/758000 (epoch 277), train_loss = 0.224, time/batch = 0.030, All_Time = 3085.889
105100/758000 (epoch 277), train_loss = 0.241, time/batch = 0.029, All_Time = 3087.369
105150/758000 (epoch 277), train_loss = 0.256, time/batch = 0.029, All_Time = 3088.833
105200/758000 (epoch 277), train_loss = 0.215, time/batch = 0.030, All_Time = 3090.296
105250/758000 (epoch 277), train_loss = 0.273, time/batch = 0.030, All_Time = 3091.766
105300/758000 (epoch 277), train_loss = 0.213, time/batch = 0.030, All_Time = 3093.242
105350/758000 (epoch 277), train_loss = 0.252, time/batch = 0.031, All_Time = 3094.716
105400/758000 (epoch 278), train_loss = 0.248, time/batch = 0.030, All_Time = 3096.200
105450/758000 (epoch 278), train_loss = 0.230, time/batch = 0.030, All_Time = 3097.672
105500/758000 (epoch 278), train_loss = 0.218, time/batch = 0.030, All_Time = 3099.143
105550/758000 (epoch 278), train_loss = 0.221, time/batch = 0.031, All_Time = 3100.626
105600/758000 (epoch 278), train_loss = 0.250, time/batch = 0.030, All_Time = 3102.127
105650/758000 (epoch 278), train_loss = 0.208, time/batch = 0.030, All_Time = 3103.594
105700/758000 (epoch 278), train_loss = 0.269, time/batch = 0.031, All_Time = 3105.074
105750/758000 (epoch 279), train_loss = 0.257, time/batch = 0.030, All_Time = 3106.556
105800/758000 (epoch 279), train_loss = 0.264, time/batch = 0.029, All_Time = 3108.016
105850/758000 (epoch 279), train_loss = 0.284, time/batch = 0.028, All_Time = 3109.483
105900/758000 (epoch 279), train_loss = 0.239, time/batch = 0.030, All_Time = 3110.948
105950/758000 (epoch 279), train_loss = 0.268, time/batch = 0.030, All_Time = 3112.414
106000/758000 (epoch 279), train_loss = 0.257, time/batch = 0.030, All_Time = 3113.877
model saved to NER/polyglot/model.ckpt
106050/758000 (epoch 279), train_loss = 0.237, time/batch = 0.030, All_Time = 3115.341
106100/758000 (epoch 279), train_loss = 0.270, time/batch = 0.029, All_Time = 3116.812
106150/758000 (epoch 280), train_loss = 0.227, time/batch = 0.030, All_Time = 3118.317
106200/758000 (epoch 280), train_loss = 0.223, time/batch = 0.029, All_Time = 3119.801
106250/758000 (epoch 280), train_loss = 0.261, time/batch = 0.030, All_Time = 3121.284
106300/758000 (epoch 280), train_loss = 0.254, time/batch = 0.029, All_Time = 3122.760
106350/758000 (epoch 280), train_loss = 0.224, time/batch = 0.030, All_Time = 3124.247
106400/758000 (epoch 280), train_loss = 0.242, time/batch = 0.030, All_Time = 3125.711
106450/758000 (epoch 280), train_loss = 0.252, time/batch = 0.030, All_Time = 3127.182
106500/758000 (epoch 281), train_loss = 0.193, time/batch = 0.029, All_Time = 3128.654
106550/758000 (epoch 281), train_loss = 0.274, time/batch = 0.030, All_Time = 3130.124
106600/758000 (epoch 281), train_loss = 0.218, time/batch = 0.031, All_Time = 3131.589
106650/758000 (epoch 281), train_loss = 0.241, time/batch = 0.029, All_Time = 3133.055
106700/758000 (epoch 281), train_loss = 0.222, time/batch = 0.029, All_Time = 3134.521
106750/758000 (epoch 281), train_loss = 0.222, time/batch = 0.029, All_Time = 3135.992
106800/758000 (epoch 281), train_loss = 0.253, time/batch = 0.030, All_Time = 3137.458
106850/758000 (epoch 281), train_loss = 0.272, time/batch = 0.030, All_Time = 3138.932
106900/758000 (epoch 282), train_loss = 0.222, time/batch = 0.028, All_Time = 3140.411
106950/758000 (epoch 282), train_loss = 0.280, time/batch = 0.030, All_Time = 3141.876
107000/758000 (epoch 282), train_loss = 0.242, time/batch = 0.032, All_Time = 3143.349
model saved to NER/polyglot/model.ckpt
107050/758000 (epoch 282), train_loss = 0.274, time/batch = 0.030, All_Time = 3144.812
107100/758000 (epoch 282), train_loss = 0.262, time/batch = 0.031, All_Time = 3146.308
107150/758000 (epoch 282), train_loss = 0.198, time/batch = 0.029, All_Time = 3147.808
107200/758000 (epoch 282), train_loss = 0.234, time/batch = 0.030, All_Time = 3149.297
107250/758000 (epoch 282), train_loss = 0.282, time/batch = 0.031, All_Time = 3150.779
107300/758000 (epoch 283), train_loss = 0.247, time/batch = 0.029, All_Time = 3152.263
107350/758000 (epoch 283), train_loss = 0.212, time/batch = 0.029, All_Time = 3153.720
107400/758000 (epoch 283), train_loss = 0.256, time/batch = 0.029, All_Time = 3155.190
107450/758000 (epoch 283), train_loss = 0.271, time/batch = 0.031, All_Time = 3156.679
107500/758000 (epoch 283), train_loss = 0.203, time/batch = 0.029, All_Time = 3158.158
107550/758000 (epoch 283), train_loss = 0.227, time/batch = 0.031, All_Time = 3159.628
107600/758000 (epoch 283), train_loss = 0.255, time/batch = 0.030, All_Time = 3161.111
107650/758000 (epoch 284), train_loss = 0.219, time/batch = 0.030, All_Time = 3162.591
107700/758000 (epoch 284), train_loss = 0.266, time/batch = 0.029, All_Time = 3164.075
107750/758000 (epoch 284), train_loss = 0.228, time/batch = 0.031, All_Time = 3165.562
107800/758000 (epoch 284), train_loss = 0.213, time/batch = 0.030, All_Time = 3167.049
107850/758000 (epoch 284), train_loss = 0.224, time/batch = 0.029, All_Time = 3168.529
107900/758000 (epoch 284), train_loss = 0.213, time/batch = 0.030, All_Time = 3170.002
107950/758000 (epoch 284), train_loss = 0.231, time/batch = 0.030, All_Time = 3171.475
108000/758000 (epoch 284), train_loss = 0.223, time/batch = 0.029, All_Time = 3172.953
model saved to NER/polyglot/model.ckpt
108050/758000 (epoch 285), train_loss = 0.275, time/batch = 0.030, All_Time = 3174.418
108100/758000 (epoch 285), train_loss = 0.230, time/batch = 0.029, All_Time = 3175.884
108150/758000 (epoch 285), train_loss = 0.271, time/batch = 0.030, All_Time = 3177.345
108200/758000 (epoch 285), train_loss = 0.273, time/batch = 0.030, All_Time = 3178.816
108250/758000 (epoch 285), train_loss = 0.234, time/batch = 0.031, All_Time = 3180.303
108300/758000 (epoch 285), train_loss = 0.268, time/batch = 0.030, All_Time = 3181.788
108350/758000 (epoch 285), train_loss = 0.280, time/batch = 0.030, All_Time = 3183.272
108400/758000 (epoch 286), train_loss = 0.239, time/batch = 0.031, All_Time = 3184.769
108450/758000 (epoch 286), train_loss = 0.219, time/batch = 0.030, All_Time = 3186.249
108500/758000 (epoch 286), train_loss = 0.244, time/batch = 0.030, All_Time = 3187.737
108550/758000 (epoch 286), train_loss = 0.245, time/batch = 0.029, All_Time = 3189.214
108600/758000 (epoch 286), train_loss = 0.243, time/batch = 0.029, All_Time = 3190.693
108650/758000 (epoch 286), train_loss = 0.245, time/batch = 0.029, All_Time = 3192.175
108700/758000 (epoch 286), train_loss = 0.213, time/batch = 0.030, All_Time = 3193.652
108750/758000 (epoch 286), train_loss = 0.290, time/batch = 0.029, All_Time = 3195.133
108800/758000 (epoch 287), train_loss = 0.238, time/batch = 0.030, All_Time = 3196.619
108850/758000 (epoch 287), train_loss = 0.246, time/batch = 0.028, All_Time = 3198.086
108900/758000 (epoch 287), train_loss = 0.288, time/batch = 0.028, All_Time = 3199.569
108950/758000 (epoch 287), train_loss = 0.258, time/batch = 0.029, All_Time = 3201.044
109000/758000 (epoch 287), train_loss = 0.219, time/batch = 0.030, All_Time = 3202.513
model saved to NER/polyglot/model.ckpt
109050/758000 (epoch 287), train_loss = 0.238, time/batch = 0.030, All_Time = 3204.003
109100/758000 (epoch 287), train_loss = 0.251, time/batch = 0.029, All_Time = 3205.478
109150/758000 (epoch 287), train_loss = 0.251, time/batch = 0.032, All_Time = 3206.943
109200/758000 (epoch 288), train_loss = 0.253, time/batch = 0.029, All_Time = 3208.425
109250/758000 (epoch 288), train_loss = 0.281, time/batch = 0.030, All_Time = 3209.902
109300/758000 (epoch 288), train_loss = 0.243, time/batch = 0.030, All_Time = 3211.369
109350/758000 (epoch 288), train_loss = 0.250, time/batch = 0.030, All_Time = 3212.844
109400/758000 (epoch 288), train_loss = 0.239, time/batch = 0.030, All_Time = 3214.319
109450/758000 (epoch 288), train_loss = 0.240, time/batch = 0.055, All_Time = 3215.813
109500/758000 (epoch 288), train_loss = 0.251, time/batch = 0.030, All_Time = 3217.349
109550/758000 (epoch 289), train_loss = 0.222, time/batch = 0.030, All_Time = 3218.852
109600/758000 (epoch 289), train_loss = 0.219, time/batch = 0.031, All_Time = 3220.340
109650/758000 (epoch 289), train_loss = 0.246, time/batch = 0.030, All_Time = 3221.855
109700/758000 (epoch 289), train_loss = 0.262, time/batch = 0.028, All_Time = 3223.322
109750/758000 (epoch 289), train_loss = 0.260, time/batch = 0.029, All_Time = 3224.789
109800/758000 (epoch 289), train_loss = 0.242, time/batch = 0.028, All_Time = 3226.257
109850/758000 (epoch 289), train_loss = 0.211, time/batch = 0.029, All_Time = 3227.724
109900/758000 (epoch 289), train_loss = 0.240, time/batch = 0.029, All_Time = 3229.194
109950/758000 (epoch 290), train_loss = 0.230, time/batch = 0.030, All_Time = 3230.658
110000/758000 (epoch 290), train_loss = 0.227, time/batch = 0.030, All_Time = 3232.129
model saved to NER/polyglot/model.ckpt
110050/758000 (epoch 290), train_loss = 0.264, time/batch = 0.030, All_Time = 3233.597
110100/758000 (epoch 290), train_loss = 0.241, time/batch = 0.030, All_Time = 3235.049
110150/758000 (epoch 290), train_loss = 0.254, time/batch = 0.031, All_Time = 3236.534
110200/758000 (epoch 290), train_loss = 0.251, time/batch = 0.029, All_Time = 3238.019
110250/758000 (epoch 290), train_loss = 0.249, time/batch = 0.029, All_Time = 3239.501
110300/758000 (epoch 291), train_loss = 0.216, time/batch = 0.030, All_Time = 3240.986
110350/758000 (epoch 291), train_loss = 0.234, time/batch = 0.030, All_Time = 3242.474
110400/758000 (epoch 291), train_loss = 0.251, time/batch = 0.031, All_Time = 3243.955
110450/758000 (epoch 291), train_loss = 0.241, time/batch = 0.028, All_Time = 3245.429
110500/758000 (epoch 291), train_loss = 0.244, time/batch = 0.029, All_Time = 3246.913
110550/758000 (epoch 291), train_loss = 0.242, time/batch = 0.029, All_Time = 3248.377
110600/758000 (epoch 291), train_loss = 0.231, time/batch = 0.029, All_Time = 3249.856
110650/758000 (epoch 291), train_loss = 0.260, time/batch = 0.030, All_Time = 3251.340
110700/758000 (epoch 292), train_loss = 0.250, time/batch = 0.030, All_Time = 3252.822
110750/758000 (epoch 292), train_loss = 0.254, time/batch = 0.030, All_Time = 3254.300
110800/758000 (epoch 292), train_loss = 0.246, time/batch = 0.029, All_Time = 3255.764
110850/758000 (epoch 292), train_loss = 0.231, time/batch = 0.029, All_Time = 3257.256
110900/758000 (epoch 292), train_loss = 0.229, time/batch = 0.031, All_Time = 3258.730
110950/758000 (epoch 292), train_loss = 0.238, time/batch = 0.029, All_Time = 3260.195
111000/758000 (epoch 292), train_loss = 0.268, time/batch = 0.029, All_Time = 3261.669
model saved to NER/polyglot/model.ckpt
111050/758000 (epoch 293), train_loss = 0.249, time/batch = 0.031, All_Time = 3263.143
111100/758000 (epoch 293), train_loss = 0.281, time/batch = 0.030, All_Time = 3264.617
111150/758000 (epoch 293), train_loss = 0.243, time/batch = 0.029, All_Time = 3266.077
111200/758000 (epoch 293), train_loss = 0.258, time/batch = 0.031, All_Time = 3267.542
111250/758000 (epoch 293), train_loss = 0.224, time/batch = 0.028, All_Time = 3269.011
111300/758000 (epoch 293), train_loss = 0.244, time/batch = 0.030, All_Time = 3270.482
111350/758000 (epoch 293), train_loss = 0.219, time/batch = 0.030, All_Time = 3271.974
111400/758000 (epoch 293), train_loss = 0.233, time/batch = 0.029, All_Time = 3273.480
111450/758000 (epoch 294), train_loss = 0.238, time/batch = 0.028, All_Time = 3274.956
111500/758000 (epoch 294), train_loss = 0.240, time/batch = 0.028, All_Time = 3276.412
111550/758000 (epoch 294), train_loss = 0.293, time/batch = 0.030, All_Time = 3277.891
111600/758000 (epoch 294), train_loss = 0.318, time/batch = 0.030, All_Time = 3279.374
111650/758000 (epoch 294), train_loss = 0.196, time/batch = 0.030, All_Time = 3280.860
111700/758000 (epoch 294), train_loss = 0.214, time/batch = 0.030, All_Time = 3282.328
111750/758000 (epoch 294), train_loss = 0.250, time/batch = 0.030, All_Time = 3283.799
111800/758000 (epoch 294), train_loss = 0.298, time/batch = 0.030, All_Time = 3285.270
111850/758000 (epoch 295), train_loss = 0.227, time/batch = 0.030, All_Time = 3286.738
111900/758000 (epoch 295), train_loss = 0.259, time/batch = 0.031, All_Time = 3288.210
111950/758000 (epoch 295), train_loss = 0.224, time/batch = 0.030, All_Time = 3289.678
112000/758000 (epoch 295), train_loss = 0.240, time/batch = 0.031, All_Time = 3291.135
model saved to NER/polyglot/model.ckpt
112050/758000 (epoch 295), train_loss = 0.212, time/batch = 0.029, All_Time = 3292.610
112100/758000 (epoch 295), train_loss = 0.244, time/batch = 0.030, All_Time = 3294.075
112150/758000 (epoch 295), train_loss = 0.216, time/batch = 0.030, All_Time = 3295.561
112200/758000 (epoch 296), train_loss = 0.229, time/batch = 0.029, All_Time = 3297.061
112250/758000 (epoch 296), train_loss = 0.252, time/batch = 0.030, All_Time = 3298.533
112300/758000 (epoch 296), train_loss = 0.260, time/batch = 0.030, All_Time = 3300.009
112350/758000 (epoch 296), train_loss = 0.228, time/batch = 0.031, All_Time = 3301.501
112400/758000 (epoch 296), train_loss = 0.236, time/batch = 0.030, All_Time = 3302.992
112450/758000 (epoch 296), train_loss = 0.272, time/batch = 0.029, All_Time = 3304.471
112500/758000 (epoch 296), train_loss = 0.238, time/batch = 0.029, All_Time = 3305.957
112550/758000 (epoch 296), train_loss = 0.268, time/batch = 0.030, All_Time = 3307.443
112600/758000 (epoch 297), train_loss = 0.249, time/batch = 0.029, All_Time = 3308.957
112650/758000 (epoch 297), train_loss = 0.249, time/batch = 0.029, All_Time = 3310.429
112700/758000 (epoch 297), train_loss = 0.241, time/batch = 0.030, All_Time = 3311.907
112750/758000 (epoch 297), train_loss = 0.247, time/batch = 0.028, All_Time = 3313.380
112800/758000 (epoch 297), train_loss = 0.235, time/batch = 0.031, All_Time = 3314.860
112850/758000 (epoch 297), train_loss = 0.248, time/batch = 0.028, All_Time = 3316.340
112900/758000 (epoch 297), train_loss = 0.252, time/batch = 0.029, All_Time = 3317.825
112950/758000 (epoch 298), train_loss = 0.243, time/batch = 0.030, All_Time = 3319.297
113000/758000 (epoch 298), train_loss = 0.276, time/batch = 0.029, All_Time = 3320.772
model saved to NER/polyglot/model.ckpt
113050/758000 (epoch 298), train_loss = 0.257, time/batch = 0.031, All_Time = 3322.256
113100/758000 (epoch 298), train_loss = 0.259, time/batch = 0.029, All_Time = 3323.759
113150/758000 (epoch 298), train_loss = 0.213, time/batch = 0.030, All_Time = 3325.232
113200/758000 (epoch 298), train_loss = 0.238, time/batch = 0.029, All_Time = 3326.705
113250/758000 (epoch 298), train_loss = 0.249, time/batch = 0.028, All_Time = 3328.172
113300/758000 (epoch 298), train_loss = 0.251, time/batch = 0.030, All_Time = 3329.706
113350/758000 (epoch 299), train_loss = 0.232, time/batch = 0.030, All_Time = 3331.211
113400/758000 (epoch 299), train_loss = 0.256, time/batch = 0.029, All_Time = 3332.675
113450/758000 (epoch 299), train_loss = 0.265, time/batch = 0.029, All_Time = 3334.133
113500/758000 (epoch 299), train_loss = 0.230, time/batch = 0.029, All_Time = 3335.591
113550/758000 (epoch 299), train_loss = 0.263, time/batch = 0.031, All_Time = 3337.057
113600/758000 (epoch 299), train_loss = 0.217, time/batch = 0.031, All_Time = 3338.526
113650/758000 (epoch 299), train_loss = 0.249, time/batch = 0.029, All_Time = 3340.007
113700/758000 (epoch 300), train_loss = 0.059, time/batch = 0.033, All_Time = 3341.511
113750/758000 (epoch 300), train_loss = 0.251, time/batch = 0.028, All_Time = 3342.989
113800/758000 (epoch 300), train_loss = 0.223, time/batch = 0.031, All_Time = 3344.459
113850/758000 (epoch 300), train_loss = 0.250, time/batch = 0.029, All_Time = 3345.919
113900/758000 (epoch 300), train_loss = 0.232, time/batch = 0.028, All_Time = 3347.395
113950/758000 (epoch 300), train_loss = 0.251, time/batch = 0.030, All_Time = 3348.868
114000/758000 (epoch 300), train_loss = 0.232, time/batch = 0.031, All_Time = 3350.499
model saved to NER/polyglot/model.ckpt
114050/758000 (epoch 300), train_loss = 0.231, time/batch = 0.030, All_Time = 3351.965
114100/758000 (epoch 301), train_loss = 0.225, time/batch = 0.028, All_Time = 3353.430
114150/758000 (epoch 301), train_loss = 0.233, time/batch = 0.031, All_Time = 3354.890
114200/758000 (epoch 301), train_loss = 0.224, time/batch = 0.030, All_Time = 3356.351
114250/758000 (epoch 301), train_loss = 0.262, time/batch = 0.028, All_Time = 3357.827
114300/758000 (epoch 301), train_loss = 0.220, time/batch = 0.030, All_Time = 3359.296
114350/758000 (epoch 301), train_loss = 0.228, time/batch = 0.029, All_Time = 3360.763
114400/758000 (epoch 301), train_loss = 0.281, time/batch = 0.030, All_Time = 3362.227
114450/758000 (epoch 301), train_loss = 0.272, time/batch = 0.028, All_Time = 3363.695
114500/758000 (epoch 302), train_loss = 0.230, time/batch = 0.030, All_Time = 3365.177
114550/758000 (epoch 302), train_loss = 0.224, time/batch = 0.030, All_Time = 3366.671
114600/758000 (epoch 302), train_loss = 0.201, time/batch = 0.029, All_Time = 3368.152
114650/758000 (epoch 302), train_loss = 0.270, time/batch = 0.029, All_Time = 3369.629
114700/758000 (epoch 302), train_loss = 0.260, time/batch = 0.028, All_Time = 3371.112
114750/758000 (epoch 302), train_loss = 0.209, time/batch = 0.029, All_Time = 3372.587
114800/758000 (epoch 302), train_loss = 0.219, time/batch = 0.030, All_Time = 3374.075
114850/758000 (epoch 303), train_loss = 0.230, time/batch = 0.031, All_Time = 3375.559
114900/758000 (epoch 303), train_loss = 0.283, time/batch = 0.030, All_Time = 3377.032
114950/758000 (epoch 303), train_loss = 0.232, time/batch = 0.030, All_Time = 3378.509
115000/758000 (epoch 303), train_loss = 0.308, time/batch = 0.028, All_Time = 3379.979
model saved to NER/polyglot/model.ckpt
115050/758000 (epoch 303), train_loss = 0.221, time/batch = 0.028, All_Time = 3381.445
115100/758000 (epoch 303), train_loss = 0.209, time/batch = 0.029, All_Time = 3382.913
115150/758000 (epoch 303), train_loss = 0.247, time/batch = 0.030, All_Time = 3384.382
115200/758000 (epoch 303), train_loss = 0.252, time/batch = 0.029, All_Time = 3385.848
115250/758000 (epoch 304), train_loss = 0.264, time/batch = 0.028, All_Time = 3387.330
115300/758000 (epoch 304), train_loss = 0.229, time/batch = 0.030, All_Time = 3388.834
115350/758000 (epoch 304), train_loss = 0.242, time/batch = 0.029, All_Time = 3390.317
115400/758000 (epoch 304), train_loss = 0.268, time/batch = 0.029, All_Time = 3391.791
115450/758000 (epoch 304), train_loss = 0.249, time/batch = 0.030, All_Time = 3393.270
115500/758000 (epoch 304), train_loss = 0.237, time/batch = 0.029, All_Time = 3394.752
115550/758000 (epoch 304), train_loss = 0.277, time/batch = 0.029, All_Time = 3396.228
115600/758000 (epoch 305), train_loss = 0.256, time/batch = 0.028, All_Time = 3397.697
115650/758000 (epoch 305), train_loss = 0.222, time/batch = 0.030, All_Time = 3399.182
115700/758000 (epoch 305), train_loss = 0.267, time/batch = 0.030, All_Time = 3400.655
115750/758000 (epoch 305), train_loss = 0.217, time/batch = 0.030, All_Time = 3402.120
115800/758000 (epoch 305), train_loss = 0.223, time/batch = 0.030, All_Time = 3403.594
115850/758000 (epoch 305), train_loss = 0.262, time/batch = 0.031, All_Time = 3405.095
115900/758000 (epoch 305), train_loss = 0.238, time/batch = 0.028, All_Time = 3406.590
115950/758000 (epoch 305), train_loss = 0.264, time/batch = 0.029, All_Time = 3408.072
116000/758000 (epoch 306), train_loss = 0.224, time/batch = 0.029, All_Time = 3409.557
model saved to NER/polyglot/model.ckpt
116050/758000 (epoch 306), train_loss = 0.231, time/batch = 0.029, All_Time = 3411.042
116100/758000 (epoch 306), train_loss = 0.238, time/batch = 0.030, All_Time = 3412.496
116150/758000 (epoch 306), train_loss = 0.266, time/batch = 0.029, All_Time = 3413.962
116200/758000 (epoch 306), train_loss = 0.239, time/batch = 0.029, All_Time = 3415.429
116250/758000 (epoch 306), train_loss = 0.227, time/batch = 0.030, All_Time = 3416.927
116300/758000 (epoch 306), train_loss = 0.276, time/batch = 0.030, All_Time = 3418.435
116350/758000 (epoch 306), train_loss = 0.240, time/batch = 0.029, All_Time = 3419.904
116400/758000 (epoch 307), train_loss = 0.282, time/batch = 0.029, All_Time = 3421.374
116450/758000 (epoch 307), train_loss = 0.257, time/batch = 0.030, All_Time = 3422.840
116500/758000 (epoch 307), train_loss = 0.241, time/batch = 0.030, All_Time = 3424.314
116550/758000 (epoch 307), train_loss = 0.231, time/batch = 0.028, All_Time = 3425.785
116600/758000 (epoch 307), train_loss = 0.217, time/batch = 0.030, All_Time = 3427.255
116650/758000 (epoch 307), train_loss = 0.225, time/batch = 0.029, All_Time = 3428.736
116700/758000 (epoch 307), train_loss = 0.216, time/batch = 0.029, All_Time = 3430.228
116750/758000 (epoch 308), train_loss = 0.249, time/batch = 0.030, All_Time = 3431.726
116800/758000 (epoch 308), train_loss = 0.211, time/batch = 0.029, All_Time = 3433.189
116850/758000 (epoch 308), train_loss = 0.246, time/batch = 0.031, All_Time = 3434.659
116900/758000 (epoch 308), train_loss = 0.217, time/batch = 0.030, All_Time = 3436.126
116950/758000 (epoch 308), train_loss = 0.233, time/batch = 0.029, All_Time = 3437.596
117000/758000 (epoch 308), train_loss = 0.228, time/batch = 0.030, All_Time = 3439.070
model saved to NER/polyglot/model.ckpt
117050/758000 (epoch 308), train_loss = 0.248, time/batch = 0.029, All_Time = 3440.551
117100/758000 (epoch 308), train_loss = 0.229, time/batch = 0.031, All_Time = 3442.024
117150/758000 (epoch 309), train_loss = 0.219, time/batch = 0.029, All_Time = 3443.518
117200/758000 (epoch 309), train_loss = 0.237, time/batch = 0.030, All_Time = 3445.001
117250/758000 (epoch 309), train_loss = 0.212, time/batch = 0.029, All_Time = 3446.480
117300/758000 (epoch 309), train_loss = 0.266, time/batch = 0.029, All_Time = 3447.952
117350/758000 (epoch 309), train_loss = 0.255, time/batch = 0.029, All_Time = 3449.421
117400/758000 (epoch 309), train_loss = 0.232, time/batch = 0.030, All_Time = 3450.897
117450/758000 (epoch 309), train_loss = 0.263, time/batch = 0.029, All_Time = 3452.373
117500/758000 (epoch 310), train_loss = 0.282, time/batch = 0.030, All_Time = 3453.838
117550/758000 (epoch 310), train_loss = 0.293, time/batch = 0.030, All_Time = 3455.303
117600/758000 (epoch 310), train_loss = 0.254, time/batch = 0.030, All_Time = 3456.764
117650/758000 (epoch 310), train_loss = 0.222, time/batch = 0.032, All_Time = 3458.240
117700/758000 (epoch 310), train_loss = 0.221, time/batch = 0.029, All_Time = 3459.743
117750/758000 (epoch 310), train_loss = 0.260, time/batch = 0.030, All_Time = 3461.230
117800/758000 (epoch 310), train_loss = 0.244, time/batch = 0.029, All_Time = 3462.705
117850/758000 (epoch 310), train_loss = 0.247, time/batch = 0.029, All_Time = 3464.190
117900/758000 (epoch 311), train_loss = 0.210, time/batch = 0.031, All_Time = 3465.679
117950/758000 (epoch 311), train_loss = 0.265, time/batch = 0.030, All_Time = 3467.152
118000/758000 (epoch 311), train_loss = 0.229, time/batch = 0.030, All_Time = 3468.624
model saved to NER/polyglot/model.ckpt
118050/758000 (epoch 311), train_loss = 0.232, time/batch = 0.030, All_Time = 3470.098
118100/758000 (epoch 311), train_loss = 0.230, time/batch = 0.029, All_Time = 3471.559
118150/758000 (epoch 311), train_loss = 0.253, time/batch = 0.032, All_Time = 3473.046
118200/758000 (epoch 311), train_loss = 0.259, time/batch = 0.030, All_Time = 3474.527
118250/758000 (epoch 312), train_loss = 0.196, time/batch = 0.029, All_Time = 3476.024
118300/758000 (epoch 312), train_loss = 0.254, time/batch = 0.028, All_Time = 3477.494
118350/758000 (epoch 312), train_loss = 0.281, time/batch = 0.029, All_Time = 3478.959
118400/758000 (epoch 312), train_loss = 0.235, time/batch = 0.030, All_Time = 3480.433
118450/758000 (epoch 312), train_loss = 0.248, time/batch = 0.030, All_Time = 3481.913
118500/758000 (epoch 312), train_loss = 0.251, time/batch = 0.029, All_Time = 3483.388
118550/758000 (epoch 312), train_loss = 0.203, time/batch = 0.029, All_Time = 3484.858
118600/758000 (epoch 312), train_loss = 0.269, time/batch = 0.030, All_Time = 3486.335
118650/758000 (epoch 313), train_loss = 0.234, time/batch = 0.029, All_Time = 3487.806
118700/758000 (epoch 313), train_loss = 0.241, time/batch = 0.029, All_Time = 3489.270
118750/758000 (epoch 313), train_loss = 0.252, time/batch = 0.031, All_Time = 3490.742
118800/758000 (epoch 313), train_loss = 0.258, time/batch = 0.029, All_Time = 3492.218
118850/758000 (epoch 313), train_loss = 0.243, time/batch = 0.030, All_Time = 3493.693
118900/758000 (epoch 313), train_loss = 0.243, time/batch = 0.029, All_Time = 3495.160
118950/758000 (epoch 313), train_loss = 0.244, time/batch = 0.029, All_Time = 3496.638
119000/758000 (epoch 313), train_loss = 0.286, time/batch = 0.031, All_Time = 3498.119
model saved to NER/polyglot/model.ckpt
119050/758000 (epoch 314), train_loss = 0.207, time/batch = 0.029, All_Time = 3499.602
119100/758000 (epoch 314), train_loss = 0.244, time/batch = 0.029, All_Time = 3501.061
119150/758000 (epoch 314), train_loss = 0.217, time/batch = 0.030, All_Time = 3502.531
119200/758000 (epoch 314), train_loss = 0.234, time/batch = 0.029, All_Time = 3504.030
119250/758000 (epoch 314), train_loss = 0.260, time/batch = 0.029, All_Time = 3505.505
119300/758000 (epoch 314), train_loss = 0.253, time/batch = 0.029, All_Time = 3506.992
119350/758000 (epoch 314), train_loss = 0.238, time/batch = 0.030, All_Time = 3508.457
119400/758000 (epoch 315), train_loss = 0.227, time/batch = 0.030, All_Time = 3509.936
119450/758000 (epoch 315), train_loss = 0.251, time/batch = 0.029, All_Time = 3511.415
119500/758000 (epoch 315), train_loss = 0.250, time/batch = 0.031, All_Time = 3512.899
119550/758000 (epoch 315), train_loss = 0.223, time/batch = 0.029, All_Time = 3514.385
119600/758000 (epoch 315), train_loss = 0.240, time/batch = 0.030, All_Time = 3515.848
119650/758000 (epoch 315), train_loss = 0.247, time/batch = 0.029, All_Time = 3517.312
119700/758000 (epoch 315), train_loss = 0.246, time/batch = 0.030, All_Time = 3518.780
119750/758000 (epoch 315), train_loss = 0.257, time/batch = 0.030, All_Time = 3520.261
119800/758000 (epoch 316), train_loss = 0.266, time/batch = 0.029, All_Time = 3521.749
119850/758000 (epoch 316), train_loss = 0.224, time/batch = 0.030, All_Time = 3523.225
119900/758000 (epoch 316), train_loss = 0.249, time/batch = 0.031, All_Time = 3524.693
119950/758000 (epoch 316), train_loss = 0.227, time/batch = 0.030, All_Time = 3526.166
120000/758000 (epoch 316), train_loss = 0.279, time/batch = 0.030, All_Time = 3527.660
model saved to NER/polyglot/model.ckpt
120050/758000 (epoch 316), train_loss = 0.256, time/batch = 0.029, All_Time = 3529.128
120100/758000 (epoch 316), train_loss = 0.254, time/batch = 0.031, All_Time = 3530.593
120150/758000 (epoch 317), train_loss = 0.245, time/batch = 0.030, All_Time = 3532.057
120200/758000 (epoch 317), train_loss = 0.248, time/batch = 0.030, All_Time = 3533.523
120250/758000 (epoch 317), train_loss = 0.270, time/batch = 0.030, All_Time = 3534.991
120300/758000 (epoch 317), train_loss = 0.246, time/batch = 0.031, All_Time = 3536.467
120350/758000 (epoch 317), train_loss = 0.237, time/batch = 0.031, All_Time = 3537.986
120400/758000 (epoch 317), train_loss = 0.224, time/batch = 0.029, All_Time = 3539.479
120450/758000 (epoch 317), train_loss = 0.229, time/batch = 0.029, All_Time = 3540.956
120500/758000 (epoch 317), train_loss = 0.246, time/batch = 0.028, All_Time = 3542.446
120550/758000 (epoch 318), train_loss = 0.249, time/batch = 0.029, All_Time = 3543.930
120600/758000 (epoch 318), train_loss = 0.264, time/batch = 0.029, All_Time = 3545.397
120650/758000 (epoch 318), train_loss = 0.240, time/batch = 0.030, All_Time = 3546.874
120700/758000 (epoch 318), train_loss = 0.250, time/batch = 0.031, All_Time = 3548.343
120750/758000 (epoch 318), train_loss = 0.227, time/batch = 0.030, All_Time = 3549.815
120800/758000 (epoch 318), train_loss = 0.217, time/batch = 0.029, All_Time = 3551.280
120850/758000 (epoch 318), train_loss = 0.277, time/batch = 0.030, All_Time = 3552.741
120900/758000 (epoch 318), train_loss = 0.259, time/batch = 0.029, All_Time = 3554.198
120950/758000 (epoch 319), train_loss = 0.269, time/batch = 0.029, All_Time = 3555.662
121000/758000 (epoch 319), train_loss = 0.296, time/batch = 0.031, All_Time = 3557.156
model saved to NER/polyglot/model.ckpt
121050/758000 (epoch 319), train_loss = 0.228, time/batch = 0.030, All_Time = 3558.654
121100/758000 (epoch 319), train_loss = 0.220, time/batch = 0.029, All_Time = 3560.127
121150/758000 (epoch 319), train_loss = 0.257, time/batch = 0.030, All_Time = 3561.605
121200/758000 (epoch 319), train_loss = 0.255, time/batch = 0.028, All_Time = 3563.090
121250/758000 (epoch 319), train_loss = 0.237, time/batch = 0.029, All_Time = 3564.564
121300/758000 (epoch 320), train_loss = 0.225, time/batch = 0.031, All_Time = 3566.052
121350/758000 (epoch 320), train_loss = 0.234, time/batch = 0.029, All_Time = 3567.520
121400/758000 (epoch 320), train_loss = 0.243, time/batch = 0.030, All_Time = 3568.978
121450/758000 (epoch 320), train_loss = 0.234, time/batch = 0.029, All_Time = 3570.443
121500/758000 (epoch 320), train_loss = 0.223, time/batch = 0.029, All_Time = 3571.904
121550/758000 (epoch 320), train_loss = 0.239, time/batch = 0.028, All_Time = 3573.375
121600/758000 (epoch 320), train_loss = 0.264, time/batch = 0.028, All_Time = 3574.855
121650/758000 (epoch 320), train_loss = 0.244, time/batch = 0.029, All_Time = 3576.334
121700/758000 (epoch 321), train_loss = 0.257, time/batch = 0.029, All_Time = 3577.816
121750/758000 (epoch 321), train_loss = 0.288, time/batch = 0.030, All_Time = 3579.296
121800/758000 (epoch 321), train_loss = 0.256, time/batch = 0.029, All_Time = 3580.770
121850/758000 (epoch 321), train_loss = 0.249, time/batch = 0.029, All_Time = 3582.242
121900/758000 (epoch 321), train_loss = 0.212, time/batch = 0.029, All_Time = 3583.711
121950/758000 (epoch 321), train_loss = 0.229, time/batch = 0.029, All_Time = 3585.193
122000/758000 (epoch 321), train_loss = 0.273, time/batch = 0.028, All_Time = 3586.671
model saved to NER/polyglot/model.ckpt
122050/758000 (epoch 322), train_loss = 0.249, time/batch = 0.028, All_Time = 3588.146
122100/758000 (epoch 322), train_loss = 0.227, time/batch = 0.030, All_Time = 3589.616
122150/758000 (epoch 322), train_loss = 0.268, time/batch = 0.029, All_Time = 3591.084
122200/758000 (epoch 322), train_loss = 0.239, time/batch = 0.029, All_Time = 3592.558
122250/758000 (epoch 322), train_loss = 0.247, time/batch = 0.029, All_Time = 3594.025
122300/758000 (epoch 322), train_loss = 0.241, time/batch = 0.029, All_Time = 3595.536
122350/758000 (epoch 322), train_loss = 0.274, time/batch = 0.029, All_Time = 3597.030
122400/758000 (epoch 322), train_loss = 0.279, time/batch = 0.029, All_Time = 3598.505
122450/758000 (epoch 323), train_loss = 0.238, time/batch = 0.030, All_Time = 3599.991
122500/758000 (epoch 323), train_loss = 0.248, time/batch = 0.028, All_Time = 3601.452
122550/758000 (epoch 323), train_loss = 0.299, time/batch = 0.029, All_Time = 3602.928
122600/758000 (epoch 323), train_loss = 0.231, time/batch = 0.030, All_Time = 3604.398
122650/758000 (epoch 323), train_loss = 0.216, time/batch = 0.029, All_Time = 3605.862
122700/758000 (epoch 323), train_loss = 0.244, time/batch = 0.030, All_Time = 3607.343
122750/758000 (epoch 323), train_loss = 0.274, time/batch = 0.029, All_Time = 3608.811
122800/758000 (epoch 324), train_loss = 0.221, time/batch = 0.028, All_Time = 3610.296
122850/758000 (epoch 324), train_loss = 0.257, time/batch = 0.030, All_Time = 3611.771
122900/758000 (epoch 324), train_loss = 0.242, time/batch = 0.030, All_Time = 3613.248
122950/758000 (epoch 324), train_loss = 0.241, time/batch = 0.031, All_Time = 3614.730
123000/758000 (epoch 324), train_loss = 0.256, time/batch = 0.030, All_Time = 3616.244
model saved to NER/polyglot/model.ckpt
123050/758000 (epoch 324), train_loss = 0.219, time/batch = 0.028, All_Time = 3617.723
123100/758000 (epoch 324), train_loss = 0.224, time/batch = 0.029, All_Time = 3619.204
123150/758000 (epoch 324), train_loss = 0.257, time/batch = 0.029, All_Time = 3620.681
123200/758000 (epoch 325), train_loss = 0.256, time/batch = 0.029, All_Time = 3622.155
123250/758000 (epoch 325), train_loss = 0.267, time/batch = 0.029, All_Time = 3623.631
123300/758000 (epoch 325), train_loss = 0.269, time/batch = 0.029, All_Time = 3625.100
123350/758000 (epoch 325), train_loss = 0.228, time/batch = 0.031, All_Time = 3626.580
123400/758000 (epoch 325), train_loss = 0.234, time/batch = 0.029, All_Time = 3628.049
123450/758000 (epoch 325), train_loss = 0.246, time/batch = 0.030, All_Time = 3629.532
123500/758000 (epoch 325), train_loss = 0.279, time/batch = 0.029, All_Time = 3631.001
123550/758000 (epoch 325), train_loss = 0.240, time/batch = 0.029, All_Time = 3632.480
123600/758000 (epoch 326), train_loss = 0.236, time/batch = 0.029, All_Time = 3633.961
123650/758000 (epoch 326), train_loss = 0.234, time/batch = 0.030, All_Time = 3635.428
123700/758000 (epoch 326), train_loss = 0.233, time/batch = 0.029, All_Time = 3636.891
123750/758000 (epoch 326), train_loss = 0.276, time/batch = 0.032, All_Time = 3638.377
123800/758000 (epoch 326), train_loss = 0.206, time/batch = 0.030, All_Time = 3639.854
123850/758000 (epoch 326), train_loss = 0.260, time/batch = 0.030, All_Time = 3641.331
123900/758000 (epoch 326), train_loss = 0.234, time/batch = 0.029, All_Time = 3642.797
123950/758000 (epoch 327), train_loss = 0.246, time/batch = 0.029, All_Time = 3644.277
124000/758000 (epoch 327), train_loss = 0.223, time/batch = 0.029, All_Time = 3645.758
model saved to NER/polyglot/model.ckpt
124050/758000 (epoch 327), train_loss = 0.240, time/batch = 0.028, All_Time = 3647.224
124100/758000 (epoch 327), train_loss = 0.256, time/batch = 0.029, All_Time = 3648.694
124150/758000 (epoch 327), train_loss = 0.214, time/batch = 0.029, All_Time = 3650.172
124200/758000 (epoch 327), train_loss = 0.272, time/batch = 0.028, All_Time = 3651.648
124250/758000 (epoch 327), train_loss = 0.213, time/batch = 0.029, All_Time = 3653.114
124300/758000 (epoch 327), train_loss = 0.252, time/batch = 0.030, All_Time = 3654.586
124350/758000 (epoch 328), train_loss = 0.247, time/batch = 0.029, All_Time = 3656.071
124400/758000 (epoch 328), train_loss = 0.229, time/batch = 0.029, All_Time = 3657.551
124450/758000 (epoch 328), train_loss = 0.217, time/batch = 0.029, All_Time = 3659.022
124500/758000 (epoch 328), train_loss = 0.220, time/batch = 0.030, All_Time = 3660.489
124550/758000 (epoch 328), train_loss = 0.250, time/batch = 0.030, All_Time = 3661.975
124600/758000 (epoch 328), train_loss = 0.207, time/batch = 0.029, All_Time = 3663.470
124650/758000 (epoch 328), train_loss = 0.268, time/batch = 0.030, All_Time = 3664.966
124700/758000 (epoch 329), train_loss = 0.257, time/batch = 0.029, All_Time = 3666.455
124750/758000 (epoch 329), train_loss = 0.264, time/batch = 0.029, All_Time = 3667.933
124800/758000 (epoch 329), train_loss = 0.284, time/batch = 0.028, All_Time = 3669.404
124850/758000 (epoch 329), train_loss = 0.239, time/batch = 0.029, All_Time = 3670.875
124900/758000 (epoch 329), train_loss = 0.267, time/batch = 0.029, All_Time = 3672.351
124950/758000 (epoch 329), train_loss = 0.256, time/batch = 0.030, All_Time = 3673.828
125000/758000 (epoch 329), train_loss = 0.236, time/batch = 0.029, All_Time = 3675.300
model saved to NER/polyglot/model.ckpt
125050/758000 (epoch 329), train_loss = 0.269, time/batch = 0.029, All_Time = 3676.773
125100/758000 (epoch 330), train_loss = 0.226, time/batch = 0.029, All_Time = 3678.249
125150/758000 (epoch 330), train_loss = 0.222, time/batch = 0.030, All_Time = 3679.830
125200/758000 (epoch 330), train_loss = 0.261, time/batch = 0.030, All_Time = 3681.328
125250/758000 (epoch 330), train_loss = 0.254, time/batch = 0.031, All_Time = 3682.810
125300/758000 (epoch 330), train_loss = 0.223, time/batch = 0.031, All_Time = 3684.304
125350/758000 (epoch 330), train_loss = 0.242, time/batch = 0.030, All_Time = 3685.809
125400/758000 (epoch 330), train_loss = 0.252, time/batch = 0.029, All_Time = 3687.286
125450/758000 (epoch 331), train_loss = 0.192, time/batch = 0.029, All_Time = 3688.758
125500/758000 (epoch 331), train_loss = 0.273, time/batch = 0.030, All_Time = 3690.223
125550/758000 (epoch 331), train_loss = 0.217, time/batch = 0.028, All_Time = 3691.682
125600/758000 (epoch 331), train_loss = 0.241, time/batch = 0.029, All_Time = 3693.149
125650/758000 (epoch 331), train_loss = 0.221, time/batch = 0.030, All_Time = 3694.652
125700/758000 (epoch 331), train_loss = 0.221, time/batch = 0.029, All_Time = 3696.144
125750/758000 (epoch 331), train_loss = 0.252, time/batch = 0.030, All_Time = 3697.614
125800/758000 (epoch 331), train_loss = 0.272, time/batch = 0.030, All_Time = 3699.085
125850/758000 (epoch 332), train_loss = 0.222, time/batch = 0.030, All_Time = 3700.566
125900/758000 (epoch 332), train_loss = 0.279, time/batch = 0.032, All_Time = 3702.051
125950/758000 (epoch 332), train_loss = 0.242, time/batch = 0.029, All_Time = 3703.532
126000/758000 (epoch 332), train_loss = 0.274, time/batch = 0.029, All_Time = 3705.000
model saved to NER/polyglot/model.ckpt
126050/758000 (epoch 332), train_loss = 0.262, time/batch = 0.029, All_Time = 3706.469
126100/758000 (epoch 332), train_loss = 0.198, time/batch = 0.031, All_Time = 3707.938
126150/758000 (epoch 332), train_loss = 0.233, time/batch = 0.030, All_Time = 3709.415
126200/758000 (epoch 332), train_loss = 0.281, time/batch = 0.030, All_Time = 3710.884
126250/758000 (epoch 333), train_loss = 0.246, time/batch = 0.030, All_Time = 3712.358
126300/758000 (epoch 333), train_loss = 0.212, time/batch = 0.029, All_Time = 3713.830
126350/758000 (epoch 333), train_loss = 0.255, time/batch = 0.029, All_Time = 3715.301
126400/758000 (epoch 333), train_loss = 0.271, time/batch = 0.030, All_Time = 3716.766
126450/758000 (epoch 333), train_loss = 0.203, time/batch = 0.028, All_Time = 3718.214
126500/758000 (epoch 333), train_loss = 0.226, time/batch = 0.030, All_Time = 3719.683
126550/758000 (epoch 333), train_loss = 0.255, time/batch = 0.030, All_Time = 3721.154
126600/758000 (epoch 334), train_loss = 0.219, time/batch = 0.029, All_Time = 3722.639
126650/758000 (epoch 334), train_loss = 0.265, time/batch = 0.028, All_Time = 3724.112
126700/758000 (epoch 334), train_loss = 0.228, time/batch = 0.030, All_Time = 3725.623
126750/758000 (epoch 334), train_loss = 0.213, time/batch = 0.029, All_Time = 3727.122
126800/758000 (epoch 334), train_loss = 0.224, time/batch = 0.029, All_Time = 3728.598
126850/758000 (epoch 334), train_loss = 0.213, time/batch = 0.029, All_Time = 3730.066
126900/758000 (epoch 334), train_loss = 0.231, time/batch = 0.031, All_Time = 3731.552
126950/758000 (epoch 334), train_loss = 0.223, time/batch = 0.029, All_Time = 3733.035
127000/758000 (epoch 335), train_loss = 0.275, time/batch = 0.029, All_Time = 3734.515
model saved to NER/polyglot/model.ckpt
127050/758000 (epoch 335), train_loss = 0.229, time/batch = 0.029, All_Time = 3735.982
127100/758000 (epoch 335), train_loss = 0.270, time/batch = 0.029, All_Time = 3737.454
127150/758000 (epoch 335), train_loss = 0.273, time/batch = 0.028, All_Time = 3738.924
127200/758000 (epoch 335), train_loss = 0.233, time/batch = 0.028, All_Time = 3740.390
127250/758000 (epoch 335), train_loss = 0.268, time/batch = 0.032, All_Time = 3741.875
127300/758000 (epoch 335), train_loss = 0.280, time/batch = 0.030, All_Time = 3743.390
127350/758000 (epoch 336), train_loss = 0.239, time/batch = 0.030, All_Time = 3744.887
127400/758000 (epoch 336), train_loss = 0.218, time/batch = 0.030, All_Time = 3746.372
127450/758000 (epoch 336), train_loss = 0.243, time/batch = 0.029, All_Time = 3747.836
127500/758000 (epoch 336), train_loss = 0.244, time/batch = 0.029, All_Time = 3749.321
127550/758000 (epoch 336), train_loss = 0.243, time/batch = 0.031, All_Time = 3750.789
127600/758000 (epoch 336), train_loss = 0.244, time/batch = 0.029, All_Time = 3752.261
127650/758000 (epoch 336), train_loss = 0.213, time/batch = 0.029, All_Time = 3753.735
127700/758000 (epoch 336), train_loss = 0.289, time/batch = 0.030, All_Time = 3755.207
127750/758000 (epoch 337), train_loss = 0.238, time/batch = 0.029, All_Time = 3756.671
127800/758000 (epoch 337), train_loss = 0.246, time/batch = 0.028, All_Time = 3758.132
127850/758000 (epoch 337), train_loss = 0.288, time/batch = 0.028, All_Time = 3759.618
127900/758000 (epoch 337), train_loss = 0.257, time/batch = 0.030, All_Time = 3761.077
127950/758000 (epoch 337), train_loss = 0.218, time/batch = 0.030, All_Time = 3762.542
128000/758000 (epoch 337), train_loss = 0.238, time/batch = 0.030, All_Time = 3764.016
model saved to NER/polyglot/model.ckpt
128050/758000 (epoch 337), train_loss = 0.251, time/batch = 0.030, All_Time = 3765.511
128100/758000 (epoch 337), train_loss = 0.251, time/batch = 0.030, All_Time = 3766.980
128150/758000 (epoch 338), train_loss = 0.252, time/batch = 0.030, All_Time = 3768.477
128200/758000 (epoch 338), train_loss = 0.280, time/batch = 0.030, All_Time = 3769.950
128250/758000 (epoch 338), train_loss = 0.242, time/batch = 0.029, All_Time = 3771.416
128300/758000 (epoch 338), train_loss = 0.250, time/batch = 0.029, All_Time = 3772.889
128350/758000 (epoch 338), train_loss = 0.239, time/batch = 0.029, All_Time = 3774.360
128400/758000 (epoch 338), train_loss = 0.240, time/batch = 0.031, All_Time = 3775.844
128450/758000 (epoch 338), train_loss = 0.251, time/batch = 0.030, All_Time = 3777.336
128500/758000 (epoch 339), train_loss = 0.221, time/batch = 0.030, All_Time = 3778.819
128550/758000 (epoch 339), train_loss = 0.219, time/batch = 0.030, All_Time = 3780.317
128600/758000 (epoch 339), train_loss = 0.246, time/batch = 0.029, All_Time = 3781.805
128650/758000 (epoch 339), train_loss = 0.262, time/batch = 0.030, All_Time = 3783.279
128700/758000 (epoch 339), train_loss = 0.260, time/batch = 0.028, All_Time = 3784.754
128750/758000 (epoch 339), train_loss = 0.242, time/batch = 0.029, All_Time = 3786.229
128800/758000 (epoch 339), train_loss = 0.210, time/batch = 0.029, All_Time = 3787.709
128850/758000 (epoch 339), train_loss = 0.239, time/batch = 0.029, All_Time = 3789.182
128900/758000 (epoch 340), train_loss = 0.230, time/batch = 0.030, All_Time = 3790.664
128950/758000 (epoch 340), train_loss = 0.227, time/batch = 0.029, All_Time = 3792.144
129000/758000 (epoch 340), train_loss = 0.264, time/batch = 0.029, All_Time = 3793.623
model saved to NER/polyglot/model.ckpt
129050/758000 (epoch 340), train_loss = 0.240, time/batch = 0.031, All_Time = 3795.095
129100/758000 (epoch 340), train_loss = 0.253, time/batch = 0.030, All_Time = 3796.556
129150/758000 (epoch 340), train_loss = 0.251, time/batch = 0.028, All_Time = 3798.028
129200/758000 (epoch 340), train_loss = 0.248, time/batch = 0.030, All_Time = 3799.513
129250/758000 (epoch 341), train_loss = 0.216, time/batch = 0.029, All_Time = 3801.009
129300/758000 (epoch 341), train_loss = 0.233, time/batch = 0.028, All_Time = 3802.488
129350/758000 (epoch 341), train_loss = 0.250, time/batch = 0.029, All_Time = 3803.955
129400/758000 (epoch 341), train_loss = 0.241, time/batch = 0.030, All_Time = 3805.430
129450/758000 (epoch 341), train_loss = 0.243, time/batch = 0.029, All_Time = 3806.907
129500/758000 (epoch 341), train_loss = 0.242, time/batch = 0.029, All_Time = 3808.377
129550/758000 (epoch 341), train_loss = 0.230, time/batch = 0.028, All_Time = 3809.853
129600/758000 (epoch 341), train_loss = 0.259, time/batch = 0.030, All_Time = 3811.320
129650/758000 (epoch 342), train_loss = 0.250, time/batch = 0.029, All_Time = 3812.790
129700/758000 (epoch 342), train_loss = 0.253, time/batch = 0.029, All_Time = 3814.248
129750/758000 (epoch 342), train_loss = 0.245, time/batch = 0.030, All_Time = 3815.714
129800/758000 (epoch 342), train_loss = 0.231, time/batch = 0.029, All_Time = 3817.213
129850/758000 (epoch 342), train_loss = 0.228, time/batch = 0.029, All_Time = 3818.696
129900/758000 (epoch 342), train_loss = 0.238, time/batch = 0.029, All_Time = 3820.173
129950/758000 (epoch 342), train_loss = 0.268, time/batch = 0.030, All_Time = 3821.658
130000/758000 (epoch 343), train_loss = 0.249, time/batch = 0.033, All_Time = 3823.152
model saved to NER/polyglot/model.ckpt
130050/758000 (epoch 343), train_loss = 0.281, time/batch = 0.029, All_Time = 3824.610
130100/758000 (epoch 343), train_loss = 0.243, time/batch = 0.028, All_Time = 3826.073
130150/758000 (epoch 343), train_loss = 0.258, time/batch = 0.029, All_Time = 3827.541
130200/758000 (epoch 343), train_loss = 0.224, time/batch = 0.030, All_Time = 3829.008
130250/758000 (epoch 343), train_loss = 0.243, time/batch = 0.029, All_Time = 3830.483
130300/758000 (epoch 343), train_loss = 0.219, time/batch = 0.030, All_Time = 3832.001
130350/758000 (epoch 343), train_loss = 0.233, time/batch = 0.031, All_Time = 3833.479
130400/758000 (epoch 344), train_loss = 0.237, time/batch = 0.029, All_Time = 3834.975
130450/758000 (epoch 344), train_loss = 0.239, time/batch = 0.030, All_Time = 3836.449
130500/758000 (epoch 344), train_loss = 0.293, time/batch = 0.028, All_Time = 3837.914
130550/758000 (epoch 344), train_loss = 0.318, time/batch = 0.029, All_Time = 3839.370
130600/758000 (epoch 344), train_loss = 0.196, time/batch = 0.029, All_Time = 3840.834
130650/758000 (epoch 344), train_loss = 0.213, time/batch = 0.029, All_Time = 3842.305
130700/758000 (epoch 344), train_loss = 0.250, time/batch = 0.030, All_Time = 3843.781
130750/758000 (epoch 344), train_loss = 0.297, time/batch = 0.031, All_Time = 3845.251
130800/758000 (epoch 345), train_loss = 0.227, time/batch = 0.030, All_Time = 3846.722
130850/758000 (epoch 345), train_loss = 0.259, time/batch = 0.029, All_Time = 3848.179
130900/758000 (epoch 345), train_loss = 0.223, time/batch = 0.029, All_Time = 3849.647
130950/758000 (epoch 345), train_loss = 0.239, time/batch = 0.031, All_Time = 3851.150
131000/758000 (epoch 345), train_loss = 0.212, time/batch = 0.028, All_Time = 3852.645
model saved to NER/polyglot/model.ckpt
131050/758000 (epoch 345), train_loss = 0.243, time/batch = 0.029, All_Time = 3854.114
131100/758000 (epoch 345), train_loss = 0.216, time/batch = 0.030, All_Time = 3855.573
131150/758000 (epoch 346), train_loss = 0.228, time/batch = 0.028, All_Time = 3857.032
131200/758000 (epoch 346), train_loss = 0.252, time/batch = 0.029, All_Time = 3858.498
131250/758000 (epoch 346), train_loss = 0.260, time/batch = 0.029, All_Time = 3859.962
131300/758000 (epoch 346), train_loss = 0.228, time/batch = 0.030, All_Time = 3861.429
131350/758000 (epoch 346), train_loss = 0.236, time/batch = 0.029, All_Time = 3862.895
131400/758000 (epoch 346), train_loss = 0.271, time/batch = 0.030, All_Time = 3864.359
131450/758000 (epoch 346), train_loss = 0.238, time/batch = 0.031, All_Time = 3865.868
131500/758000 (epoch 346), train_loss = 0.268, time/batch = 0.030, All_Time = 3867.357
131550/758000 (epoch 347), train_loss = 0.248, time/batch = 0.029, All_Time = 3868.841
131600/758000 (epoch 347), train_loss = 0.249, time/batch = 0.030, All_Time = 3870.317
131650/758000 (epoch 347), train_loss = 0.240, time/batch = 0.029, All_Time = 3871.786
131700/758000 (epoch 347), train_loss = 0.247, time/batch = 0.029, All_Time = 3873.255
131750/758000 (epoch 347), train_loss = 0.235, time/batch = 0.030, All_Time = 3874.749
131800/758000 (epoch 347), train_loss = 0.247, time/batch = 0.028, All_Time = 3876.216
131850/758000 (epoch 347), train_loss = 0.251, time/batch = 0.031, All_Time = 3877.685
131900/758000 (epoch 348), train_loss = 0.242, time/batch = 0.029, All_Time = 3879.158
131950/758000 (epoch 348), train_loss = 0.276, time/batch = 0.031, All_Time = 3880.633
132000/758000 (epoch 348), train_loss = 0.256, time/batch = 0.029, All_Time = 3882.101
model saved to NER/polyglot/model.ckpt
132050/758000 (epoch 348), train_loss = 0.258, time/batch = 0.029, All_Time = 3883.563
132100/758000 (epoch 348), train_loss = 0.213, time/batch = 0.029, All_Time = 3885.033
132150/758000 (epoch 348), train_loss = 0.237, time/batch = 0.030, All_Time = 3886.526
132200/758000 (epoch 348), train_loss = 0.249, time/batch = 0.029, All_Time = 3888.018
132250/758000 (epoch 348), train_loss = 0.251, time/batch = 0.029, All_Time = 3889.507
132300/758000 (epoch 349), train_loss = 0.232, time/batch = 0.028, All_Time = 3890.987
132350/758000 (epoch 349), train_loss = 0.255, time/batch = 0.029, All_Time = 3892.461
132400/758000 (epoch 349), train_loss = 0.265, time/batch = 0.029, All_Time = 3893.937
132450/758000 (epoch 349), train_loss = 0.229, time/batch = 0.029, All_Time = 3895.407
132500/758000 (epoch 349), train_loss = 0.263, time/batch = 0.030, All_Time = 3896.876
132550/758000 (epoch 349), train_loss = 0.217, time/batch = 0.029, All_Time = 3898.347
132600/758000 (epoch 349), train_loss = 0.248, time/batch = 0.029, All_Time = 3899.815
132650/758000 (epoch 350), train_loss = 0.059, time/batch = 0.035, All_Time = 3901.300
132700/758000 (epoch 350), train_loss = 0.250, time/batch = 0.030, All_Time = 3902.798
132750/758000 (epoch 350), train_loss = 0.223, time/batch = 0.029, All_Time = 3904.279
132800/758000 (epoch 350), train_loss = 0.250, time/batch = 0.030, All_Time = 3905.754
132850/758000 (epoch 350), train_loss = 0.231, time/batch = 0.030, All_Time = 3907.219
132900/758000 (epoch 350), train_loss = 0.251, time/batch = 0.030, All_Time = 3908.724
132950/758000 (epoch 350), train_loss = 0.232, time/batch = 0.030, All_Time = 3910.195
133000/758000 (epoch 350), train_loss = 0.230, time/batch = 0.029, All_Time = 3911.667
model saved to NER/polyglot/model.ckpt
133050/758000 (epoch 351), train_loss = 0.224, time/batch = 0.030, All_Time = 3913.138
133100/758000 (epoch 351), train_loss = 0.233, time/batch = 0.031, All_Time = 3914.608
133150/758000 (epoch 351), train_loss = 0.224, time/batch = 0.028, All_Time = 3916.070
133200/758000 (epoch 351), train_loss = 0.262, time/batch = 0.030, All_Time = 3917.543
133250/758000 (epoch 351), train_loss = 0.220, time/batch = 0.030, All_Time = 3919.010
133300/758000 (epoch 351), train_loss = 0.228, time/batch = 0.030, All_Time = 3920.491
133350/758000 (epoch 351), train_loss = 0.280, time/batch = 0.030, All_Time = 3921.958
133400/758000 (epoch 351), train_loss = 0.272, time/batch = 0.031, All_Time = 3923.482
133450/758000 (epoch 352), train_loss = 0.230, time/batch = 0.029, All_Time = 3924.974
133500/758000 (epoch 352), train_loss = 0.224, time/batch = 0.030, All_Time = 3926.453
133550/758000 (epoch 352), train_loss = 0.201, time/batch = 0.029, All_Time = 3927.933
133600/758000 (epoch 352), train_loss = 0.270, time/batch = 0.028, All_Time = 3929.409
133650/758000 (epoch 352), train_loss = 0.260, time/batch = 0.030, All_Time = 3930.884
133700/758000 (epoch 352), train_loss = 0.209, time/batch = 0.030, All_Time = 3932.351
133750/758000 (epoch 352), train_loss = 0.218, time/batch = 0.030, All_Time = 3933.821
133800/758000 (epoch 353), train_loss = 0.229, time/batch = 0.030, All_Time = 3935.302
133850/758000 (epoch 353), train_loss = 0.283, time/batch = 0.030, All_Time = 3936.780
133900/758000 (epoch 353), train_loss = 0.232, time/batch = 0.029, All_Time = 3938.260
133950/758000 (epoch 353), train_loss = 0.307, time/batch = 0.030, All_Time = 3939.739
134000/758000 (epoch 353), train_loss = 0.221, time/batch = 0.029, All_Time = 3941.205
model saved to NER/polyglot/model.ckpt
134050/758000 (epoch 353), train_loss = 0.209, time/batch = 0.030, All_Time = 3942.682
134100/758000 (epoch 353), train_loss = 0.247, time/batch = 0.030, All_Time = 3944.146
134150/758000 (epoch 353), train_loss = 0.252, time/batch = 0.029, All_Time = 3945.621
134200/758000 (epoch 354), train_loss = 0.264, time/batch = 0.029, All_Time = 3947.106
134250/758000 (epoch 354), train_loss = 0.229, time/batch = 0.029, All_Time = 3948.585
134300/758000 (epoch 354), train_loss = 0.242, time/batch = 0.029, All_Time = 3950.074
134350/758000 (epoch 354), train_loss = 0.268, time/batch = 0.030, All_Time = 3951.572
134400/758000 (epoch 354), train_loss = 0.249, time/batch = 0.030, All_Time = 3953.058
134450/758000 (epoch 354), train_loss = 0.237, time/batch = 0.029, All_Time = 3954.533
134500/758000 (epoch 354), train_loss = 0.276, time/batch = 0.030, All_Time = 3956.014
134550/758000 (epoch 355), train_loss = 0.256, time/batch = 0.029, All_Time = 3957.503
134600/758000 (epoch 355), train_loss = 0.222, time/batch = 0.030, All_Time = 3958.977
134650/758000 (epoch 355), train_loss = 0.266, time/batch = 0.029, All_Time = 3960.458
134700/758000 (epoch 355), train_loss = 0.216, time/batch = 0.030, All_Time = 3961.933
134750/758000 (epoch 355), train_loss = 0.223, time/batch = 0.029, All_Time = 3963.419
134800/758000 (epoch 355), train_loss = 0.261, time/batch = 0.030, All_Time = 3964.886
134850/758000 (epoch 355), train_loss = 0.238, time/batch = 0.029, All_Time = 3966.372
134900/758000 (epoch 355), train_loss = 0.264, time/batch = 0.029, All_Time = 3967.845
134950/758000 (epoch 356), train_loss = 0.223, time/batch = 0.031, All_Time = 3969.325
135000/758000 (epoch 356), train_loss = 0.231, time/batch = 0.031, All_Time = 3970.819
model saved to NER/polyglot/model.ckpt
135050/758000 (epoch 356), train_loss = 0.238, time/batch = 0.028, All_Time = 3972.293
135100/758000 (epoch 356), train_loss = 0.266, time/batch = 0.029, All_Time = 3973.768
135150/758000 (epoch 356), train_loss = 0.239, time/batch = 0.030, All_Time = 3975.251
135200/758000 (epoch 356), train_loss = 0.226, time/batch = 0.029, All_Time = 3976.730
135250/758000 (epoch 356), train_loss = 0.275, time/batch = 0.030, All_Time = 3978.210
135300/758000 (epoch 356), train_loss = 0.240, time/batch = 0.029, All_Time = 3979.695
135350/758000 (epoch 357), train_loss = 0.282, time/batch = 0.030, All_Time = 3981.167
135400/758000 (epoch 357), train_loss = 0.257, time/batch = 0.030, All_Time = 3982.637
135450/758000 (epoch 357), train_loss = 0.240, time/batch = 0.030, All_Time = 3984.101
135500/758000 (epoch 357), train_loss = 0.231, time/batch = 0.030, All_Time = 3985.571
135550/758000 (epoch 357), train_loss = 0.217, time/batch = 0.029, All_Time = 3987.034
135600/758000 (epoch 357), train_loss = 0.224, time/batch = 0.030, All_Time = 3988.505
135650/758000 (epoch 357), train_loss = 0.215, time/batch = 0.031, All_Time = 3989.980
135700/758000 (epoch 358), train_loss = 0.249, time/batch = 0.030, All_Time = 3991.483
135750/758000 (epoch 358), train_loss = 0.211, time/batch = 0.031, All_Time = 3992.955
135800/758000 (epoch 358), train_loss = 0.245, time/batch = 0.030, All_Time = 3994.450
135850/758000 (epoch 358), train_loss = 0.217, time/batch = 0.030, All_Time = 3995.931
135900/758000 (epoch 358), train_loss = 0.233, time/batch = 0.030, All_Time = 3997.403
135950/758000 (epoch 358), train_loss = 0.228, time/batch = 0.029, All_Time = 3998.877
136000/758000 (epoch 358), train_loss = 0.248, time/batch = 0.031, All_Time = 4000.355
model saved to NER/polyglot/model.ckpt
136050/758000 (epoch 358), train_loss = 0.229, time/batch = 0.029, All_Time = 4001.833
136100/758000 (epoch 359), train_loss = 0.218, time/batch = 0.031, All_Time = 4003.316
136150/758000 (epoch 359), train_loss = 0.237, time/batch = 0.030, All_Time = 4004.789
136200/758000 (epoch 359), train_loss = 0.212, time/batch = 0.029, All_Time = 4006.257
136250/758000 (epoch 359), train_loss = 0.266, time/batch = 0.028, All_Time = 4007.736
136300/758000 (epoch 359), train_loss = 0.255, time/batch = 0.033, All_Time = 4009.220
136350/758000 (epoch 359), train_loss = 0.232, time/batch = 0.029, All_Time = 4010.693
136400/758000 (epoch 359), train_loss = 0.262, time/batch = 0.030, All_Time = 4012.160
136450/758000 (epoch 360), train_loss = 0.282, time/batch = 0.029, All_Time = 4013.633
136500/758000 (epoch 360), train_loss = 0.292, time/batch = 0.029, All_Time = 4015.094
136550/758000 (epoch 360), train_loss = 0.253, time/batch = 0.030, All_Time = 4016.566
136600/758000 (epoch 360), train_loss = 0.222, time/batch = 0.029, All_Time = 4018.026
136650/758000 (epoch 360), train_loss = 0.221, time/batch = 0.030, All_Time = 4019.509
136700/758000 (epoch 360), train_loss = 0.260, time/batch = 0.031, All_Time = 4021.011
136750/758000 (epoch 360), train_loss = 0.244, time/batch = 0.027, All_Time = 4022.498
136800/758000 (epoch 360), train_loss = 0.247, time/batch = 0.030, All_Time = 4023.980
136850/758000 (epoch 361), train_loss = 0.210, time/batch = 0.031, All_Time = 4025.469
136900/758000 (epoch 361), train_loss = 0.265, time/batch = 0.034, All_Time = 4027.031
136950/758000 (epoch 361), train_loss = 0.229, time/batch = 0.030, All_Time = 4028.549
137000/758000 (epoch 361), train_loss = 0.232, time/batch = 0.030, All_Time = 4030.035
model saved to NER/polyglot/model.ckpt
137050/758000 (epoch 361), train_loss = 0.230, time/batch = 0.029, All_Time = 4031.615
137100/758000 (epoch 361), train_loss = 0.253, time/batch = 0.029, All_Time = 4033.079
137150/758000 (epoch 361), train_loss = 0.258, time/batch = 0.028, All_Time = 4034.530
137200/758000 (epoch 362), train_loss = 0.196, time/batch = 0.030, All_Time = 4036.042
137250/758000 (epoch 362), train_loss = 0.254, time/batch = 0.029, All_Time = 4037.527
137300/758000 (epoch 362), train_loss = 0.281, time/batch = 0.030, All_Time = 4038.996
137350/758000 (epoch 362), train_loss = 0.235, time/batch = 0.028, All_Time = 4040.459
137400/758000 (epoch 362), train_loss = 0.247, time/batch = 0.028, All_Time = 4041.921
137450/758000 (epoch 362), train_loss = 0.251, time/batch = 0.031, All_Time = 4043.384
137500/758000 (epoch 362), train_loss = 0.203, time/batch = 0.029, All_Time = 4044.847
137550/758000 (epoch 362), train_loss = 0.269, time/batch = 0.029, All_Time = 4046.320
137600/758000 (epoch 363), train_loss = 0.234, time/batch = 0.028, All_Time = 4047.806
137650/758000 (epoch 363), train_loss = 0.241, time/batch = 0.031, All_Time = 4049.282
137700/758000 (epoch 363), train_loss = 0.252, time/batch = 0.031, All_Time = 4050.752
137750/758000 (epoch 363), train_loss = 0.258, time/batch = 0.031, All_Time = 4052.233
137800/758000 (epoch 363), train_loss = 0.243, time/batch = 0.029, All_Time = 4053.703
137850/758000 (epoch 363), train_loss = 0.243, time/batch = 0.029, All_Time = 4055.176
137900/758000 (epoch 363), train_loss = 0.244, time/batch = 0.029, All_Time = 4056.652
137950/758000 (epoch 363), train_loss = 0.286, time/batch = 0.029, All_Time = 4058.125
138000/758000 (epoch 364), train_loss = 0.207, time/batch = 0.029, All_Time = 4059.611
model saved to NER/polyglot/model.ckpt
138050/758000 (epoch 364), train_loss = 0.244, time/batch = 0.029, All_Time = 4061.067
138100/758000 (epoch 364), train_loss = 0.217, time/batch = 0.030, All_Time = 4062.530
138150/758000 (epoch 364), train_loss = 0.234, time/batch = 0.029, All_Time = 4064.000
138200/758000 (epoch 364), train_loss = 0.260, time/batch = 0.028, All_Time = 4065.464
138250/758000 (epoch 364), train_loss = 0.253, time/batch = 0.031, All_Time = 4066.979
138300/758000 (epoch 364), train_loss = 0.238, time/batch = 0.032, All_Time = 4068.472
138350/758000 (epoch 365), train_loss = 0.227, time/batch = 0.030, All_Time = 4069.956
138400/758000 (epoch 365), train_loss = 0.250, time/batch = 0.031, All_Time = 4071.425
138450/758000 (epoch 365), train_loss = 0.250, time/batch = 0.030, All_Time = 4072.898
138500/758000 (epoch 365), train_loss = 0.223, time/batch = 0.030, All_Time = 4074.375
138550/758000 (epoch 365), train_loss = 0.240, time/batch = 0.029, All_Time = 4075.852
138600/758000 (epoch 365), train_loss = 0.246, time/batch = 0.029, All_Time = 4077.317
138650/758000 (epoch 365), train_loss = 0.246, time/batch = 0.030, All_Time = 4078.800
138700/758000 (epoch 365), train_loss = 0.257, time/batch = 0.031, All_Time = 4080.264
138750/758000 (epoch 366), train_loss = 0.266, time/batch = 0.031, All_Time = 4081.736
138800/758000 (epoch 366), train_loss = 0.224, time/batch = 0.029, All_Time = 4083.202
138850/758000 (epoch 366), train_loss = 0.248, time/batch = 0.029, All_Time = 4084.710
138900/758000 (epoch 366), train_loss = 0.227, time/batch = 0.030, All_Time = 4086.207
138950/758000 (epoch 366), train_loss = 0.279, time/batch = 0.030, All_Time = 4087.681
139000/758000 (epoch 366), train_loss = 0.255, time/batch = 0.030, All_Time = 4089.154
model saved to NER/polyglot/model.ckpt
139050/758000 (epoch 366), train_loss = 0.254, time/batch = 0.030, All_Time = 4090.619
139100/758000 (epoch 367), train_loss = 0.244, time/batch = 0.029, All_Time = 4092.095
139150/758000 (epoch 367), train_loss = 0.247, time/batch = 0.028, All_Time = 4093.558
139200/758000 (epoch 367), train_loss = 0.270, time/batch = 0.029, All_Time = 4095.033
139250/758000 (epoch 367), train_loss = 0.246, time/batch = 0.030, All_Time = 4096.520
139300/758000 (epoch 367), train_loss = 0.237, time/batch = 0.029, All_Time = 4098.006
139350/758000 (epoch 367), train_loss = 0.224, time/batch = 0.031, All_Time = 4099.506
139400/758000 (epoch 367), train_loss = 0.229, time/batch = 0.029, All_Time = 4100.980
139450/758000 (epoch 367), train_loss = 0.246, time/batch = 0.030, All_Time = 4102.451
139500/758000 (epoch 368), train_loss = 0.249, time/batch = 0.030, All_Time = 4103.940
139550/758000 (epoch 368), train_loss = 0.264, time/batch = 0.029, All_Time = 4105.420
139600/758000 (epoch 368), train_loss = 0.240, time/batch = 0.029, All_Time = 4106.895
139650/758000 (epoch 368), train_loss = 0.250, time/batch = 0.032, All_Time = 4108.381
139700/758000 (epoch 368), train_loss = 0.227, time/batch = 0.030, All_Time = 4109.858
139750/758000 (epoch 368), train_loss = 0.217, time/batch = 0.029, All_Time = 4111.334
139800/758000 (epoch 368), train_loss = 0.277, time/batch = 0.028, All_Time = 4112.822
139850/758000 (epoch 368), train_loss = 0.259, time/batch = 0.029, All_Time = 4114.308
139900/758000 (epoch 369), train_loss = 0.269, time/batch = 0.031, All_Time = 4115.784
139950/758000 (epoch 369), train_loss = 0.296, time/batch = 0.030, All_Time = 4117.260
140000/758000 (epoch 369), train_loss = 0.228, time/batch = 0.029, All_Time = 4118.732
model saved to NER/polyglot/model.ckpt
140050/758000 (epoch 369), train_loss = 0.220, time/batch = 0.031, All_Time = 4120.205
140100/758000 (epoch 369), train_loss = 0.257, time/batch = 0.029, All_Time = 4121.681
140150/758000 (epoch 369), train_loss = 0.255, time/batch = 0.028, All_Time = 4123.136
140200/758000 (epoch 369), train_loss = 0.237, time/batch = 0.031, All_Time = 4124.637
140250/758000 (epoch 370), train_loss = 0.225, time/batch = 0.030, All_Time = 4126.122
140300/758000 (epoch 370), train_loss = 0.234, time/batch = 0.030, All_Time = 4127.598
140350/758000 (epoch 370), train_loss = 0.243, time/batch = 0.031, All_Time = 4129.075
140400/758000 (epoch 370), train_loss = 0.234, time/batch = 0.030, All_Time = 4130.547
140450/758000 (epoch 370), train_loss = 0.223, time/batch = 0.029, All_Time = 4132.022
140500/758000 (epoch 370), train_loss = 0.239, time/batch = 0.029, All_Time = 4133.490
140550/758000 (epoch 370), train_loss = 0.264, time/batch = 0.029, All_Time = 4134.958
140600/758000 (epoch 370), train_loss = 0.244, time/batch = 0.031, All_Time = 4136.430
140650/758000 (epoch 371), train_loss = 0.257, time/batch = 0.031, All_Time = 4137.910
140700/758000 (epoch 371), train_loss = 0.287, time/batch = 0.031, All_Time = 4139.372
140750/758000 (epoch 371), train_loss = 0.255, time/batch = 0.029, All_Time = 4140.831
140800/758000 (epoch 371), train_loss = 0.249, time/batch = 0.031, All_Time = 4142.321
140850/758000 (epoch 371), train_loss = 0.212, time/batch = 0.030, All_Time = 4143.806
140900/758000 (epoch 371), train_loss = 0.229, time/batch = 0.029, All_Time = 4145.276
140950/758000 (epoch 371), train_loss = 0.272, time/batch = 0.030, All_Time = 4146.747
141000/758000 (epoch 372), train_loss = 0.249, time/batch = 0.029, All_Time = 4148.256
model saved to NER/polyglot/model.ckpt
141050/758000 (epoch 372), train_loss = 0.227, time/batch = 0.032, All_Time = 4149.734
141100/758000 (epoch 372), train_loss = 0.267, time/batch = 0.030, All_Time = 4151.206
141150/758000 (epoch 372), train_loss = 0.239, time/batch = 0.031, All_Time = 4152.669
141200/758000 (epoch 372), train_loss = 0.247, time/batch = 0.029, All_Time = 4154.134
141250/758000 (epoch 372), train_loss = 0.241, time/batch = 0.029, All_Time = 4155.618
141300/758000 (epoch 372), train_loss = 0.274, time/batch = 0.029, All_Time = 4157.115
141350/758000 (epoch 372), train_loss = 0.279, time/batch = 0.030, All_Time = 4158.589
141400/758000 (epoch 373), train_loss = 0.238, time/batch = 0.029, All_Time = 4160.074
141450/758000 (epoch 373), train_loss = 0.248, time/batch = 0.030, All_Time = 4161.553
141500/758000 (epoch 373), train_loss = 0.299, time/batch = 0.029, All_Time = 4163.023
141550/758000 (epoch 373), train_loss = 0.230, time/batch = 0.029, All_Time = 4164.496
141600/758000 (epoch 373), train_loss = 0.216, time/batch = 0.028, All_Time = 4165.966
141650/758000 (epoch 373), train_loss = 0.244, time/batch = 0.029, All_Time = 4167.449
141700/758000 (epoch 373), train_loss = 0.274, time/batch = 0.030, All_Time = 4168.929
141750/758000 (epoch 374), train_loss = 0.221, time/batch = 0.030, All_Time = 4170.406
141800/758000 (epoch 374), train_loss = 0.257, time/batch = 0.029, All_Time = 4171.882
141850/758000 (epoch 374), train_loss = 0.241, time/batch = 0.029, All_Time = 4173.347
141900/758000 (epoch 374), train_loss = 0.240, time/batch = 0.030, All_Time = 4174.829
141950/758000 (epoch 374), train_loss = 0.256, time/batch = 0.028, All_Time = 4176.301
142000/758000 (epoch 374), train_loss = 0.219, time/batch = 0.030, All_Time = 4177.776
model saved to NER/polyglot/model.ckpt
142050/758000 (epoch 374), train_loss = 0.224, time/batch = 0.028, All_Time = 4179.240
142100/758000 (epoch 374), train_loss = 0.257, time/batch = 0.028, All_Time = 4180.701
142150/758000 (epoch 375), train_loss = 0.255, time/batch = 0.028, All_Time = 4182.185
142200/758000 (epoch 375), train_loss = 0.267, time/batch = 0.028, All_Time = 4183.642
142250/758000 (epoch 375), train_loss = 0.269, time/batch = 0.030, All_Time = 4185.116
142300/758000 (epoch 375), train_loss = 0.228, time/batch = 0.029, All_Time = 4186.572
142350/758000 (epoch 375), train_loss = 0.234, time/batch = 0.029, All_Time = 4188.042
142400/758000 (epoch 375), train_loss = 0.246, time/batch = 0.028, All_Time = 4189.509
142450/758000 (epoch 375), train_loss = 0.279, time/batch = 0.029, All_Time = 4190.968
142500/758000 (epoch 375), train_loss = 0.240, time/batch = 0.030, All_Time = 4192.447
142550/758000 (epoch 376), train_loss = 0.236, time/batch = 0.030, All_Time = 4193.944
142600/758000 (epoch 376), train_loss = 0.234, time/batch = 0.029, All_Time = 4195.429
142650/758000 (epoch 376), train_loss = 0.233, time/batch = 0.031, All_Time = 4196.911
142700/758000 (epoch 376), train_loss = 0.276, time/batch = 0.030, All_Time = 4198.382
142750/758000 (epoch 376), train_loss = 0.206, time/batch = 0.030, All_Time = 4199.866
142800/758000 (epoch 376), train_loss = 0.259, time/batch = 0.030, All_Time = 4201.339
142850/758000 (epoch 376), train_loss = 0.234, time/batch = 0.029, All_Time = 4202.816
142900/758000 (epoch 377), train_loss = 0.245, time/batch = 0.028, All_Time = 4204.287
142950/758000 (epoch 377), train_loss = 0.223, time/batch = 0.030, All_Time = 4205.748
143000/758000 (epoch 377), train_loss = 0.240, time/batch = 0.029, All_Time = 4207.210
model saved to NER/polyglot/model.ckpt
143050/758000 (epoch 377), train_loss = 0.256, time/batch = 0.030, All_Time = 4208.679
143100/758000 (epoch 377), train_loss = 0.214, time/batch = 0.029, All_Time = 4210.139
143150/758000 (epoch 377), train_loss = 0.272, time/batch = 0.029, All_Time = 4211.616
143200/758000 (epoch 377), train_loss = 0.213, time/batch = 0.030, All_Time = 4213.087
143250/758000 (epoch 377), train_loss = 0.251, time/batch = 0.029, All_Time = 4214.562
143300/758000 (epoch 378), train_loss = 0.247, time/batch = 0.029, All_Time = 4216.055
143350/758000 (epoch 378), train_loss = 0.229, time/batch = 0.031, All_Time = 4217.534
143400/758000 (epoch 378), train_loss = 0.217, time/batch = 0.029, All_Time = 4219.022
143450/758000 (epoch 378), train_loss = 0.220, time/batch = 0.029, All_Time = 4220.497
143500/758000 (epoch 378), train_loss = 0.250, time/batch = 0.029, All_Time = 4221.969
143550/758000 (epoch 378), train_loss = 0.207, time/batch = 0.031, All_Time = 4223.448
143600/758000 (epoch 378), train_loss = 0.268, time/batch = 0.029, All_Time = 4224.927
143650/758000 (epoch 379), train_loss = 0.256, time/batch = 0.029, All_Time = 4226.417
143700/758000 (epoch 379), train_loss = 0.264, time/batch = 0.029, All_Time = 4227.888
143750/758000 (epoch 379), train_loss = 0.284, time/batch = 0.029, All_Time = 4229.345
143800/758000 (epoch 379), train_loss = 0.239, time/batch = 0.029, All_Time = 4230.817
143850/758000 (epoch 379), train_loss = 0.267, time/batch = 0.029, All_Time = 4232.285
143900/758000 (epoch 379), train_loss = 0.256, time/batch = 0.028, All_Time = 4233.760
143950/758000 (epoch 379), train_loss = 0.236, time/batch = 0.029, All_Time = 4235.242
144000/758000 (epoch 379), train_loss = 0.268, time/batch = 0.029, All_Time = 4236.713
model saved to NER/polyglot/model.ckpt
144050/758000 (epoch 380), train_loss = 0.226, time/batch = 0.028, All_Time = 4238.201
144100/758000 (epoch 380), train_loss = 0.222, time/batch = 0.030, All_Time = 4239.663
144150/758000 (epoch 380), train_loss = 0.261, time/batch = 0.029, All_Time = 4241.167
144200/758000 (epoch 380), train_loss = 0.254, time/batch = 0.029, All_Time = 4242.654
144250/758000 (epoch 380), train_loss = 0.223, time/batch = 0.030, All_Time = 4244.122
144300/758000 (epoch 380), train_loss = 0.242, time/batch = 0.029, All_Time = 4245.611
144350/758000 (epoch 380), train_loss = 0.251, time/batch = 0.030, All_Time = 4247.086
144400/758000 (epoch 381), train_loss = 0.192, time/batch = 0.031, All_Time = 4248.566
144450/758000 (epoch 381), train_loss = 0.273, time/batch = 0.030, All_Time = 4250.050
144500/758000 (epoch 381), train_loss = 0.217, time/batch = 0.030, All_Time = 4251.529
144550/758000 (epoch 381), train_loss = 0.240, time/batch = 0.029, All_Time = 4253.010
144600/758000 (epoch 381), train_loss = 0.221, time/batch = 0.030, All_Time = 4254.493
144650/758000 (epoch 381), train_loss = 0.221, time/batch = 0.029, All_Time = 4255.979
144700/758000 (epoch 381), train_loss = 0.252, time/batch = 0.029, All_Time = 4257.567
144750/758000 (epoch 381), train_loss = 0.272, time/batch = 0.029, All_Time = 4259.054
144800/758000 (epoch 382), train_loss = 0.222, time/batch = 0.030, All_Time = 4260.537
144850/758000 (epoch 382), train_loss = 0.279, time/batch = 0.029, All_Time = 4262.007
144900/758000 (epoch 382), train_loss = 0.242, time/batch = 0.029, All_Time = 4263.469
144950/758000 (epoch 382), train_loss = 0.274, time/batch = 0.029, All_Time = 4264.949
145000/758000 (epoch 382), train_loss = 0.262, time/batch = 0.029, All_Time = 4266.418
model saved to NER/polyglot/model.ckpt
145050/758000 (epoch 382), train_loss = 0.197, time/batch = 0.030, All_Time = 4267.904
145100/758000 (epoch 382), train_loss = 0.233, time/batch = 0.030, All_Time = 4269.374
145150/758000 (epoch 382), train_loss = 0.281, time/batch = 0.029, All_Time = 4270.850
145200/758000 (epoch 383), train_loss = 0.246, time/batch = 0.028, All_Time = 4272.322
145250/758000 (epoch 383), train_loss = 0.212, time/batch = 0.029, All_Time = 4273.795
145300/758000 (epoch 383), train_loss = 0.255, time/batch = 0.027, All_Time = 4275.265
145350/758000 (epoch 383), train_loss = 0.271, time/batch = 0.030, All_Time = 4276.741
145400/758000 (epoch 383), train_loss = 0.203, time/batch = 0.029, All_Time = 4278.203
145450/758000 (epoch 383), train_loss = 0.226, time/batch = 0.031, All_Time = 4279.697
145500/758000 (epoch 383), train_loss = 0.254, time/batch = 0.030, All_Time = 4281.175
145550/758000 (epoch 384), train_loss = 0.219, time/batch = 0.030, All_Time = 4282.666
145600/758000 (epoch 384), train_loss = 0.265, time/batch = 0.028, All_Time = 4284.137
145650/758000 (epoch 384), train_loss = 0.227, time/batch = 0.029, All_Time = 4285.622
145700/758000 (epoch 384), train_loss = 0.213, time/batch = 0.029, All_Time = 4287.109
145750/758000 (epoch 384), train_loss = 0.224, time/batch = 0.033, All_Time = 4288.591
145800/758000 (epoch 384), train_loss = 0.213, time/batch = 0.030, All_Time = 4290.078
145850/758000 (epoch 384), train_loss = 0.230, time/batch = 0.030, All_Time = 4291.562
145900/758000 (epoch 384), train_loss = 0.223, time/batch = 0.028, All_Time = 4293.038
145950/758000 (epoch 385), train_loss = 0.275, time/batch = 0.030, All_Time = 4294.533
146000/758000 (epoch 385), train_loss = 0.229, time/batch = 0.031, All_Time = 4296.008
model saved to NER/polyglot/model.ckpt
146050/758000 (epoch 385), train_loss = 0.270, time/batch = 0.027, All_Time = 4297.476
146100/758000 (epoch 385), train_loss = 0.273, time/batch = 0.028, All_Time = 4298.946
146150/758000 (epoch 385), train_loss = 0.233, time/batch = 0.030, All_Time = 4300.429
146200/758000 (epoch 385), train_loss = 0.268, time/batch = 0.030, All_Time = 4301.885
146250/758000 (epoch 385), train_loss = 0.280, time/batch = 0.030, All_Time = 4303.375
146300/758000 (epoch 386), train_loss = 0.239, time/batch = 0.029, All_Time = 4304.881
146350/758000 (epoch 386), train_loss = 0.218, time/batch = 0.030, All_Time = 4306.361
146400/758000 (epoch 386), train_loss = 0.243, time/batch = 0.029, All_Time = 4307.836
146450/758000 (epoch 386), train_loss = 0.244, time/batch = 0.030, All_Time = 4309.306
146500/758000 (epoch 386), train_loss = 0.243, time/batch = 0.029, All_Time = 4310.786
146550/758000 (epoch 386), train_loss = 0.244, time/batch = 0.030, All_Time = 4312.254
146600/758000 (epoch 386), train_loss = 0.213, time/batch = 0.029, All_Time = 4313.739
146650/758000 (epoch 386), train_loss = 0.289, time/batch = 0.029, All_Time = 4315.209
146700/758000 (epoch 387), train_loss = 0.237, time/batch = 0.030, All_Time = 4316.702
146750/758000 (epoch 387), train_loss = 0.246, time/batch = 0.030, All_Time = 4318.194
146800/758000 (epoch 387), train_loss = 0.288, time/batch = 0.029, All_Time = 4319.669
146850/758000 (epoch 387), train_loss = 0.257, time/batch = 0.028, All_Time = 4321.136
146900/758000 (epoch 387), train_loss = 0.218, time/batch = 0.029, All_Time = 4322.610
146950/758000 (epoch 387), train_loss = 0.238, time/batch = 0.030, All_Time = 4324.099
147000/758000 (epoch 387), train_loss = 0.251, time/batch = 0.029, All_Time = 4325.574
model saved to NER/polyglot/model.ckpt
147050/758000 (epoch 387), train_loss = 0.251, time/batch = 0.029, All_Time = 4327.056
147100/758000 (epoch 388), train_loss = 0.252, time/batch = 0.030, All_Time = 4328.531
147150/758000 (epoch 388), train_loss = 0.280, time/batch = 0.030, All_Time = 4329.989
147200/758000 (epoch 388), train_loss = 0.242, time/batch = 0.030, All_Time = 4331.489
147250/758000 (epoch 388), train_loss = 0.250, time/batch = 0.029, All_Time = 4332.984
147300/758000 (epoch 388), train_loss = 0.239, time/batch = 0.029, All_Time = 4334.462
147350/758000 (epoch 388), train_loss = 0.239, time/batch = 0.029, All_Time = 4335.932
147400/758000 (epoch 388), train_loss = 0.250, time/batch = 0.029, All_Time = 4337.410
147450/758000 (epoch 389), train_loss = 0.221, time/batch = 0.030, All_Time = 4338.876
147500/758000 (epoch 389), train_loss = 0.219, time/batch = 0.030, All_Time = 4340.337
147550/758000 (epoch 389), train_loss = 0.246, time/batch = 0.029, All_Time = 4341.799
147600/758000 (epoch 389), train_loss = 0.262, time/batch = 0.029, All_Time = 4343.270
147650/758000 (epoch 389), train_loss = 0.260, time/batch = 0.028, All_Time = 4344.736
147700/758000 (epoch 389), train_loss = 0.241, time/batch = 0.030, All_Time = 4346.205
147750/758000 (epoch 389), train_loss = 0.210, time/batch = 0.029, All_Time = 4347.667
147800/758000 (epoch 389), train_loss = 0.239, time/batch = 0.030, All_Time = 4349.141
147850/758000 (epoch 390), train_loss = 0.230, time/batch = 0.030, All_Time = 4350.618
147900/758000 (epoch 390), train_loss = 0.227, time/batch = 0.029, All_Time = 4352.088
147950/758000 (epoch 390), train_loss = 0.264, time/batch = 0.029, All_Time = 4353.559
148000/758000 (epoch 390), train_loss = 0.240, time/batch = 0.029, All_Time = 4355.024
model saved to NER/polyglot/model.ckpt
148050/758000 (epoch 390), train_loss = 0.253, time/batch = 0.028, All_Time = 4356.495
148100/758000 (epoch 390), train_loss = 0.251, time/batch = 0.029, All_Time = 4357.966
148150/758000 (epoch 390), train_loss = 0.248, time/batch = 0.029, All_Time = 4359.463
148200/758000 (epoch 391), train_loss = 0.216, time/batch = 0.030, All_Time = 4360.959
148250/758000 (epoch 391), train_loss = 0.233, time/batch = 0.029, All_Time = 4362.418
148300/758000 (epoch 391), train_loss = 0.250, time/batch = 0.029, All_Time = 4363.885
148350/758000 (epoch 391), train_loss = 0.241, time/batch = 0.029, All_Time = 4365.359
148400/758000 (epoch 391), train_loss = 0.243, time/batch = 0.030, All_Time = 4366.829
148450/758000 (epoch 391), train_loss = 0.242, time/batch = 0.029, All_Time = 4368.300
148500/758000 (epoch 391), train_loss = 0.230, time/batch = 0.030, All_Time = 4369.772
148550/758000 (epoch 391), train_loss = 0.259, time/batch = 0.029, All_Time = 4371.241
148600/758000 (epoch 392), train_loss = 0.250, time/batch = 0.029, All_Time = 4372.723
148650/758000 (epoch 392), train_loss = 0.253, time/batch = 0.029, All_Time = 4374.192
148700/758000 (epoch 392), train_loss = 0.245, time/batch = 0.029, All_Time = 4375.677
148750/758000 (epoch 392), train_loss = 0.231, time/batch = 0.030, All_Time = 4377.151
148800/758000 (epoch 392), train_loss = 0.228, time/batch = 0.029, All_Time = 4378.627
148850/758000 (epoch 392), train_loss = 0.238, time/batch = 0.029, All_Time = 4380.088
148900/758000 (epoch 392), train_loss = 0.268, time/batch = 0.028, All_Time = 4381.563
148950/758000 (epoch 393), train_loss = 0.248, time/batch = 0.029, All_Time = 4383.050
149000/758000 (epoch 393), train_loss = 0.281, time/batch = 0.031, All_Time = 4384.520
model saved to NER/polyglot/model.ckpt
149050/758000 (epoch 393), train_loss = 0.242, time/batch = 0.029, All_Time = 4385.977
149100/758000 (epoch 393), train_loss = 0.258, time/batch = 0.029, All_Time = 4387.443
149150/758000 (epoch 393), train_loss = 0.224, time/batch = 0.029, All_Time = 4388.913
149200/758000 (epoch 393), train_loss = 0.243, time/batch = 0.029, All_Time = 4390.385
149250/758000 (epoch 393), train_loss = 0.219, time/batch = 0.030, All_Time = 4391.862
149300/758000 (epoch 393), train_loss = 0.232, time/batch = 0.031, All_Time = 4393.348
149350/758000 (epoch 394), train_loss = 0.237, time/batch = 0.029, All_Time = 4394.825
149400/758000 (epoch 394), train_loss = 0.239, time/batch = 0.029, All_Time = 4396.296
149450/758000 (epoch 394), train_loss = 0.293, time/batch = 0.029, All_Time = 4397.769
149500/758000 (epoch 394), train_loss = 0.318, time/batch = 0.031, All_Time = 4399.261
149550/758000 (epoch 394), train_loss = 0.196, time/batch = 0.029, All_Time = 4400.758
149600/758000 (epoch 394), train_loss = 0.213, time/batch = 0.030, All_Time = 4402.245
149650/758000 (epoch 394), train_loss = 0.250, time/batch = 0.029, All_Time = 4403.728
149700/758000 (epoch 394), train_loss = 0.297, time/batch = 0.029, All_Time = 4405.215
149750/758000 (epoch 395), train_loss = 0.226, time/batch = 0.029, All_Time = 4406.700
149800/758000 (epoch 395), train_loss = 0.259, time/batch = 0.030, All_Time = 4408.180
149850/758000 (epoch 395), train_loss = 0.223, time/batch = 0.030, All_Time = 4409.657
149900/758000 (epoch 395), train_loss = 0.239, time/batch = 0.031, All_Time = 4411.175
149950/758000 (epoch 395), train_loss = 0.212, time/batch = 0.031, All_Time = 4412.666
150000/758000 (epoch 395), train_loss = 0.243, time/batch = 0.030, All_Time = 4414.153
model saved to NER/polyglot/model.ckpt
150050/758000 (epoch 395), train_loss = 0.215, time/batch = 0.029, All_Time = 4415.625
150100/758000 (epoch 396), train_loss = 0.228, time/batch = 0.030, All_Time = 4417.099
150150/758000 (epoch 396), train_loss = 0.252, time/batch = 0.030, All_Time = 4418.563
150200/758000 (epoch 396), train_loss = 0.260, time/batch = 0.029, All_Time = 4420.024
150250/758000 (epoch 396), train_loss = 0.228, time/batch = 0.029, All_Time = 4421.510
150300/758000 (epoch 396), train_loss = 0.236, time/batch = 0.029, All_Time = 4423.009
150350/758000 (epoch 396), train_loss = 0.271, time/batch = 0.030, All_Time = 4424.488
150400/758000 (epoch 396), train_loss = 0.238, time/batch = 0.029, All_Time = 4425.978
150450/758000 (epoch 396), train_loss = 0.268, time/batch = 0.030, All_Time = 4427.465
150500/758000 (epoch 397), train_loss = 0.248, time/batch = 0.030, All_Time = 4428.950
150550/758000 (epoch 397), train_loss = 0.249, time/batch = 0.030, All_Time = 4430.425
150600/758000 (epoch 397), train_loss = 0.240, time/batch = 0.029, All_Time = 4431.900
150650/758000 (epoch 397), train_loss = 0.247, time/batch = 0.029, All_Time = 4433.373
150700/758000 (epoch 397), train_loss = 0.235, time/batch = 0.028, All_Time = 4434.836
150750/758000 (epoch 397), train_loss = 0.247, time/batch = 0.030, All_Time = 4436.305
150800/758000 (epoch 397), train_loss = 0.251, time/batch = 0.030, All_Time = 4437.783
150850/758000 (epoch 398), train_loss = 0.242, time/batch = 0.029, All_Time = 4439.251
150900/758000 (epoch 398), train_loss = 0.276, time/batch = 0.030, All_Time = 4440.712
150950/758000 (epoch 398), train_loss = 0.256, time/batch = 0.029, All_Time = 4442.197
151000/758000 (epoch 398), train_loss = 0.258, time/batch = 0.031, All_Time = 4443.685
model saved to NER/polyglot/model.ckpt
151050/758000 (epoch 398), train_loss = 0.213, time/batch = 0.031, All_Time = 4445.163
151100/758000 (epoch 398), train_loss = 0.237, time/batch = 0.030, All_Time = 4446.632
151150/758000 (epoch 398), train_loss = 0.249, time/batch = 0.029, All_Time = 4448.103
151200/758000 (epoch 398), train_loss = 0.251, time/batch = 0.030, All_Time = 4449.575
151250/758000 (epoch 399), train_loss = 0.232, time/batch = 0.029, All_Time = 4451.046
151300/758000 (epoch 399), train_loss = 0.255, time/batch = 0.030, All_Time = 4452.530
151350/758000 (epoch 399), train_loss = 0.265, time/batch = 0.029, All_Time = 4454.008
151400/758000 (epoch 399), train_loss = 0.229, time/batch = 0.029, All_Time = 4455.488
151450/758000 (epoch 399), train_loss = 0.263, time/batch = 0.030, All_Time = 4456.965
151500/758000 (epoch 399), train_loss = 0.217, time/batch = 0.029, All_Time = 4458.435
151550/758000 (epoch 399), train_loss = 0.248, time/batch = 0.029, All_Time = 4459.912
151600/758000 (epoch 400), train_loss = 0.059, time/batch = 0.035, All_Time = 4461.401
151650/758000 (epoch 400), train_loss = 0.250, time/batch = 0.031, All_Time = 4462.912
151700/758000 (epoch 400), train_loss = 0.223, time/batch = 0.029, All_Time = 4464.399
151750/758000 (epoch 400), train_loss = 0.250, time/batch = 0.030, All_Time = 4465.870
151800/758000 (epoch 400), train_loss = 0.231, time/batch = 0.030, All_Time = 4467.348
151850/758000 (epoch 400), train_loss = 0.250, time/batch = 0.029, All_Time = 4468.827
151900/758000 (epoch 400), train_loss = 0.232, time/batch = 0.029, All_Time = 4470.309
151950/758000 (epoch 400), train_loss = 0.230, time/batch = 0.031, All_Time = 4471.790
152000/758000 (epoch 401), train_loss = 0.224, time/batch = 0.030, All_Time = 4473.272
model saved to NER/polyglot/model.ckpt
152050/758000 (epoch 401), train_loss = 0.233, time/batch = 0.029, All_Time = 4474.737
152100/758000 (epoch 401), train_loss = 0.224, time/batch = 0.029, All_Time = 4476.207
152150/758000 (epoch 401), train_loss = 0.262, time/batch = 0.030, All_Time = 4477.696
152200/758000 (epoch 401), train_loss = 0.220, time/batch = 0.031, All_Time = 4479.196
152250/758000 (epoch 401), train_loss = 0.228, time/batch = 0.032, All_Time = 4480.682
152300/758000 (epoch 401), train_loss = 0.280, time/batch = 0.030, All_Time = 4482.155
152350/758000 (epoch 401), train_loss = 0.272, time/batch = 0.029, All_Time = 4483.637
152400/758000 (epoch 402), train_loss = 0.230, time/batch = 0.028, All_Time = 4485.120
152450/758000 (epoch 402), train_loss = 0.224, time/batch = 0.030, All_Time = 4486.596
152500/758000 (epoch 402), train_loss = 0.201, time/batch = 0.029, All_Time = 4488.055
152550/758000 (epoch 402), train_loss = 0.270, time/batch = 0.031, All_Time = 4489.530
152600/758000 (epoch 402), train_loss = 0.259, time/batch = 0.030, All_Time = 4490.994
152650/758000 (epoch 402), train_loss = 0.209, time/batch = 0.030, All_Time = 4492.463
152700/758000 (epoch 402), train_loss = 0.218, time/batch = 0.029, All_Time = 4493.932
152750/758000 (epoch 403), train_loss = 0.229, time/batch = 0.030, All_Time = 4495.415
152800/758000 (epoch 403), train_loss = 0.283, time/batch = 0.029, All_Time = 4496.883
152850/758000 (epoch 403), train_loss = 0.231, time/batch = 0.029, All_Time = 4498.347
152900/758000 (epoch 403), train_loss = 0.307, time/batch = 0.029, All_Time = 4499.812
152950/758000 (epoch 403), train_loss = 0.221, time/batch = 0.030, All_Time = 4501.300
153000/758000 (epoch 403), train_loss = 0.208, time/batch = 0.028, All_Time = 4502.793
model saved to NER/polyglot/model.ckpt
153050/758000 (epoch 403), train_loss = 0.247, time/batch = 0.030, All_Time = 4504.263
153100/758000 (epoch 403), train_loss = 0.252, time/batch = 0.030, All_Time = 4505.743
153150/758000 (epoch 404), train_loss = 0.264, time/batch = 0.029, All_Time = 4507.229
153200/758000 (epoch 404), train_loss = 0.229, time/batch = 0.030, All_Time = 4508.707
153250/758000 (epoch 404), train_loss = 0.242, time/batch = 0.029, All_Time = 4510.175
153300/758000 (epoch 404), train_loss = 0.268, time/batch = 0.029, All_Time = 4511.638
153350/758000 (epoch 404), train_loss = 0.249, time/batch = 0.029, All_Time = 4513.110
153400/758000 (epoch 404), train_loss = 0.237, time/batch = 0.028, All_Time = 4514.581
153450/758000 (epoch 404), train_loss = 0.276, time/batch = 0.030, All_Time = 4516.042
153500/758000 (epoch 405), train_loss = 0.256, time/batch = 0.029, All_Time = 4517.509
153550/758000 (epoch 405), train_loss = 0.222, time/batch = 0.028, All_Time = 4518.984
153600/758000 (epoch 405), train_loss = 0.266, time/batch = 0.030, All_Time = 4520.479
153650/758000 (epoch 405), train_loss = 0.216, time/batch = 0.030, All_Time = 4521.963
153700/758000 (epoch 405), train_loss = 0.223, time/batch = 0.029, All_Time = 4523.446
153750/758000 (epoch 405), train_loss = 0.261, time/batch = 0.029, All_Time = 4524.940
153800/758000 (epoch 405), train_loss = 0.238, time/batch = 0.031, All_Time = 4526.430
153850/758000 (epoch 405), train_loss = 0.264, time/batch = 0.028, All_Time = 4527.912
153900/758000 (epoch 406), train_loss = 0.223, time/batch = 0.030, All_Time = 4529.404
153950/758000 (epoch 406), train_loss = 0.231, time/batch = 0.030, All_Time = 4530.880
154000/758000 (epoch 406), train_loss = 0.238, time/batch = 0.029, All_Time = 4532.365
model saved to NER/polyglot/model.ckpt
154050/758000 (epoch 406), train_loss = 0.266, time/batch = 0.029, All_Time = 4533.825
154100/758000 (epoch 406), train_loss = 0.239, time/batch = 0.029, All_Time = 4535.281
154150/758000 (epoch 406), train_loss = 0.226, time/batch = 0.029, All_Time = 4536.754
154200/758000 (epoch 406), train_loss = 0.276, time/batch = 0.030, All_Time = 4538.227
154250/758000 (epoch 406), train_loss = 0.240, time/batch = 0.029, All_Time = 4539.697
154300/758000 (epoch 407), train_loss = 0.281, time/batch = 0.028, All_Time = 4541.179
154350/758000 (epoch 407), train_loss = 0.257, time/batch = 0.031, All_Time = 4542.652
154400/758000 (epoch 407), train_loss = 0.240, time/batch = 0.029, All_Time = 4544.133
154450/758000 (epoch 407), train_loss = 0.231, time/batch = 0.030, All_Time = 4545.610
154500/758000 (epoch 407), train_loss = 0.217, time/batch = 0.030, All_Time = 4547.091
154550/758000 (epoch 407), train_loss = 0.224, time/batch = 0.030, All_Time = 4548.558
154600/758000 (epoch 407), train_loss = 0.215, time/batch = 0.029, All_Time = 4550.025
154650/758000 (epoch 408), train_loss = 0.249, time/batch = 0.029, All_Time = 4551.508
154700/758000 (epoch 408), train_loss = 0.211, time/batch = 0.030, All_Time = 4552.988
154750/758000 (epoch 408), train_loss = 0.245, time/batch = 0.032, All_Time = 4554.458
154800/758000 (epoch 408), train_loss = 0.217, time/batch = 0.029, All_Time = 4555.931
154850/758000 (epoch 408), train_loss = 0.233, time/batch = 0.030, All_Time = 4557.409
154900/758000 (epoch 408), train_loss = 0.228, time/batch = 0.030, All_Time = 4558.889
154950/758000 (epoch 408), train_loss = 0.248, time/batch = 0.029, All_Time = 4560.366
155000/758000 (epoch 408), train_loss = 0.229, time/batch = 0.029, All_Time = 4561.840
model saved to NER/polyglot/model.ckpt
155050/758000 (epoch 409), train_loss = 0.218, time/batch = 0.031, All_Time = 4563.327
155100/758000 (epoch 409), train_loss = 0.237, time/batch = 0.029, All_Time = 4564.801
155150/758000 (epoch 409), train_loss = 0.212, time/batch = 0.029, All_Time = 4566.318
155200/758000 (epoch 409), train_loss = 0.266, time/batch = 0.029, All_Time = 4567.812
155250/758000 (epoch 409), train_loss = 0.255, time/batch = 0.030, All_Time = 4569.293
155300/758000 (epoch 409), train_loss = 0.232, time/batch = 0.030, All_Time = 4570.765
155350/758000 (epoch 409), train_loss = 0.262, time/batch = 0.031, All_Time = 4572.247
155400/758000 (epoch 410), train_loss = 0.282, time/batch = 0.031, All_Time = 4573.740
155450/758000 (epoch 410), train_loss = 0.292, time/batch = 0.030, All_Time = 4575.213
155500/758000 (epoch 410), train_loss = 0.253, time/batch = 0.030, All_Time = 4576.682
155550/758000 (epoch 410), train_loss = 0.222, time/batch = 0.029, All_Time = 4578.154
155600/758000 (epoch 410), train_loss = 0.221, time/batch = 0.030, All_Time = 4579.625
155650/758000 (epoch 410), train_loss = 0.260, time/batch = 0.029, All_Time = 4581.102
155700/758000 (epoch 410), train_loss = 0.244, time/batch = 0.029, All_Time = 4582.584
155750/758000 (epoch 410), train_loss = 0.247, time/batch = 0.030, All_Time = 4584.063
155800/758000 (epoch 411), train_loss = 0.210, time/batch = 0.029, All_Time = 4585.539
155850/758000 (epoch 411), train_loss = 0.265, time/batch = 0.030, All_Time = 4587.013
155900/758000 (epoch 411), train_loss = 0.229, time/batch = 0.032, All_Time = 4588.496
155950/758000 (epoch 411), train_loss = 0.232, time/batch = 0.030, All_Time = 4589.995
156000/758000 (epoch 411), train_loss = 0.230, time/batch = 0.028, All_Time = 4591.473
model saved to NER/polyglot/model.ckpt
156050/758000 (epoch 411), train_loss = 0.253, time/batch = 0.028, All_Time = 4592.947
156100/758000 (epoch 411), train_loss = 0.258, time/batch = 0.029, All_Time = 4594.422
156150/758000 (epoch 412), train_loss = 0.196, time/batch = 0.029, All_Time = 4595.894
156200/758000 (epoch 412), train_loss = 0.254, time/batch = 0.029, All_Time = 4597.368
156250/758000 (epoch 412), train_loss = 0.281, time/batch = 0.030, All_Time = 4598.843
156300/758000 (epoch 412), train_loss = 0.235, time/batch = 0.030, All_Time = 4600.468
156350/758000 (epoch 412), train_loss = 0.247, time/batch = 0.028, All_Time = 4601.947
156400/758000 (epoch 412), train_loss = 0.251, time/batch = 0.031, All_Time = 4603.433
156450/758000 (epoch 412), train_loss = 0.203, time/batch = 0.030, All_Time = 4604.916
156500/758000 (epoch 412), train_loss = 0.268, time/batch = 0.029, All_Time = 4606.389
156550/758000 (epoch 413), train_loss = 0.233, time/batch = 0.029, All_Time = 4607.871
156600/758000 (epoch 413), train_loss = 0.241, time/batch = 0.029, All_Time = 4609.350
156650/758000 (epoch 413), train_loss = 0.252, time/batch = 0.031, All_Time = 4610.815
156700/758000 (epoch 413), train_loss = 0.258, time/batch = 0.029, All_Time = 4612.288
156750/758000 (epoch 413), train_loss = 0.243, time/batch = 0.030, All_Time = 4613.744
156800/758000 (epoch 413), train_loss = 0.243, time/batch = 0.029, All_Time = 4615.204
156850/758000 (epoch 413), train_loss = 0.244, time/batch = 0.032, All_Time = 4616.665
156900/758000 (epoch 413), train_loss = 0.286, time/batch = 0.030, All_Time = 4618.132
156950/758000 (epoch 414), train_loss = 0.207, time/batch = 0.031, All_Time = 4619.612
157000/758000 (epoch 414), train_loss = 0.244, time/batch = 0.029, All_Time = 4621.074
model saved to NER/polyglot/model.ckpt
157050/758000 (epoch 414), train_loss = 0.217, time/batch = 0.029, All_Time = 4622.530
157100/758000 (epoch 414), train_loss = 0.233, time/batch = 0.031, All_Time = 4624.003
157150/758000 (epoch 414), train_loss = 0.260, time/batch = 0.029, All_Time = 4625.508
157200/758000 (epoch 414), train_loss = 0.253, time/batch = 0.029, All_Time = 4626.985
157250/758000 (epoch 414), train_loss = 0.238, time/batch = 0.029, All_Time = 4628.473
157300/758000 (epoch 415), train_loss = 0.227, time/batch = 0.030, All_Time = 4629.954
157350/758000 (epoch 415), train_loss = 0.250, time/batch = 0.030, All_Time = 4631.426
157400/758000 (epoch 415), train_loss = 0.250, time/batch = 0.029, All_Time = 4632.901
157450/758000 (epoch 415), train_loss = 0.223, time/batch = 0.028, All_Time = 4634.374
157500/758000 (epoch 415), train_loss = 0.240, time/batch = 0.029, All_Time = 4635.846
157550/758000 (epoch 415), train_loss = 0.246, time/batch = 0.030, All_Time = 4637.323
157600/758000 (epoch 415), train_loss = 0.246, time/batch = 0.029, All_Time = 4638.795
157650/758000 (epoch 415), train_loss = 0.257, time/batch = 0.029, All_Time = 4640.275
157700/758000 (epoch 416), train_loss = 0.266, time/batch = 0.029, All_Time = 4641.758
157750/758000 (epoch 416), train_loss = 0.224, time/batch = 0.030, All_Time = 4643.233
157800/758000 (epoch 416), train_loss = 0.248, time/batch = 0.030, All_Time = 4644.715
157850/758000 (epoch 416), train_loss = 0.227, time/batch = 0.031, All_Time = 4646.198
157900/758000 (epoch 416), train_loss = 0.279, time/batch = 0.030, All_Time = 4647.667
157950/758000 (epoch 416), train_loss = 0.255, time/batch = 0.030, All_Time = 4649.140
158000/758000 (epoch 416), train_loss = 0.253, time/batch = 0.031, All_Time = 4650.632
model saved to NER/polyglot/model.ckpt
158050/758000 (epoch 417), train_loss = 0.244, time/batch = 0.031, All_Time = 4652.135
158100/758000 (epoch 417), train_loss = 0.247, time/batch = 0.029, All_Time = 4653.609
158150/758000 (epoch 417), train_loss = 0.270, time/batch = 0.032, All_Time = 4655.085
158200/758000 (epoch 417), train_loss = 0.246, time/batch = 0.029, All_Time = 4656.554
158250/758000 (epoch 417), train_loss = 0.237, time/batch = 0.029, All_Time = 4658.043
158300/758000 (epoch 417), train_loss = 0.224, time/batch = 0.029, All_Time = 4659.528
158350/758000 (epoch 417), train_loss = 0.229, time/batch = 0.030, All_Time = 4661.015
158400/758000 (epoch 417), train_loss = 0.246, time/batch = 0.029, All_Time = 4662.500
158450/758000 (epoch 418), train_loss = 0.249, time/batch = 0.029, All_Time = 4663.992
158500/758000 (epoch 418), train_loss = 0.264, time/batch = 0.029, All_Time = 4665.476
158550/758000 (epoch 418), train_loss = 0.240, time/batch = 0.029, All_Time = 4666.964
158600/758000 (epoch 418), train_loss = 0.250, time/batch = 0.029, All_Time = 4668.433
158650/758000 (epoch 418), train_loss = 0.227, time/batch = 0.029, All_Time = 4669.901
158700/758000 (epoch 418), train_loss = 0.217, time/batch = 0.030, All_Time = 4671.376
158750/758000 (epoch 418), train_loss = 0.277, time/batch = 0.030, All_Time = 4672.858
158800/758000 (epoch 418), train_loss = 0.259, time/batch = 0.031, All_Time = 4674.336
158850/758000 (epoch 419), train_loss = 0.269, time/batch = 0.028, All_Time = 4675.817
158900/758000 (epoch 419), train_loss = 0.296, time/batch = 0.031, All_Time = 4677.300
158950/758000 (epoch 419), train_loss = 0.228, time/batch = 0.028, All_Time = 4678.770
159000/758000 (epoch 419), train_loss = 0.220, time/batch = 0.030, All_Time = 4680.257
model saved to NER/polyglot/model.ckpt
159050/758000 (epoch 419), train_loss = 0.257, time/batch = 0.031, All_Time = 4681.724
159100/758000 (epoch 419), train_loss = 0.255, time/batch = 0.030, All_Time = 4683.180
159150/758000 (epoch 419), train_loss = 0.237, time/batch = 0.030, All_Time = 4684.652
159200/758000 (epoch 420), train_loss = 0.225, time/batch = 0.029, All_Time = 4686.126
159250/758000 (epoch 420), train_loss = 0.234, time/batch = 0.030, All_Time = 4687.605
159300/758000 (epoch 420), train_loss = 0.243, time/batch = 0.029, All_Time = 4689.080
159350/758000 (epoch 420), train_loss = 0.234, time/batch = 0.031, All_Time = 4690.555
159400/758000 (epoch 420), train_loss = 0.223, time/batch = 0.029, All_Time = 4692.024
159450/758000 (epoch 420), train_loss = 0.239, time/batch = 0.032, All_Time = 4693.509
159500/758000 (epoch 420), train_loss = 0.264, time/batch = 0.030, All_Time = 4695.011
159550/758000 (epoch 420), train_loss = 0.244, time/batch = 0.029, All_Time = 4696.493
159600/758000 (epoch 421), train_loss = 0.257, time/batch = 0.029, All_Time = 4697.971
159650/758000 (epoch 421), train_loss = 0.287, time/batch = 0.030, All_Time = 4699.452
159700/758000 (epoch 421), train_loss = 0.255, time/batch = 0.030, All_Time = 4700.927
159750/758000 (epoch 421), train_loss = 0.248, time/batch = 0.030, All_Time = 4702.433
159800/758000 (epoch 421), train_loss = 0.212, time/batch = 0.030, All_Time = 4703.923
159850/758000 (epoch 421), train_loss = 0.229, time/batch = 0.029, All_Time = 4705.397
159900/758000 (epoch 421), train_loss = 0.272, time/batch = 0.031, All_Time = 4706.870
159950/758000 (epoch 422), train_loss = 0.249, time/batch = 0.029, All_Time = 4708.346
160000/758000 (epoch 422), train_loss = 0.227, time/batch = 0.030, All_Time = 4709.820
model saved to NER/polyglot/model.ckpt
160050/758000 (epoch 422), train_loss = 0.267, time/batch = 0.028, All_Time = 4711.288
160100/758000 (epoch 422), train_loss = 0.239, time/batch = 0.029, All_Time = 4712.768
160150/758000 (epoch 422), train_loss = 0.247, time/batch = 0.029, All_Time = 4714.241
160200/758000 (epoch 422), train_loss = 0.241, time/batch = 0.029, All_Time = 4715.707
160250/758000 (epoch 422), train_loss = 0.274, time/batch = 0.028, All_Time = 4717.169
160300/758000 (epoch 422), train_loss = 0.279, time/batch = 0.029, All_Time = 4718.642
160350/758000 (epoch 423), train_loss = 0.238, time/batch = 0.028, All_Time = 4720.144
160400/758000 (epoch 423), train_loss = 0.248, time/batch = 0.030, All_Time = 4721.620
160450/758000 (epoch 423), train_loss = 0.299, time/batch = 0.030, All_Time = 4723.102
160500/758000 (epoch 423), train_loss = 0.230, time/batch = 0.030, All_Time = 4724.582
160550/758000 (epoch 423), train_loss = 0.216, time/batch = 0.029, All_Time = 4726.049
160600/758000 (epoch 423), train_loss = 0.244, time/batch = 0.029, All_Time = 4727.515
160650/758000 (epoch 423), train_loss = 0.274, time/batch = 0.029, All_Time = 4728.989
160700/758000 (epoch 424), train_loss = 0.221, time/batch = 0.030, All_Time = 4730.471
160750/758000 (epoch 424), train_loss = 0.257, time/batch = 0.029, All_Time = 4731.938
160800/758000 (epoch 424), train_loss = 0.241, time/batch = 0.029, All_Time = 4733.422
160850/758000 (epoch 424), train_loss = 0.240, time/batch = 0.029, All_Time = 4734.917
160900/758000 (epoch 424), train_loss = 0.256, time/batch = 0.028, All_Time = 4736.399
160950/758000 (epoch 424), train_loss = 0.219, time/batch = 0.030, All_Time = 4737.885
161000/758000 (epoch 424), train_loss = 0.224, time/batch = 0.029, All_Time = 4739.354
model saved to NER/polyglot/model.ckpt
161050/758000 (epoch 424), train_loss = 0.257, time/batch = 0.029, All_Time = 4740.818
161100/758000 (epoch 425), train_loss = 0.255, time/batch = 0.030, All_Time = 4742.298
161150/758000 (epoch 425), train_loss = 0.267, time/batch = 0.029, All_Time = 4743.761
161200/758000 (epoch 425), train_loss = 0.269, time/batch = 0.030, All_Time = 4745.223
161250/758000 (epoch 425), train_loss = 0.228, time/batch = 0.031, All_Time = 4746.698
161300/758000 (epoch 425), train_loss = 0.234, time/batch = 0.028, All_Time = 4748.204
161350/758000 (epoch 425), train_loss = 0.245, time/batch = 0.030, All_Time = 4749.681
161400/758000 (epoch 425), train_loss = 0.279, time/batch = 0.030, All_Time = 4751.157
161450/758000 (epoch 425), train_loss = 0.240, time/batch = 0.029, All_Time = 4752.636
161500/758000 (epoch 426), train_loss = 0.236, time/batch = 0.029, All_Time = 4754.116
161550/758000 (epoch 426), train_loss = 0.234, time/batch = 0.030, All_Time = 4755.593
161600/758000 (epoch 426), train_loss = 0.233, time/batch = 0.030, All_Time = 4757.064
161650/758000 (epoch 426), train_loss = 0.276, time/batch = 0.030, All_Time = 4758.544
161700/758000 (epoch 426), train_loss = 0.206, time/batch = 0.030, All_Time = 4760.029
161750/758000 (epoch 426), train_loss = 0.259, time/batch = 0.029, All_Time = 4761.504
161800/758000 (epoch 426), train_loss = 0.234, time/batch = 0.029, All_Time = 4762.979
161850/758000 (epoch 427), train_loss = 0.245, time/batch = 0.028, All_Time = 4764.458
161900/758000 (epoch 427), train_loss = 0.223, time/batch = 0.032, All_Time = 4765.928
161950/758000 (epoch 427), train_loss = 0.240, time/batch = 0.029, All_Time = 4767.431
162000/758000 (epoch 427), train_loss = 0.256, time/batch = 0.029, All_Time = 4768.920
model saved to NER/polyglot/model.ckpt
162050/758000 (epoch 427), train_loss = 0.214, time/batch = 0.030, All_Time = 4770.392
162100/758000 (epoch 427), train_loss = 0.272, time/batch = 0.030, All_Time = 4771.858
162150/758000 (epoch 427), train_loss = 0.213, time/batch = 0.027, All_Time = 4773.319
162200/758000 (epoch 427), train_loss = 0.251, time/batch = 0.029, All_Time = 4774.780
162250/758000 (epoch 428), train_loss = 0.247, time/batch = 0.030, All_Time = 4776.252
162300/758000 (epoch 428), train_loss = 0.229, time/batch = 0.028, All_Time = 4777.718
162350/758000 (epoch 428), train_loss = 0.217, time/batch = 0.030, All_Time = 4779.190
162400/758000 (epoch 428), train_loss = 0.220, time/batch = 0.030, All_Time = 4780.653
162450/758000 (epoch 428), train_loss = 0.250, time/batch = 0.030, All_Time = 4782.124
162500/758000 (epoch 428), train_loss = 0.207, time/batch = 0.028, All_Time = 4783.589
162550/758000 (epoch 428), train_loss = 0.268, time/batch = 0.029, All_Time = 4785.056
162600/758000 (epoch 429), train_loss = 0.256, time/batch = 0.030, All_Time = 4786.532
162650/758000 (epoch 429), train_loss = 0.264, time/batch = 0.030, All_Time = 4788.005
162700/758000 (epoch 429), train_loss = 0.284, time/batch = 0.030, All_Time = 4789.492
162750/758000 (epoch 429), train_loss = 0.239, time/batch = 0.029, All_Time = 4790.981
162800/758000 (epoch 429), train_loss = 0.267, time/batch = 0.030, All_Time = 4792.495
162850/758000 (epoch 429), train_loss = 0.256, time/batch = 0.030, All_Time = 4793.971
162900/758000 (epoch 429), train_loss = 0.236, time/batch = 0.030, All_Time = 4795.454
162950/758000 (epoch 429), train_loss = 0.268, time/batch = 0.030, All_Time = 4796.947
163000/758000 (epoch 430), train_loss = 0.226, time/batch = 0.031, All_Time = 4798.439
model saved to NER/polyglot/model.ckpt
163050/758000 (epoch 430), train_loss = 0.222, time/batch = 0.030, All_Time = 4799.914
163100/758000 (epoch 430), train_loss = 0.261, time/batch = 0.031, All_Time = 4801.385
163150/758000 (epoch 430), train_loss = 0.254, time/batch = 0.031, All_Time = 4802.848
163200/758000 (epoch 430), train_loss = 0.223, time/batch = 0.029, All_Time = 4804.307
163250/758000 (epoch 430), train_loss = 0.242, time/batch = 0.031, All_Time = 4805.795
163300/758000 (epoch 430), train_loss = 0.251, time/batch = 0.030, All_Time = 4807.273
163350/758000 (epoch 431), train_loss = 0.192, time/batch = 0.029, All_Time = 4808.762
163400/758000 (epoch 431), train_loss = 0.273, time/batch = 0.029, All_Time = 4810.245
163450/758000 (epoch 431), train_loss = 0.217, time/batch = 0.030, All_Time = 4811.709
163500/758000 (epoch 431), train_loss = 0.240, time/batch = 0.029, All_Time = 4813.173
163550/758000 (epoch 431), train_loss = 0.221, time/batch = 0.031, All_Time = 4814.643
163600/758000 (epoch 431), train_loss = 0.221, time/batch = 0.029, All_Time = 4816.111
163650/758000 (epoch 431), train_loss = 0.252, time/batch = 0.030, All_Time = 4817.580
163700/758000 (epoch 431), train_loss = 0.272, time/batch = 0.030, All_Time = 4819.054
163750/758000 (epoch 432), train_loss = 0.222, time/batch = 0.029, All_Time = 4820.535
163800/758000 (epoch 432), train_loss = 0.279, time/batch = 0.030, All_Time = 4822.008
163850/758000 (epoch 432), train_loss = 0.242, time/batch = 0.030, All_Time = 4823.487
163900/758000 (epoch 432), train_loss = 0.274, time/batch = 0.031, All_Time = 4824.969
163950/758000 (epoch 432), train_loss = 0.262, time/batch = 0.030, All_Time = 4826.452
164000/758000 (epoch 432), train_loss = 0.197, time/batch = 0.029, All_Time = 4827.934
model saved to NER/polyglot/model.ckpt
164050/758000 (epoch 432), train_loss = 0.233, time/batch = 0.029, All_Time = 4829.415
164100/758000 (epoch 432), train_loss = 0.281, time/batch = 0.030, All_Time = 4830.882
164150/758000 (epoch 433), train_loss = 0.246, time/batch = 0.030, All_Time = 4832.351
164200/758000 (epoch 433), train_loss = 0.212, time/batch = 0.030, All_Time = 4833.859
164250/758000 (epoch 433), train_loss = 0.255, time/batch = 0.030, All_Time = 4835.358
164300/758000 (epoch 433), train_loss = 0.271, time/batch = 0.030, All_Time = 4836.828
164350/758000 (epoch 433), train_loss = 0.203, time/batch = 0.030, All_Time = 4838.331
164400/758000 (epoch 433), train_loss = 0.226, time/batch = 0.030, All_Time = 4839.829
164450/758000 (epoch 433), train_loss = 0.254, time/batch = 0.031, All_Time = 4841.307
164500/758000 (epoch 434), train_loss = 0.219, time/batch = 0.031, All_Time = 4842.797
164550/758000 (epoch 434), train_loss = 0.265, time/batch = 0.028, All_Time = 4844.267
164600/758000 (epoch 434), train_loss = 0.227, time/batch = 0.030, All_Time = 4845.741
164650/758000 (epoch 434), train_loss = 0.213, time/batch = 0.030, All_Time = 4847.215
164700/758000 (epoch 434), train_loss = 0.224, time/batch = 0.032, All_Time = 4848.689
164750/758000 (epoch 434), train_loss = 0.213, time/batch = 0.029, All_Time = 4850.143
164800/758000 (epoch 434), train_loss = 0.230, time/batch = 0.029, All_Time = 4851.618
164850/758000 (epoch 434), train_loss = 0.223, time/batch = 0.029, All_Time = 4853.082
164900/758000 (epoch 435), train_loss = 0.275, time/batch = 0.031, All_Time = 4854.574
164950/758000 (epoch 435), train_loss = 0.229, time/batch = 0.030, All_Time = 4856.050
165000/758000 (epoch 435), train_loss = 0.270, time/batch = 0.030, All_Time = 4857.526
model saved to NER/polyglot/model.ckpt
165050/758000 (epoch 435), train_loss = 0.273, time/batch = 0.030, All_Time = 4859.006
165100/758000 (epoch 435), train_loss = 0.233, time/batch = 0.029, All_Time = 4860.475
165150/758000 (epoch 435), train_loss = 0.268, time/batch = 0.029, All_Time = 4861.965
165200/758000 (epoch 435), train_loss = 0.280, time/batch = 0.028, All_Time = 4863.462
165250/758000 (epoch 436), train_loss = 0.239, time/batch = 0.029, All_Time = 4864.946
165300/758000 (epoch 436), train_loss = 0.218, time/batch = 0.030, All_Time = 4866.413
165350/758000 (epoch 436), train_loss = 0.243, time/batch = 0.030, All_Time = 4867.903
165400/758000 (epoch 436), train_loss = 0.244, time/batch = 0.028, All_Time = 4869.380
165450/758000 (epoch 436), train_loss = 0.243, time/batch = 0.029, All_Time = 4870.858
165500/758000 (epoch 436), train_loss = 0.244, time/batch = 0.029, All_Time = 4872.330
165550/758000 (epoch 436), train_loss = 0.213, time/batch = 0.029, All_Time = 4873.800
165600/758000 (epoch 436), train_loss = 0.289, time/batch = 0.029, All_Time = 4875.289
165650/758000 (epoch 437), train_loss = 0.237, time/batch = 0.029, All_Time = 4876.769
165700/758000 (epoch 437), train_loss = 0.246, time/batch = 0.029, All_Time = 4878.230
165750/758000 (epoch 437), train_loss = 0.288, time/batch = 0.029, All_Time = 4879.703
165800/758000 (epoch 437), train_loss = 0.257, time/batch = 0.029, All_Time = 4881.163
165850/758000 (epoch 437), train_loss = 0.218, time/batch = 0.030, All_Time = 4882.638
165900/758000 (epoch 437), train_loss = 0.238, time/batch = 0.029, All_Time = 4884.111
165950/758000 (epoch 437), train_loss = 0.251, time/batch = 0.028, All_Time = 4885.567
166000/758000 (epoch 437), train_loss = 0.251, time/batch = 0.030, All_Time = 4887.034
model saved to NER/polyglot/model.ckpt
166050/758000 (epoch 438), train_loss = 0.252, time/batch = 0.030, All_Time = 4888.512
166100/758000 (epoch 438), train_loss = 0.280, time/batch = 0.031, All_Time = 4890.020
166150/758000 (epoch 438), train_loss = 0.242, time/batch = 0.029, All_Time = 4891.514
166200/758000 (epoch 438), train_loss = 0.250, time/batch = 0.030, All_Time = 4892.987
166250/758000 (epoch 438), train_loss = 0.239, time/batch = 0.030, All_Time = 4894.465
166300/758000 (epoch 438), train_loss = 0.239, time/batch = 0.030, All_Time = 4895.947
166350/758000 (epoch 438), train_loss = 0.250, time/batch = 0.029, All_Time = 4897.423
166400/758000 (epoch 439), train_loss = 0.221, time/batch = 0.029, All_Time = 4898.893
166450/758000 (epoch 439), train_loss = 0.219, time/batch = 0.029, All_Time = 4900.352
166500/758000 (epoch 439), train_loss = 0.246, time/batch = 0.030, All_Time = 4901.815
166550/758000 (epoch 439), train_loss = 0.262, time/batch = 0.029, All_Time = 4903.287
166600/758000 (epoch 439), train_loss = 0.260, time/batch = 0.030, All_Time = 4904.794
166650/758000 (epoch 439), train_loss = 0.241, time/batch = 0.029, All_Time = 4906.280
166700/758000 (epoch 439), train_loss = 0.210, time/batch = 0.029, All_Time = 4907.762
166750/758000 (epoch 439), train_loss = 0.239, time/batch = 0.029, All_Time = 4909.246
166800/758000 (epoch 440), train_loss = 0.230, time/batch = 0.029, All_Time = 4910.726
166850/758000 (epoch 440), train_loss = 0.226, time/batch = 0.029, All_Time = 4912.188
166900/758000 (epoch 440), train_loss = 0.264, time/batch = 0.030, All_Time = 4913.663
166950/758000 (epoch 440), train_loss = 0.240, time/batch = 0.029, All_Time = 4915.115
167000/758000 (epoch 440), train_loss = 0.253, time/batch = 0.029, All_Time = 4916.589
model saved to NER/polyglot/model.ckpt
167050/758000 (epoch 440), train_loss = 0.251, time/batch = 0.028, All_Time = 4918.057
167100/758000 (epoch 440), train_loss = 0.248, time/batch = 0.029, All_Time = 4919.524
167150/758000 (epoch 441), train_loss = 0.216, time/batch = 0.029, All_Time = 4920.994
167200/758000 (epoch 441), train_loss = 0.233, time/batch = 0.029, All_Time = 4922.460
167250/758000 (epoch 441), train_loss = 0.250, time/batch = 0.030, All_Time = 4923.922
167300/758000 (epoch 441), train_loss = 0.241, time/batch = 0.029, All_Time = 4925.391
167350/758000 (epoch 441), train_loss = 0.243, time/batch = 0.031, All_Time = 4926.902
167400/758000 (epoch 441), train_loss = 0.242, time/batch = 0.031, All_Time = 4928.375
167450/758000 (epoch 441), train_loss = 0.230, time/batch = 0.028, All_Time = 4929.865
167500/758000 (epoch 441), train_loss = 0.259, time/batch = 0.031, All_Time = 4931.338
167550/758000 (epoch 442), train_loss = 0.250, time/batch = 0.029, All_Time = 4932.813
167600/758000 (epoch 442), train_loss = 0.253, time/batch = 0.030, All_Time = 4934.279
167650/758000 (epoch 442), train_loss = 0.245, time/batch = 0.033, All_Time = 4935.744
167700/758000 (epoch 442), train_loss = 0.231, time/batch = 0.029, All_Time = 4937.204
167750/758000 (epoch 442), train_loss = 0.228, time/batch = 0.030, All_Time = 4938.682
167800/758000 (epoch 442), train_loss = 0.238, time/batch = 0.030, All_Time = 4940.149
167850/758000 (epoch 442), train_loss = 0.268, time/batch = 0.029, All_Time = 4941.652
167900/758000 (epoch 443), train_loss = 0.248, time/batch = 0.029, All_Time = 4943.144
167950/758000 (epoch 443), train_loss = 0.280, time/batch = 0.030, All_Time = 4944.618
168000/758000 (epoch 443), train_loss = 0.242, time/batch = 0.029, All_Time = 4946.093
model saved to NER/polyglot/model.ckpt
168050/758000 (epoch 443), train_loss = 0.258, time/batch = 0.029, All_Time = 4947.568
168100/758000 (epoch 443), train_loss = 0.224, time/batch = 0.029, All_Time = 4949.029
168150/758000 (epoch 443), train_loss = 0.243, time/batch = 0.031, All_Time = 4950.483
168200/758000 (epoch 443), train_loss = 0.219, time/batch = 0.030, All_Time = 4951.953
168250/758000 (epoch 443), train_loss = 0.232, time/batch = 0.030, All_Time = 4953.425
168300/758000 (epoch 444), train_loss = 0.237, time/batch = 0.030, All_Time = 4954.901
168350/758000 (epoch 444), train_loss = 0.239, time/batch = 0.028, All_Time = 4956.373
168400/758000 (epoch 444), train_loss = 0.293, time/batch = 0.029, All_Time = 4957.872
168450/758000 (epoch 444), train_loss = 0.318, time/batch = 0.029, All_Time = 4959.358
168500/758000 (epoch 444), train_loss = 0.196, time/batch = 0.030, All_Time = 4960.830
168550/758000 (epoch 444), train_loss = 0.213, time/batch = 0.030, All_Time = 4962.304
168600/758000 (epoch 444), train_loss = 0.250, time/batch = 0.029, All_Time = 4963.778
168650/758000 (epoch 444), train_loss = 0.297, time/batch = 0.028, All_Time = 4965.249
168700/758000 (epoch 445), train_loss = 0.226, time/batch = 0.029, All_Time = 4966.717
168750/758000 (epoch 445), train_loss = 0.259, time/batch = 0.029, All_Time = 4968.191
168800/758000 (epoch 445), train_loss = 0.223, time/batch = 0.028, All_Time = 4969.650
168850/758000 (epoch 445), train_loss = 0.239, time/batch = 0.029, All_Time = 4971.115
168900/758000 (epoch 445), train_loss = 0.212, time/batch = 0.029, All_Time = 4972.594
168950/758000 (epoch 445), train_loss = 0.243, time/batch = 0.030, All_Time = 4974.078
169000/758000 (epoch 445), train_loss = 0.215, time/batch = 0.030, All_Time = 4975.554
model saved to NER/polyglot/model.ckpt
169050/758000 (epoch 446), train_loss = 0.228, time/batch = 0.029, All_Time = 4977.027
169100/758000 (epoch 446), train_loss = 0.252, time/batch = 0.030, All_Time = 4978.488
169150/758000 (epoch 446), train_loss = 0.260, time/batch = 0.029, All_Time = 4979.997
169200/758000 (epoch 446), train_loss = 0.228, time/batch = 0.029, All_Time = 4981.496
169250/758000 (epoch 446), train_loss = 0.236, time/batch = 0.029, All_Time = 4982.987
169300/758000 (epoch 446), train_loss = 0.271, time/batch = 0.029, All_Time = 4984.457
169350/758000 (epoch 446), train_loss = 0.238, time/batch = 0.030, All_Time = 4985.946
169400/758000 (epoch 446), train_loss = 0.268, time/batch = 0.029, All_Time = 4987.431
169450/758000 (epoch 447), train_loss = 0.248, time/batch = 0.029, All_Time = 4988.905
169500/758000 (epoch 447), train_loss = 0.249, time/batch = 0.030, All_Time = 4990.387
169550/758000 (epoch 447), train_loss = 0.240, time/batch = 0.030, All_Time = 4991.848
169600/758000 (epoch 447), train_loss = 0.247, time/batch = 0.030, All_Time = 4993.322
169650/758000 (epoch 447), train_loss = 0.235, time/batch = 0.029, All_Time = 4994.788
169700/758000 (epoch 447), train_loss = 0.247, time/batch = 0.029, All_Time = 4996.289
169750/758000 (epoch 447), train_loss = 0.251, time/batch = 0.030, All_Time = 4997.768
169800/758000 (epoch 448), train_loss = 0.242, time/batch = 0.030, All_Time = 4999.253
169850/758000 (epoch 448), train_loss = 0.276, time/batch = 0.029, All_Time = 5000.719
169900/758000 (epoch 448), train_loss = 0.256, time/batch = 0.030, All_Time = 5002.189
169950/758000 (epoch 448), train_loss = 0.258, time/batch = 0.029, All_Time = 5003.657
170000/758000 (epoch 448), train_loss = 0.213, time/batch = 0.029, All_Time = 5005.129
model saved to NER/polyglot/model.ckpt
170050/758000 (epoch 448), train_loss = 0.237, time/batch = 0.029, All_Time = 5006.597
170100/758000 (epoch 448), train_loss = 0.249, time/batch = 0.031, All_Time = 5008.078
170150/758000 (epoch 448), train_loss = 0.251, time/batch = 0.030, All_Time = 5009.584
170200/758000 (epoch 449), train_loss = 0.232, time/batch = 0.029, All_Time = 5011.082
170250/758000 (epoch 449), train_loss = 0.255, time/batch = 0.030, All_Time = 5012.547
170300/758000 (epoch 449), train_loss = 0.265, time/batch = 0.029, All_Time = 5014.021
170350/758000 (epoch 449), train_loss = 0.229, time/batch = 0.030, All_Time = 5015.484
170400/758000 (epoch 449), train_loss = 0.263, time/batch = 0.030, All_Time = 5016.957
170450/758000 (epoch 449), train_loss = 0.217, time/batch = 0.030, All_Time = 5018.438
170500/758000 (epoch 449), train_loss = 0.248, time/batch = 0.029, All_Time = 5019.921
170550/758000 (epoch 450), train_loss = 0.059, time/batch = 0.035, All_Time = 5021.409
170600/758000 (epoch 450), train_loss = 0.250, time/batch = 0.030, All_Time = 5022.889
170650/758000 (epoch 450), train_loss = 0.223, time/batch = 0.028, All_Time = 5024.361
170700/758000 (epoch 450), train_loss = 0.250, time/batch = 0.029, All_Time = 5025.832
170750/758000 (epoch 450), train_loss = 0.231, time/batch = 0.029, All_Time = 5027.302
170800/758000 (epoch 450), train_loss = 0.250, time/batch = 0.029, All_Time = 5028.776
170850/758000 (epoch 450), train_loss = 0.232, time/batch = 0.029, All_Time = 5030.279
170900/758000 (epoch 450), train_loss = 0.230, time/batch = 0.030, All_Time = 5031.772
170950/758000 (epoch 451), train_loss = 0.224, time/batch = 0.030, All_Time = 5033.263
171000/758000 (epoch 451), train_loss = 0.233, time/batch = 0.030, All_Time = 5034.732
model saved to NER/polyglot/model.ckpt
171050/758000 (epoch 451), train_loss = 0.224, time/batch = 0.029, All_Time = 5036.199
171100/758000 (epoch 451), train_loss = 0.262, time/batch = 0.029, All_Time = 5037.668
171150/758000 (epoch 451), train_loss = 0.220, time/batch = 0.029, All_Time = 5039.135
171200/758000 (epoch 451), train_loss = 0.228, time/batch = 0.028, All_Time = 5040.598
171250/758000 (epoch 451), train_loss = 0.280, time/batch = 0.030, All_Time = 5042.062
171300/758000 (epoch 451), train_loss = 0.272, time/batch = 0.029, All_Time = 5043.543
171350/758000 (epoch 452), train_loss = 0.230, time/batch = 0.029, All_Time = 5045.033
171400/758000 (epoch 452), train_loss = 0.224, time/batch = 0.029, All_Time = 5046.504
171450/758000 (epoch 452), train_loss = 0.201, time/batch = 0.029, All_Time = 5048.008
171500/758000 (epoch 452), train_loss = 0.270, time/batch = 0.030, All_Time = 5049.490
171550/758000 (epoch 452), train_loss = 0.259, time/batch = 0.030, All_Time = 5050.979
171600/758000 (epoch 452), train_loss = 0.209, time/batch = 0.031, All_Time = 5052.451
171650/758000 (epoch 452), train_loss = 0.218, time/batch = 0.031, All_Time = 5053.932
171700/758000 (epoch 453), train_loss = 0.229, time/batch = 0.029, All_Time = 5055.417
171750/758000 (epoch 453), train_loss = 0.283, time/batch = 0.030, All_Time = 5056.896
171800/758000 (epoch 453), train_loss = 0.231, time/batch = 0.031, All_Time = 5058.389
171850/758000 (epoch 453), train_loss = 0.307, time/batch = 0.028, All_Time = 5059.876
171900/758000 (epoch 453), train_loss = 0.221, time/batch = 0.029, All_Time = 5061.355
171950/758000 (epoch 453), train_loss = 0.208, time/batch = 0.030, All_Time = 5062.841
172000/758000 (epoch 453), train_loss = 0.247, time/batch = 0.029, All_Time = 5064.308
model saved to NER/polyglot/model.ckpt
172050/758000 (epoch 453), train_loss = 0.252, time/batch = 0.029, All_Time = 5065.779
172100/758000 (epoch 454), train_loss = 0.264, time/batch = 0.030, All_Time = 5067.252
172150/758000 (epoch 454), train_loss = 0.229, time/batch = 0.029, All_Time = 5068.713
172200/758000 (epoch 454), train_loss = 0.242, time/batch = 0.030, All_Time = 5070.184
172250/758000 (epoch 454), train_loss = 0.267, time/batch = 0.031, All_Time = 5071.679
172300/758000 (epoch 454), train_loss = 0.249, time/batch = 0.028, All_Time = 5073.167
172350/758000 (epoch 454), train_loss = 0.237, time/batch = 0.030, All_Time = 5074.638
172400/758000 (epoch 454), train_loss = 0.276, time/batch = 0.030, All_Time = 5076.114
172450/758000 (epoch 455), train_loss = 0.256, time/batch = 0.030, All_Time = 5077.595
172500/758000 (epoch 455), train_loss = 0.222, time/batch = 0.029, All_Time = 5079.068
172550/758000 (epoch 455), train_loss = 0.266, time/batch = 0.029, All_Time = 5080.532
172600/758000 (epoch 455), train_loss = 0.216, time/batch = 0.031, All_Time = 5082.007
172650/758000 (epoch 455), train_loss = 0.223, time/batch = 0.030, All_Time = 5083.490
172700/758000 (epoch 455), train_loss = 0.261, time/batch = 0.030, All_Time = 5084.959
172750/758000 (epoch 455), train_loss = 0.238, time/batch = 0.029, All_Time = 5086.443
172800/758000 (epoch 455), train_loss = 0.264, time/batch = 0.030, All_Time = 5087.910
172850/758000 (epoch 456), train_loss = 0.223, time/batch = 0.029, All_Time = 5089.388
172900/758000 (epoch 456), train_loss = 0.231, time/batch = 0.030, All_Time = 5090.859
172950/758000 (epoch 456), train_loss = 0.238, time/batch = 0.030, All_Time = 5092.329
173000/758000 (epoch 456), train_loss = 0.266, time/batch = 0.030, All_Time = 5093.821
model saved to NER/polyglot/model.ckpt
173050/758000 (epoch 456), train_loss = 0.239, time/batch = 0.030, All_Time = 5095.293
173100/758000 (epoch 456), train_loss = 0.226, time/batch = 0.030, All_Time = 5096.770
173150/758000 (epoch 456), train_loss = 0.276, time/batch = 0.028, All_Time = 5098.246
173200/758000 (epoch 456), train_loss = 0.240, time/batch = 0.029, All_Time = 5099.712
173250/758000 (epoch 457), train_loss = 0.281, time/batch = 0.030, All_Time = 5101.188
173300/758000 (epoch 457), train_loss = 0.257, time/batch = 0.028, All_Time = 5102.665
173350/758000 (epoch 457), train_loss = 0.240, time/batch = 0.030, All_Time = 5104.149
173400/758000 (epoch 457), train_loss = 0.231, time/batch = 0.030, All_Time = 5105.623
173450/758000 (epoch 457), train_loss = 0.217, time/batch = 0.031, All_Time = 5107.078
173500/758000 (epoch 457), train_loss = 0.224, time/batch = 0.031, All_Time = 5108.566
173550/758000 (epoch 457), train_loss = 0.215, time/batch = 0.031, All_Time = 5110.070
173600/758000 (epoch 458), train_loss = 0.249, time/batch = 0.031, All_Time = 5111.566
173650/758000 (epoch 458), train_loss = 0.211, time/batch = 0.030, All_Time = 5113.029
173700/758000 (epoch 458), train_loss = 0.245, time/batch = 0.028, All_Time = 5114.508
173750/758000 (epoch 458), train_loss = 0.217, time/batch = 0.030, All_Time = 5115.978
173800/758000 (epoch 458), train_loss = 0.233, time/batch = 0.030, All_Time = 5117.458
173850/758000 (epoch 458), train_loss = 0.228, time/batch = 0.029, All_Time = 5118.952
173900/758000 (epoch 458), train_loss = 0.248, time/batch = 0.030, All_Time = 5120.438
173950/758000 (epoch 458), train_loss = 0.229, time/batch = 0.030, All_Time = 5121.912
174000/758000 (epoch 459), train_loss = 0.218, time/batch = 0.031, All_Time = 5123.416
model saved to NER/polyglot/model.ckpt
174050/758000 (epoch 459), train_loss = 0.237, time/batch = 0.029, All_Time = 5124.891
174100/758000 (epoch 459), train_loss = 0.212, time/batch = 0.030, All_Time = 5126.376
174150/758000 (epoch 459), train_loss = 0.266, time/batch = 0.029, All_Time = 5127.868
174200/758000 (epoch 459), train_loss = 0.255, time/batch = 0.031, All_Time = 5129.349
174250/758000 (epoch 459), train_loss = 0.232, time/batch = 0.030, All_Time = 5130.832
174300/758000 (epoch 459), train_loss = 0.262, time/batch = 0.031, All_Time = 5132.303
174350/758000 (epoch 460), train_loss = 0.282, time/batch = 0.028, All_Time = 5133.797
174400/758000 (epoch 460), train_loss = 0.292, time/batch = 0.029, All_Time = 5135.265
174450/758000 (epoch 460), train_loss = 0.253, time/batch = 0.029, All_Time = 5136.739
174500/758000 (epoch 460), train_loss = 0.222, time/batch = 0.030, All_Time = 5138.210
174550/758000 (epoch 460), train_loss = 0.221, time/batch = 0.030, All_Time = 5139.691
174600/758000 (epoch 460), train_loss = 0.260, time/batch = 0.030, All_Time = 5141.159
174650/758000 (epoch 460), train_loss = 0.244, time/batch = 0.028, All_Time = 5142.626
174700/758000 (epoch 460), train_loss = 0.247, time/batch = 0.029, All_Time = 5144.102
174750/758000 (epoch 461), train_loss = 0.210, time/batch = 0.030, All_Time = 5145.567
174800/758000 (epoch 461), train_loss = 0.265, time/batch = 0.029, All_Time = 5147.036
174850/758000 (epoch 461), train_loss = 0.229, time/batch = 0.029, All_Time = 5148.498
174900/758000 (epoch 461), train_loss = 0.232, time/batch = 0.030, All_Time = 5149.975
174950/758000 (epoch 461), train_loss = 0.230, time/batch = 0.029, All_Time = 5151.492
175000/758000 (epoch 461), train_loss = 0.253, time/batch = 0.029, All_Time = 5152.984
model saved to NER/polyglot/model.ckpt
175050/758000 (epoch 461), train_loss = 0.258, time/batch = 0.029, All_Time = 5154.459
175100/758000 (epoch 462), train_loss = 0.196, time/batch = 0.029, All_Time = 5155.929
175150/758000 (epoch 462), train_loss = 0.254, time/batch = 0.029, All_Time = 5157.386
175200/758000 (epoch 462), train_loss = 0.281, time/batch = 0.031, All_Time = 5158.890
175250/758000 (epoch 462), train_loss = 0.235, time/batch = 0.031, All_Time = 5160.380
175300/758000 (epoch 462), train_loss = 0.247, time/batch = 0.029, All_Time = 5161.865
175350/758000 (epoch 462), train_loss = 0.251, time/batch = 0.028, All_Time = 5163.342
175400/758000 (epoch 462), train_loss = 0.203, time/batch = 0.031, All_Time = 5164.814
175450/758000 (epoch 462), train_loss = 0.268, time/batch = 0.029, All_Time = 5166.282
175500/758000 (epoch 463), train_loss = 0.233, time/batch = 0.030, All_Time = 5167.756
175550/758000 (epoch 463), train_loss = 0.241, time/batch = 0.029, All_Time = 5169.224
175600/758000 (epoch 463), train_loss = 0.252, time/batch = 0.029, All_Time = 5170.695
175650/758000 (epoch 463), train_loss = 0.258, time/batch = 0.029, All_Time = 5172.163
175700/758000 (epoch 463), train_loss = 0.243, time/batch = 0.029, All_Time = 5173.640
175750/758000 (epoch 463), train_loss = 0.243, time/batch = 0.029, All_Time = 5175.113
175800/758000 (epoch 463), train_loss = 0.244, time/batch = 0.029, All_Time = 5176.582
175850/758000 (epoch 463), train_loss = 0.286, time/batch = 0.029, All_Time = 5178.058
175900/758000 (epoch 464), train_loss = 0.207, time/batch = 0.028, All_Time = 5179.541
175950/758000 (epoch 464), train_loss = 0.244, time/batch = 0.030, All_Time = 5181.003
176000/758000 (epoch 464), train_loss = 0.217, time/batch = 0.029, All_Time = 5182.478
model saved to NER/polyglot/model.ckpt
176050/758000 (epoch 464), train_loss = 0.233, time/batch = 0.029, All_Time = 5183.943
176100/758000 (epoch 464), train_loss = 0.260, time/batch = 0.028, All_Time = 5185.407
176150/758000 (epoch 464), train_loss = 0.253, time/batch = 0.030, All_Time = 5186.898
176200/758000 (epoch 464), train_loss = 0.238, time/batch = 0.029, All_Time = 5188.392
176250/758000 (epoch 465), train_loss = 0.227, time/batch = 0.028, All_Time = 5189.888
176300/758000 (epoch 465), train_loss = 0.250, time/batch = 0.030, All_Time = 5191.352
176350/758000 (epoch 465), train_loss = 0.250, time/batch = 0.029, All_Time = 5192.838
176400/758000 (epoch 465), train_loss = 0.223, time/batch = 0.029, All_Time = 5194.317
176450/758000 (epoch 465), train_loss = 0.240, time/batch = 0.031, All_Time = 5195.794
176500/758000 (epoch 465), train_loss = 0.246, time/batch = 0.030, All_Time = 5197.268
176550/758000 (epoch 465), train_loss = 0.246, time/batch = 0.030, All_Time = 5198.742
176600/758000 (epoch 465), train_loss = 0.257, time/batch = 0.029, All_Time = 5200.229
176650/758000 (epoch 466), train_loss = 0.266, time/batch = 0.029, All_Time = 5201.739
176700/758000 (epoch 466), train_loss = 0.224, time/batch = 0.030, All_Time = 5203.226
176750/758000 (epoch 466), train_loss = 0.248, time/batch = 0.029, All_Time = 5204.726
176800/758000 (epoch 466), train_loss = 0.227, time/batch = 0.030, All_Time = 5206.218
176850/758000 (epoch 466), train_loss = 0.279, time/batch = 0.029, All_Time = 5207.709
176900/758000 (epoch 466), train_loss = 0.255, time/batch = 0.030, All_Time = 5209.201
176950/758000 (epoch 466), train_loss = 0.253, time/batch = 0.029, All_Time = 5210.692
177000/758000 (epoch 467), train_loss = 0.244, time/batch = 0.030, All_Time = 5212.181
model saved to NER/polyglot/model.ckpt
177050/758000 (epoch 467), train_loss = 0.247, time/batch = 0.029, All_Time = 5213.660
177100/758000 (epoch 467), train_loss = 0.270, time/batch = 0.029, All_Time = 5215.131
177150/758000 (epoch 467), train_loss = 0.246, time/batch = 0.030, All_Time = 5216.597
177200/758000 (epoch 467), train_loss = 0.237, time/batch = 0.030, All_Time = 5218.057
177250/758000 (epoch 467), train_loss = 0.224, time/batch = 0.029, All_Time = 5219.555
177300/758000 (epoch 467), train_loss = 0.229, time/batch = 0.030, All_Time = 5221.041
177350/758000 (epoch 467), train_loss = 0.246, time/batch = 0.030, All_Time = 5222.551
177400/758000 (epoch 468), train_loss = 0.249, time/batch = 0.030, All_Time = 5224.042
177450/758000 (epoch 468), train_loss = 0.264, time/batch = 0.030, All_Time = 5225.516
177500/758000 (epoch 468), train_loss = 0.240, time/batch = 0.029, All_Time = 5226.988
177550/758000 (epoch 468), train_loss = 0.250, time/batch = 0.029, All_Time = 5228.464
177600/758000 (epoch 468), train_loss = 0.227, time/batch = 0.031, All_Time = 5229.943
177650/758000 (epoch 468), train_loss = 0.217, time/batch = 0.030, All_Time = 5231.421
177700/758000 (epoch 468), train_loss = 0.277, time/batch = 0.028, All_Time = 5232.890
177750/758000 (epoch 468), train_loss = 0.259, time/batch = 0.032, All_Time = 5234.372
177800/758000 (epoch 469), train_loss = 0.269, time/batch = 0.029, All_Time = 5235.856
177850/758000 (epoch 469), train_loss = 0.296, time/batch = 0.030, All_Time = 5237.333
177900/758000 (epoch 469), train_loss = 0.228, time/batch = 0.029, All_Time = 5238.811
177950/758000 (epoch 469), train_loss = 0.220, time/batch = 0.029, All_Time = 5240.289
178000/758000 (epoch 469), train_loss = 0.257, time/batch = 0.029, All_Time = 5241.769
model saved to NER/polyglot/model.ckpt
178050/758000 (epoch 469), train_loss = 0.255, time/batch = 0.029, All_Time = 5243.240
178100/758000 (epoch 469), train_loss = 0.237, time/batch = 0.030, All_Time = 5244.704
178150/758000 (epoch 470), train_loss = 0.225, time/batch = 0.029, All_Time = 5246.185
178200/758000 (epoch 470), train_loss = 0.234, time/batch = 0.030, All_Time = 5247.678
178250/758000 (epoch 470), train_loss = 0.243, time/batch = 0.028, All_Time = 5249.169
178300/758000 (epoch 470), train_loss = 0.234, time/batch = 0.032, All_Time = 5250.650
178350/758000 (epoch 470), train_loss = 0.223, time/batch = 0.029, All_Time = 5252.121
178400/758000 (epoch 470), train_loss = 0.239, time/batch = 0.029, All_Time = 5253.602
178450/758000 (epoch 470), train_loss = 0.264, time/batch = 0.029, All_Time = 5255.086
178500/758000 (epoch 470), train_loss = 0.244, time/batch = 0.029, All_Time = 5256.558
178550/758000 (epoch 471), train_loss = 0.257, time/batch = 0.028, All_Time = 5258.043
178600/758000 (epoch 471), train_loss = 0.287, time/batch = 0.030, All_Time = 5259.524
178650/758000 (epoch 471), train_loss = 0.255, time/batch = 0.030, All_Time = 5260.997
178700/758000 (epoch 471), train_loss = 0.248, time/batch = 0.028, All_Time = 5262.471
178750/758000 (epoch 471), train_loss = 0.212, time/batch = 0.030, All_Time = 5263.950
178800/758000 (epoch 471), train_loss = 0.229, time/batch = 0.028, All_Time = 5265.434
178850/758000 (epoch 471), train_loss = 0.272, time/batch = 0.030, All_Time = 5266.911
178900/758000 (epoch 472), train_loss = 0.249, time/batch = 0.029, All_Time = 5268.398
178950/758000 (epoch 472), train_loss = 0.227, time/batch = 0.029, All_Time = 5269.873
179000/758000 (epoch 472), train_loss = 0.267, time/batch = 0.029, All_Time = 5271.349
model saved to NER/polyglot/model.ckpt
179050/758000 (epoch 472), train_loss = 0.239, time/batch = 0.030, All_Time = 5272.819
179100/758000 (epoch 472), train_loss = 0.247, time/batch = 0.029, All_Time = 5274.293
179150/758000 (epoch 472), train_loss = 0.241, time/batch = 0.028, All_Time = 5275.764
179200/758000 (epoch 472), train_loss = 0.274, time/batch = 0.030, All_Time = 5277.234
179250/758000 (epoch 472), train_loss = 0.279, time/batch = 0.029, All_Time = 5278.729
179300/758000 (epoch 473), train_loss = 0.238, time/batch = 0.029, All_Time = 5280.232
179350/758000 (epoch 473), train_loss = 0.248, time/batch = 0.029, All_Time = 5281.705
179400/758000 (epoch 473), train_loss = 0.299, time/batch = 0.029, All_Time = 5283.175
179450/758000 (epoch 473), train_loss = 0.230, time/batch = 0.029, All_Time = 5284.646
179500/758000 (epoch 473), train_loss = 0.216, time/batch = 0.028, All_Time = 5286.118
179550/758000 (epoch 473), train_loss = 0.244, time/batch = 0.030, All_Time = 5287.595
179600/758000 (epoch 473), train_loss = 0.274, time/batch = 0.030, All_Time = 5289.062
179650/758000 (epoch 474), train_loss = 0.221, time/batch = 0.028, All_Time = 5290.540
179700/758000 (epoch 474), train_loss = 0.257, time/batch = 0.030, All_Time = 5292.021
179750/758000 (epoch 474), train_loss = 0.241, time/batch = 0.030, All_Time = 5293.506
179800/758000 (epoch 474), train_loss = 0.240, time/batch = 0.029, All_Time = 5294.975
179850/758000 (epoch 474), train_loss = 0.256, time/batch = 0.031, All_Time = 5296.461
179900/758000 (epoch 474), train_loss = 0.219, time/batch = 0.030, All_Time = 5297.955
179950/758000 (epoch 474), train_loss = 0.224, time/batch = 0.031, All_Time = 5299.441
180000/758000 (epoch 474), train_loss = 0.257, time/batch = 0.029, All_Time = 5300.917
model saved to NER/polyglot/model.ckpt
180050/758000 (epoch 475), train_loss = 0.255, time/batch = 0.030, All_Time = 5302.401
180100/758000 (epoch 475), train_loss = 0.267, time/batch = 0.030, All_Time = 5303.862
180150/758000 (epoch 475), train_loss = 0.269, time/batch = 0.030, All_Time = 5305.326
180200/758000 (epoch 475), train_loss = 0.228, time/batch = 0.031, All_Time = 5306.801
180250/758000 (epoch 475), train_loss = 0.234, time/batch = 0.030, All_Time = 5308.270
180300/758000 (epoch 475), train_loss = 0.245, time/batch = 0.030, All_Time = 5309.740
180350/758000 (epoch 475), train_loss = 0.279, time/batch = 0.029, All_Time = 5311.205
180400/758000 (epoch 475), train_loss = 0.240, time/batch = 0.029, All_Time = 5312.667
180450/758000 (epoch 476), train_loss = 0.236, time/batch = 0.029, All_Time = 5314.154
180500/758000 (epoch 476), train_loss = 0.234, time/batch = 0.030, All_Time = 5315.652
180550/758000 (epoch 476), train_loss = 0.233, time/batch = 0.030, All_Time = 5317.122
180600/758000 (epoch 476), train_loss = 0.276, time/batch = 0.030, All_Time = 5318.611
180650/758000 (epoch 476), train_loss = 0.206, time/batch = 0.031, All_Time = 5320.093
180700/758000 (epoch 476), train_loss = 0.259, time/batch = 0.030, All_Time = 5321.575
180750/758000 (epoch 476), train_loss = 0.234, time/batch = 0.029, All_Time = 5323.066
180800/758000 (epoch 477), train_loss = 0.245, time/batch = 0.029, All_Time = 5324.553
180850/758000 (epoch 477), train_loss = 0.223, time/batch = 0.028, All_Time = 5326.030
180900/758000 (epoch 477), train_loss = 0.240, time/batch = 0.029, All_Time = 5327.503
180950/758000 (epoch 477), train_loss = 0.256, time/batch = 0.028, All_Time = 5328.973
181000/758000 (epoch 477), train_loss = 0.214, time/batch = 0.029, All_Time = 5330.444
model saved to NER/polyglot/model.ckpt
181050/758000 (epoch 477), train_loss = 0.272, time/batch = 0.029, All_Time = 5331.929
181100/758000 (epoch 477), train_loss = 0.213, time/batch = 0.031, All_Time = 5333.408
181150/758000 (epoch 477), train_loss = 0.251, time/batch = 0.029, All_Time = 5334.888
181200/758000 (epoch 478), train_loss = 0.247, time/batch = 0.030, All_Time = 5336.366
181250/758000 (epoch 478), train_loss = 0.229, time/batch = 0.029, All_Time = 5337.853
181300/758000 (epoch 478), train_loss = 0.217, time/batch = 0.031, All_Time = 5339.332
181350/758000 (epoch 478), train_loss = 0.220, time/batch = 0.029, All_Time = 5340.833
181400/758000 (epoch 478), train_loss = 0.250, time/batch = 0.031, All_Time = 5342.323
181450/758000 (epoch 478), train_loss = 0.207, time/batch = 0.031, All_Time = 5343.803
181500/758000 (epoch 478), train_loss = 0.268, time/batch = 0.030, All_Time = 5345.286
181550/758000 (epoch 479), train_loss = 0.256, time/batch = 0.028, All_Time = 5346.772
181600/758000 (epoch 479), train_loss = 0.264, time/batch = 0.031, All_Time = 5348.244
181650/758000 (epoch 479), train_loss = 0.284, time/batch = 0.029, All_Time = 5349.717
181700/758000 (epoch 479), train_loss = 0.239, time/batch = 0.030, All_Time = 5351.191
181750/758000 (epoch 479), train_loss = 0.267, time/batch = 0.028, All_Time = 5352.650
181800/758000 (epoch 479), train_loss = 0.256, time/batch = 0.031, All_Time = 5354.120
181850/758000 (epoch 479), train_loss = 0.236, time/batch = 0.030, All_Time = 5355.601
181900/758000 (epoch 479), train_loss = 0.268, time/batch = 0.030, All_Time = 5357.101
181950/758000 (epoch 480), train_loss = 0.226, time/batch = 0.029, All_Time = 5358.600
182000/758000 (epoch 480), train_loss = 0.222, time/batch = 0.028, All_Time = 5360.052
model saved to NER/polyglot/model.ckpt
182050/758000 (epoch 480), train_loss = 0.261, time/batch = 0.029, All_Time = 5361.523
182100/758000 (epoch 480), train_loss = 0.254, time/batch = 0.030, All_Time = 5363.010
182150/758000 (epoch 480), train_loss = 0.223, time/batch = 0.031, All_Time = 5364.507
182200/758000 (epoch 480), train_loss = 0.242, time/batch = 0.030, All_Time = 5366.000
182250/758000 (epoch 480), train_loss = 0.251, time/batch = 0.028, All_Time = 5367.472
182300/758000 (epoch 481), train_loss = 0.192, time/batch = 0.030, All_Time = 5368.959
182350/758000 (epoch 481), train_loss = 0.273, time/batch = 0.029, All_Time = 5370.434
182400/758000 (epoch 481), train_loss = 0.217, time/batch = 0.030, All_Time = 5371.908
182450/758000 (epoch 481), train_loss = 0.240, time/batch = 0.028, All_Time = 5373.376
182500/758000 (epoch 481), train_loss = 0.221, time/batch = 0.030, All_Time = 5374.837
182550/758000 (epoch 481), train_loss = 0.221, time/batch = 0.029, All_Time = 5376.298
182600/758000 (epoch 481), train_loss = 0.252, time/batch = 0.030, All_Time = 5377.764
182650/758000 (epoch 481), train_loss = 0.272, time/batch = 0.031, All_Time = 5379.240
182700/758000 (epoch 482), train_loss = 0.222, time/batch = 0.029, All_Time = 5380.742
182750/758000 (epoch 482), train_loss = 0.279, time/batch = 0.030, All_Time = 5382.228
182800/758000 (epoch 482), train_loss = 0.242, time/batch = 0.030, All_Time = 5383.712
182850/758000 (epoch 482), train_loss = 0.274, time/batch = 0.030, All_Time = 5385.200
182900/758000 (epoch 482), train_loss = 0.262, time/batch = 0.027, All_Time = 5386.694
182950/758000 (epoch 482), train_loss = 0.197, time/batch = 0.030, All_Time = 5388.170
183000/758000 (epoch 482), train_loss = 0.233, time/batch = 0.030, All_Time = 5389.655
model saved to NER/polyglot/model.ckpt
183050/758000 (epoch 482), train_loss = 0.281, time/batch = 0.028, All_Time = 5391.119
183100/758000 (epoch 483), train_loss = 0.246, time/batch = 0.028, All_Time = 5392.581
183150/758000 (epoch 483), train_loss = 0.212, time/batch = 0.029, All_Time = 5394.048
183200/758000 (epoch 483), train_loss = 0.255, time/batch = 0.029, All_Time = 5395.509
183250/758000 (epoch 483), train_loss = 0.271, time/batch = 0.029, All_Time = 5397.017
183300/758000 (epoch 483), train_loss = 0.203, time/batch = 0.031, All_Time = 5398.500
183350/758000 (epoch 483), train_loss = 0.226, time/batch = 0.029, All_Time = 5399.966
183400/758000 (epoch 483), train_loss = 0.254, time/batch = 0.031, All_Time = 5401.445
183450/758000 (epoch 484), train_loss = 0.219, time/batch = 0.030, All_Time = 5402.921
183500/758000 (epoch 484), train_loss = 0.265, time/batch = 0.031, All_Time = 5404.394
183550/758000 (epoch 484), train_loss = 0.227, time/batch = 0.029, All_Time = 5405.865
183600/758000 (epoch 484), train_loss = 0.213, time/batch = 0.031, All_Time = 5407.336
183650/758000 (epoch 484), train_loss = 0.224, time/batch = 0.029, All_Time = 5408.798
183700/758000 (epoch 484), train_loss = 0.213, time/batch = 0.030, All_Time = 5410.267
183750/758000 (epoch 484), train_loss = 0.230, time/batch = 0.031, All_Time = 5411.741
183800/758000 (epoch 484), train_loss = 0.223, time/batch = 0.030, All_Time = 5413.218
183850/758000 (epoch 485), train_loss = 0.275, time/batch = 0.029, All_Time = 5414.693
183900/758000 (epoch 485), train_loss = 0.229, time/batch = 0.031, All_Time = 5416.196
183950/758000 (epoch 485), train_loss = 0.270, time/batch = 0.030, All_Time = 5417.693
184000/758000 (epoch 485), train_loss = 0.273, time/batch = 0.031, All_Time = 5419.182
model saved to NER/polyglot/model.ckpt
184050/758000 (epoch 485), train_loss = 0.233, time/batch = 0.030, All_Time = 5420.657
184100/758000 (epoch 485), train_loss = 0.268, time/batch = 0.030, All_Time = 5422.128
184150/758000 (epoch 485), train_loss = 0.280, time/batch = 0.030, All_Time = 5423.600
184200/758000 (epoch 486), train_loss = 0.239, time/batch = 0.030, All_Time = 5425.067
184250/758000 (epoch 486), train_loss = 0.218, time/batch = 0.029, All_Time = 5426.535
184300/758000 (epoch 486), train_loss = 0.243, time/batch = 0.028, All_Time = 5427.999
184350/758000 (epoch 486), train_loss = 0.244, time/batch = 0.031, All_Time = 5429.475
184400/758000 (epoch 486), train_loss = 0.243, time/batch = 0.029, All_Time = 5430.935
184450/758000 (epoch 486), train_loss = 0.244, time/batch = 0.029, All_Time = 5432.427
184500/758000 (epoch 486), train_loss = 0.213, time/batch = 0.030, All_Time = 5433.936
184550/758000 (epoch 486), train_loss = 0.289, time/batch = 0.030, All_Time = 5435.418
184600/758000 (epoch 487), train_loss = 0.237, time/batch = 0.029, All_Time = 5436.901
184650/758000 (epoch 487), train_loss = 0.246, time/batch = 0.029, All_Time = 5438.365
184700/758000 (epoch 487), train_loss = 0.288, time/batch = 0.031, All_Time = 5439.842
184750/758000 (epoch 487), train_loss = 0.257, time/batch = 0.029, All_Time = 5441.318
184800/758000 (epoch 487), train_loss = 0.218, time/batch = 0.029, All_Time = 5442.787
184850/758000 (epoch 487), train_loss = 0.238, time/batch = 0.030, All_Time = 5444.253
184900/758000 (epoch 487), train_loss = 0.251, time/batch = 0.029, All_Time = 5445.719
184950/758000 (epoch 487), train_loss = 0.251, time/batch = 0.031, All_Time = 5447.193
185000/758000 (epoch 488), train_loss = 0.252, time/batch = 0.029, All_Time = 5448.670
model saved to NER/polyglot/model.ckpt
185050/758000 (epoch 488), train_loss = 0.280, time/batch = 0.028, All_Time = 5450.139
185100/758000 (epoch 488), train_loss = 0.242, time/batch = 0.031, All_Time = 5451.639
185150/758000 (epoch 488), train_loss = 0.250, time/batch = 0.030, All_Time = 5453.140
185200/758000 (epoch 488), train_loss = 0.239, time/batch = 0.032, All_Time = 5454.624
185250/758000 (epoch 488), train_loss = 0.239, time/batch = 0.030, All_Time = 5456.107
185300/758000 (epoch 488), train_loss = 0.250, time/batch = 0.029, All_Time = 5457.585
185350/758000 (epoch 489), train_loss = 0.221, time/batch = 0.029, All_Time = 5459.066
185400/758000 (epoch 489), train_loss = 0.219, time/batch = 0.030, All_Time = 5460.534
185450/758000 (epoch 489), train_loss = 0.246, time/batch = 0.028, All_Time = 5462.016
185500/758000 (epoch 489), train_loss = 0.262, time/batch = 0.029, All_Time = 5463.485
185550/758000 (epoch 489), train_loss = 0.260, time/batch = 0.029, All_Time = 5464.956
185600/758000 (epoch 489), train_loss = 0.241, time/batch = 0.029, All_Time = 5466.444
185650/758000 (epoch 489), train_loss = 0.210, time/batch = 0.030, All_Time = 5467.940
185700/758000 (epoch 489), train_loss = 0.239, time/batch = 0.029, All_Time = 5469.417
185750/758000 (epoch 490), train_loss = 0.230, time/batch = 0.030, All_Time = 5470.892
185800/758000 (epoch 490), train_loss = 0.226, time/batch = 0.031, All_Time = 5472.376
185850/758000 (epoch 490), train_loss = 0.264, time/batch = 0.030, All_Time = 5473.843
185900/758000 (epoch 490), train_loss = 0.240, time/batch = 0.029, All_Time = 5475.313
185950/758000 (epoch 490), train_loss = 0.253, time/batch = 0.029, All_Time = 5476.785
186000/758000 (epoch 490), train_loss = 0.251, time/batch = 0.030, All_Time = 5478.249
model saved to NER/polyglot/model.ckpt
186050/758000 (epoch 490), train_loss = 0.248, time/batch = 0.028, All_Time = 5479.709
186100/758000 (epoch 491), train_loss = 0.216, time/batch = 0.029, All_Time = 5481.181
186150/758000 (epoch 491), train_loss = 0.233, time/batch = 0.029, All_Time = 5482.646
186200/758000 (epoch 491), train_loss = 0.250, time/batch = 0.028, All_Time = 5484.270
186250/758000 (epoch 491), train_loss = 0.241, time/batch = 0.030, All_Time = 5485.752
186300/758000 (epoch 491), train_loss = 0.243, time/batch = 0.031, All_Time = 5487.234
186350/758000 (epoch 491), train_loss = 0.242, time/batch = 0.030, All_Time = 5488.713
186400/758000 (epoch 491), train_loss = 0.230, time/batch = 0.035, All_Time = 5490.200
186450/758000 (epoch 491), train_loss = 0.259, time/batch = 0.030, All_Time = 5491.685
186500/758000 (epoch 492), train_loss = 0.250, time/batch = 0.029, All_Time = 5493.163
186550/758000 (epoch 492), train_loss = 0.253, time/batch = 0.029, All_Time = 5494.631
186600/758000 (epoch 492), train_loss = 0.245, time/batch = 0.031, All_Time = 5496.113
186650/758000 (epoch 492), train_loss = 0.231, time/batch = 0.030, All_Time = 5497.584
186700/758000 (epoch 492), train_loss = 0.228, time/batch = 0.030, All_Time = 5499.061
186750/758000 (epoch 492), train_loss = 0.238, time/batch = 0.030, All_Time = 5500.533
186800/758000 (epoch 492), train_loss = 0.268, time/batch = 0.028, All_Time = 5502.000
186850/758000 (epoch 493), train_loss = 0.248, time/batch = 0.030, All_Time = 5503.492
186900/758000 (epoch 493), train_loss = 0.280, time/batch = 0.031, All_Time = 5504.970
186950/758000 (epoch 493), train_loss = 0.242, time/batch = 0.028, All_Time = 5506.434
187000/758000 (epoch 493), train_loss = 0.258, time/batch = 0.029, All_Time = 5507.912
model saved to NER/polyglot/model.ckpt
187050/758000 (epoch 493), train_loss = 0.224, time/batch = 0.030, All_Time = 5509.390
187100/758000 (epoch 493), train_loss = 0.243, time/batch = 0.031, All_Time = 5510.899
187150/758000 (epoch 493), train_loss = 0.219, time/batch = 0.029, All_Time = 5512.377
187200/758000 (epoch 493), train_loss = 0.232, time/batch = 0.030, All_Time = 5513.850
187250/758000 (epoch 494), train_loss = 0.237, time/batch = 0.030, All_Time = 5515.342
187300/758000 (epoch 494), train_loss = 0.239, time/batch = 0.031, All_Time = 5516.822
187350/758000 (epoch 494), train_loss = 0.293, time/batch = 0.029, All_Time = 5518.311
187400/758000 (epoch 494), train_loss = 0.318, time/batch = 0.030, All_Time = 5519.803
187450/758000 (epoch 494), train_loss = 0.196, time/batch = 0.029, All_Time = 5521.273
187500/758000 (epoch 494), train_loss = 0.213, time/batch = 0.028, All_Time = 5522.745
187550/758000 (epoch 494), train_loss = 0.250, time/batch = 0.028, All_Time = 5524.227
187600/758000 (epoch 494), train_loss = 0.297, time/batch = 0.029, All_Time = 5525.709
187650/758000 (epoch 495), train_loss = 0.226, time/batch = 0.028, All_Time = 5527.180
187700/758000 (epoch 495), train_loss = 0.259, time/batch = 0.029, All_Time = 5528.635
187750/758000 (epoch 495), train_loss = 0.223, time/batch = 0.029, All_Time = 5530.102
187800/758000 (epoch 495), train_loss = 0.239, time/batch = 0.029, All_Time = 5531.567
187850/758000 (epoch 495), train_loss = 0.212, time/batch = 0.031, All_Time = 5533.053
187900/758000 (epoch 495), train_loss = 0.243, time/batch = 0.030, All_Time = 5534.532
187950/758000 (epoch 495), train_loss = 0.215, time/batch = 0.029, All_Time = 5536.014
188000/758000 (epoch 496), train_loss = 0.228, time/batch = 0.029, All_Time = 5537.495
model saved to NER/polyglot/model.ckpt
188050/758000 (epoch 496), train_loss = 0.252, time/batch = 0.030, All_Time = 5538.965
188100/758000 (epoch 496), train_loss = 0.260, time/batch = 0.030, All_Time = 5540.440
188150/758000 (epoch 496), train_loss = 0.228, time/batch = 0.030, All_Time = 5541.924
188200/758000 (epoch 496), train_loss = 0.236, time/batch = 0.029, All_Time = 5543.426
188250/758000 (epoch 496), train_loss = 0.271, time/batch = 0.030, All_Time = 5544.904
188300/758000 (epoch 496), train_loss = 0.238, time/batch = 0.031, All_Time = 5546.379
188350/758000 (epoch 496), train_loss = 0.268, time/batch = 0.031, All_Time = 5547.869
188400/758000 (epoch 497), train_loss = 0.248, time/batch = 0.030, All_Time = 5549.355
188450/758000 (epoch 497), train_loss = 0.249, time/batch = 0.029, All_Time = 5550.841
188500/758000 (epoch 497), train_loss = 0.240, time/batch = 0.030, All_Time = 5552.323
188550/758000 (epoch 497), train_loss = 0.247, time/batch = 0.032, All_Time = 5553.799
188600/758000 (epoch 497), train_loss = 0.235, time/batch = 0.030, All_Time = 5555.278
188650/758000 (epoch 497), train_loss = 0.247, time/batch = 0.030, All_Time = 5556.747
188700/758000 (epoch 497), train_loss = 0.251, time/batch = 0.030, All_Time = 5558.223
188750/758000 (epoch 498), train_loss = 0.242, time/batch = 0.030, All_Time = 5559.705
188800/758000 (epoch 498), train_loss = 0.276, time/batch = 0.030, All_Time = 5561.181
188850/758000 (epoch 498), train_loss = 0.256, time/batch = 0.030, All_Time = 5562.658
188900/758000 (epoch 498), train_loss = 0.258, time/batch = 0.029, All_Time = 5564.133
188950/758000 (epoch 498), train_loss = 0.213, time/batch = 0.030, All_Time = 5565.595
189000/758000 (epoch 498), train_loss = 0.237, time/batch = 0.030, All_Time = 5567.071
model saved to NER/polyglot/model.ckpt
189050/758000 (epoch 498), train_loss = 0.249, time/batch = 0.029, All_Time = 5568.538
189100/758000 (epoch 498), train_loss = 0.251, time/batch = 0.029, All_Time = 5570.015
189150/758000 (epoch 499), train_loss = 0.232, time/batch = 0.029, All_Time = 5571.490
189200/758000 (epoch 499), train_loss = 0.255, time/batch = 0.030, All_Time = 5572.997
189250/758000 (epoch 499), train_loss = 0.265, time/batch = 0.029, All_Time = 5574.489
189300/758000 (epoch 499), train_loss = 0.229, time/batch = 0.030, All_Time = 5575.969
189350/758000 (epoch 499), train_loss = 0.263, time/batch = 0.030, All_Time = 5577.452
189400/758000 (epoch 499), train_loss = 0.217, time/batch = 0.030, All_Time = 5578.932
189450/758000 (epoch 499), train_loss = 0.248, time/batch = 0.031, All_Time = 5580.422
189500/758000 (epoch 500), train_loss = 0.059, time/batch = 0.036, All_Time = 5581.909
189550/758000 (epoch 500), train_loss = 0.250, time/batch = 0.029, All_Time = 5583.396
189600/758000 (epoch 500), train_loss = 0.223, time/batch = 0.030, All_Time = 5584.864
189650/758000 (epoch 500), train_loss = 0.250, time/batch = 0.029, All_Time = 5586.373
189700/758000 (epoch 500), train_loss = 0.231, time/batch = 0.029, All_Time = 5587.859
189750/758000 (epoch 500), train_loss = 0.250, time/batch = 0.031, All_Time = 5589.333
189800/758000 (epoch 500), train_loss = 0.232, time/batch = 0.030, All_Time = 5590.814
189850/758000 (epoch 500), train_loss = 0.230, time/batch = 0.029, All_Time = 5592.280
189900/758000 (epoch 501), train_loss = 0.224, time/batch = 0.031, All_Time = 5593.765
189950/758000 (epoch 501), train_loss = 0.233, time/batch = 0.030, All_Time = 5595.224
190000/758000 (epoch 501), train_loss = 0.224, time/batch = 0.029, All_Time = 5596.700
model saved to NER/polyglot/model.ckpt
190050/758000 (epoch 501), train_loss = 0.262, time/batch = 0.029, All_Time = 5598.168
190100/758000 (epoch 501), train_loss = 0.220, time/batch = 0.028, All_Time = 5599.645
190150/758000 (epoch 501), train_loss = 0.228, time/batch = 0.030, All_Time = 5601.115
190200/758000 (epoch 501), train_loss = 0.280, time/batch = 0.030, All_Time = 5602.580
190250/758000 (epoch 501), train_loss = 0.272, time/batch = 0.029, All_Time = 5604.055
190300/758000 (epoch 502), train_loss = 0.230, time/batch = 0.028, All_Time = 5605.532
190350/758000 (epoch 502), train_loss = 0.224, time/batch = 0.032, All_Time = 5607.065
190400/758000 (epoch 502), train_loss = 0.201, time/batch = 0.034, All_Time = 5608.643
190450/758000 (epoch 502), train_loss = 0.270, time/batch = 0.028, All_Time = 5610.113
190500/758000 (epoch 502), train_loss = 0.259, time/batch = 0.030, All_Time = 5611.587
190550/758000 (epoch 502), train_loss = 0.209, time/batch = 0.029, All_Time = 5613.067
190600/758000 (epoch 502), train_loss = 0.218, time/batch = 0.029, All_Time = 5614.544
190650/758000 (epoch 503), train_loss = 0.229, time/batch = 0.029, All_Time = 5616.029
190700/758000 (epoch 503), train_loss = 0.283, time/batch = 0.030, All_Time = 5617.504
190750/758000 (epoch 503), train_loss = 0.231, time/batch = 0.030, All_Time = 5618.981
190800/758000 (epoch 503), train_loss = 0.307, time/batch = 0.030, All_Time = 5620.456
190850/758000 (epoch 503), train_loss = 0.221, time/batch = 0.029, All_Time = 5621.926
190900/758000 (epoch 503), train_loss = 0.208, time/batch = 0.030, All_Time = 5623.397
190950/758000 (epoch 503), train_loss = 0.247, time/batch = 0.031, All_Time = 5624.873
191000/758000 (epoch 503), train_loss = 0.252, time/batch = 0.029, All_Time = 5626.358
model saved to NER/polyglot/model.ckpt
191050/758000 (epoch 504), train_loss = 0.264, time/batch = 0.030, All_Time = 5627.840
191100/758000 (epoch 504), train_loss = 0.229, time/batch = 0.032, All_Time = 5629.333
191150/758000 (epoch 504), train_loss = 0.242, time/batch = 0.030, All_Time = 5630.837
191200/758000 (epoch 504), train_loss = 0.267, time/batch = 0.029, All_Time = 5632.313
191250/758000 (epoch 504), train_loss = 0.249, time/batch = 0.033, All_Time = 5633.782
191300/758000 (epoch 504), train_loss = 0.237, time/batch = 0.029, All_Time = 5635.247
191350/758000 (epoch 504), train_loss = 0.276, time/batch = 0.030, All_Time = 5636.719
191400/758000 (epoch 505), train_loss = 0.256, time/batch = 0.031, All_Time = 5638.194
191450/758000 (epoch 505), train_loss = 0.222, time/batch = 0.029, All_Time = 5639.654
191500/758000 (epoch 505), train_loss = 0.266, time/batch = 0.030, All_Time = 5641.122
191550/758000 (epoch 505), train_loss = 0.216, time/batch = 0.029, All_Time = 5642.587
191600/758000 (epoch 505), train_loss = 0.223, time/batch = 0.029, All_Time = 5644.060
191650/758000 (epoch 505), train_loss = 0.261, time/batch = 0.031, All_Time = 5645.533
191700/758000 (epoch 505), train_loss = 0.238, time/batch = 0.031, All_Time = 5647.025
191750/758000 (epoch 505), train_loss = 0.264, time/batch = 0.028, All_Time = 5648.520
191800/758000 (epoch 506), train_loss = 0.223, time/batch = 0.030, All_Time = 5650.007
191850/758000 (epoch 506), train_loss = 0.231, time/batch = 0.030, All_Time = 5651.484
191900/758000 (epoch 506), train_loss = 0.238, time/batch = 0.031, All_Time = 5652.960
191950/758000 (epoch 506), train_loss = 0.266, time/batch = 0.031, All_Time = 5654.438
192000/758000 (epoch 506), train_loss = 0.239, time/batch = 0.029, All_Time = 5655.905
model saved to NER/polyglot/model.ckpt
192050/758000 (epoch 506), train_loss = 0.226, time/batch = 0.029, All_Time = 5657.370
192100/758000 (epoch 506), train_loss = 0.276, time/batch = 0.029, All_Time = 5658.840
192150/758000 (epoch 506), train_loss = 0.240, time/batch = 0.031, All_Time = 5660.329
192200/758000 (epoch 507), train_loss = 0.281, time/batch = 0.029, All_Time = 5661.839
192250/758000 (epoch 507), train_loss = 0.257, time/batch = 0.031, All_Time = 5663.317
192300/758000 (epoch 507), train_loss = 0.240, time/batch = 0.030, All_Time = 5664.809
192350/758000 (epoch 507), train_loss = 0.231, time/batch = 0.029, All_Time = 5666.292
192400/758000 (epoch 507), train_loss = 0.217, time/batch = 0.030, All_Time = 5667.780
192450/758000 (epoch 507), train_loss = 0.224, time/batch = 0.031, All_Time = 5669.263
192500/758000 (epoch 507), train_loss = 0.215, time/batch = 0.029, All_Time = 5670.740
192550/758000 (epoch 508), train_loss = 0.249, time/batch = 0.029, All_Time = 5672.218
192600/758000 (epoch 508), train_loss = 0.211, time/batch = 0.030, All_Time = 5673.681
192650/758000 (epoch 508), train_loss = 0.245, time/batch = 0.029, All_Time = 5675.149
192700/758000 (epoch 508), train_loss = 0.217, time/batch = 0.028, All_Time = 5676.613
192750/758000 (epoch 508), train_loss = 0.233, time/batch = 0.029, All_Time = 5678.089
192800/758000 (epoch 508), train_loss = 0.228, time/batch = 0.030, All_Time = 5679.567
192850/758000 (epoch 508), train_loss = 0.248, time/batch = 0.029, All_Time = 5681.034
192900/758000 (epoch 508), train_loss = 0.229, time/batch = 0.029, All_Time = 5682.503
192950/758000 (epoch 509), train_loss = 0.218, time/batch = 0.030, All_Time = 5683.974
193000/758000 (epoch 509), train_loss = 0.237, time/batch = 0.028, All_Time = 5685.451
model saved to NER/polyglot/model.ckpt
193050/758000 (epoch 509), train_loss = 0.212, time/batch = 0.029, All_Time = 5686.939
193100/758000 (epoch 509), train_loss = 0.266, time/batch = 0.033, All_Time = 5688.436
193150/758000 (epoch 509), train_loss = 0.255, time/batch = 0.032, All_Time = 5689.896
193200/758000 (epoch 509), train_loss = 0.232, time/batch = 0.030, All_Time = 5691.386
193250/758000 (epoch 509), train_loss = 0.262, time/batch = 0.029, All_Time = 5692.860
193300/758000 (epoch 510), train_loss = 0.282, time/batch = 0.030, All_Time = 5694.357
193350/758000 (epoch 510), train_loss = 0.292, time/batch = 0.031, All_Time = 5695.830
193400/758000 (epoch 510), train_loss = 0.253, time/batch = 0.030, All_Time = 5697.295
193450/758000 (epoch 510), train_loss = 0.222, time/batch = 0.030, All_Time = 5698.765
193500/758000 (epoch 510), train_loss = 0.221, time/batch = 0.031, All_Time = 5700.240
193550/758000 (epoch 510), train_loss = 0.260, time/batch = 0.030, All_Time = 5701.700
193600/758000 (epoch 510), train_loss = 0.244, time/batch = 0.031, All_Time = 5703.164
193650/758000 (epoch 510), train_loss = 0.247, time/batch = 0.031, All_Time = 5704.637
193700/758000 (epoch 511), train_loss = 0.210, time/batch = 0.029, All_Time = 5706.132
193750/758000 (epoch 511), train_loss = 0.265, time/batch = 0.029, All_Time = 5707.606
193800/758000 (epoch 511), train_loss = 0.229, time/batch = 0.031, All_Time = 5709.081
193850/758000 (epoch 511), train_loss = 0.232, time/batch = 0.029, All_Time = 5710.563
193900/758000 (epoch 511), train_loss = 0.230, time/batch = 0.030, All_Time = 5712.035
193950/758000 (epoch 511), train_loss = 0.253, time/batch = 0.029, All_Time = 5713.517
194000/758000 (epoch 511), train_loss = 0.258, time/batch = 0.029, All_Time = 5714.986
model saved to NER/polyglot/model.ckpt
194050/758000 (epoch 512), train_loss = 0.196, time/batch = 0.028, All_Time = 5716.470
194100/758000 (epoch 512), train_loss = 0.254, time/batch = 0.030, All_Time = 5717.930
194150/758000 (epoch 512), train_loss = 0.281, time/batch = 0.031, All_Time = 5719.403
194200/758000 (epoch 512), train_loss = 0.235, time/batch = 0.030, All_Time = 5720.883
194250/758000 (epoch 512), train_loss = 0.247, time/batch = 0.029, All_Time = 5722.365
194300/758000 (epoch 512), train_loss = 0.251, time/batch = 0.029, All_Time = 5723.840
194350/758000 (epoch 512), train_loss = 0.203, time/batch = 0.030, All_Time = 5725.360
194400/758000 (epoch 512), train_loss = 0.268, time/batch = 0.030, All_Time = 5726.844
194450/758000 (epoch 513), train_loss = 0.233, time/batch = 0.028, All_Time = 5728.338
194500/758000 (epoch 513), train_loss = 0.241, time/batch = 0.029, All_Time = 5729.812
194550/758000 (epoch 513), train_loss = 0.252, time/batch = 0.030, All_Time = 5731.297
194600/758000 (epoch 513), train_loss = 0.258, time/batch = 0.031, All_Time = 5732.763
194650/758000 (epoch 513), train_loss = 0.243, time/batch = 0.031, All_Time = 5734.236
194700/758000 (epoch 513), train_loss = 0.243, time/batch = 0.029, All_Time = 5735.702
194750/758000 (epoch 513), train_loss = 0.244, time/batch = 0.029, All_Time = 5737.171
194800/758000 (epoch 513), train_loss = 0.286, time/batch = 0.031, All_Time = 5738.630
194850/758000 (epoch 514), train_loss = 0.207, time/batch = 0.028, All_Time = 5740.115
194900/758000 (epoch 514), train_loss = 0.244, time/batch = 0.030, All_Time = 5741.622
194950/758000 (epoch 514), train_loss = 0.217, time/batch = 0.029, All_Time = 5743.110
195000/758000 (epoch 514), train_loss = 0.233, time/batch = 0.030, All_Time = 5744.589
model saved to NER/polyglot/model.ckpt
195050/758000 (epoch 514), train_loss = 0.260, time/batch = 0.031, All_Time = 5746.071
195100/758000 (epoch 514), train_loss = 0.253, time/batch = 0.030, All_Time = 5747.550
195150/758000 (epoch 514), train_loss = 0.238, time/batch = 0.031, All_Time = 5749.030
195200/758000 (epoch 515), train_loss = 0.227, time/batch = 0.030, All_Time = 5750.502
195250/758000 (epoch 515), train_loss = 0.250, time/batch = 0.029, All_Time = 5751.963
195300/758000 (epoch 515), train_loss = 0.250, time/batch = 0.029, All_Time = 5753.433
195350/758000 (epoch 515), train_loss = 0.223, time/batch = 0.029, All_Time = 5754.893
195400/758000 (epoch 515), train_loss = 0.240, time/batch = 0.030, All_Time = 5756.388
195450/758000 (epoch 515), train_loss = 0.246, time/batch = 0.029, All_Time = 5757.881
195500/758000 (epoch 515), train_loss = 0.246, time/batch = 0.030, All_Time = 5759.368
195550/758000 (epoch 515), train_loss = 0.257, time/batch = 0.030, All_Time = 5760.847
195600/758000 (epoch 516), train_loss = 0.266, time/batch = 0.030, All_Time = 5762.326
195650/758000 (epoch 516), train_loss = 0.224, time/batch = 0.031, All_Time = 5763.809
195700/758000 (epoch 516), train_loss = 0.248, time/batch = 0.029, All_Time = 5765.275
195750/758000 (epoch 516), train_loss = 0.227, time/batch = 0.029, All_Time = 5766.748
195800/758000 (epoch 516), train_loss = 0.279, time/batch = 0.029, All_Time = 5768.228
195850/758000 (epoch 516), train_loss = 0.255, time/batch = 0.030, All_Time = 5769.727
195900/758000 (epoch 516), train_loss = 0.253, time/batch = 0.031, All_Time = 5771.208
195950/758000 (epoch 517), train_loss = 0.244, time/batch = 0.029, All_Time = 5772.698
196000/758000 (epoch 517), train_loss = 0.247, time/batch = 0.030, All_Time = 5774.174
model saved to NER/polyglot/model.ckpt
196050/758000 (epoch 517), train_loss = 0.270, time/batch = 0.030, All_Time = 5775.648
196100/758000 (epoch 517), train_loss = 0.246, time/batch = 0.028, All_Time = 5777.116
196150/758000 (epoch 517), train_loss = 0.237, time/batch = 0.029, All_Time = 5778.582
196200/758000 (epoch 517), train_loss = 0.224, time/batch = 0.029, All_Time = 5780.061
196250/758000 (epoch 517), train_loss = 0.229, time/batch = 0.029, All_Time = 5781.530
196300/758000 (epoch 517), train_loss = 0.246, time/batch = 0.030, All_Time = 5783.022
196350/758000 (epoch 518), train_loss = 0.249, time/batch = 0.030, All_Time = 5784.503
196400/758000 (epoch 518), train_loss = 0.264, time/batch = 0.029, All_Time = 5785.975
196450/758000 (epoch 518), train_loss = 0.240, time/batch = 0.029, All_Time = 5787.439
196500/758000 (epoch 518), train_loss = 0.250, time/batch = 0.029, All_Time = 5788.907
196550/758000 (epoch 518), train_loss = 0.227, time/batch = 0.030, All_Time = 5790.385
196600/758000 (epoch 518), train_loss = 0.217, time/batch = 0.029, All_Time = 5791.848
196650/758000 (epoch 518), train_loss = 0.277, time/batch = 0.029, All_Time = 5793.327
196700/758000 (epoch 518), train_loss = 0.259, time/batch = 0.029, All_Time = 5794.801
196750/758000 (epoch 519), train_loss = 0.269, time/batch = 0.029, All_Time = 5796.281
196800/758000 (epoch 519), train_loss = 0.296, time/batch = 0.029, All_Time = 5797.751
196850/758000 (epoch 519), train_loss = 0.228, time/batch = 0.030, All_Time = 5799.232
196900/758000 (epoch 519), train_loss = 0.220, time/batch = 0.028, All_Time = 5800.704
196950/758000 (epoch 519), train_loss = 0.257, time/batch = 0.031, All_Time = 5802.172
197000/758000 (epoch 519), train_loss = 0.255, time/batch = 0.028, All_Time = 5803.642
model saved to NER/polyglot/model.ckpt
197050/758000 (epoch 519), train_loss = 0.237, time/batch = 0.030, All_Time = 5805.120
197100/758000 (epoch 520), train_loss = 0.225, time/batch = 0.029, All_Time = 5806.598
197150/758000 (epoch 520), train_loss = 0.234, time/batch = 0.028, All_Time = 5808.060
197200/758000 (epoch 520), train_loss = 0.243, time/batch = 0.031, All_Time = 5809.565
197250/758000 (epoch 520), train_loss = 0.234, time/batch = 0.030, All_Time = 5811.048
197300/758000 (epoch 520), train_loss = 0.223, time/batch = 0.030, All_Time = 5812.532
197350/758000 (epoch 520), train_loss = 0.239, time/batch = 0.028, All_Time = 5814.010
197400/758000 (epoch 520), train_loss = 0.264, time/batch = 0.029, All_Time = 5815.480
197450/758000 (epoch 520), train_loss = 0.244, time/batch = 0.029, All_Time = 5816.951
197500/758000 (epoch 521), train_loss = 0.257, time/batch = 0.029, All_Time = 5818.440
197550/758000 (epoch 521), train_loss = 0.287, time/batch = 0.028, All_Time = 5819.911
197600/758000 (epoch 521), train_loss = 0.255, time/batch = 0.029, All_Time = 5821.377
197650/758000 (epoch 521), train_loss = 0.248, time/batch = 0.029, All_Time = 5822.840
197700/758000 (epoch 521), train_loss = 0.212, time/batch = 0.029, All_Time = 5824.317
197750/758000 (epoch 521), train_loss = 0.229, time/batch = 0.029, All_Time = 5825.793
197800/758000 (epoch 521), train_loss = 0.272, time/batch = 0.030, All_Time = 5827.272
197850/758000 (epoch 522), train_loss = 0.249, time/batch = 0.029, All_Time = 5828.756
197900/758000 (epoch 522), train_loss = 0.227, time/batch = 0.029, All_Time = 5830.217
197950/758000 (epoch 522), train_loss = 0.267, time/batch = 0.030, All_Time = 5831.694
198000/758000 (epoch 522), train_loss = 0.239, time/batch = 0.030, All_Time = 5833.174
model saved to NER/polyglot/model.ckpt
198050/758000 (epoch 522), train_loss = 0.247, time/batch = 0.030, All_Time = 5834.651
198100/758000 (epoch 522), train_loss = 0.241, time/batch = 0.029, All_Time = 5836.127
198150/758000 (epoch 522), train_loss = 0.274, time/batch = 0.030, All_Time = 5837.593
198200/758000 (epoch 522), train_loss = 0.279, time/batch = 0.029, All_Time = 5839.069
198250/758000 (epoch 523), train_loss = 0.238, time/batch = 0.030, All_Time = 5840.547
198300/758000 (epoch 523), train_loss = 0.248, time/batch = 0.032, All_Time = 5842.012
198350/758000 (epoch 523), train_loss = 0.299, time/batch = 0.029, All_Time = 5843.472
198400/758000 (epoch 523), train_loss = 0.230, time/batch = 0.029, All_Time = 5844.937
198450/758000 (epoch 523), train_loss = 0.216, time/batch = 0.030, All_Time = 5846.425
198500/758000 (epoch 523), train_loss = 0.244, time/batch = 0.029, All_Time = 5847.897
198550/758000 (epoch 523), train_loss = 0.274, time/batch = 0.032, All_Time = 5849.378
198600/758000 (epoch 524), train_loss = 0.221, time/batch = 0.030, All_Time = 5850.856
198650/758000 (epoch 524), train_loss = 0.257, time/batch = 0.029, All_Time = 5852.325
198700/758000 (epoch 524), train_loss = 0.241, time/batch = 0.029, All_Time = 5853.794
198750/758000 (epoch 524), train_loss = 0.240, time/batch = 0.029, All_Time = 5855.255
198800/758000 (epoch 524), train_loss = 0.256, time/batch = 0.028, All_Time = 5856.727
198850/758000 (epoch 524), train_loss = 0.219, time/batch = 0.031, All_Time = 5858.210
198900/758000 (epoch 524), train_loss = 0.224, time/batch = 0.029, All_Time = 5859.685
198950/758000 (epoch 524), train_loss = 0.257, time/batch = 0.029, All_Time = 5861.156
199000/758000 (epoch 525), train_loss = 0.255, time/batch = 0.028, All_Time = 5862.649
model saved to NER/polyglot/model.ckpt
199050/758000 (epoch 525), train_loss = 0.267, time/batch = 0.030, All_Time = 5864.125
199100/758000 (epoch 525), train_loss = 0.269, time/batch = 0.030, All_Time = 5865.598
199150/758000 (epoch 525), train_loss = 0.228, time/batch = 0.030, All_Time = 5867.085
199200/758000 (epoch 525), train_loss = 0.234, time/batch = 0.029, All_Time = 5868.568
199250/758000 (epoch 525), train_loss = 0.245, time/batch = 0.031, All_Time = 5870.062
199300/758000 (epoch 525), train_loss = 0.279, time/batch = 0.029, All_Time = 5871.535
199350/758000 (epoch 525), train_loss = 0.240, time/batch = 0.029, All_Time = 5873.004
199400/758000 (epoch 526), train_loss = 0.236, time/batch = 0.029, All_Time = 5874.483
199450/758000 (epoch 526), train_loss = 0.234, time/batch = 0.029, All_Time = 5875.954
199500/758000 (epoch 526), train_loss = 0.233, time/batch = 0.031, All_Time = 5877.432
199550/758000 (epoch 526), train_loss = 0.276, time/batch = 0.030, All_Time = 5878.918
199600/758000 (epoch 526), train_loss = 0.206, time/batch = 0.029, All_Time = 5880.389
199650/758000 (epoch 526), train_loss = 0.259, time/batch = 0.030, All_Time = 5881.876
199700/758000 (epoch 526), train_loss = 0.234, time/batch = 0.029, All_Time = 5883.366
199750/758000 (epoch 527), train_loss = 0.245, time/batch = 0.030, All_Time = 5884.850
199800/758000 (epoch 527), train_loss = 0.223, time/batch = 0.029, All_Time = 5886.323
199850/758000 (epoch 527), train_loss = 0.240, time/batch = 0.028, All_Time = 5887.786
199900/758000 (epoch 527), train_loss = 0.256, time/batch = 0.030, All_Time = 5889.260
199950/758000 (epoch 527), train_loss = 0.214, time/batch = 0.029, All_Time = 5890.736
200000/758000 (epoch 527), train_loss = 0.272, time/batch = 0.028, All_Time = 5892.200
model saved to NER/polyglot/model.ckpt
200050/758000 (epoch 527), train_loss = 0.213, time/batch = 0.030, All_Time = 5893.679
200100/758000 (epoch 527), train_loss = 0.251, time/batch = 0.030, All_Time = 5895.138
200150/758000 (epoch 528), train_loss = 0.247, time/batch = 0.029, All_Time = 5896.604
200200/758000 (epoch 528), train_loss = 0.229, time/batch = 0.029, All_Time = 5898.075
200250/758000 (epoch 528), train_loss = 0.217, time/batch = 0.030, All_Time = 5899.540
200300/758000 (epoch 528), train_loss = 0.220, time/batch = 0.031, All_Time = 5901.021
200350/758000 (epoch 528), train_loss = 0.250, time/batch = 0.031, All_Time = 5902.500
200400/758000 (epoch 528), train_loss = 0.207, time/batch = 0.029, All_Time = 5903.971
200450/758000 (epoch 528), train_loss = 0.268, time/batch = 0.032, All_Time = 5905.477
200500/758000 (epoch 529), train_loss = 0.256, time/batch = 0.029, All_Time = 5906.970
200550/758000 (epoch 529), train_loss = 0.264, time/batch = 0.030, All_Time = 5908.440
200600/758000 (epoch 529), train_loss = 0.284, time/batch = 0.032, All_Time = 5909.937
200650/758000 (epoch 529), train_loss = 0.239, time/batch = 0.031, All_Time = 5911.407
200700/758000 (epoch 529), train_loss = 0.267, time/batch = 0.029, All_Time = 5912.882
200750/758000 (epoch 529), train_loss = 0.256, time/batch = 0.031, All_Time = 5914.357
200800/758000 (epoch 529), train_loss = 0.236, time/batch = 0.030, All_Time = 5915.834
200850/758000 (epoch 529), train_loss = 0.268, time/batch = 0.029, All_Time = 5917.311
200900/758000 (epoch 530), train_loss = 0.226, time/batch = 0.029, All_Time = 5918.789
200950/758000 (epoch 530), train_loss = 0.222, time/batch = 0.030, All_Time = 5920.255
201000/758000 (epoch 530), train_loss = 0.261, time/batch = 0.028, All_Time = 5921.734
model saved to NER/polyglot/model.ckpt
201050/758000 (epoch 530), train_loss = 0.254, time/batch = 0.030, All_Time = 5923.204
201100/758000 (epoch 530), train_loss = 0.223, time/batch = 0.029, All_Time = 5924.676
201150/758000 (epoch 530), train_loss = 0.242, time/batch = 0.030, All_Time = 5926.143
201200/758000 (epoch 530), train_loss = 0.251, time/batch = 0.030, All_Time = 5927.614
201250/758000 (epoch 531), train_loss = 0.192, time/batch = 0.029, All_Time = 5929.091
201300/758000 (epoch 531), train_loss = 0.273, time/batch = 0.029, All_Time = 5930.556
201350/758000 (epoch 531), train_loss = 0.217, time/batch = 0.031, All_Time = 5932.046
201400/758000 (epoch 531), train_loss = 0.240, time/batch = 0.030, All_Time = 5933.542
201450/758000 (epoch 531), train_loss = 0.221, time/batch = 0.030, All_Time = 5935.042
201500/758000 (epoch 531), train_loss = 0.221, time/batch = 0.030, All_Time = 5936.535
201550/758000 (epoch 531), train_loss = 0.252, time/batch = 0.030, All_Time = 5938.020
201600/758000 (epoch 531), train_loss = 0.272, time/batch = 0.028, All_Time = 5939.495
201650/758000 (epoch 532), train_loss = 0.222, time/batch = 0.029, All_Time = 5940.990
201700/758000 (epoch 532), train_loss = 0.279, time/batch = 0.029, All_Time = 5942.462
201750/758000 (epoch 532), train_loss = 0.242, time/batch = 0.029, All_Time = 5943.956
201800/758000 (epoch 532), train_loss = 0.274, time/batch = 0.030, All_Time = 5945.438
201850/758000 (epoch 532), train_loss = 0.262, time/batch = 0.029, All_Time = 5946.929
201900/758000 (epoch 532), train_loss = 0.197, time/batch = 0.030, All_Time = 5948.405
201950/758000 (epoch 532), train_loss = 0.233, time/batch = 0.029, All_Time = 5949.882
202000/758000 (epoch 532), train_loss = 0.281, time/batch = 0.030, All_Time = 5951.349
model saved to NER/polyglot/model.ckpt
202050/758000 (epoch 533), train_loss = 0.246, time/batch = 0.029, All_Time = 5952.831
202100/758000 (epoch 533), train_loss = 0.212, time/batch = 0.029, All_Time = 5954.287
202150/758000 (epoch 533), train_loss = 0.255, time/batch = 0.029, All_Time = 5955.747
202200/758000 (epoch 533), train_loss = 0.271, time/batch = 0.029, All_Time = 5957.204
202250/758000 (epoch 533), train_loss = 0.203, time/batch = 0.030, All_Time = 5958.668
202300/758000 (epoch 533), train_loss = 0.226, time/batch = 0.031, All_Time = 5960.156
202350/758000 (epoch 533), train_loss = 0.254, time/batch = 0.031, All_Time = 5961.648
202400/758000 (epoch 534), train_loss = 0.219, time/batch = 0.030, All_Time = 5963.136
202450/758000 (epoch 534), train_loss = 0.265, time/batch = 0.029, All_Time = 5964.604
202500/758000 (epoch 534), train_loss = 0.227, time/batch = 0.031, All_Time = 5966.079
202550/758000 (epoch 534), train_loss = 0.213, time/batch = 0.028, All_Time = 5967.556
202600/758000 (epoch 534), train_loss = 0.224, time/batch = 0.032, All_Time = 5969.033
202650/758000 (epoch 534), train_loss = 0.213, time/batch = 0.030, All_Time = 5970.503
202700/758000 (epoch 534), train_loss = 0.230, time/batch = 0.029, All_Time = 5971.979
202750/758000 (epoch 534), train_loss = 0.223, time/batch = 0.029, All_Time = 5973.451
202800/758000 (epoch 535), train_loss = 0.275, time/batch = 0.031, All_Time = 5974.930
202850/758000 (epoch 535), train_loss = 0.229, time/batch = 0.031, All_Time = 5976.393
202900/758000 (epoch 535), train_loss = 0.270, time/batch = 0.029, All_Time = 5977.865
202950/758000 (epoch 535), train_loss = 0.273, time/batch = 0.030, All_Time = 5979.334
203000/758000 (epoch 535), train_loss = 0.233, time/batch = 0.029, All_Time = 5980.805
model saved to NER/polyglot/model.ckpt
203050/758000 (epoch 535), train_loss = 0.268, time/batch = 0.029, All_Time = 5982.279
203100/758000 (epoch 535), train_loss = 0.280, time/batch = 0.029, All_Time = 5983.751
203150/758000 (epoch 536), train_loss = 0.239, time/batch = 0.029, All_Time = 5985.223
203200/758000 (epoch 536), train_loss = 0.218, time/batch = 0.029, All_Time = 5986.688
203250/758000 (epoch 536), train_loss = 0.243, time/batch = 0.030, All_Time = 5988.152
203300/758000 (epoch 536), train_loss = 0.244, time/batch = 0.033, All_Time = 5989.640
203350/758000 (epoch 536), train_loss = 0.243, time/batch = 0.032, All_Time = 5991.144
203400/758000 (epoch 536), train_loss = 0.244, time/batch = 0.030, All_Time = 5992.617
203450/758000 (epoch 536), train_loss = 0.213, time/batch = 0.029, All_Time = 5994.099
203500/758000 (epoch 536), train_loss = 0.289, time/batch = 0.030, All_Time = 5995.580
203550/758000 (epoch 537), train_loss = 0.237, time/batch = 0.029, All_Time = 5997.057
203600/758000 (epoch 537), train_loss = 0.246, time/batch = 0.029, All_Time = 5998.520
203650/758000 (epoch 537), train_loss = 0.288, time/batch = 0.028, All_Time = 5999.983
203700/758000 (epoch 537), train_loss = 0.257, time/batch = 0.028, All_Time = 6001.446
203750/758000 (epoch 537), train_loss = 0.218, time/batch = 0.029, All_Time = 6002.916
203800/758000 (epoch 537), train_loss = 0.238, time/batch = 0.030, All_Time = 6004.414
203850/758000 (epoch 537), train_loss = 0.251, time/batch = 0.027, All_Time = 6005.902
203900/758000 (epoch 537), train_loss = 0.251, time/batch = 0.030, All_Time = 6007.378
203950/758000 (epoch 538), train_loss = 0.252, time/batch = 0.028, All_Time = 6008.862
204000/758000 (epoch 538), train_loss = 0.280, time/batch = 0.031, All_Time = 6010.329
model saved to NER/polyglot/model.ckpt
204050/758000 (epoch 538), train_loss = 0.242, time/batch = 0.030, All_Time = 6011.791
204100/758000 (epoch 538), train_loss = 0.250, time/batch = 0.030, All_Time = 6013.254
204150/758000 (epoch 538), train_loss = 0.239, time/batch = 0.029, All_Time = 6014.715
204200/758000 (epoch 538), train_loss = 0.239, time/batch = 0.028, All_Time = 6016.183
204250/758000 (epoch 538), train_loss = 0.250, time/batch = 0.028, All_Time = 6017.655
204300/758000 (epoch 539), train_loss = 0.221, time/batch = 0.032, All_Time = 6019.154
204350/758000 (epoch 539), train_loss = 0.219, time/batch = 0.029, All_Time = 6020.644
204400/758000 (epoch 539), train_loss = 0.246, time/batch = 0.029, All_Time = 6022.119
204450/758000 (epoch 539), train_loss = 0.262, time/batch = 0.030, All_Time = 6023.607
204500/758000 (epoch 539), train_loss = 0.260, time/batch = 0.030, All_Time = 6025.086
204550/758000 (epoch 539), train_loss = 0.241, time/batch = 0.029, All_Time = 6026.574
204600/758000 (epoch 539), train_loss = 0.210, time/batch = 0.031, All_Time = 6028.062
204650/758000 (epoch 539), train_loss = 0.239, time/batch = 0.031, All_Time = 6029.548
204700/758000 (epoch 540), train_loss = 0.230, time/batch = 0.031, All_Time = 6031.037
204750/758000 (epoch 540), train_loss = 0.226, time/batch = 0.031, All_Time = 6032.513
204800/758000 (epoch 540), train_loss = 0.264, time/batch = 0.029, All_Time = 6033.985
204850/758000 (epoch 540), train_loss = 0.240, time/batch = 0.030, All_Time = 6035.449
204900/758000 (epoch 540), train_loss = 0.253, time/batch = 0.029, All_Time = 6036.904
204950/758000 (epoch 540), train_loss = 0.251, time/batch = 0.029, All_Time = 6038.369
205000/758000 (epoch 540), train_loss = 0.248, time/batch = 0.029, All_Time = 6039.836
model saved to NER/polyglot/model.ckpt
205050/758000 (epoch 541), train_loss = 0.216, time/batch = 0.030, All_Time = 6041.325
205100/758000 (epoch 541), train_loss = 0.233, time/batch = 0.030, All_Time = 6042.782
205150/758000 (epoch 541), train_loss = 0.250, time/batch = 0.029, All_Time = 6044.242
205200/758000 (epoch 541), train_loss = 0.241, time/batch = 0.031, All_Time = 6045.728
205250/758000 (epoch 541), train_loss = 0.243, time/batch = 0.030, All_Time = 6047.245
205300/758000 (epoch 541), train_loss = 0.242, time/batch = 0.030, All_Time = 6048.716
205350/758000 (epoch 541), train_loss = 0.230, time/batch = 0.030, All_Time = 6050.193
205400/758000 (epoch 541), train_loss = 0.259, time/batch = 0.031, All_Time = 6051.678
205450/758000 (epoch 542), train_loss = 0.250, time/batch = 0.030, All_Time = 6053.169
205500/758000 (epoch 542), train_loss = 0.253, time/batch = 0.029, All_Time = 6054.633
205550/758000 (epoch 542), train_loss = 0.245, time/batch = 0.030, All_Time = 6056.089
205600/758000 (epoch 542), train_loss = 0.231, time/batch = 0.030, All_Time = 6057.556
205650/758000 (epoch 542), train_loss = 0.228, time/batch = 0.030, All_Time = 6059.029
205700/758000 (epoch 542), train_loss = 0.238, time/batch = 0.029, All_Time = 6060.508
205750/758000 (epoch 542), train_loss = 0.268, time/batch = 0.029, All_Time = 6061.977
205800/758000 (epoch 543), train_loss = 0.248, time/batch = 0.029, All_Time = 6063.447
205850/758000 (epoch 543), train_loss = 0.280, time/batch = 0.032, All_Time = 6064.924
205900/758000 (epoch 543), train_loss = 0.242, time/batch = 0.029, All_Time = 6066.394
205950/758000 (epoch 543), train_loss = 0.258, time/batch = 0.030, All_Time = 6067.887
206000/758000 (epoch 543), train_loss = 0.224, time/batch = 0.031, All_Time = 6069.374
model saved to NER/polyglot/model.ckpt
206050/758000 (epoch 543), train_loss = 0.243, time/batch = 0.030, All_Time = 6070.859
206100/758000 (epoch 543), train_loss = 0.219, time/batch = 0.029, All_Time = 6072.329
206150/758000 (epoch 543), train_loss = 0.232, time/batch = 0.030, All_Time = 6073.806
206200/758000 (epoch 544), train_loss = 0.237, time/batch = 0.028, All_Time = 6075.287
206250/758000 (epoch 544), train_loss = 0.239, time/batch = 0.029, All_Time = 6076.747
206300/758000 (epoch 544), train_loss = 0.293, time/batch = 0.029, All_Time = 6078.217
206350/758000 (epoch 544), train_loss = 0.318, time/batch = 0.028, All_Time = 6079.685
206400/758000 (epoch 544), train_loss = 0.196, time/batch = 0.032, All_Time = 6081.173
206450/758000 (epoch 544), train_loss = 0.213, time/batch = 0.030, All_Time = 6082.676
206500/758000 (epoch 544), train_loss = 0.250, time/batch = 0.029, All_Time = 6084.169
206550/758000 (epoch 544), train_loss = 0.297, time/batch = 0.029, All_Time = 6085.655
206600/758000 (epoch 545), train_loss = 0.226, time/batch = 0.029, All_Time = 6087.135
206650/758000 (epoch 545), train_loss = 0.259, time/batch = 0.029, All_Time = 6088.606
206700/758000 (epoch 545), train_loss = 0.223, time/batch = 0.030, All_Time = 6090.083
206750/758000 (epoch 545), train_loss = 0.239, time/batch = 0.029, All_Time = 6091.545
206800/758000 (epoch 545), train_loss = 0.212, time/batch = 0.029, All_Time = 6093.053
206850/758000 (epoch 545), train_loss = 0.243, time/batch = 0.029, All_Time = 6094.548
206900/758000 (epoch 545), train_loss = 0.215, time/batch = 0.030, All_Time = 6096.026
206950/758000 (epoch 546), train_loss = 0.228, time/batch = 0.031, All_Time = 6097.518
207000/758000 (epoch 546), train_loss = 0.252, time/batch = 0.029, All_Time = 6098.992
model saved to NER/polyglot/model.ckpt
207050/758000 (epoch 546), train_loss = 0.260, time/batch = 0.029, All_Time = 6100.468
207100/758000 (epoch 546), train_loss = 0.228, time/batch = 0.029, All_Time = 6101.932
207150/758000 (epoch 546), train_loss = 0.236, time/batch = 0.028, All_Time = 6103.392
207200/758000 (epoch 546), train_loss = 0.271, time/batch = 0.030, All_Time = 6104.852
207250/758000 (epoch 546), train_loss = 0.238, time/batch = 0.029, All_Time = 6106.315
207300/758000 (epoch 546), train_loss = 0.268, time/batch = 0.028, All_Time = 6107.786
207350/758000 (epoch 547), train_loss = 0.248, time/batch = 0.030, All_Time = 6109.267
207400/758000 (epoch 547), train_loss = 0.249, time/batch = 0.030, All_Time = 6110.731
207450/758000 (epoch 547), train_loss = 0.240, time/batch = 0.030, All_Time = 6112.224
207500/758000 (epoch 547), train_loss = 0.247, time/batch = 0.029, All_Time = 6113.727
207550/758000 (epoch 547), train_loss = 0.235, time/batch = 0.029, All_Time = 6115.214
207600/758000 (epoch 547), train_loss = 0.247, time/batch = 0.029, All_Time = 6116.701
207650/758000 (epoch 547), train_loss = 0.251, time/batch = 0.030, All_Time = 6118.180
207700/758000 (epoch 548), train_loss = 0.242, time/batch = 0.031, All_Time = 6119.662
207750/758000 (epoch 548), train_loss = 0.276, time/batch = 0.029, All_Time = 6121.141
207800/758000 (epoch 548), train_loss = 0.256, time/batch = 0.029, All_Time = 6122.609
207850/758000 (epoch 548), train_loss = 0.258, time/batch = 0.028, All_Time = 6124.078
207900/758000 (epoch 548), train_loss = 0.213, time/batch = 0.029, All_Time = 6125.553
207950/758000 (epoch 548), train_loss = 0.237, time/batch = 0.029, All_Time = 6127.023
208000/758000 (epoch 548), train_loss = 0.249, time/batch = 0.029, All_Time = 6128.500
model saved to NER/polyglot/model.ckpt
208050/758000 (epoch 548), train_loss = 0.251, time/batch = 0.029, All_Time = 6129.955
208100/758000 (epoch 549), train_loss = 0.232, time/batch = 0.028, All_Time = 6131.436
208150/758000 (epoch 549), train_loss = 0.255, time/batch = 0.031, All_Time = 6132.898
208200/758000 (epoch 549), train_loss = 0.265, time/batch = 0.032, All_Time = 6134.402
208250/758000 (epoch 549), train_loss = 0.229, time/batch = 0.028, All_Time = 6135.879
208300/758000 (epoch 549), train_loss = 0.263, time/batch = 0.031, All_Time = 6137.351
208350/758000 (epoch 549), train_loss = 0.217, time/batch = 0.029, All_Time = 6138.831
208400/758000 (epoch 549), train_loss = 0.248, time/batch = 0.029, All_Time = 6140.306
208450/758000 (epoch 550), train_loss = 0.059, time/batch = 0.036, All_Time = 6141.784
208500/758000 (epoch 550), train_loss = 0.250, time/batch = 0.031, All_Time = 6143.270
208550/758000 (epoch 550), train_loss = 0.223, time/batch = 0.029, All_Time = 6144.763
208600/758000 (epoch 550), train_loss = 0.250, time/batch = 0.030, All_Time = 6146.250
208650/758000 (epoch 550), train_loss = 0.231, time/batch = 0.030, All_Time = 6147.724
208700/758000 (epoch 550), train_loss = 0.250, time/batch = 0.030, All_Time = 6149.205
208750/758000 (epoch 550), train_loss = 0.232, time/batch = 0.030, All_Time = 6150.695
208800/758000 (epoch 550), train_loss = 0.230, time/batch = 0.030, All_Time = 6152.186
208850/758000 (epoch 551), train_loss = 0.224, time/batch = 0.030, All_Time = 6153.666
208900/758000 (epoch 551), train_loss = 0.233, time/batch = 0.029, All_Time = 6155.136
208950/758000 (epoch 551), train_loss = 0.224, time/batch = 0.029, All_Time = 6156.591
209000/758000 (epoch 551), train_loss = 0.262, time/batch = 0.029, All_Time = 6158.064
model saved to NER/polyglot/model.ckpt
209050/758000 (epoch 551), train_loss = 0.220, time/batch = 0.030, All_Time = 6159.539
209100/758000 (epoch 551), train_loss = 0.228, time/batch = 0.030, All_Time = 6161.011
209150/758000 (epoch 551), train_loss = 0.280, time/batch = 0.030, All_Time = 6162.481
209200/758000 (epoch 551), train_loss = 0.272, time/batch = 0.030, All_Time = 6163.975
209250/758000 (epoch 552), train_loss = 0.230, time/batch = 0.028, All_Time = 6165.465
209300/758000 (epoch 552), train_loss = 0.224, time/batch = 0.028, All_Time = 6166.926
209350/758000 (epoch 552), train_loss = 0.201, time/batch = 0.030, All_Time = 6168.398
209400/758000 (epoch 552), train_loss = 0.270, time/batch = 0.029, All_Time = 6169.873
209450/758000 (epoch 552), train_loss = 0.259, time/batch = 0.030, All_Time = 6171.355
209500/758000 (epoch 552), train_loss = 0.209, time/batch = 0.030, All_Time = 6172.835
209550/758000 (epoch 552), train_loss = 0.218, time/batch = 0.029, All_Time = 6174.328
209600/758000 (epoch 553), train_loss = 0.229, time/batch = 0.029, All_Time = 6175.818
209650/758000 (epoch 553), train_loss = 0.283, time/batch = 0.029, All_Time = 6177.294
209700/758000 (epoch 553), train_loss = 0.231, time/batch = 0.030, All_Time = 6178.777
209750/758000 (epoch 553), train_loss = 0.307, time/batch = 0.029, All_Time = 6180.252
209800/758000 (epoch 553), train_loss = 0.221, time/batch = 0.030, All_Time = 6181.727
209850/758000 (epoch 553), train_loss = 0.208, time/batch = 0.029, All_Time = 6183.210
209900/758000 (epoch 553), train_loss = 0.247, time/batch = 0.029, All_Time = 6184.686
209950/758000 (epoch 553), train_loss = 0.252, time/batch = 0.030, All_Time = 6186.164
210000/758000 (epoch 554), train_loss = 0.264, time/batch = 0.029, All_Time = 6187.648
model saved to NER/polyglot/model.ckpt
210050/758000 (epoch 554), train_loss = 0.229, time/batch = 0.029, All_Time = 6189.119
210100/758000 (epoch 554), train_loss = 0.242, time/batch = 0.029, All_Time = 6190.588
210150/758000 (epoch 554), train_loss = 0.267, time/batch = 0.030, All_Time = 6192.048
210200/758000 (epoch 554), train_loss = 0.249, time/batch = 0.031, All_Time = 6193.542
210250/758000 (epoch 554), train_loss = 0.237, time/batch = 0.028, All_Time = 6195.019
210300/758000 (epoch 554), train_loss = 0.276, time/batch = 0.029, All_Time = 6196.499
210350/758000 (epoch 555), train_loss = 0.256, time/batch = 0.029, All_Time = 6197.986
210400/758000 (epoch 555), train_loss = 0.222, time/batch = 0.029, All_Time = 6199.455
210450/758000 (epoch 555), train_loss = 0.266, time/batch = 0.031, All_Time = 6200.928
210500/758000 (epoch 555), train_loss = 0.216, time/batch = 0.030, All_Time = 6202.397
210550/758000 (epoch 555), train_loss = 0.223, time/batch = 0.029, All_Time = 6203.878
210600/758000 (epoch 555), train_loss = 0.261, time/batch = 0.029, All_Time = 6205.364
210650/758000 (epoch 555), train_loss = 0.238, time/batch = 0.029, All_Time = 6206.835
210700/758000 (epoch 555), train_loss = 0.264, time/batch = 0.032, All_Time = 6208.315
210750/758000 (epoch 556), train_loss = 0.223, time/batch = 0.031, All_Time = 6209.832
210800/758000 (epoch 556), train_loss = 0.231, time/batch = 0.030, All_Time = 6211.307
210850/758000 (epoch 556), train_loss = 0.238, time/batch = 0.030, All_Time = 6212.827
210900/758000 (epoch 556), train_loss = 0.266, time/batch = 0.029, All_Time = 6214.318
210950/758000 (epoch 556), train_loss = 0.239, time/batch = 0.029, All_Time = 6215.789
211000/758000 (epoch 556), train_loss = 0.226, time/batch = 0.030, All_Time = 6217.264
model saved to NER/polyglot/model.ckpt
211050/758000 (epoch 556), train_loss = 0.276, time/batch = 0.030, All_Time = 6218.737
211100/758000 (epoch 556), train_loss = 0.240, time/batch = 0.030, All_Time = 6220.198
211150/758000 (epoch 557), train_loss = 0.281, time/batch = 0.030, All_Time = 6221.659
211200/758000 (epoch 557), train_loss = 0.257, time/batch = 0.031, All_Time = 6223.137
211250/758000 (epoch 557), train_loss = 0.240, time/batch = 0.029, All_Time = 6224.601
211300/758000 (epoch 557), train_loss = 0.231, time/batch = 0.029, All_Time = 6226.081
211350/758000 (epoch 557), train_loss = 0.217, time/batch = 0.029, All_Time = 6227.561
211400/758000 (epoch 557), train_loss = 0.224, time/batch = 0.030, All_Time = 6229.037
211450/758000 (epoch 557), train_loss = 0.215, time/batch = 0.029, All_Time = 6230.502
211500/758000 (epoch 558), train_loss = 0.249, time/batch = 0.031, All_Time = 6231.979
211550/758000 (epoch 558), train_loss = 0.211, time/batch = 0.031, All_Time = 6233.450
211600/758000 (epoch 558), train_loss = 0.245, time/batch = 0.029, All_Time = 6234.918
211650/758000 (epoch 558), train_loss = 0.217, time/batch = 0.031, All_Time = 6236.414
211700/758000 (epoch 558), train_loss = 0.233, time/batch = 0.029, All_Time = 6237.911
211750/758000 (epoch 558), train_loss = 0.228, time/batch = 0.029, All_Time = 6239.394
211800/758000 (epoch 558), train_loss = 0.248, time/batch = 0.029, All_Time = 6240.873
211850/758000 (epoch 558), train_loss = 0.229, time/batch = 0.029, All_Time = 6242.360
211900/758000 (epoch 559), train_loss = 0.218, time/batch = 0.031, All_Time = 6243.846
211950/758000 (epoch 559), train_loss = 0.237, time/batch = 0.031, All_Time = 6245.330
212000/758000 (epoch 559), train_loss = 0.212, time/batch = 0.029, All_Time = 6246.792
model saved to NER/polyglot/model.ckpt
212050/758000 (epoch 559), train_loss = 0.266, time/batch = 0.028, All_Time = 6248.262
212100/758000 (epoch 559), train_loss = 0.255, time/batch = 0.030, All_Time = 6249.735
212150/758000 (epoch 559), train_loss = 0.232, time/batch = 0.031, All_Time = 6251.192
212200/758000 (epoch 559), train_loss = 0.262, time/batch = 0.029, All_Time = 6252.661
212250/758000 (epoch 560), train_loss = 0.282, time/batch = 0.030, All_Time = 6254.177
212300/758000 (epoch 560), train_loss = 0.292, time/batch = 0.029, All_Time = 6255.662
212350/758000 (epoch 560), train_loss = 0.253, time/batch = 0.029, All_Time = 6257.136
212400/758000 (epoch 560), train_loss = 0.222, time/batch = 0.031, All_Time = 6258.612
212450/758000 (epoch 560), train_loss = 0.221, time/batch = 0.028, All_Time = 6260.094
212500/758000 (epoch 560), train_loss = 0.260, time/batch = 0.029, All_Time = 6261.562
212550/758000 (epoch 560), train_loss = 0.244, time/batch = 0.033, All_Time = 6263.049
212600/758000 (epoch 560), train_loss = 0.247, time/batch = 0.030, All_Time = 6264.535
212650/758000 (epoch 561), train_loss = 0.210, time/batch = 0.028, All_Time = 6266.024
212700/758000 (epoch 561), train_loss = 0.265, time/batch = 0.028, All_Time = 6267.494
212750/758000 (epoch 561), train_loss = 0.229, time/batch = 0.032, All_Time = 6268.967
212800/758000 (epoch 561), train_loss = 0.232, time/batch = 0.030, All_Time = 6270.429
212850/758000 (epoch 561), train_loss = 0.230, time/batch = 0.029, All_Time = 6271.902
212900/758000 (epoch 561), train_loss = 0.253, time/batch = 0.029, All_Time = 6273.369
212950/758000 (epoch 561), train_loss = 0.258, time/batch = 0.031, All_Time = 6274.830
213000/758000 (epoch 562), train_loss = 0.196, time/batch = 0.029, All_Time = 6276.314
model saved to NER/polyglot/model.ckpt
213050/758000 (epoch 562), train_loss = 0.254, time/batch = 0.032, All_Time = 6277.808
213100/758000 (epoch 562), train_loss = 0.281, time/batch = 0.028, All_Time = 6279.284
213150/758000 (epoch 562), train_loss = 0.235, time/batch = 0.029, All_Time = 6280.745
213200/758000 (epoch 562), train_loss = 0.247, time/batch = 0.029, All_Time = 6282.224
213250/758000 (epoch 562), train_loss = 0.251, time/batch = 0.032, All_Time = 6283.713
213300/758000 (epoch 562), train_loss = 0.203, time/batch = 0.030, All_Time = 6285.196
213350/758000 (epoch 562), train_loss = 0.268, time/batch = 0.029, All_Time = 6286.674
213400/758000 (epoch 563), train_loss = 0.233, time/batch = 0.031, All_Time = 6288.157
213450/758000 (epoch 563), train_loss = 0.241, time/batch = 0.031, All_Time = 6289.623
213500/758000 (epoch 563), train_loss = 0.252, time/batch = 0.029, All_Time = 6291.076
213550/758000 (epoch 563), train_loss = 0.258, time/batch = 0.030, All_Time = 6292.551
213600/758000 (epoch 563), train_loss = 0.243, time/batch = 0.030, All_Time = 6294.012
213650/758000 (epoch 563), train_loss = 0.243, time/batch = 0.031, All_Time = 6295.490
213700/758000 (epoch 563), train_loss = 0.244, time/batch = 0.030, All_Time = 6296.978
213750/758000 (epoch 563), train_loss = 0.286, time/batch = 0.029, All_Time = 6298.470
213800/758000 (epoch 564), train_loss = 0.207, time/batch = 0.029, All_Time = 6299.967
213850/758000 (epoch 564), train_loss = 0.244, time/batch = 0.029, All_Time = 6301.444
213900/758000 (epoch 564), train_loss = 0.217, time/batch = 0.029, All_Time = 6302.926
213950/758000 (epoch 564), train_loss = 0.233, time/batch = 0.029, All_Time = 6304.392
214000/758000 (epoch 564), train_loss = 0.260, time/batch = 0.030, All_Time = 6305.863
model saved to NER/polyglot/model.ckpt
214050/758000 (epoch 564), train_loss = 0.253, time/batch = 0.029, All_Time = 6307.334
214100/758000 (epoch 564), train_loss = 0.238, time/batch = 0.030, All_Time = 6308.804
214150/758000 (epoch 565), train_loss = 0.227, time/batch = 0.030, All_Time = 6310.282
214200/758000 (epoch 565), train_loss = 0.250, time/batch = 0.030, All_Time = 6311.741
214250/758000 (epoch 565), train_loss = 0.250, time/batch = 0.030, All_Time = 6313.225
214300/758000 (epoch 565), train_loss = 0.223, time/batch = 0.031, All_Time = 6314.722
214350/758000 (epoch 565), train_loss = 0.240, time/batch = 0.029, All_Time = 6316.209
214400/758000 (epoch 565), train_loss = 0.246, time/batch = 0.031, All_Time = 6317.683
214450/758000 (epoch 565), train_loss = 0.246, time/batch = 0.030, All_Time = 6319.175
214500/758000 (epoch 565), train_loss = 0.257, time/batch = 0.030, All_Time = 6320.664
214550/758000 (epoch 566), train_loss = 0.266, time/batch = 0.029, All_Time = 6322.150
214600/758000 (epoch 566), train_loss = 0.224, time/batch = 0.029, All_Time = 6323.619
214650/758000 (epoch 566), train_loss = 0.248, time/batch = 0.031, All_Time = 6325.090
214700/758000 (epoch 566), train_loss = 0.227, time/batch = 0.028, All_Time = 6326.563
214750/758000 (epoch 566), train_loss = 0.279, time/batch = 0.029, All_Time = 6328.027
214800/758000 (epoch 566), train_loss = 0.255, time/batch = 0.028, All_Time = 6329.491
214850/758000 (epoch 566), train_loss = 0.253, time/batch = 0.029, All_Time = 6330.967
214900/758000 (epoch 567), train_loss = 0.244, time/batch = 0.029, All_Time = 6332.483
214950/758000 (epoch 567), train_loss = 0.247, time/batch = 0.030, All_Time = 6333.966
215000/758000 (epoch 567), train_loss = 0.270, time/batch = 0.030, All_Time = 6335.428
model saved to NER/polyglot/model.ckpt
215050/758000 (epoch 567), train_loss = 0.246, time/batch = 0.030, All_Time = 6336.894
215100/758000 (epoch 567), train_loss = 0.237, time/batch = 0.029, All_Time = 6338.359
215150/758000 (epoch 567), train_loss = 0.224, time/batch = 0.030, All_Time = 6339.830
215200/758000 (epoch 567), train_loss = 0.229, time/batch = 0.029, All_Time = 6341.307
215250/758000 (epoch 567), train_loss = 0.246, time/batch = 0.030, All_Time = 6342.792
215300/758000 (epoch 568), train_loss = 0.249, time/batch = 0.029, All_Time = 6344.270
215350/758000 (epoch 568), train_loss = 0.264, time/batch = 0.031, All_Time = 6345.741
215400/758000 (epoch 568), train_loss = 0.240, time/batch = 0.030, All_Time = 6347.206
215450/758000 (epoch 568), train_loss = 0.250, time/batch = 0.029, All_Time = 6348.680
215500/758000 (epoch 568), train_loss = 0.227, time/batch = 0.029, All_Time = 6350.147
215550/758000 (epoch 568), train_loss = 0.217, time/batch = 0.030, All_Time = 6351.618
215600/758000 (epoch 568), train_loss = 0.277, time/batch = 0.030, All_Time = 6353.099
215650/758000 (epoch 568), train_loss = 0.259, time/batch = 0.031, All_Time = 6354.579
215700/758000 (epoch 569), train_loss = 0.269, time/batch = 0.033, All_Time = 6356.108
215750/758000 (epoch 569), train_loss = 0.296, time/batch = 0.030, All_Time = 6357.658
215800/758000 (epoch 569), train_loss = 0.228, time/batch = 0.030, All_Time = 6359.174
215850/758000 (epoch 569), train_loss = 0.220, time/batch = 0.031, All_Time = 6360.710
215900/758000 (epoch 569), train_loss = 0.257, time/batch = 0.030, All_Time = 6362.219
215950/758000 (epoch 569), train_loss = 0.255, time/batch = 0.028, All_Time = 6363.728
216000/758000 (epoch 569), train_loss = 0.237, time/batch = 0.029, All_Time = 6365.242
model saved to NER/polyglot/model.ckpt
216050/758000 (epoch 570), train_loss = 0.225, time/batch = 0.029, All_Time = 6366.740
216100/758000 (epoch 570), train_loss = 0.234, time/batch = 0.029, All_Time = 6368.215
216150/758000 (epoch 570), train_loss = 0.243, time/batch = 0.030, All_Time = 6369.688
216200/758000 (epoch 570), train_loss = 0.234, time/batch = 0.029, All_Time = 6371.154
216250/758000 (epoch 570), train_loss = 0.223, time/batch = 0.030, All_Time = 6372.625
216300/758000 (epoch 570), train_loss = 0.239, time/batch = 0.030, All_Time = 6374.131
216350/758000 (epoch 570), train_loss = 0.264, time/batch = 0.031, All_Time = 6375.616
216400/758000 (epoch 570), train_loss = 0.244, time/batch = 0.032, All_Time = 6377.102
216450/758000 (epoch 571), train_loss = 0.257, time/batch = 0.030, All_Time = 6378.583
216500/758000 (epoch 571), train_loss = 0.287, time/batch = 0.030, All_Time = 6380.055
216550/758000 (epoch 571), train_loss = 0.255, time/batch = 0.029, All_Time = 6381.520
216600/758000 (epoch 571), train_loss = 0.248, time/batch = 0.030, All_Time = 6382.996
216650/758000 (epoch 571), train_loss = 0.212, time/batch = 0.031, All_Time = 6384.466
216700/758000 (epoch 571), train_loss = 0.229, time/batch = 0.030, All_Time = 6385.943
216750/758000 (epoch 571), train_loss = 0.272, time/batch = 0.029, All_Time = 6387.414
216800/758000 (epoch 572), train_loss = 0.249, time/batch = 0.029, All_Time = 6388.898
216850/758000 (epoch 572), train_loss = 0.227, time/batch = 0.030, All_Time = 6390.371
216900/758000 (epoch 572), train_loss = 0.267, time/batch = 0.031, All_Time = 6391.838
216950/758000 (epoch 572), train_loss = 0.239, time/batch = 0.031, All_Time = 6393.309
217000/758000 (epoch 572), train_loss = 0.247, time/batch = 0.029, All_Time = 6394.784
model saved to NER/polyglot/model.ckpt
217050/758000 (epoch 572), train_loss = 0.241, time/batch = 0.030, All_Time = 6396.255
217100/758000 (epoch 572), train_loss = 0.274, time/batch = 0.029, All_Time = 6397.760
217150/758000 (epoch 572), train_loss = 0.279, time/batch = 0.031, All_Time = 6399.243
217200/758000 (epoch 573), train_loss = 0.238, time/batch = 0.029, All_Time = 6400.722
217250/758000 (epoch 573), train_loss = 0.248, time/batch = 0.029, All_Time = 6402.193
217300/758000 (epoch 573), train_loss = 0.299, time/batch = 0.029, All_Time = 6403.666
217350/758000 (epoch 573), train_loss = 0.230, time/batch = 0.029, All_Time = 6405.132
217400/758000 (epoch 573), train_loss = 0.216, time/batch = 0.028, All_Time = 6406.600
217450/758000 (epoch 573), train_loss = 0.244, time/batch = 0.033, All_Time = 6408.067
217500/758000 (epoch 573), train_loss = 0.274, time/batch = 0.029, All_Time = 6409.541
217550/758000 (epoch 574), train_loss = 0.221, time/batch = 0.030, All_Time = 6411.023
217600/758000 (epoch 574), train_loss = 0.257, time/batch = 0.030, All_Time = 6412.498
217650/758000 (epoch 574), train_loss = 0.241, time/batch = 0.030, All_Time = 6413.972
217700/758000 (epoch 574), train_loss = 0.240, time/batch = 0.030, All_Time = 6415.478
217750/758000 (epoch 574), train_loss = 0.256, time/batch = 0.030, All_Time = 6416.971
217800/758000 (epoch 574), train_loss = 0.219, time/batch = 0.029, All_Time = 6418.449
217850/758000 (epoch 574), train_loss = 0.224, time/batch = 0.029, All_Time = 6419.928
217900/758000 (epoch 574), train_loss = 0.257, time/batch = 0.029, All_Time = 6421.414
217950/758000 (epoch 575), train_loss = 0.255, time/batch = 0.030, All_Time = 6422.912
218000/758000 (epoch 575), train_loss = 0.267, time/batch = 0.030, All_Time = 6424.380
model saved to NER/polyglot/model.ckpt
218050/758000 (epoch 575), train_loss = 0.269, time/batch = 0.030, All_Time = 6425.846
218100/758000 (epoch 575), train_loss = 0.228, time/batch = 0.029, All_Time = 6427.316
218150/758000 (epoch 575), train_loss = 0.234, time/batch = 0.032, All_Time = 6428.885
218200/758000 (epoch 575), train_loss = 0.245, time/batch = 0.032, All_Time = 6430.422
218250/758000 (epoch 575), train_loss = 0.279, time/batch = 0.030, All_Time = 6431.921
218300/758000 (epoch 575), train_loss = 0.240, time/batch = 0.031, All_Time = 6433.442
218350/758000 (epoch 576), train_loss = 0.236, time/batch = 0.030, All_Time = 6434.938
218400/758000 (epoch 576), train_loss = 0.234, time/batch = 0.030, All_Time = 6436.409
218450/758000 (epoch 576), train_loss = 0.233, time/batch = 0.030, All_Time = 6437.878
218500/758000 (epoch 576), train_loss = 0.276, time/batch = 0.028, All_Time = 6439.351
218550/758000 (epoch 576), train_loss = 0.206, time/batch = 0.030, All_Time = 6440.815
218600/758000 (epoch 576), train_loss = 0.259, time/batch = 0.028, All_Time = 6442.285
218650/758000 (epoch 576), train_loss = 0.234, time/batch = 0.030, All_Time = 6443.760
218700/758000 (epoch 577), train_loss = 0.245, time/batch = 0.030, All_Time = 6445.248
218750/758000 (epoch 577), train_loss = 0.223, time/batch = 0.029, All_Time = 6446.712
218800/758000 (epoch 577), train_loss = 0.240, time/batch = 0.030, All_Time = 6448.194
218850/758000 (epoch 577), train_loss = 0.256, time/batch = 0.030, All_Time = 6449.717
218900/758000 (epoch 577), train_loss = 0.214, time/batch = 0.030, All_Time = 6451.201
218950/758000 (epoch 577), train_loss = 0.272, time/batch = 0.029, All_Time = 6452.667
219000/758000 (epoch 577), train_loss = 0.213, time/batch = 0.031, All_Time = 6454.132
model saved to NER/polyglot/model.ckpt
219050/758000 (epoch 577), train_loss = 0.251, time/batch = 0.030, All_Time = 6455.610
219100/758000 (epoch 578), train_loss = 0.247, time/batch = 0.029, All_Time = 6457.082
219150/758000 (epoch 578), train_loss = 0.229, time/batch = 0.029, All_Time = 6458.552
219200/758000 (epoch 578), train_loss = 0.217, time/batch = 0.030, All_Time = 6460.028
219250/758000 (epoch 578), train_loss = 0.220, time/batch = 0.030, All_Time = 6461.492
219300/758000 (epoch 578), train_loss = 0.250, time/batch = 0.029, All_Time = 6462.989
219350/758000 (epoch 578), train_loss = 0.207, time/batch = 0.031, All_Time = 6464.490
219400/758000 (epoch 578), train_loss = 0.268, time/batch = 0.029, All_Time = 6465.968
219450/758000 (epoch 579), train_loss = 0.256, time/batch = 0.030, All_Time = 6467.456
219500/758000 (epoch 579), train_loss = 0.264, time/batch = 0.030, All_Time = 6468.948
219550/758000 (epoch 579), train_loss = 0.284, time/batch = 0.029, All_Time = 6470.412
219600/758000 (epoch 579), train_loss = 0.239, time/batch = 0.028, All_Time = 6471.878
219650/758000 (epoch 579), train_loss = 0.267, time/batch = 0.031, All_Time = 6473.362
219700/758000 (epoch 579), train_loss = 0.256, time/batch = 0.030, All_Time = 6474.847
219750/758000 (epoch 579), train_loss = 0.236, time/batch = 0.030, All_Time = 6476.318
219800/758000 (epoch 579), train_loss = 0.268, time/batch = 0.031, All_Time = 6477.796
219850/758000 (epoch 580), train_loss = 0.226, time/batch = 0.030, All_Time = 6479.273
219900/758000 (epoch 580), train_loss = 0.222, time/batch = 0.029, All_Time = 6480.766
219950/758000 (epoch 580), train_loss = 0.261, time/batch = 0.030, All_Time = 6482.262
220000/758000 (epoch 580), train_loss = 0.254, time/batch = 0.030, All_Time = 6483.733
model saved to NER/polyglot/model.ckpt
220050/758000 (epoch 580), train_loss = 0.223, time/batch = 0.031, All_Time = 6485.201
220100/758000 (epoch 580), train_loss = 0.242, time/batch = 0.030, All_Time = 6486.668
220150/758000 (epoch 580), train_loss = 0.251, time/batch = 0.031, All_Time = 6488.136
220200/758000 (epoch 581), train_loss = 0.192, time/batch = 0.032, All_Time = 6489.625
220250/758000 (epoch 581), train_loss = 0.273, time/batch = 0.030, All_Time = 6491.112
220300/758000 (epoch 581), train_loss = 0.217, time/batch = 0.029, All_Time = 6492.599
220350/758000 (epoch 581), train_loss = 0.240, time/batch = 0.029, All_Time = 6494.084
220400/758000 (epoch 581), train_loss = 0.221, time/batch = 0.028, All_Time = 6495.568
220450/758000 (epoch 581), train_loss = 0.221, time/batch = 0.029, All_Time = 6497.043
220500/758000 (epoch 581), train_loss = 0.252, time/batch = 0.029, All_Time = 6498.527
220550/758000 (epoch 581), train_loss = 0.272, time/batch = 0.029, All_Time = 6500.006
220600/758000 (epoch 582), train_loss = 0.222, time/batch = 0.029, All_Time = 6501.498
220650/758000 (epoch 582), train_loss = 0.279, time/batch = 0.031, All_Time = 6502.966
220700/758000 (epoch 582), train_loss = 0.242, time/batch = 0.029, All_Time = 6504.432
220750/758000 (epoch 582), train_loss = 0.274, time/batch = 0.029, All_Time = 6505.905
220800/758000 (epoch 582), train_loss = 0.262, time/batch = 0.030, All_Time = 6507.363
220850/758000 (epoch 582), train_loss = 0.197, time/batch = 0.028, All_Time = 6508.858
220900/758000 (epoch 582), train_loss = 0.233, time/batch = 0.031, All_Time = 6510.348
220950/758000 (epoch 582), train_loss = 0.281, time/batch = 0.028, All_Time = 6511.834
221000/758000 (epoch 583), train_loss = 0.246, time/batch = 0.028, All_Time = 6513.326
model saved to NER/polyglot/model.ckpt
221050/758000 (epoch 583), train_loss = 0.212, time/batch = 0.029, All_Time = 6514.789
221100/758000 (epoch 583), train_loss = 0.255, time/batch = 0.029, All_Time = 6516.262
221150/758000 (epoch 583), train_loss = 0.271, time/batch = 0.030, All_Time = 6517.732
221200/758000 (epoch 583), train_loss = 0.203, time/batch = 0.029, All_Time = 6519.196
221250/758000 (epoch 583), train_loss = 0.226, time/batch = 0.031, All_Time = 6520.670
221300/758000 (epoch 583), train_loss = 0.254, time/batch = 0.031, All_Time = 6522.148
221350/758000 (epoch 584), train_loss = 0.219, time/batch = 0.029, All_Time = 6523.622
221400/758000 (epoch 584), train_loss = 0.265, time/batch = 0.030, All_Time = 6525.097
221450/758000 (epoch 584), train_loss = 0.227, time/batch = 0.029, All_Time = 6526.566
221500/758000 (epoch 584), train_loss = 0.213, time/batch = 0.030, All_Time = 6528.040
221550/758000 (epoch 584), train_loss = 0.224, time/batch = 0.031, All_Time = 6529.518
221600/758000 (epoch 584), train_loss = 0.213, time/batch = 0.030, All_Time = 6531.007
221650/758000 (epoch 584), train_loss = 0.230, time/batch = 0.030, All_Time = 6532.505
221700/758000 (epoch 584), train_loss = 0.223, time/batch = 0.031, All_Time = 6534.021
221750/758000 (epoch 585), train_loss = 0.275, time/batch = 0.028, All_Time = 6535.513
221800/758000 (epoch 585), train_loss = 0.229, time/batch = 0.030, All_Time = 6536.989
221850/758000 (epoch 585), train_loss = 0.270, time/batch = 0.029, All_Time = 6538.462
221900/758000 (epoch 585), train_loss = 0.273, time/batch = 0.030, All_Time = 6539.944
221950/758000 (epoch 585), train_loss = 0.233, time/batch = 0.029, All_Time = 6541.417
222000/758000 (epoch 585), train_loss = 0.268, time/batch = 0.032, All_Time = 6542.895
model saved to NER/polyglot/model.ckpt
222050/758000 (epoch 585), train_loss = 0.280, time/batch = 0.029, All_Time = 6544.366
222100/758000 (epoch 586), train_loss = 0.239, time/batch = 0.031, All_Time = 6545.841
222150/758000 (epoch 586), train_loss = 0.218, time/batch = 0.029, All_Time = 6547.309
222200/758000 (epoch 586), train_loss = 0.243, time/batch = 0.030, All_Time = 6548.806
222250/758000 (epoch 586), train_loss = 0.244, time/batch = 0.031, All_Time = 6550.297
222300/758000 (epoch 586), train_loss = 0.243, time/batch = 0.031, All_Time = 6551.772
222350/758000 (epoch 586), train_loss = 0.244, time/batch = 0.029, All_Time = 6553.250
222400/758000 (epoch 586), train_loss = 0.213, time/batch = 0.029, All_Time = 6554.727
222450/758000 (epoch 586), train_loss = 0.289, time/batch = 0.028, All_Time = 6556.189
222500/758000 (epoch 587), train_loss = 0.237, time/batch = 0.029, All_Time = 6557.724
222550/758000 (epoch 587), train_loss = 0.246, time/batch = 0.028, All_Time = 6559.199
222600/758000 (epoch 587), train_loss = 0.288, time/batch = 0.029, All_Time = 6560.650
222650/758000 (epoch 587), train_loss = 0.257, time/batch = 0.029, All_Time = 6562.129
222700/758000 (epoch 587), train_loss = 0.218, time/batch = 0.031, All_Time = 6563.596
222750/758000 (epoch 587), train_loss = 0.238, time/batch = 0.029, All_Time = 6565.067
222800/758000 (epoch 587), train_loss = 0.251, time/batch = 0.028, All_Time = 6566.538
222850/758000 (epoch 587), train_loss = 0.251, time/batch = 0.029, All_Time = 6568.020
222900/758000 (epoch 588), train_loss = 0.252, time/batch = 0.030, All_Time = 6569.493
222950/758000 (epoch 588), train_loss = 0.280, time/batch = 0.031, All_Time = 6570.995
223000/758000 (epoch 588), train_loss = 0.242, time/batch = 0.029, All_Time = 6572.501
model saved to NER/polyglot/model.ckpt
223050/758000 (epoch 588), train_loss = 0.250, time/batch = 0.029, All_Time = 6573.972
223100/758000 (epoch 588), train_loss = 0.239, time/batch = 0.029, All_Time = 6575.447
223150/758000 (epoch 588), train_loss = 0.239, time/batch = 0.029, All_Time = 6576.912
223200/758000 (epoch 588), train_loss = 0.250, time/batch = 0.030, All_Time = 6578.389
223250/758000 (epoch 589), train_loss = 0.221, time/batch = 0.030, All_Time = 6579.870
223300/758000 (epoch 589), train_loss = 0.219, time/batch = 0.029, All_Time = 6581.328
223350/758000 (epoch 589), train_loss = 0.246, time/batch = 0.029, All_Time = 6582.800
223400/758000 (epoch 589), train_loss = 0.262, time/batch = 0.029, All_Time = 6584.277
223450/758000 (epoch 589), train_loss = 0.260, time/batch = 0.030, All_Time = 6585.756
223500/758000 (epoch 589), train_loss = 0.241, time/batch = 0.029, All_Time = 6587.240
223550/758000 (epoch 589), train_loss = 0.210, time/batch = 0.030, All_Time = 6588.729
223600/758000 (epoch 589), train_loss = 0.239, time/batch = 0.029, All_Time = 6590.210
223650/758000 (epoch 590), train_loss = 0.230, time/batch = 0.030, All_Time = 6591.692
223700/758000 (epoch 590), train_loss = 0.226, time/batch = 0.029, All_Time = 6593.175
223750/758000 (epoch 590), train_loss = 0.264, time/batch = 0.030, All_Time = 6594.650
223800/758000 (epoch 590), train_loss = 0.240, time/batch = 0.028, All_Time = 6596.129
223850/758000 (epoch 590), train_loss = 0.253, time/batch = 0.030, All_Time = 6597.619
223900/758000 (epoch 590), train_loss = 0.251, time/batch = 0.031, All_Time = 6599.098
223950/758000 (epoch 590), train_loss = 0.248, time/batch = 0.029, All_Time = 6600.577
224000/758000 (epoch 591), train_loss = 0.216, time/batch = 0.029, All_Time = 6602.075
model saved to NER/polyglot/model.ckpt
224050/758000 (epoch 591), train_loss = 0.233, time/batch = 0.030, All_Time = 6603.534
224100/758000 (epoch 591), train_loss = 0.250, time/batch = 0.028, All_Time = 6605.010
224150/758000 (epoch 591), train_loss = 0.241, time/batch = 0.031, All_Time = 6606.523
224200/758000 (epoch 591), train_loss = 0.243, time/batch = 0.029, All_Time = 6608.013
224250/758000 (epoch 591), train_loss = 0.242, time/batch = 0.031, All_Time = 6609.498
224300/758000 (epoch 591), train_loss = 0.230, time/batch = 0.030, All_Time = 6610.989
224350/758000 (epoch 591), train_loss = 0.259, time/batch = 0.029, All_Time = 6612.469
224400/758000 (epoch 592), train_loss = 0.250, time/batch = 0.029, All_Time = 6613.961
224450/758000 (epoch 592), train_loss = 0.253, time/batch = 0.029, All_Time = 6615.430
224500/758000 (epoch 592), train_loss = 0.245, time/batch = 0.028, All_Time = 6616.897
224550/758000 (epoch 592), train_loss = 0.231, time/batch = 0.030, All_Time = 6618.363
224600/758000 (epoch 592), train_loss = 0.228, time/batch = 0.029, All_Time = 6619.840
224650/758000 (epoch 592), train_loss = 0.238, time/batch = 0.030, All_Time = 6621.327
224700/758000 (epoch 592), train_loss = 0.268, time/batch = 0.030, All_Time = 6622.815
224750/758000 (epoch 593), train_loss = 0.248, time/batch = 0.030, All_Time = 6624.291
224800/758000 (epoch 593), train_loss = 0.280, time/batch = 0.033, All_Time = 6625.770
224850/758000 (epoch 593), train_loss = 0.242, time/batch = 0.029, All_Time = 6627.257
224900/758000 (epoch 593), train_loss = 0.258, time/batch = 0.030, All_Time = 6628.736
224950/758000 (epoch 593), train_loss = 0.224, time/batch = 0.031, All_Time = 6630.209
225000/758000 (epoch 593), train_loss = 0.243, time/batch = 0.031, All_Time = 6631.693
model saved to NER/polyglot/model.ckpt
225050/758000 (epoch 593), train_loss = 0.219, time/batch = 0.029, All_Time = 6633.157
225100/758000 (epoch 593), train_loss = 0.232, time/batch = 0.030, All_Time = 6634.630
225150/758000 (epoch 594), train_loss = 0.237, time/batch = 0.029, All_Time = 6636.095
225200/758000 (epoch 594), train_loss = 0.239, time/batch = 0.032, All_Time = 6637.566
225250/758000 (epoch 594), train_loss = 0.293, time/batch = 0.030, All_Time = 6639.069
225300/758000 (epoch 594), train_loss = 0.318, time/batch = 0.031, All_Time = 6640.541
225350/758000 (epoch 594), train_loss = 0.196, time/batch = 0.030, All_Time = 6642.018
225400/758000 (epoch 594), train_loss = 0.213, time/batch = 0.030, All_Time = 6643.501
225450/758000 (epoch 594), train_loss = 0.250, time/batch = 0.030, All_Time = 6644.978
225500/758000 (epoch 594), train_loss = 0.297, time/batch = 0.030, All_Time = 6646.448
225550/758000 (epoch 595), train_loss = 0.226, time/batch = 0.029, All_Time = 6647.935
225600/758000 (epoch 595), train_loss = 0.259, time/batch = 0.029, All_Time = 6649.396
225650/758000 (epoch 595), train_loss = 0.223, time/batch = 0.032, All_Time = 6650.862
225700/758000 (epoch 595), train_loss = 0.239, time/batch = 0.029, All_Time = 6652.339
225750/758000 (epoch 595), train_loss = 0.212, time/batch = 0.029, All_Time = 6653.810
225800/758000 (epoch 595), train_loss = 0.243, time/batch = 0.029, All_Time = 6655.280
225850/758000 (epoch 595), train_loss = 0.215, time/batch = 0.031, All_Time = 6656.754
225900/758000 (epoch 596), train_loss = 0.228, time/batch = 0.030, All_Time = 6658.265
225950/758000 (epoch 596), train_loss = 0.252, time/batch = 0.028, All_Time = 6659.742
226000/758000 (epoch 596), train_loss = 0.260, time/batch = 0.030, All_Time = 6661.218
model saved to NER/polyglot/model.ckpt
226050/758000 (epoch 596), train_loss = 0.228, time/batch = 0.029, All_Time = 6662.697
226100/758000 (epoch 596), train_loss = 0.236, time/batch = 0.029, All_Time = 6664.154
226150/758000 (epoch 596), train_loss = 0.271, time/batch = 0.031, All_Time = 6665.647
226200/758000 (epoch 596), train_loss = 0.238, time/batch = 0.030, All_Time = 6667.125
226250/758000 (epoch 596), train_loss = 0.268, time/batch = 0.031, All_Time = 6668.605
226300/758000 (epoch 597), train_loss = 0.248, time/batch = 0.030, All_Time = 6670.087
226350/758000 (epoch 597), train_loss = 0.249, time/batch = 0.029, All_Time = 6671.560
226400/758000 (epoch 597), train_loss = 0.240, time/batch = 0.028, All_Time = 6673.043
226450/758000 (epoch 597), train_loss = 0.247, time/batch = 0.030, All_Time = 6674.533
226500/758000 (epoch 597), train_loss = 0.235, time/batch = 0.029, All_Time = 6676.028
226550/758000 (epoch 597), train_loss = 0.247, time/batch = 0.029, All_Time = 6677.515
226600/758000 (epoch 597), train_loss = 0.251, time/batch = 0.029, All_Time = 6678.981
226650/758000 (epoch 598), train_loss = 0.242, time/batch = 0.030, All_Time = 6680.462
226700/758000 (epoch 598), train_loss = 0.276, time/batch = 0.030, All_Time = 6681.924
226750/758000 (epoch 598), train_loss = 0.256, time/batch = 0.029, All_Time = 6683.402
226800/758000 (epoch 598), train_loss = 0.258, time/batch = 0.031, All_Time = 6684.871
226850/758000 (epoch 598), train_loss = 0.213, time/batch = 0.029, All_Time = 6686.346
226900/758000 (epoch 598), train_loss = 0.237, time/batch = 0.030, All_Time = 6687.814
226950/758000 (epoch 598), train_loss = 0.249, time/batch = 0.030, All_Time = 6689.299
227000/758000 (epoch 598), train_loss = 0.251, time/batch = 0.029, All_Time = 6690.774
model saved to NER/polyglot/model.ckpt
227050/758000 (epoch 599), train_loss = 0.232, time/batch = 0.030, All_Time = 6692.255
227100/758000 (epoch 599), train_loss = 0.255, time/batch = 0.028, All_Time = 6693.716
227150/758000 (epoch 599), train_loss = 0.265, time/batch = 0.033, All_Time = 6695.193
227200/758000 (epoch 599), train_loss = 0.229, time/batch = 0.029, All_Time = 6696.694
227250/758000 (epoch 599), train_loss = 0.263, time/batch = 0.029, All_Time = 6698.172
227300/758000 (epoch 599), train_loss = 0.217, time/batch = 0.029, All_Time = 6699.665
227350/758000 (epoch 599), train_loss = 0.248, time/batch = 0.028, All_Time = 6701.152
227400/758000 (epoch 600), train_loss = 0.059, time/batch = 0.036, All_Time = 6702.643
227450/758000 (epoch 600), train_loss = 0.250, time/batch = 0.030, All_Time = 6704.126
227500/758000 (epoch 600), train_loss = 0.223, time/batch = 0.031, All_Time = 6705.609
227550/758000 (epoch 600), train_loss = 0.250, time/batch = 0.029, All_Time = 6707.088
227600/758000 (epoch 600), train_loss = 0.231, time/batch = 0.031, All_Time = 6708.571
227650/758000 (epoch 600), train_loss = 0.250, time/batch = 0.029, All_Time = 6710.039
227700/758000 (epoch 600), train_loss = 0.232, time/batch = 0.028, All_Time = 6711.520
227750/758000 (epoch 600), train_loss = 0.230, time/batch = 0.029, All_Time = 6713.007
227800/758000 (epoch 601), train_loss = 0.224, time/batch = 0.030, All_Time = 6714.508
227850/758000 (epoch 601), train_loss = 0.233, time/batch = 0.029, All_Time = 6715.990
227900/758000 (epoch 601), train_loss = 0.224, time/batch = 0.030, All_Time = 6717.465
227950/758000 (epoch 601), train_loss = 0.262, time/batch = 0.030, All_Time = 6718.930
228000/758000 (epoch 601), train_loss = 0.220, time/batch = 0.030, All_Time = 6720.408
model saved to NER/polyglot/model.ckpt
228050/758000 (epoch 601), train_loss = 0.228, time/batch = 0.030, All_Time = 6721.875
228100/758000 (epoch 601), train_loss = 0.280, time/batch = 0.030, All_Time = 6723.335
228150/758000 (epoch 601), train_loss = 0.272, time/batch = 0.031, All_Time = 6724.803
228200/758000 (epoch 602), train_loss = 0.230, time/batch = 0.029, All_Time = 6726.279
228250/758000 (epoch 602), train_loss = 0.224, time/batch = 0.030, All_Time = 6727.769
228300/758000 (epoch 602), train_loss = 0.201, time/batch = 0.030, All_Time = 6729.257
228350/758000 (epoch 602), train_loss = 0.270, time/batch = 0.029, All_Time = 6730.752
228400/758000 (epoch 602), train_loss = 0.259, time/batch = 0.030, All_Time = 6732.240
228450/758000 (epoch 602), train_loss = 0.209, time/batch = 0.029, All_Time = 6733.728
228500/758000 (epoch 602), train_loss = 0.218, time/batch = 0.029, All_Time = 6735.216
228550/758000 (epoch 603), train_loss = 0.229, time/batch = 0.031, All_Time = 6736.705
228600/758000 (epoch 603), train_loss = 0.283, time/batch = 0.029, All_Time = 6738.175
228650/758000 (epoch 603), train_loss = 0.231, time/batch = 0.031, All_Time = 6739.650
228700/758000 (epoch 603), train_loss = 0.307, time/batch = 0.030, All_Time = 6741.122
228750/758000 (epoch 603), train_loss = 0.221, time/batch = 0.029, All_Time = 6742.587
228800/758000 (epoch 603), train_loss = 0.208, time/batch = 0.031, All_Time = 6744.058
228850/758000 (epoch 603), train_loss = 0.247, time/batch = 0.031, All_Time = 6745.521
228900/758000 (epoch 603), train_loss = 0.252, time/batch = 0.030, All_Time = 6747.010
228950/758000 (epoch 604), train_loss = 0.264, time/batch = 0.029, All_Time = 6748.493
229000/758000 (epoch 604), train_loss = 0.229, time/batch = 0.029, All_Time = 6749.958
model saved to NER/polyglot/model.ckpt
229050/758000 (epoch 604), train_loss = 0.242, time/batch = 0.030, All_Time = 6751.435
229100/758000 (epoch 604), train_loss = 0.267, time/batch = 0.029, All_Time = 6752.900
229150/758000 (epoch 604), train_loss = 0.249, time/batch = 0.032, All_Time = 6754.374
229200/758000 (epoch 604), train_loss = 0.237, time/batch = 0.029, All_Time = 6755.881
229250/758000 (epoch 604), train_loss = 0.276, time/batch = 0.029, All_Time = 6757.354
229300/758000 (epoch 605), train_loss = 0.256, time/batch = 0.029, All_Time = 6758.838
229350/758000 (epoch 605), train_loss = 0.222, time/batch = 0.032, All_Time = 6760.315
229400/758000 (epoch 605), train_loss = 0.266, time/batch = 0.030, All_Time = 6761.788
229450/758000 (epoch 605), train_loss = 0.216, time/batch = 0.028, All_Time = 6763.257
229500/758000 (epoch 605), train_loss = 0.223, time/batch = 0.029, All_Time = 6764.738
229550/758000 (epoch 605), train_loss = 0.261, time/batch = 0.029, All_Time = 6766.211
229600/758000 (epoch 605), train_loss = 0.238, time/batch = 0.029, All_Time = 6767.692
229650/758000 (epoch 605), train_loss = 0.264, time/batch = 0.029, All_Time = 6769.162
229700/758000 (epoch 606), train_loss = 0.223, time/batch = 0.029, All_Time = 6770.649
229750/758000 (epoch 606), train_loss = 0.231, time/batch = 0.031, All_Time = 6772.133
229800/758000 (epoch 606), train_loss = 0.238, time/batch = 0.029, All_Time = 6773.600
229850/758000 (epoch 606), train_loss = 0.266, time/batch = 0.030, All_Time = 6775.064
229900/758000 (epoch 606), train_loss = 0.239, time/batch = 0.030, All_Time = 6776.546
229950/758000 (epoch 606), train_loss = 0.226, time/batch = 0.029, All_Time = 6778.022
230000/758000 (epoch 606), train_loss = 0.276, time/batch = 0.030, All_Time = 6779.491
model saved to NER/polyglot/model.ckpt
230050/758000 (epoch 606), train_loss = 0.240, time/batch = 0.030, All_Time = 6780.968
230100/758000 (epoch 607), train_loss = 0.281, time/batch = 0.030, All_Time = 6782.454
230150/758000 (epoch 607), train_loss = 0.257, time/batch = 0.032, All_Time = 6783.915
230200/758000 (epoch 607), train_loss = 0.240, time/batch = 0.030, All_Time = 6785.414
230250/758000 (epoch 607), train_loss = 0.231, time/batch = 0.029, All_Time = 6786.911
230300/758000 (epoch 607), train_loss = 0.217, time/batch = 0.031, All_Time = 6788.389
230350/758000 (epoch 607), train_loss = 0.224, time/batch = 0.028, All_Time = 6789.875
230400/758000 (epoch 607), train_loss = 0.215, time/batch = 0.029, All_Time = 6791.337
230450/758000 (epoch 608), train_loss = 0.249, time/batch = 0.029, All_Time = 6792.819
230500/758000 (epoch 608), train_loss = 0.211, time/batch = 0.029, All_Time = 6794.303
230550/758000 (epoch 608), train_loss = 0.245, time/batch = 0.029, All_Time = 6795.783
230600/758000 (epoch 608), train_loss = 0.217, time/batch = 0.030, All_Time = 6797.264
230650/758000 (epoch 608), train_loss = 0.233, time/batch = 0.029, All_Time = 6798.752
230700/758000 (epoch 608), train_loss = 0.228, time/batch = 0.029, All_Time = 6800.227
230750/758000 (epoch 608), train_loss = 0.248, time/batch = 0.031, All_Time = 6801.709
230800/758000 (epoch 608), train_loss = 0.229, time/batch = 0.028, All_Time = 6803.180
230850/758000 (epoch 609), train_loss = 0.218, time/batch = 0.029, All_Time = 6804.660
230900/758000 (epoch 609), train_loss = 0.237, time/batch = 0.029, All_Time = 6806.131
230950/758000 (epoch 609), train_loss = 0.212, time/batch = 0.031, All_Time = 6807.633
231000/758000 (epoch 609), train_loss = 0.266, time/batch = 0.029, All_Time = 6809.118
model saved to NER/polyglot/model.ckpt
231050/758000 (epoch 609), train_loss = 0.255, time/batch = 0.030, All_Time = 6810.593
231100/758000 (epoch 609), train_loss = 0.232, time/batch = 0.030, All_Time = 6812.063
231150/758000 (epoch 609), train_loss = 0.262, time/batch = 0.029, All_Time = 6813.538
231200/758000 (epoch 610), train_loss = 0.282, time/batch = 0.029, All_Time = 6815.019
231250/758000 (epoch 610), train_loss = 0.292, time/batch = 0.030, All_Time = 6816.481
231300/758000 (epoch 610), train_loss = 0.253, time/batch = 0.031, All_Time = 6817.990
231350/758000 (epoch 610), train_loss = 0.222, time/batch = 0.031, All_Time = 6819.484
231400/758000 (epoch 610), train_loss = 0.221, time/batch = 0.030, All_Time = 6820.978
231450/758000 (epoch 610), train_loss = 0.260, time/batch = 0.029, All_Time = 6822.465
231500/758000 (epoch 610), train_loss = 0.244, time/batch = 0.029, All_Time = 6823.952
231550/758000 (epoch 610), train_loss = 0.247, time/batch = 0.029, All_Time = 6825.442
231600/758000 (epoch 611), train_loss = 0.210, time/batch = 0.029, All_Time = 6826.923
231650/758000 (epoch 611), train_loss = 0.265, time/batch = 0.028, All_Time = 6828.390
231700/758000 (epoch 611), train_loss = 0.229, time/batch = 0.029, All_Time = 6829.858
231750/758000 (epoch 611), train_loss = 0.232, time/batch = 0.030, All_Time = 6831.324
231800/758000 (epoch 611), train_loss = 0.230, time/batch = 0.029, All_Time = 6832.796
231850/758000 (epoch 611), train_loss = 0.253, time/batch = 0.030, All_Time = 6834.284
231900/758000 (epoch 611), train_loss = 0.258, time/batch = 0.032, All_Time = 6835.770
231950/758000 (epoch 612), train_loss = 0.196, time/batch = 0.032, All_Time = 6837.253
232000/758000 (epoch 612), train_loss = 0.254, time/batch = 0.029, All_Time = 6838.727
model saved to NER/polyglot/model.ckpt
232050/758000 (epoch 612), train_loss = 0.281, time/batch = 0.030, All_Time = 6840.200
232100/758000 (epoch 612), train_loss = 0.235, time/batch = 0.030, All_Time = 6841.668
232150/758000 (epoch 612), train_loss = 0.247, time/batch = 0.030, All_Time = 6843.128
232200/758000 (epoch 612), train_loss = 0.251, time/batch = 0.030, All_Time = 6844.634
232250/758000 (epoch 612), train_loss = 0.203, time/batch = 0.029, All_Time = 6846.137
232300/758000 (epoch 612), train_loss = 0.268, time/batch = 0.029, All_Time = 6847.615
232350/758000 (epoch 613), train_loss = 0.233, time/batch = 0.030, All_Time = 6849.091
232400/758000 (epoch 613), train_loss = 0.241, time/batch = 0.029, All_Time = 6850.558
232450/758000 (epoch 613), train_loss = 0.252, time/batch = 0.029, All_Time = 6852.026
232500/758000 (epoch 613), train_loss = 0.258, time/batch = 0.030, All_Time = 6853.493
232550/758000 (epoch 613), train_loss = 0.243, time/batch = 0.029, All_Time = 6854.972
232600/758000 (epoch 613), train_loss = 0.243, time/batch = 0.029, All_Time = 6856.436
232650/758000 (epoch 613), train_loss = 0.244, time/batch = 0.030, All_Time = 6857.898
232700/758000 (epoch 613), train_loss = 0.286, time/batch = 0.032, All_Time = 6859.373
232750/758000 (epoch 614), train_loss = 0.207, time/batch = 0.030, All_Time = 6860.884
232800/758000 (epoch 614), train_loss = 0.244, time/batch = 0.029, All_Time = 6862.373
232850/758000 (epoch 614), train_loss = 0.217, time/batch = 0.030, All_Time = 6863.855
232900/758000 (epoch 614), train_loss = 0.233, time/batch = 0.030, All_Time = 6865.335
232950/758000 (epoch 614), train_loss = 0.260, time/batch = 0.032, All_Time = 6866.824
233000/758000 (epoch 614), train_loss = 0.253, time/batch = 0.030, All_Time = 6868.304
model saved to NER/polyglot/model.ckpt
233050/758000 (epoch 614), train_loss = 0.238, time/batch = 0.029, All_Time = 6869.777
233100/758000 (epoch 615), train_loss = 0.227, time/batch = 0.029, All_Time = 6871.246
233150/758000 (epoch 615), train_loss = 0.250, time/batch = 0.028, All_Time = 6872.697
233200/758000 (epoch 615), train_loss = 0.250, time/batch = 0.029, All_Time = 6874.155
233250/758000 (epoch 615), train_loss = 0.223, time/batch = 0.028, All_Time = 6875.625
233300/758000 (epoch 615), train_loss = 0.240, time/batch = 0.031, All_Time = 6877.125
233350/758000 (epoch 615), train_loss = 0.246, time/batch = 0.028, All_Time = 6878.610
233400/758000 (epoch 615), train_loss = 0.246, time/batch = 0.030, All_Time = 6880.096
233450/758000 (epoch 615), train_loss = 0.257, time/batch = 0.030, All_Time = 6881.577
233500/758000 (epoch 616), train_loss = 0.266, time/batch = 0.030, All_Time = 6883.060
233550/758000 (epoch 616), train_loss = 0.224, time/batch = 0.028, All_Time = 6884.521
233600/758000 (epoch 616), train_loss = 0.248, time/batch = 0.028, All_Time = 6885.988
233650/758000 (epoch 616), train_loss = 0.227, time/batch = 0.028, All_Time = 6887.452
233700/758000 (epoch 616), train_loss = 0.279, time/batch = 0.029, All_Time = 6888.919
233750/758000 (epoch 616), train_loss = 0.255, time/batch = 0.029, All_Time = 6890.397
233800/758000 (epoch 616), train_loss = 0.253, time/batch = 0.031, All_Time = 6891.873
233850/758000 (epoch 617), train_loss = 0.244, time/batch = 0.029, All_Time = 6893.362
233900/758000 (epoch 617), train_loss = 0.247, time/batch = 0.029, All_Time = 6894.834
233950/758000 (epoch 617), train_loss = 0.270, time/batch = 0.030, All_Time = 6896.303
234000/758000 (epoch 617), train_loss = 0.246, time/batch = 0.029, All_Time = 6897.767
model saved to NER/polyglot/model.ckpt
234050/758000 (epoch 617), train_loss = 0.237, time/batch = 0.029, All_Time = 6899.233
234100/758000 (epoch 617), train_loss = 0.224, time/batch = 0.030, All_Time = 6900.702
234150/758000 (epoch 617), train_loss = 0.229, time/batch = 0.029, All_Time = 6902.165
234200/758000 (epoch 617), train_loss = 0.246, time/batch = 0.030, All_Time = 6903.642
234250/758000 (epoch 618), train_loss = 0.249, time/batch = 0.030, All_Time = 6905.144
234300/758000 (epoch 618), train_loss = 0.264, time/batch = 0.030, All_Time = 6906.643
234350/758000 (epoch 618), train_loss = 0.240, time/batch = 0.030, All_Time = 6908.132
234400/758000 (epoch 618), train_loss = 0.250, time/batch = 0.030, All_Time = 6909.623
234450/758000 (epoch 618), train_loss = 0.227, time/batch = 0.029, All_Time = 6911.103
234500/758000 (epoch 618), train_loss = 0.217, time/batch = 0.029, All_Time = 6912.584
234550/758000 (epoch 618), train_loss = 0.277, time/batch = 0.030, All_Time = 6914.065
234600/758000 (epoch 618), train_loss = 0.259, time/batch = 0.029, All_Time = 6915.543
234650/758000 (epoch 619), train_loss = 0.269, time/batch = 0.028, All_Time = 6917.029
234700/758000 (epoch 619), train_loss = 0.296, time/batch = 0.029, All_Time = 6918.495
234750/758000 (epoch 619), train_loss = 0.228, time/batch = 0.029, All_Time = 6919.970
234800/758000 (epoch 619), train_loss = 0.220, time/batch = 0.030, All_Time = 6921.443
234850/758000 (epoch 619), train_loss = 0.257, time/batch = 0.030, All_Time = 6922.918
234900/758000 (epoch 619), train_loss = 0.255, time/batch = 0.030, All_Time = 6924.392
234950/758000 (epoch 619), train_loss = 0.237, time/batch = 0.031, All_Time = 6925.874
235000/758000 (epoch 620), train_loss = 0.225, time/batch = 0.028, All_Time = 6927.352
model saved to NER/polyglot/model.ckpt
235050/758000 (epoch 620), train_loss = 0.234, time/batch = 0.030, All_Time = 6928.824
235100/758000 (epoch 620), train_loss = 0.243, time/batch = 0.029, All_Time = 6930.292
235150/758000 (epoch 620), train_loss = 0.234, time/batch = 0.030, All_Time = 6931.787
235200/758000 (epoch 620), train_loss = 0.223, time/batch = 0.031, All_Time = 6933.283
235250/758000 (epoch 620), train_loss = 0.239, time/batch = 0.030, All_Time = 6934.768
235300/758000 (epoch 620), train_loss = 0.264, time/batch = 0.029, All_Time = 6936.250
235350/758000 (epoch 620), train_loss = 0.244, time/batch = 0.031, All_Time = 6937.744
235400/758000 (epoch 621), train_loss = 0.257, time/batch = 0.030, All_Time = 6939.233
235450/758000 (epoch 621), train_loss = 0.287, time/batch = 0.030, All_Time = 6940.708
235500/758000 (epoch 621), train_loss = 0.255, time/batch = 0.028, All_Time = 6942.172
235550/758000 (epoch 621), train_loss = 0.248, time/batch = 0.029, All_Time = 6943.642
235600/758000 (epoch 621), train_loss = 0.212, time/batch = 0.029, All_Time = 6945.115
235650/758000 (epoch 621), train_loss = 0.229, time/batch = 0.030, All_Time = 6946.585
235700/758000 (epoch 621), train_loss = 0.272, time/batch = 0.030, All_Time = 6948.078
235750/758000 (epoch 622), train_loss = 0.249, time/batch = 0.031, All_Time = 6949.593
235800/758000 (epoch 622), train_loss = 0.227, time/batch = 0.029, All_Time = 6951.066
235850/758000 (epoch 622), train_loss = 0.267, time/batch = 0.029, All_Time = 6952.538
235900/758000 (epoch 622), train_loss = 0.239, time/batch = 0.029, All_Time = 6954.020
235950/758000 (epoch 622), train_loss = 0.247, time/batch = 0.029, All_Time = 6955.490
236000/758000 (epoch 622), train_loss = 0.241, time/batch = 0.031, All_Time = 6956.995
model saved to NER/polyglot/model.ckpt
236050/758000 (epoch 622), train_loss = 0.274, time/batch = 0.029, All_Time = 6958.485
236100/758000 (epoch 622), train_loss = 0.279, time/batch = 0.030, All_Time = 6959.953
236150/758000 (epoch 623), train_loss = 0.238, time/batch = 0.029, All_Time = 6961.421
236200/758000 (epoch 623), train_loss = 0.248, time/batch = 0.030, All_Time = 6962.883
236250/758000 (epoch 623), train_loss = 0.299, time/batch = 0.030, All_Time = 6964.347
236300/758000 (epoch 623), train_loss = 0.230, time/batch = 0.030, All_Time = 6965.809
236350/758000 (epoch 623), train_loss = 0.216, time/batch = 0.030, All_Time = 6967.278
236400/758000 (epoch 623), train_loss = 0.244, time/batch = 0.030, All_Time = 6968.796
236450/758000 (epoch 623), train_loss = 0.274, time/batch = 0.030, All_Time = 6970.280
236500/758000 (epoch 624), train_loss = 0.221, time/batch = 0.029, All_Time = 6971.766
236550/758000 (epoch 624), train_loss = 0.257, time/batch = 0.030, All_Time = 6973.238
236600/758000 (epoch 624), train_loss = 0.241, time/batch = 0.029, All_Time = 6974.699
236650/758000 (epoch 624), train_loss = 0.240, time/batch = 0.030, All_Time = 6976.170
236700/758000 (epoch 624), train_loss = 0.256, time/batch = 0.030, All_Time = 6977.648
236750/758000 (epoch 624), train_loss = 0.219, time/batch = 0.031, All_Time = 6979.115
236800/758000 (epoch 624), train_loss = 0.224, time/batch = 0.030, All_Time = 6980.603
236850/758000 (epoch 624), train_loss = 0.257, time/batch = 0.029, All_Time = 6982.118
236900/758000 (epoch 625), train_loss = 0.255, time/batch = 0.029, All_Time = 6983.606
236950/758000 (epoch 625), train_loss = 0.267, time/batch = 0.029, All_Time = 6985.076
237000/758000 (epoch 625), train_loss = 0.269, time/batch = 0.030, All_Time = 6986.544
model saved to NER/polyglot/model.ckpt
237050/758000 (epoch 625), train_loss = 0.228, time/batch = 0.029, All_Time = 6988.010
237100/758000 (epoch 625), train_loss = 0.234, time/batch = 0.030, All_Time = 6989.472
237150/758000 (epoch 625), train_loss = 0.245, time/batch = 0.031, All_Time = 6990.958
237200/758000 (epoch 625), train_loss = 0.279, time/batch = 0.029, All_Time = 6992.460
237250/758000 (epoch 625), train_loss = 0.240, time/batch = 0.028, All_Time = 6993.938
237300/758000 (epoch 626), train_loss = 0.236, time/batch = 0.028, All_Time = 6995.416
237350/758000 (epoch 626), train_loss = 0.234, time/batch = 0.030, All_Time = 6996.892
237400/758000 (epoch 626), train_loss = 0.233, time/batch = 0.029, All_Time = 6998.361
237450/758000 (epoch 626), train_loss = 0.276, time/batch = 0.029, All_Time = 6999.828
237500/758000 (epoch 626), train_loss = 0.206, time/batch = 0.029, All_Time = 7001.292
237550/758000 (epoch 626), train_loss = 0.259, time/batch = 0.029, All_Time = 7002.754
237600/758000 (epoch 626), train_loss = 0.234, time/batch = 0.030, All_Time = 7004.250
237650/758000 (epoch 627), train_loss = 0.245, time/batch = 0.031, All_Time = 7005.752
237700/758000 (epoch 627), train_loss = 0.223, time/batch = 0.030, All_Time = 7007.226
237750/758000 (epoch 627), train_loss = 0.240, time/batch = 0.028, All_Time = 7008.708
237800/758000 (epoch 627), train_loss = 0.256, time/batch = 0.029, All_Time = 7010.182
237850/758000 (epoch 627), train_loss = 0.214, time/batch = 0.030, All_Time = 7011.658
237900/758000 (epoch 627), train_loss = 0.272, time/batch = 0.029, All_Time = 7013.126
237950/758000 (epoch 627), train_loss = 0.213, time/batch = 0.029, All_Time = 7014.604
238000/758000 (epoch 627), train_loss = 0.251, time/batch = 0.029, All_Time = 7016.064
model saved to NER/polyglot/model.ckpt
238050/758000 (epoch 628), train_loss = 0.247, time/batch = 0.029, All_Time = 7017.533
238100/758000 (epoch 628), train_loss = 0.229, time/batch = 0.029, All_Time = 7018.992
238150/758000 (epoch 628), train_loss = 0.217, time/batch = 0.027, All_Time = 7020.458
238200/758000 (epoch 628), train_loss = 0.220, time/batch = 0.029, All_Time = 7021.930
238250/758000 (epoch 628), train_loss = 0.250, time/batch = 0.031, All_Time = 7023.437
238300/758000 (epoch 628), train_loss = 0.207, time/batch = 0.031, All_Time = 7024.909
238350/758000 (epoch 628), train_loss = 0.268, time/batch = 0.030, All_Time = 7026.385
238400/758000 (epoch 629), train_loss = 0.256, time/batch = 0.031, All_Time = 7027.862
238450/758000 (epoch 629), train_loss = 0.264, time/batch = 0.029, All_Time = 7029.338
238500/758000 (epoch 629), train_loss = 0.284, time/batch = 0.030, All_Time = 7030.813
238550/758000 (epoch 629), train_loss = 0.239, time/batch = 0.031, All_Time = 7032.285
238600/758000 (epoch 629), train_loss = 0.267, time/batch = 0.030, All_Time = 7033.767
238650/758000 (epoch 629), train_loss = 0.256, time/batch = 0.028, All_Time = 7035.240
238700/758000 (epoch 629), train_loss = 0.236, time/batch = 0.029, All_Time = 7036.712
238750/758000 (epoch 629), train_loss = 0.268, time/batch = 0.028, All_Time = 7038.184
238800/758000 (epoch 630), train_loss = 0.226, time/batch = 0.029, All_Time = 7039.667
238850/758000 (epoch 630), train_loss = 0.222, time/batch = 0.031, All_Time = 7041.136
238900/758000 (epoch 630), train_loss = 0.261, time/batch = 0.030, All_Time = 7042.609
238950/758000 (epoch 630), train_loss = 0.254, time/batch = 0.029, All_Time = 7044.109
239000/758000 (epoch 630), train_loss = 0.223, time/batch = 0.030, All_Time = 7045.596
model saved to NER/polyglot/model.ckpt
239050/758000 (epoch 630), train_loss = 0.242, time/batch = 0.029, All_Time = 7047.070
239100/758000 (epoch 630), train_loss = 0.251, time/batch = 0.028, All_Time = 7048.541
239150/758000 (epoch 631), train_loss = 0.192, time/batch = 0.030, All_Time = 7050.024
239200/758000 (epoch 631), train_loss = 0.273, time/batch = 0.028, All_Time = 7051.489
239250/758000 (epoch 631), train_loss = 0.217, time/batch = 0.029, All_Time = 7052.951
239300/758000 (epoch 631), train_loss = 0.240, time/batch = 0.029, All_Time = 7054.421
239350/758000 (epoch 631), train_loss = 0.221, time/batch = 0.029, All_Time = 7055.894
239400/758000 (epoch 631), train_loss = 0.221, time/batch = 0.028, All_Time = 7057.368
239450/758000 (epoch 631), train_loss = 0.252, time/batch = 0.029, All_Time = 7058.850
239500/758000 (epoch 631), train_loss = 0.272, time/batch = 0.030, All_Time = 7060.330
239550/758000 (epoch 632), train_loss = 0.222, time/batch = 0.030, All_Time = 7061.820
239600/758000 (epoch 632), train_loss = 0.279, time/batch = 0.031, All_Time = 7063.291
239650/758000 (epoch 632), train_loss = 0.242, time/batch = 0.028, All_Time = 7064.764
239700/758000 (epoch 632), train_loss = 0.274, time/batch = 0.030, All_Time = 7066.248
239750/758000 (epoch 632), train_loss = 0.262, time/batch = 0.030, All_Time = 7067.720
239800/758000 (epoch 632), train_loss = 0.197, time/batch = 0.031, All_Time = 7069.206
239850/758000 (epoch 632), train_loss = 0.233, time/batch = 0.029, All_Time = 7070.673
239900/758000 (epoch 632), train_loss = 0.281, time/batch = 0.030, All_Time = 7072.136
239950/758000 (epoch 633), train_loss = 0.246, time/batch = 0.031, All_Time = 7073.599
240000/758000 (epoch 633), train_loss = 0.212, time/batch = 0.031, All_Time = 7075.110
model saved to NER/polyglot/model.ckpt
240050/758000 (epoch 633), train_loss = 0.255, time/batch = 0.030, All_Time = 7076.605
240100/758000 (epoch 633), train_loss = 0.271, time/batch = 0.029, All_Time = 7078.081
240150/758000 (epoch 633), train_loss = 0.203, time/batch = 0.029, All_Time = 7079.552
240200/758000 (epoch 633), train_loss = 0.226, time/batch = 0.030, All_Time = 7081.013
240250/758000 (epoch 633), train_loss = 0.254, time/batch = 0.030, All_Time = 7082.482
240300/758000 (epoch 634), train_loss = 0.219, time/batch = 0.029, All_Time = 7083.956
240350/758000 (epoch 634), train_loss = 0.265, time/batch = 0.030, All_Time = 7085.420
240400/758000 (epoch 634), train_loss = 0.227, time/batch = 0.030, All_Time = 7086.920
240450/758000 (epoch 634), train_loss = 0.213, time/batch = 0.029, All_Time = 7088.400
240500/758000 (epoch 634), train_loss = 0.224, time/batch = 0.030, All_Time = 7089.892
240550/758000 (epoch 634), train_loss = 0.213, time/batch = 0.029, All_Time = 7091.385
240600/758000 (epoch 634), train_loss = 0.230, time/batch = 0.031, All_Time = 7092.879
240650/758000 (epoch 634), train_loss = 0.223, time/batch = 0.029, All_Time = 7094.363
240700/758000 (epoch 635), train_loss = 0.275, time/batch = 0.030, All_Time = 7095.847
240750/758000 (epoch 635), train_loss = 0.229, time/batch = 0.029, All_Time = 7097.341
240800/758000 (epoch 635), train_loss = 0.270, time/batch = 0.030, All_Time = 7098.810
240850/758000 (epoch 635), train_loss = 0.273, time/batch = 0.029, All_Time = 7100.282
240900/758000 (epoch 635), train_loss = 0.233, time/batch = 0.030, All_Time = 7101.762
240950/758000 (epoch 635), train_loss = 0.268, time/batch = 0.030, All_Time = 7103.240
241000/758000 (epoch 635), train_loss = 0.280, time/batch = 0.031, All_Time = 7104.715
model saved to NER/polyglot/model.ckpt
241050/758000 (epoch 636), train_loss = 0.239, time/batch = 0.031, All_Time = 7106.201
241100/758000 (epoch 636), train_loss = 0.218, time/batch = 0.031, All_Time = 7107.663
241150/758000 (epoch 636), train_loss = 0.243, time/batch = 0.029, All_Time = 7109.132
241200/758000 (epoch 636), train_loss = 0.244, time/batch = 0.031, All_Time = 7110.644
241250/758000 (epoch 636), train_loss = 0.243, time/batch = 0.029, All_Time = 7112.130
241300/758000 (epoch 636), train_loss = 0.244, time/batch = 0.030, All_Time = 7113.607
241350/758000 (epoch 636), train_loss = 0.213, time/batch = 0.028, All_Time = 7115.090
241400/758000 (epoch 636), train_loss = 0.289, time/batch = 0.031, All_Time = 7116.572
241450/758000 (epoch 637), train_loss = 0.237, time/batch = 0.029, All_Time = 7118.067
241500/758000 (epoch 637), train_loss = 0.246, time/batch = 0.028, All_Time = 7119.539
241550/758000 (epoch 637), train_loss = 0.288, time/batch = 0.031, All_Time = 7120.997
241600/758000 (epoch 637), train_loss = 0.257, time/batch = 0.030, All_Time = 7122.455
241650/758000 (epoch 637), train_loss = 0.218, time/batch = 0.028, All_Time = 7123.925
241700/758000 (epoch 637), train_loss = 0.238, time/batch = 0.029, All_Time = 7125.387
241750/758000 (epoch 637), train_loss = 0.251, time/batch = 0.031, All_Time = 7126.912
241800/758000 (epoch 637), train_loss = 0.251, time/batch = 0.028, All_Time = 7128.387
241850/758000 (epoch 638), train_loss = 0.252, time/batch = 0.028, All_Time = 7129.873
241900/758000 (epoch 638), train_loss = 0.280, time/batch = 0.029, All_Time = 7131.332
241950/758000 (epoch 638), train_loss = 0.242, time/batch = 0.030, All_Time = 7132.816
242000/758000 (epoch 638), train_loss = 0.250, time/batch = 0.029, All_Time = 7134.280
model saved to NER/polyglot/model.ckpt
242050/758000 (epoch 638), train_loss = 0.239, time/batch = 0.030, All_Time = 7135.753
242100/758000 (epoch 638), train_loss = 0.239, time/batch = 0.030, All_Time = 7137.219
242150/758000 (epoch 638), train_loss = 0.250, time/batch = 0.029, All_Time = 7138.686
242200/758000 (epoch 639), train_loss = 0.221, time/batch = 0.029, All_Time = 7140.154
242250/758000 (epoch 639), train_loss = 0.219, time/batch = 0.029, All_Time = 7141.617
242300/758000 (epoch 639), train_loss = 0.246, time/batch = 0.029, All_Time = 7143.075
242350/758000 (epoch 639), train_loss = 0.262, time/batch = 0.031, All_Time = 7144.575
242400/758000 (epoch 639), train_loss = 0.260, time/batch = 0.029, All_Time = 7146.062
242450/758000 (epoch 639), train_loss = 0.241, time/batch = 0.030, All_Time = 7147.534
242500/758000 (epoch 639), train_loss = 0.210, time/batch = 0.029, All_Time = 7149.016
242550/758000 (epoch 639), train_loss = 0.239, time/batch = 0.029, All_Time = 7150.490
242600/758000 (epoch 640), train_loss = 0.230, time/batch = 0.029, All_Time = 7151.973
242650/758000 (epoch 640), train_loss = 0.226, time/batch = 0.030, All_Time = 7153.446
242700/758000 (epoch 640), train_loss = 0.264, time/batch = 0.029, All_Time = 7154.913
242750/758000 (epoch 640), train_loss = 0.240, time/batch = 0.029, All_Time = 7156.390
242800/758000 (epoch 640), train_loss = 0.253, time/batch = 0.030, All_Time = 7157.866
242850/758000 (epoch 640), train_loss = 0.251, time/batch = 0.029, All_Time = 7159.330
242900/758000 (epoch 640), train_loss = 0.248, time/batch = 0.030, All_Time = 7160.823
242950/758000 (epoch 641), train_loss = 0.216, time/batch = 0.030, All_Time = 7162.314
243000/758000 (epoch 641), train_loss = 0.233, time/batch = 0.030, All_Time = 7163.810
model saved to NER/polyglot/model.ckpt
243050/758000 (epoch 641), train_loss = 0.250, time/batch = 0.029, All_Time = 7165.287
243100/758000 (epoch 641), train_loss = 0.241, time/batch = 0.028, All_Time = 7166.751
243150/758000 (epoch 641), train_loss = 0.243, time/batch = 0.030, All_Time = 7168.210
243200/758000 (epoch 641), train_loss = 0.242, time/batch = 0.030, All_Time = 7169.703
243250/758000 (epoch 641), train_loss = 0.230, time/batch = 0.029, All_Time = 7171.203
243300/758000 (epoch 641), train_loss = 0.259, time/batch = 0.030, All_Time = 7172.687
243350/758000 (epoch 642), train_loss = 0.250, time/batch = 0.030, All_Time = 7174.166
243400/758000 (epoch 642), train_loss = 0.253, time/batch = 0.029, All_Time = 7175.627
243450/758000 (epoch 642), train_loss = 0.245, time/batch = 0.029, All_Time = 7177.087
243500/758000 (epoch 642), train_loss = 0.231, time/batch = 0.029, All_Time = 7178.552
243550/758000 (epoch 642), train_loss = 0.228, time/batch = 0.029, All_Time = 7180.022
243600/758000 (epoch 642), train_loss = 0.238, time/batch = 0.030, All_Time = 7181.492
243650/758000 (epoch 642), train_loss = 0.268, time/batch = 0.030, All_Time = 7182.973
243700/758000 (epoch 643), train_loss = 0.248, time/batch = 0.030, All_Time = 7184.486
243750/758000 (epoch 643), train_loss = 0.280, time/batch = 0.029, All_Time = 7185.960
243800/758000 (epoch 643), train_loss = 0.242, time/batch = 0.030, All_Time = 7187.432
243850/758000 (epoch 643), train_loss = 0.258, time/batch = 0.029, All_Time = 7188.898
243900/758000 (epoch 643), train_loss = 0.224, time/batch = 0.028, All_Time = 7190.369
243950/758000 (epoch 643), train_loss = 0.243, time/batch = 0.029, All_Time = 7191.849
244000/758000 (epoch 643), train_loss = 0.219, time/batch = 0.031, All_Time = 7193.342
model saved to NER/polyglot/model.ckpt
244050/758000 (epoch 643), train_loss = 0.232, time/batch = 0.030, All_Time = 7194.833
244100/758000 (epoch 644), train_loss = 0.237, time/batch = 0.030, All_Time = 7196.311
244150/758000 (epoch 644), train_loss = 0.239, time/batch = 0.030, All_Time = 7197.790
244200/758000 (epoch 644), train_loss = 0.293, time/batch = 0.030, All_Time = 7199.264
244250/758000 (epoch 644), train_loss = 0.318, time/batch = 0.031, All_Time = 7200.736
244300/758000 (epoch 644), train_loss = 0.196, time/batch = 0.031, All_Time = 7202.236
244350/758000 (epoch 644), train_loss = 0.213, time/batch = 0.031, All_Time = 7203.728
244400/758000 (epoch 644), train_loss = 0.250, time/batch = 0.030, All_Time = 7205.209
244450/758000 (epoch 644), train_loss = 0.297, time/batch = 0.031, All_Time = 7206.716
244500/758000 (epoch 645), train_loss = 0.226, time/batch = 0.029, All_Time = 7208.200
244550/758000 (epoch 645), train_loss = 0.259, time/batch = 0.029, All_Time = 7209.682
244600/758000 (epoch 645), train_loss = 0.223, time/batch = 0.031, All_Time = 7211.158
244650/758000 (epoch 645), train_loss = 0.239, time/batch = 0.029, All_Time = 7212.638
244700/758000 (epoch 645), train_loss = 0.212, time/batch = 0.030, All_Time = 7214.123
244750/758000 (epoch 645), train_loss = 0.243, time/batch = 0.029, All_Time = 7215.592
244800/758000 (epoch 645), train_loss = 0.215, time/batch = 0.028, All_Time = 7217.063
244850/758000 (epoch 646), train_loss = 0.228, time/batch = 0.030, All_Time = 7218.549
244900/758000 (epoch 646), train_loss = 0.252, time/batch = 0.029, All_Time = 7220.018
244950/758000 (epoch 646), train_loss = 0.260, time/batch = 0.028, All_Time = 7221.479
245000/758000 (epoch 646), train_loss = 0.228, time/batch = 0.029, All_Time = 7222.949
model saved to NER/polyglot/model.ckpt
245050/758000 (epoch 646), train_loss = 0.236, time/batch = 0.029, All_Time = 7224.417
245100/758000 (epoch 646), train_loss = 0.271, time/batch = 0.029, All_Time = 7225.871
245150/758000 (epoch 646), train_loss = 0.238, time/batch = 0.029, All_Time = 7227.331
245200/758000 (epoch 646), train_loss = 0.268, time/batch = 0.032, All_Time = 7228.815
245250/758000 (epoch 647), train_loss = 0.248, time/batch = 0.030, All_Time = 7230.316
245300/758000 (epoch 647), train_loss = 0.249, time/batch = 0.029, All_Time = 7231.797
245350/758000 (epoch 647), train_loss = 0.240, time/batch = 0.032, All_Time = 7233.283
245400/758000 (epoch 647), train_loss = 0.247, time/batch = 0.029, All_Time = 7234.765
245450/758000 (epoch 647), train_loss = 0.235, time/batch = 0.029, All_Time = 7236.246
245500/758000 (epoch 647), train_loss = 0.247, time/batch = 0.029, All_Time = 7237.726
245550/758000 (epoch 647), train_loss = 0.251, time/batch = 0.029, All_Time = 7239.204
245600/758000 (epoch 648), train_loss = 0.242, time/batch = 0.031, All_Time = 7240.694
245650/758000 (epoch 648), train_loss = 0.276, time/batch = 0.029, All_Time = 7242.170
245700/758000 (epoch 648), train_loss = 0.256, time/batch = 0.029, All_Time = 7243.634
245750/758000 (epoch 648), train_loss = 0.258, time/batch = 0.029, All_Time = 7245.109
245800/758000 (epoch 648), train_loss = 0.213, time/batch = 0.029, All_Time = 7246.577
245850/758000 (epoch 648), train_loss = 0.237, time/batch = 0.030, All_Time = 7248.046
245900/758000 (epoch 648), train_loss = 0.249, time/batch = 0.028, All_Time = 7249.521
245950/758000 (epoch 648), train_loss = 0.251, time/batch = 0.029, All_Time = 7250.995
246000/758000 (epoch 649), train_loss = 0.232, time/batch = 0.029, All_Time = 7252.474
model saved to NER/polyglot/model.ckpt
246050/758000 (epoch 649), train_loss = 0.255, time/batch = 0.030, All_Time = 7253.940
246100/758000 (epoch 649), train_loss = 0.265, time/batch = 0.028, All_Time = 7255.401
246150/758000 (epoch 649), train_loss = 0.229, time/batch = 0.030, All_Time = 7256.882
246200/758000 (epoch 649), train_loss = 0.263, time/batch = 0.030, All_Time = 7258.339
246250/758000 (epoch 649), train_loss = 0.217, time/batch = 0.030, All_Time = 7259.855
246300/758000 (epoch 649), train_loss = 0.248, time/batch = 0.030, All_Time = 7261.350
246350/758000 (epoch 650), train_loss = 0.059, time/batch = 0.037, All_Time = 7262.901
246400/758000 (epoch 650), train_loss = 0.250, time/batch = 0.031, All_Time = 7264.378
246450/758000 (epoch 650), train_loss = 0.223, time/batch = 0.030, All_Time = 7265.859
246500/758000 (epoch 650), train_loss = 0.250, time/batch = 0.031, All_Time = 7267.336
246550/758000 (epoch 650), train_loss = 0.231, time/batch = 0.029, All_Time = 7268.819
246600/758000 (epoch 650), train_loss = 0.250, time/batch = 0.028, All_Time = 7270.294
246650/758000 (epoch 650), train_loss = 0.232, time/batch = 0.031, All_Time = 7271.761
246700/758000 (epoch 650), train_loss = 0.230, time/batch = 0.028, All_Time = 7273.224
246750/758000 (epoch 651), train_loss = 0.224, time/batch = 0.029, All_Time = 7274.703
246800/758000 (epoch 651), train_loss = 0.233, time/batch = 0.029, All_Time = 7276.184
246850/758000 (epoch 651), train_loss = 0.224, time/batch = 0.031, All_Time = 7277.644
246900/758000 (epoch 651), train_loss = 0.262, time/batch = 0.028, All_Time = 7279.099
246950/758000 (epoch 651), train_loss = 0.220, time/batch = 0.030, All_Time = 7280.568
247000/758000 (epoch 651), train_loss = 0.228, time/batch = 0.031, All_Time = 7282.040
model saved to NER/polyglot/model.ckpt
247050/758000 (epoch 651), train_loss = 0.280, time/batch = 0.035, All_Time = 7283.566
247100/758000 (epoch 651), train_loss = 0.272, time/batch = 0.028, All_Time = 7285.121
247150/758000 (epoch 652), train_loss = 0.230, time/batch = 0.028, All_Time = 7286.601
247200/758000 (epoch 652), train_loss = 0.224, time/batch = 0.032, All_Time = 7288.096
247250/758000 (epoch 652), train_loss = 0.201, time/batch = 0.029, All_Time = 7289.594
247300/758000 (epoch 652), train_loss = 0.270, time/batch = 0.030, All_Time = 7291.069
247350/758000 (epoch 652), train_loss = 0.259, time/batch = 0.030, All_Time = 7292.534
247400/758000 (epoch 652), train_loss = 0.209, time/batch = 0.031, All_Time = 7294.017
247450/758000 (epoch 652), train_loss = 0.218, time/batch = 0.031, All_Time = 7295.495
247500/758000 (epoch 653), train_loss = 0.229, time/batch = 0.030, All_Time = 7296.981
247550/758000 (epoch 653), train_loss = 0.283, time/batch = 0.028, All_Time = 7298.458
247600/758000 (epoch 653), train_loss = 0.231, time/batch = 0.029, All_Time = 7299.924
247650/758000 (epoch 653), train_loss = 0.307, time/batch = 0.030, All_Time = 7301.391
247700/758000 (epoch 653), train_loss = 0.221, time/batch = 0.030, All_Time = 7302.856
247750/758000 (epoch 653), train_loss = 0.208, time/batch = 0.029, All_Time = 7304.322
247800/758000 (epoch 653), train_loss = 0.247, time/batch = 0.031, All_Time = 7305.831
247850/758000 (epoch 653), train_loss = 0.252, time/batch = 0.030, All_Time = 7307.321
247900/758000 (epoch 654), train_loss = 0.264, time/batch = 0.029, All_Time = 7308.797
247950/758000 (epoch 654), train_loss = 0.229, time/batch = 0.029, All_Time = 7310.265
248000/758000 (epoch 654), train_loss = 0.242, time/batch = 0.030, All_Time = 7311.741
model saved to NER/polyglot/model.ckpt
248050/758000 (epoch 654), train_loss = 0.267, time/batch = 0.030, All_Time = 7313.215
248100/758000 (epoch 654), train_loss = 0.249, time/batch = 0.029, All_Time = 7314.679
248150/758000 (epoch 654), train_loss = 0.237, time/batch = 0.030, All_Time = 7316.136
248200/758000 (epoch 654), train_loss = 0.276, time/batch = 0.029, All_Time = 7317.614
248250/758000 (epoch 655), train_loss = 0.256, time/batch = 0.031, All_Time = 7319.099
248300/758000 (epoch 655), train_loss = 0.222, time/batch = 0.029, All_Time = 7320.575
248350/758000 (epoch 655), train_loss = 0.266, time/batch = 0.030, All_Time = 7322.052
248400/758000 (epoch 655), train_loss = 0.216, time/batch = 0.029, All_Time = 7323.543
248450/758000 (epoch 655), train_loss = 0.223, time/batch = 0.029, All_Time = 7325.019
248500/758000 (epoch 655), train_loss = 0.261, time/batch = 0.029, All_Time = 7326.490
248550/758000 (epoch 655), train_loss = 0.238, time/batch = 0.031, All_Time = 7327.968
248600/758000 (epoch 655), train_loss = 0.264, time/batch = 0.031, All_Time = 7329.444
248650/758000 (epoch 656), train_loss = 0.223, time/batch = 0.029, All_Time = 7330.919
248700/758000 (epoch 656), train_loss = 0.231, time/batch = 0.030, All_Time = 7332.387
248750/758000 (epoch 656), train_loss = 0.238, time/batch = 0.028, All_Time = 7333.865
248800/758000 (epoch 656), train_loss = 0.266, time/batch = 0.030, All_Time = 7335.356
248850/758000 (epoch 656), train_loss = 0.239, time/batch = 0.029, All_Time = 7336.825
248900/758000 (epoch 656), train_loss = 0.226, time/batch = 0.029, All_Time = 7338.302
248950/758000 (epoch 656), train_loss = 0.276, time/batch = 0.028, All_Time = 7339.776
249000/758000 (epoch 656), train_loss = 0.240, time/batch = 0.030, All_Time = 7341.247
model saved to NER/polyglot/model.ckpt
249050/758000 (epoch 657), train_loss = 0.281, time/batch = 0.031, All_Time = 7342.753
249100/758000 (epoch 657), train_loss = 0.257, time/batch = 0.030, All_Time = 7344.232
249150/758000 (epoch 657), train_loss = 0.240, time/batch = 0.030, All_Time = 7345.705
249200/758000 (epoch 657), train_loss = 0.231, time/batch = 0.029, All_Time = 7347.185
249250/758000 (epoch 657), train_loss = 0.217, time/batch = 0.028, All_Time = 7348.657
249300/758000 (epoch 657), train_loss = 0.224, time/batch = 0.029, All_Time = 7350.123
249350/758000 (epoch 657), train_loss = 0.215, time/batch = 0.031, All_Time = 7351.595
249400/758000 (epoch 658), train_loss = 0.249, time/batch = 0.029, All_Time = 7353.073
249450/758000 (epoch 658), train_loss = 0.211, time/batch = 0.029, All_Time = 7354.538
249500/758000 (epoch 658), train_loss = 0.245, time/batch = 0.029, All_Time = 7356.007
249550/758000 (epoch 658), train_loss = 0.217, time/batch = 0.030, All_Time = 7357.482
249600/758000 (epoch 658), train_loss = 0.233, time/batch = 0.029, All_Time = 7358.952
249650/758000 (epoch 658), train_loss = 0.228, time/batch = 0.030, All_Time = 7360.418
249700/758000 (epoch 658), train_loss = 0.248, time/batch = 0.030, All_Time = 7361.879
249750/758000 (epoch 658), train_loss = 0.229, time/batch = 0.031, All_Time = 7363.369
249800/758000 (epoch 659), train_loss = 0.218, time/batch = 0.030, All_Time = 7364.853
249850/758000 (epoch 659), train_loss = 0.237, time/batch = 0.029, All_Time = 7366.331
249900/758000 (epoch 659), train_loss = 0.212, time/batch = 0.033, All_Time = 7367.800
249950/758000 (epoch 659), train_loss = 0.266, time/batch = 0.030, All_Time = 7369.272
250000/758000 (epoch 659), train_loss = 0.255, time/batch = 0.030, All_Time = 7370.745
model saved to NER/polyglot/model.ckpt
250050/758000 (epoch 659), train_loss = 0.232, time/batch = 0.028, All_Time = 7372.215
250100/758000 (epoch 659), train_loss = 0.262, time/batch = 0.030, All_Time = 7373.677
250150/758000 (epoch 660), train_loss = 0.282, time/batch = 0.030, All_Time = 7375.153
250200/758000 (epoch 660), train_loss = 0.292, time/batch = 0.031, All_Time = 7376.624
250250/758000 (epoch 660), train_loss = 0.253, time/batch = 0.028, All_Time = 7378.085
250300/758000 (epoch 660), train_loss = 0.222, time/batch = 0.030, All_Time = 7379.559
250350/758000 (epoch 660), train_loss = 0.221, time/batch = 0.029, All_Time = 7381.018
250400/758000 (epoch 660), train_loss = 0.260, time/batch = 0.029, All_Time = 7382.524
250450/758000 (epoch 660), train_loss = 0.244, time/batch = 0.029, All_Time = 7384.030
250500/758000 (epoch 660), train_loss = 0.247, time/batch = 0.030, All_Time = 7385.520
250550/758000 (epoch 661), train_loss = 0.210, time/batch = 0.030, All_Time = 7387.015
250600/758000 (epoch 661), train_loss = 0.265, time/batch = 0.029, All_Time = 7388.479
250650/758000 (epoch 661), train_loss = 0.229, time/batch = 0.030, All_Time = 7389.953
250700/758000 (epoch 661), train_loss = 0.232, time/batch = 0.029, All_Time = 7391.431
250750/758000 (epoch 661), train_loss = 0.230, time/batch = 0.031, All_Time = 7392.912
250800/758000 (epoch 661), train_loss = 0.253, time/batch = 0.029, All_Time = 7394.419
250850/758000 (epoch 661), train_loss = 0.258, time/batch = 0.030, All_Time = 7395.902
250900/758000 (epoch 662), train_loss = 0.196, time/batch = 0.030, All_Time = 7397.384
250950/758000 (epoch 662), train_loss = 0.254, time/batch = 0.028, All_Time = 7398.862
251000/758000 (epoch 662), train_loss = 0.281, time/batch = 0.030, All_Time = 7400.340
model saved to NER/polyglot/model.ckpt
251050/758000 (epoch 662), train_loss = 0.235, time/batch = 0.030, All_Time = 7401.799
251100/758000 (epoch 662), train_loss = 0.247, time/batch = 0.030, All_Time = 7403.271
251150/758000 (epoch 662), train_loss = 0.251, time/batch = 0.029, All_Time = 7404.739
251200/758000 (epoch 662), train_loss = 0.203, time/batch = 0.028, All_Time = 7406.199
251250/758000 (epoch 662), train_loss = 0.268, time/batch = 0.029, All_Time = 7407.668
251300/758000 (epoch 663), train_loss = 0.233, time/batch = 0.032, All_Time = 7409.167
251350/758000 (epoch 663), train_loss = 0.241, time/batch = 0.029, All_Time = 7410.666
251400/758000 (epoch 663), train_loss = 0.252, time/batch = 0.029, All_Time = 7412.156
251450/758000 (epoch 663), train_loss = 0.258, time/batch = 0.029, All_Time = 7413.633
251500/758000 (epoch 663), train_loss = 0.243, time/batch = 0.030, All_Time = 7415.127
251550/758000 (epoch 663), train_loss = 0.243, time/batch = 0.029, All_Time = 7416.600
251600/758000 (epoch 663), train_loss = 0.244, time/batch = 0.029, All_Time = 7418.066
251650/758000 (epoch 663), train_loss = 0.286, time/batch = 0.029, All_Time = 7419.533
251700/758000 (epoch 664), train_loss = 0.207, time/batch = 0.029, All_Time = 7421.012
251750/758000 (epoch 664), train_loss = 0.244, time/batch = 0.030, All_Time = 7422.475
251800/758000 (epoch 664), train_loss = 0.217, time/batch = 0.030, All_Time = 7423.950
251850/758000 (epoch 664), train_loss = 0.233, time/batch = 0.029, All_Time = 7425.445
251900/758000 (epoch 664), train_loss = 0.260, time/batch = 0.028, All_Time = 7426.939
251950/758000 (epoch 664), train_loss = 0.253, time/batch = 0.029, All_Time = 7428.415
252000/758000 (epoch 664), train_loss = 0.238, time/batch = 0.031, All_Time = 7429.895
model saved to NER/polyglot/model.ckpt
252050/758000 (epoch 665), train_loss = 0.227, time/batch = 0.030, All_Time = 7431.382
252100/758000 (epoch 665), train_loss = 0.250, time/batch = 0.031, All_Time = 7432.841
252150/758000 (epoch 665), train_loss = 0.250, time/batch = 0.030, All_Time = 7434.306
252200/758000 (epoch 665), train_loss = 0.223, time/batch = 0.029, All_Time = 7435.761
252250/758000 (epoch 665), train_loss = 0.240, time/batch = 0.028, All_Time = 7437.223
252300/758000 (epoch 665), train_loss = 0.246, time/batch = 0.030, All_Time = 7438.683
252350/758000 (epoch 665), train_loss = 0.246, time/batch = 0.029, All_Time = 7440.144
252400/758000 (epoch 665), train_loss = 0.257, time/batch = 0.030, All_Time = 7441.618
252450/758000 (epoch 666), train_loss = 0.266, time/batch = 0.028, All_Time = 7443.101
252500/758000 (epoch 666), train_loss = 0.224, time/batch = 0.030, All_Time = 7444.589
252550/758000 (epoch 666), train_loss = 0.248, time/batch = 0.031, All_Time = 7446.069
252600/758000 (epoch 666), train_loss = 0.227, time/batch = 0.029, All_Time = 7447.545
252650/758000 (epoch 666), train_loss = 0.279, time/batch = 0.031, All_Time = 7449.022
252700/758000 (epoch 666), train_loss = 0.255, time/batch = 0.030, All_Time = 7450.507
252750/758000 (epoch 666), train_loss = 0.253, time/batch = 0.030, All_Time = 7451.976
252800/758000 (epoch 667), train_loss = 0.244, time/batch = 0.029, All_Time = 7453.466
252850/758000 (epoch 667), train_loss = 0.247, time/batch = 0.028, All_Time = 7454.941
252900/758000 (epoch 667), train_loss = 0.270, time/batch = 0.029, All_Time = 7456.413
252950/758000 (epoch 667), train_loss = 0.246, time/batch = 0.029, All_Time = 7457.889
253000/758000 (epoch 667), train_loss = 0.237, time/batch = 0.029, All_Time = 7459.362
model saved to NER/polyglot/model.ckpt
253050/758000 (epoch 667), train_loss = 0.224, time/batch = 0.031, All_Time = 7460.837
253100/758000 (epoch 667), train_loss = 0.229, time/batch = 0.030, All_Time = 7462.320
253150/758000 (epoch 667), train_loss = 0.246, time/batch = 0.029, All_Time = 7463.812
253200/758000 (epoch 668), train_loss = 0.249, time/batch = 0.029, All_Time = 7465.307
253250/758000 (epoch 668), train_loss = 0.264, time/batch = 0.030, All_Time = 7466.776
253300/758000 (epoch 668), train_loss = 0.240, time/batch = 0.030, All_Time = 7468.240
253350/758000 (epoch 668), train_loss = 0.250, time/batch = 0.029, All_Time = 7469.722
253400/758000 (epoch 668), train_loss = 0.227, time/batch = 0.029, All_Time = 7471.198
253450/758000 (epoch 668), train_loss = 0.217, time/batch = 0.029, All_Time = 7472.669
253500/758000 (epoch 668), train_loss = 0.277, time/batch = 0.029, All_Time = 7474.144
253550/758000 (epoch 668), train_loss = 0.259, time/batch = 0.029, All_Time = 7475.615
253600/758000 (epoch 669), train_loss = 0.269, time/batch = 0.031, All_Time = 7477.095
253650/758000 (epoch 669), train_loss = 0.296, time/batch = 0.029, All_Time = 7478.561
253700/758000 (epoch 669), train_loss = 0.228, time/batch = 0.030, All_Time = 7480.060
253750/758000 (epoch 669), train_loss = 0.220, time/batch = 0.029, All_Time = 7481.547
253800/758000 (epoch 669), train_loss = 0.257, time/batch = 0.030, All_Time = 7483.028
253850/758000 (epoch 669), train_loss = 0.255, time/batch = 0.030, All_Time = 7484.497
253900/758000 (epoch 669), train_loss = 0.237, time/batch = 0.031, All_Time = 7485.972
253950/758000 (epoch 670), train_loss = 0.225, time/batch = 0.029, All_Time = 7487.462
254000/758000 (epoch 670), train_loss = 0.234, time/batch = 0.029, All_Time = 7488.929
model saved to NER/polyglot/model.ckpt
254050/758000 (epoch 670), train_loss = 0.243, time/batch = 0.029, All_Time = 7490.392
254100/758000 (epoch 670), train_loss = 0.234, time/batch = 0.031, All_Time = 7491.856
254150/758000 (epoch 670), train_loss = 0.223, time/batch = 0.030, All_Time = 7493.331
254200/758000 (epoch 670), train_loss = 0.239, time/batch = 0.028, All_Time = 7494.792
254250/758000 (epoch 670), train_loss = 0.264, time/batch = 0.030, All_Time = 7496.306
254300/758000 (epoch 670), train_loss = 0.244, time/batch = 0.029, All_Time = 7497.797
254350/758000 (epoch 671), train_loss = 0.257, time/batch = 0.029, All_Time = 7499.276
254400/758000 (epoch 671), train_loss = 0.287, time/batch = 0.030, All_Time = 7500.743
254450/758000 (epoch 671), train_loss = 0.255, time/batch = 0.030, All_Time = 7502.222
254500/758000 (epoch 671), train_loss = 0.248, time/batch = 0.029, All_Time = 7503.708
254550/758000 (epoch 671), train_loss = 0.212, time/batch = 0.030, All_Time = 7505.185
254600/758000 (epoch 671), train_loss = 0.229, time/batch = 0.030, All_Time = 7506.657
254650/758000 (epoch 671), train_loss = 0.272, time/batch = 0.030, All_Time = 7508.136
254700/758000 (epoch 672), train_loss = 0.249, time/batch = 0.029, All_Time = 7509.629
254750/758000 (epoch 672), train_loss = 0.227, time/batch = 0.031, All_Time = 7511.115
254800/758000 (epoch 672), train_loss = 0.267, time/batch = 0.030, All_Time = 7512.610
254850/758000 (epoch 672), train_loss = 0.239, time/batch = 0.030, All_Time = 7514.105
254900/758000 (epoch 672), train_loss = 0.247, time/batch = 0.033, All_Time = 7515.591
254950/758000 (epoch 672), train_loss = 0.241, time/batch = 0.029, All_Time = 7517.066
255000/758000 (epoch 672), train_loss = 0.274, time/batch = 0.031, All_Time = 7518.547
model saved to NER/polyglot/model.ckpt
255050/758000 (epoch 672), train_loss = 0.279, time/batch = 0.029, All_Time = 7520.015
255100/758000 (epoch 673), train_loss = 0.238, time/batch = 0.029, All_Time = 7521.490
255150/758000 (epoch 673), train_loss = 0.248, time/batch = 0.030, All_Time = 7522.955
255200/758000 (epoch 673), train_loss = 0.299, time/batch = 0.030, All_Time = 7524.451
255250/758000 (epoch 673), train_loss = 0.230, time/batch = 0.031, All_Time = 7525.949
255300/758000 (epoch 673), train_loss = 0.216, time/batch = 0.031, All_Time = 7527.432
255350/758000 (epoch 673), train_loss = 0.244, time/batch = 0.029, All_Time = 7528.916
255400/758000 (epoch 673), train_loss = 0.274, time/batch = 0.029, All_Time = 7530.378
255450/758000 (epoch 674), train_loss = 0.221, time/batch = 0.029, All_Time = 7531.856
255500/758000 (epoch 674), train_loss = 0.257, time/batch = 0.029, All_Time = 7533.321
255550/758000 (epoch 674), train_loss = 0.241, time/batch = 0.030, All_Time = 7534.784
255600/758000 (epoch 674), train_loss = 0.240, time/batch = 0.028, All_Time = 7536.260
255650/758000 (epoch 674), train_loss = 0.256, time/batch = 0.028, All_Time = 7537.737
255700/758000 (epoch 674), train_loss = 0.219, time/batch = 0.031, All_Time = 7539.215
255750/758000 (epoch 674), train_loss = 0.224, time/batch = 0.029, All_Time = 7540.690
255800/758000 (epoch 674), train_loss = 0.257, time/batch = 0.028, All_Time = 7542.166
255850/758000 (epoch 675), train_loss = 0.255, time/batch = 0.029, All_Time = 7543.651
255900/758000 (epoch 675), train_loss = 0.267, time/batch = 0.029, All_Time = 7545.114
255950/758000 (epoch 675), train_loss = 0.269, time/batch = 0.030, All_Time = 7546.590
256000/758000 (epoch 675), train_loss = 0.228, time/batch = 0.029, All_Time = 7548.100
model saved to NER/polyglot/model.ckpt
256050/758000 (epoch 675), train_loss = 0.234, time/batch = 0.029, All_Time = 7549.588
256100/758000 (epoch 675), train_loss = 0.245, time/batch = 0.030, All_Time = 7551.054
256150/758000 (epoch 675), train_loss = 0.279, time/batch = 0.029, All_Time = 7552.533
256200/758000 (epoch 675), train_loss = 0.240, time/batch = 0.029, All_Time = 7553.998
256250/758000 (epoch 676), train_loss = 0.236, time/batch = 0.029, All_Time = 7555.475
256300/758000 (epoch 676), train_loss = 0.234, time/batch = 0.030, All_Time = 7556.931
256350/758000 (epoch 676), train_loss = 0.233, time/batch = 0.029, All_Time = 7558.444
256400/758000 (epoch 676), train_loss = 0.276, time/batch = 0.029, All_Time = 7559.921
256450/758000 (epoch 676), train_loss = 0.206, time/batch = 0.030, All_Time = 7561.414
256500/758000 (epoch 676), train_loss = 0.259, time/batch = 0.028, All_Time = 7562.884
256550/758000 (epoch 676), train_loss = 0.234, time/batch = 0.030, All_Time = 7564.364
256600/758000 (epoch 677), train_loss = 0.245, time/batch = 0.029, All_Time = 7565.851
256650/758000 (epoch 677), train_loss = 0.223, time/batch = 0.030, All_Time = 7567.314
256700/758000 (epoch 677), train_loss = 0.240, time/batch = 0.030, All_Time = 7568.774
256750/758000 (epoch 677), train_loss = 0.256, time/batch = 0.029, All_Time = 7570.249
256800/758000 (epoch 677), train_loss = 0.214, time/batch = 0.030, All_Time = 7571.716
256850/758000 (epoch 677), train_loss = 0.272, time/batch = 0.028, All_Time = 7573.175
256900/758000 (epoch 677), train_loss = 0.213, time/batch = 0.030, All_Time = 7574.652
256950/758000 (epoch 677), train_loss = 0.251, time/batch = 0.031, All_Time = 7576.144
257000/758000 (epoch 678), train_loss = 0.247, time/batch = 0.031, All_Time = 7577.658
model saved to NER/polyglot/model.ckpt
257050/758000 (epoch 678), train_loss = 0.229, time/batch = 0.032, All_Time = 7579.124
257100/758000 (epoch 678), train_loss = 0.217, time/batch = 0.030, All_Time = 7580.600
257150/758000 (epoch 678), train_loss = 0.220, time/batch = 0.030, All_Time = 7582.092
257200/758000 (epoch 678), train_loss = 0.250, time/batch = 0.030, All_Time = 7583.572
257250/758000 (epoch 678), train_loss = 0.207, time/batch = 0.030, All_Time = 7585.056
257300/758000 (epoch 678), train_loss = 0.268, time/batch = 0.029, All_Time = 7586.541
257350/758000 (epoch 679), train_loss = 0.256, time/batch = 0.031, All_Time = 7588.036
257400/758000 (epoch 679), train_loss = 0.264, time/batch = 0.028, All_Time = 7589.511
257450/758000 (epoch 679), train_loss = 0.284, time/batch = 0.028, All_Time = 7590.966
257500/758000 (epoch 679), train_loss = 0.239, time/batch = 0.029, All_Time = 7592.440
257550/758000 (epoch 679), train_loss = 0.267, time/batch = 0.028, All_Time = 7593.911
257600/758000 (epoch 679), train_loss = 0.256, time/batch = 0.030, All_Time = 7595.377
257650/758000 (epoch 679), train_loss = 0.236, time/batch = 0.031, All_Time = 7596.892
257700/758000 (epoch 679), train_loss = 0.268, time/batch = 0.030, All_Time = 7598.369
257750/758000 (epoch 680), train_loss = 0.226, time/batch = 0.030, All_Time = 7599.852
257800/758000 (epoch 680), train_loss = 0.222, time/batch = 0.029, All_Time = 7601.322
257850/758000 (epoch 680), train_loss = 0.261, time/batch = 0.030, All_Time = 7602.802
257900/758000 (epoch 680), train_loss = 0.254, time/batch = 0.033, All_Time = 7604.268
257950/758000 (epoch 680), train_loss = 0.223, time/batch = 0.029, All_Time = 7605.744
258000/758000 (epoch 680), train_loss = 0.242, time/batch = 0.029, All_Time = 7607.225
model saved to NER/polyglot/model.ckpt
258050/758000 (epoch 680), train_loss = 0.251, time/batch = 0.029, All_Time = 7608.716
258100/758000 (epoch 681), train_loss = 0.192, time/batch = 0.031, All_Time = 7610.229
258150/758000 (epoch 681), train_loss = 0.273, time/batch = 0.030, All_Time = 7611.696
258200/758000 (epoch 681), train_loss = 0.217, time/batch = 0.030, All_Time = 7613.168
258250/758000 (epoch 681), train_loss = 0.240, time/batch = 0.028, All_Time = 7614.637
258300/758000 (epoch 681), train_loss = 0.221, time/batch = 0.029, All_Time = 7616.117
258350/758000 (epoch 681), train_loss = 0.221, time/batch = 0.030, All_Time = 7617.583
258400/758000 (epoch 681), train_loss = 0.252, time/batch = 0.029, All_Time = 7619.057
258450/758000 (epoch 681), train_loss = 0.272, time/batch = 0.030, All_Time = 7620.547
258500/758000 (epoch 682), train_loss = 0.222, time/batch = 0.029, All_Time = 7622.050
258550/758000 (epoch 682), train_loss = 0.279, time/batch = 0.029, All_Time = 7623.520
258600/758000 (epoch 682), train_loss = 0.242, time/batch = 0.030, All_Time = 7624.994
258650/758000 (epoch 682), train_loss = 0.274, time/batch = 0.030, All_Time = 7626.463
258700/758000 (epoch 682), train_loss = 0.262, time/batch = 0.029, All_Time = 7627.935
258750/758000 (epoch 682), train_loss = 0.197, time/batch = 0.030, All_Time = 7629.407
258800/758000 (epoch 682), train_loss = 0.233, time/batch = 0.029, All_Time = 7630.900
258850/758000 (epoch 682), train_loss = 0.281, time/batch = 0.031, All_Time = 7632.413
258900/758000 (epoch 683), train_loss = 0.246, time/batch = 0.029, All_Time = 7633.905
258950/758000 (epoch 683), train_loss = 0.212, time/batch = 0.029, All_Time = 7635.372
259000/758000 (epoch 683), train_loss = 0.255, time/batch = 0.028, All_Time = 7636.850
model saved to NER/polyglot/model.ckpt
259050/758000 (epoch 683), train_loss = 0.271, time/batch = 0.029, All_Time = 7638.322
259100/758000 (epoch 683), train_loss = 0.203, time/batch = 0.030, All_Time = 7639.801
259150/758000 (epoch 683), train_loss = 0.226, time/batch = 0.031, All_Time = 7641.284
259200/758000 (epoch 683), train_loss = 0.254, time/batch = 0.029, All_Time = 7642.772
259250/758000 (epoch 684), train_loss = 0.219, time/batch = 0.030, All_Time = 7644.252
259300/758000 (epoch 684), train_loss = 0.265, time/batch = 0.029, All_Time = 7645.721
259350/758000 (epoch 684), train_loss = 0.227, time/batch = 0.033, All_Time = 7647.372
259400/758000 (epoch 684), train_loss = 0.213, time/batch = 0.031, All_Time = 7648.879
259450/758000 (epoch 684), train_loss = 0.224, time/batch = 0.029, All_Time = 7650.361
259500/758000 (epoch 684), train_loss = 0.213, time/batch = 0.030, All_Time = 7651.839
259550/758000 (epoch 684), train_loss = 0.230, time/batch = 0.031, All_Time = 7653.311
259600/758000 (epoch 684), train_loss = 0.223, time/batch = 0.029, All_Time = 7654.773
259650/758000 (epoch 685), train_loss = 0.275, time/batch = 0.029, All_Time = 7656.272
259700/758000 (epoch 685), train_loss = 0.229, time/batch = 0.031, All_Time = 7657.752
259750/758000 (epoch 685), train_loss = 0.270, time/batch = 0.029, All_Time = 7659.233
259800/758000 (epoch 685), train_loss = 0.273, time/batch = 0.029, All_Time = 7660.725
259850/758000 (epoch 685), train_loss = 0.233, time/batch = 0.029, All_Time = 7662.198
259900/758000 (epoch 685), train_loss = 0.268, time/batch = 0.029, All_Time = 7663.680
259950/758000 (epoch 685), train_loss = 0.280, time/batch = 0.031, All_Time = 7665.157
260000/758000 (epoch 686), train_loss = 0.239, time/batch = 0.029, All_Time = 7666.655
model saved to NER/polyglot/model.ckpt
260050/758000 (epoch 686), train_loss = 0.218, time/batch = 0.029, All_Time = 7668.125
260100/758000 (epoch 686), train_loss = 0.243, time/batch = 0.029, All_Time = 7669.586
260150/758000 (epoch 686), train_loss = 0.244, time/batch = 0.031, All_Time = 7671.060
260200/758000 (epoch 686), train_loss = 0.243, time/batch = 0.029, All_Time = 7672.555
260250/758000 (epoch 686), train_loss = 0.244, time/batch = 0.031, All_Time = 7674.043
260300/758000 (epoch 686), train_loss = 0.213, time/batch = 0.030, All_Time = 7675.543
260350/758000 (epoch 686), train_loss = 0.289, time/batch = 0.030, All_Time = 7677.033
260400/758000 (epoch 687), train_loss = 0.237, time/batch = 0.029, All_Time = 7678.511
260450/758000 (epoch 687), train_loss = 0.246, time/batch = 0.029, All_Time = 7679.992
260500/758000 (epoch 687), train_loss = 0.288, time/batch = 0.029, All_Time = 7681.464
260550/758000 (epoch 687), train_loss = 0.257, time/batch = 0.028, All_Time = 7682.950
260600/758000 (epoch 687), train_loss = 0.218, time/batch = 0.029, All_Time = 7684.426
260650/758000 (epoch 687), train_loss = 0.238, time/batch = 0.029, All_Time = 7685.914
260700/758000 (epoch 687), train_loss = 0.251, time/batch = 0.031, All_Time = 7687.396
260750/758000 (epoch 687), train_loss = 0.251, time/batch = 0.029, All_Time = 7688.875
260800/758000 (epoch 688), train_loss = 0.252, time/batch = 0.029, All_Time = 7690.353
260850/758000 (epoch 688), train_loss = 0.280, time/batch = 0.030, All_Time = 7691.832
260900/758000 (epoch 688), train_loss = 0.242, time/batch = 0.030, All_Time = 7693.344
260950/758000 (epoch 688), train_loss = 0.250, time/batch = 0.029, All_Time = 7694.828
261000/758000 (epoch 688), train_loss = 0.239, time/batch = 0.030, All_Time = 7696.315
model saved to NER/polyglot/model.ckpt
261050/758000 (epoch 688), train_loss = 0.239, time/batch = 0.029, All_Time = 7697.782
261100/758000 (epoch 688), train_loss = 0.250, time/batch = 0.030, All_Time = 7699.257
261150/758000 (epoch 689), train_loss = 0.221, time/batch = 0.029, All_Time = 7700.739
261200/758000 (epoch 689), train_loss = 0.219, time/batch = 0.029, All_Time = 7702.205
261250/758000 (epoch 689), train_loss = 0.246, time/batch = 0.028, All_Time = 7703.669
261300/758000 (epoch 689), train_loss = 0.262, time/batch = 0.030, All_Time = 7705.137
261350/758000 (epoch 689), train_loss = 0.260, time/batch = 0.029, All_Time = 7706.602
261400/758000 (epoch 689), train_loss = 0.241, time/batch = 0.033, All_Time = 7708.086
261450/758000 (epoch 689), train_loss = 0.210, time/batch = 0.029, All_Time = 7709.579
261500/758000 (epoch 689), train_loss = 0.239, time/batch = 0.030, All_Time = 7711.070
261550/758000 (epoch 690), train_loss = 0.230, time/batch = 0.030, All_Time = 7712.555
261600/758000 (epoch 690), train_loss = 0.226, time/batch = 0.029, All_Time = 7714.033
261650/758000 (epoch 690), train_loss = 0.264, time/batch = 0.029, All_Time = 7715.495
261700/758000 (epoch 690), train_loss = 0.240, time/batch = 0.029, All_Time = 7716.952
261750/758000 (epoch 690), train_loss = 0.253, time/batch = 0.029, All_Time = 7718.426
261800/758000 (epoch 690), train_loss = 0.251, time/batch = 0.030, All_Time = 7719.891
261850/758000 (epoch 690), train_loss = 0.248, time/batch = 0.031, All_Time = 7721.372
261900/758000 (epoch 691), train_loss = 0.216, time/batch = 0.030, All_Time = 7722.853
261950/758000 (epoch 691), train_loss = 0.233, time/batch = 0.030, All_Time = 7724.315
262000/758000 (epoch 691), train_loss = 0.250, time/batch = 0.030, All_Time = 7725.806
model saved to NER/polyglot/model.ckpt
262050/758000 (epoch 691), train_loss = 0.241, time/batch = 0.030, All_Time = 7727.276
262100/758000 (epoch 691), train_loss = 0.243, time/batch = 0.029, All_Time = 7728.752
262150/758000 (epoch 691), train_loss = 0.242, time/batch = 0.029, All_Time = 7730.229
262200/758000 (epoch 691), train_loss = 0.230, time/batch = 0.029, All_Time = 7731.707
262250/758000 (epoch 691), train_loss = 0.259, time/batch = 0.029, All_Time = 7733.182
262300/758000 (epoch 692), train_loss = 0.250, time/batch = 0.028, All_Time = 7734.663
262350/758000 (epoch 692), train_loss = 0.253, time/batch = 0.030, All_Time = 7736.139
262400/758000 (epoch 692), train_loss = 0.245, time/batch = 0.029, All_Time = 7737.617
262450/758000 (epoch 692), train_loss = 0.231, time/batch = 0.029, All_Time = 7739.079
262500/758000 (epoch 692), train_loss = 0.228, time/batch = 0.029, All_Time = 7740.553
262550/758000 (epoch 692), train_loss = 0.238, time/batch = 0.029, All_Time = 7742.021
262600/758000 (epoch 692), train_loss = 0.268, time/batch = 0.031, All_Time = 7743.525
262650/758000 (epoch 693), train_loss = 0.248, time/batch = 0.029, All_Time = 7745.011
262700/758000 (epoch 693), train_loss = 0.280, time/batch = 0.029, All_Time = 7746.488
262750/758000 (epoch 693), train_loss = 0.242, time/batch = 0.030, All_Time = 7747.958
262800/758000 (epoch 693), train_loss = 0.258, time/batch = 0.029, All_Time = 7749.439
262850/758000 (epoch 693), train_loss = 0.224, time/batch = 0.031, All_Time = 7750.934
262900/758000 (epoch 693), train_loss = 0.243, time/batch = 0.030, All_Time = 7752.428
262950/758000 (epoch 693), train_loss = 0.219, time/batch = 0.030, All_Time = 7753.906
263000/758000 (epoch 693), train_loss = 0.232, time/batch = 0.029, All_Time = 7755.384
model saved to NER/polyglot/model.ckpt
263050/758000 (epoch 694), train_loss = 0.237, time/batch = 0.029, All_Time = 7756.864
263100/758000 (epoch 694), train_loss = 0.239, time/batch = 0.028, All_Time = 7758.327
263150/758000 (epoch 694), train_loss = 0.293, time/batch = 0.029, All_Time = 7759.789
263200/758000 (epoch 694), train_loss = 0.318, time/batch = 0.028, All_Time = 7761.256
263250/758000 (epoch 694), train_loss = 0.196, time/batch = 0.030, All_Time = 7762.744
263300/758000 (epoch 694), train_loss = 0.213, time/batch = 0.030, All_Time = 7764.211
263350/758000 (epoch 694), train_loss = 0.250, time/batch = 0.028, All_Time = 7765.699
263400/758000 (epoch 694), train_loss = 0.297, time/batch = 0.029, All_Time = 7767.192
263450/758000 (epoch 695), train_loss = 0.226, time/batch = 0.029, All_Time = 7768.679
263500/758000 (epoch 695), train_loss = 0.259, time/batch = 0.029, All_Time = 7770.148
263550/758000 (epoch 695), train_loss = 0.223, time/batch = 0.028, All_Time = 7771.612
263600/758000 (epoch 695), train_loss = 0.239, time/batch = 0.031, All_Time = 7773.075
263650/758000 (epoch 695), train_loss = 0.212, time/batch = 0.028, All_Time = 7774.540
263700/758000 (epoch 695), train_loss = 0.243, time/batch = 0.029, All_Time = 7776.010
263750/758000 (epoch 695), train_loss = 0.215, time/batch = 0.029, All_Time = 7777.487
263800/758000 (epoch 696), train_loss = 0.228, time/batch = 0.029, All_Time = 7778.974
263850/758000 (epoch 696), train_loss = 0.252, time/batch = 0.029, All_Time = 7780.439
263900/758000 (epoch 696), train_loss = 0.260, time/batch = 0.029, All_Time = 7781.914
263950/758000 (epoch 696), train_loss = 0.228, time/batch = 0.030, All_Time = 7783.404
264000/758000 (epoch 696), train_loss = 0.236, time/batch = 0.031, All_Time = 7784.905
model saved to NER/polyglot/model.ckpt
264050/758000 (epoch 696), train_loss = 0.271, time/batch = 0.031, All_Time = 7786.394
264100/758000 (epoch 696), train_loss = 0.238, time/batch = 0.030, All_Time = 7787.875
264150/758000 (epoch 696), train_loss = 0.268, time/batch = 0.029, All_Time = 7789.353
264200/758000 (epoch 697), train_loss = 0.248, time/batch = 0.029, All_Time = 7790.828
264250/758000 (epoch 697), train_loss = 0.249, time/batch = 0.031, All_Time = 7792.308
264300/758000 (epoch 697), train_loss = 0.240, time/batch = 0.029, All_Time = 7793.783
264350/758000 (epoch 697), train_loss = 0.247, time/batch = 0.028, All_Time = 7795.252
264400/758000 (epoch 697), train_loss = 0.235, time/batch = 0.029, All_Time = 7796.722
264450/758000 (epoch 697), train_loss = 0.247, time/batch = 0.030, All_Time = 7798.223
264500/758000 (epoch 697), train_loss = 0.251, time/batch = 0.031, All_Time = 7799.731
264550/758000 (epoch 698), train_loss = 0.242, time/batch = 0.030, All_Time = 7801.239
264600/758000 (epoch 698), train_loss = 0.276, time/batch = 0.029, All_Time = 7802.716
264650/758000 (epoch 698), train_loss = 0.256, time/batch = 0.028, All_Time = 7804.185
264700/758000 (epoch 698), train_loss = 0.258, time/batch = 0.030, All_Time = 7805.656
264750/758000 (epoch 698), train_loss = 0.213, time/batch = 0.029, All_Time = 7807.122
264800/758000 (epoch 698), train_loss = 0.237, time/batch = 0.030, All_Time = 7808.588
264850/758000 (epoch 698), train_loss = 0.249, time/batch = 0.030, All_Time = 7810.062
264900/758000 (epoch 698), train_loss = 0.251, time/batch = 0.031, All_Time = 7811.551
264950/758000 (epoch 699), train_loss = 0.232, time/batch = 0.030, All_Time = 7813.055
265000/758000 (epoch 699), train_loss = 0.255, time/batch = 0.029, All_Time = 7814.526
model saved to NER/polyglot/model.ckpt
265050/758000 (epoch 699), train_loss = 0.265, time/batch = 0.031, All_Time = 7815.978
265100/758000 (epoch 699), train_loss = 0.229, time/batch = 0.030, All_Time = 7817.443
265150/758000 (epoch 699), train_loss = 0.263, time/batch = 0.031, All_Time = 7818.942
265200/758000 (epoch 699), train_loss = 0.217, time/batch = 0.029, All_Time = 7820.408
265250/758000 (epoch 699), train_loss = 0.248, time/batch = 0.029, All_Time = 7821.874
265300/758000 (epoch 700), train_loss = 0.059, time/batch = 0.037, All_Time = 7823.346
265350/758000 (epoch 700), train_loss = 0.250, time/batch = 0.030, All_Time = 7824.803
265400/758000 (epoch 700), train_loss = 0.223, time/batch = 0.031, All_Time = 7826.266
265450/758000 (epoch 700), train_loss = 0.250, time/batch = 0.030, All_Time = 7827.731
265500/758000 (epoch 700), train_loss = 0.231, time/batch = 0.029, All_Time = 7829.228
265550/758000 (epoch 700), train_loss = 0.250, time/batch = 0.029, All_Time = 7830.719
265600/758000 (epoch 700), train_loss = 0.232, time/batch = 0.030, All_Time = 7832.197
265650/758000 (epoch 700), train_loss = 0.230, time/batch = 0.029, All_Time = 7833.676
265700/758000 (epoch 701), train_loss = 0.224, time/batch = 0.029, All_Time = 7835.159
265750/758000 (epoch 701), train_loss = 0.233, time/batch = 0.029, All_Time = 7836.622
265800/758000 (epoch 701), train_loss = 0.224, time/batch = 0.029, All_Time = 7838.087
265850/758000 (epoch 701), train_loss = 0.262, time/batch = 0.028, All_Time = 7839.553
265900/758000 (epoch 701), train_loss = 0.220, time/batch = 0.030, All_Time = 7841.018
265950/758000 (epoch 701), train_loss = 0.228, time/batch = 0.030, All_Time = 7842.488
266000/758000 (epoch 701), train_loss = 0.280, time/batch = 0.029, All_Time = 7843.965
model saved to NER/polyglot/model.ckpt
266050/758000 (epoch 701), train_loss = 0.272, time/batch = 0.030, All_Time = 7845.481
266100/758000 (epoch 702), train_loss = 0.230, time/batch = 0.031, All_Time = 7846.968
266150/758000 (epoch 702), train_loss = 0.224, time/batch = 0.030, All_Time = 7848.446
266200/758000 (epoch 702), train_loss = 0.201, time/batch = 0.029, All_Time = 7849.920
266250/758000 (epoch 702), train_loss = 0.270, time/batch = 0.030, All_Time = 7851.393
266300/758000 (epoch 702), train_loss = 0.259, time/batch = 0.029, All_Time = 7852.863
266350/758000 (epoch 702), train_loss = 0.209, time/batch = 0.029, All_Time = 7854.334
266400/758000 (epoch 702), train_loss = 0.218, time/batch = 0.031, All_Time = 7855.805
266450/758000 (epoch 703), train_loss = 0.229, time/batch = 0.029, All_Time = 7857.300
266500/758000 (epoch 703), train_loss = 0.283, time/batch = 0.029, All_Time = 7858.782
266550/758000 (epoch 703), train_loss = 0.231, time/batch = 0.031, All_Time = 7860.265
266600/758000 (epoch 703), train_loss = 0.307, time/batch = 0.030, All_Time = 7861.751
266650/758000 (epoch 703), train_loss = 0.221, time/batch = 0.029, All_Time = 7863.242
266700/758000 (epoch 703), train_loss = 0.208, time/batch = 0.030, All_Time = 7864.731
266750/758000 (epoch 703), train_loss = 0.247, time/batch = 0.028, All_Time = 7866.200
266800/758000 (epoch 703), train_loss = 0.252, time/batch = 0.028, All_Time = 7867.673
266850/758000 (epoch 704), train_loss = 0.264, time/batch = 0.029, All_Time = 7869.160
266900/758000 (epoch 704), train_loss = 0.229, time/batch = 0.030, All_Time = 7870.626
266950/758000 (epoch 704), train_loss = 0.242, time/batch = 0.030, All_Time = 7872.139
267000/758000 (epoch 704), train_loss = 0.267, time/batch = 0.029, All_Time = 7873.621
model saved to NER/polyglot/model.ckpt
267050/758000 (epoch 704), train_loss = 0.249, time/batch = 0.029, All_Time = 7875.105
267100/758000 (epoch 704), train_loss = 0.237, time/batch = 0.030, All_Time = 7876.583
267150/758000 (epoch 704), train_loss = 0.276, time/batch = 0.030, All_Time = 7878.067
267200/758000 (epoch 705), train_loss = 0.256, time/batch = 0.031, All_Time = 7879.542
267250/758000 (epoch 705), train_loss = 0.222, time/batch = 0.030, All_Time = 7880.996
267300/758000 (epoch 705), train_loss = 0.266, time/batch = 0.029, All_Time = 7882.461
267350/758000 (epoch 705), train_loss = 0.216, time/batch = 0.029, All_Time = 7883.938
267400/758000 (epoch 705), train_loss = 0.223, time/batch = 0.031, All_Time = 7885.413
267450/758000 (epoch 705), train_loss = 0.261, time/batch = 0.029, All_Time = 7886.887
267500/758000 (epoch 705), train_loss = 0.238, time/batch = 0.028, All_Time = 7888.360
267550/758000 (epoch 705), train_loss = 0.264, time/batch = 0.030, All_Time = 7889.838
267600/758000 (epoch 706), train_loss = 0.223, time/batch = 0.028, All_Time = 7891.334
267650/758000 (epoch 706), train_loss = 0.231, time/batch = 0.029, All_Time = 7892.805
267700/758000 (epoch 706), train_loss = 0.238, time/batch = 0.030, All_Time = 7894.290
267750/758000 (epoch 706), train_loss = 0.266, time/batch = 0.030, All_Time = 7895.765
267800/758000 (epoch 706), train_loss = 0.239, time/batch = 0.029, All_Time = 7897.239
267850/758000 (epoch 706), train_loss = 0.226, time/batch = 0.029, All_Time = 7898.718
267900/758000 (epoch 706), train_loss = 0.276, time/batch = 0.030, All_Time = 7900.196
267950/758000 (epoch 706), train_loss = 0.240, time/batch = 0.030, All_Time = 7901.661
268000/758000 (epoch 707), train_loss = 0.281, time/batch = 0.030, All_Time = 7903.148
model saved to NER/polyglot/model.ckpt
268050/758000 (epoch 707), train_loss = 0.257, time/batch = 0.029, All_Time = 7904.618
268100/758000 (epoch 707), train_loss = 0.240, time/batch = 0.029, All_Time = 7906.082
268150/758000 (epoch 707), train_loss = 0.231, time/batch = 0.029, All_Time = 7907.552
268200/758000 (epoch 707), train_loss = 0.217, time/batch = 0.031, All_Time = 7909.025
268250/758000 (epoch 707), train_loss = 0.224, time/batch = 0.029, All_Time = 7910.503
268300/758000 (epoch 707), train_loss = 0.215, time/batch = 0.031, All_Time = 7911.990
268350/758000 (epoch 708), train_loss = 0.249, time/batch = 0.031, All_Time = 7913.475
268400/758000 (epoch 708), train_loss = 0.211, time/batch = 0.029, All_Time = 7914.951
268450/758000 (epoch 708), train_loss = 0.245, time/batch = 0.029, All_Time = 7916.436
268500/758000 (epoch 708), train_loss = 0.217, time/batch = 0.029, All_Time = 7917.907
268550/758000 (epoch 708), train_loss = 0.233, time/batch = 0.030, All_Time = 7919.400
268600/758000 (epoch 708), train_loss = 0.228, time/batch = 0.030, All_Time = 7920.882
268650/758000 (epoch 708), train_loss = 0.248, time/batch = 0.029, All_Time = 7922.358
268700/758000 (epoch 708), train_loss = 0.229, time/batch = 0.029, All_Time = 7923.835
268750/758000 (epoch 709), train_loss = 0.218, time/batch = 0.030, All_Time = 7925.322
268800/758000 (epoch 709), train_loss = 0.237, time/batch = 0.029, All_Time = 7926.783
268850/758000 (epoch 709), train_loss = 0.212, time/batch = 0.029, All_Time = 7928.257
268900/758000 (epoch 709), train_loss = 0.266, time/batch = 0.029, All_Time = 7929.739
268950/758000 (epoch 709), train_loss = 0.255, time/batch = 0.029, All_Time = 7931.247
269000/758000 (epoch 709), train_loss = 0.232, time/batch = 0.029, All_Time = 7932.732
model saved to NER/polyglot/model.ckpt
269050/758000 (epoch 709), train_loss = 0.262, time/batch = 0.028, All_Time = 7934.210
269100/758000 (epoch 710), train_loss = 0.282, time/batch = 0.028, All_Time = 7935.683
269150/758000 (epoch 710), train_loss = 0.292, time/batch = 0.031, All_Time = 7937.141
269200/758000 (epoch 710), train_loss = 0.253, time/batch = 0.030, All_Time = 7938.641
269250/758000 (epoch 710), train_loss = 0.222, time/batch = 0.029, All_Time = 7940.137
269300/758000 (epoch 710), train_loss = 0.221, time/batch = 0.029, All_Time = 7941.634
269350/758000 (epoch 710), train_loss = 0.260, time/batch = 0.030, All_Time = 7943.115
269400/758000 (epoch 710), train_loss = 0.244, time/batch = 0.031, All_Time = 7944.586
269450/758000 (epoch 710), train_loss = 0.247, time/batch = 0.029, All_Time = 7946.056
269500/758000 (epoch 711), train_loss = 0.210, time/batch = 0.030, All_Time = 7947.540
269550/758000 (epoch 711), train_loss = 0.265, time/batch = 0.029, All_Time = 7949.005
269600/758000 (epoch 711), train_loss = 0.229, time/batch = 0.029, All_Time = 7950.471
269650/758000 (epoch 711), train_loss = 0.232, time/batch = 0.028, All_Time = 7951.936
269700/758000 (epoch 711), train_loss = 0.230, time/batch = 0.031, All_Time = 7953.424
269750/758000 (epoch 711), train_loss = 0.253, time/batch = 0.028, All_Time = 7954.938
269800/758000 (epoch 711), train_loss = 0.258, time/batch = 0.030, All_Time = 7956.422
269850/758000 (epoch 712), train_loss = 0.196, time/batch = 0.031, All_Time = 7957.913
269900/758000 (epoch 712), train_loss = 0.254, time/batch = 0.029, All_Time = 7959.393
269950/758000 (epoch 712), train_loss = 0.281, time/batch = 0.029, All_Time = 7960.861
270000/758000 (epoch 712), train_loss = 0.235, time/batch = 0.030, All_Time = 7962.330
model saved to NER/polyglot/model.ckpt
270050/758000 (epoch 712), train_loss = 0.247, time/batch = 0.028, All_Time = 7963.802
270100/758000 (epoch 712), train_loss = 0.251, time/batch = 0.030, All_Time = 7965.273
270150/758000 (epoch 712), train_loss = 0.203, time/batch = 0.030, All_Time = 7966.751
270200/758000 (epoch 712), train_loss = 0.268, time/batch = 0.028, All_Time = 7968.246
270250/758000 (epoch 713), train_loss = 0.233, time/batch = 0.030, All_Time = 7969.728
270300/758000 (epoch 713), train_loss = 0.241, time/batch = 0.030, All_Time = 7971.206
270350/758000 (epoch 713), train_loss = 0.252, time/batch = 0.029, All_Time = 7972.672
270400/758000 (epoch 713), train_loss = 0.258, time/batch = 0.029, All_Time = 7974.137
270450/758000 (epoch 713), train_loss = 0.243, time/batch = 0.030, All_Time = 7975.618
270500/758000 (epoch 713), train_loss = 0.243, time/batch = 0.032, All_Time = 7977.088
270550/758000 (epoch 713), train_loss = 0.244, time/batch = 0.030, All_Time = 7978.592
270600/758000 (epoch 713), train_loss = 0.286, time/batch = 0.031, All_Time = 7980.080
270650/758000 (epoch 714), train_loss = 0.207, time/batch = 0.030, All_Time = 7981.566
270700/758000 (epoch 714), train_loss = 0.244, time/batch = 0.029, All_Time = 7983.029
270750/758000 (epoch 714), train_loss = 0.217, time/batch = 0.029, All_Time = 7984.496
270800/758000 (epoch 714), train_loss = 0.233, time/batch = 0.030, All_Time = 7985.969
270850/758000 (epoch 714), train_loss = 0.260, time/batch = 0.030, All_Time = 7987.455
270900/758000 (epoch 714), train_loss = 0.253, time/batch = 0.029, All_Time = 7988.963
270950/758000 (epoch 714), train_loss = 0.238, time/batch = 0.031, All_Time = 7990.432
271000/758000 (epoch 715), train_loss = 0.227, time/batch = 0.030, All_Time = 7991.906
model saved to NER/polyglot/model.ckpt
271050/758000 (epoch 715), train_loss = 0.250, time/batch = 0.029, All_Time = 7993.373
271100/758000 (epoch 715), train_loss = 0.250, time/batch = 0.028, All_Time = 7994.821
271150/758000 (epoch 715), train_loss = 0.223, time/batch = 0.030, All_Time = 7996.283
271200/758000 (epoch 715), train_loss = 0.240, time/batch = 0.029, All_Time = 7997.744
271250/758000 (epoch 715), train_loss = 0.246, time/batch = 0.029, All_Time = 7999.221
271300/758000 (epoch 715), train_loss = 0.246, time/batch = 0.030, All_Time = 8000.696
271350/758000 (epoch 715), train_loss = 0.257, time/batch = 0.029, All_Time = 8002.167
271400/758000 (epoch 716), train_loss = 0.266, time/batch = 0.030, All_Time = 8003.667
271450/758000 (epoch 716), train_loss = 0.224, time/batch = 0.028, All_Time = 8005.139
271500/758000 (epoch 716), train_loss = 0.248, time/batch = 0.030, All_Time = 8006.600
271550/758000 (epoch 716), train_loss = 0.227, time/batch = 0.031, All_Time = 8008.061
271600/758000 (epoch 716), train_loss = 0.279, time/batch = 0.029, All_Time = 8009.526
271650/758000 (epoch 716), train_loss = 0.255, time/batch = 0.029, All_Time = 8010.999
271700/758000 (epoch 716), train_loss = 0.253, time/batch = 0.028, All_Time = 8012.465
271750/758000 (epoch 717), train_loss = 0.244, time/batch = 0.030, All_Time = 8013.960
271800/758000 (epoch 717), train_loss = 0.247, time/batch = 0.029, All_Time = 8015.426
271850/758000 (epoch 717), train_loss = 0.270, time/batch = 0.030, All_Time = 8016.899
271900/758000 (epoch 717), train_loss = 0.246, time/batch = 0.030, All_Time = 8018.365
271950/758000 (epoch 717), train_loss = 0.237, time/batch = 0.030, All_Time = 8019.852
272000/758000 (epoch 717), train_loss = 0.224, time/batch = 0.029, All_Time = 8021.362
model saved to NER/polyglot/model.ckpt
272050/758000 (epoch 717), train_loss = 0.229, time/batch = 0.027, All_Time = 8022.839
272100/758000 (epoch 717), train_loss = 0.246, time/batch = 0.029, All_Time = 8024.309
272150/758000 (epoch 718), train_loss = 0.249, time/batch = 0.031, All_Time = 8025.786
272200/758000 (epoch 718), train_loss = 0.264, time/batch = 0.029, All_Time = 8027.253
272250/758000 (epoch 718), train_loss = 0.240, time/batch = 0.030, All_Time = 8028.717
272300/758000 (epoch 718), train_loss = 0.250, time/batch = 0.031, All_Time = 8030.226
272350/758000 (epoch 718), train_loss = 0.227, time/batch = 0.029, All_Time = 8031.713
272400/758000 (epoch 718), train_loss = 0.217, time/batch = 0.028, All_Time = 8033.207
272450/758000 (epoch 718), train_loss = 0.277, time/batch = 0.028, All_Time = 8034.680
272500/758000 (epoch 718), train_loss = 0.259, time/batch = 0.030, All_Time = 8036.160
272550/758000 (epoch 719), train_loss = 0.269, time/batch = 0.029, All_Time = 8037.660
272600/758000 (epoch 719), train_loss = 0.296, time/batch = 0.030, All_Time = 8039.150
272650/758000 (epoch 719), train_loss = 0.228, time/batch = 0.029, All_Time = 8040.630
272700/758000 (epoch 719), train_loss = 0.220, time/batch = 0.029, All_Time = 8042.106
272750/758000 (epoch 719), train_loss = 0.257, time/batch = 0.030, All_Time = 8043.580
272800/758000 (epoch 719), train_loss = 0.255, time/batch = 0.030, All_Time = 8045.052
272850/758000 (epoch 719), train_loss = 0.237, time/batch = 0.029, All_Time = 8046.521
272900/758000 (epoch 720), train_loss = 0.225, time/batch = 0.029, All_Time = 8048.000
272950/758000 (epoch 720), train_loss = 0.234, time/batch = 0.030, All_Time = 8049.467
273000/758000 (epoch 720), train_loss = 0.243, time/batch = 0.030, All_Time = 8050.939
model saved to NER/polyglot/model.ckpt
273050/758000 (epoch 720), train_loss = 0.234, time/batch = 0.030, All_Time = 8052.402
273100/758000 (epoch 720), train_loss = 0.223, time/batch = 0.028, All_Time = 8053.866
273150/758000 (epoch 720), train_loss = 0.239, time/batch = 0.030, All_Time = 8055.356
273200/758000 (epoch 720), train_loss = 0.264, time/batch = 0.029, All_Time = 8056.858
273250/758000 (epoch 720), train_loss = 0.244, time/batch = 0.029, All_Time = 8058.348
273300/758000 (epoch 721), train_loss = 0.257, time/batch = 0.030, All_Time = 8059.822
273350/758000 (epoch 721), train_loss = 0.287, time/batch = 0.029, All_Time = 8061.291
273400/758000 (epoch 721), train_loss = 0.255, time/batch = 0.029, All_Time = 8062.757
273450/758000 (epoch 721), train_loss = 0.248, time/batch = 0.030, All_Time = 8064.226
273500/758000 (epoch 721), train_loss = 0.212, time/batch = 0.030, All_Time = 8065.688
273550/758000 (epoch 721), train_loss = 0.229, time/batch = 0.030, All_Time = 8067.164
273600/758000 (epoch 721), train_loss = 0.272, time/batch = 0.029, All_Time = 8068.636
273650/758000 (epoch 722), train_loss = 0.249, time/batch = 0.029, All_Time = 8070.118
273700/758000 (epoch 722), train_loss = 0.227, time/batch = 0.030, All_Time = 8071.579
273750/758000 (epoch 722), train_loss = 0.267, time/batch = 0.029, All_Time = 8073.049
273800/758000 (epoch 722), train_loss = 0.239, time/batch = 0.029, All_Time = 8074.549
273850/758000 (epoch 722), train_loss = 0.247, time/batch = 0.028, All_Time = 8076.040
273900/758000 (epoch 722), train_loss = 0.241, time/batch = 0.029, All_Time = 8077.523
273950/758000 (epoch 722), train_loss = 0.274, time/batch = 0.030, All_Time = 8078.999
274000/758000 (epoch 722), train_loss = 0.279, time/batch = 0.030, All_Time = 8080.489
model saved to NER/polyglot/model.ckpt
274050/758000 (epoch 723), train_loss = 0.238, time/batch = 0.030, All_Time = 8081.991
274100/758000 (epoch 723), train_loss = 0.248, time/batch = 0.031, All_Time = 8083.459
274150/758000 (epoch 723), train_loss = 0.299, time/batch = 0.028, All_Time = 8084.916
274200/758000 (epoch 723), train_loss = 0.230, time/batch = 0.029, All_Time = 8086.394
274250/758000 (epoch 723), train_loss = 0.216, time/batch = 0.031, All_Time = 8087.865
274300/758000 (epoch 723), train_loss = 0.244, time/batch = 0.030, All_Time = 8089.335
274350/758000 (epoch 723), train_loss = 0.274, time/batch = 0.030, All_Time = 8090.813
274400/758000 (epoch 724), train_loss = 0.221, time/batch = 0.030, All_Time = 8092.295
274450/758000 (epoch 724), train_loss = 0.257, time/batch = 0.030, All_Time = 8093.770
274500/758000 (epoch 724), train_loss = 0.241, time/batch = 0.030, All_Time = 8095.250
274550/758000 (epoch 724), train_loss = 0.240, time/batch = 0.029, All_Time = 8096.720
274600/758000 (epoch 724), train_loss = 0.256, time/batch = 0.030, All_Time = 8098.188
274650/758000 (epoch 724), train_loss = 0.219, time/batch = 0.029, All_Time = 8099.665
274700/758000 (epoch 724), train_loss = 0.224, time/batch = 0.029, All_Time = 8101.123
274750/758000 (epoch 724), train_loss = 0.257, time/batch = 0.030, All_Time = 8102.595
274800/758000 (epoch 725), train_loss = 0.255, time/batch = 0.028, All_Time = 8104.128
274850/758000 (epoch 725), train_loss = 0.267, time/batch = 0.029, All_Time = 8105.615
274900/758000 (epoch 725), train_loss = 0.269, time/batch = 0.029, All_Time = 8107.093
274950/758000 (epoch 725), train_loss = 0.228, time/batch = 0.031, All_Time = 8108.571
275000/758000 (epoch 725), train_loss = 0.234, time/batch = 0.031, All_Time = 8110.051
model saved to NER/polyglot/model.ckpt
275050/758000 (epoch 725), train_loss = 0.245, time/batch = 0.029, All_Time = 8111.530
275100/758000 (epoch 725), train_loss = 0.279, time/batch = 0.031, All_Time = 8112.993
275150/758000 (epoch 725), train_loss = 0.240, time/batch = 0.029, All_Time = 8114.466
275200/758000 (epoch 726), train_loss = 0.236, time/batch = 0.029, All_Time = 8115.964
275250/758000 (epoch 726), train_loss = 0.234, time/batch = 0.029, All_Time = 8117.435
275300/758000 (epoch 726), train_loss = 0.233, time/batch = 0.032, All_Time = 8118.907
275350/758000 (epoch 726), train_loss = 0.276, time/batch = 0.029, All_Time = 8120.409
275400/758000 (epoch 726), train_loss = 0.206, time/batch = 0.030, All_Time = 8121.894
275450/758000 (epoch 726), train_loss = 0.259, time/batch = 0.029, All_Time = 8123.387
275500/758000 (epoch 726), train_loss = 0.234, time/batch = 0.029, All_Time = 8124.886
275550/758000 (epoch 727), train_loss = 0.245, time/batch = 0.029, All_Time = 8126.380
275600/758000 (epoch 727), train_loss = 0.223, time/batch = 0.031, All_Time = 8127.859
275650/758000 (epoch 727), train_loss = 0.240, time/batch = 0.030, All_Time = 8129.330
275700/758000 (epoch 727), train_loss = 0.256, time/batch = 0.031, All_Time = 8130.807
275750/758000 (epoch 727), train_loss = 0.214, time/batch = 0.030, All_Time = 8132.280
275800/758000 (epoch 727), train_loss = 0.272, time/batch = 0.030, All_Time = 8133.745
275850/758000 (epoch 727), train_loss = 0.213, time/batch = 0.030, All_Time = 8135.225
275900/758000 (epoch 727), train_loss = 0.251, time/batch = 0.029, All_Time = 8136.744
275950/758000 (epoch 728), train_loss = 0.247, time/batch = 0.029, All_Time = 8138.235
276000/758000 (epoch 728), train_loss = 0.229, time/batch = 0.029, All_Time = 8139.703
model saved to NER/polyglot/model.ckpt
276050/758000 (epoch 728), train_loss = 0.217, time/batch = 0.028, All_Time = 8141.173
276100/758000 (epoch 728), train_loss = 0.220, time/batch = 0.028, All_Time = 8142.642
276150/758000 (epoch 728), train_loss = 0.250, time/batch = 0.031, All_Time = 8144.113
276200/758000 (epoch 728), train_loss = 0.207, time/batch = 0.028, All_Time = 8145.581
276250/758000 (epoch 728), train_loss = 0.268, time/batch = 0.031, All_Time = 8147.094
276300/758000 (epoch 729), train_loss = 0.256, time/batch = 0.031, All_Time = 8148.600
276350/758000 (epoch 729), train_loss = 0.264, time/batch = 0.030, All_Time = 8150.067
276400/758000 (epoch 729), train_loss = 0.284, time/batch = 0.030, All_Time = 8151.538
276450/758000 (epoch 729), train_loss = 0.239, time/batch = 0.029, All_Time = 8153.007
276500/758000 (epoch 729), train_loss = 0.267, time/batch = 0.031, All_Time = 8154.477
276550/758000 (epoch 729), train_loss = 0.256, time/batch = 0.030, All_Time = 8155.946
276600/758000 (epoch 729), train_loss = 0.236, time/batch = 0.031, All_Time = 8157.439
276650/758000 (epoch 729), train_loss = 0.268, time/batch = 0.030, All_Time = 8158.930
276700/758000 (epoch 730), train_loss = 0.226, time/batch = 0.029, All_Time = 8160.423
276750/758000 (epoch 730), train_loss = 0.222, time/batch = 0.030, All_Time = 8161.900
276800/758000 (epoch 730), train_loss = 0.261, time/batch = 0.029, All_Time = 8163.377
276850/758000 (epoch 730), train_loss = 0.254, time/batch = 0.029, All_Time = 8164.849
276900/758000 (epoch 730), train_loss = 0.223, time/batch = 0.029, All_Time = 8166.318
276950/758000 (epoch 730), train_loss = 0.242, time/batch = 0.030, All_Time = 8167.780
277000/758000 (epoch 730), train_loss = 0.251, time/batch = 0.030, All_Time = 8169.249
model saved to NER/polyglot/model.ckpt
277050/758000 (epoch 731), train_loss = 0.192, time/batch = 0.028, All_Time = 8170.723
277100/758000 (epoch 731), train_loss = 0.273, time/batch = 0.030, All_Time = 8172.200
277150/758000 (epoch 731), train_loss = 0.217, time/batch = 0.031, All_Time = 8173.684
277200/758000 (epoch 731), train_loss = 0.240, time/batch = 0.029, All_Time = 8175.192
277250/758000 (epoch 731), train_loss = 0.221, time/batch = 0.028, All_Time = 8176.671
277300/758000 (epoch 731), train_loss = 0.221, time/batch = 0.030, All_Time = 8178.140
277350/758000 (epoch 731), train_loss = 0.252, time/batch = 0.029, All_Time = 8179.609
277400/758000 (epoch 731), train_loss = 0.272, time/batch = 0.030, All_Time = 8181.081
277450/758000 (epoch 732), train_loss = 0.222, time/batch = 0.029, All_Time = 8182.558
277500/758000 (epoch 732), train_loss = 0.279, time/batch = 0.028, All_Time = 8184.025
277550/758000 (epoch 732), train_loss = 0.242, time/batch = 0.029, All_Time = 8185.497
277600/758000 (epoch 732), train_loss = 0.274, time/batch = 0.030, All_Time = 8186.982
277650/758000 (epoch 732), train_loss = 0.262, time/batch = 0.029, All_Time = 8188.442
277700/758000 (epoch 732), train_loss = 0.197, time/batch = 0.029, All_Time = 8189.910
277750/758000 (epoch 732), train_loss = 0.233, time/batch = 0.029, All_Time = 8191.377
277800/758000 (epoch 732), train_loss = 0.281, time/batch = 0.031, All_Time = 8192.883
277850/758000 (epoch 733), train_loss = 0.246, time/batch = 0.028, All_Time = 8194.365
277900/758000 (epoch 733), train_loss = 0.212, time/batch = 0.029, All_Time = 8195.846
277950/758000 (epoch 733), train_loss = 0.255, time/batch = 0.029, All_Time = 8197.323
278000/758000 (epoch 733), train_loss = 0.271, time/batch = 0.029, All_Time = 8198.804
model saved to NER/polyglot/model.ckpt
278050/758000 (epoch 733), train_loss = 0.203, time/batch = 0.030, All_Time = 8200.271
278100/758000 (epoch 733), train_loss = 0.226, time/batch = 0.030, All_Time = 8201.745
278150/758000 (epoch 733), train_loss = 0.254, time/batch = 0.030, All_Time = 8203.219
278200/758000 (epoch 734), train_loss = 0.219, time/batch = 0.030, All_Time = 8204.692
278250/758000 (epoch 734), train_loss = 0.265, time/batch = 0.029, All_Time = 8206.161
278300/758000 (epoch 734), train_loss = 0.227, time/batch = 0.030, All_Time = 8207.667
278350/758000 (epoch 734), train_loss = 0.213, time/batch = 0.030, All_Time = 8209.165
278400/758000 (epoch 734), train_loss = 0.224, time/batch = 0.030, All_Time = 8210.651
278450/758000 (epoch 734), train_loss = 0.213, time/batch = 0.031, All_Time = 8212.136
278500/758000 (epoch 734), train_loss = 0.230, time/batch = 0.028, All_Time = 8213.615
278550/758000 (epoch 734), train_loss = 0.223, time/batch = 0.031, All_Time = 8215.090
278600/758000 (epoch 735), train_loss = 0.275, time/batch = 0.029, All_Time = 8216.590
278650/758000 (epoch 735), train_loss = 0.229, time/batch = 0.028, All_Time = 8218.049
278700/758000 (epoch 735), train_loss = 0.270, time/batch = 0.029, All_Time = 8219.500
278750/758000 (epoch 735), train_loss = 0.273, time/batch = 0.031, All_Time = 8220.975
278800/758000 (epoch 735), train_loss = 0.233, time/batch = 0.030, All_Time = 8222.466
278850/758000 (epoch 735), train_loss = 0.268, time/batch = 0.030, All_Time = 8223.944
278900/758000 (epoch 735), train_loss = 0.280, time/batch = 0.029, All_Time = 8225.424
278950/758000 (epoch 736), train_loss = 0.239, time/batch = 0.028, All_Time = 8226.917
279000/758000 (epoch 736), train_loss = 0.218, time/batch = 0.029, All_Time = 8228.387
model saved to NER/polyglot/model.ckpt
279050/758000 (epoch 736), train_loss = 0.243, time/batch = 0.028, All_Time = 8229.846
279100/758000 (epoch 736), train_loss = 0.244, time/batch = 0.030, All_Time = 8231.315
279150/758000 (epoch 736), train_loss = 0.243, time/batch = 0.030, All_Time = 8232.783
279200/758000 (epoch 736), train_loss = 0.244, time/batch = 0.030, All_Time = 8234.265
279250/758000 (epoch 736), train_loss = 0.213, time/batch = 0.030, All_Time = 8235.761
279300/758000 (epoch 736), train_loss = 0.289, time/batch = 0.030, All_Time = 8237.255
279350/758000 (epoch 737), train_loss = 0.237, time/batch = 0.028, All_Time = 8238.743
279400/758000 (epoch 737), train_loss = 0.246, time/batch = 0.028, All_Time = 8240.215
279450/758000 (epoch 737), train_loss = 0.288, time/batch = 0.031, All_Time = 8241.688
279500/758000 (epoch 737), train_loss = 0.257, time/batch = 0.030, All_Time = 8243.159
279550/758000 (epoch 737), train_loss = 0.218, time/batch = 0.029, All_Time = 8244.622
279600/758000 (epoch 737), train_loss = 0.238, time/batch = 0.031, All_Time = 8246.095
279650/758000 (epoch 737), train_loss = 0.251, time/batch = 0.032, All_Time = 8247.586
279700/758000 (epoch 737), train_loss = 0.251, time/batch = 0.029, All_Time = 8249.080
279750/758000 (epoch 738), train_loss = 0.252, time/batch = 0.030, All_Time = 8250.569
279800/758000 (epoch 738), train_loss = 0.280, time/batch = 0.030, All_Time = 8252.044
279850/758000 (epoch 738), train_loss = 0.242, time/batch = 0.029, All_Time = 8253.525
279900/758000 (epoch 738), train_loss = 0.250, time/batch = 0.031, All_Time = 8255.036
279950/758000 (epoch 738), train_loss = 0.239, time/batch = 0.029, All_Time = 8256.521
280000/758000 (epoch 738), train_loss = 0.239, time/batch = 0.029, All_Time = 8257.997
model saved to NER/polyglot/model.ckpt
280050/758000 (epoch 738), train_loss = 0.250, time/batch = 0.028, All_Time = 8259.461
280100/758000 (epoch 739), train_loss = 0.221, time/batch = 0.030, All_Time = 8260.945
280150/758000 (epoch 739), train_loss = 0.219, time/batch = 0.029, All_Time = 8262.406
280200/758000 (epoch 739), train_loss = 0.246, time/batch = 0.030, All_Time = 8263.872
280250/758000 (epoch 739), train_loss = 0.262, time/batch = 0.028, All_Time = 8265.337
280300/758000 (epoch 739), train_loss = 0.260, time/batch = 0.031, All_Time = 8266.819
280350/758000 (epoch 739), train_loss = 0.241, time/batch = 0.030, All_Time = 8268.296
280400/758000 (epoch 739), train_loss = 0.210, time/batch = 0.030, All_Time = 8269.765
280450/758000 (epoch 739), train_loss = 0.239, time/batch = 0.030, All_Time = 8271.245
280500/758000 (epoch 740), train_loss = 0.230, time/batch = 0.031, All_Time = 8272.733
280550/758000 (epoch 740), train_loss = 0.226, time/batch = 0.031, All_Time = 8274.212
280600/758000 (epoch 740), train_loss = 0.264, time/batch = 0.028, All_Time = 8275.681
280650/758000 (epoch 740), train_loss = 0.240, time/batch = 0.029, All_Time = 8277.159
280700/758000 (epoch 740), train_loss = 0.253, time/batch = 0.029, All_Time = 8278.628
280750/758000 (epoch 740), train_loss = 0.251, time/batch = 0.030, All_Time = 8280.106
280800/758000 (epoch 740), train_loss = 0.248, time/batch = 0.030, All_Time = 8281.596
280850/758000 (epoch 741), train_loss = 0.216, time/batch = 0.030, All_Time = 8283.106
280900/758000 (epoch 741), train_loss = 0.233, time/batch = 0.029, All_Time = 8284.579
280950/758000 (epoch 741), train_loss = 0.250, time/batch = 0.029, All_Time = 8286.048
281000/758000 (epoch 741), train_loss = 0.241, time/batch = 0.029, All_Time = 8287.525
model saved to NER/polyglot/model.ckpt
281050/758000 (epoch 741), train_loss = 0.243, time/batch = 0.030, All_Time = 8288.993
281100/758000 (epoch 741), train_loss = 0.242, time/batch = 0.028, All_Time = 8290.458
281150/758000 (epoch 741), train_loss = 0.230, time/batch = 0.029, All_Time = 8291.917
281200/758000 (epoch 741), train_loss = 0.259, time/batch = 0.029, All_Time = 8293.392
281250/758000 (epoch 742), train_loss = 0.250, time/batch = 0.029, All_Time = 8294.880
281300/758000 (epoch 742), train_loss = 0.253, time/batch = 0.029, All_Time = 8296.353
281350/758000 (epoch 742), train_loss = 0.245, time/batch = 0.029, All_Time = 8297.824
281400/758000 (epoch 742), train_loss = 0.231, time/batch = 0.029, All_Time = 8299.299
281450/758000 (epoch 742), train_loss = 0.228, time/batch = 0.029, All_Time = 8300.768
281500/758000 (epoch 742), train_loss = 0.238, time/batch = 0.029, All_Time = 8302.240
281550/758000 (epoch 742), train_loss = 0.268, time/batch = 0.029, All_Time = 8303.716
281600/758000 (epoch 743), train_loss = 0.248, time/batch = 0.030, All_Time = 8305.205
281650/758000 (epoch 743), train_loss = 0.280, time/batch = 0.029, All_Time = 8306.681
281700/758000 (epoch 743), train_loss = 0.242, time/batch = 0.030, All_Time = 8308.157
281750/758000 (epoch 743), train_loss = 0.258, time/batch = 0.029, All_Time = 8309.638
281800/758000 (epoch 743), train_loss = 0.224, time/batch = 0.029, All_Time = 8311.130
281850/758000 (epoch 743), train_loss = 0.243, time/batch = 0.029, All_Time = 8312.624
281900/758000 (epoch 743), train_loss = 0.219, time/batch = 0.030, All_Time = 8314.121
281950/758000 (epoch 743), train_loss = 0.232, time/batch = 0.030, All_Time = 8315.604
282000/758000 (epoch 744), train_loss = 0.237, time/batch = 0.030, All_Time = 8317.093
model saved to NER/polyglot/model.ckpt
282050/758000 (epoch 744), train_loss = 0.239, time/batch = 0.029, All_Time = 8318.565
282100/758000 (epoch 744), train_loss = 0.293, time/batch = 0.030, All_Time = 8320.040
282150/758000 (epoch 744), train_loss = 0.318, time/batch = 0.029, All_Time = 8321.509
282200/758000 (epoch 744), train_loss = 0.196, time/batch = 0.030, All_Time = 8323.003
282250/758000 (epoch 744), train_loss = 0.213, time/batch = 0.029, All_Time = 8324.476
282300/758000 (epoch 744), train_loss = 0.250, time/batch = 0.028, All_Time = 8325.967
282350/758000 (epoch 744), train_loss = 0.297, time/batch = 0.029, All_Time = 8327.446
282400/758000 (epoch 745), train_loss = 0.226, time/batch = 0.029, All_Time = 8328.920
282450/758000 (epoch 745), train_loss = 0.259, time/batch = 0.030, All_Time = 8330.388
282500/758000 (epoch 745), train_loss = 0.223, time/batch = 0.029, All_Time = 8331.854
282550/758000 (epoch 745), train_loss = 0.239, time/batch = 0.029, All_Time = 8333.314
282600/758000 (epoch 745), train_loss = 0.212, time/batch = 0.030, All_Time = 8334.785
282650/758000 (epoch 745), train_loss = 0.243, time/batch = 0.032, All_Time = 8336.252
282700/758000 (epoch 745), train_loss = 0.215, time/batch = 0.029, All_Time = 8337.762
282750/758000 (epoch 746), train_loss = 0.228, time/batch = 0.028, All_Time = 8339.256
282800/758000 (epoch 746), train_loss = 0.252, time/batch = 0.028, All_Time = 8340.734
282850/758000 (epoch 746), train_loss = 0.260, time/batch = 0.029, All_Time = 8342.204
282900/758000 (epoch 746), train_loss = 0.228, time/batch = 0.031, All_Time = 8343.672
282950/758000 (epoch 746), train_loss = 0.236, time/batch = 0.030, All_Time = 8345.139
283000/758000 (epoch 746), train_loss = 0.271, time/batch = 0.030, All_Time = 8346.615
model saved to NER/polyglot/model.ckpt
283050/758000 (epoch 746), train_loss = 0.238, time/batch = 0.029, All_Time = 8348.085
283100/758000 (epoch 746), train_loss = 0.268, time/batch = 0.028, All_Time = 8349.536
283150/758000 (epoch 747), train_loss = 0.248, time/batch = 0.029, All_Time = 8351.022
283200/758000 (epoch 747), train_loss = 0.249, time/batch = 0.029, All_Time = 8352.489
283250/758000 (epoch 747), train_loss = 0.240, time/batch = 0.030, All_Time = 8353.958
283300/758000 (epoch 747), train_loss = 0.247, time/batch = 0.029, All_Time = 8355.426
283350/758000 (epoch 747), train_loss = 0.235, time/batch = 0.030, All_Time = 8356.924
283400/758000 (epoch 747), train_loss = 0.247, time/batch = 0.028, All_Time = 8358.426
283450/758000 (epoch 747), train_loss = 0.251, time/batch = 0.030, All_Time = 8359.916
283500/758000 (epoch 748), train_loss = 0.242, time/batch = 0.029, All_Time = 8361.417
283550/758000 (epoch 748), train_loss = 0.276, time/batch = 0.029, All_Time = 8362.886
283600/758000 (epoch 748), train_loss = 0.256, time/batch = 0.034, All_Time = 8364.363
283650/758000 (epoch 748), train_loss = 0.258, time/batch = 0.029, All_Time = 8365.838
283700/758000 (epoch 748), train_loss = 0.213, time/batch = 0.031, All_Time = 8367.307
283750/758000 (epoch 748), train_loss = 0.237, time/batch = 0.031, All_Time = 8368.792
283800/758000 (epoch 748), train_loss = 0.249, time/batch = 0.030, All_Time = 8370.266
283850/758000 (epoch 748), train_loss = 0.251, time/batch = 0.028, All_Time = 8371.730
283900/758000 (epoch 749), train_loss = 0.232, time/batch = 0.032, All_Time = 8373.240
283950/758000 (epoch 749), train_loss = 0.255, time/batch = 0.030, All_Time = 8374.727
284000/758000 (epoch 749), train_loss = 0.265, time/batch = 0.030, All_Time = 8376.212
model saved to NER/polyglot/model.ckpt
284050/758000 (epoch 749), train_loss = 0.229, time/batch = 0.031, All_Time = 8377.690
284100/758000 (epoch 749), train_loss = 0.263, time/batch = 0.029, All_Time = 8379.163
284150/758000 (epoch 749), train_loss = 0.217, time/batch = 0.029, All_Time = 8380.637
284200/758000 (epoch 749), train_loss = 0.248, time/batch = 0.031, All_Time = 8382.103
284250/758000 (epoch 750), train_loss = 0.059, time/batch = 0.038, All_Time = 8383.583
284300/758000 (epoch 750), train_loss = 0.250, time/batch = 0.029, All_Time = 8385.064
284350/758000 (epoch 750), train_loss = 0.223, time/batch = 0.029, All_Time = 8386.536
284400/758000 (epoch 750), train_loss = 0.250, time/batch = 0.029, All_Time = 8388.013
284450/758000 (epoch 750), train_loss = 0.231, time/batch = 0.029, All_Time = 8389.488
284500/758000 (epoch 750), train_loss = 0.250, time/batch = 0.031, All_Time = 8390.963
284550/758000 (epoch 750), train_loss = 0.232, time/batch = 0.029, All_Time = 8392.438
284600/758000 (epoch 750), train_loss = 0.230, time/batch = 0.029, All_Time = 8393.908
284650/758000 (epoch 751), train_loss = 0.224, time/batch = 0.028, All_Time = 8395.386
284700/758000 (epoch 751), train_loss = 0.233, time/batch = 0.029, All_Time = 8396.852
284750/758000 (epoch 751), train_loss = 0.224, time/batch = 0.029, All_Time = 8398.362
284800/758000 (epoch 751), train_loss = 0.262, time/batch = 0.030, All_Time = 8399.865
284850/758000 (epoch 751), train_loss = 0.220, time/batch = 0.030, All_Time = 8401.341
284900/758000 (epoch 751), train_loss = 0.228, time/batch = 0.030, All_Time = 8402.826
284950/758000 (epoch 751), train_loss = 0.280, time/batch = 0.030, All_Time = 8404.309
285000/758000 (epoch 751), train_loss = 0.272, time/batch = 0.030, All_Time = 8405.780
model saved to NER/polyglot/model.ckpt
285050/758000 (epoch 752), train_loss = 0.230, time/batch = 0.029, All_Time = 8407.271
285100/758000 (epoch 752), train_loss = 0.224, time/batch = 0.029, All_Time = 8408.724
285150/758000 (epoch 752), train_loss = 0.201, time/batch = 0.030, All_Time = 8410.188
285200/758000 (epoch 752), train_loss = 0.270, time/batch = 0.029, All_Time = 8411.655
285250/758000 (epoch 752), train_loss = 0.259, time/batch = 0.031, All_Time = 8413.131
285300/758000 (epoch 752), train_loss = 0.209, time/batch = 0.030, All_Time = 8414.639
285350/758000 (epoch 752), train_loss = 0.218, time/batch = 0.029, All_Time = 8416.108
285400/758000 (epoch 753), train_loss = 0.229, time/batch = 0.029, All_Time = 8417.594
285450/758000 (epoch 753), train_loss = 0.283, time/batch = 0.030, All_Time = 8419.054
285500/758000 (epoch 753), train_loss = 0.231, time/batch = 0.031, All_Time = 8420.530
285550/758000 (epoch 753), train_loss = 0.307, time/batch = 0.027, All_Time = 8422.002
285600/758000 (epoch 753), train_loss = 0.221, time/batch = 0.031, All_Time = 8423.491
285650/758000 (epoch 753), train_loss = 0.208, time/batch = 0.030, All_Time = 8424.990
285700/758000 (epoch 753), train_loss = 0.247, time/batch = 0.031, All_Time = 8426.469
285750/758000 (epoch 753), train_loss = 0.252, time/batch = 0.031, All_Time = 8427.952
285800/758000 (epoch 754), train_loss = 0.264, time/batch = 0.029, All_Time = 8429.436
285850/758000 (epoch 754), train_loss = 0.229, time/batch = 0.029, All_Time = 8430.912
285900/758000 (epoch 754), train_loss = 0.242, time/batch = 0.028, All_Time = 8432.375
285950/758000 (epoch 754), train_loss = 0.267, time/batch = 0.029, All_Time = 8433.838
286000/758000 (epoch 754), train_loss = 0.249, time/batch = 0.028, All_Time = 8435.304
model saved to NER/polyglot/model.ckpt
286050/758000 (epoch 754), train_loss = 0.237, time/batch = 0.030, All_Time = 8436.780
286100/758000 (epoch 754), train_loss = 0.276, time/batch = 0.029, All_Time = 8438.258
286150/758000 (epoch 755), train_loss = 0.256, time/batch = 0.029, All_Time = 8439.742
286200/758000 (epoch 755), train_loss = 0.222, time/batch = 0.030, All_Time = 8441.262
286250/758000 (epoch 755), train_loss = 0.266, time/batch = 0.029, All_Time = 8442.751
286300/758000 (epoch 755), train_loss = 0.216, time/batch = 0.030, All_Time = 8444.238
286350/758000 (epoch 755), train_loss = 0.223, time/batch = 0.029, All_Time = 8445.715
286400/758000 (epoch 755), train_loss = 0.261, time/batch = 0.031, All_Time = 8447.188
286450/758000 (epoch 755), train_loss = 0.238, time/batch = 0.030, All_Time = 8448.655
286500/758000 (epoch 755), train_loss = 0.264, time/batch = 0.030, All_Time = 8450.152
286550/758000 (epoch 756), train_loss = 0.223, time/batch = 0.028, All_Time = 8451.629
286600/758000 (epoch 756), train_loss = 0.231, time/batch = 0.029, All_Time = 8453.108
286650/758000 (epoch 756), train_loss = 0.238, time/batch = 0.029, All_Time = 8454.583
286700/758000 (epoch 756), train_loss = 0.266, time/batch = 0.031, All_Time = 8456.058
286750/758000 (epoch 756), train_loss = 0.239, time/batch = 0.031, All_Time = 8457.557
286800/758000 (epoch 756), train_loss = 0.226, time/batch = 0.029, All_Time = 8459.044
286850/758000 (epoch 756), train_loss = 0.276, time/batch = 0.029, All_Time = 8460.535
286900/758000 (epoch 756), train_loss = 0.240, time/batch = 0.029, All_Time = 8462.021
286950/758000 (epoch 757), train_loss = 0.281, time/batch = 0.028, All_Time = 8463.512
287000/758000 (epoch 757), train_loss = 0.257, time/batch = 0.029, All_Time = 8464.979
model saved to NER/polyglot/model.ckpt
287050/758000 (epoch 757), train_loss = 0.240, time/batch = 0.029, All_Time = 8466.455
287100/758000 (epoch 757), train_loss = 0.231, time/batch = 0.029, All_Time = 8467.926
287150/758000 (epoch 757), train_loss = 0.217, time/batch = 0.029, All_Time = 8469.389
287200/758000 (epoch 757), train_loss = 0.224, time/batch = 0.029, All_Time = 8470.884
287250/758000 (epoch 757), train_loss = 0.215, time/batch = 0.028, All_Time = 8472.388
287300/758000 (epoch 758), train_loss = 0.249, time/batch = 0.029, All_Time = 8473.876
287350/758000 (epoch 758), train_loss = 0.211, time/batch = 0.029, All_Time = 8475.344
287400/758000 (epoch 758), train_loss = 0.245, time/batch = 0.029, All_Time = 8476.813
287450/758000 (epoch 758), train_loss = 0.217, time/batch = 0.029, All_Time = 8478.284
287500/758000 (epoch 758), train_loss = 0.233, time/batch = 0.030, All_Time = 8479.757
287550/758000 (epoch 758), train_loss = 0.228, time/batch = 0.030, All_Time = 8481.224
287600/758000 (epoch 758), train_loss = 0.248, time/batch = 0.031, All_Time = 8482.698
287650/758000 (epoch 758), train_loss = 0.229, time/batch = 0.030, All_Time = 8484.216
287700/758000 (epoch 759), train_loss = 0.218, time/batch = 0.030, All_Time = 8485.721
287750/758000 (epoch 759), train_loss = 0.237, time/batch = 0.030, All_Time = 8487.197
287800/758000 (epoch 759), train_loss = 0.212, time/batch = 0.029, All_Time = 8488.681
287850/758000 (epoch 759), train_loss = 0.266, time/batch = 0.029, All_Time = 8490.157
287900/758000 (epoch 759), train_loss = 0.255, time/batch = 0.030, All_Time = 8491.651
287950/758000 (epoch 759), train_loss = 0.232, time/batch = 0.030, All_Time = 8493.133
288000/758000 (epoch 759), train_loss = 0.262, time/batch = 0.029, All_Time = 8494.613
model saved to NER/polyglot/model.ckpt
288050/758000 (epoch 760), train_loss = 0.282, time/batch = 0.029, All_Time = 8496.105
288100/758000 (epoch 760), train_loss = 0.292, time/batch = 0.030, All_Time = 8497.581
288150/758000 (epoch 760), train_loss = 0.253, time/batch = 0.029, All_Time = 8499.047
288200/758000 (epoch 760), train_loss = 0.222, time/batch = 0.030, All_Time = 8500.508
288250/758000 (epoch 760), train_loss = 0.221, time/batch = 0.030, All_Time = 8501.995
288300/758000 (epoch 760), train_loss = 0.260, time/batch = 0.032, All_Time = 8503.502
288350/758000 (epoch 760), train_loss = 0.244, time/batch = 0.030, All_Time = 8504.981
288400/758000 (epoch 760), train_loss = 0.247, time/batch = 0.027, All_Time = 8506.456
288450/758000 (epoch 761), train_loss = 0.210, time/batch = 0.030, All_Time = 8507.941
288500/758000 (epoch 761), train_loss = 0.265, time/batch = 0.031, All_Time = 8509.412
288550/758000 (epoch 761), train_loss = 0.229, time/batch = 0.029, All_Time = 8510.888
288600/758000 (epoch 761), train_loss = 0.232, time/batch = 0.029, All_Time = 8512.357
288650/758000 (epoch 761), train_loss = 0.230, time/batch = 0.030, All_Time = 8513.815
288700/758000 (epoch 761), train_loss = 0.253, time/batch = 0.030, All_Time = 8515.294
288750/758000 (epoch 761), train_loss = 0.258, time/batch = 0.028, All_Time = 8516.779
288800/758000 (epoch 762), train_loss = 0.196, time/batch = 0.030, All_Time = 8518.265
288850/758000 (epoch 762), train_loss = 0.254, time/batch = 0.029, All_Time = 8519.750
288900/758000 (epoch 762), train_loss = 0.281, time/batch = 0.029, All_Time = 8521.231
288950/758000 (epoch 762), train_loss = 0.235, time/batch = 0.028, All_Time = 8522.703
289000/758000 (epoch 762), train_loss = 0.247, time/batch = 0.031, All_Time = 8524.176
model saved to NER/polyglot/model.ckpt
289050/758000 (epoch 762), train_loss = 0.251, time/batch = 0.031, All_Time = 8525.662
289100/758000 (epoch 762), train_loss = 0.203, time/batch = 0.030, All_Time = 8527.151
289150/758000 (epoch 762), train_loss = 0.268, time/batch = 0.029, All_Time = 8528.633
289200/758000 (epoch 763), train_loss = 0.233, time/batch = 0.030, All_Time = 8530.113
289250/758000 (epoch 763), train_loss = 0.241, time/batch = 0.030, All_Time = 8531.597
289300/758000 (epoch 763), train_loss = 0.252, time/batch = 0.030, All_Time = 8533.066
289350/758000 (epoch 763), train_loss = 0.258, time/batch = 0.028, All_Time = 8534.528
289400/758000 (epoch 763), train_loss = 0.243, time/batch = 0.029, All_Time = 8536.002
289450/758000 (epoch 763), train_loss = 0.243, time/batch = 0.031, All_Time = 8537.475
289500/758000 (epoch 763), train_loss = 0.244, time/batch = 0.028, All_Time = 8538.948
289550/758000 (epoch 763), train_loss = 0.286, time/batch = 0.029, All_Time = 8540.425
289600/758000 (epoch 764), train_loss = 0.207, time/batch = 0.029, All_Time = 8541.936
289650/758000 (epoch 764), train_loss = 0.244, time/batch = 0.031, All_Time = 8543.436
289700/758000 (epoch 764), train_loss = 0.217, time/batch = 0.029, All_Time = 8544.928
289750/758000 (epoch 764), train_loss = 0.233, time/batch = 0.029, All_Time = 8546.425
289800/758000 (epoch 764), train_loss = 0.260, time/batch = 0.029, All_Time = 8547.910
289850/758000 (epoch 764), train_loss = 0.253, time/batch = 0.030, All_Time = 8549.405
289900/758000 (epoch 764), train_loss = 0.238, time/batch = 0.029, All_Time = 8550.888
289950/758000 (epoch 765), train_loss = 0.227, time/batch = 0.030, All_Time = 8552.370
290000/758000 (epoch 765), train_loss = 0.250, time/batch = 0.029, All_Time = 8553.839
model saved to NER/polyglot/model.ckpt
290050/758000 (epoch 765), train_loss = 0.250, time/batch = 0.030, All_Time = 8555.309
290100/758000 (epoch 765), train_loss = 0.223, time/batch = 0.030, All_Time = 8556.774
290150/758000 (epoch 765), train_loss = 0.240, time/batch = 0.028, All_Time = 8558.242
290200/758000 (epoch 765), train_loss = 0.246, time/batch = 0.030, All_Time = 8559.750
290250/758000 (epoch 765), train_loss = 0.246, time/batch = 0.028, All_Time = 8561.239
290300/758000 (epoch 765), train_loss = 0.257, time/batch = 0.029, All_Time = 8562.717
290350/758000 (epoch 766), train_loss = 0.266, time/batch = 0.030, All_Time = 8564.196
290400/758000 (epoch 766), train_loss = 0.224, time/batch = 0.029, All_Time = 8565.657
290450/758000 (epoch 766), train_loss = 0.248, time/batch = 0.030, All_Time = 8567.131
290500/758000 (epoch 766), train_loss = 0.227, time/batch = 0.031, All_Time = 8568.593
290550/758000 (epoch 766), train_loss = 0.279, time/batch = 0.030, All_Time = 8570.076
290600/758000 (epoch 766), train_loss = 0.255, time/batch = 0.030, All_Time = 8571.584
290650/758000 (epoch 766), train_loss = 0.253, time/batch = 0.029, All_Time = 8573.067
290700/758000 (epoch 767), train_loss = 0.244, time/batch = 0.030, All_Time = 8574.554
290750/758000 (epoch 767), train_loss = 0.247, time/batch = 0.029, All_Time = 8576.034
290800/758000 (epoch 767), train_loss = 0.270, time/batch = 0.029, All_Time = 8577.512
290850/758000 (epoch 767), train_loss = 0.246, time/batch = 0.030, All_Time = 8578.986
290900/758000 (epoch 767), train_loss = 0.237, time/batch = 0.032, All_Time = 8580.478
290950/758000 (epoch 767), train_loss = 0.224, time/batch = 0.030, All_Time = 8581.960
291000/758000 (epoch 767), train_loss = 0.229, time/batch = 0.032, All_Time = 8583.430
model saved to NER/polyglot/model.ckpt
291050/758000 (epoch 767), train_loss = 0.246, time/batch = 0.030, All_Time = 8584.896
291100/758000 (epoch 768), train_loss = 0.249, time/batch = 0.029, All_Time = 8586.373
291150/758000 (epoch 768), train_loss = 0.264, time/batch = 0.030, All_Time = 8587.834
291200/758000 (epoch 768), train_loss = 0.240, time/batch = 0.031, All_Time = 8589.342
291250/758000 (epoch 768), train_loss = 0.250, time/batch = 0.029, All_Time = 8590.828
291300/758000 (epoch 768), train_loss = 0.227, time/batch = 0.031, All_Time = 8592.306
291350/758000 (epoch 768), train_loss = 0.217, time/batch = 0.030, All_Time = 8593.788
291400/758000 (epoch 768), train_loss = 0.277, time/batch = 0.029, All_Time = 8595.265
291450/758000 (epoch 768), train_loss = 0.259, time/batch = 0.030, All_Time = 8596.753
291500/758000 (epoch 769), train_loss = 0.269, time/batch = 0.031, All_Time = 8598.326
291550/758000 (epoch 769), train_loss = 0.296, time/batch = 0.029, All_Time = 8599.819
291600/758000 (epoch 769), train_loss = 0.228, time/batch = 0.029, All_Time = 8601.289
291650/758000 (epoch 769), train_loss = 0.220, time/batch = 0.028, All_Time = 8602.763
291700/758000 (epoch 769), train_loss = 0.257, time/batch = 0.030, All_Time = 8604.230
291750/758000 (epoch 769), train_loss = 0.255, time/batch = 0.029, All_Time = 8605.704
291800/758000 (epoch 769), train_loss = 0.237, time/batch = 0.031, All_Time = 8607.213
291850/758000 (epoch 770), train_loss = 0.225, time/batch = 0.029, All_Time = 8608.725
291900/758000 (epoch 770), train_loss = 0.234, time/batch = 0.030, All_Time = 8610.188
291950/758000 (epoch 770), train_loss = 0.243, time/batch = 0.029, All_Time = 8611.649
292000/758000 (epoch 770), train_loss = 0.234, time/batch = 0.030, All_Time = 8613.113
model saved to NER/polyglot/model.ckpt
292050/758000 (epoch 770), train_loss = 0.223, time/batch = 0.028, All_Time = 8614.583
292100/758000 (epoch 770), train_loss = 0.239, time/batch = 0.029, All_Time = 8616.058
292150/758000 (epoch 770), train_loss = 0.264, time/batch = 0.031, All_Time = 8617.526
292200/758000 (epoch 770), train_loss = 0.244, time/batch = 0.029, All_Time = 8619.003
292250/758000 (epoch 771), train_loss = 0.257, time/batch = 0.030, All_Time = 8620.488
292300/758000 (epoch 771), train_loss = 0.287, time/batch = 0.030, All_Time = 8621.950
292350/758000 (epoch 771), train_loss = 0.255, time/batch = 0.029, All_Time = 8623.432
292400/758000 (epoch 771), train_loss = 0.248, time/batch = 0.029, All_Time = 8624.919
292450/758000 (epoch 771), train_loss = 0.212, time/batch = 0.031, All_Time = 8626.402
292500/758000 (epoch 771), train_loss = 0.229, time/batch = 0.030, All_Time = 8627.909
292550/758000 (epoch 771), train_loss = 0.272, time/batch = 0.030, All_Time = 8629.392
292600/758000 (epoch 772), train_loss = 0.249, time/batch = 0.031, All_Time = 8630.892
292650/758000 (epoch 772), train_loss = 0.227, time/batch = 0.029, All_Time = 8632.365
292700/758000 (epoch 772), train_loss = 0.267, time/batch = 0.031, All_Time = 8633.842
292750/758000 (epoch 772), train_loss = 0.239, time/batch = 0.031, All_Time = 8635.323
292800/758000 (epoch 772), train_loss = 0.247, time/batch = 0.030, All_Time = 8636.794
292850/758000 (epoch 772), train_loss = 0.241, time/batch = 0.034, All_Time = 8638.262
292900/758000 (epoch 772), train_loss = 0.274, time/batch = 0.029, All_Time = 8639.732
292950/758000 (epoch 772), train_loss = 0.279, time/batch = 0.033, All_Time = 8641.211
293000/758000 (epoch 773), train_loss = 0.238, time/batch = 0.029, All_Time = 8642.680
model saved to NER/polyglot/model.ckpt
293050/758000 (epoch 773), train_loss = 0.248, time/batch = 0.030, All_Time = 8644.148
293100/758000 (epoch 773), train_loss = 0.299, time/batch = 0.029, All_Time = 8645.613
293150/758000 (epoch 773), train_loss = 0.230, time/batch = 0.030, All_Time = 8647.086
293200/758000 (epoch 773), train_loss = 0.216, time/batch = 0.029, All_Time = 8648.570
293250/758000 (epoch 773), train_loss = 0.244, time/batch = 0.029, All_Time = 8650.037
293300/758000 (epoch 773), train_loss = 0.274, time/batch = 0.028, All_Time = 8651.506
293350/758000 (epoch 774), train_loss = 0.221, time/batch = 0.030, All_Time = 8652.991
293400/758000 (epoch 774), train_loss = 0.257, time/batch = 0.030, All_Time = 8654.458
293450/758000 (epoch 774), train_loss = 0.241, time/batch = 0.029, All_Time = 8655.922
293500/758000 (epoch 774), train_loss = 0.240, time/batch = 0.029, All_Time = 8657.396
293550/758000 (epoch 774), train_loss = 0.256, time/batch = 0.030, All_Time = 8658.872
293600/758000 (epoch 774), train_loss = 0.219, time/batch = 0.029, All_Time = 8660.343
293650/758000 (epoch 774), train_loss = 0.224, time/batch = 0.030, All_Time = 8661.816
293700/758000 (epoch 774), train_loss = 0.257, time/batch = 0.029, All_Time = 8663.284
293750/758000 (epoch 775), train_loss = 0.255, time/batch = 0.029, All_Time = 8664.759
293800/758000 (epoch 775), train_loss = 0.267, time/batch = 0.029, All_Time = 8666.230
293850/758000 (epoch 775), train_loss = 0.269, time/batch = 0.029, All_Time = 8667.716
293900/758000 (epoch 775), train_loss = 0.228, time/batch = 0.032, All_Time = 8669.228
293950/758000 (epoch 775), train_loss = 0.234, time/batch = 0.030, All_Time = 8670.712
294000/758000 (epoch 775), train_loss = 0.245, time/batch = 0.029, All_Time = 8672.189
model saved to NER/polyglot/model.ckpt
294050/758000 (epoch 775), train_loss = 0.279, time/batch = 0.028, All_Time = 8673.669
294100/758000 (epoch 775), train_loss = 0.240, time/batch = 0.029, All_Time = 8675.129
294150/758000 (epoch 776), train_loss = 0.236, time/batch = 0.030, All_Time = 8676.598
294200/758000 (epoch 776), train_loss = 0.234, time/batch = 0.029, All_Time = 8678.076
294250/758000 (epoch 776), train_loss = 0.233, time/batch = 0.030, All_Time = 8679.573
294300/758000 (epoch 776), train_loss = 0.276, time/batch = 0.029, All_Time = 8681.051
294350/758000 (epoch 776), train_loss = 0.206, time/batch = 0.030, All_Time = 8682.525
294400/758000 (epoch 776), train_loss = 0.259, time/batch = 0.030, All_Time = 8684.001
294450/758000 (epoch 776), train_loss = 0.234, time/batch = 0.031, All_Time = 8685.483
294500/758000 (epoch 777), train_loss = 0.245, time/batch = 0.029, All_Time = 8686.975
294550/758000 (epoch 777), train_loss = 0.223, time/batch = 0.030, All_Time = 8688.456
294600/758000 (epoch 777), train_loss = 0.240, time/batch = 0.030, All_Time = 8689.918
294650/758000 (epoch 777), train_loss = 0.256, time/batch = 0.028, All_Time = 8691.386
294700/758000 (epoch 777), train_loss = 0.214, time/batch = 0.031, All_Time = 8692.881
294750/758000 (epoch 777), train_loss = 0.272, time/batch = 0.032, All_Time = 8694.384
294800/758000 (epoch 777), train_loss = 0.213, time/batch = 0.031, All_Time = 8695.877
294850/758000 (epoch 777), train_loss = 0.251, time/batch = 0.030, All_Time = 8697.352
294900/758000 (epoch 778), train_loss = 0.247, time/batch = 0.029, All_Time = 8698.837
294950/758000 (epoch 778), train_loss = 0.229, time/batch = 0.031, All_Time = 8700.307
295000/758000 (epoch 778), train_loss = 0.217, time/batch = 0.029, All_Time = 8701.787
model saved to NER/polyglot/model.ckpt
295050/758000 (epoch 778), train_loss = 0.220, time/batch = 0.029, All_Time = 8703.255
295100/758000 (epoch 778), train_loss = 0.250, time/batch = 0.029, All_Time = 8704.719
295150/758000 (epoch 778), train_loss = 0.207, time/batch = 0.029, All_Time = 8706.179
295200/758000 (epoch 778), train_loss = 0.268, time/batch = 0.030, All_Time = 8707.641
295250/758000 (epoch 779), train_loss = 0.256, time/batch = 0.029, All_Time = 8709.129
295300/758000 (epoch 779), train_loss = 0.264, time/batch = 0.030, All_Time = 8710.613
295350/758000 (epoch 779), train_loss = 0.284, time/batch = 0.031, All_Time = 8712.091
295400/758000 (epoch 779), train_loss = 0.239, time/batch = 0.028, All_Time = 8713.567
295450/758000 (epoch 779), train_loss = 0.267, time/batch = 0.030, All_Time = 8715.030
295500/758000 (epoch 779), train_loss = 0.256, time/batch = 0.030, All_Time = 8716.502
295550/758000 (epoch 779), train_loss = 0.236, time/batch = 0.029, All_Time = 8717.983
295600/758000 (epoch 779), train_loss = 0.268, time/batch = 0.029, All_Time = 8719.459
295650/758000 (epoch 780), train_loss = 0.226, time/batch = 0.030, All_Time = 8720.939
295700/758000 (epoch 780), train_loss = 0.222, time/batch = 0.029, All_Time = 8722.418
295750/758000 (epoch 780), train_loss = 0.261, time/batch = 0.029, All_Time = 8723.883
295800/758000 (epoch 780), train_loss = 0.254, time/batch = 0.031, All_Time = 8725.360
295850/758000 (epoch 780), train_loss = 0.223, time/batch = 0.029, All_Time = 8726.828
295900/758000 (epoch 780), train_loss = 0.242, time/batch = 0.029, All_Time = 8728.325
295950/758000 (epoch 780), train_loss = 0.251, time/batch = 0.029, All_Time = 8729.829
296000/758000 (epoch 781), train_loss = 0.192, time/batch = 0.031, All_Time = 8731.324
model saved to NER/polyglot/model.ckpt
296050/758000 (epoch 781), train_loss = 0.273, time/batch = 0.029, All_Time = 8732.786
296100/758000 (epoch 781), train_loss = 0.217, time/batch = 0.030, All_Time = 8734.253
296150/758000 (epoch 781), train_loss = 0.240, time/batch = 0.030, All_Time = 8735.741
296200/758000 (epoch 781), train_loss = 0.221, time/batch = 0.030, All_Time = 8737.226
296250/758000 (epoch 781), train_loss = 0.221, time/batch = 0.030, All_Time = 8738.709
296300/758000 (epoch 781), train_loss = 0.252, time/batch = 0.029, All_Time = 8740.183
296350/758000 (epoch 781), train_loss = 0.272, time/batch = 0.030, All_Time = 8741.648
296400/758000 (epoch 782), train_loss = 0.222, time/batch = 0.030, All_Time = 8743.130
296450/758000 (epoch 782), train_loss = 0.279, time/batch = 0.029, All_Time = 8744.603
296500/758000 (epoch 782), train_loss = 0.242, time/batch = 0.030, All_Time = 8746.079
296550/758000 (epoch 782), train_loss = 0.274, time/batch = 0.030, All_Time = 8747.558
296600/758000 (epoch 782), train_loss = 0.262, time/batch = 0.029, All_Time = 8749.035
296650/758000 (epoch 782), train_loss = 0.197, time/batch = 0.030, All_Time = 8750.523
296700/758000 (epoch 782), train_loss = 0.233, time/batch = 0.029, All_Time = 8752.019
296750/758000 (epoch 782), train_loss = 0.281, time/batch = 0.029, All_Time = 8753.521
296800/758000 (epoch 783), train_loss = 0.246, time/batch = 0.028, All_Time = 8755.008
296850/758000 (epoch 783), train_loss = 0.212, time/batch = 0.028, All_Time = 8756.479
296900/758000 (epoch 783), train_loss = 0.255, time/batch = 0.029, All_Time = 8757.945
296950/758000 (epoch 783), train_loss = 0.271, time/batch = 0.030, All_Time = 8759.415
297000/758000 (epoch 783), train_loss = 0.203, time/batch = 0.031, All_Time = 8760.887
model saved to NER/polyglot/model.ckpt
297050/758000 (epoch 783), train_loss = 0.226, time/batch = 0.029, All_Time = 8762.368
297100/758000 (epoch 783), train_loss = 0.254, time/batch = 0.029, All_Time = 8763.835
297150/758000 (epoch 784), train_loss = 0.219, time/batch = 0.029, All_Time = 8765.304
297200/758000 (epoch 784), train_loss = 0.265, time/batch = 0.030, All_Time = 8766.772
297250/758000 (epoch 784), train_loss = 0.227, time/batch = 0.029, All_Time = 8768.283
297300/758000 (epoch 784), train_loss = 0.213, time/batch = 0.030, All_Time = 8769.771
297350/758000 (epoch 784), train_loss = 0.224, time/batch = 0.028, All_Time = 8771.252
297400/758000 (epoch 784), train_loss = 0.213, time/batch = 0.028, All_Time = 8772.738
297450/758000 (epoch 784), train_loss = 0.230, time/batch = 0.029, All_Time = 8774.227
297500/758000 (epoch 784), train_loss = 0.223, time/batch = 0.032, All_Time = 8775.707
297550/758000 (epoch 785), train_loss = 0.275, time/batch = 0.030, All_Time = 8777.201
297600/758000 (epoch 785), train_loss = 0.229, time/batch = 0.030, All_Time = 8778.681
297650/758000 (epoch 785), train_loss = 0.270, time/batch = 0.029, All_Time = 8780.148
297700/758000 (epoch 785), train_loss = 0.273, time/batch = 0.029, All_Time = 8781.609
297750/758000 (epoch 785), train_loss = 0.233, time/batch = 0.028, All_Time = 8783.082
297800/758000 (epoch 785), train_loss = 0.268, time/batch = 0.029, All_Time = 8784.553
297850/758000 (epoch 785), train_loss = 0.280, time/batch = 0.031, All_Time = 8786.026
297900/758000 (epoch 786), train_loss = 0.239, time/batch = 0.030, All_Time = 8787.523
297950/758000 (epoch 786), train_loss = 0.218, time/batch = 0.030, All_Time = 8789.020
298000/758000 (epoch 786), train_loss = 0.243, time/batch = 0.028, All_Time = 8790.502
model saved to NER/polyglot/model.ckpt
298050/758000 (epoch 786), train_loss = 0.244, time/batch = 0.030, All_Time = 8791.980
298100/758000 (epoch 786), train_loss = 0.243, time/batch = 0.029, All_Time = 8793.453
298150/758000 (epoch 786), train_loss = 0.244, time/batch = 0.030, All_Time = 8794.929
298200/758000 (epoch 786), train_loss = 0.213, time/batch = 0.030, All_Time = 8796.397
298250/758000 (epoch 786), train_loss = 0.289, time/batch = 0.030, All_Time = 8797.864
298300/758000 (epoch 787), train_loss = 0.237, time/batch = 0.031, All_Time = 8799.390
298350/758000 (epoch 787), train_loss = 0.246, time/batch = 0.029, All_Time = 8800.873
298400/758000 (epoch 787), train_loss = 0.288, time/batch = 0.030, All_Time = 8802.347
298450/758000 (epoch 787), train_loss = 0.257, time/batch = 0.029, All_Time = 8803.831
298500/758000 (epoch 787), train_loss = 0.218, time/batch = 0.029, All_Time = 8805.306
298550/758000 (epoch 787), train_loss = 0.238, time/batch = 0.029, All_Time = 8806.773
298600/758000 (epoch 787), train_loss = 0.251, time/batch = 0.030, All_Time = 8808.252
298650/758000 (epoch 787), train_loss = 0.251, time/batch = 0.031, All_Time = 8809.734
298700/758000 (epoch 788), train_loss = 0.252, time/batch = 0.030, All_Time = 8811.204
298750/758000 (epoch 788), train_loss = 0.280, time/batch = 0.029, All_Time = 8812.671
298800/758000 (epoch 788), train_loss = 0.242, time/batch = 0.029, All_Time = 8814.147
298850/758000 (epoch 788), train_loss = 0.250, time/batch = 0.031, All_Time = 8815.660
298900/758000 (epoch 788), train_loss = 0.239, time/batch = 0.029, All_Time = 8817.158
298950/758000 (epoch 788), train_loss = 0.239, time/batch = 0.030, All_Time = 8818.637
299000/758000 (epoch 788), train_loss = 0.250, time/batch = 0.031, All_Time = 8820.132
model saved to NER/polyglot/model.ckpt
299050/758000 (epoch 789), train_loss = 0.221, time/batch = 0.029, All_Time = 8821.605
299100/758000 (epoch 789), train_loss = 0.219, time/batch = 0.032, All_Time = 8823.068
299150/758000 (epoch 789), train_loss = 0.246, time/batch = 0.029, All_Time = 8824.535
299200/758000 (epoch 789), train_loss = 0.262, time/batch = 0.030, All_Time = 8826.019
299250/758000 (epoch 789), train_loss = 0.260, time/batch = 0.032, All_Time = 8827.621
299300/758000 (epoch 789), train_loss = 0.241, time/batch = 0.030, All_Time = 8829.126
299350/758000 (epoch 789), train_loss = 0.210, time/batch = 0.030, All_Time = 8830.608
299400/758000 (epoch 789), train_loss = 0.239, time/batch = 0.029, All_Time = 8832.073
299450/758000 (epoch 790), train_loss = 0.230, time/batch = 0.030, All_Time = 8833.557
299500/758000 (epoch 790), train_loss = 0.226, time/batch = 0.029, All_Time = 8835.019
299550/758000 (epoch 790), train_loss = 0.264, time/batch = 0.030, All_Time = 8836.490
299600/758000 (epoch 790), train_loss = 0.240, time/batch = 0.029, All_Time = 8837.968
299650/758000 (epoch 790), train_loss = 0.253, time/batch = 0.029, All_Time = 8839.437
299700/758000 (epoch 790), train_loss = 0.251, time/batch = 0.029, All_Time = 8840.905
299750/758000 (epoch 790), train_loss = 0.248, time/batch = 0.028, All_Time = 8842.376
299800/758000 (epoch 791), train_loss = 0.216, time/batch = 0.028, All_Time = 8843.852
299850/758000 (epoch 791), train_loss = 0.233, time/batch = 0.030, All_Time = 8845.356
299900/758000 (epoch 791), train_loss = 0.250, time/batch = 0.031, All_Time = 8846.853
299950/758000 (epoch 791), train_loss = 0.241, time/batch = 0.030, All_Time = 8848.334
300000/758000 (epoch 791), train_loss = 0.243, time/batch = 0.028, All_Time = 8849.825
model saved to NER/polyglot/model.ckpt
300050/758000 (epoch 791), train_loss = 0.242, time/batch = 0.029, All_Time = 8851.294
300100/758000 (epoch 791), train_loss = 0.230, time/batch = 0.030, All_Time = 8852.763
300150/758000 (epoch 791), train_loss = 0.259, time/batch = 0.030, All_Time = 8854.227
300200/758000 (epoch 792), train_loss = 0.250, time/batch = 0.029, All_Time = 8855.696
300250/758000 (epoch 792), train_loss = 0.253, time/batch = 0.028, All_Time = 8857.159
300300/758000 (epoch 792), train_loss = 0.245, time/batch = 0.028, All_Time = 8858.636
300350/758000 (epoch 792), train_loss = 0.231, time/batch = 0.031, All_Time = 8860.123
300400/758000 (epoch 792), train_loss = 0.228, time/batch = 0.030, All_Time = 8861.627
300450/758000 (epoch 792), train_loss = 0.238, time/batch = 0.030, All_Time = 8863.109
300500/758000 (epoch 792), train_loss = 0.268, time/batch = 0.030, All_Time = 8864.594
300550/758000 (epoch 793), train_loss = 0.248, time/batch = 0.029, All_Time = 8866.069
300600/758000 (epoch 793), train_loss = 0.280, time/batch = 0.029, All_Time = 8867.550
300650/758000 (epoch 793), train_loss = 0.242, time/batch = 0.029, All_Time = 8869.027
300700/758000 (epoch 793), train_loss = 0.258, time/batch = 0.030, All_Time = 8870.500
300750/758000 (epoch 793), train_loss = 0.224, time/batch = 0.030, All_Time = 8871.967
300800/758000 (epoch 793), train_loss = 0.243, time/batch = 0.029, All_Time = 8873.439
300850/758000 (epoch 793), train_loss = 0.219, time/batch = 0.028, All_Time = 8874.921
300900/758000 (epoch 793), train_loss = 0.232, time/batch = 0.032, All_Time = 8876.421
300950/758000 (epoch 794), train_loss = 0.237, time/batch = 0.029, All_Time = 8877.922
301000/758000 (epoch 794), train_loss = 0.239, time/batch = 0.028, All_Time = 8879.384
model saved to NER/polyglot/model.ckpt
301050/758000 (epoch 794), train_loss = 0.293, time/batch = 0.032, All_Time = 8880.854
301100/758000 (epoch 794), train_loss = 0.318, time/batch = 0.030, All_Time = 8882.314
301150/758000 (epoch 794), train_loss = 0.196, time/batch = 0.030, All_Time = 8883.778
301200/758000 (epoch 794), train_loss = 0.213, time/batch = 0.028, All_Time = 8885.242
301250/758000 (epoch 794), train_loss = 0.250, time/batch = 0.029, All_Time = 8886.714
301300/758000 (epoch 794), train_loss = 0.297, time/batch = 0.029, All_Time = 8888.196
301350/758000 (epoch 795), train_loss = 0.226, time/batch = 0.029, All_Time = 8889.678
301400/758000 (epoch 795), train_loss = 0.259, time/batch = 0.029, All_Time = 8891.162
301450/758000 (epoch 795), train_loss = 0.223, time/batch = 0.029, All_Time = 8892.625
301500/758000 (epoch 795), train_loss = 0.239, time/batch = 0.030, All_Time = 8894.089
301550/758000 (epoch 795), train_loss = 0.212, time/batch = 0.028, All_Time = 8895.553
301600/758000 (epoch 795), train_loss = 0.243, time/batch = 0.031, All_Time = 8897.029
301650/758000 (epoch 795), train_loss = 0.215, time/batch = 0.030, All_Time = 8898.534
301700/758000 (epoch 796), train_loss = 0.228, time/batch = 0.030, All_Time = 8900.019
301750/758000 (epoch 796), train_loss = 0.252, time/batch = 0.031, All_Time = 8901.492
301800/758000 (epoch 796), train_loss = 0.260, time/batch = 0.030, All_Time = 8902.959
301850/758000 (epoch 796), train_loss = 0.228, time/batch = 0.028, All_Time = 8904.425
301900/758000 (epoch 796), train_loss = 0.236, time/batch = 0.028, All_Time = 8905.898
301950/758000 (epoch 796), train_loss = 0.271, time/batch = 0.029, All_Time = 8907.370
302000/758000 (epoch 796), train_loss = 0.238, time/batch = 0.029, All_Time = 8908.841
model saved to NER/polyglot/model.ckpt
302050/758000 (epoch 796), train_loss = 0.268, time/batch = 0.032, All_Time = 8910.320
302100/758000 (epoch 797), train_loss = 0.248, time/batch = 0.030, All_Time = 8911.825
302150/758000 (epoch 797), train_loss = 0.249, time/batch = 0.029, All_Time = 8913.307
302200/758000 (epoch 797), train_loss = 0.240, time/batch = 0.030, All_Time = 8914.779
302250/758000 (epoch 797), train_loss = 0.247, time/batch = 0.028, All_Time = 8916.249
302300/758000 (epoch 797), train_loss = 0.235, time/batch = 0.028, All_Time = 8917.728
302350/758000 (epoch 797), train_loss = 0.247, time/batch = 0.029, All_Time = 8919.202
302400/758000 (epoch 797), train_loss = 0.251, time/batch = 0.031, All_Time = 8920.668
302450/758000 (epoch 798), train_loss = 0.242, time/batch = 0.031, All_Time = 8922.143
302500/758000 (epoch 798), train_loss = 0.276, time/batch = 0.029, All_Time = 8923.611
302550/758000 (epoch 798), train_loss = 0.256, time/batch = 0.030, All_Time = 8925.087
302600/758000 (epoch 798), train_loss = 0.258, time/batch = 0.029, All_Time = 8926.550
302650/758000 (epoch 798), train_loss = 0.213, time/batch = 0.030, All_Time = 8928.013
302700/758000 (epoch 798), train_loss = 0.237, time/batch = 0.029, All_Time = 8929.480
302750/758000 (epoch 798), train_loss = 0.249, time/batch = 0.030, All_Time = 8930.958
302800/758000 (epoch 798), train_loss = 0.251, time/batch = 0.029, All_Time = 8932.446
302850/758000 (epoch 799), train_loss = 0.232, time/batch = 0.030, All_Time = 8933.927
302900/758000 (epoch 799), train_loss = 0.255, time/batch = 0.030, All_Time = 8935.401
302950/758000 (epoch 799), train_loss = 0.265, time/batch = 0.031, All_Time = 8936.893
303000/758000 (epoch 799), train_loss = 0.229, time/batch = 0.029, All_Time = 8938.372
model saved to NER/polyglot/model.ckpt
303050/758000 (epoch 799), train_loss = 0.263, time/batch = 0.030, All_Time = 8939.846
303100/758000 (epoch 799), train_loss = 0.217, time/batch = 0.029, All_Time = 8941.316
303150/758000 (epoch 799), train_loss = 0.248, time/batch = 0.029, All_Time = 8942.823
303200/758000 (epoch 800), train_loss = 0.059, time/batch = 0.038, All_Time = 8944.322
303250/758000 (epoch 800), train_loss = 0.250, time/batch = 0.028, All_Time = 8945.811
303300/758000 (epoch 800), train_loss = 0.223, time/batch = 0.030, All_Time = 8947.301
303350/758000 (epoch 800), train_loss = 0.250, time/batch = 0.028, All_Time = 8948.775
303400/758000 (epoch 800), train_loss = 0.231, time/batch = 0.030, All_Time = 8950.265
303450/758000 (epoch 800), train_loss = 0.250, time/batch = 0.030, All_Time = 8951.753
303500/758000 (epoch 800), train_loss = 0.232, time/batch = 0.030, All_Time = 8953.230
303550/758000 (epoch 800), train_loss = 0.230, time/batch = 0.029, All_Time = 8954.710
303600/758000 (epoch 801), train_loss = 0.224, time/batch = 0.030, All_Time = 8956.203
303650/758000 (epoch 801), train_loss = 0.233, time/batch = 0.029, All_Time = 8957.675
303700/758000 (epoch 801), train_loss = 0.224, time/batch = 0.030, All_Time = 8959.134
303750/758000 (epoch 801), train_loss = 0.262, time/batch = 0.030, All_Time = 8960.604
303800/758000 (epoch 801), train_loss = 0.220, time/batch = 0.029, All_Time = 8962.076
303850/758000 (epoch 801), train_loss = 0.228, time/batch = 0.030, All_Time = 8963.539
303900/758000 (epoch 801), train_loss = 0.280, time/batch = 0.029, All_Time = 8965.032
303950/758000 (epoch 801), train_loss = 0.272, time/batch = 0.029, All_Time = 8966.546
304000/758000 (epoch 802), train_loss = 0.230, time/batch = 0.028, All_Time = 8968.030
model saved to NER/polyglot/model.ckpt
304050/758000 (epoch 802), train_loss = 0.224, time/batch = 0.028, All_Time = 8969.507
304100/758000 (epoch 802), train_loss = 0.201, time/batch = 0.029, All_Time = 8970.973
304150/758000 (epoch 802), train_loss = 0.270, time/batch = 0.030, All_Time = 8972.430
304200/758000 (epoch 802), train_loss = 0.259, time/batch = 0.030, All_Time = 8973.908
304250/758000 (epoch 802), train_loss = 0.209, time/batch = 0.030, All_Time = 8975.403
304300/758000 (epoch 802), train_loss = 0.218, time/batch = 0.028, All_Time = 8976.893
304350/758000 (epoch 803), train_loss = 0.229, time/batch = 0.030, All_Time = 8978.389
304400/758000 (epoch 803), train_loss = 0.283, time/batch = 0.030, All_Time = 8979.860
304450/758000 (epoch 803), train_loss = 0.231, time/batch = 0.028, All_Time = 8981.324
304500/758000 (epoch 803), train_loss = 0.307, time/batch = 0.030, All_Time = 8982.796
304550/758000 (epoch 803), train_loss = 0.221, time/batch = 0.031, All_Time = 8984.277
304600/758000 (epoch 803), train_loss = 0.208, time/batch = 0.029, All_Time = 8985.781
304650/758000 (epoch 803), train_loss = 0.247, time/batch = 0.031, All_Time = 8987.256
304700/758000 (epoch 803), train_loss = 0.252, time/batch = 0.029, All_Time = 8988.735
304750/758000 (epoch 804), train_loss = 0.264, time/batch = 0.029, All_Time = 8990.221
304800/758000 (epoch 804), train_loss = 0.229, time/batch = 0.029, All_Time = 8991.679
304850/758000 (epoch 804), train_loss = 0.242, time/batch = 0.029, All_Time = 8993.148
304900/758000 (epoch 804), train_loss = 0.267, time/batch = 0.030, All_Time = 8994.625
304950/758000 (epoch 804), train_loss = 0.249, time/batch = 0.030, All_Time = 8996.120
305000/758000 (epoch 804), train_loss = 0.237, time/batch = 0.029, All_Time = 8997.588
model saved to NER/polyglot/model.ckpt
305050/758000 (epoch 804), train_loss = 0.276, time/batch = 0.029, All_Time = 8999.073
305100/758000 (epoch 805), train_loss = 0.256, time/batch = 0.030, All_Time = 9000.545
305150/758000 (epoch 805), train_loss = 0.222, time/batch = 0.028, All_Time = 9002.015
305200/758000 (epoch 805), train_loss = 0.266, time/batch = 0.029, All_Time = 9003.485
305250/758000 (epoch 805), train_loss = 0.216, time/batch = 0.031, All_Time = 9004.961
305300/758000 (epoch 805), train_loss = 0.223, time/batch = 0.029, All_Time = 9006.435
305350/758000 (epoch 805), train_loss = 0.261, time/batch = 0.029, All_Time = 9007.901
305400/758000 (epoch 805), train_loss = 0.238, time/batch = 0.029, All_Time = 9009.367
305450/758000 (epoch 805), train_loss = 0.264, time/batch = 0.029, All_Time = 9010.846
305500/758000 (epoch 806), train_loss = 0.223, time/batch = 0.030, All_Time = 9012.330
305550/758000 (epoch 806), train_loss = 0.231, time/batch = 0.029, All_Time = 9013.794
305600/758000 (epoch 806), train_loss = 0.238, time/batch = 0.029, All_Time = 9015.261
305650/758000 (epoch 806), train_loss = 0.266, time/batch = 0.028, All_Time = 9016.726
305700/758000 (epoch 806), train_loss = 0.239, time/batch = 0.029, All_Time = 9018.202
305750/758000 (epoch 806), train_loss = 0.226, time/batch = 0.031, All_Time = 9019.708
305800/758000 (epoch 806), train_loss = 0.276, time/batch = 0.029, All_Time = 9021.199
305850/758000 (epoch 806), train_loss = 0.240, time/batch = 0.031, All_Time = 9022.699
305900/758000 (epoch 807), train_loss = 0.281, time/batch = 0.030, All_Time = 9024.198
305950/758000 (epoch 807), train_loss = 0.257, time/batch = 0.029, All_Time = 9025.671
306000/758000 (epoch 807), train_loss = 0.240, time/batch = 0.032, All_Time = 9027.140
model saved to NER/polyglot/model.ckpt
306050/758000 (epoch 807), train_loss = 0.231, time/batch = 0.029, All_Time = 9028.617
306100/758000 (epoch 807), train_loss = 0.217, time/batch = 0.028, All_Time = 9030.077
306150/758000 (epoch 807), train_loss = 0.224, time/batch = 0.031, All_Time = 9031.544
306200/758000 (epoch 807), train_loss = 0.215, time/batch = 0.030, All_Time = 9033.020
306250/758000 (epoch 808), train_loss = 0.249, time/batch = 0.028, All_Time = 9034.505
306300/758000 (epoch 808), train_loss = 0.211, time/batch = 0.030, All_Time = 9035.969
306350/758000 (epoch 808), train_loss = 0.245, time/batch = 0.030, All_Time = 9037.437
306400/758000 (epoch 808), train_loss = 0.217, time/batch = 0.027, All_Time = 9038.903
306450/758000 (epoch 808), train_loss = 0.233, time/batch = 0.030, All_Time = 9040.374
306500/758000 (epoch 808), train_loss = 0.228, time/batch = 0.028, All_Time = 9041.836
306550/758000 (epoch 808), train_loss = 0.248, time/batch = 0.030, All_Time = 9043.320
306600/758000 (epoch 808), train_loss = 0.229, time/batch = 0.030, All_Time = 9044.827
306650/758000 (epoch 809), train_loss = 0.218, time/batch = 0.029, All_Time = 9046.327
306700/758000 (epoch 809), train_loss = 0.237, time/batch = 0.031, All_Time = 9047.812
306750/758000 (epoch 809), train_loss = 0.212, time/batch = 0.029, All_Time = 9049.306
306800/758000 (epoch 809), train_loss = 0.266, time/batch = 0.029, All_Time = 9050.778
306850/758000 (epoch 809), train_loss = 0.255, time/batch = 0.029, All_Time = 9052.262
306900/758000 (epoch 809), train_loss = 0.232, time/batch = 0.031, All_Time = 9053.740
306950/758000 (epoch 809), train_loss = 0.262, time/batch = 0.030, All_Time = 9055.235
307000/758000 (epoch 810), train_loss = 0.282, time/batch = 0.030, All_Time = 9056.725
model saved to NER/polyglot/model.ckpt
307050/758000 (epoch 810), train_loss = 0.292, time/batch = 0.029, All_Time = 9058.203
307100/758000 (epoch 810), train_loss = 0.253, time/batch = 0.028, All_Time = 9059.668
307150/758000 (epoch 810), train_loss = 0.222, time/batch = 0.029, All_Time = 9061.131
307200/758000 (epoch 810), train_loss = 0.221, time/batch = 0.029, All_Time = 9062.631
307250/758000 (epoch 810), train_loss = 0.260, time/batch = 0.030, All_Time = 9064.123
307300/758000 (epoch 810), train_loss = 0.244, time/batch = 0.030, All_Time = 9065.595
307350/758000 (epoch 810), train_loss = 0.247, time/batch = 0.029, All_Time = 9067.071
307400/758000 (epoch 811), train_loss = 0.210, time/batch = 0.033, All_Time = 9068.556
307450/758000 (epoch 811), train_loss = 0.265, time/batch = 0.030, All_Time = 9070.026
307500/758000 (epoch 811), train_loss = 0.229, time/batch = 0.030, All_Time = 9071.506
307550/758000 (epoch 811), train_loss = 0.232, time/batch = 0.029, All_Time = 9072.970
307600/758000 (epoch 811), train_loss = 0.230, time/batch = 0.031, All_Time = 9074.457
307650/758000 (epoch 811), train_loss = 0.253, time/batch = 0.028, All_Time = 9075.968
307700/758000 (epoch 811), train_loss = 0.258, time/batch = 0.029, All_Time = 9077.462
307750/758000 (epoch 812), train_loss = 0.196, time/batch = 0.029, All_Time = 9078.951
307800/758000 (epoch 812), train_loss = 0.254, time/batch = 0.029, All_Time = 9080.434
307850/758000 (epoch 812), train_loss = 0.281, time/batch = 0.030, All_Time = 9081.917
307900/758000 (epoch 812), train_loss = 0.235, time/batch = 0.030, All_Time = 9083.399
307950/758000 (epoch 812), train_loss = 0.247, time/batch = 0.029, All_Time = 9084.876
308000/758000 (epoch 812), train_loss = 0.251, time/batch = 0.030, All_Time = 9086.342
model saved to NER/polyglot/model.ckpt
308050/758000 (epoch 812), train_loss = 0.203, time/batch = 0.028, All_Time = 9087.799
308100/758000 (epoch 812), train_loss = 0.268, time/batch = 0.028, All_Time = 9089.265
308150/758000 (epoch 813), train_loss = 0.233, time/batch = 0.029, All_Time = 9090.770
308200/758000 (epoch 813), train_loss = 0.241, time/batch = 0.030, All_Time = 9092.251
308250/758000 (epoch 813), train_loss = 0.252, time/batch = 0.031, All_Time = 9093.730
308300/758000 (epoch 813), train_loss = 0.258, time/batch = 0.030, All_Time = 9095.206
308350/758000 (epoch 813), train_loss = 0.243, time/batch = 0.030, All_Time = 9096.705
308400/758000 (epoch 813), train_loss = 0.243, time/batch = 0.030, All_Time = 9098.181
308450/758000 (epoch 813), train_loss = 0.244, time/batch = 0.029, All_Time = 9099.657
308500/758000 (epoch 813), train_loss = 0.286, time/batch = 0.029, All_Time = 9101.125
308550/758000 (epoch 814), train_loss = 0.207, time/batch = 0.028, All_Time = 9102.610
308600/758000 (epoch 814), train_loss = 0.244, time/batch = 0.028, All_Time = 9104.070
308650/758000 (epoch 814), train_loss = 0.217, time/batch = 0.030, All_Time = 9105.538
308700/758000 (epoch 814), train_loss = 0.233, time/batch = 0.030, All_Time = 9107.007
308750/758000 (epoch 814), train_loss = 0.260, time/batch = 0.031, All_Time = 9108.493
308800/758000 (epoch 814), train_loss = 0.253, time/batch = 0.030, All_Time = 9109.976
308850/758000 (epoch 814), train_loss = 0.238, time/batch = 0.031, All_Time = 9111.457
308900/758000 (epoch 815), train_loss = 0.227, time/batch = 0.028, All_Time = 9112.952
308950/758000 (epoch 815), train_loss = 0.250, time/batch = 0.029, All_Time = 9114.424
309000/758000 (epoch 815), train_loss = 0.250, time/batch = 0.029, All_Time = 9115.889
model saved to NER/polyglot/model.ckpt
309050/758000 (epoch 815), train_loss = 0.223, time/batch = 0.029, All_Time = 9117.354
309100/758000 (epoch 815), train_loss = 0.240, time/batch = 0.030, All_Time = 9118.815
309150/758000 (epoch 815), train_loss = 0.246, time/batch = 0.029, All_Time = 9120.268
309200/758000 (epoch 815), train_loss = 0.246, time/batch = 0.031, All_Time = 9121.760
309250/758000 (epoch 815), train_loss = 0.257, time/batch = 0.031, All_Time = 9123.256
309300/758000 (epoch 816), train_loss = 0.266, time/batch = 0.030, All_Time = 9124.741
309350/758000 (epoch 816), train_loss = 0.224, time/batch = 0.032, All_Time = 9126.250
309400/758000 (epoch 816), train_loss = 0.248, time/batch = 0.030, All_Time = 9127.760
309450/758000 (epoch 816), train_loss = 0.227, time/batch = 0.031, All_Time = 9129.256
309500/758000 (epoch 816), train_loss = 0.279, time/batch = 0.030, All_Time = 9130.740
309550/758000 (epoch 816), train_loss = 0.255, time/batch = 0.028, All_Time = 9132.241
309600/758000 (epoch 816), train_loss = 0.253, time/batch = 0.031, All_Time = 9133.717
309650/758000 (epoch 817), train_loss = 0.244, time/batch = 0.030, All_Time = 9135.208
309700/758000 (epoch 817), train_loss = 0.247, time/batch = 0.030, All_Time = 9136.685
309750/758000 (epoch 817), train_loss = 0.270, time/batch = 0.029, All_Time = 9138.159
309800/758000 (epoch 817), train_loss = 0.246, time/batch = 0.029, All_Time = 9139.620
309850/758000 (epoch 817), train_loss = 0.237, time/batch = 0.029, All_Time = 9141.101
309900/758000 (epoch 817), train_loss = 0.224, time/batch = 0.030, All_Time = 9142.582
309950/758000 (epoch 817), train_loss = 0.229, time/batch = 0.028, All_Time = 9144.055
310000/758000 (epoch 817), train_loss = 0.246, time/batch = 0.030, All_Time = 9145.533
model saved to NER/polyglot/model.ckpt
310050/758000 (epoch 818), train_loss = 0.249, time/batch = 0.029, All_Time = 9147.011
310100/758000 (epoch 818), train_loss = 0.264, time/batch = 0.029, All_Time = 9148.474
310150/758000 (epoch 818), train_loss = 0.240, time/batch = 0.029, All_Time = 9149.947
310200/758000 (epoch 818), train_loss = 0.250, time/batch = 0.030, All_Time = 9151.424
310250/758000 (epoch 818), train_loss = 0.227, time/batch = 0.030, All_Time = 9152.933
310300/758000 (epoch 818), train_loss = 0.217, time/batch = 0.029, All_Time = 9154.409
310350/758000 (epoch 818), train_loss = 0.277, time/batch = 0.030, All_Time = 9155.885
310400/758000 (epoch 818), train_loss = 0.259, time/batch = 0.029, All_Time = 9157.361
310450/758000 (epoch 819), train_loss = 0.269, time/batch = 0.030, All_Time = 9158.833
310500/758000 (epoch 819), train_loss = 0.296, time/batch = 0.028, All_Time = 9160.304
310550/758000 (epoch 819), train_loss = 0.228, time/batch = 0.030, All_Time = 9161.770
310600/758000 (epoch 819), train_loss = 0.220, time/batch = 0.030, All_Time = 9163.244
310650/758000 (epoch 819), train_loss = 0.257, time/batch = 0.029, All_Time = 9164.754
310700/758000 (epoch 819), train_loss = 0.255, time/batch = 0.030, All_Time = 9166.232
310750/758000 (epoch 819), train_loss = 0.237, time/batch = 0.029, All_Time = 9167.711
310800/758000 (epoch 820), train_loss = 0.225, time/batch = 0.030, All_Time = 9169.200
310850/758000 (epoch 820), train_loss = 0.234, time/batch = 0.033, All_Time = 9170.683
310900/758000 (epoch 820), train_loss = 0.243, time/batch = 0.031, All_Time = 9172.157
310950/758000 (epoch 820), train_loss = 0.234, time/batch = 0.030, All_Time = 9173.636
311000/758000 (epoch 820), train_loss = 0.223, time/batch = 0.028, All_Time = 9175.114
model saved to NER/polyglot/model.ckpt
311050/758000 (epoch 820), train_loss = 0.239, time/batch = 0.029, All_Time = 9176.586
311100/758000 (epoch 820), train_loss = 0.264, time/batch = 0.029, All_Time = 9178.054
311150/758000 (epoch 820), train_loss = 0.244, time/batch = 0.028, All_Time = 9179.517
311200/758000 (epoch 821), train_loss = 0.257, time/batch = 0.027, All_Time = 9180.990
311250/758000 (epoch 821), train_loss = 0.287, time/batch = 0.029, All_Time = 9182.458
311300/758000 (epoch 821), train_loss = 0.255, time/batch = 0.029, All_Time = 9183.924
311350/758000 (epoch 821), train_loss = 0.248, time/batch = 0.030, All_Time = 9185.410
311400/758000 (epoch 821), train_loss = 0.212, time/batch = 0.029, All_Time = 9186.895
311450/758000 (epoch 821), train_loss = 0.229, time/batch = 0.032, All_Time = 9188.376
311500/758000 (epoch 821), train_loss = 0.272, time/batch = 0.029, All_Time = 9189.871
311550/758000 (epoch 822), train_loss = 0.249, time/batch = 0.031, All_Time = 9191.361
311600/758000 (epoch 822), train_loss = 0.227, time/batch = 0.028, All_Time = 9192.832
311650/758000 (epoch 822), train_loss = 0.267, time/batch = 0.029, All_Time = 9194.294
311700/758000 (epoch 822), train_loss = 0.239, time/batch = 0.029, All_Time = 9195.761
311750/758000 (epoch 822), train_loss = 0.247, time/batch = 0.030, All_Time = 9197.232
311800/758000 (epoch 822), train_loss = 0.241, time/batch = 0.029, All_Time = 9198.696
311850/758000 (epoch 822), train_loss = 0.274, time/batch = 0.030, All_Time = 9200.166
311900/758000 (epoch 822), train_loss = 0.279, time/batch = 0.029, All_Time = 9201.634
311950/758000 (epoch 823), train_loss = 0.238, time/batch = 0.029, All_Time = 9203.131
312000/758000 (epoch 823), train_loss = 0.248, time/batch = 0.031, All_Time = 9204.599
model saved to NER/polyglot/model.ckpt
312050/758000 (epoch 823), train_loss = 0.299, time/batch = 0.031, All_Time = 9206.079
312100/758000 (epoch 823), train_loss = 0.230, time/batch = 0.030, All_Time = 9207.544
312150/758000 (epoch 823), train_loss = 0.216, time/batch = 0.030, All_Time = 9209.058
312200/758000 (epoch 823), train_loss = 0.244, time/batch = 0.030, All_Time = 9210.541
312250/758000 (epoch 823), train_loss = 0.274, time/batch = 0.030, All_Time = 9212.019
312300/758000 (epoch 824), train_loss = 0.221, time/batch = 0.029, All_Time = 9213.515
312350/758000 (epoch 824), train_loss = 0.257, time/batch = 0.029, All_Time = 9214.987
312400/758000 (epoch 824), train_loss = 0.241, time/batch = 0.030, All_Time = 9216.455
312450/758000 (epoch 824), train_loss = 0.240, time/batch = 0.029, All_Time = 9217.917
312500/758000 (epoch 824), train_loss = 0.256, time/batch = 0.029, All_Time = 9219.389
312550/758000 (epoch 824), train_loss = 0.219, time/batch = 0.029, All_Time = 9220.859
312600/758000 (epoch 824), train_loss = 0.224, time/batch = 0.030, All_Time = 9222.329
312650/758000 (epoch 824), train_loss = 0.257, time/batch = 0.029, All_Time = 9223.789
312700/758000 (epoch 825), train_loss = 0.255, time/batch = 0.029, All_Time = 9225.289
312750/758000 (epoch 825), train_loss = 0.267, time/batch = 0.030, All_Time = 9226.767
312800/758000 (epoch 825), train_loss = 0.269, time/batch = 0.031, All_Time = 9228.247
312850/758000 (epoch 825), train_loss = 0.228, time/batch = 0.029, All_Time = 9229.728
312900/758000 (epoch 825), train_loss = 0.234, time/batch = 0.031, All_Time = 9231.219
312950/758000 (epoch 825), train_loss = 0.245, time/batch = 0.032, All_Time = 9232.720
313000/758000 (epoch 825), train_loss = 0.279, time/batch = 0.031, All_Time = 9234.263
model saved to NER/polyglot/model.ckpt
313050/758000 (epoch 825), train_loss = 0.240, time/batch = 0.031, All_Time = 9235.733
313100/758000 (epoch 826), train_loss = 0.236, time/batch = 0.029, All_Time = 9237.207
313150/758000 (epoch 826), train_loss = 0.234, time/batch = 0.030, All_Time = 9238.658
313200/758000 (epoch 826), train_loss = 0.233, time/batch = 0.029, All_Time = 9240.123
313250/758000 (epoch 826), train_loss = 0.276, time/batch = 0.028, All_Time = 9241.597
313300/758000 (epoch 826), train_loss = 0.206, time/batch = 0.029, All_Time = 9243.077
313350/758000 (epoch 826), train_loss = 0.259, time/batch = 0.032, All_Time = 9244.578
313400/758000 (epoch 826), train_loss = 0.234, time/batch = 0.029, All_Time = 9246.047
313450/758000 (epoch 827), train_loss = 0.245, time/batch = 0.029, All_Time = 9247.539
313500/758000 (epoch 827), train_loss = 0.223, time/batch = 0.030, All_Time = 9249.008
313550/758000 (epoch 827), train_loss = 0.240, time/batch = 0.028, All_Time = 9250.476
313600/758000 (epoch 827), train_loss = 0.256, time/batch = 0.030, All_Time = 9251.944
313650/758000 (epoch 827), train_loss = 0.214, time/batch = 0.029, All_Time = 9253.423
313700/758000 (epoch 827), train_loss = 0.272, time/batch = 0.029, All_Time = 9254.889
313750/758000 (epoch 827), train_loss = 0.213, time/batch = 0.030, All_Time = 9256.358
313800/758000 (epoch 827), train_loss = 0.251, time/batch = 0.029, All_Time = 9257.830
313850/758000 (epoch 828), train_loss = 0.247, time/batch = 0.029, All_Time = 9259.345
313900/758000 (epoch 828), train_loss = 0.229, time/batch = 0.031, All_Time = 9260.830
313950/758000 (epoch 828), train_loss = 0.217, time/batch = 0.031, All_Time = 9262.320
314000/758000 (epoch 828), train_loss = 0.220, time/batch = 0.030, All_Time = 9263.817
model saved to NER/polyglot/model.ckpt
314050/758000 (epoch 828), train_loss = 0.250, time/batch = 0.029, All_Time = 9265.287
314100/758000 (epoch 828), train_loss = 0.207, time/batch = 0.029, All_Time = 9266.754
314150/758000 (epoch 828), train_loss = 0.268, time/batch = 0.031, All_Time = 9268.231
314200/758000 (epoch 829), train_loss = 0.256, time/batch = 0.030, All_Time = 9269.717
314250/758000 (epoch 829), train_loss = 0.264, time/batch = 0.028, All_Time = 9271.185
314300/758000 (epoch 829), train_loss = 0.284, time/batch = 0.030, All_Time = 9272.653
314350/758000 (epoch 829), train_loss = 0.239, time/batch = 0.030, All_Time = 9274.128
314400/758000 (epoch 829), train_loss = 0.267, time/batch = 0.030, All_Time = 9275.596
314450/758000 (epoch 829), train_loss = 0.256, time/batch = 0.029, All_Time = 9277.055
314500/758000 (epoch 829), train_loss = 0.236, time/batch = 0.029, All_Time = 9278.518
314550/758000 (epoch 829), train_loss = 0.268, time/batch = 0.028, All_Time = 9279.997
314600/758000 (epoch 830), train_loss = 0.226, time/batch = 0.030, All_Time = 9281.486
314650/758000 (epoch 830), train_loss = 0.222, time/batch = 0.028, All_Time = 9282.956
314700/758000 (epoch 830), train_loss = 0.261, time/batch = 0.028, All_Time = 9284.440
314750/758000 (epoch 830), train_loss = 0.254, time/batch = 0.029, All_Time = 9285.921
314800/758000 (epoch 830), train_loss = 0.223, time/batch = 0.029, All_Time = 9287.409
314850/758000 (epoch 830), train_loss = 0.242, time/batch = 0.029, All_Time = 9288.893
314900/758000 (epoch 830), train_loss = 0.251, time/batch = 0.029, All_Time = 9290.393
314950/758000 (epoch 831), train_loss = 0.192, time/batch = 0.028, All_Time = 9291.891
315000/758000 (epoch 831), train_loss = 0.273, time/batch = 0.028, All_Time = 9293.367
model saved to NER/polyglot/model.ckpt
315050/758000 (epoch 831), train_loss = 0.217, time/batch = 0.028, All_Time = 9294.834
315100/758000 (epoch 831), train_loss = 0.240, time/batch = 0.030, All_Time = 9296.298
315150/758000 (epoch 831), train_loss = 0.221, time/batch = 0.029, All_Time = 9297.753
315200/758000 (epoch 831), train_loss = 0.221, time/batch = 0.029, All_Time = 9299.225
315250/758000 (epoch 831), train_loss = 0.252, time/batch = 0.029, All_Time = 9300.704
315300/758000 (epoch 831), train_loss = 0.272, time/batch = 0.028, All_Time = 9302.174
315350/758000 (epoch 832), train_loss = 0.222, time/batch = 0.030, All_Time = 9303.659
315400/758000 (epoch 832), train_loss = 0.279, time/batch = 0.029, All_Time = 9305.124
315450/758000 (epoch 832), train_loss = 0.242, time/batch = 0.028, All_Time = 9306.607
315500/758000 (epoch 832), train_loss = 0.274, time/batch = 0.031, All_Time = 9308.111
315550/758000 (epoch 832), train_loss = 0.262, time/batch = 0.030, All_Time = 9309.600
315600/758000 (epoch 832), train_loss = 0.197, time/batch = 0.029, All_Time = 9311.068
315650/758000 (epoch 832), train_loss = 0.233, time/batch = 0.031, All_Time = 9312.553
315700/758000 (epoch 832), train_loss = 0.281, time/batch = 0.029, All_Time = 9314.028
315750/758000 (epoch 833), train_loss = 0.246, time/batch = 0.029, All_Time = 9315.501
315800/758000 (epoch 833), train_loss = 0.212, time/batch = 0.029, All_Time = 9316.975
315850/758000 (epoch 833), train_loss = 0.255, time/batch = 0.028, All_Time = 9318.443
315900/758000 (epoch 833), train_loss = 0.271, time/batch = 0.030, All_Time = 9319.904
315950/758000 (epoch 833), train_loss = 0.203, time/batch = 0.030, All_Time = 9321.376
316000/758000 (epoch 833), train_loss = 0.226, time/batch = 0.029, All_Time = 9322.833
model saved to NER/polyglot/model.ckpt
316050/758000 (epoch 833), train_loss = 0.254, time/batch = 0.029, All_Time = 9324.291
316100/758000 (epoch 834), train_loss = 0.219, time/batch = 0.032, All_Time = 9325.787
316150/758000 (epoch 834), train_loss = 0.265, time/batch = 0.028, All_Time = 9327.285
316200/758000 (epoch 834), train_loss = 0.227, time/batch = 0.033, All_Time = 9328.776
316250/758000 (epoch 834), train_loss = 0.213, time/batch = 0.031, All_Time = 9330.249
316300/758000 (epoch 834), train_loss = 0.224, time/batch = 0.029, All_Time = 9331.742
316350/758000 (epoch 834), train_loss = 0.213, time/batch = 0.030, All_Time = 9333.215
316400/758000 (epoch 834), train_loss = 0.230, time/batch = 0.029, All_Time = 9334.694
316450/758000 (epoch 834), train_loss = 0.223, time/batch = 0.028, All_Time = 9336.183
316500/758000 (epoch 835), train_loss = 0.275, time/batch = 0.030, All_Time = 9337.669
316550/758000 (epoch 835), train_loss = 0.229, time/batch = 0.028, All_Time = 9339.148
316600/758000 (epoch 835), train_loss = 0.270, time/batch = 0.027, All_Time = 9340.617
316650/758000 (epoch 835), train_loss = 0.273, time/batch = 0.031, All_Time = 9342.095
316700/758000 (epoch 835), train_loss = 0.233, time/batch = 0.030, All_Time = 9343.598
316750/758000 (epoch 835), train_loss = 0.268, time/batch = 0.030, All_Time = 9345.093
316800/758000 (epoch 835), train_loss = 0.280, time/batch = 0.029, All_Time = 9346.585
316850/758000 (epoch 836), train_loss = 0.239, time/batch = 0.029, All_Time = 9348.079
316900/758000 (epoch 836), train_loss = 0.218, time/batch = 0.031, All_Time = 9349.558
316950/758000 (epoch 836), train_loss = 0.243, time/batch = 0.028, All_Time = 9351.031
317000/758000 (epoch 836), train_loss = 0.244, time/batch = 0.028, All_Time = 9352.506
model saved to NER/polyglot/model.ckpt
317050/758000 (epoch 836), train_loss = 0.243, time/batch = 0.029, All_Time = 9353.978
317100/758000 (epoch 836), train_loss = 0.244, time/batch = 0.029, All_Time = 9355.441
317150/758000 (epoch 836), train_loss = 0.213, time/batch = 0.029, All_Time = 9356.913
317200/758000 (epoch 836), train_loss = 0.289, time/batch = 0.030, All_Time = 9358.415
317250/758000 (epoch 837), train_loss = 0.237, time/batch = 0.029, All_Time = 9359.899
317300/758000 (epoch 837), train_loss = 0.246, time/batch = 0.030, All_Time = 9361.377
317350/758000 (epoch 837), train_loss = 0.288, time/batch = 0.029, All_Time = 9362.845
317400/758000 (epoch 837), train_loss = 0.257, time/batch = 0.031, All_Time = 9364.320
317450/758000 (epoch 837), train_loss = 0.218, time/batch = 0.030, All_Time = 9365.792
317500/758000 (epoch 837), train_loss = 0.238, time/batch = 0.030, All_Time = 9367.290
317550/758000 (epoch 837), train_loss = 0.251, time/batch = 0.029, All_Time = 9368.789
317600/758000 (epoch 837), train_loss = 0.251, time/batch = 0.032, All_Time = 9370.260
317650/758000 (epoch 838), train_loss = 0.252, time/batch = 0.030, All_Time = 9371.759
317700/758000 (epoch 838), train_loss = 0.280, time/batch = 0.029, All_Time = 9373.235
317750/758000 (epoch 838), train_loss = 0.242, time/batch = 0.030, All_Time = 9374.705
317800/758000 (epoch 838), train_loss = 0.250, time/batch = 0.031, All_Time = 9376.178
317850/758000 (epoch 838), train_loss = 0.239, time/batch = 0.029, All_Time = 9377.648
317900/758000 (epoch 838), train_loss = 0.239, time/batch = 0.029, All_Time = 9379.123
317950/758000 (epoch 838), train_loss = 0.250, time/batch = 0.029, All_Time = 9380.599
318000/758000 (epoch 839), train_loss = 0.221, time/batch = 0.029, All_Time = 9382.084
model saved to NER/polyglot/model.ckpt
318050/758000 (epoch 839), train_loss = 0.219, time/batch = 0.029, All_Time = 9383.556
318100/758000 (epoch 839), train_loss = 0.246, time/batch = 0.031, All_Time = 9385.029
318150/758000 (epoch 839), train_loss = 0.262, time/batch = 0.030, All_Time = 9386.538
318200/758000 (epoch 839), train_loss = 0.260, time/batch = 0.029, All_Time = 9388.018
318250/758000 (epoch 839), train_loss = 0.241, time/batch = 0.031, All_Time = 9389.507
318300/758000 (epoch 839), train_loss = 0.210, time/batch = 0.031, All_Time = 9390.984
318350/758000 (epoch 839), train_loss = 0.239, time/batch = 0.030, All_Time = 9392.474
318400/758000 (epoch 840), train_loss = 0.230, time/batch = 0.029, All_Time = 9393.972
318450/758000 (epoch 840), train_loss = 0.226, time/batch = 0.030, All_Time = 9395.442
318500/758000 (epoch 840), train_loss = 0.264, time/batch = 0.031, All_Time = 9396.901
318550/758000 (epoch 840), train_loss = 0.240, time/batch = 0.029, All_Time = 9398.377
318600/758000 (epoch 840), train_loss = 0.253, time/batch = 0.030, All_Time = 9399.845
318650/758000 (epoch 840), train_loss = 0.251, time/batch = 0.030, All_Time = 9401.323
318700/758000 (epoch 840), train_loss = 0.248, time/batch = 0.030, All_Time = 9402.803
318750/758000 (epoch 841), train_loss = 0.216, time/batch = 0.029, All_Time = 9404.287
318800/758000 (epoch 841), train_loss = 0.233, time/batch = 0.030, All_Time = 9405.750
318850/758000 (epoch 841), train_loss = 0.250, time/batch = 0.031, All_Time = 9407.208
318900/758000 (epoch 841), train_loss = 0.241, time/batch = 0.031, All_Time = 9408.719
318950/758000 (epoch 841), train_loss = 0.243, time/batch = 0.029, All_Time = 9410.211
319000/758000 (epoch 841), train_loss = 0.242, time/batch = 0.030, All_Time = 9411.699
model saved to NER/polyglot/model.ckpt
319050/758000 (epoch 841), train_loss = 0.230, time/batch = 0.028, All_Time = 9413.171
319100/758000 (epoch 841), train_loss = 0.259, time/batch = 0.029, All_Time = 9414.640
319150/758000 (epoch 842), train_loss = 0.250, time/batch = 0.030, All_Time = 9416.112
319200/758000 (epoch 842), train_loss = 0.253, time/batch = 0.029, All_Time = 9417.562
319250/758000 (epoch 842), train_loss = 0.245, time/batch = 0.030, All_Time = 9419.033
319300/758000 (epoch 842), train_loss = 0.231, time/batch = 0.029, All_Time = 9420.495
319350/758000 (epoch 842), train_loss = 0.228, time/batch = 0.030, All_Time = 9421.997
319400/758000 (epoch 842), train_loss = 0.238, time/batch = 0.029, All_Time = 9423.490
319450/758000 (epoch 842), train_loss = 0.268, time/batch = 0.029, All_Time = 9424.972
319500/758000 (epoch 843), train_loss = 0.248, time/batch = 0.029, All_Time = 9426.467
319550/758000 (epoch 843), train_loss = 0.280, time/batch = 0.029, All_Time = 9427.932
319600/758000 (epoch 843), train_loss = 0.242, time/batch = 0.030, All_Time = 9429.404
319650/758000 (epoch 843), train_loss = 0.258, time/batch = 0.028, All_Time = 9430.884
319700/758000 (epoch 843), train_loss = 0.224, time/batch = 0.031, All_Time = 9432.348
319750/758000 (epoch 843), train_loss = 0.243, time/batch = 0.031, All_Time = 9433.815
319800/758000 (epoch 843), train_loss = 0.219, time/batch = 0.030, All_Time = 9435.284
319850/758000 (epoch 843), train_loss = 0.232, time/batch = 0.029, All_Time = 9436.751
319900/758000 (epoch 844), train_loss = 0.237, time/batch = 0.031, All_Time = 9438.234
319950/758000 (epoch 844), train_loss = 0.239, time/batch = 0.029, All_Time = 9439.722
320000/758000 (epoch 844), train_loss = 0.293, time/batch = 0.031, All_Time = 9441.240
model saved to NER/polyglot/model.ckpt
320050/758000 (epoch 844), train_loss = 0.318, time/batch = 0.029, All_Time = 9442.709
320100/758000 (epoch 844), train_loss = 0.196, time/batch = 0.030, All_Time = 9444.181
320150/758000 (epoch 844), train_loss = 0.213, time/batch = 0.028, All_Time = 9445.647
320200/758000 (epoch 844), train_loss = 0.250, time/batch = 0.030, All_Time = 9447.135
320250/758000 (epoch 844), train_loss = 0.297, time/batch = 0.031, All_Time = 9448.626
320300/758000 (epoch 845), train_loss = 0.226, time/batch = 0.030, All_Time = 9450.117
320350/758000 (epoch 845), train_loss = 0.259, time/batch = 0.030, All_Time = 9451.586
320400/758000 (epoch 845), train_loss = 0.223, time/batch = 0.030, All_Time = 9453.064
320450/758000 (epoch 845), train_loss = 0.239, time/batch = 0.030, All_Time = 9454.541
320500/758000 (epoch 845), train_loss = 0.212, time/batch = 0.029, All_Time = 9456.026
320550/758000 (epoch 845), train_loss = 0.243, time/batch = 0.030, All_Time = 9457.498
320600/758000 (epoch 845), train_loss = 0.215, time/batch = 0.029, All_Time = 9458.987
320650/758000 (epoch 846), train_loss = 0.228, time/batch = 0.030, All_Time = 9460.473
320700/758000 (epoch 846), train_loss = 0.252, time/batch = 0.029, All_Time = 9461.936
320750/758000 (epoch 846), train_loss = 0.260, time/batch = 0.028, All_Time = 9463.395
320800/758000 (epoch 846), train_loss = 0.228, time/batch = 0.031, All_Time = 9464.879
320850/758000 (epoch 846), train_loss = 0.236, time/batch = 0.028, All_Time = 9466.355
320900/758000 (epoch 846), train_loss = 0.271, time/batch = 0.030, All_Time = 9467.833
320950/758000 (epoch 846), train_loss = 0.238, time/batch = 0.029, All_Time = 9469.309
321000/758000 (epoch 846), train_loss = 0.268, time/batch = 0.030, All_Time = 9470.786
model saved to NER/polyglot/model.ckpt
321050/758000 (epoch 847), train_loss = 0.248, time/batch = 0.028, All_Time = 9472.262
321100/758000 (epoch 847), train_loss = 0.249, time/batch = 0.031, All_Time = 9473.724
321150/758000 (epoch 847), train_loss = 0.240, time/batch = 0.029, All_Time = 9475.194
321200/758000 (epoch 847), train_loss = 0.247, time/batch = 0.028, All_Time = 9476.665
321250/758000 (epoch 847), train_loss = 0.235, time/batch = 0.030, All_Time = 9478.170
321300/758000 (epoch 847), train_loss = 0.247, time/batch = 0.030, All_Time = 9479.657
321350/758000 (epoch 847), train_loss = 0.251, time/batch = 0.030, All_Time = 9481.140
321400/758000 (epoch 848), train_loss = 0.242, time/batch = 0.029, All_Time = 9482.622
321450/758000 (epoch 848), train_loss = 0.276, time/batch = 0.028, All_Time = 9484.079
321500/758000 (epoch 848), train_loss = 0.256, time/batch = 0.030, All_Time = 9485.543
321550/758000 (epoch 848), train_loss = 0.258, time/batch = 0.029, All_Time = 9487.010
321600/758000 (epoch 848), train_loss = 0.213, time/batch = 0.031, All_Time = 9488.495
321650/758000 (epoch 848), train_loss = 0.237, time/batch = 0.030, All_Time = 9489.998
321700/758000 (epoch 848), train_loss = 0.249, time/batch = 0.030, All_Time = 9491.478
321750/758000 (epoch 848), train_loss = 0.251, time/batch = 0.029, All_Time = 9492.953
321800/758000 (epoch 849), train_loss = 0.232, time/batch = 0.030, All_Time = 9494.442
321850/758000 (epoch 849), train_loss = 0.255, time/batch = 0.031, All_Time = 9495.906
321900/758000 (epoch 849), train_loss = 0.265, time/batch = 0.029, All_Time = 9497.376
321950/758000 (epoch 849), train_loss = 0.229, time/batch = 0.031, All_Time = 9498.846
322000/758000 (epoch 849), train_loss = 0.263, time/batch = 0.028, All_Time = 9500.317
model saved to NER/polyglot/model.ckpt
322050/758000 (epoch 849), train_loss = 0.217, time/batch = 0.030, All_Time = 9501.791
322100/758000 (epoch 849), train_loss = 0.248, time/batch = 0.029, All_Time = 9503.258
322150/758000 (epoch 850), train_loss = 0.059, time/batch = 0.040, All_Time = 9504.774
322200/758000 (epoch 850), train_loss = 0.250, time/batch = 0.030, All_Time = 9506.251
322250/758000 (epoch 850), train_loss = 0.223, time/batch = 0.029, All_Time = 9507.719
322300/758000 (epoch 850), train_loss = 0.250, time/batch = 0.030, All_Time = 9509.202
322350/758000 (epoch 850), train_loss = 0.231, time/batch = 0.031, All_Time = 9510.685
322400/758000 (epoch 850), train_loss = 0.250, time/batch = 0.029, All_Time = 9512.159
322450/758000 (epoch 850), train_loss = 0.232, time/batch = 0.030, All_Time = 9513.641
322500/758000 (epoch 850), train_loss = 0.230, time/batch = 0.031, All_Time = 9515.133
322550/758000 (epoch 851), train_loss = 0.224, time/batch = 0.030, All_Time = 9516.617
322600/758000 (epoch 851), train_loss = 0.233, time/batch = 0.031, All_Time = 9518.110
322650/758000 (epoch 851), train_loss = 0.224, time/batch = 0.029, All_Time = 9519.587
322700/758000 (epoch 851), train_loss = 0.262, time/batch = 0.030, All_Time = 9521.078
322750/758000 (epoch 851), train_loss = 0.220, time/batch = 0.029, All_Time = 9522.553
322800/758000 (epoch 851), train_loss = 0.228, time/batch = 0.030, All_Time = 9524.035
322850/758000 (epoch 851), train_loss = 0.280, time/batch = 0.030, All_Time = 9525.503
322900/758000 (epoch 851), train_loss = 0.272, time/batch = 0.029, All_Time = 9526.975
322950/758000 (epoch 852), train_loss = 0.230, time/batch = 0.029, All_Time = 9528.443
323000/758000 (epoch 852), train_loss = 0.224, time/batch = 0.029, All_Time = 9529.913
model saved to NER/polyglot/model.ckpt
323050/758000 (epoch 852), train_loss = 0.201, time/batch = 0.028, All_Time = 9531.379
323100/758000 (epoch 852), train_loss = 0.270, time/batch = 0.031, All_Time = 9532.853
323150/758000 (epoch 852), train_loss = 0.259, time/batch = 0.030, All_Time = 9534.365
323200/758000 (epoch 852), train_loss = 0.209, time/batch = 0.029, All_Time = 9535.840
323250/758000 (epoch 852), train_loss = 0.218, time/batch = 0.028, All_Time = 9537.325
323300/758000 (epoch 853), train_loss = 0.229, time/batch = 0.031, All_Time = 9538.806
323350/758000 (epoch 853), train_loss = 0.283, time/batch = 0.029, All_Time = 9540.274
323400/758000 (epoch 853), train_loss = 0.231, time/batch = 0.030, All_Time = 9541.747
323450/758000 (epoch 853), train_loss = 0.307, time/batch = 0.030, All_Time = 9543.259
323500/758000 (epoch 853), train_loss = 0.221, time/batch = 0.030, All_Time = 9544.754
323550/758000 (epoch 853), train_loss = 0.208, time/batch = 0.028, All_Time = 9546.222
323600/758000 (epoch 853), train_loss = 0.247, time/batch = 0.031, All_Time = 9547.707
323650/758000 (epoch 853), train_loss = 0.252, time/batch = 0.031, All_Time = 9549.183
323700/758000 (epoch 854), train_loss = 0.264, time/batch = 0.029, All_Time = 9550.664
323750/758000 (epoch 854), train_loss = 0.229, time/batch = 0.029, All_Time = 9552.140
323800/758000 (epoch 854), train_loss = 0.242, time/batch = 0.031, All_Time = 9553.604
323850/758000 (epoch 854), train_loss = 0.267, time/batch = 0.030, All_Time = 9555.080
323900/758000 (epoch 854), train_loss = 0.249, time/batch = 0.029, All_Time = 9556.554
323950/758000 (epoch 854), train_loss = 0.237, time/batch = 0.030, All_Time = 9558.032
324000/758000 (epoch 854), train_loss = 0.276, time/batch = 0.028, All_Time = 9559.510
model saved to NER/polyglot/model.ckpt
324050/758000 (epoch 855), train_loss = 0.256, time/batch = 0.029, All_Time = 9560.985
324100/758000 (epoch 855), train_loss = 0.222, time/batch = 0.029, All_Time = 9562.449
324150/758000 (epoch 855), train_loss = 0.266, time/batch = 0.030, All_Time = 9563.940
324200/758000 (epoch 855), train_loss = 0.216, time/batch = 0.030, All_Time = 9565.442
324250/758000 (epoch 855), train_loss = 0.223, time/batch = 0.029, All_Time = 9566.927
324300/758000 (epoch 855), train_loss = 0.261, time/batch = 0.030, All_Time = 9568.409
324350/758000 (epoch 855), train_loss = 0.238, time/batch = 0.030, All_Time = 9569.880
324400/758000 (epoch 855), train_loss = 0.264, time/batch = 0.030, All_Time = 9571.356
324450/758000 (epoch 856), train_loss = 0.223, time/batch = 0.030, All_Time = 9572.843
324500/758000 (epoch 856), train_loss = 0.231, time/batch = 0.031, All_Time = 9574.317
324550/758000 (epoch 856), train_loss = 0.238, time/batch = 0.029, All_Time = 9575.789
324600/758000 (epoch 856), train_loss = 0.266, time/batch = 0.029, All_Time = 9577.248
324650/758000 (epoch 856), train_loss = 0.239, time/batch = 0.029, All_Time = 9578.752
324700/758000 (epoch 856), train_loss = 0.226, time/batch = 0.028, All_Time = 9580.238
324750/758000 (epoch 856), train_loss = 0.276, time/batch = 0.031, All_Time = 9581.728
324800/758000 (epoch 856), train_loss = 0.240, time/batch = 0.031, All_Time = 9583.214
324850/758000 (epoch 857), train_loss = 0.281, time/batch = 0.029, All_Time = 9584.704
324900/758000 (epoch 857), train_loss = 0.257, time/batch = 0.030, All_Time = 9586.183
324950/758000 (epoch 857), train_loss = 0.240, time/batch = 0.029, All_Time = 9587.653
325000/758000 (epoch 857), train_loss = 0.231, time/batch = 0.030, All_Time = 9589.118
model saved to NER/polyglot/model.ckpt
325050/758000 (epoch 857), train_loss = 0.217, time/batch = 0.029, All_Time = 9590.595
325100/758000 (epoch 857), train_loss = 0.224, time/batch = 0.029, All_Time = 9592.055
325150/758000 (epoch 857), train_loss = 0.215, time/batch = 0.030, All_Time = 9593.518
325200/758000 (epoch 858), train_loss = 0.249, time/batch = 0.030, All_Time = 9594.986
325250/758000 (epoch 858), train_loss = 0.211, time/batch = 0.029, All_Time = 9596.444
325300/758000 (epoch 858), train_loss = 0.245, time/batch = 0.033, All_Time = 9597.931
325350/758000 (epoch 858), train_loss = 0.217, time/batch = 0.031, All_Time = 9599.432
325400/758000 (epoch 858), train_loss = 0.233, time/batch = 0.031, All_Time = 9600.921
325450/758000 (epoch 858), train_loss = 0.228, time/batch = 0.029, All_Time = 9602.406
325500/758000 (epoch 858), train_loss = 0.248, time/batch = 0.028, All_Time = 9603.882
325550/758000 (epoch 858), train_loss = 0.229, time/batch = 0.031, All_Time = 9605.377
325600/758000 (epoch 859), train_loss = 0.218, time/batch = 0.030, All_Time = 9606.862
325650/758000 (epoch 859), train_loss = 0.237, time/batch = 0.029, All_Time = 9608.338
325700/758000 (epoch 859), train_loss = 0.212, time/batch = 0.029, All_Time = 9609.815
325750/758000 (epoch 859), train_loss = 0.266, time/batch = 0.030, All_Time = 9611.300
325800/758000 (epoch 859), train_loss = 0.255, time/batch = 0.029, All_Time = 9612.782
325850/758000 (epoch 859), train_loss = 0.232, time/batch = 0.030, All_Time = 9614.268
325900/758000 (epoch 859), train_loss = 0.262, time/batch = 0.030, All_Time = 9615.756
325950/758000 (epoch 860), train_loss = 0.282, time/batch = 0.028, All_Time = 9617.254
326000/758000 (epoch 860), train_loss = 0.292, time/batch = 0.029, All_Time = 9618.725
model saved to NER/polyglot/model.ckpt
326050/758000 (epoch 860), train_loss = 0.253, time/batch = 0.029, All_Time = 9620.197
326100/758000 (epoch 860), train_loss = 0.222, time/batch = 0.029, All_Time = 9621.657
326150/758000 (epoch 860), train_loss = 0.221, time/batch = 0.032, All_Time = 9623.145
326200/758000 (epoch 860), train_loss = 0.260, time/batch = 0.031, All_Time = 9624.636
326250/758000 (epoch 860), train_loss = 0.244, time/batch = 0.029, All_Time = 9626.129
326300/758000 (epoch 860), train_loss = 0.247, time/batch = 0.030, All_Time = 9627.607
326350/758000 (epoch 861), train_loss = 0.210, time/batch = 0.029, All_Time = 9629.088
326400/758000 (epoch 861), train_loss = 0.265, time/batch = 0.029, All_Time = 9630.561
326450/758000 (epoch 861), train_loss = 0.229, time/batch = 0.028, All_Time = 9632.037
326500/758000 (epoch 861), train_loss = 0.232, time/batch = 0.029, All_Time = 9633.502
326550/758000 (epoch 861), train_loss = 0.230, time/batch = 0.030, All_Time = 9634.989
326600/758000 (epoch 861), train_loss = 0.253, time/batch = 0.030, All_Time = 9636.486
326650/758000 (epoch 861), train_loss = 0.258, time/batch = 0.031, All_Time = 9637.973
326700/758000 (epoch 862), train_loss = 0.196, time/batch = 0.030, All_Time = 9639.463
326750/758000 (epoch 862), train_loss = 0.254, time/batch = 0.029, All_Time = 9640.931
326800/758000 (epoch 862), train_loss = 0.281, time/batch = 0.029, All_Time = 9642.411
326850/758000 (epoch 862), train_loss = 0.235, time/batch = 0.029, All_Time = 9643.876
326900/758000 (epoch 862), train_loss = 0.247, time/batch = 0.030, All_Time = 9645.338
326950/758000 (epoch 862), train_loss = 0.251, time/batch = 0.030, All_Time = 9646.844
327000/758000 (epoch 862), train_loss = 0.203, time/batch = 0.028, All_Time = 9648.350
model saved to NER/polyglot/model.ckpt
327050/758000 (epoch 862), train_loss = 0.268, time/batch = 0.029, All_Time = 9649.824
327100/758000 (epoch 863), train_loss = 0.233, time/batch = 0.030, All_Time = 9651.294
327150/758000 (epoch 863), train_loss = 0.241, time/batch = 0.029, All_Time = 9652.745
327200/758000 (epoch 863), train_loss = 0.252, time/batch = 0.028, All_Time = 9654.206
327250/758000 (epoch 863), train_loss = 0.258, time/batch = 0.029, All_Time = 9655.680
327300/758000 (epoch 863), train_loss = 0.243, time/batch = 0.029, All_Time = 9657.184
327350/758000 (epoch 863), train_loss = 0.243, time/batch = 0.029, All_Time = 9658.658
327400/758000 (epoch 863), train_loss = 0.244, time/batch = 0.028, All_Time = 9660.135
327450/758000 (epoch 863), train_loss = 0.286, time/batch = 0.029, All_Time = 9661.627
327500/758000 (epoch 864), train_loss = 0.207, time/batch = 0.031, All_Time = 9663.129
327550/758000 (epoch 864), train_loss = 0.244, time/batch = 0.030, All_Time = 9664.610
327600/758000 (epoch 864), train_loss = 0.217, time/batch = 0.029, All_Time = 9666.094
327650/758000 (epoch 864), train_loss = 0.233, time/batch = 0.029, All_Time = 9667.563
327700/758000 (epoch 864), train_loss = 0.260, time/batch = 0.029, All_Time = 9669.045
327750/758000 (epoch 864), train_loss = 0.253, time/batch = 0.031, All_Time = 9670.521
327800/758000 (epoch 864), train_loss = 0.238, time/batch = 0.031, All_Time = 9672.000
327850/758000 (epoch 865), train_loss = 0.227, time/batch = 0.029, All_Time = 9673.479
327900/758000 (epoch 865), train_loss = 0.250, time/batch = 0.031, All_Time = 9674.952
327950/758000 (epoch 865), train_loss = 0.250, time/batch = 0.029, All_Time = 9676.421
328000/758000 (epoch 865), train_loss = 0.223, time/batch = 0.029, All_Time = 9677.895
model saved to NER/polyglot/model.ckpt
328050/758000 (epoch 865), train_loss = 0.240, time/batch = 0.030, All_Time = 9679.365
328100/758000 (epoch 865), train_loss = 0.246, time/batch = 0.034, All_Time = 9680.865
328150/758000 (epoch 865), train_loss = 0.246, time/batch = 0.030, All_Time = 9682.362
328200/758000 (epoch 865), train_loss = 0.257, time/batch = 0.030, All_Time = 9683.840
328250/758000 (epoch 866), train_loss = 0.266, time/batch = 0.031, All_Time = 9685.323
328300/758000 (epoch 866), train_loss = 0.224, time/batch = 0.031, All_Time = 9686.788
328350/758000 (epoch 866), train_loss = 0.248, time/batch = 0.029, All_Time = 9688.250
328400/758000 (epoch 866), train_loss = 0.227, time/batch = 0.030, All_Time = 9689.726
328450/758000 (epoch 866), train_loss = 0.279, time/batch = 0.031, All_Time = 9691.200
328500/758000 (epoch 866), train_loss = 0.255, time/batch = 0.029, All_Time = 9692.669
328550/758000 (epoch 866), train_loss = 0.253, time/batch = 0.030, All_Time = 9694.144
328600/758000 (epoch 867), train_loss = 0.244, time/batch = 0.029, All_Time = 9695.625
328650/758000 (epoch 867), train_loss = 0.247, time/batch = 0.029, All_Time = 9697.097
328700/758000 (epoch 867), train_loss = 0.270, time/batch = 0.029, All_Time = 9698.577
328750/758000 (epoch 867), train_loss = 0.246, time/batch = 0.030, All_Time = 9700.063
328800/758000 (epoch 867), train_loss = 0.237, time/batch = 0.029, All_Time = 9701.569
328850/758000 (epoch 867), train_loss = 0.224, time/batch = 0.031, All_Time = 9703.053
328900/758000 (epoch 867), train_loss = 0.229, time/batch = 0.030, All_Time = 9704.536
328950/758000 (epoch 867), train_loss = 0.246, time/batch = 0.029, All_Time = 9706.027
329000/758000 (epoch 868), train_loss = 0.249, time/batch = 0.030, All_Time = 9707.518
model saved to NER/polyglot/model.ckpt
329050/758000 (epoch 868), train_loss = 0.264, time/batch = 0.030, All_Time = 9708.994
329100/758000 (epoch 868), train_loss = 0.240, time/batch = 0.030, All_Time = 9710.453
329150/758000 (epoch 868), train_loss = 0.250, time/batch = 0.030, All_Time = 9711.926
329200/758000 (epoch 868), train_loss = 0.227, time/batch = 0.031, All_Time = 9713.381
329250/758000 (epoch 868), train_loss = 0.217, time/batch = 0.030, All_Time = 9714.869
329300/758000 (epoch 868), train_loss = 0.277, time/batch = 0.029, All_Time = 9716.356
329350/758000 (epoch 868), train_loss = 0.259, time/batch = 0.031, All_Time = 9717.838
329400/758000 (epoch 869), train_loss = 0.269, time/batch = 0.029, All_Time = 9719.327
329450/758000 (epoch 869), train_loss = 0.296, time/batch = 0.030, All_Time = 9720.807
329500/758000 (epoch 869), train_loss = 0.228, time/batch = 0.029, All_Time = 9722.278
329550/758000 (epoch 869), train_loss = 0.220, time/batch = 0.030, All_Time = 9723.759
329600/758000 (epoch 869), train_loss = 0.257, time/batch = 0.030, All_Time = 9725.232
329650/758000 (epoch 869), train_loss = 0.255, time/batch = 0.030, All_Time = 9726.703
329700/758000 (epoch 869), train_loss = 0.237, time/batch = 0.028, All_Time = 9728.182
329750/758000 (epoch 870), train_loss = 0.225, time/batch = 0.028, All_Time = 9729.669
329800/758000 (epoch 870), train_loss = 0.234, time/batch = 0.030, All_Time = 9731.144
329850/758000 (epoch 870), train_loss = 0.243, time/batch = 0.031, All_Time = 9732.617
329900/758000 (epoch 870), train_loss = 0.234, time/batch = 0.031, All_Time = 9734.120
329950/758000 (epoch 870), train_loss = 0.223, time/batch = 0.030, All_Time = 9735.618
330000/758000 (epoch 870), train_loss = 0.239, time/batch = 0.029, All_Time = 9737.095
model saved to NER/polyglot/model.ckpt
330050/758000 (epoch 870), train_loss = 0.264, time/batch = 0.029, All_Time = 9738.574
330100/758000 (epoch 870), train_loss = 0.244, time/batch = 0.029, All_Time = 9740.050
330150/758000 (epoch 871), train_loss = 0.257, time/batch = 0.030, All_Time = 9741.543
330200/758000 (epoch 871), train_loss = 0.287, time/batch = 0.031, All_Time = 9743.011
330250/758000 (epoch 871), train_loss = 0.255, time/batch = 0.032, All_Time = 9744.471
330300/758000 (epoch 871), train_loss = 0.248, time/batch = 0.031, All_Time = 9745.962
330350/758000 (epoch 871), train_loss = 0.212, time/batch = 0.030, All_Time = 9747.462
330400/758000 (epoch 871), train_loss = 0.229, time/batch = 0.032, All_Time = 9748.950
330450/758000 (epoch 871), train_loss = 0.272, time/batch = 0.030, All_Time = 9750.431
330500/758000 (epoch 872), train_loss = 0.249, time/batch = 0.031, All_Time = 9751.916
330550/758000 (epoch 872), train_loss = 0.227, time/batch = 0.029, All_Time = 9753.380
330600/758000 (epoch 872), train_loss = 0.267, time/batch = 0.028, All_Time = 9754.848
330650/758000 (epoch 872), train_loss = 0.239, time/batch = 0.028, All_Time = 9756.337
330700/758000 (epoch 872), train_loss = 0.247, time/batch = 0.029, All_Time = 9757.828
330750/758000 (epoch 872), train_loss = 0.241, time/batch = 0.029, All_Time = 9759.314
330800/758000 (epoch 872), train_loss = 0.274, time/batch = 0.030, All_Time = 9760.806
330850/758000 (epoch 872), train_loss = 0.279, time/batch = 0.031, All_Time = 9762.303
330900/758000 (epoch 873), train_loss = 0.238, time/batch = 0.030, All_Time = 9763.800
330950/758000 (epoch 873), train_loss = 0.248, time/batch = 0.030, All_Time = 9765.269
331000/758000 (epoch 873), train_loss = 0.299, time/batch = 0.029, All_Time = 9766.758
model saved to NER/polyglot/model.ckpt
331050/758000 (epoch 873), train_loss = 0.230, time/batch = 0.031, All_Time = 9768.227
331100/758000 (epoch 873), train_loss = 0.216, time/batch = 0.030, All_Time = 9769.697
331150/758000 (epoch 873), train_loss = 0.244, time/batch = 0.031, All_Time = 9771.173
331200/758000 (epoch 873), train_loss = 0.274, time/batch = 0.030, All_Time = 9772.632
331250/758000 (epoch 874), train_loss = 0.221, time/batch = 0.029, All_Time = 9774.113
331300/758000 (epoch 874), train_loss = 0.257, time/batch = 0.029, All_Time = 9775.595
331350/758000 (epoch 874), train_loss = 0.241, time/batch = 0.030, All_Time = 9777.099
331400/758000 (epoch 874), train_loss = 0.240, time/batch = 0.030, All_Time = 9778.575
331450/758000 (epoch 874), train_loss = 0.256, time/batch = 0.029, All_Time = 9780.070
331500/758000 (epoch 874), train_loss = 0.219, time/batch = 0.029, All_Time = 9781.559
331550/758000 (epoch 874), train_loss = 0.224, time/batch = 0.030, All_Time = 9783.038
331600/758000 (epoch 874), train_loss = 0.257, time/batch = 0.029, All_Time = 9784.525
331650/758000 (epoch 875), train_loss = 0.255, time/batch = 0.030, All_Time = 9786.012
331700/758000 (epoch 875), train_loss = 0.267, time/batch = 0.030, All_Time = 9787.478
331750/758000 (epoch 875), train_loss = 0.269, time/batch = 0.031, All_Time = 9788.952
331800/758000 (epoch 875), train_loss = 0.228, time/batch = 0.031, All_Time = 9790.420
331850/758000 (epoch 875), train_loss = 0.234, time/batch = 0.030, All_Time = 9791.889
331900/758000 (epoch 875), train_loss = 0.245, time/batch = 0.028, All_Time = 9793.358
331950/758000 (epoch 875), train_loss = 0.279, time/batch = 0.032, All_Time = 9794.822
332000/758000 (epoch 875), train_loss = 0.240, time/batch = 0.030, All_Time = 9796.331
model saved to NER/polyglot/model.ckpt
332050/758000 (epoch 876), train_loss = 0.236, time/batch = 0.030, All_Time = 9797.808
332100/758000 (epoch 876), train_loss = 0.234, time/batch = 0.030, All_Time = 9799.278
332150/758000 (epoch 876), train_loss = 0.233, time/batch = 0.029, All_Time = 9800.737
332200/758000 (epoch 876), train_loss = 0.276, time/batch = 0.028, All_Time = 9802.205
332250/758000 (epoch 876), train_loss = 0.206, time/batch = 0.031, All_Time = 9803.680
332300/758000 (epoch 876), train_loss = 0.259, time/batch = 0.030, All_Time = 9805.162
332350/758000 (epoch 876), train_loss = 0.234, time/batch = 0.031, All_Time = 9806.760
332400/758000 (epoch 877), train_loss = 0.245, time/batch = 0.030, All_Time = 9808.301
332450/758000 (epoch 877), train_loss = 0.223, time/batch = 0.033, All_Time = 9809.784
332500/758000 (epoch 877), train_loss = 0.240, time/batch = 0.030, All_Time = 9811.265
332550/758000 (epoch 877), train_loss = 0.256, time/batch = 0.030, All_Time = 9812.744
332600/758000 (epoch 877), train_loss = 0.214, time/batch = 0.029, All_Time = 9814.226
332650/758000 (epoch 877), train_loss = 0.272, time/batch = 0.029, All_Time = 9815.692
332700/758000 (epoch 877), train_loss = 0.213, time/batch = 0.031, All_Time = 9817.176
332750/758000 (epoch 877), train_loss = 0.251, time/batch = 0.030, All_Time = 9818.658
332800/758000 (epoch 878), train_loss = 0.247, time/batch = 0.030, All_Time = 9820.141
332850/758000 (epoch 878), train_loss = 0.229, time/batch = 0.031, All_Time = 9821.618
332900/758000 (epoch 878), train_loss = 0.217, time/batch = 0.028, All_Time = 9823.080
332950/758000 (epoch 878), train_loss = 0.220, time/batch = 0.030, All_Time = 9824.545
333000/758000 (epoch 878), train_loss = 0.250, time/batch = 0.030, All_Time = 9826.013
model saved to NER/polyglot/model.ckpt
333050/758000 (epoch 878), train_loss = 0.207, time/batch = 0.029, All_Time = 9827.486
333100/758000 (epoch 878), train_loss = 0.268, time/batch = 0.029, All_Time = 9828.938
333150/758000 (epoch 879), train_loss = 0.256, time/batch = 0.030, All_Time = 9830.440
333200/758000 (epoch 879), train_loss = 0.264, time/batch = 0.031, All_Time = 9831.913
333250/758000 (epoch 879), train_loss = 0.284, time/batch = 0.028, All_Time = 9833.390
333300/758000 (epoch 879), train_loss = 0.239, time/batch = 0.031, All_Time = 9834.868
333350/758000 (epoch 879), train_loss = 0.267, time/batch = 0.030, All_Time = 9836.346
333400/758000 (epoch 879), train_loss = 0.256, time/batch = 0.030, All_Time = 9837.829
333450/758000 (epoch 879), train_loss = 0.236, time/batch = 0.029, All_Time = 9839.310
333500/758000 (epoch 879), train_loss = 0.268, time/batch = 0.029, All_Time = 9840.778
333550/758000 (epoch 880), train_loss = 0.226, time/batch = 0.030, All_Time = 9842.255
333600/758000 (epoch 880), train_loss = 0.222, time/batch = 0.029, All_Time = 9843.712
333650/758000 (epoch 880), train_loss = 0.261, time/batch = 0.030, All_Time = 9845.205
333700/758000 (epoch 880), train_loss = 0.254, time/batch = 0.029, All_Time = 9846.703
333750/758000 (epoch 880), train_loss = 0.223, time/batch = 0.031, All_Time = 9848.194
333800/758000 (epoch 880), train_loss = 0.242, time/batch = 0.029, All_Time = 9849.662
333850/758000 (epoch 880), train_loss = 0.251, time/batch = 0.030, All_Time = 9851.147
333900/758000 (epoch 881), train_loss = 0.192, time/batch = 0.029, All_Time = 9852.643
333950/758000 (epoch 881), train_loss = 0.273, time/batch = 0.028, All_Time = 9854.111
334000/758000 (epoch 881), train_loss = 0.217, time/batch = 0.030, All_Time = 9855.582
model saved to NER/polyglot/model.ckpt
334050/758000 (epoch 881), train_loss = 0.240, time/batch = 0.030, All_Time = 9857.052
334100/758000 (epoch 881), train_loss = 0.221, time/batch = 0.030, All_Time = 9858.520
334150/758000 (epoch 881), train_loss = 0.221, time/batch = 0.029, All_Time = 9859.997
334200/758000 (epoch 881), train_loss = 0.252, time/batch = 0.030, All_Time = 9861.472
334250/758000 (epoch 881), train_loss = 0.272, time/batch = 0.029, All_Time = 9862.953
334300/758000 (epoch 882), train_loss = 0.222, time/batch = 0.028, All_Time = 9864.431
334350/758000 (epoch 882), train_loss = 0.279, time/batch = 0.029, All_Time = 9865.898
334400/758000 (epoch 882), train_loss = 0.242, time/batch = 0.029, All_Time = 9867.363
334450/758000 (epoch 882), train_loss = 0.274, time/batch = 0.029, All_Time = 9868.819
334500/758000 (epoch 882), train_loss = 0.262, time/batch = 0.029, All_Time = 9870.329
334550/758000 (epoch 882), train_loss = 0.197, time/batch = 0.030, All_Time = 9871.804
334600/758000 (epoch 882), train_loss = 0.233, time/batch = 0.028, All_Time = 9873.287
334650/758000 (epoch 882), train_loss = 0.281, time/batch = 0.029, All_Time = 9874.777
334700/758000 (epoch 883), train_loss = 0.246, time/batch = 0.030, All_Time = 9876.263
334750/758000 (epoch 883), train_loss = 0.212, time/batch = 0.030, All_Time = 9877.739
334800/758000 (epoch 883), train_loss = 0.255, time/batch = 0.030, All_Time = 9879.211
334850/758000 (epoch 883), train_loss = 0.271, time/batch = 0.030, All_Time = 9880.669
334900/758000 (epoch 883), train_loss = 0.203, time/batch = 0.029, All_Time = 9882.133
334950/758000 (epoch 883), train_loss = 0.226, time/batch = 0.030, All_Time = 9883.617
335000/758000 (epoch 883), train_loss = 0.254, time/batch = 0.031, All_Time = 9885.102
model saved to NER/polyglot/model.ckpt
335050/758000 (epoch 884), train_loss = 0.219, time/batch = 0.029, All_Time = 9886.585
335100/758000 (epoch 884), train_loss = 0.265, time/batch = 0.029, All_Time = 9888.056
335150/758000 (epoch 884), train_loss = 0.227, time/batch = 0.029, All_Time = 9889.523
335200/758000 (epoch 884), train_loss = 0.213, time/batch = 0.031, All_Time = 9891.021
335250/758000 (epoch 884), train_loss = 0.224, time/batch = 0.030, All_Time = 9892.505
335300/758000 (epoch 884), train_loss = 0.213, time/batch = 0.030, All_Time = 9893.998
335350/758000 (epoch 884), train_loss = 0.230, time/batch = 0.029, All_Time = 9895.475
335400/758000 (epoch 884), train_loss = 0.223, time/batch = 0.031, All_Time = 9896.959
335450/758000 (epoch 885), train_loss = 0.275, time/batch = 0.029, All_Time = 9898.442
335500/758000 (epoch 885), train_loss = 0.229, time/batch = 0.029, All_Time = 9899.923
335550/758000 (epoch 885), train_loss = 0.270, time/batch = 0.028, All_Time = 9901.389
335600/758000 (epoch 885), train_loss = 0.273, time/batch = 0.034, All_Time = 9902.880
335650/758000 (epoch 885), train_loss = 0.233, time/batch = 0.029, All_Time = 9904.352
335700/758000 (epoch 885), train_loss = 0.268, time/batch = 0.030, All_Time = 9905.830
335750/758000 (epoch 885), train_loss = 0.280, time/batch = 0.029, All_Time = 9907.306
335800/758000 (epoch 886), train_loss = 0.239, time/batch = 0.030, All_Time = 9908.798
335850/758000 (epoch 886), train_loss = 0.218, time/batch = 0.029, All_Time = 9910.266
335900/758000 (epoch 886), train_loss = 0.243, time/batch = 0.030, All_Time = 9911.725
335950/758000 (epoch 886), train_loss = 0.244, time/batch = 0.030, All_Time = 9913.188
336000/758000 (epoch 886), train_loss = 0.243, time/batch = 0.030, All_Time = 9914.651
model saved to NER/polyglot/model.ckpt
336050/758000 (epoch 886), train_loss = 0.244, time/batch = 0.028, All_Time = 9916.117
336100/758000 (epoch 886), train_loss = 0.213, time/batch = 0.028, All_Time = 9917.613
336150/758000 (epoch 886), train_loss = 0.289, time/batch = 0.030, All_Time = 9919.107
336200/758000 (epoch 887), train_loss = 0.237, time/batch = 0.029, All_Time = 9920.611
336250/758000 (epoch 887), train_loss = 0.246, time/batch = 0.029, All_Time = 9922.079
336300/758000 (epoch 887), train_loss = 0.288, time/batch = 0.029, All_Time = 9923.552
336350/758000 (epoch 887), train_loss = 0.257, time/batch = 0.029, All_Time = 9925.022
336400/758000 (epoch 887), train_loss = 0.218, time/batch = 0.029, All_Time = 9926.492
336450/758000 (epoch 887), train_loss = 0.238, time/batch = 0.029, All_Time = 9927.977
336500/758000 (epoch 887), train_loss = 0.251, time/batch = 0.030, All_Time = 9929.468
336550/758000 (epoch 887), train_loss = 0.251, time/batch = 0.030, All_Time = 9930.953
336600/758000 (epoch 888), train_loss = 0.252, time/batch = 0.030, All_Time = 9932.438
336650/758000 (epoch 888), train_loss = 0.280, time/batch = 0.030, All_Time = 9933.915
336700/758000 (epoch 888), train_loss = 0.242, time/batch = 0.030, All_Time = 9935.375
336750/758000 (epoch 888), train_loss = 0.250, time/batch = 0.030, All_Time = 9936.850
336800/758000 (epoch 888), train_loss = 0.239, time/batch = 0.029, All_Time = 9938.334
336850/758000 (epoch 888), train_loss = 0.239, time/batch = 0.030, All_Time = 9939.823
336900/758000 (epoch 888), train_loss = 0.250, time/batch = 0.029, All_Time = 9941.326
336950/758000 (epoch 889), train_loss = 0.221, time/batch = 0.031, All_Time = 9942.824
337000/758000 (epoch 889), train_loss = 0.219, time/batch = 0.029, All_Time = 9944.308
model saved to NER/polyglot/model.ckpt
337050/758000 (epoch 889), train_loss = 0.246, time/batch = 0.029, All_Time = 9945.780
337100/758000 (epoch 889), train_loss = 0.262, time/batch = 0.028, All_Time = 9947.247
337150/758000 (epoch 889), train_loss = 0.260, time/batch = 0.029, All_Time = 9948.715
337200/758000 (epoch 889), train_loss = 0.241, time/batch = 0.029, All_Time = 9950.174
337250/758000 (epoch 889), train_loss = 0.210, time/batch = 0.030, All_Time = 9951.648
337300/758000 (epoch 889), train_loss = 0.239, time/batch = 0.028, All_Time = 9953.114
337350/758000 (epoch 890), train_loss = 0.230, time/batch = 0.029, All_Time = 9954.592
337400/758000 (epoch 890), train_loss = 0.226, time/batch = 0.029, All_Time = 9956.055
337450/758000 (epoch 890), train_loss = 0.264, time/batch = 0.030, All_Time = 9957.529
337500/758000 (epoch 890), train_loss = 0.240, time/batch = 0.032, All_Time = 9959.056
337550/758000 (epoch 890), train_loss = 0.253, time/batch = 0.030, All_Time = 9960.536
337600/758000 (epoch 890), train_loss = 0.251, time/batch = 0.031, All_Time = 9962.018
337650/758000 (epoch 890), train_loss = 0.248, time/batch = 0.030, All_Time = 9963.508
337700/758000 (epoch 891), train_loss = 0.216, time/batch = 0.029, All_Time = 9965.009
337750/758000 (epoch 891), train_loss = 0.233, time/batch = 0.029, All_Time = 9966.485
337800/758000 (epoch 891), train_loss = 0.250, time/batch = 0.030, All_Time = 9967.964
337850/758000 (epoch 891), train_loss = 0.241, time/batch = 0.030, All_Time = 9969.441
337900/758000 (epoch 891), train_loss = 0.243, time/batch = 0.029, All_Time = 9970.937
337950/758000 (epoch 891), train_loss = 0.242, time/batch = 0.031, All_Time = 9972.416
338000/758000 (epoch 891), train_loss = 0.230, time/batch = 0.030, All_Time = 9973.900
model saved to NER/polyglot/model.ckpt
338050/758000 (epoch 891), train_loss = 0.259, time/batch = 0.029, All_Time = 9975.370
338100/758000 (epoch 892), train_loss = 0.250, time/batch = 0.031, All_Time = 9976.849
338150/758000 (epoch 892), train_loss = 0.253, time/batch = 0.029, All_Time = 9978.313
338200/758000 (epoch 892), train_loss = 0.245, time/batch = 0.030, All_Time = 9979.772
338250/758000 (epoch 892), train_loss = 0.231, time/batch = 0.029, All_Time = 9981.233
338300/758000 (epoch 892), train_loss = 0.228, time/batch = 0.029, All_Time = 9982.688
338350/758000 (epoch 892), train_loss = 0.238, time/batch = 0.031, All_Time = 9984.174
338400/758000 (epoch 892), train_loss = 0.268, time/batch = 0.030, All_Time = 9985.666
338450/758000 (epoch 893), train_loss = 0.248, time/batch = 0.031, All_Time = 9987.155
338500/758000 (epoch 893), train_loss = 0.280, time/batch = 0.030, All_Time = 9988.635
338550/758000 (epoch 893), train_loss = 0.242, time/batch = 0.029, All_Time = 9990.096
338600/758000 (epoch 893), train_loss = 0.258, time/batch = 0.030, All_Time = 9991.572
338650/758000 (epoch 893), train_loss = 0.224, time/batch = 0.030, All_Time = 9993.041
338700/758000 (epoch 893), train_loss = 0.243, time/batch = 0.029, All_Time = 9994.510
338750/758000 (epoch 893), train_loss = 0.219, time/batch = 0.030, All_Time = 9995.982
338800/758000 (epoch 893), train_loss = 0.232, time/batch = 0.031, All_Time = 9997.486
338850/758000 (epoch 894), train_loss = 0.237, time/batch = 0.029, All_Time = 9998.997
338900/758000 (epoch 894), train_loss = 0.239, time/batch = 0.030, All_Time = 10000.478
338950/758000 (epoch 894), train_loss = 0.293, time/batch = 0.028, All_Time = 10001.963
339000/758000 (epoch 894), train_loss = 0.318, time/batch = 0.029, All_Time = 10003.442
model saved to NER/polyglot/model.ckpt
339050/758000 (epoch 894), train_loss = 0.196, time/batch = 0.030, All_Time = 10004.917
339100/758000 (epoch 894), train_loss = 0.213, time/batch = 0.028, All_Time = 10006.384
339150/758000 (epoch 894), train_loss = 0.250, time/batch = 0.029, All_Time = 10007.851
339200/758000 (epoch 894), train_loss = 0.297, time/batch = 0.031, All_Time = 10009.320
339250/758000 (epoch 895), train_loss = 0.226, time/batch = 0.030, All_Time = 10010.800
339300/758000 (epoch 895), train_loss = 0.259, time/batch = 0.030, All_Time = 10012.268
339350/758000 (epoch 895), train_loss = 0.223, time/batch = 0.028, All_Time = 10013.743
339400/758000 (epoch 895), train_loss = 0.239, time/batch = 0.030, All_Time = 10015.238
339450/758000 (epoch 895), train_loss = 0.212, time/batch = 0.029, All_Time = 10016.733
339500/758000 (epoch 895), train_loss = 0.243, time/batch = 0.030, All_Time = 10018.231
339550/758000 (epoch 895), train_loss = 0.215, time/batch = 0.029, All_Time = 10019.714
339600/758000 (epoch 896), train_loss = 0.228, time/batch = 0.029, All_Time = 10021.203
339650/758000 (epoch 896), train_loss = 0.252, time/batch = 0.029, All_Time = 10022.681
339700/758000 (epoch 896), train_loss = 0.260, time/batch = 0.029, All_Time = 10024.164
339750/758000 (epoch 896), train_loss = 0.228, time/batch = 0.029, All_Time = 10025.631
339800/758000 (epoch 896), train_loss = 0.236, time/batch = 0.029, All_Time = 10027.096
339850/758000 (epoch 896), train_loss = 0.271, time/batch = 0.029, All_Time = 10028.569
339900/758000 (epoch 896), train_loss = 0.238, time/batch = 0.030, All_Time = 10030.033
339950/758000 (epoch 896), train_loss = 0.268, time/batch = 0.031, All_Time = 10031.508
340000/758000 (epoch 897), train_loss = 0.248, time/batch = 0.029, All_Time = 10032.989
model saved to NER/polyglot/model.ckpt
340050/758000 (epoch 897), train_loss = 0.249, time/batch = 0.031, All_Time = 10034.467
340100/758000 (epoch 897), train_loss = 0.240, time/batch = 0.029, All_Time = 10035.923
340150/758000 (epoch 897), train_loss = 0.247, time/batch = 0.030, All_Time = 10037.391
340200/758000 (epoch 897), train_loss = 0.235, time/batch = 0.032, All_Time = 10038.884
340250/758000 (epoch 897), train_loss = 0.247, time/batch = 0.029, All_Time = 10040.370
340300/758000 (epoch 897), train_loss = 0.251, time/batch = 0.030, All_Time = 10041.846
340350/758000 (epoch 898), train_loss = 0.242, time/batch = 0.029, All_Time = 10043.335
340400/758000 (epoch 898), train_loss = 0.276, time/batch = 0.029, All_Time = 10044.802
340450/758000 (epoch 898), train_loss = 0.256, time/batch = 0.030, All_Time = 10046.272
340500/758000 (epoch 898), train_loss = 0.258, time/batch = 0.028, All_Time = 10047.743
340550/758000 (epoch 898), train_loss = 0.213, time/batch = 0.029, All_Time = 10049.210
340600/758000 (epoch 898), train_loss = 0.237, time/batch = 0.031, All_Time = 10050.673
340650/758000 (epoch 898), train_loss = 0.249, time/batch = 0.030, All_Time = 10052.161
340700/758000 (epoch 898), train_loss = 0.251, time/batch = 0.030, All_Time = 10053.671
340750/758000 (epoch 899), train_loss = 0.232, time/batch = 0.030, All_Time = 10055.164
340800/758000 (epoch 899), train_loss = 0.255, time/batch = 0.029, All_Time = 10056.640
340850/758000 (epoch 899), train_loss = 0.265, time/batch = 0.028, All_Time = 10058.105
340900/758000 (epoch 899), train_loss = 0.229, time/batch = 0.029, All_Time = 10059.574
340950/758000 (epoch 899), train_loss = 0.263, time/batch = 0.033, All_Time = 10061.069
341000/758000 (epoch 899), train_loss = 0.217, time/batch = 0.029, All_Time = 10062.568
model saved to NER/polyglot/model.ckpt
341050/758000 (epoch 899), train_loss = 0.248, time/batch = 0.028, All_Time = 10064.037
341100/758000 (epoch 900), train_loss = 0.059, time/batch = 0.040, All_Time = 10065.526
341150/758000 (epoch 900), train_loss = 0.250, time/batch = 0.030, All_Time = 10066.984
341200/758000 (epoch 900), train_loss = 0.223, time/batch = 0.031, All_Time = 10068.450
341250/758000 (epoch 900), train_loss = 0.250, time/batch = 0.030, All_Time = 10069.940
341300/758000 (epoch 900), train_loss = 0.231, time/batch = 0.029, All_Time = 10071.449
341350/758000 (epoch 900), train_loss = 0.250, time/batch = 0.030, All_Time = 10072.937
341400/758000 (epoch 900), train_loss = 0.232, time/batch = 0.029, All_Time = 10074.414
341450/758000 (epoch 900), train_loss = 0.230, time/batch = 0.028, All_Time = 10075.878
341500/758000 (epoch 901), train_loss = 0.224, time/batch = 0.029, All_Time = 10077.358
341550/758000 (epoch 901), train_loss = 0.233, time/batch = 0.030, All_Time = 10078.811
341600/758000 (epoch 901), train_loss = 0.224, time/batch = 0.030, All_Time = 10080.278
341650/758000 (epoch 901), train_loss = 0.262, time/batch = 0.029, All_Time = 10081.745
341700/758000 (epoch 901), train_loss = 0.220, time/batch = 0.028, All_Time = 10083.218
341750/758000 (epoch 901), train_loss = 0.228, time/batch = 0.031, All_Time = 10084.709
341800/758000 (epoch 901), train_loss = 0.280, time/batch = 0.028, All_Time = 10086.213
341850/758000 (epoch 901), train_loss = 0.272, time/batch = 0.029, All_Time = 10087.695
341900/758000 (epoch 902), train_loss = 0.230, time/batch = 0.030, All_Time = 10089.176
341950/758000 (epoch 902), train_loss = 0.224, time/batch = 0.029, All_Time = 10090.635
342000/758000 (epoch 902), train_loss = 0.201, time/batch = 0.029, All_Time = 10092.110
model saved to NER/polyglot/model.ckpt
342050/758000 (epoch 902), train_loss = 0.270, time/batch = 0.028, All_Time = 10093.581
342100/758000 (epoch 902), train_loss = 0.259, time/batch = 0.029, All_Time = 10095.052
342150/758000 (epoch 902), train_loss = 0.209, time/batch = 0.029, All_Time = 10096.520
342200/758000 (epoch 902), train_loss = 0.218, time/batch = 0.029, All_Time = 10097.987
342250/758000 (epoch 903), train_loss = 0.229, time/batch = 0.030, All_Time = 10099.489
342300/758000 (epoch 903), train_loss = 0.283, time/batch = 0.029, All_Time = 10100.966
342350/758000 (epoch 903), train_loss = 0.231, time/batch = 0.031, All_Time = 10102.435
342400/758000 (epoch 903), train_loss = 0.307, time/batch = 0.031, All_Time = 10103.912
342450/758000 (epoch 903), train_loss = 0.221, time/batch = 0.029, All_Time = 10105.385
342500/758000 (epoch 903), train_loss = 0.208, time/batch = 0.029, All_Time = 10106.856
342550/758000 (epoch 903), train_loss = 0.247, time/batch = 0.029, All_Time = 10108.347
342600/758000 (epoch 903), train_loss = 0.252, time/batch = 0.030, All_Time = 10109.831
342650/758000 (epoch 904), train_loss = 0.264, time/batch = 0.029, All_Time = 10111.315
342700/758000 (epoch 904), train_loss = 0.229, time/batch = 0.029, All_Time = 10112.776
342750/758000 (epoch 904), train_loss = 0.242, time/batch = 0.029, All_Time = 10114.251
342800/758000 (epoch 904), train_loss = 0.267, time/batch = 0.030, All_Time = 10115.724
342850/758000 (epoch 904), train_loss = 0.249, time/batch = 0.031, All_Time = 10117.197
342900/758000 (epoch 904), train_loss = 0.237, time/batch = 0.030, All_Time = 10118.665
342950/758000 (epoch 904), train_loss = 0.276, time/batch = 0.029, All_Time = 10120.146
343000/758000 (epoch 905), train_loss = 0.256, time/batch = 0.031, All_Time = 10121.635
model saved to NER/polyglot/model.ckpt
343050/758000 (epoch 905), train_loss = 0.222, time/batch = 0.029, All_Time = 10123.105
343100/758000 (epoch 905), train_loss = 0.266, time/batch = 0.030, All_Time = 10124.570
343150/758000 (epoch 905), train_loss = 0.216, time/batch = 0.030, All_Time = 10126.040
343200/758000 (epoch 905), train_loss = 0.223, time/batch = 0.032, All_Time = 10127.516
343250/758000 (epoch 905), train_loss = 0.261, time/batch = 0.030, All_Time = 10129.040
343300/758000 (epoch 905), train_loss = 0.238, time/batch = 0.028, All_Time = 10130.538
343350/758000 (epoch 905), train_loss = 0.264, time/batch = 0.029, All_Time = 10132.029
343400/758000 (epoch 906), train_loss = 0.223, time/batch = 0.031, All_Time = 10133.517
343450/758000 (epoch 906), train_loss = 0.231, time/batch = 0.028, All_Time = 10134.977
343500/758000 (epoch 906), train_loss = 0.238, time/batch = 0.028, All_Time = 10136.439
343550/758000 (epoch 906), train_loss = 0.266, time/batch = 0.029, All_Time = 10137.919
343600/758000 (epoch 906), train_loss = 0.239, time/batch = 0.029, All_Time = 10139.388
343650/758000 (epoch 906), train_loss = 0.226, time/batch = 0.030, All_Time = 10140.865
343700/758000 (epoch 906), train_loss = 0.276, time/batch = 0.029, All_Time = 10142.328
343750/758000 (epoch 906), train_loss = 0.240, time/batch = 0.031, All_Time = 10143.847
343800/758000 (epoch 907), train_loss = 0.281, time/batch = 0.029, All_Time = 10145.341
343850/758000 (epoch 907), train_loss = 0.257, time/batch = 0.028, All_Time = 10146.824
343900/758000 (epoch 907), train_loss = 0.240, time/batch = 0.030, All_Time = 10148.310
343950/758000 (epoch 907), train_loss = 0.231, time/batch = 0.029, All_Time = 10149.782
344000/758000 (epoch 907), train_loss = 0.217, time/batch = 0.029, All_Time = 10151.258
model saved to NER/polyglot/model.ckpt
344050/758000 (epoch 907), train_loss = 0.224, time/batch = 0.029, All_Time = 10152.721
344100/758000 (epoch 907), train_loss = 0.215, time/batch = 0.028, All_Time = 10154.186
344150/758000 (epoch 908), train_loss = 0.249, time/batch = 0.032, All_Time = 10155.696
344200/758000 (epoch 908), train_loss = 0.211, time/batch = 0.030, All_Time = 10157.185
344250/758000 (epoch 908), train_loss = 0.245, time/batch = 0.030, All_Time = 10158.671
344300/758000 (epoch 908), train_loss = 0.217, time/batch = 0.029, All_Time = 10160.139
344350/758000 (epoch 908), train_loss = 0.233, time/batch = 0.028, All_Time = 10161.613
344400/758000 (epoch 908), train_loss = 0.228, time/batch = 0.029, All_Time = 10163.099
344450/758000 (epoch 908), train_loss = 0.248, time/batch = 0.029, All_Time = 10164.580
344500/758000 (epoch 908), train_loss = 0.229, time/batch = 0.029, All_Time = 10166.046
344550/758000 (epoch 909), train_loss = 0.218, time/batch = 0.028, All_Time = 10167.539
344600/758000 (epoch 909), train_loss = 0.237, time/batch = 0.029, All_Time = 10169.007
344650/758000 (epoch 909), train_loss = 0.212, time/batch = 0.029, All_Time = 10170.482
344700/758000 (epoch 909), train_loss = 0.266, time/batch = 0.030, All_Time = 10171.956
344750/758000 (epoch 909), train_loss = 0.255, time/batch = 0.029, All_Time = 10173.436
344800/758000 (epoch 909), train_loss = 0.232, time/batch = 0.029, All_Time = 10174.905
344850/758000 (epoch 909), train_loss = 0.262, time/batch = 0.030, All_Time = 10176.371
344900/758000 (epoch 910), train_loss = 0.282, time/batch = 0.030, All_Time = 10177.889
344950/758000 (epoch 910), train_loss = 0.292, time/batch = 0.029, All_Time = 10179.369
345000/758000 (epoch 910), train_loss = 0.253, time/batch = 0.030, All_Time = 10180.866
model saved to NER/polyglot/model.ckpt
345050/758000 (epoch 910), train_loss = 0.222, time/batch = 0.030, All_Time = 10182.342
345100/758000 (epoch 910), train_loss = 0.221, time/batch = 0.029, All_Time = 10183.802
345150/758000 (epoch 910), train_loss = 0.260, time/batch = 0.028, All_Time = 10185.272
345200/758000 (epoch 910), train_loss = 0.244, time/batch = 0.031, All_Time = 10186.741
345250/758000 (epoch 910), train_loss = 0.247, time/batch = 0.030, All_Time = 10188.213
345300/758000 (epoch 911), train_loss = 0.210, time/batch = 0.030, All_Time = 10189.706
345350/758000 (epoch 911), train_loss = 0.265, time/batch = 0.029, All_Time = 10191.181
345400/758000 (epoch 911), train_loss = 0.229, time/batch = 0.031, All_Time = 10192.662
345450/758000 (epoch 911), train_loss = 0.232, time/batch = 0.030, All_Time = 10194.130
345500/758000 (epoch 911), train_loss = 0.230, time/batch = 0.029, All_Time = 10195.598
345550/758000 (epoch 911), train_loss = 0.253, time/batch = 0.030, All_Time = 10197.085
345600/758000 (epoch 911), train_loss = 0.258, time/batch = 0.029, All_Time = 10198.557
345650/758000 (epoch 912), train_loss = 0.196, time/batch = 0.031, All_Time = 10200.035
345700/758000 (epoch 912), train_loss = 0.254, time/batch = 0.030, All_Time = 10201.515
345750/758000 (epoch 912), train_loss = 0.281, time/batch = 0.029, All_Time = 10202.981
345800/758000 (epoch 912), train_loss = 0.235, time/batch = 0.030, All_Time = 10204.459
345850/758000 (epoch 912), train_loss = 0.247, time/batch = 0.031, All_Time = 10205.942
345900/758000 (epoch 912), train_loss = 0.251, time/batch = 0.030, All_Time = 10207.431
345950/758000 (epoch 912), train_loss = 0.203, time/batch = 0.030, All_Time = 10208.931
346000/758000 (epoch 912), train_loss = 0.268, time/batch = 0.029, All_Time = 10210.414
model saved to NER/polyglot/model.ckpt
346050/758000 (epoch 913), train_loss = 0.233, time/batch = 0.028, All_Time = 10211.902
346100/758000 (epoch 913), train_loss = 0.241, time/batch = 0.031, All_Time = 10213.369
346150/758000 (epoch 913), train_loss = 0.252, time/batch = 0.030, All_Time = 10214.872
346200/758000 (epoch 913), train_loss = 0.258, time/batch = 0.030, All_Time = 10216.366
346250/758000 (epoch 913), train_loss = 0.243, time/batch = 0.029, All_Time = 10217.853
346300/758000 (epoch 913), train_loss = 0.243, time/batch = 0.030, All_Time = 10219.328
346350/758000 (epoch 913), train_loss = 0.244, time/batch = 0.030, All_Time = 10220.819
346400/758000 (epoch 913), train_loss = 0.286, time/batch = 0.030, All_Time = 10222.302
346450/758000 (epoch 914), train_loss = 0.207, time/batch = 0.028, All_Time = 10223.786
346500/758000 (epoch 914), train_loss = 0.244, time/batch = 0.029, All_Time = 10225.261
346550/758000 (epoch 914), train_loss = 0.217, time/batch = 0.029, All_Time = 10226.743
346600/758000 (epoch 914), train_loss = 0.233, time/batch = 0.030, All_Time = 10228.227
346650/758000 (epoch 914), train_loss = 0.260, time/batch = 0.030, All_Time = 10229.708
346700/758000 (epoch 914), train_loss = 0.253, time/batch = 0.029, All_Time = 10231.187
346750/758000 (epoch 914), train_loss = 0.238, time/batch = 0.029, All_Time = 10232.650
346800/758000 (epoch 915), train_loss = 0.227, time/batch = 0.029, All_Time = 10234.135
346850/758000 (epoch 915), train_loss = 0.250, time/batch = 0.029, All_Time = 10235.602
346900/758000 (epoch 915), train_loss = 0.250, time/batch = 0.028, All_Time = 10237.073
346950/758000 (epoch 915), train_loss = 0.223, time/batch = 0.030, All_Time = 10238.575
347000/758000 (epoch 915), train_loss = 0.240, time/batch = 0.030, All_Time = 10240.059
model saved to NER/polyglot/model.ckpt
347050/758000 (epoch 915), train_loss = 0.246, time/batch = 0.030, All_Time = 10241.542
347100/758000 (epoch 915), train_loss = 0.246, time/batch = 0.031, All_Time = 10243.008
347150/758000 (epoch 915), train_loss = 0.257, time/batch = 0.029, All_Time = 10244.481
347200/758000 (epoch 916), train_loss = 0.266, time/batch = 0.030, All_Time = 10245.961
347250/758000 (epoch 916), train_loss = 0.224, time/batch = 0.028, All_Time = 10247.436
347300/758000 (epoch 916), train_loss = 0.248, time/batch = 0.029, All_Time = 10248.911
347350/758000 (epoch 916), train_loss = 0.227, time/batch = 0.030, All_Time = 10250.385
347400/758000 (epoch 916), train_loss = 0.279, time/batch = 0.028, All_Time = 10251.860
347450/758000 (epoch 916), train_loss = 0.255, time/batch = 0.030, All_Time = 10253.355
347500/758000 (epoch 916), train_loss = 0.253, time/batch = 0.029, All_Time = 10254.861
347550/758000 (epoch 917), train_loss = 0.244, time/batch = 0.031, All_Time = 10256.348
347600/758000 (epoch 917), train_loss = 0.247, time/batch = 0.031, All_Time = 10257.823
347650/758000 (epoch 917), train_loss = 0.270, time/batch = 0.031, All_Time = 10259.281
347700/758000 (epoch 917), train_loss = 0.246, time/batch = 0.029, All_Time = 10260.743
347750/758000 (epoch 917), train_loss = 0.237, time/batch = 0.030, All_Time = 10262.219
347800/758000 (epoch 917), train_loss = 0.224, time/batch = 0.030, All_Time = 10263.694
347850/758000 (epoch 917), train_loss = 0.229, time/batch = 0.029, All_Time = 10265.169
347900/758000 (epoch 917), train_loss = 0.246, time/batch = 0.029, All_Time = 10266.649
347950/758000 (epoch 918), train_loss = 0.249, time/batch = 0.029, All_Time = 10268.138
348000/758000 (epoch 918), train_loss = 0.264, time/batch = 0.028, All_Time = 10269.605
model saved to NER/polyglot/model.ckpt
348050/758000 (epoch 918), train_loss = 0.240, time/batch = 0.030, All_Time = 10271.077
348100/758000 (epoch 918), train_loss = 0.250, time/batch = 0.029, All_Time = 10272.542
348150/758000 (epoch 918), train_loss = 0.227, time/batch = 0.029, All_Time = 10274.045
348200/758000 (epoch 918), train_loss = 0.217, time/batch = 0.028, All_Time = 10275.525
348250/758000 (epoch 918), train_loss = 0.277, time/batch = 0.030, All_Time = 10276.998
348300/758000 (epoch 918), train_loss = 0.259, time/batch = 0.030, All_Time = 10278.483
348350/758000 (epoch 919), train_loss = 0.269, time/batch = 0.029, All_Time = 10279.964
348400/758000 (epoch 919), train_loss = 0.296, time/batch = 0.029, All_Time = 10281.437
348450/758000 (epoch 919), train_loss = 0.228, time/batch = 0.029, All_Time = 10282.907
348500/758000 (epoch 919), train_loss = 0.220, time/batch = 0.029, All_Time = 10284.383
348550/758000 (epoch 919), train_loss = 0.257, time/batch = 0.029, All_Time = 10285.851
348600/758000 (epoch 919), train_loss = 0.255, time/batch = 0.031, All_Time = 10287.322
348650/758000 (epoch 919), train_loss = 0.237, time/batch = 0.027, All_Time = 10288.793
348700/758000 (epoch 920), train_loss = 0.225, time/batch = 0.029, All_Time = 10290.295
348750/758000 (epoch 920), train_loss = 0.234, time/batch = 0.031, All_Time = 10291.786
348800/758000 (epoch 920), train_loss = 0.243, time/batch = 0.029, All_Time = 10293.275
348850/758000 (epoch 920), train_loss = 0.234, time/batch = 0.029, All_Time = 10294.764
348900/758000 (epoch 920), train_loss = 0.223, time/batch = 0.029, All_Time = 10296.240
348950/758000 (epoch 920), train_loss = 0.239, time/batch = 0.029, All_Time = 10297.717
349000/758000 (epoch 920), train_loss = 0.264, time/batch = 0.031, All_Time = 10299.191
model saved to NER/polyglot/model.ckpt
349050/758000 (epoch 920), train_loss = 0.244, time/batch = 0.028, All_Time = 10300.662
349100/758000 (epoch 921), train_loss = 0.257, time/batch = 0.030, All_Time = 10302.143
349150/758000 (epoch 921), train_loss = 0.287, time/batch = 0.031, All_Time = 10303.605
349200/758000 (epoch 921), train_loss = 0.255, time/batch = 0.030, All_Time = 10305.079
349250/758000 (epoch 921), train_loss = 0.248, time/batch = 0.028, All_Time = 10306.544
349300/758000 (epoch 921), train_loss = 0.212, time/batch = 0.030, All_Time = 10308.059
349350/758000 (epoch 921), train_loss = 0.229, time/batch = 0.029, All_Time = 10309.536
349400/758000 (epoch 921), train_loss = 0.272, time/batch = 0.031, All_Time = 10311.007
349450/758000 (epoch 922), train_loss = 0.249, time/batch = 0.029, All_Time = 10312.491
349500/758000 (epoch 922), train_loss = 0.227, time/batch = 0.030, All_Time = 10313.960
349550/758000 (epoch 922), train_loss = 0.267, time/batch = 0.030, All_Time = 10315.424
349600/758000 (epoch 922), train_loss = 0.239, time/batch = 0.030, All_Time = 10316.895
349650/758000 (epoch 922), train_loss = 0.247, time/batch = 0.030, All_Time = 10318.388
349700/758000 (epoch 922), train_loss = 0.241, time/batch = 0.030, All_Time = 10319.888
349750/758000 (epoch 922), train_loss = 0.274, time/batch = 0.030, All_Time = 10321.367
349800/758000 (epoch 922), train_loss = 0.279, time/batch = 0.029, All_Time = 10322.848
349850/758000 (epoch 923), train_loss = 0.238, time/batch = 0.029, All_Time = 10324.343
349900/758000 (epoch 923), train_loss = 0.248, time/batch = 0.030, All_Time = 10325.817
349950/758000 (epoch 923), train_loss = 0.299, time/batch = 0.029, All_Time = 10327.289
350000/758000 (epoch 923), train_loss = 0.230, time/batch = 0.028, All_Time = 10328.756
model saved to NER/polyglot/model.ckpt
350050/758000 (epoch 923), train_loss = 0.216, time/batch = 0.029, All_Time = 10330.231
350100/758000 (epoch 923), train_loss = 0.244, time/batch = 0.029, All_Time = 10331.705
350150/758000 (epoch 923), train_loss = 0.274, time/batch = 0.030, All_Time = 10333.173
350200/758000 (epoch 924), train_loss = 0.221, time/batch = 0.029, All_Time = 10334.691
350250/758000 (epoch 924), train_loss = 0.257, time/batch = 0.029, All_Time = 10336.164
350300/758000 (epoch 924), train_loss = 0.241, time/batch = 0.028, All_Time = 10337.642
350350/758000 (epoch 924), train_loss = 0.240, time/batch = 0.029, All_Time = 10339.123
350400/758000 (epoch 924), train_loss = 0.256, time/batch = 0.030, All_Time = 10340.595
350450/758000 (epoch 924), train_loss = 0.219, time/batch = 0.030, All_Time = 10342.073
350500/758000 (epoch 924), train_loss = 0.224, time/batch = 0.029, All_Time = 10343.549
350550/758000 (epoch 924), train_loss = 0.257, time/batch = 0.031, All_Time = 10345.023
350600/758000 (epoch 925), train_loss = 0.255, time/batch = 0.029, All_Time = 10346.516
350650/758000 (epoch 925), train_loss = 0.267, time/batch = 0.029, All_Time = 10347.976
350700/758000 (epoch 925), train_loss = 0.269, time/batch = 0.030, All_Time = 10349.448
350750/758000 (epoch 925), train_loss = 0.228, time/batch = 0.030, All_Time = 10350.927
350800/758000 (epoch 925), train_loss = 0.234, time/batch = 0.031, All_Time = 10352.394
350850/758000 (epoch 925), train_loss = 0.245, time/batch = 0.031, All_Time = 10353.895
350900/758000 (epoch 925), train_loss = 0.279, time/batch = 0.029, All_Time = 10355.404
350950/758000 (epoch 925), train_loss = 0.240, time/batch = 0.031, All_Time = 10356.895
351000/758000 (epoch 926), train_loss = 0.236, time/batch = 0.030, All_Time = 10358.384
model saved to NER/polyglot/model.ckpt
351050/758000 (epoch 926), train_loss = 0.234, time/batch = 0.030, All_Time = 10359.856
351100/758000 (epoch 926), train_loss = 0.233, time/batch = 0.029, All_Time = 10361.326
351150/758000 (epoch 926), train_loss = 0.276, time/batch = 0.028, All_Time = 10362.787
351200/758000 (epoch 926), train_loss = 0.206, time/batch = 0.032, All_Time = 10364.284
351250/758000 (epoch 926), train_loss = 0.259, time/batch = 0.029, All_Time = 10365.775
351300/758000 (epoch 926), train_loss = 0.234, time/batch = 0.033, All_Time = 10367.271
351350/758000 (epoch 927), train_loss = 0.245, time/batch = 0.030, All_Time = 10368.771
351400/758000 (epoch 927), train_loss = 0.223, time/batch = 0.028, All_Time = 10370.249
351450/758000 (epoch 927), train_loss = 0.240, time/batch = 0.030, All_Time = 10371.723
351500/758000 (epoch 927), train_loss = 0.256, time/batch = 0.030, All_Time = 10373.188
351550/758000 (epoch 927), train_loss = 0.214, time/batch = 0.029, All_Time = 10374.665
351600/758000 (epoch 927), train_loss = 0.272, time/batch = 0.028, All_Time = 10376.133
351650/758000 (epoch 927), train_loss = 0.213, time/batch = 0.029, All_Time = 10377.603
351700/758000 (epoch 927), train_loss = 0.251, time/batch = 0.031, All_Time = 10379.103
351750/758000 (epoch 928), train_loss = 0.247, time/batch = 0.028, All_Time = 10380.592
351800/758000 (epoch 928), train_loss = 0.229, time/batch = 0.029, All_Time = 10382.064
351850/758000 (epoch 928), train_loss = 0.217, time/batch = 0.029, All_Time = 10383.528
351900/758000 (epoch 928), train_loss = 0.220, time/batch = 0.029, All_Time = 10385.003
351950/758000 (epoch 928), train_loss = 0.250, time/batch = 0.030, All_Time = 10386.468
352000/758000 (epoch 928), train_loss = 0.207, time/batch = 0.028, All_Time = 10387.973
model saved to NER/polyglot/model.ckpt
352050/758000 (epoch 928), train_loss = 0.268, time/batch = 0.030, All_Time = 10389.465
352100/758000 (epoch 929), train_loss = 0.256, time/batch = 0.029, All_Time = 10390.950
352150/758000 (epoch 929), train_loss = 0.264, time/batch = 0.028, All_Time = 10392.412
352200/758000 (epoch 929), train_loss = 0.284, time/batch = 0.032, All_Time = 10393.879
352250/758000 (epoch 929), train_loss = 0.239, time/batch = 0.030, All_Time = 10395.381
352300/758000 (epoch 929), train_loss = 0.267, time/batch = 0.031, All_Time = 10396.873
352350/758000 (epoch 929), train_loss = 0.256, time/batch = 0.029, All_Time = 10398.339
352400/758000 (epoch 929), train_loss = 0.236, time/batch = 0.030, All_Time = 10399.809
352450/758000 (epoch 929), train_loss = 0.268, time/batch = 0.030, All_Time = 10401.290
352500/758000 (epoch 930), train_loss = 0.226, time/batch = 0.029, All_Time = 10402.774
352550/758000 (epoch 930), train_loss = 0.222, time/batch = 0.029, All_Time = 10404.240
352600/758000 (epoch 930), train_loss = 0.261, time/batch = 0.029, All_Time = 10405.701
352650/758000 (epoch 930), train_loss = 0.254, time/batch = 0.029, All_Time = 10407.211
352700/758000 (epoch 930), train_loss = 0.223, time/batch = 0.030, All_Time = 10408.704
352750/758000 (epoch 930), train_loss = 0.242, time/batch = 0.029, All_Time = 10410.178
352800/758000 (epoch 930), train_loss = 0.251, time/batch = 0.029, All_Time = 10411.667
352850/758000 (epoch 931), train_loss = 0.192, time/batch = 0.029, All_Time = 10413.164
352900/758000 (epoch 931), train_loss = 0.273, time/batch = 0.029, All_Time = 10414.643
352950/758000 (epoch 931), train_loss = 0.217, time/batch = 0.029, All_Time = 10416.105
353000/758000 (epoch 931), train_loss = 0.240, time/batch = 0.030, All_Time = 10417.573
model saved to NER/polyglot/model.ckpt
353050/758000 (epoch 931), train_loss = 0.221, time/batch = 0.029, All_Time = 10419.048
353100/758000 (epoch 931), train_loss = 0.221, time/batch = 0.030, All_Time = 10420.502
353150/758000 (epoch 931), train_loss = 0.252, time/batch = 0.030, All_Time = 10422.008
353200/758000 (epoch 931), train_loss = 0.272, time/batch = 0.029, All_Time = 10423.500
353250/758000 (epoch 932), train_loss = 0.222, time/batch = 0.028, All_Time = 10424.991
353300/758000 (epoch 932), train_loss = 0.279, time/batch = 0.030, All_Time = 10426.456
353350/758000 (epoch 932), train_loss = 0.242, time/batch = 0.031, All_Time = 10427.925
353400/758000 (epoch 932), train_loss = 0.274, time/batch = 0.029, All_Time = 10429.398
353450/758000 (epoch 932), train_loss = 0.262, time/batch = 0.028, All_Time = 10430.863
353500/758000 (epoch 932), train_loss = 0.197, time/batch = 0.030, All_Time = 10432.332
353550/758000 (epoch 932), train_loss = 0.233, time/batch = 0.028, All_Time = 10433.805
353600/758000 (epoch 932), train_loss = 0.281, time/batch = 0.028, All_Time = 10435.265
353650/758000 (epoch 933), train_loss = 0.246, time/batch = 0.030, All_Time = 10436.755
353700/758000 (epoch 933), train_loss = 0.212, time/batch = 0.029, All_Time = 10438.239
353750/758000 (epoch 933), train_loss = 0.255, time/batch = 0.033, All_Time = 10439.748
353800/758000 (epoch 933), train_loss = 0.271, time/batch = 0.031, All_Time = 10441.225
353850/758000 (epoch 933), train_loss = 0.203, time/batch = 0.029, All_Time = 10442.679
353900/758000 (epoch 933), train_loss = 0.226, time/batch = 0.030, All_Time = 10444.139
353950/758000 (epoch 933), train_loss = 0.254, time/batch = 0.028, All_Time = 10445.604
354000/758000 (epoch 934), train_loss = 0.219, time/batch = 0.028, All_Time = 10447.071
model saved to NER/polyglot/model.ckpt
354050/758000 (epoch 934), train_loss = 0.265, time/batch = 0.029, All_Time = 10448.538
354100/758000 (epoch 934), train_loss = 0.227, time/batch = 0.030, All_Time = 10450.005
354150/758000 (epoch 934), train_loss = 0.213, time/batch = 0.030, All_Time = 10451.496
354200/758000 (epoch 934), train_loss = 0.224, time/batch = 0.028, All_Time = 10453.002
354250/758000 (epoch 934), train_loss = 0.213, time/batch = 0.029, All_Time = 10454.500
354300/758000 (epoch 934), train_loss = 0.230, time/batch = 0.029, All_Time = 10455.976
354350/758000 (epoch 934), train_loss = 0.223, time/batch = 0.029, All_Time = 10457.459
354400/758000 (epoch 935), train_loss = 0.275, time/batch = 0.029, All_Time = 10458.936
354450/758000 (epoch 935), train_loss = 0.229, time/batch = 0.028, All_Time = 10460.401
354500/758000 (epoch 935), train_loss = 0.270, time/batch = 0.028, All_Time = 10461.868
354550/758000 (epoch 935), train_loss = 0.273, time/batch = 0.029, All_Time = 10463.354
354600/758000 (epoch 935), train_loss = 0.233, time/batch = 0.030, All_Time = 10464.854
354650/758000 (epoch 935), train_loss = 0.268, time/batch = 0.028, All_Time = 10466.337
354700/758000 (epoch 935), train_loss = 0.280, time/batch = 0.029, All_Time = 10467.839
354750/758000 (epoch 936), train_loss = 0.239, time/batch = 0.029, All_Time = 10469.330
354800/758000 (epoch 936), train_loss = 0.218, time/batch = 0.028, All_Time = 10470.809
354850/758000 (epoch 936), train_loss = 0.243, time/batch = 0.028, All_Time = 10472.288
354900/758000 (epoch 936), train_loss = 0.244, time/batch = 0.030, All_Time = 10473.768
354950/758000 (epoch 936), train_loss = 0.243, time/batch = 0.030, All_Time = 10475.248
355000/758000 (epoch 936), train_loss = 0.244, time/batch = 0.029, All_Time = 10476.730
model saved to NER/polyglot/model.ckpt
355050/758000 (epoch 936), train_loss = 0.213, time/batch = 0.028, All_Time = 10478.205
355100/758000 (epoch 936), train_loss = 0.289, time/batch = 0.030, All_Time = 10479.676
355150/758000 (epoch 937), train_loss = 0.237, time/batch = 0.029, All_Time = 10481.158
355200/758000 (epoch 937), train_loss = 0.246, time/batch = 0.029, All_Time = 10482.619
355250/758000 (epoch 937), train_loss = 0.288, time/batch = 0.029, All_Time = 10484.088
355300/758000 (epoch 937), train_loss = 0.257, time/batch = 0.032, All_Time = 10485.558
355350/758000 (epoch 937), train_loss = 0.218, time/batch = 0.030, All_Time = 10487.032
355400/758000 (epoch 937), train_loss = 0.238, time/batch = 0.029, All_Time = 10488.524
355450/758000 (epoch 937), train_loss = 0.251, time/batch = 0.029, All_Time = 10490.003
355500/758000 (epoch 937), train_loss = 0.251, time/batch = 0.030, All_Time = 10491.509
355550/758000 (epoch 938), train_loss = 0.252, time/batch = 0.030, All_Time = 10492.989
355600/758000 (epoch 938), train_loss = 0.280, time/batch = 0.029, All_Time = 10494.461
355650/758000 (epoch 938), train_loss = 0.242, time/batch = 0.029, All_Time = 10495.934
355700/758000 (epoch 938), train_loss = 0.250, time/batch = 0.029, All_Time = 10497.402
355750/758000 (epoch 938), train_loss = 0.239, time/batch = 0.030, All_Time = 10498.877
355800/758000 (epoch 938), train_loss = 0.239, time/batch = 0.029, All_Time = 10500.351
355850/758000 (epoch 938), train_loss = 0.250, time/batch = 0.028, All_Time = 10501.821
355900/758000 (epoch 939), train_loss = 0.221, time/batch = 0.030, All_Time = 10503.301
355950/758000 (epoch 939), train_loss = 0.219, time/batch = 0.031, All_Time = 10504.781
356000/758000 (epoch 939), train_loss = 0.246, time/batch = 0.029, All_Time = 10506.248
model saved to NER/polyglot/model.ckpt
356050/758000 (epoch 939), train_loss = 0.262, time/batch = 0.029, All_Time = 10507.733
356100/758000 (epoch 939), train_loss = 0.260, time/batch = 0.031, All_Time = 10509.234
356150/758000 (epoch 939), train_loss = 0.241, time/batch = 0.029, All_Time = 10510.736
356200/758000 (epoch 939), train_loss = 0.210, time/batch = 0.029, All_Time = 10512.220
356250/758000 (epoch 939), train_loss = 0.239, time/batch = 0.028, All_Time = 10513.696
356300/758000 (epoch 940), train_loss = 0.230, time/batch = 0.029, All_Time = 10515.180
356350/758000 (epoch 940), train_loss = 0.226, time/batch = 0.028, All_Time = 10516.650
356400/758000 (epoch 940), train_loss = 0.264, time/batch = 0.031, All_Time = 10518.123
356450/758000 (epoch 940), train_loss = 0.240, time/batch = 0.030, All_Time = 10519.587
356500/758000 (epoch 940), train_loss = 0.253, time/batch = 0.030, All_Time = 10521.074
356550/758000 (epoch 940), train_loss = 0.251, time/batch = 0.031, All_Time = 10522.540
356600/758000 (epoch 940), train_loss = 0.248, time/batch = 0.030, All_Time = 10524.028
356650/758000 (epoch 941), train_loss = 0.216, time/batch = 0.029, All_Time = 10525.538
356700/758000 (epoch 941), train_loss = 0.233, time/batch = 0.030, All_Time = 10527.012
356750/758000 (epoch 941), train_loss = 0.250, time/batch = 0.031, All_Time = 10528.504
356800/758000 (epoch 941), train_loss = 0.241, time/batch = 0.031, All_Time = 10529.996
356850/758000 (epoch 941), train_loss = 0.243, time/batch = 0.031, All_Time = 10531.494
356900/758000 (epoch 941), train_loss = 0.242, time/batch = 0.029, All_Time = 10532.985
356950/758000 (epoch 941), train_loss = 0.230, time/batch = 0.030, All_Time = 10534.475
357000/758000 (epoch 941), train_loss = 0.259, time/batch = 0.029, All_Time = 10535.955
model saved to NER/polyglot/model.ckpt
357050/758000 (epoch 942), train_loss = 0.250, time/batch = 0.029, All_Time = 10537.432
357100/758000 (epoch 942), train_loss = 0.253, time/batch = 0.030, All_Time = 10538.919
357150/758000 (epoch 942), train_loss = 0.245, time/batch = 0.029, All_Time = 10540.405
357200/758000 (epoch 942), train_loss = 0.231, time/batch = 0.029, All_Time = 10541.877
357250/758000 (epoch 942), train_loss = 0.228, time/batch = 0.031, All_Time = 10543.353
357300/758000 (epoch 942), train_loss = 0.238, time/batch = 0.029, All_Time = 10544.821
357350/758000 (epoch 942), train_loss = 0.268, time/batch = 0.029, All_Time = 10546.298
357400/758000 (epoch 943), train_loss = 0.248, time/batch = 0.029, All_Time = 10547.785
357450/758000 (epoch 943), train_loss = 0.280, time/batch = 0.029, All_Time = 10549.253
357500/758000 (epoch 943), train_loss = 0.242, time/batch = 0.028, All_Time = 10550.723
357550/758000 (epoch 943), train_loss = 0.258, time/batch = 0.029, All_Time = 10552.179
357600/758000 (epoch 943), train_loss = 0.224, time/batch = 0.029, All_Time = 10553.681
357650/758000 (epoch 943), train_loss = 0.243, time/batch = 0.029, All_Time = 10555.164
357700/758000 (epoch 943), train_loss = 0.219, time/batch = 0.029, All_Time = 10556.642
357750/758000 (epoch 943), train_loss = 0.232, time/batch = 0.031, All_Time = 10558.133
357800/758000 (epoch 944), train_loss = 0.237, time/batch = 0.030, All_Time = 10559.608
357850/758000 (epoch 944), train_loss = 0.239, time/batch = 0.029, All_Time = 10561.066
357900/758000 (epoch 944), train_loss = 0.293, time/batch = 0.030, All_Time = 10562.538
357950/758000 (epoch 944), train_loss = 0.318, time/batch = 0.030, All_Time = 10564.004
358000/758000 (epoch 944), train_loss = 0.196, time/batch = 0.030, All_Time = 10565.479
model saved to NER/polyglot/model.ckpt
358050/758000 (epoch 944), train_loss = 0.213, time/batch = 0.029, All_Time = 10566.959
358100/758000 (epoch 944), train_loss = 0.250, time/batch = 0.029, All_Time = 10568.445
358150/758000 (epoch 944), train_loss = 0.297, time/batch = 0.029, All_Time = 10569.932
358200/758000 (epoch 945), train_loss = 0.226, time/batch = 0.029, All_Time = 10571.404
358250/758000 (epoch 945), train_loss = 0.259, time/batch = 0.029, All_Time = 10572.867
358300/758000 (epoch 945), train_loss = 0.223, time/batch = 0.030, All_Time = 10574.337
358350/758000 (epoch 945), train_loss = 0.239, time/batch = 0.030, All_Time = 10575.826
358400/758000 (epoch 945), train_loss = 0.212, time/batch = 0.029, All_Time = 10577.291
358450/758000 (epoch 945), train_loss = 0.243, time/batch = 0.028, All_Time = 10578.764
358500/758000 (epoch 945), train_loss = 0.215, time/batch = 0.029, All_Time = 10580.238
358550/758000 (epoch 946), train_loss = 0.228, time/batch = 0.029, All_Time = 10581.750
358600/758000 (epoch 946), train_loss = 0.252, time/batch = 0.029, All_Time = 10583.222
358650/758000 (epoch 946), train_loss = 0.260, time/batch = 0.030, All_Time = 10584.700
358700/758000 (epoch 946), train_loss = 0.228, time/batch = 0.030, All_Time = 10586.175
358750/758000 (epoch 946), train_loss = 0.236, time/batch = 0.030, All_Time = 10587.647
358800/758000 (epoch 946), train_loss = 0.271, time/batch = 0.030, All_Time = 10589.124
358850/758000 (epoch 946), train_loss = 0.238, time/batch = 0.029, All_Time = 10590.639
358900/758000 (epoch 946), train_loss = 0.268, time/batch = 0.029, All_Time = 10592.112
358950/758000 (epoch 947), train_loss = 0.248, time/batch = 0.029, All_Time = 10593.595
359000/758000 (epoch 947), train_loss = 0.249, time/batch = 0.030, All_Time = 10595.068
model saved to NER/polyglot/model.ckpt
359050/758000 (epoch 947), train_loss = 0.240, time/batch = 0.029, All_Time = 10596.541
359100/758000 (epoch 947), train_loss = 0.247, time/batch = 0.030, All_Time = 10598.017
359150/758000 (epoch 947), train_loss = 0.235, time/batch = 0.029, All_Time = 10599.508
359200/758000 (epoch 947), train_loss = 0.247, time/batch = 0.030, All_Time = 10600.983
359250/758000 (epoch 947), train_loss = 0.251, time/batch = 0.030, All_Time = 10602.467
359300/758000 (epoch 948), train_loss = 0.242, time/batch = 0.030, All_Time = 10603.949
359350/758000 (epoch 948), train_loss = 0.276, time/batch = 0.029, All_Time = 10605.423
359400/758000 (epoch 948), train_loss = 0.256, time/batch = 0.029, All_Time = 10606.887
359450/758000 (epoch 948), train_loss = 0.258, time/batch = 0.031, All_Time = 10608.393
359500/758000 (epoch 948), train_loss = 0.213, time/batch = 0.029, All_Time = 10609.895
359550/758000 (epoch 948), train_loss = 0.237, time/batch = 0.028, All_Time = 10611.367
359600/758000 (epoch 948), train_loss = 0.249, time/batch = 0.030, All_Time = 10612.848
359650/758000 (epoch 948), train_loss = 0.251, time/batch = 0.030, All_Time = 10614.327
359700/758000 (epoch 949), train_loss = 0.232, time/batch = 0.029, All_Time = 10615.819
359750/758000 (epoch 949), train_loss = 0.255, time/batch = 0.029, All_Time = 10617.296
359800/758000 (epoch 949), train_loss = 0.265, time/batch = 0.029, All_Time = 10618.762
359850/758000 (epoch 949), train_loss = 0.229, time/batch = 0.030, All_Time = 10620.231
359900/758000 (epoch 949), train_loss = 0.263, time/batch = 0.029, All_Time = 10621.701
359950/758000 (epoch 949), train_loss = 0.217, time/batch = 0.028, All_Time = 10623.179
360000/758000 (epoch 949), train_loss = 0.248, time/batch = 0.030, All_Time = 10624.645
model saved to NER/polyglot/model.ckpt
360050/758000 (epoch 950), train_loss = 0.059, time/batch = 0.040, All_Time = 10626.126
360100/758000 (epoch 950), train_loss = 0.250, time/batch = 0.029, All_Time = 10627.584
360150/758000 (epoch 950), train_loss = 0.223, time/batch = 0.029, All_Time = 10629.051
360200/758000 (epoch 950), train_loss = 0.250, time/batch = 0.030, All_Time = 10630.550
360250/758000 (epoch 950), train_loss = 0.231, time/batch = 0.030, All_Time = 10632.045
360300/758000 (epoch 950), train_loss = 0.250, time/batch = 0.030, All_Time = 10633.519
360350/758000 (epoch 950), train_loss = 0.232, time/batch = 0.030, All_Time = 10634.996
360400/758000 (epoch 950), train_loss = 0.230, time/batch = 0.029, All_Time = 10636.473
360450/758000 (epoch 951), train_loss = 0.224, time/batch = 0.030, All_Time = 10637.963
360500/758000 (epoch 951), train_loss = 0.233, time/batch = 0.030, All_Time = 10639.430
360550/758000 (epoch 951), train_loss = 0.224, time/batch = 0.029, All_Time = 10640.896
360600/758000 (epoch 951), train_loss = 0.262, time/batch = 0.029, All_Time = 10642.361
360650/758000 (epoch 951), train_loss = 0.220, time/batch = 0.029, All_Time = 10643.840
360700/758000 (epoch 951), train_loss = 0.228, time/batch = 0.028, All_Time = 10645.314
360750/758000 (epoch 951), train_loss = 0.280, time/batch = 0.031, All_Time = 10646.798
360800/758000 (epoch 951), train_loss = 0.272, time/batch = 0.030, All_Time = 10648.268
360850/758000 (epoch 952), train_loss = 0.230, time/batch = 0.029, All_Time = 10649.762
360900/758000 (epoch 952), train_loss = 0.224, time/batch = 0.031, All_Time = 10651.250
360950/758000 (epoch 952), train_loss = 0.201, time/batch = 0.031, All_Time = 10652.722
361000/758000 (epoch 952), train_loss = 0.270, time/batch = 0.029, All_Time = 10654.207
model saved to NER/polyglot/model.ckpt
361050/758000 (epoch 952), train_loss = 0.259, time/batch = 0.031, All_Time = 10655.681
361100/758000 (epoch 952), train_loss = 0.209, time/batch = 0.030, All_Time = 10657.166
361150/758000 (epoch 952), train_loss = 0.218, time/batch = 0.029, All_Time = 10658.657
361200/758000 (epoch 953), train_loss = 0.229, time/batch = 0.029, All_Time = 10660.143
361250/758000 (epoch 953), train_loss = 0.283, time/batch = 0.030, All_Time = 10661.609
361300/758000 (epoch 953), train_loss = 0.231, time/batch = 0.030, All_Time = 10663.083
361350/758000 (epoch 953), train_loss = 0.307, time/batch = 0.031, All_Time = 10664.555
361400/758000 (epoch 953), train_loss = 0.221, time/batch = 0.030, All_Time = 10666.058
361450/758000 (epoch 953), train_loss = 0.208, time/batch = 0.028, All_Time = 10667.541
361500/758000 (epoch 953), train_loss = 0.247, time/batch = 0.030, All_Time = 10669.019
361550/758000 (epoch 953), train_loss = 0.252, time/batch = 0.029, All_Time = 10670.508
361600/758000 (epoch 954), train_loss = 0.264, time/batch = 0.029, All_Time = 10672.005
361650/758000 (epoch 954), train_loss = 0.229, time/batch = 0.030, All_Time = 10673.476
361700/758000 (epoch 954), train_loss = 0.242, time/batch = 0.030, All_Time = 10674.945
361750/758000 (epoch 954), train_loss = 0.267, time/batch = 0.030, All_Time = 10676.426
361800/758000 (epoch 954), train_loss = 0.249, time/batch = 0.030, All_Time = 10677.890
361850/758000 (epoch 954), train_loss = 0.237, time/batch = 0.029, All_Time = 10679.368
361900/758000 (epoch 954), train_loss = 0.276, time/batch = 0.029, All_Time = 10680.834
361950/758000 (epoch 955), train_loss = 0.256, time/batch = 0.030, All_Time = 10682.315
362000/758000 (epoch 955), train_loss = 0.222, time/batch = 0.029, All_Time = 10683.783
model saved to NER/polyglot/model.ckpt
362050/758000 (epoch 955), train_loss = 0.266, time/batch = 0.030, All_Time = 10685.249
362100/758000 (epoch 955), train_loss = 0.216, time/batch = 0.029, All_Time = 10686.709
362150/758000 (epoch 955), train_loss = 0.223, time/batch = 0.030, All_Time = 10688.186
362200/758000 (epoch 955), train_loss = 0.261, time/batch = 0.030, All_Time = 10689.684
362250/758000 (epoch 955), train_loss = 0.238, time/batch = 0.029, All_Time = 10691.175
362300/758000 (epoch 955), train_loss = 0.264, time/batch = 0.029, All_Time = 10692.652
362350/758000 (epoch 956), train_loss = 0.223, time/batch = 0.030, All_Time = 10694.130
362400/758000 (epoch 956), train_loss = 0.231, time/batch = 0.029, All_Time = 10695.599
362450/758000 (epoch 956), train_loss = 0.238, time/batch = 0.029, All_Time = 10697.076
362500/758000 (epoch 956), train_loss = 0.266, time/batch = 0.028, All_Time = 10698.552
362550/758000 (epoch 956), train_loss = 0.239, time/batch = 0.033, All_Time = 10700.028
362600/758000 (epoch 956), train_loss = 0.226, time/batch = 0.028, All_Time = 10701.502
362650/758000 (epoch 956), train_loss = 0.276, time/batch = 0.030, All_Time = 10702.971
362700/758000 (epoch 956), train_loss = 0.240, time/batch = 0.028, All_Time = 10704.443
362750/758000 (epoch 957), train_loss = 0.281, time/batch = 0.028, All_Time = 10705.925
362800/758000 (epoch 957), train_loss = 0.257, time/batch = 0.030, All_Time = 10707.394
362850/758000 (epoch 957), train_loss = 0.240, time/batch = 0.031, All_Time = 10708.874
362900/758000 (epoch 957), train_loss = 0.231, time/batch = 0.029, All_Time = 10710.348
362950/758000 (epoch 957), train_loss = 0.217, time/batch = 0.029, All_Time = 10711.820
363000/758000 (epoch 957), train_loss = 0.224, time/batch = 0.032, All_Time = 10713.299
model saved to NER/polyglot/model.ckpt
363050/758000 (epoch 957), train_loss = 0.215, time/batch = 0.029, All_Time = 10714.788
363100/758000 (epoch 958), train_loss = 0.249, time/batch = 0.030, All_Time = 10716.276
363150/758000 (epoch 958), train_loss = 0.211, time/batch = 0.030, All_Time = 10717.754
363200/758000 (epoch 958), train_loss = 0.245, time/batch = 0.029, All_Time = 10719.219
363250/758000 (epoch 958), train_loss = 0.217, time/batch = 0.030, All_Time = 10720.707
363300/758000 (epoch 958), train_loss = 0.233, time/batch = 0.031, All_Time = 10722.313
363350/758000 (epoch 958), train_loss = 0.228, time/batch = 0.032, All_Time = 10723.897
363400/758000 (epoch 958), train_loss = 0.248, time/batch = 0.029, All_Time = 10725.466
363450/758000 (epoch 958), train_loss = 0.229, time/batch = 0.030, All_Time = 10726.944
363500/758000 (epoch 959), train_loss = 0.218, time/batch = 0.029, All_Time = 10728.434
363550/758000 (epoch 959), train_loss = 0.237, time/batch = 0.029, All_Time = 10729.911
363600/758000 (epoch 959), train_loss = 0.212, time/batch = 0.029, All_Time = 10731.379
363650/758000 (epoch 959), train_loss = 0.266, time/batch = 0.028, All_Time = 10732.849
363700/758000 (epoch 959), train_loss = 0.255, time/batch = 0.030, All_Time = 10734.356
363750/758000 (epoch 959), train_loss = 0.232, time/batch = 0.030, All_Time = 10735.853
363800/758000 (epoch 959), train_loss = 0.262, time/batch = 0.031, All_Time = 10737.343
363850/758000 (epoch 960), train_loss = 0.282, time/batch = 0.030, All_Time = 10738.847
363900/758000 (epoch 960), train_loss = 0.292, time/batch = 0.030, All_Time = 10740.318
363950/758000 (epoch 960), train_loss = 0.253, time/batch = 0.028, All_Time = 10741.775
364000/758000 (epoch 960), train_loss = 0.222, time/batch = 0.030, All_Time = 10743.237
model saved to NER/polyglot/model.ckpt
364050/758000 (epoch 960), train_loss = 0.221, time/batch = 0.029, All_Time = 10744.713
364100/758000 (epoch 960), train_loss = 0.260, time/batch = 0.030, All_Time = 10746.176
364150/758000 (epoch 960), train_loss = 0.244, time/batch = 0.033, All_Time = 10747.672
364200/758000 (epoch 960), train_loss = 0.247, time/batch = 0.030, All_Time = 10749.166
364250/758000 (epoch 961), train_loss = 0.210, time/batch = 0.030, All_Time = 10750.654
364300/758000 (epoch 961), train_loss = 0.265, time/batch = 0.029, All_Time = 10752.127
364350/758000 (epoch 961), train_loss = 0.229, time/batch = 0.028, All_Time = 10753.589
364400/758000 (epoch 961), train_loss = 0.232, time/batch = 0.030, All_Time = 10755.058
364450/758000 (epoch 961), train_loss = 0.230, time/batch = 0.028, All_Time = 10756.530
364500/758000 (epoch 961), train_loss = 0.253, time/batch = 0.029, All_Time = 10758.007
364550/758000 (epoch 961), train_loss = 0.258, time/batch = 0.030, All_Time = 10759.491
364600/758000 (epoch 962), train_loss = 0.196, time/batch = 0.030, All_Time = 10760.985
364650/758000 (epoch 962), train_loss = 0.254, time/batch = 0.032, All_Time = 10762.470
364700/758000 (epoch 962), train_loss = 0.281, time/batch = 0.029, All_Time = 10763.954
364750/758000 (epoch 962), train_loss = 0.235, time/batch = 0.028, All_Time = 10765.426
364800/758000 (epoch 962), train_loss = 0.247, time/batch = 0.029, All_Time = 10766.891
364850/758000 (epoch 962), train_loss = 0.251, time/batch = 0.031, All_Time = 10768.373
364900/758000 (epoch 962), train_loss = 0.203, time/batch = 0.030, All_Time = 10769.849
364950/758000 (epoch 962), train_loss = 0.268, time/batch = 0.028, All_Time = 10771.335
365000/758000 (epoch 963), train_loss = 0.233, time/batch = 0.030, All_Time = 10772.822
model saved to NER/polyglot/model.ckpt
365050/758000 (epoch 963), train_loss = 0.241, time/batch = 0.030, All_Time = 10774.312
365100/758000 (epoch 963), train_loss = 0.252, time/batch = 0.029, All_Time = 10775.804
365150/758000 (epoch 963), train_loss = 0.258, time/batch = 0.030, All_Time = 10777.279
365200/758000 (epoch 963), train_loss = 0.243, time/batch = 0.029, All_Time = 10778.753
365250/758000 (epoch 963), train_loss = 0.243, time/batch = 0.030, All_Time = 10780.235
365300/758000 (epoch 963), train_loss = 0.244, time/batch = 0.029, All_Time = 10781.708
365350/758000 (epoch 963), train_loss = 0.286, time/batch = 0.029, All_Time = 10783.181
365400/758000 (epoch 964), train_loss = 0.207, time/batch = 0.030, All_Time = 10784.666
365450/758000 (epoch 964), train_loss = 0.244, time/batch = 0.029, All_Time = 10786.134
365500/758000 (epoch 964), train_loss = 0.217, time/batch = 0.029, All_Time = 10787.591
365550/758000 (epoch 964), train_loss = 0.233, time/batch = 0.030, All_Time = 10789.082
365600/758000 (epoch 964), train_loss = 0.260, time/batch = 0.030, All_Time = 10790.575
365650/758000 (epoch 964), train_loss = 0.253, time/batch = 0.031, All_Time = 10792.060
365700/758000 (epoch 964), train_loss = 0.238, time/batch = 0.028, All_Time = 10793.549
365750/758000 (epoch 965), train_loss = 0.227, time/batch = 0.029, All_Time = 10795.039
365800/758000 (epoch 965), train_loss = 0.250, time/batch = 0.030, All_Time = 10796.507
365850/758000 (epoch 965), train_loss = 0.250, time/batch = 0.030, All_Time = 10797.977
365900/758000 (epoch 965), train_loss = 0.223, time/batch = 0.028, All_Time = 10799.442
365950/758000 (epoch 965), train_loss = 0.240, time/batch = 0.029, All_Time = 10800.903
366000/758000 (epoch 965), train_loss = 0.246, time/batch = 0.028, All_Time = 10802.374
model saved to NER/polyglot/model.ckpt
366050/758000 (epoch 965), train_loss = 0.246, time/batch = 0.030, All_Time = 10803.850
366100/758000 (epoch 965), train_loss = 0.257, time/batch = 0.030, All_Time = 10805.318
366150/758000 (epoch 966), train_loss = 0.266, time/batch = 0.030, All_Time = 10806.788
366200/758000 (epoch 966), train_loss = 0.224, time/batch = 0.029, All_Time = 10808.249
366250/758000 (epoch 966), train_loss = 0.248, time/batch = 0.029, All_Time = 10809.733
366300/758000 (epoch 966), train_loss = 0.227, time/batch = 0.029, All_Time = 10811.219
366350/758000 (epoch 966), train_loss = 0.279, time/batch = 0.028, All_Time = 10812.705
366400/758000 (epoch 966), train_loss = 0.255, time/batch = 0.031, All_Time = 10814.168
366450/758000 (epoch 966), train_loss = 0.253, time/batch = 0.031, All_Time = 10815.652
366500/758000 (epoch 967), train_loss = 0.244, time/batch = 0.030, All_Time = 10817.148
366550/758000 (epoch 967), train_loss = 0.247, time/batch = 0.030, All_Time = 10818.619
366600/758000 (epoch 967), train_loss = 0.270, time/batch = 0.030, All_Time = 10820.083
366650/758000 (epoch 967), train_loss = 0.246, time/batch = 0.029, All_Time = 10821.559
366700/758000 (epoch 967), train_loss = 0.237, time/batch = 0.031, All_Time = 10823.037
366750/758000 (epoch 967), train_loss = 0.224, time/batch = 0.029, All_Time = 10824.518
366800/758000 (epoch 967), train_loss = 0.229, time/batch = 0.030, All_Time = 10826.012
366850/758000 (epoch 967), train_loss = 0.246, time/batch = 0.030, All_Time = 10827.484
366900/758000 (epoch 968), train_loss = 0.249, time/batch = 0.029, All_Time = 10828.968
366950/758000 (epoch 968), train_loss = 0.264, time/batch = 0.030, All_Time = 10830.435
367000/758000 (epoch 968), train_loss = 0.240, time/batch = 0.029, All_Time = 10831.893
model saved to NER/polyglot/model.ckpt
367050/758000 (epoch 968), train_loss = 0.250, time/batch = 0.029, All_Time = 10833.361
367100/758000 (epoch 968), train_loss = 0.227, time/batch = 0.030, All_Time = 10834.821
367150/758000 (epoch 968), train_loss = 0.217, time/batch = 0.030, All_Time = 10836.303
367200/758000 (epoch 968), train_loss = 0.277, time/batch = 0.033, All_Time = 10837.778
367250/758000 (epoch 968), train_loss = 0.259, time/batch = 0.029, All_Time = 10839.260
367300/758000 (epoch 969), train_loss = 0.269, time/batch = 0.029, All_Time = 10840.728
367350/758000 (epoch 969), train_loss = 0.296, time/batch = 0.028, All_Time = 10842.206
367400/758000 (epoch 969), train_loss = 0.228, time/batch = 0.030, All_Time = 10843.671
367450/758000 (epoch 969), train_loss = 0.220, time/batch = 0.031, All_Time = 10845.146
367500/758000 (epoch 969), train_loss = 0.257, time/batch = 0.030, All_Time = 10846.620
367550/758000 (epoch 969), train_loss = 0.255, time/batch = 0.029, All_Time = 10848.084
367600/758000 (epoch 969), train_loss = 0.237, time/batch = 0.028, All_Time = 10849.586
367650/758000 (epoch 970), train_loss = 0.225, time/batch = 0.029, All_Time = 10851.087
367700/758000 (epoch 970), train_loss = 0.234, time/batch = 0.029, All_Time = 10852.556
367750/758000 (epoch 970), train_loss = 0.243, time/batch = 0.030, All_Time = 10854.028
367800/758000 (epoch 970), train_loss = 0.234, time/batch = 0.029, All_Time = 10855.498
367850/758000 (epoch 970), train_loss = 0.223, time/batch = 0.030, All_Time = 10856.957
367900/758000 (epoch 970), train_loss = 0.239, time/batch = 0.030, All_Time = 10858.455
367950/758000 (epoch 970), train_loss = 0.264, time/batch = 0.029, All_Time = 10859.965
368000/758000 (epoch 970), train_loss = 0.244, time/batch = 0.029, All_Time = 10861.439
model saved to NER/polyglot/model.ckpt
368050/758000 (epoch 971), train_loss = 0.257, time/batch = 0.030, All_Time = 10862.928
368100/758000 (epoch 971), train_loss = 0.287, time/batch = 0.029, All_Time = 10864.390
368150/758000 (epoch 971), train_loss = 0.255, time/batch = 0.031, All_Time = 10865.858
368200/758000 (epoch 971), train_loss = 0.248, time/batch = 0.029, All_Time = 10867.329
368250/758000 (epoch 971), train_loss = 0.212, time/batch = 0.029, All_Time = 10868.790
368300/758000 (epoch 971), train_loss = 0.229, time/batch = 0.029, All_Time = 10870.263
368350/758000 (epoch 971), train_loss = 0.272, time/batch = 0.030, All_Time = 10871.756
368400/758000 (epoch 972), train_loss = 0.249, time/batch = 0.029, All_Time = 10873.243
368450/758000 (epoch 972), train_loss = 0.227, time/batch = 0.030, All_Time = 10874.699
368500/758000 (epoch 972), train_loss = 0.267, time/batch = 0.029, All_Time = 10876.167
368550/758000 (epoch 972), train_loss = 0.239, time/batch = 0.030, All_Time = 10877.639
368600/758000 (epoch 972), train_loss = 0.247, time/batch = 0.030, All_Time = 10879.148
368650/758000 (epoch 972), train_loss = 0.241, time/batch = 0.031, All_Time = 10880.651
368700/758000 (epoch 972), train_loss = 0.274, time/batch = 0.029, All_Time = 10882.138
368750/758000 (epoch 972), train_loss = 0.279, time/batch = 0.029, All_Time = 10883.608
368800/758000 (epoch 973), train_loss = 0.238, time/batch = 0.029, All_Time = 10885.087
368850/758000 (epoch 973), train_loss = 0.248, time/batch = 0.029, All_Time = 10886.550
368900/758000 (epoch 973), train_loss = 0.299, time/batch = 0.028, All_Time = 10888.012
368950/758000 (epoch 973), train_loss = 0.230, time/batch = 0.029, All_Time = 10889.485
369000/758000 (epoch 973), train_loss = 0.216, time/batch = 0.030, All_Time = 10890.989
model saved to NER/polyglot/model.ckpt
369050/758000 (epoch 973), train_loss = 0.244, time/batch = 0.029, All_Time = 10892.474
369100/758000 (epoch 973), train_loss = 0.274, time/batch = 0.029, All_Time = 10893.958
369150/758000 (epoch 974), train_loss = 0.221, time/batch = 0.030, All_Time = 10895.442
369200/758000 (epoch 974), train_loss = 0.257, time/batch = 0.030, All_Time = 10896.907
369250/758000 (epoch 974), train_loss = 0.241, time/batch = 0.029, All_Time = 10898.373
369300/758000 (epoch 974), train_loss = 0.240, time/batch = 0.028, All_Time = 10899.836
369350/758000 (epoch 974), train_loss = 0.256, time/batch = 0.029, All_Time = 10901.302
369400/758000 (epoch 974), train_loss = 0.219, time/batch = 0.028, All_Time = 10902.770
369450/758000 (epoch 974), train_loss = 0.224, time/batch = 0.028, All_Time = 10904.234
369500/758000 (epoch 974), train_loss = 0.257, time/batch = 0.030, All_Time = 10905.700
369550/758000 (epoch 975), train_loss = 0.255, time/batch = 0.029, All_Time = 10907.193
369600/758000 (epoch 975), train_loss = 0.267, time/batch = 0.030, All_Time = 10908.691
369650/758000 (epoch 975), train_loss = 0.269, time/batch = 0.029, All_Time = 10910.170
369700/758000 (epoch 975), train_loss = 0.228, time/batch = 0.029, All_Time = 10911.664
369750/758000 (epoch 975), train_loss = 0.234, time/batch = 0.030, All_Time = 10913.141
369800/758000 (epoch 975), train_loss = 0.245, time/batch = 0.030, All_Time = 10914.622
369850/758000 (epoch 975), train_loss = 0.279, time/batch = 0.029, All_Time = 10916.109
369900/758000 (epoch 975), train_loss = 0.240, time/batch = 0.032, All_Time = 10917.593
369950/758000 (epoch 976), train_loss = 0.236, time/batch = 0.028, All_Time = 10919.076
370000/758000 (epoch 976), train_loss = 0.234, time/batch = 0.029, All_Time = 10920.544
model saved to NER/polyglot/model.ckpt
370050/758000 (epoch 976), train_loss = 0.233, time/batch = 0.029, All_Time = 10922.011
370100/758000 (epoch 976), train_loss = 0.276, time/batch = 0.029, All_Time = 10923.473
370150/758000 (epoch 976), train_loss = 0.206, time/batch = 0.031, All_Time = 10924.944
370200/758000 (epoch 976), train_loss = 0.259, time/batch = 0.029, All_Time = 10926.436
370250/758000 (epoch 976), train_loss = 0.234, time/batch = 0.031, All_Time = 10927.916
370300/758000 (epoch 977), train_loss = 0.245, time/batch = 0.029, All_Time = 10929.401
370350/758000 (epoch 977), train_loss = 0.223, time/batch = 0.030, All_Time = 10930.868
370400/758000 (epoch 977), train_loss = 0.240, time/batch = 0.029, All_Time = 10932.340
370450/758000 (epoch 977), train_loss = 0.256, time/batch = 0.030, All_Time = 10933.816
370500/758000 (epoch 977), train_loss = 0.214, time/batch = 0.029, All_Time = 10935.296
370550/758000 (epoch 977), train_loss = 0.272, time/batch = 0.029, All_Time = 10936.784
370600/758000 (epoch 977), train_loss = 0.213, time/batch = 0.030, All_Time = 10938.290
370650/758000 (epoch 977), train_loss = 0.251, time/batch = 0.030, All_Time = 10939.775
370700/758000 (epoch 978), train_loss = 0.247, time/batch = 0.034, All_Time = 10941.270
370750/758000 (epoch 978), train_loss = 0.229, time/batch = 0.030, All_Time = 10942.744
370800/758000 (epoch 978), train_loss = 0.217, time/batch = 0.028, All_Time = 10944.213
370850/758000 (epoch 978), train_loss = 0.220, time/batch = 0.030, All_Time = 10945.688
370900/758000 (epoch 978), train_loss = 0.250, time/batch = 0.030, All_Time = 10947.174
370950/758000 (epoch 978), train_loss = 0.207, time/batch = 0.029, All_Time = 10948.641
371000/758000 (epoch 978), train_loss = 0.268, time/batch = 0.031, All_Time = 10950.112
model saved to NER/polyglot/model.ckpt
371050/758000 (epoch 979), train_loss = 0.256, time/batch = 0.030, All_Time = 10951.601
371100/758000 (epoch 979), train_loss = 0.264, time/batch = 0.029, All_Time = 10953.060
371150/758000 (epoch 979), train_loss = 0.284, time/batch = 0.029, All_Time = 10954.528
371200/758000 (epoch 979), train_loss = 0.239, time/batch = 0.030, All_Time = 10956.021
371250/758000 (epoch 979), train_loss = 0.267, time/batch = 0.030, All_Time = 10957.542
371300/758000 (epoch 979), train_loss = 0.256, time/batch = 0.030, All_Time = 10959.026
371350/758000 (epoch 979), train_loss = 0.236, time/batch = 0.029, All_Time = 10960.489
371400/758000 (epoch 979), train_loss = 0.268, time/batch = 0.030, All_Time = 10961.964
371450/758000 (epoch 980), train_loss = 0.226, time/batch = 0.029, All_Time = 10963.465
371500/758000 (epoch 980), train_loss = 0.222, time/batch = 0.029, All_Time = 10964.937
371550/758000 (epoch 980), train_loss = 0.261, time/batch = 0.029, All_Time = 10966.404
371600/758000 (epoch 980), train_loss = 0.254, time/batch = 0.029, All_Time = 10967.875
371650/758000 (epoch 980), train_loss = 0.223, time/batch = 0.028, All_Time = 10969.351
371700/758000 (epoch 980), train_loss = 0.242, time/batch = 0.029, All_Time = 10970.820
371750/758000 (epoch 980), train_loss = 0.251, time/batch = 0.028, All_Time = 10972.302
371800/758000 (epoch 981), train_loss = 0.192, time/batch = 0.030, All_Time = 10973.808
371850/758000 (epoch 981), train_loss = 0.273, time/batch = 0.031, All_Time = 10975.303
371900/758000 (epoch 981), train_loss = 0.217, time/batch = 0.030, All_Time = 10976.785
371950/758000 (epoch 981), train_loss = 0.240, time/batch = 0.029, All_Time = 10978.248
372000/758000 (epoch 981), train_loss = 0.221, time/batch = 0.029, All_Time = 10979.718
model saved to NER/polyglot/model.ckpt
372050/758000 (epoch 981), train_loss = 0.221, time/batch = 0.029, All_Time = 10981.190
372100/758000 (epoch 981), train_loss = 0.252, time/batch = 0.029, All_Time = 10982.662
372150/758000 (epoch 981), train_loss = 0.272, time/batch = 0.030, All_Time = 10984.124
372200/758000 (epoch 982), train_loss = 0.222, time/batch = 0.029, All_Time = 10985.593
372250/758000 (epoch 982), train_loss = 0.279, time/batch = 0.028, All_Time = 10987.051
372300/758000 (epoch 982), train_loss = 0.242, time/batch = 0.030, All_Time = 10988.519
372350/758000 (epoch 982), train_loss = 0.274, time/batch = 0.030, All_Time = 10989.989
372400/758000 (epoch 982), train_loss = 0.262, time/batch = 0.031, All_Time = 10991.464
372450/758000 (epoch 982), train_loss = 0.197, time/batch = 0.030, All_Time = 10992.938
372500/758000 (epoch 982), train_loss = 0.233, time/batch = 0.030, All_Time = 10994.411
372550/758000 (epoch 982), train_loss = 0.281, time/batch = 0.030, All_Time = 10995.894
372600/758000 (epoch 983), train_loss = 0.246, time/batch = 0.029, All_Time = 10997.391
372650/758000 (epoch 983), train_loss = 0.212, time/batch = 0.033, All_Time = 10998.880
372700/758000 (epoch 983), train_loss = 0.255, time/batch = 0.030, All_Time = 11000.367
372750/758000 (epoch 983), train_loss = 0.271, time/batch = 0.029, All_Time = 11001.854
372800/758000 (epoch 983), train_loss = 0.203, time/batch = 0.029, All_Time = 11003.328
372850/758000 (epoch 983), train_loss = 0.226, time/batch = 0.031, All_Time = 11004.800
372900/758000 (epoch 983), train_loss = 0.254, time/batch = 0.029, All_Time = 11006.283
372950/758000 (epoch 984), train_loss = 0.219, time/batch = 0.029, All_Time = 11007.775
373000/758000 (epoch 984), train_loss = 0.265, time/batch = 0.029, All_Time = 11009.253
model saved to NER/polyglot/model.ckpt
373050/758000 (epoch 984), train_loss = 0.227, time/batch = 0.030, All_Time = 11010.731
373100/758000 (epoch 984), train_loss = 0.213, time/batch = 0.029, All_Time = 11012.228
373150/758000 (epoch 984), train_loss = 0.224, time/batch = 0.031, All_Time = 11013.727
373200/758000 (epoch 984), train_loss = 0.213, time/batch = 0.028, All_Time = 11015.215
373250/758000 (epoch 984), train_loss = 0.230, time/batch = 0.032, All_Time = 11016.693
373300/758000 (epoch 984), train_loss = 0.223, time/batch = 0.029, All_Time = 11018.188
373350/758000 (epoch 985), train_loss = 0.275, time/batch = 0.030, All_Time = 11019.670
373400/758000 (epoch 985), train_loss = 0.229, time/batch = 0.029, All_Time = 11021.142
373450/758000 (epoch 985), train_loss = 0.270, time/batch = 0.031, All_Time = 11022.614
373500/758000 (epoch 985), train_loss = 0.273, time/batch = 0.031, All_Time = 11024.099
373550/758000 (epoch 985), train_loss = 0.233, time/batch = 0.030, All_Time = 11025.603
373600/758000 (epoch 985), train_loss = 0.268, time/batch = 0.029, All_Time = 11027.082
373650/758000 (epoch 985), train_loss = 0.280, time/batch = 0.029, All_Time = 11028.560
373700/758000 (epoch 986), train_loss = 0.239, time/batch = 0.031, All_Time = 11030.058
373750/758000 (epoch 986), train_loss = 0.218, time/batch = 0.031, All_Time = 11031.527
373800/758000 (epoch 986), train_loss = 0.243, time/batch = 0.029, All_Time = 11033.009
373850/758000 (epoch 986), train_loss = 0.244, time/batch = 0.031, All_Time = 11034.508
373900/758000 (epoch 986), train_loss = 0.243, time/batch = 0.030, All_Time = 11035.992
373950/758000 (epoch 986), train_loss = 0.244, time/batch = 0.028, All_Time = 11037.457
374000/758000 (epoch 986), train_loss = 0.213, time/batch = 0.029, All_Time = 11038.922
model saved to NER/polyglot/model.ckpt
374050/758000 (epoch 986), train_loss = 0.289, time/batch = 0.030, All_Time = 11040.393
374100/758000 (epoch 987), train_loss = 0.237, time/batch = 0.029, All_Time = 11041.881
374150/758000 (epoch 987), train_loss = 0.246, time/batch = 0.029, All_Time = 11043.345
374200/758000 (epoch 987), train_loss = 0.288, time/batch = 0.030, All_Time = 11044.821
374250/758000 (epoch 987), train_loss = 0.257, time/batch = 0.029, All_Time = 11046.305
374300/758000 (epoch 987), train_loss = 0.218, time/batch = 0.031, All_Time = 11047.818
374350/758000 (epoch 987), train_loss = 0.238, time/batch = 0.029, All_Time = 11049.296
374400/758000 (epoch 987), train_loss = 0.251, time/batch = 0.029, All_Time = 11050.765
374450/758000 (epoch 987), train_loss = 0.251, time/batch = 0.030, All_Time = 11052.250
374500/758000 (epoch 988), train_loss = 0.252, time/batch = 0.028, All_Time = 11053.735
374550/758000 (epoch 988), train_loss = 0.280, time/batch = 0.029, All_Time = 11055.198
374600/758000 (epoch 988), train_loss = 0.242, time/batch = 0.029, All_Time = 11056.668
374650/758000 (epoch 988), train_loss = 0.250, time/batch = 0.031, All_Time = 11058.167
374700/758000 (epoch 988), train_loss = 0.239, time/batch = 0.029, All_Time = 11059.674
374750/758000 (epoch 988), train_loss = 0.239, time/batch = 0.032, All_Time = 11061.155
374800/758000 (epoch 988), train_loss = 0.250, time/batch = 0.032, All_Time = 11062.641
374850/758000 (epoch 989), train_loss = 0.221, time/batch = 0.031, All_Time = 11064.124
374900/758000 (epoch 989), train_loss = 0.219, time/batch = 0.029, All_Time = 11065.589
374950/758000 (epoch 989), train_loss = 0.246, time/batch = 0.028, All_Time = 11067.051
375000/758000 (epoch 989), train_loss = 0.262, time/batch = 0.029, All_Time = 11068.522
model saved to NER/polyglot/model.ckpt
375050/758000 (epoch 989), train_loss = 0.260, time/batch = 0.030, All_Time = 11069.989
375100/758000 (epoch 989), train_loss = 0.241, time/batch = 0.029, All_Time = 11071.458
375150/758000 (epoch 989), train_loss = 0.210, time/batch = 0.029, All_Time = 11072.931
375200/758000 (epoch 989), train_loss = 0.239, time/batch = 0.029, All_Time = 11074.440
375250/758000 (epoch 990), train_loss = 0.230, time/batch = 0.030, All_Time = 11075.931
375300/758000 (epoch 990), train_loss = 0.226, time/batch = 0.030, All_Time = 11077.405
375350/758000 (epoch 990), train_loss = 0.264, time/batch = 0.029, All_Time = 11078.889
375400/758000 (epoch 990), train_loss = 0.240, time/batch = 0.029, All_Time = 11080.367
375450/758000 (epoch 990), train_loss = 0.253, time/batch = 0.030, All_Time = 11081.842
375500/758000 (epoch 990), train_loss = 0.251, time/batch = 0.029, All_Time = 11083.304
375550/758000 (epoch 990), train_loss = 0.248, time/batch = 0.028, All_Time = 11084.787
375600/758000 (epoch 991), train_loss = 0.216, time/batch = 0.029, All_Time = 11086.267
375650/758000 (epoch 991), train_loss = 0.233, time/batch = 0.029, All_Time = 11087.729
375700/758000 (epoch 991), train_loss = 0.250, time/batch = 0.029, All_Time = 11089.196
375750/758000 (epoch 991), train_loss = 0.241, time/batch = 0.031, All_Time = 11090.714
375800/758000 (epoch 991), train_loss = 0.243, time/batch = 0.029, All_Time = 11092.197
375850/758000 (epoch 991), train_loss = 0.242, time/batch = 0.030, All_Time = 11093.674
375900/758000 (epoch 991), train_loss = 0.230, time/batch = 0.029, All_Time = 11095.146
375950/758000 (epoch 991), train_loss = 0.259, time/batch = 0.029, All_Time = 11096.625
376000/758000 (epoch 992), train_loss = 0.250, time/batch = 0.029, All_Time = 11098.111
model saved to NER/polyglot/model.ckpt
376050/758000 (epoch 992), train_loss = 0.253, time/batch = 0.029, All_Time = 11099.580
376100/758000 (epoch 992), train_loss = 0.245, time/batch = 0.027, All_Time = 11101.034
376150/758000 (epoch 992), train_loss = 0.231, time/batch = 0.030, All_Time = 11102.491
376200/758000 (epoch 992), train_loss = 0.228, time/batch = 0.029, All_Time = 11103.961
376250/758000 (epoch 992), train_loss = 0.238, time/batch = 0.028, All_Time = 11105.424
376300/758000 (epoch 992), train_loss = 0.268, time/batch = 0.030, All_Time = 11106.886
376350/758000 (epoch 993), train_loss = 0.248, time/batch = 0.029, All_Time = 11108.365
376400/758000 (epoch 993), train_loss = 0.280, time/batch = 0.028, All_Time = 11109.829
376450/758000 (epoch 993), train_loss = 0.242, time/batch = 0.029, All_Time = 11111.295
376500/758000 (epoch 993), train_loss = 0.258, time/batch = 0.030, All_Time = 11112.778
376550/758000 (epoch 993), train_loss = 0.224, time/batch = 0.029, All_Time = 11114.253
376600/758000 (epoch 993), train_loss = 0.243, time/batch = 0.031, All_Time = 11115.727
376650/758000 (epoch 993), train_loss = 0.219, time/batch = 0.029, All_Time = 11117.197
376700/758000 (epoch 993), train_loss = 0.232, time/batch = 0.033, All_Time = 11118.669
376750/758000 (epoch 994), train_loss = 0.237, time/batch = 0.029, All_Time = 11120.150
376800/758000 (epoch 994), train_loss = 0.239, time/batch = 0.029, All_Time = 11121.616
376850/758000 (epoch 994), train_loss = 0.293, time/batch = 0.029, All_Time = 11123.086
376900/758000 (epoch 994), train_loss = 0.318, time/batch = 0.029, All_Time = 11124.554
376950/758000 (epoch 994), train_loss = 0.196, time/batch = 0.031, All_Time = 11126.039
377000/758000 (epoch 994), train_loss = 0.213, time/batch = 0.032, All_Time = 11127.547
model saved to NER/polyglot/model.ckpt
377050/758000 (epoch 994), train_loss = 0.250, time/batch = 0.030, All_Time = 11129.020
377100/758000 (epoch 994), train_loss = 0.297, time/batch = 0.030, All_Time = 11130.483
377150/758000 (epoch 995), train_loss = 0.226, time/batch = 0.028, All_Time = 11131.960
377200/758000 (epoch 995), train_loss = 0.259, time/batch = 0.029, All_Time = 11133.429
377250/758000 (epoch 995), train_loss = 0.223, time/batch = 0.028, All_Time = 11134.889
377300/758000 (epoch 995), train_loss = 0.239, time/batch = 0.030, All_Time = 11136.367
377350/758000 (epoch 995), train_loss = 0.212, time/batch = 0.029, All_Time = 11137.849
377400/758000 (epoch 995), train_loss = 0.243, time/batch = 0.030, All_Time = 11139.316
377450/758000 (epoch 995), train_loss = 0.215, time/batch = 0.029, All_Time = 11140.788
377500/758000 (epoch 996), train_loss = 0.228, time/batch = 0.028, All_Time = 11142.279
377550/758000 (epoch 996), train_loss = 0.252, time/batch = 0.029, All_Time = 11143.741
377600/758000 (epoch 996), train_loss = 0.260, time/batch = 0.031, All_Time = 11145.254
377650/758000 (epoch 996), train_loss = 0.228, time/batch = 0.030, All_Time = 11146.755
377700/758000 (epoch 996), train_loss = 0.236, time/batch = 0.030, All_Time = 11148.245
377750/758000 (epoch 996), train_loss = 0.271, time/batch = 0.030, All_Time = 11149.726
377800/758000 (epoch 996), train_loss = 0.238, time/batch = 0.029, All_Time = 11151.212
377850/758000 (epoch 996), train_loss = 0.268, time/batch = 0.029, All_Time = 11152.704
377900/758000 (epoch 997), train_loss = 0.248, time/batch = 0.030, All_Time = 11154.199
377950/758000 (epoch 997), train_loss = 0.249, time/batch = 0.030, All_Time = 11155.665
378000/758000 (epoch 997), train_loss = 0.240, time/batch = 0.031, All_Time = 11157.144
model saved to NER/polyglot/model.ckpt
378050/758000 (epoch 997), train_loss = 0.247, time/batch = 0.030, All_Time = 11158.622
378100/758000 (epoch 997), train_loss = 0.235, time/batch = 0.029, All_Time = 11160.088
378150/758000 (epoch 997), train_loss = 0.247, time/batch = 0.030, All_Time = 11161.551
378200/758000 (epoch 997), train_loss = 0.251, time/batch = 0.031, All_Time = 11163.029
378250/758000 (epoch 998), train_loss = 0.242, time/batch = 0.031, All_Time = 11164.550
378300/758000 (epoch 998), train_loss = 0.276, time/batch = 0.030, All_Time = 11166.031
378350/758000 (epoch 998), train_loss = 0.256, time/batch = 0.029, All_Time = 11167.508
378400/758000 (epoch 998), train_loss = 0.258, time/batch = 0.029, All_Time = 11168.981
378450/758000 (epoch 998), train_loss = 0.213, time/batch = 0.029, All_Time = 11170.455
378500/758000 (epoch 998), train_loss = 0.237, time/batch = 0.029, All_Time = 11171.922
378550/758000 (epoch 998), train_loss = 0.249, time/batch = 0.029, All_Time = 11173.395
378600/758000 (epoch 998), train_loss = 0.251, time/batch = 0.031, All_Time = 11174.873
378650/758000 (epoch 999), train_loss = 0.232, time/batch = 0.029, All_Time = 11176.371
378700/758000 (epoch 999), train_loss = 0.255, time/batch = 0.029, All_Time = 11177.862
378750/758000 (epoch 999), train_loss = 0.265, time/batch = 0.031, All_Time = 11179.345
378800/758000 (epoch 999), train_loss = 0.229, time/batch = 0.029, All_Time = 11180.832
378850/758000 (epoch 999), train_loss = 0.263, time/batch = 0.031, All_Time = 11182.317
378900/758000 (epoch 999), train_loss = 0.217, time/batch = 0.030, All_Time = 11183.803
378950/758000 (epoch 999), train_loss = 0.248, time/batch = 0.029, All_Time = 11185.273
379000/758000 (epoch 1000), train_loss = 0.059, time/batch = 0.040, All_Time = 11186.764
model saved to NER/polyglot/model.ckpt
379050/758000 (epoch 1000), train_loss = 0.250, time/batch = 0.030, All_Time = 11188.233
379100/758000 (epoch 1000), train_loss = 0.223, time/batch = 0.030, All_Time = 11189.700
379150/758000 (epoch 1000), train_loss = 0.250, time/batch = 0.029, All_Time = 11191.170
379200/758000 (epoch 1000), train_loss = 0.231, time/batch = 0.030, All_Time = 11192.664
379250/758000 (epoch 1000), train_loss = 0.250, time/batch = 0.030, All_Time = 11194.150
379300/758000 (epoch 1000), train_loss = 0.232, time/batch = 0.029, All_Time = 11195.632
379350/758000 (epoch 1000), train_loss = 0.230, time/batch = 0.029, All_Time = 11197.107
379400/758000 (epoch 1001), train_loss = 0.224, time/batch = 0.028, All_Time = 11198.584
379450/758000 (epoch 1001), train_loss = 0.233, time/batch = 0.030, All_Time = 11200.062
379500/758000 (epoch 1001), train_loss = 0.224, time/batch = 0.031, All_Time = 11201.561
379550/758000 (epoch 1001), train_loss = 0.262, time/batch = 0.029, All_Time = 11203.054
379600/758000 (epoch 1001), train_loss = 0.220, time/batch = 0.028, All_Time = 11204.538
379650/758000 (epoch 1001), train_loss = 0.228, time/batch = 0.030, All_Time = 11206.006
379700/758000 (epoch 1001), train_loss = 0.280, time/batch = 0.030, All_Time = 11207.487
379750/758000 (epoch 1001), train_loss = 0.272, time/batch = 0.031, All_Time = 11208.982
379800/758000 (epoch 1002), train_loss = 0.230, time/batch = 0.028, All_Time = 11210.470
379850/758000 (epoch 1002), train_loss = 0.224, time/batch = 0.030, All_Time = 11211.960
379900/758000 (epoch 1002), train_loss = 0.201, time/batch = 0.029, All_Time = 11213.437
379950/758000 (epoch 1002), train_loss = 0.270, time/batch = 0.029, All_Time = 11214.913
380000/758000 (epoch 1002), train_loss = 0.259, time/batch = 0.029, All_Time = 11216.385
model saved to NER/polyglot/model.ckpt
380050/758000 (epoch 1002), train_loss = 0.209, time/batch = 0.029, All_Time = 11217.856
380100/758000 (epoch 1002), train_loss = 0.218, time/batch = 0.028, All_Time = 11219.325
380150/758000 (epoch 1003), train_loss = 0.229, time/batch = 0.030, All_Time = 11220.829
380200/758000 (epoch 1003), train_loss = 0.283, time/batch = 0.028, All_Time = 11222.306
380250/758000 (epoch 1003), train_loss = 0.231, time/batch = 0.029, All_Time = 11223.779
380300/758000 (epoch 1003), train_loss = 0.307, time/batch = 0.030, All_Time = 11225.242
380350/758000 (epoch 1003), train_loss = 0.221, time/batch = 0.033, All_Time = 11226.717
380400/758000 (epoch 1003), train_loss = 0.208, time/batch = 0.029, All_Time = 11228.214
380450/758000 (epoch 1003), train_loss = 0.247, time/batch = 0.029, All_Time = 11229.701
380500/758000 (epoch 1003), train_loss = 0.252, time/batch = 0.029, All_Time = 11231.189
380550/758000 (epoch 1004), train_loss = 0.264, time/batch = 0.030, All_Time = 11232.685
380600/758000 (epoch 1004), train_loss = 0.229, time/batch = 0.030, All_Time = 11234.147
380650/758000 (epoch 1004), train_loss = 0.242, time/batch = 0.029, All_Time = 11235.615
380700/758000 (epoch 1004), train_loss = 0.267, time/batch = 0.029, All_Time = 11237.087
380750/758000 (epoch 1004), train_loss = 0.249, time/batch = 0.029, All_Time = 11238.558
380800/758000 (epoch 1004), train_loss = 0.237, time/batch = 0.030, All_Time = 11240.077
380850/758000 (epoch 1004), train_loss = 0.276, time/batch = 0.028, All_Time = 11241.570
380900/758000 (epoch 1005), train_loss = 0.256, time/batch = 0.030, All_Time = 11243.054
380950/758000 (epoch 1005), train_loss = 0.222, time/batch = 0.031, All_Time = 11244.514
381000/758000 (epoch 1005), train_loss = 0.266, time/batch = 0.030, All_Time = 11245.980
model saved to NER/polyglot/model.ckpt
381050/758000 (epoch 1005), train_loss = 0.216, time/batch = 0.028, All_Time = 11247.450
381100/758000 (epoch 1005), train_loss = 0.223, time/batch = 0.029, All_Time = 11248.910
381150/758000 (epoch 1005), train_loss = 0.261, time/batch = 0.030, All_Time = 11250.371
381200/758000 (epoch 1005), train_loss = 0.238, time/batch = 0.030, All_Time = 11251.846
381250/758000 (epoch 1005), train_loss = 0.264, time/batch = 0.029, All_Time = 11253.342
381300/758000 (epoch 1006), train_loss = 0.223, time/batch = 0.030, All_Time = 11254.827
381350/758000 (epoch 1006), train_loss = 0.231, time/batch = 0.029, All_Time = 11256.304
381400/758000 (epoch 1006), train_loss = 0.238, time/batch = 0.031, All_Time = 11257.792
381450/758000 (epoch 1006), train_loss = 0.266, time/batch = 0.029, All_Time = 11259.261
381500/758000 (epoch 1006), train_loss = 0.239, time/batch = 0.029, All_Time = 11260.744
381550/758000 (epoch 1006), train_loss = 0.226, time/batch = 0.030, All_Time = 11262.219
381600/758000 (epoch 1006), train_loss = 0.276, time/batch = 0.030, All_Time = 11263.698
381650/758000 (epoch 1006), train_loss = 0.240, time/batch = 0.030, All_Time = 11265.194
381700/758000 (epoch 1007), train_loss = 0.281, time/batch = 0.030, All_Time = 11266.690
381750/758000 (epoch 1007), train_loss = 0.257, time/batch = 0.029, All_Time = 11268.152
381800/758000 (epoch 1007), train_loss = 0.240, time/batch = 0.030, All_Time = 11269.626
381850/758000 (epoch 1007), train_loss = 0.231, time/batch = 0.029, All_Time = 11271.099
381900/758000 (epoch 1007), train_loss = 0.217, time/batch = 0.031, All_Time = 11272.597
381950/758000 (epoch 1007), train_loss = 0.224, time/batch = 0.030, All_Time = 11274.099
382000/758000 (epoch 1007), train_loss = 0.215, time/batch = 0.031, All_Time = 11275.602
model saved to NER/polyglot/model.ckpt
382050/758000 (epoch 1008), train_loss = 0.249, time/batch = 0.030, All_Time = 11277.096
382100/758000 (epoch 1008), train_loss = 0.211, time/batch = 0.029, All_Time = 11278.560
382150/758000 (epoch 1008), train_loss = 0.245, time/batch = 0.030, All_Time = 11280.022
382200/758000 (epoch 1008), train_loss = 0.217, time/batch = 0.030, All_Time = 11281.481
382250/758000 (epoch 1008), train_loss = 0.233, time/batch = 0.030, All_Time = 11282.966
382300/758000 (epoch 1008), train_loss = 0.228, time/batch = 0.031, All_Time = 11284.464
382350/758000 (epoch 1008), train_loss = 0.248, time/batch = 0.029, All_Time = 11285.949
382400/758000 (epoch 1008), train_loss = 0.229, time/batch = 0.029, All_Time = 11287.421
382450/758000 (epoch 1009), train_loss = 0.218, time/batch = 0.030, All_Time = 11288.913
382500/758000 (epoch 1009), train_loss = 0.237, time/batch = 0.029, All_Time = 11290.385
382550/758000 (epoch 1009), train_loss = 0.212, time/batch = 0.029, All_Time = 11291.853
382600/758000 (epoch 1009), train_loss = 0.266, time/batch = 0.030, All_Time = 11293.322
382650/758000 (epoch 1009), train_loss = 0.255, time/batch = 0.030, All_Time = 11294.827
382700/758000 (epoch 1009), train_loss = 0.232, time/batch = 0.029, All_Time = 11296.317
382750/758000 (epoch 1009), train_loss = 0.262, time/batch = 0.030, All_Time = 11297.798
382800/758000 (epoch 1010), train_loss = 0.282, time/batch = 0.028, All_Time = 11299.285
382850/758000 (epoch 1010), train_loss = 0.292, time/batch = 0.029, All_Time = 11300.761
382900/758000 (epoch 1010), train_loss = 0.253, time/batch = 0.029, All_Time = 11302.231
382950/758000 (epoch 1010), train_loss = 0.222, time/batch = 0.030, All_Time = 11303.706
383000/758000 (epoch 1010), train_loss = 0.221, time/batch = 0.029, All_Time = 11305.175
model saved to NER/polyglot/model.ckpt
383050/758000 (epoch 1010), train_loss = 0.260, time/batch = 0.028, All_Time = 11306.646
383100/758000 (epoch 1010), train_loss = 0.244, time/batch = 0.029, All_Time = 11308.212
383150/758000 (epoch 1010), train_loss = 0.247, time/batch = 0.031, All_Time = 11309.724
383200/758000 (epoch 1011), train_loss = 0.210, time/batch = 0.030, All_Time = 11311.234
383250/758000 (epoch 1011), train_loss = 0.265, time/batch = 0.029, All_Time = 11312.702
383300/758000 (epoch 1011), train_loss = 0.229, time/batch = 0.029, All_Time = 11314.170
383350/758000 (epoch 1011), train_loss = 0.232, time/batch = 0.030, All_Time = 11315.646
383400/758000 (epoch 1011), train_loss = 0.230, time/batch = 0.030, All_Time = 11317.135
383450/758000 (epoch 1011), train_loss = 0.253, time/batch = 0.029, All_Time = 11318.603
383500/758000 (epoch 1011), train_loss = 0.258, time/batch = 0.029, All_Time = 11320.076
383550/758000 (epoch 1012), train_loss = 0.196, time/batch = 0.028, All_Time = 11321.567
383600/758000 (epoch 1012), train_loss = 0.254, time/batch = 0.029, All_Time = 11323.032
383650/758000 (epoch 1012), train_loss = 0.281, time/batch = 0.031, All_Time = 11324.500
383700/758000 (epoch 1012), train_loss = 0.235, time/batch = 0.032, All_Time = 11325.979
383750/758000 (epoch 1012), train_loss = 0.247, time/batch = 0.029, All_Time = 11327.468
383800/758000 (epoch 1012), train_loss = 0.251, time/batch = 0.029, All_Time = 11328.942
383850/758000 (epoch 1012), train_loss = 0.203, time/batch = 0.030, All_Time = 11330.437
383900/758000 (epoch 1012), train_loss = 0.268, time/batch = 0.030, All_Time = 11331.920
383950/758000 (epoch 1013), train_loss = 0.233, time/batch = 0.030, All_Time = 11333.414
384000/758000 (epoch 1013), train_loss = 0.241, time/batch = 0.029, All_Time = 11334.883
model saved to NER/polyglot/model.ckpt
384050/758000 (epoch 1013), train_loss = 0.252, time/batch = 0.029, All_Time = 11336.354
384100/758000 (epoch 1013), train_loss = 0.258, time/batch = 0.030, All_Time = 11337.817
384150/758000 (epoch 1013), train_loss = 0.243, time/batch = 0.029, All_Time = 11339.287
384200/758000 (epoch 1013), train_loss = 0.243, time/batch = 0.029, All_Time = 11340.767
384250/758000 (epoch 1013), train_loss = 0.244, time/batch = 0.029, All_Time = 11342.235
384300/758000 (epoch 1013), train_loss = 0.286, time/batch = 0.030, All_Time = 11343.745
384350/758000 (epoch 1014), train_loss = 0.207, time/batch = 0.029, All_Time = 11345.239
384400/758000 (epoch 1014), train_loss = 0.244, time/batch = 0.029, All_Time = 11346.714
384450/758000 (epoch 1014), train_loss = 0.217, time/batch = 0.029, All_Time = 11348.200
384500/758000 (epoch 1014), train_loss = 0.233, time/batch = 0.030, All_Time = 11349.681
384550/758000 (epoch 1014), train_loss = 0.260, time/batch = 0.030, All_Time = 11351.161
384600/758000 (epoch 1014), train_loss = 0.253, time/batch = 0.031, All_Time = 11352.635
384650/758000 (epoch 1014), train_loss = 0.238, time/batch = 0.028, All_Time = 11354.100
384700/758000 (epoch 1015), train_loss = 0.227, time/batch = 0.030, All_Time = 11355.580
384750/758000 (epoch 1015), train_loss = 0.250, time/batch = 0.029, All_Time = 11357.049
384800/758000 (epoch 1015), train_loss = 0.250, time/batch = 0.031, All_Time = 11358.521
384850/758000 (epoch 1015), train_loss = 0.223, time/batch = 0.030, All_Time = 11360.007
384900/758000 (epoch 1015), train_loss = 0.240, time/batch = 0.030, All_Time = 11361.510
384950/758000 (epoch 1015), train_loss = 0.246, time/batch = 0.030, All_Time = 11363.006
385000/758000 (epoch 1015), train_loss = 0.246, time/batch = 0.029, All_Time = 11364.569
model saved to NER/polyglot/model.ckpt
385050/758000 (epoch 1015), train_loss = 0.257, time/batch = 0.030, All_Time = 11366.041
385100/758000 (epoch 1016), train_loss = 0.266, time/batch = 0.031, All_Time = 11367.520
385150/758000 (epoch 1016), train_loss = 0.224, time/batch = 0.029, All_Time = 11368.986
385200/758000 (epoch 1016), train_loss = 0.248, time/batch = 0.029, All_Time = 11370.450
385250/758000 (epoch 1016), train_loss = 0.227, time/batch = 0.028, All_Time = 11371.912
385300/758000 (epoch 1016), train_loss = 0.279, time/batch = 0.029, All_Time = 11373.370
385350/758000 (epoch 1016), train_loss = 0.255, time/batch = 0.032, All_Time = 11374.904
385400/758000 (epoch 1016), train_loss = 0.253, time/batch = 0.029, All_Time = 11376.408
385450/758000 (epoch 1017), train_loss = 0.244, time/batch = 0.029, All_Time = 11377.902
385500/758000 (epoch 1017), train_loss = 0.247, time/batch = 0.029, All_Time = 11379.383
385550/758000 (epoch 1017), train_loss = 0.270, time/batch = 0.030, All_Time = 11380.854
385600/758000 (epoch 1017), train_loss = 0.246, time/batch = 0.030, All_Time = 11382.314
385650/758000 (epoch 1017), train_loss = 0.237, time/batch = 0.030, All_Time = 11383.786
385700/758000 (epoch 1017), train_loss = 0.224, time/batch = 0.029, All_Time = 11385.245
385750/758000 (epoch 1017), train_loss = 0.229, time/batch = 0.028, All_Time = 11386.753
385800/758000 (epoch 1017), train_loss = 0.246, time/batch = 0.029, All_Time = 11388.235
385850/758000 (epoch 1018), train_loss = 0.249, time/batch = 0.030, All_Time = 11389.733
385900/758000 (epoch 1018), train_loss = 0.264, time/batch = 0.031, All_Time = 11391.196
385950/758000 (epoch 1018), train_loss = 0.240, time/batch = 0.031, All_Time = 11392.677
386000/758000 (epoch 1018), train_loss = 0.250, time/batch = 0.029, All_Time = 11394.176
model saved to NER/polyglot/model.ckpt
386050/758000 (epoch 1018), train_loss = 0.227, time/batch = 0.029, All_Time = 11395.656
386100/758000 (epoch 1018), train_loss = 0.217, time/batch = 0.030, All_Time = 11397.120
386150/758000 (epoch 1018), train_loss = 0.277, time/batch = 0.029, All_Time = 11398.585
386200/758000 (epoch 1018), train_loss = 0.259, time/batch = 0.029, All_Time = 11400.047
386250/758000 (epoch 1019), train_loss = 0.269, time/batch = 0.030, All_Time = 11401.526
386300/758000 (epoch 1019), train_loss = 0.296, time/batch = 0.030, All_Time = 11402.994
386350/758000 (epoch 1019), train_loss = 0.228, time/batch = 0.029, All_Time = 11404.501
386400/758000 (epoch 1019), train_loss = 0.220, time/batch = 0.031, All_Time = 11406.005
386450/758000 (epoch 1019), train_loss = 0.257, time/batch = 0.029, All_Time = 11407.486
386500/758000 (epoch 1019), train_loss = 0.255, time/batch = 0.029, All_Time = 11408.957
386550/758000 (epoch 1019), train_loss = 0.237, time/batch = 0.031, All_Time = 11410.435
386600/758000 (epoch 1020), train_loss = 0.225, time/batch = 0.030, All_Time = 11411.912
386650/758000 (epoch 1020), train_loss = 0.234, time/batch = 0.029, All_Time = 11413.372
386700/758000 (epoch 1020), train_loss = 0.243, time/batch = 0.030, All_Time = 11414.833
386750/758000 (epoch 1020), train_loss = 0.234, time/batch = 0.031, All_Time = 11416.335
386800/758000 (epoch 1020), train_loss = 0.223, time/batch = 0.030, All_Time = 11417.825
386850/758000 (epoch 1020), train_loss = 0.239, time/batch = 0.030, All_Time = 11419.310
386900/758000 (epoch 1020), train_loss = 0.264, time/batch = 0.030, All_Time = 11420.800
386950/758000 (epoch 1020), train_loss = 0.244, time/batch = 0.030, All_Time = 11422.284
387000/758000 (epoch 1021), train_loss = 0.257, time/batch = 0.029, All_Time = 11423.768
model saved to NER/polyglot/model.ckpt
387050/758000 (epoch 1021), train_loss = 0.287, time/batch = 0.030, All_Time = 11425.237
387100/758000 (epoch 1021), train_loss = 0.255, time/batch = 0.030, All_Time = 11426.696
387150/758000 (epoch 1021), train_loss = 0.248, time/batch = 0.030, All_Time = 11428.155
387200/758000 (epoch 1021), train_loss = 0.212, time/batch = 0.029, All_Time = 11429.616
387250/758000 (epoch 1021), train_loss = 0.229, time/batch = 0.030, All_Time = 11431.079
387300/758000 (epoch 1021), train_loss = 0.272, time/batch = 0.029, All_Time = 11432.570
387350/758000 (epoch 1022), train_loss = 0.249, time/batch = 0.029, All_Time = 11434.068
387400/758000 (epoch 1022), train_loss = 0.227, time/batch = 0.029, All_Time = 11435.551
387450/758000 (epoch 1022), train_loss = 0.267, time/batch = 0.031, All_Time = 11437.023
387500/758000 (epoch 1022), train_loss = 0.239, time/batch = 0.028, All_Time = 11438.488
387550/758000 (epoch 1022), train_loss = 0.247, time/batch = 0.029, All_Time = 11439.964
387600/758000 (epoch 1022), train_loss = 0.241, time/batch = 0.030, All_Time = 11441.437
387650/758000 (epoch 1022), train_loss = 0.274, time/batch = 0.031, All_Time = 11442.923
387700/758000 (epoch 1022), train_loss = 0.279, time/batch = 0.029, All_Time = 11444.429
387750/758000 (epoch 1023), train_loss = 0.238, time/batch = 0.028, All_Time = 11445.921
387800/758000 (epoch 1023), train_loss = 0.248, time/batch = 0.029, All_Time = 11447.402
387850/758000 (epoch 1023), train_loss = 0.299, time/batch = 0.030, All_Time = 11448.867
387900/758000 (epoch 1023), train_loss = 0.230, time/batch = 0.029, All_Time = 11450.342
387950/758000 (epoch 1023), train_loss = 0.216, time/batch = 0.029, All_Time = 11451.834
388000/758000 (epoch 1023), train_loss = 0.244, time/batch = 0.030, All_Time = 11453.309
model saved to NER/polyglot/model.ckpt
388050/758000 (epoch 1023), train_loss = 0.274, time/batch = 0.030, All_Time = 11454.774
388100/758000 (epoch 1024), train_loss = 0.221, time/batch = 0.031, All_Time = 11456.267
388150/758000 (epoch 1024), train_loss = 0.257, time/batch = 0.029, All_Time = 11457.758
388200/758000 (epoch 1024), train_loss = 0.241, time/batch = 0.028, All_Time = 11459.229
388250/758000 (epoch 1024), train_loss = 0.240, time/batch = 0.029, All_Time = 11460.702
388300/758000 (epoch 1024), train_loss = 0.256, time/batch = 0.029, All_Time = 11462.167
388350/758000 (epoch 1024), train_loss = 0.219, time/batch = 0.028, All_Time = 11463.655
388400/758000 (epoch 1024), train_loss = 0.224, time/batch = 0.029, All_Time = 11465.123
388450/758000 (epoch 1024), train_loss = 0.257, time/batch = 0.029, All_Time = 11466.600
388500/758000 (epoch 1025), train_loss = 0.255, time/batch = 0.030, All_Time = 11468.084
388550/758000 (epoch 1025), train_loss = 0.267, time/batch = 0.029, All_Time = 11469.552
388600/758000 (epoch 1025), train_loss = 0.269, time/batch = 0.029, All_Time = 11471.024
388650/758000 (epoch 1025), train_loss = 0.228, time/batch = 0.030, All_Time = 11472.534
388700/758000 (epoch 1025), train_loss = 0.234, time/batch = 0.030, All_Time = 11474.025
388750/758000 (epoch 1025), train_loss = 0.245, time/batch = 0.029, All_Time = 11475.502
388800/758000 (epoch 1025), train_loss = 0.279, time/batch = 0.030, All_Time = 11476.980
388850/758000 (epoch 1025), train_loss = 0.240, time/batch = 0.030, All_Time = 11478.454
388900/758000 (epoch 1026), train_loss = 0.236, time/batch = 0.030, All_Time = 11479.931
388950/758000 (epoch 1026), train_loss = 0.234, time/batch = 0.030, All_Time = 11481.403
389000/758000 (epoch 1026), train_loss = 0.233, time/batch = 0.030, All_Time = 11482.881
model saved to NER/polyglot/model.ckpt
389050/758000 (epoch 1026), train_loss = 0.276, time/batch = 0.028, All_Time = 11484.353
389100/758000 (epoch 1026), train_loss = 0.206, time/batch = 0.032, All_Time = 11485.832
389150/758000 (epoch 1026), train_loss = 0.259, time/batch = 0.029, All_Time = 11487.348
389200/758000 (epoch 1026), train_loss = 0.234, time/batch = 0.029, All_Time = 11488.836
389250/758000 (epoch 1027), train_loss = 0.245, time/batch = 0.029, All_Time = 11490.333
389300/758000 (epoch 1027), train_loss = 0.223, time/batch = 0.029, All_Time = 11491.809
389350/758000 (epoch 1027), train_loss = 0.240, time/batch = 0.030, All_Time = 11493.319
389400/758000 (epoch 1027), train_loss = 0.256, time/batch = 0.031, All_Time = 11494.809
389450/758000 (epoch 1027), train_loss = 0.214, time/batch = 0.032, All_Time = 11496.276
389500/758000 (epoch 1027), train_loss = 0.272, time/batch = 0.030, All_Time = 11497.749
389550/758000 (epoch 1027), train_loss = 0.213, time/batch = 0.031, All_Time = 11499.225
389600/758000 (epoch 1027), train_loss = 0.251, time/batch = 0.029, All_Time = 11500.704
389650/758000 (epoch 1028), train_loss = 0.247, time/batch = 0.030, All_Time = 11502.179
389700/758000 (epoch 1028), train_loss = 0.229, time/batch = 0.029, All_Time = 11503.648
389750/758000 (epoch 1028), train_loss = 0.217, time/batch = 0.029, All_Time = 11505.136
389800/758000 (epoch 1028), train_loss = 0.220, time/batch = 0.031, All_Time = 11506.646
389850/758000 (epoch 1028), train_loss = 0.250, time/batch = 0.031, All_Time = 11508.143
389900/758000 (epoch 1028), train_loss = 0.207, time/batch = 0.029, All_Time = 11509.632
389950/758000 (epoch 1028), train_loss = 0.268, time/batch = 0.029, All_Time = 11511.121
390000/758000 (epoch 1029), train_loss = 0.256, time/batch = 0.029, All_Time = 11512.623
model saved to NER/polyglot/model.ckpt
390050/758000 (epoch 1029), train_loss = 0.264, time/batch = 0.029, All_Time = 11514.094
390100/758000 (epoch 1029), train_loss = 0.284, time/batch = 0.029, All_Time = 11515.560
390150/758000 (epoch 1029), train_loss = 0.239, time/batch = 0.028, All_Time = 11517.038
390200/758000 (epoch 1029), train_loss = 0.267, time/batch = 0.029, All_Time = 11518.504
390250/758000 (epoch 1029), train_loss = 0.256, time/batch = 0.029, All_Time = 11519.966
390300/758000 (epoch 1029), train_loss = 0.236, time/batch = 0.030, All_Time = 11521.431
390350/758000 (epoch 1029), train_loss = 0.268, time/batch = 0.030, All_Time = 11522.936
390400/758000 (epoch 1030), train_loss = 0.226, time/batch = 0.028, All_Time = 11524.431
390450/758000 (epoch 1030), train_loss = 0.222, time/batch = 0.030, All_Time = 11525.895
390500/758000 (epoch 1030), train_loss = 0.261, time/batch = 0.031, All_Time = 11527.363
390550/758000 (epoch 1030), train_loss = 0.254, time/batch = 0.029, All_Time = 11528.830
390600/758000 (epoch 1030), train_loss = 0.223, time/batch = 0.028, All_Time = 11530.302
390650/758000 (epoch 1030), train_loss = 0.242, time/batch = 0.030, All_Time = 11531.767
390700/758000 (epoch 1030), train_loss = 0.251, time/batch = 0.031, All_Time = 11533.248
390750/758000 (epoch 1031), train_loss = 0.192, time/batch = 0.030, All_Time = 11534.755
390800/758000 (epoch 1031), train_loss = 0.273, time/batch = 0.029, All_Time = 11536.235
390850/758000 (epoch 1031), train_loss = 0.217, time/batch = 0.030, All_Time = 11537.706
390900/758000 (epoch 1031), train_loss = 0.240, time/batch = 0.029, All_Time = 11539.174
390950/758000 (epoch 1031), train_loss = 0.221, time/batch = 0.031, All_Time = 11540.687
391000/758000 (epoch 1031), train_loss = 0.221, time/batch = 0.030, All_Time = 11542.190
model saved to NER/polyglot/model.ckpt
391050/758000 (epoch 1031), train_loss = 0.252, time/batch = 0.028, All_Time = 11543.668
391100/758000 (epoch 1031), train_loss = 0.272, time/batch = 0.029, All_Time = 11545.140
391150/758000 (epoch 1032), train_loss = 0.222, time/batch = 0.029, All_Time = 11546.634
391200/758000 (epoch 1032), train_loss = 0.279, time/batch = 0.029, All_Time = 11548.094
391250/758000 (epoch 1032), train_loss = 0.242, time/batch = 0.029, All_Time = 11549.599
391300/758000 (epoch 1032), train_loss = 0.274, time/batch = 0.029, All_Time = 11551.106
391350/758000 (epoch 1032), train_loss = 0.262, time/batch = 0.030, All_Time = 11552.592
391400/758000 (epoch 1032), train_loss = 0.197, time/batch = 0.029, All_Time = 11554.076
391450/758000 (epoch 1032), train_loss = 0.233, time/batch = 0.030, All_Time = 11555.560
391500/758000 (epoch 1032), train_loss = 0.281, time/batch = 0.030, All_Time = 11557.039
391550/758000 (epoch 1033), train_loss = 0.246, time/batch = 0.030, All_Time = 11558.525
391600/758000 (epoch 1033), train_loss = 0.212, time/batch = 0.032, All_Time = 11560.000
391650/758000 (epoch 1033), train_loss = 0.255, time/batch = 0.029, All_Time = 11561.506
391700/758000 (epoch 1033), train_loss = 0.271, time/batch = 0.031, All_Time = 11562.990
391750/758000 (epoch 1033), train_loss = 0.203, time/batch = 0.031, All_Time = 11564.477
391800/758000 (epoch 1033), train_loss = 0.226, time/batch = 0.030, All_Time = 11565.960
391850/758000 (epoch 1033), train_loss = 0.254, time/batch = 0.030, All_Time = 11567.427
391900/758000 (epoch 1034), train_loss = 0.219, time/batch = 0.030, All_Time = 11568.909
391950/758000 (epoch 1034), train_loss = 0.265, time/batch = 0.028, All_Time = 11570.380
392000/758000 (epoch 1034), train_loss = 0.227, time/batch = 0.030, All_Time = 11571.834
model saved to NER/polyglot/model.ckpt
392050/758000 (epoch 1034), train_loss = 0.213, time/batch = 0.029, All_Time = 11573.300
392100/758000 (epoch 1034), train_loss = 0.224, time/batch = 0.029, All_Time = 11574.756
392150/758000 (epoch 1034), train_loss = 0.213, time/batch = 0.033, All_Time = 11576.437
392200/758000 (epoch 1034), train_loss = 0.230, time/batch = 0.032, All_Time = 11577.933
392250/758000 (epoch 1034), train_loss = 0.223, time/batch = 0.029, All_Time = 11579.431
392300/758000 (epoch 1035), train_loss = 0.275, time/batch = 0.029, All_Time = 11580.918
392350/758000 (epoch 1035), train_loss = 0.229, time/batch = 0.029, All_Time = 11582.394
392400/758000 (epoch 1035), train_loss = 0.270, time/batch = 0.029, All_Time = 11583.859
392450/758000 (epoch 1035), train_loss = 0.273, time/batch = 0.030, All_Time = 11585.334
392500/758000 (epoch 1035), train_loss = 0.233, time/batch = 0.028, All_Time = 11586.799
392550/758000 (epoch 1035), train_loss = 0.268, time/batch = 0.030, All_Time = 11588.266
392600/758000 (epoch 1035), train_loss = 0.280, time/batch = 0.028, All_Time = 11589.733
392650/758000 (epoch 1036), train_loss = 0.239, time/batch = 0.028, All_Time = 11591.207
392700/758000 (epoch 1036), train_loss = 0.218, time/batch = 0.030, All_Time = 11592.681
392750/758000 (epoch 1036), train_loss = 0.243, time/batch = 0.031, All_Time = 11594.152
392800/758000 (epoch 1036), train_loss = 0.244, time/batch = 0.031, All_Time = 11595.619
392850/758000 (epoch 1036), train_loss = 0.243, time/batch = 0.030, All_Time = 11597.130
392900/758000 (epoch 1036), train_loss = 0.244, time/batch = 0.031, All_Time = 11598.615
392950/758000 (epoch 1036), train_loss = 0.213, time/batch = 0.030, All_Time = 11600.101
393000/758000 (epoch 1036), train_loss = 0.289, time/batch = 0.030, All_Time = 11601.587
model saved to NER/polyglot/model.ckpt
393050/758000 (epoch 1037), train_loss = 0.237, time/batch = 0.029, All_Time = 11603.076
393100/758000 (epoch 1037), train_loss = 0.246, time/batch = 0.030, All_Time = 11604.542
393150/758000 (epoch 1037), train_loss = 0.288, time/batch = 0.030, All_Time = 11606.000
393200/758000 (epoch 1037), train_loss = 0.257, time/batch = 0.029, All_Time = 11607.503
393250/758000 (epoch 1037), train_loss = 0.218, time/batch = 0.029, All_Time = 11608.990
393300/758000 (epoch 1037), train_loss = 0.238, time/batch = 0.029, All_Time = 11610.463
393350/758000 (epoch 1037), train_loss = 0.251, time/batch = 0.029, All_Time = 11611.949
393400/758000 (epoch 1037), train_loss = 0.251, time/batch = 0.030, All_Time = 11613.430
393450/758000 (epoch 1038), train_loss = 0.252, time/batch = 0.030, All_Time = 11614.911
393500/758000 (epoch 1038), train_loss = 0.280, time/batch = 0.030, All_Time = 11616.373
393550/758000 (epoch 1038), train_loss = 0.242, time/batch = 0.029, All_Time = 11617.842
393600/758000 (epoch 1038), train_loss = 0.250, time/batch = 0.029, All_Time = 11619.306
393650/758000 (epoch 1038), train_loss = 0.239, time/batch = 0.029, All_Time = 11620.798
393700/758000 (epoch 1038), train_loss = 0.239, time/batch = 0.028, All_Time = 11622.295
393750/758000 (epoch 1038), train_loss = 0.250, time/batch = 0.029, All_Time = 11623.775
393800/758000 (epoch 1039), train_loss = 0.221, time/batch = 0.028, All_Time = 11625.256
393850/758000 (epoch 1039), train_loss = 0.219, time/batch = 0.029, All_Time = 11626.725
393900/758000 (epoch 1039), train_loss = 0.246, time/batch = 0.027, All_Time = 11628.186
393950/758000 (epoch 1039), train_loss = 0.262, time/batch = 0.030, All_Time = 11629.651
394000/758000 (epoch 1039), train_loss = 0.260, time/batch = 0.029, All_Time = 11631.111
model saved to NER/polyglot/model.ckpt
394050/758000 (epoch 1039), train_loss = 0.241, time/batch = 0.029, All_Time = 11632.570
394100/758000 (epoch 1039), train_loss = 0.210, time/batch = 0.032, All_Time = 11634.028
394150/758000 (epoch 1039), train_loss = 0.239, time/batch = 0.028, All_Time = 11635.505
394200/758000 (epoch 1040), train_loss = 0.230, time/batch = 0.030, All_Time = 11636.987
394250/758000 (epoch 1040), train_loss = 0.226, time/batch = 0.030, All_Time = 11638.455
394300/758000 (epoch 1040), train_loss = 0.264, time/batch = 0.030, All_Time = 11639.933
394350/758000 (epoch 1040), train_loss = 0.240, time/batch = 0.029, All_Time = 11641.417
394400/758000 (epoch 1040), train_loss = 0.253, time/batch = 0.030, All_Time = 11642.904
394450/758000 (epoch 1040), train_loss = 0.251, time/batch = 0.029, All_Time = 11644.388
394500/758000 (epoch 1040), train_loss = 0.248, time/batch = 0.031, All_Time = 11645.881
394550/758000 (epoch 1041), train_loss = 0.216, time/batch = 0.028, All_Time = 11647.378
394600/758000 (epoch 1041), train_loss = 0.233, time/batch = 0.028, All_Time = 11648.846
394650/758000 (epoch 1041), train_loss = 0.250, time/batch = 0.029, All_Time = 11650.310
394700/758000 (epoch 1041), train_loss = 0.241, time/batch = 0.030, All_Time = 11651.777
394750/758000 (epoch 1041), train_loss = 0.243, time/batch = 0.029, All_Time = 11653.242
394800/758000 (epoch 1041), train_loss = 0.242, time/batch = 0.030, All_Time = 11654.715
394850/758000 (epoch 1041), train_loss = 0.230, time/batch = 0.029, All_Time = 11656.196
394900/758000 (epoch 1041), train_loss = 0.259, time/batch = 0.030, All_Time = 11657.675
394950/758000 (epoch 1042), train_loss = 0.250, time/batch = 0.032, All_Time = 11659.173
395000/758000 (epoch 1042), train_loss = 0.253, time/batch = 0.029, All_Time = 11660.645
model saved to NER/polyglot/model.ckpt
395050/758000 (epoch 1042), train_loss = 0.245, time/batch = 0.031, All_Time = 11662.113
395100/758000 (epoch 1042), train_loss = 0.231, time/batch = 0.030, All_Time = 11663.577
395150/758000 (epoch 1042), train_loss = 0.228, time/batch = 0.029, All_Time = 11665.043
395200/758000 (epoch 1042), train_loss = 0.238, time/batch = 0.031, All_Time = 11666.516
395250/758000 (epoch 1042), train_loss = 0.268, time/batch = 0.030, All_Time = 11668.036
395300/758000 (epoch 1043), train_loss = 0.248, time/batch = 0.030, All_Time = 11669.535
395350/758000 (epoch 1043), train_loss = 0.280, time/batch = 0.029, All_Time = 11671.004
395400/758000 (epoch 1043), train_loss = 0.242, time/batch = 0.031, All_Time = 11672.493
395450/758000 (epoch 1043), train_loss = 0.258, time/batch = 0.030, All_Time = 11673.976
395500/758000 (epoch 1043), train_loss = 0.224, time/batch = 0.030, All_Time = 11675.452
395550/758000 (epoch 1043), train_loss = 0.243, time/batch = 0.030, All_Time = 11676.968
395600/758000 (epoch 1043), train_loss = 0.219, time/batch = 0.030, All_Time = 11678.461
395650/758000 (epoch 1043), train_loss = 0.232, time/batch = 0.030, All_Time = 11679.943
395700/758000 (epoch 1044), train_loss = 0.237, time/batch = 0.031, All_Time = 11681.434
395750/758000 (epoch 1044), train_loss = 0.239, time/batch = 0.030, All_Time = 11682.898
395800/758000 (epoch 1044), train_loss = 0.293, time/batch = 0.029, All_Time = 11684.369
395850/758000 (epoch 1044), train_loss = 0.318, time/batch = 0.029, All_Time = 11685.839
395900/758000 (epoch 1044), train_loss = 0.196, time/batch = 0.030, All_Time = 11687.310
395950/758000 (epoch 1044), train_loss = 0.213, time/batch = 0.033, All_Time = 11688.784
396000/758000 (epoch 1044), train_loss = 0.250, time/batch = 0.029, All_Time = 11690.293
model saved to NER/polyglot/model.ckpt
396050/758000 (epoch 1044), train_loss = 0.297, time/batch = 0.029, All_Time = 11691.775
396100/758000 (epoch 1045), train_loss = 0.226, time/batch = 0.029, All_Time = 11693.252
396150/758000 (epoch 1045), train_loss = 0.259, time/batch = 0.030, All_Time = 11694.710
396200/758000 (epoch 1045), train_loss = 0.223, time/batch = 0.030, All_Time = 11696.171
396250/758000 (epoch 1045), train_loss = 0.239, time/batch = 0.031, All_Time = 11697.636
396300/758000 (epoch 1045), train_loss = 0.212, time/batch = 0.029, All_Time = 11699.115
396350/758000 (epoch 1045), train_loss = 0.243, time/batch = 0.029, All_Time = 11700.579
396400/758000 (epoch 1045), train_loss = 0.215, time/batch = 0.030, All_Time = 11702.047
396450/758000 (epoch 1046), train_loss = 0.228, time/batch = 0.030, All_Time = 11703.530
396500/758000 (epoch 1046), train_loss = 0.252, time/batch = 0.029, All_Time = 11704.996
396550/758000 (epoch 1046), train_loss = 0.260, time/batch = 0.030, All_Time = 11706.470
396600/758000 (epoch 1046), train_loss = 0.228, time/batch = 0.029, All_Time = 11707.937
396650/758000 (epoch 1046), train_loss = 0.236, time/batch = 0.030, All_Time = 11709.418
396700/758000 (epoch 1046), train_loss = 0.271, time/batch = 0.031, All_Time = 11710.926
396750/758000 (epoch 1046), train_loss = 0.238, time/batch = 0.029, All_Time = 11712.419
396800/758000 (epoch 1046), train_loss = 0.268, time/batch = 0.029, All_Time = 11713.909
396850/758000 (epoch 1047), train_loss = 0.248, time/batch = 0.029, All_Time = 11715.385
396900/758000 (epoch 1047), train_loss = 0.249, time/batch = 0.029, All_Time = 11716.850
396950/758000 (epoch 1047), train_loss = 0.240, time/batch = 0.030, All_Time = 11718.315
397000/758000 (epoch 1047), train_loss = 0.247, time/batch = 0.032, All_Time = 11719.824
model saved to NER/polyglot/model.ckpt
397050/758000 (epoch 1047), train_loss = 0.235, time/batch = 0.029, All_Time = 11721.315
397100/758000 (epoch 1047), train_loss = 0.247, time/batch = 0.030, All_Time = 11722.794
397150/758000 (epoch 1047), train_loss = 0.251, time/batch = 0.028, All_Time = 11724.278
397200/758000 (epoch 1048), train_loss = 0.242, time/batch = 0.030, All_Time = 11725.774
397250/758000 (epoch 1048), train_loss = 0.276, time/batch = 0.031, All_Time = 11727.239
397300/758000 (epoch 1048), train_loss = 0.256, time/batch = 0.029, All_Time = 11728.743
397350/758000 (epoch 1048), train_loss = 0.258, time/batch = 0.029, All_Time = 11730.223
397400/758000 (epoch 1048), train_loss = 0.213, time/batch = 0.030, All_Time = 11731.695
397450/758000 (epoch 1048), train_loss = 0.237, time/batch = 0.030, All_Time = 11733.165
397500/758000 (epoch 1048), train_loss = 0.249, time/batch = 0.029, All_Time = 11734.643
397550/758000 (epoch 1048), train_loss = 0.251, time/batch = 0.029, All_Time = 11736.108
397600/758000 (epoch 1049), train_loss = 0.232, time/batch = 0.029, All_Time = 11737.584
397650/758000 (epoch 1049), train_loss = 0.255, time/batch = 0.029, All_Time = 11739.049
397700/758000 (epoch 1049), train_loss = 0.265, time/batch = 0.031, All_Time = 11740.535
397750/758000 (epoch 1049), train_loss = 0.229, time/batch = 0.031, All_Time = 11742.026
397800/758000 (epoch 1049), train_loss = 0.263, time/batch = 0.030, All_Time = 11743.500
397850/758000 (epoch 1049), train_loss = 0.217, time/batch = 0.029, All_Time = 11744.983
397900/758000 (epoch 1049), train_loss = 0.248, time/batch = 0.029, All_Time = 11746.461
397950/758000 (epoch 1050), train_loss = 0.059, time/batch = 0.041, All_Time = 11747.953
398000/758000 (epoch 1050), train_loss = 0.250, time/batch = 0.030, All_Time = 11749.428
model saved to NER/polyglot/model.ckpt
398050/758000 (epoch 1050), train_loss = 0.223, time/batch = 0.030, All_Time = 11750.907
398100/758000 (epoch 1050), train_loss = 0.250, time/batch = 0.036, All_Time = 11752.641
398150/758000 (epoch 1050), train_loss = 0.231, time/batch = 0.030, All_Time = 11754.143
398200/758000 (epoch 1050), train_loss = 0.250, time/batch = 0.030, All_Time = 11755.641
398250/758000 (epoch 1050), train_loss = 0.232, time/batch = 0.030, All_Time = 11757.137
398300/758000 (epoch 1050), train_loss = 0.230, time/batch = 0.031, All_Time = 11758.645
398350/758000 (epoch 1051), train_loss = 0.224, time/batch = 0.029, All_Time = 11760.138
398400/758000 (epoch 1051), train_loss = 0.233, time/batch = 0.028, All_Time = 11761.606
398450/758000 (epoch 1051), train_loss = 0.224, time/batch = 0.029, All_Time = 11763.088
398500/758000 (epoch 1051), train_loss = 0.262, time/batch = 0.030, All_Time = 11764.572
398550/758000 (epoch 1051), train_loss = 0.220, time/batch = 0.030, All_Time = 11766.044
398600/758000 (epoch 1051), train_loss = 0.228, time/batch = 0.031, All_Time = 11767.536
398650/758000 (epoch 1051), train_loss = 0.280, time/batch = 0.029, All_Time = 11769.009
398700/758000 (epoch 1051), train_loss = 0.272, time/batch = 0.029, All_Time = 11770.494
398750/758000 (epoch 1052), train_loss = 0.230, time/batch = 0.030, All_Time = 11771.972
398800/758000 (epoch 1052), train_loss = 0.224, time/batch = 0.029, All_Time = 11773.430
398850/758000 (epoch 1052), train_loss = 0.201, time/batch = 0.029, All_Time = 11774.911
398900/758000 (epoch 1052), train_loss = 0.270, time/batch = 0.030, All_Time = 11776.386
398950/758000 (epoch 1052), train_loss = 0.259, time/batch = 0.030, All_Time = 11777.865
399000/758000 (epoch 1052), train_loss = 0.209, time/batch = 0.030, All_Time = 11779.344
model saved to NER/polyglot/model.ckpt
399050/758000 (epoch 1052), train_loss = 0.218, time/batch = 0.031, All_Time = 11780.829
399100/758000 (epoch 1053), train_loss = 0.229, time/batch = 0.030, All_Time = 11782.336
399150/758000 (epoch 1053), train_loss = 0.283, time/batch = 0.031, All_Time = 11783.821
399200/758000 (epoch 1053), train_loss = 0.231, time/batch = 0.029, All_Time = 11785.305
399250/758000 (epoch 1053), train_loss = 0.307, time/batch = 0.030, All_Time = 11786.788
399300/758000 (epoch 1053), train_loss = 0.221, time/batch = 0.030, All_Time = 11788.272
399350/758000 (epoch 1053), train_loss = 0.208, time/batch = 0.030, All_Time = 11789.750
399400/758000 (epoch 1053), train_loss = 0.247, time/batch = 0.029, All_Time = 11791.238
399450/758000 (epoch 1053), train_loss = 0.252, time/batch = 0.029, All_Time = 11792.709
399500/758000 (epoch 1054), train_loss = 0.264, time/batch = 0.029, All_Time = 11794.205
399550/758000 (epoch 1054), train_loss = 0.229, time/batch = 0.032, All_Time = 11795.707
399600/758000 (epoch 1054), train_loss = 0.242, time/batch = 0.029, All_Time = 11797.197
399650/758000 (epoch 1054), train_loss = 0.267, time/batch = 0.031, All_Time = 11798.680
399700/758000 (epoch 1054), train_loss = 0.249, time/batch = 0.030, All_Time = 11800.153
399750/758000 (epoch 1054), train_loss = 0.237, time/batch = 0.029, All_Time = 11801.627
399800/758000 (epoch 1054), train_loss = 0.276, time/batch = 0.030, All_Time = 11803.112
399850/758000 (epoch 1055), train_loss = 0.256, time/batch = 0.029, All_Time = 11804.593
399900/758000 (epoch 1055), train_loss = 0.222, time/batch = 0.030, All_Time = 11806.075
399950/758000 (epoch 1055), train_loss = 0.266, time/batch = 0.030, All_Time = 11807.540
400000/758000 (epoch 1055), train_loss = 0.216, time/batch = 0.030, All_Time = 11809.019
model saved to NER/polyglot/model.ckpt
400050/758000 (epoch 1055), train_loss = 0.223, time/batch = 0.029, All_Time = 11810.489
400100/758000 (epoch 1055), train_loss = 0.261, time/batch = 0.029, All_Time = 11811.953
400150/758000 (epoch 1055), train_loss = 0.238, time/batch = 0.030, All_Time = 11813.414
400200/758000 (epoch 1055), train_loss = 0.264, time/batch = 0.031, All_Time = 11814.891
400250/758000 (epoch 1056), train_loss = 0.223, time/batch = 0.030, All_Time = 11816.414
400300/758000 (epoch 1056), train_loss = 0.231, time/batch = 0.029, All_Time = 11817.890
400350/758000 (epoch 1056), train_loss = 0.238, time/batch = 0.030, All_Time = 11819.374
400400/758000 (epoch 1056), train_loss = 0.266, time/batch = 0.030, All_Time = 11820.866
400450/758000 (epoch 1056), train_loss = 0.239, time/batch = 0.030, All_Time = 11822.347
400500/758000 (epoch 1056), train_loss = 0.226, time/batch = 0.029, All_Time = 11823.835
400550/758000 (epoch 1056), train_loss = 0.276, time/batch = 0.029, All_Time = 11825.305
400600/758000 (epoch 1056), train_loss = 0.240, time/batch = 0.030, All_Time = 11826.791
400650/758000 (epoch 1057), train_loss = 0.281, time/batch = 0.027, All_Time = 11828.271
400700/758000 (epoch 1057), train_loss = 0.257, time/batch = 0.030, All_Time = 11829.748
400750/758000 (epoch 1057), train_loss = 0.240, time/batch = 0.028, All_Time = 11831.221
400800/758000 (epoch 1057), train_loss = 0.231, time/batch = 0.028, All_Time = 11832.678
400850/758000 (epoch 1057), train_loss = 0.217, time/batch = 0.029, All_Time = 11834.140
400900/758000 (epoch 1057), train_loss = 0.224, time/batch = 0.030, All_Time = 11835.603
400950/758000 (epoch 1057), train_loss = 0.215, time/batch = 0.029, All_Time = 11837.080
401000/758000 (epoch 1058), train_loss = 0.249, time/batch = 0.029, All_Time = 11838.568
model saved to NER/polyglot/model.ckpt
401050/758000 (epoch 1058), train_loss = 0.211, time/batch = 0.029, All_Time = 11840.036
401100/758000 (epoch 1058), train_loss = 0.245, time/batch = 0.030, All_Time = 11841.489
401150/758000 (epoch 1058), train_loss = 0.217, time/batch = 0.030, All_Time = 11842.968
401200/758000 (epoch 1058), train_loss = 0.233, time/batch = 0.031, All_Time = 11844.473
401250/758000 (epoch 1058), train_loss = 0.228, time/batch = 0.029, All_Time = 11845.956
401300/758000 (epoch 1058), train_loss = 0.248, time/batch = 0.031, All_Time = 11847.434
401350/758000 (epoch 1058), train_loss = 0.229, time/batch = 0.031, All_Time = 11848.916
401400/758000 (epoch 1059), train_loss = 0.218, time/batch = 0.028, All_Time = 11850.388
401450/758000 (epoch 1059), train_loss = 0.237, time/batch = 0.031, All_Time = 11851.847
401500/758000 (epoch 1059), train_loss = 0.212, time/batch = 0.029, All_Time = 11853.319
401550/758000 (epoch 1059), train_loss = 0.266, time/batch = 0.029, All_Time = 11854.808
401600/758000 (epoch 1059), train_loss = 0.255, time/batch = 0.030, All_Time = 11856.307
401650/758000 (epoch 1059), train_loss = 0.232, time/batch = 0.030, All_Time = 11857.784
401700/758000 (epoch 1059), train_loss = 0.262, time/batch = 0.029, All_Time = 11859.266
401750/758000 (epoch 1060), train_loss = 0.282, time/batch = 0.031, All_Time = 11860.772
401800/758000 (epoch 1060), train_loss = 0.292, time/batch = 0.030, All_Time = 11862.254
401850/758000 (epoch 1060), train_loss = 0.253, time/batch = 0.029, All_Time = 11863.731
401900/758000 (epoch 1060), train_loss = 0.222, time/batch = 0.031, All_Time = 11865.201
401950/758000 (epoch 1060), train_loss = 0.221, time/batch = 0.029, All_Time = 11866.680
402000/758000 (epoch 1060), train_loss = 0.260, time/batch = 0.029, All_Time = 11868.142
model saved to NER/polyglot/model.ckpt
402050/758000 (epoch 1060), train_loss = 0.244, time/batch = 0.029, All_Time = 11869.612
402100/758000 (epoch 1060), train_loss = 0.247, time/batch = 0.030, All_Time = 11871.083
402150/758000 (epoch 1061), train_loss = 0.210, time/batch = 0.030, All_Time = 11872.605
402200/758000 (epoch 1061), train_loss = 0.265, time/batch = 0.029, All_Time = 11874.093
402250/758000 (epoch 1061), train_loss = 0.229, time/batch = 0.029, All_Time = 11875.575
402300/758000 (epoch 1061), train_loss = 0.232, time/batch = 0.029, All_Time = 11877.054
402350/758000 (epoch 1061), train_loss = 0.230, time/batch = 0.029, All_Time = 11878.542
402400/758000 (epoch 1061), train_loss = 0.253, time/batch = 0.029, All_Time = 11880.024
402450/758000 (epoch 1061), train_loss = 0.258, time/batch = 0.030, All_Time = 11881.510
402500/758000 (epoch 1062), train_loss = 0.196, time/batch = 0.030, All_Time = 11882.997
402550/758000 (epoch 1062), train_loss = 0.254, time/batch = 0.029, All_Time = 11884.468
402600/758000 (epoch 1062), train_loss = 0.281, time/batch = 0.028, All_Time = 11885.945
402650/758000 (epoch 1062), train_loss = 0.235, time/batch = 0.029, All_Time = 11887.424
402700/758000 (epoch 1062), train_loss = 0.247, time/batch = 0.030, All_Time = 11888.910
402750/758000 (epoch 1062), train_loss = 0.251, time/batch = 0.029, All_Time = 11890.381
402800/758000 (epoch 1062), train_loss = 0.203, time/batch = 0.030, All_Time = 11891.858
402850/758000 (epoch 1062), train_loss = 0.268, time/batch = 0.030, All_Time = 11893.339
402900/758000 (epoch 1063), train_loss = 0.233, time/batch = 0.029, All_Time = 11894.827
402950/758000 (epoch 1063), train_loss = 0.241, time/batch = 0.032, All_Time = 11896.289
403000/758000 (epoch 1063), train_loss = 0.252, time/batch = 0.029, All_Time = 11897.762
model saved to NER/polyglot/model.ckpt
403050/758000 (epoch 1063), train_loss = 0.258, time/batch = 0.031, All_Time = 11899.238
403100/758000 (epoch 1063), train_loss = 0.243, time/batch = 0.028, All_Time = 11900.706
403150/758000 (epoch 1063), train_loss = 0.243, time/batch = 0.029, All_Time = 11902.214
403200/758000 (epoch 1063), train_loss = 0.244, time/batch = 0.030, All_Time = 11903.708
403250/758000 (epoch 1063), train_loss = 0.286, time/batch = 0.030, All_Time = 11905.198
403300/758000 (epoch 1064), train_loss = 0.207, time/batch = 0.028, All_Time = 11906.679
403350/758000 (epoch 1064), train_loss = 0.244, time/batch = 0.032, All_Time = 11908.141
403400/758000 (epoch 1064), train_loss = 0.217, time/batch = 0.028, All_Time = 11909.611
403450/758000 (epoch 1064), train_loss = 0.233, time/batch = 0.028, All_Time = 11911.088
403500/758000 (epoch 1064), train_loss = 0.260, time/batch = 0.029, All_Time = 11912.574
403550/758000 (epoch 1064), train_loss = 0.253, time/batch = 0.029, All_Time = 11914.072
403600/758000 (epoch 1064), train_loss = 0.238, time/batch = 0.030, All_Time = 11915.557
403650/758000 (epoch 1065), train_loss = 0.227, time/batch = 0.030, All_Time = 11917.026
403700/758000 (epoch 1065), train_loss = 0.250, time/batch = 0.028, All_Time = 11918.498
403750/758000 (epoch 1065), train_loss = 0.250, time/batch = 0.029, All_Time = 11919.960
403800/758000 (epoch 1065), train_loss = 0.223, time/batch = 0.029, All_Time = 11921.416
403850/758000 (epoch 1065), train_loss = 0.240, time/batch = 0.030, All_Time = 11922.890
403900/758000 (epoch 1065), train_loss = 0.246, time/batch = 0.029, All_Time = 11924.371
403950/758000 (epoch 1065), train_loss = 0.246, time/batch = 0.034, All_Time = 11925.853
404000/758000 (epoch 1065), train_loss = 0.257, time/batch = 0.030, All_Time = 11927.337
model saved to NER/polyglot/model.ckpt
404050/758000 (epoch 1066), train_loss = 0.266, time/batch = 0.029, All_Time = 11928.818
404100/758000 (epoch 1066), train_loss = 0.224, time/batch = 0.028, All_Time = 11930.281
404150/758000 (epoch 1066), train_loss = 0.248, time/batch = 0.028, All_Time = 11931.744
404200/758000 (epoch 1066), train_loss = 0.227, time/batch = 0.030, All_Time = 11933.215
404250/758000 (epoch 1066), train_loss = 0.279, time/batch = 0.030, All_Time = 11934.692
404300/758000 (epoch 1066), train_loss = 0.255, time/batch = 0.029, All_Time = 11936.162
404350/758000 (epoch 1066), train_loss = 0.253, time/batch = 0.029, All_Time = 11937.630
404400/758000 (epoch 1067), train_loss = 0.244, time/batch = 0.031, All_Time = 11939.111
404450/758000 (epoch 1067), train_loss = 0.247, time/batch = 0.030, All_Time = 11940.594
404500/758000 (epoch 1067), train_loss = 0.270, time/batch = 0.030, All_Time = 11942.055
404550/758000 (epoch 1067), train_loss = 0.246, time/batch = 0.030, All_Time = 11943.528
404600/758000 (epoch 1067), train_loss = 0.237, time/batch = 0.030, All_Time = 11945.018
404650/758000 (epoch 1067), train_loss = 0.224, time/batch = 0.030, All_Time = 11946.512
404700/758000 (epoch 1067), train_loss = 0.229, time/batch = 0.030, All_Time = 11947.995
404750/758000 (epoch 1067), train_loss = 0.246, time/batch = 0.030, All_Time = 11949.474
404800/758000 (epoch 1068), train_loss = 0.249, time/batch = 0.030, All_Time = 11950.971
404850/758000 (epoch 1068), train_loss = 0.264, time/batch = 0.030, All_Time = 11952.433
404900/758000 (epoch 1068), train_loss = 0.240, time/batch = 0.030, All_Time = 11953.904
404950/758000 (epoch 1068), train_loss = 0.250, time/batch = 0.031, All_Time = 11955.378
405000/758000 (epoch 1068), train_loss = 0.227, time/batch = 0.029, All_Time = 11956.855
model saved to NER/polyglot/model.ckpt
405050/758000 (epoch 1068), train_loss = 0.217, time/batch = 0.029, All_Time = 11958.329
405100/758000 (epoch 1068), train_loss = 0.277, time/batch = 0.030, All_Time = 11959.808
405150/758000 (epoch 1068), train_loss = 0.259, time/batch = 0.031, All_Time = 11961.323
405200/758000 (epoch 1069), train_loss = 0.269, time/batch = 0.029, All_Time = 11962.812
405250/758000 (epoch 1069), train_loss = 0.296, time/batch = 0.029, All_Time = 11964.288
405300/758000 (epoch 1069), train_loss = 0.228, time/batch = 0.031, All_Time = 11965.776
405350/758000 (epoch 1069), train_loss = 0.220, time/batch = 0.028, All_Time = 11967.242
405400/758000 (epoch 1069), train_loss = 0.257, time/batch = 0.031, All_Time = 11968.718
405450/758000 (epoch 1069), train_loss = 0.255, time/batch = 0.029, All_Time = 11970.188
405500/758000 (epoch 1069), train_loss = 0.237, time/batch = 0.030, All_Time = 11971.670
405550/758000 (epoch 1070), train_loss = 0.225, time/batch = 0.030, All_Time = 11973.158
405600/758000 (epoch 1070), train_loss = 0.234, time/batch = 0.029, All_Time = 11974.635
405650/758000 (epoch 1070), train_loss = 0.243, time/batch = 0.030, All_Time = 11976.100
405700/758000 (epoch 1070), train_loss = 0.234, time/batch = 0.032, All_Time = 11977.601
405750/758000 (epoch 1070), train_loss = 0.223, time/batch = 0.033, All_Time = 11979.119
405800/758000 (epoch 1070), train_loss = 0.239, time/batch = 0.030, All_Time = 11980.599
405850/758000 (epoch 1070), train_loss = 0.264, time/batch = 0.029, All_Time = 11982.084
405900/758000 (epoch 1070), train_loss = 0.244, time/batch = 0.035, All_Time = 11983.632
405950/758000 (epoch 1071), train_loss = 0.257, time/batch = 0.029, All_Time = 11985.153
406000/758000 (epoch 1071), train_loss = 0.287, time/batch = 0.029, All_Time = 11986.628
model saved to NER/polyglot/model.ckpt
406050/758000 (epoch 1071), train_loss = 0.255, time/batch = 0.029, All_Time = 11988.106
406100/758000 (epoch 1071), train_loss = 0.248, time/batch = 0.030, All_Time = 11989.572
406150/758000 (epoch 1071), train_loss = 0.212, time/batch = 0.030, All_Time = 11991.056
406200/758000 (epoch 1071), train_loss = 0.229, time/batch = 0.030, All_Time = 11992.555
406250/758000 (epoch 1071), train_loss = 0.272, time/batch = 0.029, All_Time = 11994.040
406300/758000 (epoch 1072), train_loss = 0.249, time/batch = 0.030, All_Time = 11995.531
406350/758000 (epoch 1072), train_loss = 0.227, time/batch = 0.030, All_Time = 11997.009
406400/758000 (epoch 1072), train_loss = 0.267, time/batch = 0.030, All_Time = 11998.483
406450/758000 (epoch 1072), train_loss = 0.239, time/batch = 0.030, All_Time = 11999.949
406500/758000 (epoch 1072), train_loss = 0.247, time/batch = 0.029, All_Time = 12001.420
406550/758000 (epoch 1072), train_loss = 0.241, time/batch = 0.030, All_Time = 12002.883
406600/758000 (epoch 1072), train_loss = 0.274, time/batch = 0.030, All_Time = 12004.381
406650/758000 (epoch 1072), train_loss = 0.279, time/batch = 0.030, All_Time = 12005.877
406700/758000 (epoch 1073), train_loss = 0.238, time/batch = 0.029, All_Time = 12007.375
406750/758000 (epoch 1073), train_loss = 0.248, time/batch = 0.029, All_Time = 12008.847
406800/758000 (epoch 1073), train_loss = 0.299, time/batch = 0.029, All_Time = 12010.328
406850/758000 (epoch 1073), train_loss = 0.230, time/batch = 0.028, All_Time = 12011.799
406900/758000 (epoch 1073), train_loss = 0.216, time/batch = 0.028, All_Time = 12013.275
406950/758000 (epoch 1073), train_loss = 0.244, time/batch = 0.030, All_Time = 12014.750
407000/758000 (epoch 1073), train_loss = 0.274, time/batch = 0.029, All_Time = 12016.232
model saved to NER/polyglot/model.ckpt
407050/758000 (epoch 1074), train_loss = 0.221, time/batch = 0.028, All_Time = 12017.731
407100/758000 (epoch 1074), train_loss = 0.257, time/batch = 0.029, All_Time = 12019.214
407150/758000 (epoch 1074), train_loss = 0.241, time/batch = 0.028, All_Time = 12020.672
407200/758000 (epoch 1074), train_loss = 0.240, time/batch = 0.029, All_Time = 12022.139
407250/758000 (epoch 1074), train_loss = 0.256, time/batch = 0.030, All_Time = 12023.614
407300/758000 (epoch 1074), train_loss = 0.219, time/batch = 0.030, All_Time = 12025.085
407350/758000 (epoch 1074), train_loss = 0.224, time/batch = 0.029, All_Time = 12026.562
407400/758000 (epoch 1074), train_loss = 0.257, time/batch = 0.030, All_Time = 12028.033
407450/758000 (epoch 1075), train_loss = 0.255, time/batch = 0.030, All_Time = 12029.518
407500/758000 (epoch 1075), train_loss = 0.267, time/batch = 0.029, All_Time = 12030.988
407550/758000 (epoch 1075), train_loss = 0.269, time/batch = 0.028, All_Time = 12032.459
407600/758000 (epoch 1075), train_loss = 0.228, time/batch = 0.030, All_Time = 12033.929
407650/758000 (epoch 1075), train_loss = 0.234, time/batch = 0.030, All_Time = 12035.404
407700/758000 (epoch 1075), train_loss = 0.245, time/batch = 0.030, All_Time = 12036.884
407750/758000 (epoch 1075), train_loss = 0.279, time/batch = 0.029, All_Time = 12038.353
407800/758000 (epoch 1075), train_loss = 0.240, time/batch = 0.029, All_Time = 12039.828
407850/758000 (epoch 1076), train_loss = 0.236, time/batch = 0.029, All_Time = 12041.317
407900/758000 (epoch 1076), train_loss = 0.234, time/batch = 0.030, All_Time = 12042.789
407950/758000 (epoch 1076), train_loss = 0.233, time/batch = 0.030, All_Time = 12044.282
408000/758000 (epoch 1076), train_loss = 0.276, time/batch = 0.031, All_Time = 12045.789
model saved to NER/polyglot/model.ckpt
408050/758000 (epoch 1076), train_loss = 0.206, time/batch = 0.028, All_Time = 12047.267
408100/758000 (epoch 1076), train_loss = 0.259, time/batch = 0.029, All_Time = 12048.749
408150/758000 (epoch 1076), train_loss = 0.234, time/batch = 0.030, All_Time = 12050.224
408200/758000 (epoch 1077), train_loss = 0.245, time/batch = 0.030, All_Time = 12051.708
408250/758000 (epoch 1077), train_loss = 0.223, time/batch = 0.028, All_Time = 12053.169
408300/758000 (epoch 1077), train_loss = 0.240, time/batch = 0.029, All_Time = 12054.646
408350/758000 (epoch 1077), train_loss = 0.256, time/batch = 0.030, All_Time = 12056.125
408400/758000 (epoch 1077), train_loss = 0.214, time/batch = 0.030, All_Time = 12057.595
408450/758000 (epoch 1077), train_loss = 0.272, time/batch = 0.029, All_Time = 12059.067
408500/758000 (epoch 1077), train_loss = 0.213, time/batch = 0.030, All_Time = 12060.570
408550/758000 (epoch 1077), train_loss = 0.251, time/batch = 0.031, All_Time = 12062.077
408600/758000 (epoch 1078), train_loss = 0.247, time/batch = 0.029, All_Time = 12063.564
408650/758000 (epoch 1078), train_loss = 0.229, time/batch = 0.029, All_Time = 12065.032
408700/758000 (epoch 1078), train_loss = 0.217, time/batch = 0.030, All_Time = 12066.494
408750/758000 (epoch 1078), train_loss = 0.220, time/batch = 0.030, All_Time = 12067.961
408800/758000 (epoch 1078), train_loss = 0.250, time/batch = 0.030, All_Time = 12069.432
408850/758000 (epoch 1078), train_loss = 0.207, time/batch = 0.029, All_Time = 12070.933
408900/758000 (epoch 1078), train_loss = 0.268, time/batch = 0.030, All_Time = 12072.443
408950/758000 (epoch 1079), train_loss = 0.256, time/batch = 0.029, All_Time = 12073.956
409000/758000 (epoch 1079), train_loss = 0.264, time/batch = 0.029, All_Time = 12075.418
model saved to NER/polyglot/model.ckpt
409050/758000 (epoch 1079), train_loss = 0.284, time/batch = 0.028, All_Time = 12076.885
409100/758000 (epoch 1079), train_loss = 0.239, time/batch = 0.029, All_Time = 12078.357
409150/758000 (epoch 1079), train_loss = 0.267, time/batch = 0.029, All_Time = 12079.823
409200/758000 (epoch 1079), train_loss = 0.256, time/batch = 0.030, All_Time = 12081.294
409250/758000 (epoch 1079), train_loss = 0.236, time/batch = 0.029, All_Time = 12082.757
409300/758000 (epoch 1079), train_loss = 0.268, time/batch = 0.030, All_Time = 12084.234
409350/758000 (epoch 1080), train_loss = 0.226, time/batch = 0.030, All_Time = 12085.750
409400/758000 (epoch 1080), train_loss = 0.222, time/batch = 0.028, All_Time = 12087.225
409450/758000 (epoch 1080), train_loss = 0.261, time/batch = 0.029, All_Time = 12088.704
409500/758000 (epoch 1080), train_loss = 0.254, time/batch = 0.031, All_Time = 12090.188
409550/758000 (epoch 1080), train_loss = 0.223, time/batch = 0.029, All_Time = 12091.667
409600/758000 (epoch 1080), train_loss = 0.242, time/batch = 0.030, All_Time = 12093.144
409650/758000 (epoch 1080), train_loss = 0.251, time/batch = 0.029, All_Time = 12094.613
409700/758000 (epoch 1081), train_loss = 0.192, time/batch = 0.030, All_Time = 12096.104
409750/758000 (epoch 1081), train_loss = 0.273, time/batch = 0.029, All_Time = 12097.571
409800/758000 (epoch 1081), train_loss = 0.217, time/batch = 0.030, All_Time = 12099.036
409850/758000 (epoch 1081), train_loss = 0.240, time/batch = 0.029, All_Time = 12100.499
409900/758000 (epoch 1081), train_loss = 0.221, time/batch = 0.032, All_Time = 12102.005
409950/758000 (epoch 1081), train_loss = 0.221, time/batch = 0.029, All_Time = 12103.488
410000/758000 (epoch 1081), train_loss = 0.252, time/batch = 0.029, All_Time = 12104.963
model saved to NER/polyglot/model.ckpt
410050/758000 (epoch 1081), train_loss = 0.272, time/batch = 0.030, All_Time = 12106.431
410100/758000 (epoch 1082), train_loss = 0.222, time/batch = 0.028, All_Time = 12107.912
410150/758000 (epoch 1082), train_loss = 0.279, time/batch = 0.029, All_Time = 12109.372
410200/758000 (epoch 1082), train_loss = 0.242, time/batch = 0.029, All_Time = 12110.830
410250/758000 (epoch 1082), train_loss = 0.274, time/batch = 0.030, All_Time = 12112.298
410300/758000 (epoch 1082), train_loss = 0.262, time/batch = 0.029, All_Time = 12113.794
410350/758000 (epoch 1082), train_loss = 0.197, time/batch = 0.031, All_Time = 12115.291
410400/758000 (epoch 1082), train_loss = 0.233, time/batch = 0.029, All_Time = 12116.775
410450/758000 (epoch 1082), train_loss = 0.281, time/batch = 0.030, All_Time = 12118.261
410500/758000 (epoch 1083), train_loss = 0.246, time/batch = 0.029, All_Time = 12119.741
410550/758000 (epoch 1083), train_loss = 0.212, time/batch = 0.030, All_Time = 12121.213
410600/758000 (epoch 1083), train_loss = 0.255, time/batch = 0.030, All_Time = 12122.680
410650/758000 (epoch 1083), train_loss = 0.271, time/batch = 0.029, All_Time = 12124.152
410700/758000 (epoch 1083), train_loss = 0.203, time/batch = 0.028, All_Time = 12125.619
410750/758000 (epoch 1083), train_loss = 0.226, time/batch = 0.031, All_Time = 12127.097
410800/758000 (epoch 1083), train_loss = 0.254, time/batch = 0.031, All_Time = 12128.609
410850/758000 (epoch 1084), train_loss = 0.219, time/batch = 0.029, All_Time = 12130.112
410900/758000 (epoch 1084), train_loss = 0.265, time/batch = 0.028, All_Time = 12131.573
410950/758000 (epoch 1084), train_loss = 0.227, time/batch = 0.030, All_Time = 12133.039
411000/758000 (epoch 1084), train_loss = 0.213, time/batch = 0.029, All_Time = 12134.507
model saved to NER/polyglot/model.ckpt
411050/758000 (epoch 1084), train_loss = 0.224, time/batch = 0.029, All_Time = 12135.982
411100/758000 (epoch 1084), train_loss = 0.213, time/batch = 0.030, All_Time = 12137.445
411150/758000 (epoch 1084), train_loss = 0.230, time/batch = 0.029, All_Time = 12138.909
411200/758000 (epoch 1084), train_loss = 0.223, time/batch = 0.030, All_Time = 12140.387
411250/758000 (epoch 1085), train_loss = 0.275, time/batch = 0.028, All_Time = 12141.891
411300/758000 (epoch 1085), train_loss = 0.229, time/batch = 0.031, All_Time = 12143.371
411350/758000 (epoch 1085), train_loss = 0.270, time/batch = 0.029, All_Time = 12144.838
411400/758000 (epoch 1085), train_loss = 0.273, time/batch = 0.030, All_Time = 12146.314
411450/758000 (epoch 1085), train_loss = 0.233, time/batch = 0.029, All_Time = 12147.780
411500/758000 (epoch 1085), train_loss = 0.268, time/batch = 0.028, All_Time = 12149.249
411550/758000 (epoch 1085), train_loss = 0.280, time/batch = 0.029, All_Time = 12150.721
411600/758000 (epoch 1086), train_loss = 0.239, time/batch = 0.030, All_Time = 12152.226
411650/758000 (epoch 1086), train_loss = 0.218, time/batch = 0.029, All_Time = 12153.706
411700/758000 (epoch 1086), train_loss = 0.243, time/batch = 0.029, All_Time = 12155.192
411750/758000 (epoch 1086), train_loss = 0.244, time/batch = 0.031, All_Time = 12156.687
411800/758000 (epoch 1086), train_loss = 0.243, time/batch = 0.029, All_Time = 12158.176
411850/758000 (epoch 1086), train_loss = 0.244, time/batch = 0.029, All_Time = 12159.667
411900/758000 (epoch 1086), train_loss = 0.213, time/batch = 0.030, All_Time = 12161.156
411950/758000 (epoch 1086), train_loss = 0.289, time/batch = 0.029, All_Time = 12162.634
412000/758000 (epoch 1087), train_loss = 0.237, time/batch = 0.030, All_Time = 12164.116
model saved to NER/polyglot/model.ckpt
412050/758000 (epoch 1087), train_loss = 0.246, time/batch = 0.028, All_Time = 12165.590
412100/758000 (epoch 1087), train_loss = 0.288, time/batch = 0.029, All_Time = 12167.054
412150/758000 (epoch 1087), train_loss = 0.257, time/batch = 0.029, All_Time = 12168.520
412200/758000 (epoch 1087), train_loss = 0.218, time/batch = 0.029, All_Time = 12170.001
412250/758000 (epoch 1087), train_loss = 0.238, time/batch = 0.030, All_Time = 12171.494
412300/758000 (epoch 1087), train_loss = 0.251, time/batch = 0.030, All_Time = 12172.975
412350/758000 (epoch 1087), train_loss = 0.251, time/batch = 0.029, All_Time = 12174.446
412400/758000 (epoch 1088), train_loss = 0.252, time/batch = 0.029, All_Time = 12175.910
412450/758000 (epoch 1088), train_loss = 0.280, time/batch = 0.030, All_Time = 12177.380
412500/758000 (epoch 1088), train_loss = 0.242, time/batch = 0.030, All_Time = 12178.853
412550/758000 (epoch 1088), train_loss = 0.250, time/batch = 0.029, All_Time = 12180.333
412600/758000 (epoch 1088), train_loss = 0.239, time/batch = 0.029, All_Time = 12181.803
412650/758000 (epoch 1088), train_loss = 0.239, time/batch = 0.029, All_Time = 12183.273
412700/758000 (epoch 1088), train_loss = 0.250, time/batch = 0.030, All_Time = 12184.743
412750/758000 (epoch 1089), train_loss = 0.221, time/batch = 0.030, All_Time = 12186.208
412800/758000 (epoch 1089), train_loss = 0.219, time/batch = 0.030, All_Time = 12187.672
412850/758000 (epoch 1089), train_loss = 0.246, time/batch = 0.030, All_Time = 12189.160
412900/758000 (epoch 1089), train_loss = 0.262, time/batch = 0.029, All_Time = 12190.673
412950/758000 (epoch 1089), train_loss = 0.260, time/batch = 0.030, All_Time = 12192.177
413000/758000 (epoch 1089), train_loss = 0.241, time/batch = 0.028, All_Time = 12193.659
model saved to NER/polyglot/model.ckpt
413050/758000 (epoch 1089), train_loss = 0.210, time/batch = 0.029, All_Time = 12195.123
413100/758000 (epoch 1089), train_loss = 0.239, time/batch = 0.030, All_Time = 12196.588
413150/758000 (epoch 1090), train_loss = 0.230, time/batch = 0.029, All_Time = 12198.054
413200/758000 (epoch 1090), train_loss = 0.226, time/batch = 0.028, All_Time = 12199.511
413250/758000 (epoch 1090), train_loss = 0.264, time/batch = 0.028, All_Time = 12200.983
413300/758000 (epoch 1090), train_loss = 0.240, time/batch = 0.030, All_Time = 12202.447
413350/758000 (epoch 1090), train_loss = 0.253, time/batch = 0.029, All_Time = 12203.926
413400/758000 (epoch 1090), train_loss = 0.251, time/batch = 0.029, All_Time = 12205.399
413450/758000 (epoch 1090), train_loss = 0.248, time/batch = 0.029, All_Time = 12206.883
413500/758000 (epoch 1091), train_loss = 0.216, time/batch = 0.031, All_Time = 12208.358
413550/758000 (epoch 1091), train_loss = 0.233, time/batch = 0.029, All_Time = 12209.818
413600/758000 (epoch 1091), train_loss = 0.250, time/batch = 0.032, All_Time = 12211.294
413650/758000 (epoch 1091), train_loss = 0.241, time/batch = 0.033, All_Time = 12212.799
413700/758000 (epoch 1091), train_loss = 0.243, time/batch = 0.028, All_Time = 12214.275
413750/758000 (epoch 1091), train_loss = 0.242, time/batch = 0.030, All_Time = 12215.743
413800/758000 (epoch 1091), train_loss = 0.230, time/batch = 0.029, All_Time = 12217.227
413850/758000 (epoch 1091), train_loss = 0.259, time/batch = 0.029, All_Time = 12218.701
413900/758000 (epoch 1092), train_loss = 0.250, time/batch = 0.029, All_Time = 12220.176
413950/758000 (epoch 1092), train_loss = 0.253, time/batch = 0.030, All_Time = 12221.651
414000/758000 (epoch 1092), train_loss = 0.245, time/batch = 0.029, All_Time = 12223.122
model saved to NER/polyglot/model.ckpt
414050/758000 (epoch 1092), train_loss = 0.231, time/batch = 0.029, All_Time = 12224.612
414100/758000 (epoch 1092), train_loss = 0.228, time/batch = 0.031, All_Time = 12226.082
414150/758000 (epoch 1092), train_loss = 0.238, time/batch = 0.032, All_Time = 12227.595
414200/758000 (epoch 1092), train_loss = 0.268, time/batch = 0.030, All_Time = 12229.104
414250/758000 (epoch 1093), train_loss = 0.248, time/batch = 0.031, All_Time = 12230.602
414300/758000 (epoch 1093), train_loss = 0.280, time/batch = 0.029, All_Time = 12232.080
414350/758000 (epoch 1093), train_loss = 0.242, time/batch = 0.029, All_Time = 12233.555
414400/758000 (epoch 1093), train_loss = 0.258, time/batch = 0.029, All_Time = 12235.012
414450/758000 (epoch 1093), train_loss = 0.224, time/batch = 0.029, All_Time = 12236.470
414500/758000 (epoch 1093), train_loss = 0.243, time/batch = 0.031, All_Time = 12237.966
414550/758000 (epoch 1093), train_loss = 0.219, time/batch = 0.032, All_Time = 12239.459
414600/758000 (epoch 1093), train_loss = 0.232, time/batch = 0.030, All_Time = 12240.937
414650/758000 (epoch 1094), train_loss = 0.237, time/batch = 0.031, All_Time = 12242.416
414700/758000 (epoch 1094), train_loss = 0.239, time/batch = 0.030, All_Time = 12243.874
414750/758000 (epoch 1094), train_loss = 0.293, time/batch = 0.030, All_Time = 12245.372
414800/758000 (epoch 1094), train_loss = 0.318, time/batch = 0.029, All_Time = 12246.852
414850/758000 (epoch 1094), train_loss = 0.196, time/batch = 0.030, All_Time = 12248.330
414900/758000 (epoch 1094), train_loss = 0.213, time/batch = 0.032, All_Time = 12249.802
414950/758000 (epoch 1094), train_loss = 0.250, time/batch = 0.030, All_Time = 12251.276
415000/758000 (epoch 1094), train_loss = 0.297, time/batch = 0.030, All_Time = 12252.747
model saved to NER/polyglot/model.ckpt
415050/758000 (epoch 1095), train_loss = 0.226, time/batch = 0.029, All_Time = 12254.226
415100/758000 (epoch 1095), train_loss = 0.259, time/batch = 0.029, All_Time = 12255.687
415150/758000 (epoch 1095), train_loss = 0.223, time/batch = 0.030, All_Time = 12257.164
415200/758000 (epoch 1095), train_loss = 0.239, time/batch = 0.030, All_Time = 12258.645
415250/758000 (epoch 1095), train_loss = 0.212, time/batch = 0.030, All_Time = 12260.143
415300/758000 (epoch 1095), train_loss = 0.243, time/batch = 0.029, All_Time = 12261.624
415350/758000 (epoch 1095), train_loss = 0.215, time/batch = 0.029, All_Time = 12263.109
415400/758000 (epoch 1096), train_loss = 0.228, time/batch = 0.031, All_Time = 12264.594
415450/758000 (epoch 1096), train_loss = 0.252, time/batch = 0.029, All_Time = 12266.064
415500/758000 (epoch 1096), train_loss = 0.260, time/batch = 0.029, All_Time = 12267.540
415550/758000 (epoch 1096), train_loss = 0.228, time/batch = 0.029, All_Time = 12269.010
415600/758000 (epoch 1096), train_loss = 0.236, time/batch = 0.028, All_Time = 12270.479
415650/758000 (epoch 1096), train_loss = 0.271, time/batch = 0.029, All_Time = 12271.963
415700/758000 (epoch 1096), train_loss = 0.238, time/batch = 0.028, All_Time = 12273.436
415750/758000 (epoch 1096), train_loss = 0.268, time/batch = 0.030, All_Time = 12274.904
415800/758000 (epoch 1097), train_loss = 0.248, time/batch = 0.029, All_Time = 12276.389
415850/758000 (epoch 1097), train_loss = 0.249, time/batch = 0.030, All_Time = 12277.856
415900/758000 (epoch 1097), train_loss = 0.240, time/batch = 0.032, All_Time = 12279.352
415950/758000 (epoch 1097), train_loss = 0.247, time/batch = 0.030, All_Time = 12280.836
416000/758000 (epoch 1097), train_loss = 0.235, time/batch = 0.029, All_Time = 12282.330
model saved to NER/polyglot/model.ckpt
416050/758000 (epoch 1097), train_loss = 0.247, time/batch = 0.030, All_Time = 12283.813
416100/758000 (epoch 1097), train_loss = 0.251, time/batch = 0.029, All_Time = 12285.278
416150/758000 (epoch 1098), train_loss = 0.242, time/batch = 0.030, All_Time = 12286.750
416200/758000 (epoch 1098), train_loss = 0.276, time/batch = 0.029, All_Time = 12288.211
416250/758000 (epoch 1098), train_loss = 0.256, time/batch = 0.030, All_Time = 12289.678
416300/758000 (epoch 1098), train_loss = 0.258, time/batch = 0.028, All_Time = 12291.185
416350/758000 (epoch 1098), train_loss = 0.213, time/batch = 0.030, All_Time = 12292.676
416400/758000 (epoch 1098), train_loss = 0.237, time/batch = 0.029, All_Time = 12294.165
416450/758000 (epoch 1098), train_loss = 0.249, time/batch = 0.028, All_Time = 12295.641
416500/758000 (epoch 1098), train_loss = 0.251, time/batch = 0.030, All_Time = 12297.105
416550/758000 (epoch 1099), train_loss = 0.232, time/batch = 0.030, All_Time = 12298.588
416600/758000 (epoch 1099), train_loss = 0.255, time/batch = 0.030, All_Time = 12300.053
416650/758000 (epoch 1099), train_loss = 0.265, time/batch = 0.029, All_Time = 12301.513
416700/758000 (epoch 1099), train_loss = 0.229, time/batch = 0.030, All_Time = 12303.007
416750/758000 (epoch 1099), train_loss = 0.263, time/batch = 0.030, All_Time = 12304.499
416800/758000 (epoch 1099), train_loss = 0.217, time/batch = 0.030, All_Time = 12305.976
416850/758000 (epoch 1099), train_loss = 0.248, time/batch = 0.029, All_Time = 12307.449
416900/758000 (epoch 1100), train_loss = 0.059, time/batch = 0.042, All_Time = 12308.938
416950/758000 (epoch 1100), train_loss = 0.250, time/batch = 0.029, All_Time = 12310.404
417000/758000 (epoch 1100), train_loss = 0.223, time/batch = 0.029, All_Time = 12311.867
model saved to NER/polyglot/model.ckpt
417050/758000 (epoch 1100), train_loss = 0.250, time/batch = 0.029, All_Time = 12313.336
417100/758000 (epoch 1100), train_loss = 0.231, time/batch = 0.030, All_Time = 12314.805
417150/758000 (epoch 1100), train_loss = 0.250, time/batch = 0.030, All_Time = 12316.304
417200/758000 (epoch 1100), train_loss = 0.232, time/batch = 0.030, All_Time = 12317.788
417250/758000 (epoch 1100), train_loss = 0.230, time/batch = 0.030, All_Time = 12319.275
417300/758000 (epoch 1101), train_loss = 0.224, time/batch = 0.029, All_Time = 12320.759
417350/758000 (epoch 1101), train_loss = 0.233, time/batch = 0.029, All_Time = 12322.223
417400/758000 (epoch 1101), train_loss = 0.224, time/batch = 0.030, All_Time = 12323.691
417450/758000 (epoch 1101), train_loss = 0.262, time/batch = 0.029, All_Time = 12325.156
417500/758000 (epoch 1101), train_loss = 0.220, time/batch = 0.029, All_Time = 12326.623
417550/758000 (epoch 1101), train_loss = 0.228, time/batch = 0.029, All_Time = 12328.108
417600/758000 (epoch 1101), train_loss = 0.280, time/batch = 0.028, All_Time = 12329.588
417650/758000 (epoch 1101), train_loss = 0.272, time/batch = 0.030, All_Time = 12331.069
417700/758000 (epoch 1102), train_loss = 0.230, time/batch = 0.029, All_Time = 12332.555
417750/758000 (epoch 1102), train_loss = 0.224, time/batch = 0.030, All_Time = 12334.028
417800/758000 (epoch 1102), train_loss = 0.201, time/batch = 0.031, All_Time = 12335.532
417850/758000 (epoch 1102), train_loss = 0.270, time/batch = 0.030, All_Time = 12337.012
417900/758000 (epoch 1102), train_loss = 0.259, time/batch = 0.030, All_Time = 12338.499
417950/758000 (epoch 1102), train_loss = 0.209, time/batch = 0.030, All_Time = 12339.996
418000/758000 (epoch 1102), train_loss = 0.218, time/batch = 0.029, All_Time = 12341.470
model saved to NER/polyglot/model.ckpt
418050/758000 (epoch 1103), train_loss = 0.229, time/batch = 0.030, All_Time = 12342.963
418100/758000 (epoch 1103), train_loss = 0.283, time/batch = 0.029, All_Time = 12344.424
418150/758000 (epoch 1103), train_loss = 0.231, time/batch = 0.030, All_Time = 12345.881
418200/758000 (epoch 1103), train_loss = 0.307, time/batch = 0.029, All_Time = 12347.347
418250/758000 (epoch 1103), train_loss = 0.221, time/batch = 0.029, All_Time = 12348.812
418300/758000 (epoch 1103), train_loss = 0.208, time/batch = 0.029, All_Time = 12350.281
418350/758000 (epoch 1103), train_loss = 0.247, time/batch = 0.029, All_Time = 12351.746
418400/758000 (epoch 1103), train_loss = 0.252, time/batch = 0.030, All_Time = 12353.280
418450/758000 (epoch 1104), train_loss = 0.264, time/batch = 0.029, All_Time = 12354.768
418500/758000 (epoch 1104), train_loss = 0.229, time/batch = 0.029, All_Time = 12356.246
418550/758000 (epoch 1104), train_loss = 0.242, time/batch = 0.030, All_Time = 12357.714
418600/758000 (epoch 1104), train_loss = 0.267, time/batch = 0.030, All_Time = 12359.199
418650/758000 (epoch 1104), train_loss = 0.249, time/batch = 0.029, All_Time = 12360.683
418700/758000 (epoch 1104), train_loss = 0.237, time/batch = 0.029, All_Time = 12362.162
418750/758000 (epoch 1104), train_loss = 0.276, time/batch = 0.029, All_Time = 12363.649
418800/758000 (epoch 1105), train_loss = 0.256, time/batch = 0.030, All_Time = 12365.138
418850/758000 (epoch 1105), train_loss = 0.222, time/batch = 0.030, All_Time = 12366.619
418900/758000 (epoch 1105), train_loss = 0.266, time/batch = 0.029, All_Time = 12368.088
418950/758000 (epoch 1105), train_loss = 0.216, time/batch = 0.030, All_Time = 12369.563
419000/758000 (epoch 1105), train_loss = 0.223, time/batch = 0.029, All_Time = 12371.035
model saved to NER/polyglot/model.ckpt
419050/758000 (epoch 1105), train_loss = 0.261, time/batch = 0.029, All_Time = 12372.512
419100/758000 (epoch 1105), train_loss = 0.238, time/batch = 0.029, All_Time = 12373.974
419150/758000 (epoch 1105), train_loss = 0.264, time/batch = 0.029, All_Time = 12375.479
419200/758000 (epoch 1106), train_loss = 0.223, time/batch = 0.029, All_Time = 12376.975
419250/758000 (epoch 1106), train_loss = 0.231, time/batch = 0.032, All_Time = 12378.449
419300/758000 (epoch 1106), train_loss = 0.238, time/batch = 0.029, All_Time = 12379.917
419350/758000 (epoch 1106), train_loss = 0.266, time/batch = 0.032, All_Time = 12381.439
419400/758000 (epoch 1106), train_loss = 0.239, time/batch = 0.030, All_Time = 12382.932
419450/758000 (epoch 1106), train_loss = 0.226, time/batch = 0.031, All_Time = 12384.419
419500/758000 (epoch 1106), train_loss = 0.276, time/batch = 0.031, All_Time = 12385.906
419550/758000 (epoch 1106), train_loss = 0.240, time/batch = 0.030, All_Time = 12387.392
419600/758000 (epoch 1107), train_loss = 0.281, time/batch = 0.029, All_Time = 12388.869
419650/758000 (epoch 1107), train_loss = 0.257, time/batch = 0.027, All_Time = 12390.346
419700/758000 (epoch 1107), train_loss = 0.240, time/batch = 0.028, All_Time = 12391.818
419750/758000 (epoch 1107), train_loss = 0.231, time/batch = 0.028, All_Time = 12393.289
419800/758000 (epoch 1107), train_loss = 0.217, time/batch = 0.029, All_Time = 12394.757
419850/758000 (epoch 1107), train_loss = 0.224, time/batch = 0.031, All_Time = 12396.234
419900/758000 (epoch 1107), train_loss = 0.215, time/batch = 0.030, All_Time = 12397.740
419950/758000 (epoch 1108), train_loss = 0.249, time/batch = 0.029, All_Time = 12399.229
420000/758000 (epoch 1108), train_loss = 0.211, time/batch = 0.031, All_Time = 12400.698
model saved to NER/polyglot/model.ckpt
420050/758000 (epoch 1108), train_loss = 0.245, time/batch = 0.029, All_Time = 12402.173
420100/758000 (epoch 1108), train_loss = 0.217, time/batch = 0.029, All_Time = 12403.642
420150/758000 (epoch 1108), train_loss = 0.233, time/batch = 0.031, All_Time = 12405.126
420200/758000 (epoch 1108), train_loss = 0.228, time/batch = 0.030, All_Time = 12406.614
420250/758000 (epoch 1108), train_loss = 0.248, time/batch = 0.029, All_Time = 12408.096
420300/758000 (epoch 1108), train_loss = 0.229, time/batch = 0.028, All_Time = 12409.585
420350/758000 (epoch 1109), train_loss = 0.218, time/batch = 0.028, All_Time = 12411.064
420400/758000 (epoch 1109), train_loss = 0.237, time/batch = 0.029, All_Time = 12412.530
420450/758000 (epoch 1109), train_loss = 0.212, time/batch = 0.028, All_Time = 12413.994
420500/758000 (epoch 1109), train_loss = 0.266, time/batch = 0.029, All_Time = 12415.483
420550/758000 (epoch 1109), train_loss = 0.255, time/batch = 0.029, All_Time = 12416.984
420600/758000 (epoch 1109), train_loss = 0.232, time/batch = 0.029, All_Time = 12418.460
420650/758000 (epoch 1109), train_loss = 0.262, time/batch = 0.031, All_Time = 12419.932
420700/758000 (epoch 1110), train_loss = 0.282, time/batch = 0.030, All_Time = 12421.413
420750/758000 (epoch 1110), train_loss = 0.292, time/batch = 0.029, All_Time = 12422.882
420800/758000 (epoch 1110), train_loss = 0.253, time/batch = 0.029, All_Time = 12424.353
420850/758000 (epoch 1110), train_loss = 0.222, time/batch = 0.028, All_Time = 12425.809
420900/758000 (epoch 1110), train_loss = 0.221, time/batch = 0.028, All_Time = 12427.281
420950/758000 (epoch 1110), train_loss = 0.260, time/batch = 0.029, All_Time = 12428.740
421000/758000 (epoch 1110), train_loss = 0.244, time/batch = 0.029, All_Time = 12430.207
model saved to NER/polyglot/model.ckpt
421050/758000 (epoch 1110), train_loss = 0.247, time/batch = 0.029, All_Time = 12431.680
421100/758000 (epoch 1111), train_loss = 0.210, time/batch = 0.029, All_Time = 12433.158
421150/758000 (epoch 1111), train_loss = 0.265, time/batch = 0.029, All_Time = 12434.622
421200/758000 (epoch 1111), train_loss = 0.229, time/batch = 0.030, All_Time = 12436.111
421250/758000 (epoch 1111), train_loss = 0.232, time/batch = 0.029, All_Time = 12437.605
421300/758000 (epoch 1111), train_loss = 0.230, time/batch = 0.030, All_Time = 12439.098
421350/758000 (epoch 1111), train_loss = 0.253, time/batch = 0.029, All_Time = 12440.580
421400/758000 (epoch 1111), train_loss = 0.258, time/batch = 0.029, All_Time = 12442.062
421450/758000 (epoch 1112), train_loss = 0.196, time/batch = 0.030, All_Time = 12443.566
421500/758000 (epoch 1112), train_loss = 0.254, time/batch = 0.029, All_Time = 12445.036
421550/758000 (epoch 1112), train_loss = 0.281, time/batch = 0.029, All_Time = 12446.507
421600/758000 (epoch 1112), train_loss = 0.235, time/batch = 0.030, All_Time = 12447.977
421650/758000 (epoch 1112), train_loss = 0.247, time/batch = 0.028, All_Time = 12449.447
421700/758000 (epoch 1112), train_loss = 0.251, time/batch = 0.030, All_Time = 12450.920
421750/758000 (epoch 1112), train_loss = 0.203, time/batch = 0.032, All_Time = 12452.429
421800/758000 (epoch 1112), train_loss = 0.268, time/batch = 0.031, All_Time = 12453.905
421850/758000 (epoch 1113), train_loss = 0.233, time/batch = 0.030, All_Time = 12455.395
421900/758000 (epoch 1113), train_loss = 0.241, time/batch = 0.029, All_Time = 12456.870
421950/758000 (epoch 1113), train_loss = 0.252, time/batch = 0.028, All_Time = 12458.344
422000/758000 (epoch 1113), train_loss = 0.258, time/batch = 0.029, All_Time = 12459.807
model saved to NER/polyglot/model.ckpt
422050/758000 (epoch 1113), train_loss = 0.243, time/batch = 0.030, All_Time = 12461.279
422100/758000 (epoch 1113), train_loss = 0.243, time/batch = 0.029, All_Time = 12462.747
422150/758000 (epoch 1113), train_loss = 0.244, time/batch = 0.032, All_Time = 12464.214
422200/758000 (epoch 1113), train_loss = 0.286, time/batch = 0.029, All_Time = 12465.710
422250/758000 (epoch 1114), train_loss = 0.207, time/batch = 0.028, All_Time = 12467.211
422300/758000 (epoch 1114), train_loss = 0.244, time/batch = 0.029, All_Time = 12468.676
422350/758000 (epoch 1114), train_loss = 0.217, time/batch = 0.031, All_Time = 12470.156
422400/758000 (epoch 1114), train_loss = 0.233, time/batch = 0.029, All_Time = 12471.628
422450/758000 (epoch 1114), train_loss = 0.260, time/batch = 0.029, All_Time = 12473.098
422500/758000 (epoch 1114), train_loss = 0.253, time/batch = 0.028, All_Time = 12474.567
422550/758000 (epoch 1114), train_loss = 0.238, time/batch = 0.029, All_Time = 12476.034
422600/758000 (epoch 1115), train_loss = 0.227, time/batch = 0.029, All_Time = 12477.522
422650/758000 (epoch 1115), train_loss = 0.250, time/batch = 0.029, All_Time = 12478.982
422700/758000 (epoch 1115), train_loss = 0.250, time/batch = 0.029, All_Time = 12480.450
422750/758000 (epoch 1115), train_loss = 0.223, time/batch = 0.030, All_Time = 12481.910
422800/758000 (epoch 1115), train_loss = 0.240, time/batch = 0.029, All_Time = 12483.394
422850/758000 (epoch 1115), train_loss = 0.246, time/batch = 0.033, All_Time = 12484.907
422900/758000 (epoch 1115), train_loss = 0.246, time/batch = 0.029, All_Time = 12486.388
422950/758000 (epoch 1115), train_loss = 0.257, time/batch = 0.028, All_Time = 12487.865
423000/758000 (epoch 1116), train_loss = 0.266, time/batch = 0.027, All_Time = 12489.348
model saved to NER/polyglot/model.ckpt
423050/758000 (epoch 1116), train_loss = 0.224, time/batch = 0.028, All_Time = 12490.827
423100/758000 (epoch 1116), train_loss = 0.248, time/batch = 0.030, All_Time = 12492.293
423150/758000 (epoch 1116), train_loss = 0.227, time/batch = 0.030, All_Time = 12493.753
423200/758000 (epoch 1116), train_loss = 0.279, time/batch = 0.029, All_Time = 12495.221
423250/758000 (epoch 1116), train_loss = 0.255, time/batch = 0.029, All_Time = 12496.720
423300/758000 (epoch 1116), train_loss = 0.253, time/batch = 0.029, All_Time = 12498.216
423350/758000 (epoch 1117), train_loss = 0.244, time/batch = 0.030, All_Time = 12499.713
423400/758000 (epoch 1117), train_loss = 0.247, time/batch = 0.029, All_Time = 12501.189
423450/758000 (epoch 1117), train_loss = 0.270, time/batch = 0.029, All_Time = 12502.659
423500/758000 (epoch 1117), train_loss = 0.246, time/batch = 0.029, All_Time = 12504.117
423550/758000 (epoch 1117), train_loss = 0.237, time/batch = 0.031, All_Time = 12505.585
423600/758000 (epoch 1117), train_loss = 0.224, time/batch = 0.028, All_Time = 12507.049
423650/758000 (epoch 1117), train_loss = 0.229, time/batch = 0.028, All_Time = 12508.514
423700/758000 (epoch 1117), train_loss = 0.246, time/batch = 0.028, All_Time = 12509.977
423750/758000 (epoch 1118), train_loss = 0.249, time/batch = 0.030, All_Time = 12511.461
423800/758000 (epoch 1118), train_loss = 0.264, time/batch = 0.030, All_Time = 12512.932
423850/758000 (epoch 1118), train_loss = 0.240, time/batch = 0.029, All_Time = 12514.405
423900/758000 (epoch 1118), train_loss = 0.250, time/batch = 0.030, All_Time = 12515.898
423950/758000 (epoch 1118), train_loss = 0.227, time/batch = 0.032, All_Time = 12517.399
424000/758000 (epoch 1118), train_loss = 0.217, time/batch = 0.029, All_Time = 12518.886
model saved to NER/polyglot/model.ckpt
424050/758000 (epoch 1118), train_loss = 0.277, time/batch = 0.029, All_Time = 12520.373
424100/758000 (epoch 1118), train_loss = 0.259, time/batch = 0.029, All_Time = 12521.842
424150/758000 (epoch 1119), train_loss = 0.269, time/batch = 0.029, All_Time = 12523.332
424200/758000 (epoch 1119), train_loss = 0.296, time/batch = 0.029, All_Time = 12524.794
424250/758000 (epoch 1119), train_loss = 0.228, time/batch = 0.030, All_Time = 12526.266
424300/758000 (epoch 1119), train_loss = 0.220, time/batch = 0.030, All_Time = 12527.736
424350/758000 (epoch 1119), train_loss = 0.257, time/batch = 0.030, All_Time = 12529.227
424400/758000 (epoch 1119), train_loss = 0.255, time/batch = 0.029, All_Time = 12530.728
424450/758000 (epoch 1119), train_loss = 0.237, time/batch = 0.029, All_Time = 12532.217
424500/758000 (epoch 1120), train_loss = 0.225, time/batch = 0.030, All_Time = 12533.706
424550/758000 (epoch 1120), train_loss = 0.234, time/batch = 0.028, All_Time = 12535.174
424600/758000 (epoch 1120), train_loss = 0.243, time/batch = 0.029, All_Time = 12536.640
424650/758000 (epoch 1120), train_loss = 0.234, time/batch = 0.030, All_Time = 12538.109
424700/758000 (epoch 1120), train_loss = 0.223, time/batch = 0.030, All_Time = 12539.584
424750/758000 (epoch 1120), train_loss = 0.239, time/batch = 0.029, All_Time = 12541.080
424800/758000 (epoch 1120), train_loss = 0.264, time/batch = 0.031, All_Time = 12542.575
424850/758000 (epoch 1120), train_loss = 0.244, time/batch = 0.031, All_Time = 12544.082
424900/758000 (epoch 1121), train_loss = 0.257, time/batch = 0.029, All_Time = 12545.563
424950/758000 (epoch 1121), train_loss = 0.287, time/batch = 0.029, All_Time = 12547.020
425000/758000 (epoch 1121), train_loss = 0.255, time/batch = 0.030, All_Time = 12548.493
model saved to NER/polyglot/model.ckpt
425050/758000 (epoch 1121), train_loss = 0.248, time/batch = 0.030, All_Time = 12549.955
425100/758000 (epoch 1121), train_loss = 0.212, time/batch = 0.031, All_Time = 12551.415
425150/758000 (epoch 1121), train_loss = 0.229, time/batch = 0.028, All_Time = 12552.882
425200/758000 (epoch 1121), train_loss = 0.272, time/batch = 0.031, All_Time = 12554.343
425250/758000 (epoch 1122), train_loss = 0.249, time/batch = 0.030, All_Time = 12555.830
425300/758000 (epoch 1122), train_loss = 0.227, time/batch = 0.029, All_Time = 12557.312
425350/758000 (epoch 1122), train_loss = 0.267, time/batch = 0.028, All_Time = 12558.789
425400/758000 (epoch 1122), train_loss = 0.239, time/batch = 0.030, All_Time = 12560.281
425450/758000 (epoch 1122), train_loss = 0.247, time/batch = 0.028, All_Time = 12561.766
425500/758000 (epoch 1122), train_loss = 0.241, time/batch = 0.031, All_Time = 12563.245
425550/758000 (epoch 1122), train_loss = 0.274, time/batch = 0.031, All_Time = 12564.719
425600/758000 (epoch 1122), train_loss = 0.279, time/batch = 0.031, All_Time = 12566.202
425650/758000 (epoch 1123), train_loss = 0.238, time/batch = 0.029, All_Time = 12567.701
425700/758000 (epoch 1123), train_loss = 0.248, time/batch = 0.028, All_Time = 12569.164
425750/758000 (epoch 1123), train_loss = 0.299, time/batch = 0.030, All_Time = 12570.640
425800/758000 (epoch 1123), train_loss = 0.230, time/batch = 0.030, All_Time = 12572.104
425850/758000 (epoch 1123), train_loss = 0.216, time/batch = 0.029, All_Time = 12573.570
425900/758000 (epoch 1123), train_loss = 0.244, time/batch = 0.032, All_Time = 12575.051
425950/758000 (epoch 1123), train_loss = 0.274, time/batch = 0.030, All_Time = 12576.545
426000/758000 (epoch 1124), train_loss = 0.221, time/batch = 0.031, All_Time = 12578.054
model saved to NER/polyglot/model.ckpt
426050/758000 (epoch 1124), train_loss = 0.257, time/batch = 0.028, All_Time = 12579.514
426100/758000 (epoch 1124), train_loss = 0.241, time/batch = 0.028, All_Time = 12580.979
426150/758000 (epoch 1124), train_loss = 0.240, time/batch = 0.030, All_Time = 12582.438
426200/758000 (epoch 1124), train_loss = 0.256, time/batch = 0.030, All_Time = 12583.890
426250/758000 (epoch 1124), train_loss = 0.219, time/batch = 0.029, All_Time = 12585.360
426300/758000 (epoch 1124), train_loss = 0.224, time/batch = 0.030, All_Time = 12586.845
426350/758000 (epoch 1124), train_loss = 0.257, time/batch = 0.030, All_Time = 12588.341
426400/758000 (epoch 1125), train_loss = 0.255, time/batch = 0.028, All_Time = 12589.836
426450/758000 (epoch 1125), train_loss = 0.267, time/batch = 0.029, All_Time = 12591.312
426500/758000 (epoch 1125), train_loss = 0.269, time/batch = 0.029, All_Time = 12592.793
426550/758000 (epoch 1125), train_loss = 0.228, time/batch = 0.029, All_Time = 12594.266
426600/758000 (epoch 1125), train_loss = 0.234, time/batch = 0.030, All_Time = 12595.744
426650/758000 (epoch 1125), train_loss = 0.245, time/batch = 0.028, All_Time = 12597.216
426700/758000 (epoch 1125), train_loss = 0.279, time/batch = 0.029, All_Time = 12598.728
426750/758000 (epoch 1125), train_loss = 0.240, time/batch = 0.028, All_Time = 12600.211
426800/758000 (epoch 1126), train_loss = 0.236, time/batch = 0.027, All_Time = 12601.684
426850/758000 (epoch 1126), train_loss = 0.234, time/batch = 0.030, All_Time = 12603.157
426900/758000 (epoch 1126), train_loss = 0.233, time/batch = 0.028, All_Time = 12604.626
426950/758000 (epoch 1126), train_loss = 0.276, time/batch = 0.030, All_Time = 12606.101
427000/758000 (epoch 1126), train_loss = 0.206, time/batch = 0.029, All_Time = 12607.599
model saved to NER/polyglot/model.ckpt
427050/758000 (epoch 1126), train_loss = 0.259, time/batch = 0.030, All_Time = 12609.092
427100/758000 (epoch 1126), train_loss = 0.234, time/batch = 0.029, All_Time = 12610.570
427150/758000 (epoch 1127), train_loss = 0.245, time/batch = 0.028, All_Time = 12612.050
427200/758000 (epoch 1127), train_loss = 0.223, time/batch = 0.029, All_Time = 12613.516
427250/758000 (epoch 1127), train_loss = 0.240, time/batch = 0.029, All_Time = 12614.976
427300/758000 (epoch 1127), train_loss = 0.256, time/batch = 0.031, All_Time = 12616.442
427350/758000 (epoch 1127), train_loss = 0.214, time/batch = 0.030, All_Time = 12617.956
427400/758000 (epoch 1127), train_loss = 0.272, time/batch = 0.029, All_Time = 12619.455
427450/758000 (epoch 1127), train_loss = 0.213, time/batch = 0.029, All_Time = 12620.945
427500/758000 (epoch 1127), train_loss = 0.251, time/batch = 0.029, All_Time = 12622.438
427550/758000 (epoch 1128), train_loss = 0.247, time/batch = 0.029, All_Time = 12623.906
427600/758000 (epoch 1128), train_loss = 0.229, time/batch = 0.029, All_Time = 12625.383
427650/758000 (epoch 1128), train_loss = 0.217, time/batch = 0.029, All_Time = 12626.869
427700/758000 (epoch 1128), train_loss = 0.220, time/batch = 0.030, All_Time = 12628.366
427750/758000 (epoch 1128), train_loss = 0.250, time/batch = 0.030, All_Time = 12629.839
427800/758000 (epoch 1128), train_loss = 0.207, time/batch = 0.034, All_Time = 12631.342
427850/758000 (epoch 1128), train_loss = 0.268, time/batch = 0.032, All_Time = 12632.819
427900/758000 (epoch 1129), train_loss = 0.256, time/batch = 0.028, All_Time = 12634.302
427950/758000 (epoch 1129), train_loss = 0.264, time/batch = 0.030, All_Time = 12635.784
428000/758000 (epoch 1129), train_loss = 0.284, time/batch = 0.030, All_Time = 12637.248
model saved to NER/polyglot/model.ckpt
428050/758000 (epoch 1129), train_loss = 0.239, time/batch = 0.030, All_Time = 12638.712
428100/758000 (epoch 1129), train_loss = 0.267, time/batch = 0.028, All_Time = 12640.164
428150/758000 (epoch 1129), train_loss = 0.256, time/batch = 0.029, All_Time = 12641.629
428200/758000 (epoch 1129), train_loss = 0.236, time/batch = 0.030, All_Time = 12643.104
428250/758000 (epoch 1129), train_loss = 0.268, time/batch = 0.031, All_Time = 12644.576
428300/758000 (epoch 1130), train_loss = 0.226, time/batch = 0.032, All_Time = 12646.083
428350/758000 (epoch 1130), train_loss = 0.222, time/batch = 0.030, All_Time = 12647.550
428400/758000 (epoch 1130), train_loss = 0.261, time/batch = 0.030, All_Time = 12649.032
428450/758000 (epoch 1130), train_loss = 0.254, time/batch = 0.030, All_Time = 12650.507
428500/758000 (epoch 1130), train_loss = 0.223, time/batch = 0.030, All_Time = 12651.982
428550/758000 (epoch 1130), train_loss = 0.242, time/batch = 0.029, All_Time = 12653.461
428600/758000 (epoch 1130), train_loss = 0.251, time/batch = 0.029, All_Time = 12654.938
428650/758000 (epoch 1131), train_loss = 0.192, time/batch = 0.030, All_Time = 12656.424
428700/758000 (epoch 1131), train_loss = 0.273, time/batch = 0.030, All_Time = 12657.887
428750/758000 (epoch 1131), train_loss = 0.217, time/batch = 0.030, All_Time = 12659.362
428800/758000 (epoch 1131), train_loss = 0.240, time/batch = 0.029, All_Time = 12660.838
428850/758000 (epoch 1131), train_loss = 0.221, time/batch = 0.030, All_Time = 12662.320
428900/758000 (epoch 1131), train_loss = 0.221, time/batch = 0.029, All_Time = 12663.828
428950/758000 (epoch 1131), train_loss = 0.252, time/batch = 0.031, All_Time = 12665.310
429000/758000 (epoch 1131), train_loss = 0.272, time/batch = 0.030, All_Time = 12666.801
model saved to NER/polyglot/model.ckpt
429050/758000 (epoch 1132), train_loss = 0.222, time/batch = 0.030, All_Time = 12668.291
429100/758000 (epoch 1132), train_loss = 0.279, time/batch = 0.029, All_Time = 12669.771
429150/758000 (epoch 1132), train_loss = 0.242, time/batch = 0.029, All_Time = 12671.227
429200/758000 (epoch 1132), train_loss = 0.274, time/batch = 0.030, All_Time = 12672.687
429250/758000 (epoch 1132), train_loss = 0.262, time/batch = 0.029, All_Time = 12674.204
429300/758000 (epoch 1132), train_loss = 0.197, time/batch = 0.027, All_Time = 12675.689
429350/758000 (epoch 1132), train_loss = 0.233, time/batch = 0.029, All_Time = 12677.168
429400/758000 (epoch 1132), train_loss = 0.281, time/batch = 0.030, All_Time = 12678.660
429450/758000 (epoch 1133), train_loss = 0.246, time/batch = 0.031, All_Time = 12680.152
429500/758000 (epoch 1133), train_loss = 0.212, time/batch = 0.029, All_Time = 12681.624
429550/758000 (epoch 1133), train_loss = 0.255, time/batch = 0.030, All_Time = 12683.098
429600/758000 (epoch 1133), train_loss = 0.271, time/batch = 0.029, All_Time = 12684.567
429650/758000 (epoch 1133), train_loss = 0.203, time/batch = 0.029, All_Time = 12686.037
429700/758000 (epoch 1133), train_loss = 0.226, time/batch = 0.029, All_Time = 12687.511
429750/758000 (epoch 1133), train_loss = 0.254, time/batch = 0.031, All_Time = 12689.013
429800/758000 (epoch 1134), train_loss = 0.219, time/batch = 0.030, All_Time = 12690.519
429850/758000 (epoch 1134), train_loss = 0.265, time/batch = 0.030, All_Time = 12691.988
429900/758000 (epoch 1134), train_loss = 0.227, time/batch = 0.029, All_Time = 12693.449
429950/758000 (epoch 1134), train_loss = 0.213, time/batch = 0.029, All_Time = 12694.920
430000/758000 (epoch 1134), train_loss = 0.224, time/batch = 0.030, All_Time = 12696.424
model saved to NER/polyglot/model.ckpt
430050/758000 (epoch 1134), train_loss = 0.213, time/batch = 0.030, All_Time = 12697.902
430100/758000 (epoch 1134), train_loss = 0.230, time/batch = 0.031, All_Time = 12699.365
430150/758000 (epoch 1134), train_loss = 0.223, time/batch = 0.030, All_Time = 12700.826
430200/758000 (epoch 1135), train_loss = 0.275, time/batch = 0.029, All_Time = 12702.303
430250/758000 (epoch 1135), train_loss = 0.229, time/batch = 0.031, All_Time = 12703.763
430300/758000 (epoch 1135), train_loss = 0.270, time/batch = 0.029, All_Time = 12705.223
430350/758000 (epoch 1135), train_loss = 0.273, time/batch = 0.030, All_Time = 12706.723
430400/758000 (epoch 1135), train_loss = 0.233, time/batch = 0.030, All_Time = 12708.220
430450/758000 (epoch 1135), train_loss = 0.268, time/batch = 0.030, All_Time = 12709.711
430500/758000 (epoch 1135), train_loss = 0.280, time/batch = 0.029, All_Time = 12711.190
430550/758000 (epoch 1136), train_loss = 0.239, time/batch = 0.029, All_Time = 12712.678
430600/758000 (epoch 1136), train_loss = 0.218, time/batch = 0.029, All_Time = 12714.151
430650/758000 (epoch 1136), train_loss = 0.243, time/batch = 0.030, All_Time = 12715.612
430700/758000 (epoch 1136), train_loss = 0.244, time/batch = 0.029, All_Time = 12717.086
430750/758000 (epoch 1136), train_loss = 0.243, time/batch = 0.029, All_Time = 12718.571
430800/758000 (epoch 1136), train_loss = 0.244, time/batch = 0.029, All_Time = 12720.039
430850/758000 (epoch 1136), train_loss = 0.213, time/batch = 0.031, All_Time = 12721.509
430900/758000 (epoch 1136), train_loss = 0.289, time/batch = 0.029, All_Time = 12722.989
430950/758000 (epoch 1137), train_loss = 0.237, time/batch = 0.029, All_Time = 12724.477
431000/758000 (epoch 1137), train_loss = 0.246, time/batch = 0.031, All_Time = 12725.955
model saved to NER/polyglot/model.ckpt
431050/758000 (epoch 1137), train_loss = 0.288, time/batch = 0.029, All_Time = 12727.442
431100/758000 (epoch 1137), train_loss = 0.257, time/batch = 0.030, All_Time = 12728.921
431150/758000 (epoch 1137), train_loss = 0.218, time/batch = 0.030, All_Time = 12730.406
431200/758000 (epoch 1137), train_loss = 0.238, time/batch = 0.029, All_Time = 12731.872
431250/758000 (epoch 1137), train_loss = 0.251, time/batch = 0.029, All_Time = 12733.345
431300/758000 (epoch 1137), train_loss = 0.251, time/batch = 0.029, All_Time = 12734.815
431350/758000 (epoch 1138), train_loss = 0.252, time/batch = 0.029, All_Time = 12736.296
431400/758000 (epoch 1138), train_loss = 0.280, time/batch = 0.030, All_Time = 12737.760
431450/758000 (epoch 1138), train_loss = 0.242, time/batch = 0.033, All_Time = 12739.343
431500/758000 (epoch 1138), train_loss = 0.250, time/batch = 0.029, All_Time = 12740.857
431550/758000 (epoch 1138), train_loss = 0.239, time/batch = 0.030, All_Time = 12742.328
431600/758000 (epoch 1138), train_loss = 0.239, time/batch = 0.029, All_Time = 12743.811
431650/758000 (epoch 1138), train_loss = 0.250, time/batch = 0.030, All_Time = 12745.308
431700/758000 (epoch 1139), train_loss = 0.221, time/batch = 0.029, All_Time = 12746.818
431750/758000 (epoch 1139), train_loss = 0.219, time/batch = 0.031, All_Time = 12748.282
431800/758000 (epoch 1139), train_loss = 0.246, time/batch = 0.029, All_Time = 12749.751
431850/758000 (epoch 1139), train_loss = 0.262, time/batch = 0.029, All_Time = 12751.210
431900/758000 (epoch 1139), train_loss = 0.260, time/batch = 0.030, All_Time = 12752.679
431950/758000 (epoch 1139), train_loss = 0.241, time/batch = 0.030, All_Time = 12754.166
432000/758000 (epoch 1139), train_loss = 0.210, time/batch = 0.030, All_Time = 12755.670
model saved to NER/polyglot/model.ckpt
432050/758000 (epoch 1139), train_loss = 0.239, time/batch = 0.031, All_Time = 12757.140
432100/758000 (epoch 1140), train_loss = 0.230, time/batch = 0.029, All_Time = 12758.619
432150/758000 (epoch 1140), train_loss = 0.226, time/batch = 0.029, All_Time = 12760.079
432200/758000 (epoch 1140), train_loss = 0.264, time/batch = 0.029, All_Time = 12761.550
432250/758000 (epoch 1140), train_loss = 0.240, time/batch = 0.030, All_Time = 12763.027
432300/758000 (epoch 1140), train_loss = 0.253, time/batch = 0.030, All_Time = 12764.518
432350/758000 (epoch 1140), train_loss = 0.251, time/batch = 0.031, All_Time = 12766.011
432400/758000 (epoch 1140), train_loss = 0.248, time/batch = 0.029, All_Time = 12767.492
432450/758000 (epoch 1141), train_loss = 0.216, time/batch = 0.030, All_Time = 12768.982
432500/758000 (epoch 1141), train_loss = 0.233, time/batch = 0.031, All_Time = 12770.451
432550/758000 (epoch 1141), train_loss = 0.250, time/batch = 0.029, All_Time = 12771.915
432600/758000 (epoch 1141), train_loss = 0.241, time/batch = 0.030, All_Time = 12773.391
432650/758000 (epoch 1141), train_loss = 0.243, time/batch = 0.030, All_Time = 12774.881
432700/758000 (epoch 1141), train_loss = 0.242, time/batch = 0.029, All_Time = 12776.564
432750/758000 (epoch 1141), train_loss = 0.230, time/batch = 0.031, All_Time = 12778.068
432800/758000 (epoch 1141), train_loss = 0.259, time/batch = 0.030, All_Time = 12779.556
432850/758000 (epoch 1142), train_loss = 0.250, time/batch = 0.029, All_Time = 12781.044
432900/758000 (epoch 1142), train_loss = 0.253, time/batch = 0.031, All_Time = 12782.512
432950/758000 (epoch 1142), train_loss = 0.245, time/batch = 0.031, All_Time = 12783.992
433000/758000 (epoch 1142), train_loss = 0.231, time/batch = 0.031, All_Time = 12785.498
model saved to NER/polyglot/model.ckpt
433050/758000 (epoch 1142), train_loss = 0.228, time/batch = 0.031, All_Time = 12786.975
433100/758000 (epoch 1142), train_loss = 0.238, time/batch = 0.031, All_Time = 12788.447
433150/758000 (epoch 1142), train_loss = 0.268, time/batch = 0.030, All_Time = 12789.926
433200/758000 (epoch 1143), train_loss = 0.248, time/batch = 0.030, All_Time = 12791.421
433250/758000 (epoch 1143), train_loss = 0.280, time/batch = 0.029, All_Time = 12792.903
433300/758000 (epoch 1143), train_loss = 0.242, time/batch = 0.030, All_Time = 12794.394
433350/758000 (epoch 1143), train_loss = 0.258, time/batch = 0.031, All_Time = 12795.873
433400/758000 (epoch 1143), train_loss = 0.224, time/batch = 0.030, All_Time = 12797.361
433450/758000 (epoch 1143), train_loss = 0.243, time/batch = 0.030, All_Time = 12798.844
433500/758000 (epoch 1143), train_loss = 0.219, time/batch = 0.029, All_Time = 12800.330
433550/758000 (epoch 1143), train_loss = 0.232, time/batch = 0.029, All_Time = 12801.808
433600/758000 (epoch 1144), train_loss = 0.237, time/batch = 0.030, All_Time = 12803.310
433650/758000 (epoch 1144), train_loss = 0.239, time/batch = 0.028, All_Time = 12804.775
433700/758000 (epoch 1144), train_loss = 0.293, time/batch = 0.028, All_Time = 12806.240
433750/758000 (epoch 1144), train_loss = 0.318, time/batch = 0.030, All_Time = 12807.720
433800/758000 (epoch 1144), train_loss = 0.196, time/batch = 0.030, All_Time = 12809.212
433850/758000 (epoch 1144), train_loss = 0.213, time/batch = 0.029, All_Time = 12810.696
433900/758000 (epoch 1144), train_loss = 0.250, time/batch = 0.031, All_Time = 12812.183
433950/758000 (epoch 1144), train_loss = 0.297, time/batch = 0.030, All_Time = 12813.697
434000/758000 (epoch 1145), train_loss = 0.226, time/batch = 0.029, All_Time = 12815.186
model saved to NER/polyglot/model.ckpt
434050/758000 (epoch 1145), train_loss = 0.259, time/batch = 0.030, All_Time = 12816.657
434100/758000 (epoch 1145), train_loss = 0.223, time/batch = 0.029, All_Time = 12818.120
434150/758000 (epoch 1145), train_loss = 0.239, time/batch = 0.029, All_Time = 12819.602
434200/758000 (epoch 1145), train_loss = 0.212, time/batch = 0.030, All_Time = 12821.089
434250/758000 (epoch 1145), train_loss = 0.243, time/batch = 0.030, All_Time = 12822.569
434300/758000 (epoch 1145), train_loss = 0.215, time/batch = 0.030, All_Time = 12824.052
434350/758000 (epoch 1146), train_loss = 0.228, time/batch = 0.029, All_Time = 12825.561
434400/758000 (epoch 1146), train_loss = 0.252, time/batch = 0.029, All_Time = 12827.037
434450/758000 (epoch 1146), train_loss = 0.260, time/batch = 0.029, All_Time = 12828.510
434500/758000 (epoch 1146), train_loss = 0.228, time/batch = 0.030, All_Time = 12829.978
434550/758000 (epoch 1146), train_loss = 0.236, time/batch = 0.030, All_Time = 12831.473
434600/758000 (epoch 1146), train_loss = 0.271, time/batch = 0.033, All_Time = 12833.087
434650/758000 (epoch 1146), train_loss = 0.238, time/batch = 0.031, All_Time = 12834.697
434700/758000 (epoch 1146), train_loss = 0.268, time/batch = 0.031, All_Time = 12836.230
434750/758000 (epoch 1147), train_loss = 0.248, time/batch = 0.030, All_Time = 12837.734
434800/758000 (epoch 1147), train_loss = 0.249, time/batch = 0.030, All_Time = 12839.224
434850/758000 (epoch 1147), train_loss = 0.240, time/batch = 0.029, All_Time = 12840.703
434900/758000 (epoch 1147), train_loss = 0.247, time/batch = 0.029, All_Time = 12842.174
434950/758000 (epoch 1147), train_loss = 0.235, time/batch = 0.031, All_Time = 12843.658
435000/758000 (epoch 1147), train_loss = 0.247, time/batch = 0.031, All_Time = 12845.152
model saved to NER/polyglot/model.ckpt
435050/758000 (epoch 1147), train_loss = 0.251, time/batch = 0.029, All_Time = 12846.629
435100/758000 (epoch 1148), train_loss = 0.242, time/batch = 0.030, All_Time = 12848.119
435150/758000 (epoch 1148), train_loss = 0.276, time/batch = 0.030, All_Time = 12849.593
435200/758000 (epoch 1148), train_loss = 0.256, time/batch = 0.028, All_Time = 12851.059
435250/758000 (epoch 1148), train_loss = 0.258, time/batch = 0.029, All_Time = 12852.531
435300/758000 (epoch 1148), train_loss = 0.213, time/batch = 0.028, All_Time = 12853.993
435350/758000 (epoch 1148), train_loss = 0.237, time/batch = 0.030, All_Time = 12855.470
435400/758000 (epoch 1148), train_loss = 0.249, time/batch = 0.030, All_Time = 12856.946
435450/758000 (epoch 1148), train_loss = 0.251, time/batch = 0.030, All_Time = 12858.443
435500/758000 (epoch 1149), train_loss = 0.232, time/batch = 0.031, All_Time = 12859.945
435550/758000 (epoch 1149), train_loss = 0.255, time/batch = 0.030, All_Time = 12861.444
435600/758000 (epoch 1149), train_loss = 0.265, time/batch = 0.030, All_Time = 12862.913
435650/758000 (epoch 1149), train_loss = 0.229, time/batch = 0.031, All_Time = 12864.532
435700/758000 (epoch 1149), train_loss = 0.263, time/batch = 0.032, All_Time = 12866.111
435750/758000 (epoch 1149), train_loss = 0.217, time/batch = 0.030, All_Time = 12867.634
435800/758000 (epoch 1149), train_loss = 0.248, time/batch = 0.029, All_Time = 12869.148
435850/758000 (epoch 1150), train_loss = 0.059, time/batch = 0.042, All_Time = 12870.654
435900/758000 (epoch 1150), train_loss = 0.250, time/batch = 0.029, All_Time = 12872.125
435950/758000 (epoch 1150), train_loss = 0.223, time/batch = 0.028, All_Time = 12873.589
436000/758000 (epoch 1150), train_loss = 0.250, time/batch = 0.028, All_Time = 12875.052
model saved to NER/polyglot/model.ckpt
436050/758000 (epoch 1150), train_loss = 0.231, time/batch = 0.030, All_Time = 12876.518
436100/758000 (epoch 1150), train_loss = 0.250, time/batch = 0.030, All_Time = 12877.980
436150/758000 (epoch 1150), train_loss = 0.232, time/batch = 0.031, All_Time = 12879.448
436200/758000 (epoch 1150), train_loss = 0.230, time/batch = 0.029, All_Time = 12880.917
436250/758000 (epoch 1151), train_loss = 0.224, time/batch = 0.031, All_Time = 12882.432
436300/758000 (epoch 1151), train_loss = 0.233, time/batch = 0.030, All_Time = 12883.913
436350/758000 (epoch 1151), train_loss = 0.224, time/batch = 0.031, All_Time = 12885.396
436400/758000 (epoch 1151), train_loss = 0.262, time/batch = 0.028, All_Time = 12886.864
436450/758000 (epoch 1151), train_loss = 0.220, time/batch = 0.030, All_Time = 12888.345
436500/758000 (epoch 1151), train_loss = 0.228, time/batch = 0.028, All_Time = 12889.811
436550/758000 (epoch 1151), train_loss = 0.280, time/batch = 0.029, All_Time = 12891.284
436600/758000 (epoch 1151), train_loss = 0.272, time/batch = 0.029, All_Time = 12892.760
436650/758000 (epoch 1152), train_loss = 0.230, time/batch = 0.030, All_Time = 12894.248
436700/758000 (epoch 1152), train_loss = 0.224, time/batch = 0.028, All_Time = 12895.732
436750/758000 (epoch 1152), train_loss = 0.201, time/batch = 0.029, All_Time = 12897.212
436800/758000 (epoch 1152), train_loss = 0.270, time/batch = 0.031, All_Time = 12898.711
436850/758000 (epoch 1152), train_loss = 0.259, time/batch = 0.030, All_Time = 12900.223
436900/758000 (epoch 1152), train_loss = 0.209, time/batch = 0.030, All_Time = 12901.714
436950/758000 (epoch 1152), train_loss = 0.218, time/batch = 0.031, All_Time = 12903.195
437000/758000 (epoch 1153), train_loss = 0.229, time/batch = 0.030, All_Time = 12904.689
model saved to NER/polyglot/model.ckpt
437050/758000 (epoch 1153), train_loss = 0.283, time/batch = 0.028, All_Time = 12906.158
437100/758000 (epoch 1153), train_loss = 0.231, time/batch = 0.032, All_Time = 12907.768
437150/758000 (epoch 1153), train_loss = 0.307, time/batch = 0.030, All_Time = 12909.320
437200/758000 (epoch 1153), train_loss = 0.221, time/batch = 0.031, All_Time = 12910.858
437250/758000 (epoch 1153), train_loss = 0.208, time/batch = 0.030, All_Time = 12912.375
437300/758000 (epoch 1153), train_loss = 0.247, time/batch = 0.029, All_Time = 12913.857
437350/758000 (epoch 1153), train_loss = 0.252, time/batch = 0.030, All_Time = 12915.333
437400/758000 (epoch 1154), train_loss = 0.264, time/batch = 0.030, All_Time = 12916.803
437450/758000 (epoch 1154), train_loss = 0.229, time/batch = 0.028, All_Time = 12918.274
437500/758000 (epoch 1154), train_loss = 0.242, time/batch = 0.029, All_Time = 12919.758
437550/758000 (epoch 1154), train_loss = 0.267, time/batch = 0.031, All_Time = 12921.241
437600/758000 (epoch 1154), train_loss = 0.249, time/batch = 0.031, All_Time = 12922.743
437650/758000 (epoch 1154), train_loss = 0.237, time/batch = 0.029, All_Time = 12924.240
437700/758000 (epoch 1154), train_loss = 0.276, time/batch = 0.029, All_Time = 12925.727
437750/758000 (epoch 1155), train_loss = 0.256, time/batch = 0.029, All_Time = 12927.216
437800/758000 (epoch 1155), train_loss = 0.222, time/batch = 0.031, All_Time = 12928.684
437850/758000 (epoch 1155), train_loss = 0.266, time/batch = 0.029, All_Time = 12930.157
437900/758000 (epoch 1155), train_loss = 0.216, time/batch = 0.029, All_Time = 12931.640
437950/758000 (epoch 1155), train_loss = 0.223, time/batch = 0.032, All_Time = 12933.121
438000/758000 (epoch 1155), train_loss = 0.261, time/batch = 0.028, All_Time = 12934.602
model saved to NER/polyglot/model.ckpt
438050/758000 (epoch 1155), train_loss = 0.238, time/batch = 0.030, All_Time = 12936.081
438100/758000 (epoch 1155), train_loss = 0.264, time/batch = 0.031, All_Time = 12937.554
438150/758000 (epoch 1156), train_loss = 0.223, time/batch = 0.030, All_Time = 12939.032
438200/758000 (epoch 1156), train_loss = 0.231, time/batch = 0.029, All_Time = 12940.511
438250/758000 (epoch 1156), train_loss = 0.238, time/batch = 0.031, All_Time = 12942.000
438300/758000 (epoch 1156), train_loss = 0.266, time/batch = 0.029, All_Time = 12943.500
438350/758000 (epoch 1156), train_loss = 0.239, time/batch = 0.030, All_Time = 12944.997
438400/758000 (epoch 1156), train_loss = 0.226, time/batch = 0.029, All_Time = 12946.476
438450/758000 (epoch 1156), train_loss = 0.276, time/batch = 0.029, All_Time = 12947.958
438500/758000 (epoch 1156), train_loss = 0.240, time/batch = 0.030, All_Time = 12949.445
438550/758000 (epoch 1157), train_loss = 0.281, time/batch = 0.029, All_Time = 12950.927
438600/758000 (epoch 1157), train_loss = 0.257, time/batch = 0.029, All_Time = 12952.396
438650/758000 (epoch 1157), train_loss = 0.240, time/batch = 0.028, All_Time = 12953.862
438700/758000 (epoch 1157), train_loss = 0.231, time/batch = 0.029, All_Time = 12955.333
438750/758000 (epoch 1157), train_loss = 0.217, time/batch = 0.030, All_Time = 12956.800
438800/758000 (epoch 1157), train_loss = 0.224, time/batch = 0.029, All_Time = 12958.277
438850/758000 (epoch 1157), train_loss = 0.215, time/batch = 0.028, All_Time = 12959.754
438900/758000 (epoch 1158), train_loss = 0.249, time/batch = 0.030, All_Time = 12961.274
438950/758000 (epoch 1158), train_loss = 0.211, time/batch = 0.029, All_Time = 12962.761
439000/758000 (epoch 1158), train_loss = 0.245, time/batch = 0.030, All_Time = 12964.238
model saved to NER/polyglot/model.ckpt
439050/758000 (epoch 1158), train_loss = 0.217, time/batch = 0.028, All_Time = 12965.711
439100/758000 (epoch 1158), train_loss = 0.233, time/batch = 0.030, All_Time = 12967.189
439150/758000 (epoch 1158), train_loss = 0.228, time/batch = 0.030, All_Time = 12968.706
439200/758000 (epoch 1158), train_loss = 0.248, time/batch = 0.031, All_Time = 12970.193
439250/758000 (epoch 1158), train_loss = 0.229, time/batch = 0.029, All_Time = 12971.669
439300/758000 (epoch 1159), train_loss = 0.218, time/batch = 0.029, All_Time = 12973.140
439350/758000 (epoch 1159), train_loss = 0.237, time/batch = 0.029, All_Time = 12974.611
439400/758000 (epoch 1159), train_loss = 0.212, time/batch = 0.029, All_Time = 12976.080
439450/758000 (epoch 1159), train_loss = 0.266, time/batch = 0.029, All_Time = 12977.547
439500/758000 (epoch 1159), train_loss = 0.255, time/batch = 0.030, All_Time = 12979.016
439550/758000 (epoch 1159), train_loss = 0.232, time/batch = 0.029, All_Time = 12980.490
439600/758000 (epoch 1159), train_loss = 0.262, time/batch = 0.029, All_Time = 12981.974
439650/758000 (epoch 1160), train_loss = 0.282, time/batch = 0.029, All_Time = 12983.454
439700/758000 (epoch 1160), train_loss = 0.292, time/batch = 0.029, All_Time = 12984.923
439750/758000 (epoch 1160), train_loss = 0.253, time/batch = 0.030, All_Time = 12986.427
439800/758000 (epoch 1160), train_loss = 0.222, time/batch = 0.028, All_Time = 12987.921
439850/758000 (epoch 1160), train_loss = 0.221, time/batch = 0.029, All_Time = 12989.398
439900/758000 (epoch 1160), train_loss = 0.260, time/batch = 0.030, All_Time = 12990.878
439950/758000 (epoch 1160), train_loss = 0.244, time/batch = 0.030, All_Time = 12992.356
440000/758000 (epoch 1160), train_loss = 0.247, time/batch = 0.030, All_Time = 12993.843
model saved to NER/polyglot/model.ckpt
440050/758000 (epoch 1161), train_loss = 0.210, time/batch = 0.028, All_Time = 12995.327
440100/758000 (epoch 1161), train_loss = 0.265, time/batch = 0.030, All_Time = 12996.789
440150/758000 (epoch 1161), train_loss = 0.229, time/batch = 0.029, All_Time = 12998.258
440200/758000 (epoch 1161), train_loss = 0.232, time/batch = 0.030, All_Time = 12999.759
440250/758000 (epoch 1161), train_loss = 0.230, time/batch = 0.028, All_Time = 13001.244
440300/758000 (epoch 1161), train_loss = 0.253, time/batch = 0.029, All_Time = 13002.713
440350/758000 (epoch 1161), train_loss = 0.258, time/batch = 0.030, All_Time = 13004.192
440400/758000 (epoch 1162), train_loss = 0.196, time/batch = 0.031, All_Time = 13005.674
440450/758000 (epoch 1162), train_loss = 0.254, time/batch = 0.028, All_Time = 13007.150
440500/758000 (epoch 1162), train_loss = 0.281, time/batch = 0.030, All_Time = 13008.611
440550/758000 (epoch 1162), train_loss = 0.235, time/batch = 0.029, All_Time = 13010.074
440600/758000 (epoch 1162), train_loss = 0.247, time/batch = 0.029, All_Time = 13011.547
440650/758000 (epoch 1162), train_loss = 0.251, time/batch = 0.031, All_Time = 13013.030
440700/758000 (epoch 1162), train_loss = 0.203, time/batch = 0.029, All_Time = 13014.513
440750/758000 (epoch 1162), train_loss = 0.268, time/batch = 0.031, All_Time = 13015.997
440800/758000 (epoch 1163), train_loss = 0.233, time/batch = 0.030, All_Time = 13017.492
440850/758000 (epoch 1163), train_loss = 0.241, time/batch = 0.030, All_Time = 13018.960
440900/758000 (epoch 1163), train_loss = 0.252, time/batch = 0.030, All_Time = 13020.440
440950/758000 (epoch 1163), train_loss = 0.258, time/batch = 0.030, All_Time = 13021.959
441000/758000 (epoch 1163), train_loss = 0.243, time/batch = 0.029, All_Time = 13023.453
model saved to NER/polyglot/model.ckpt
441050/758000 (epoch 1163), train_loss = 0.243, time/batch = 0.030, All_Time = 13024.929
441100/758000 (epoch 1163), train_loss = 0.244, time/batch = 0.028, All_Time = 13026.399
441150/758000 (epoch 1163), train_loss = 0.286, time/batch = 0.029, All_Time = 13027.863
441200/758000 (epoch 1164), train_loss = 0.207, time/batch = 0.030, All_Time = 13029.342
441250/758000 (epoch 1164), train_loss = 0.244, time/batch = 0.031, All_Time = 13030.810
441300/758000 (epoch 1164), train_loss = 0.217, time/batch = 0.030, All_Time = 13032.312
441350/758000 (epoch 1164), train_loss = 0.233, time/batch = 0.028, All_Time = 13033.792
441400/758000 (epoch 1164), train_loss = 0.260, time/batch = 0.030, All_Time = 13035.297
441450/758000 (epoch 1164), train_loss = 0.253, time/batch = 0.029, All_Time = 13036.782
441500/758000 (epoch 1164), train_loss = 0.238, time/batch = 0.031, All_Time = 13038.254
441550/758000 (epoch 1165), train_loss = 0.227, time/batch = 0.029, All_Time = 13039.740
441600/758000 (epoch 1165), train_loss = 0.250, time/batch = 0.030, All_Time = 13041.203
441650/758000 (epoch 1165), train_loss = 0.250, time/batch = 0.029, All_Time = 13042.665
441700/758000 (epoch 1165), train_loss = 0.223, time/batch = 0.028, All_Time = 13044.132
441750/758000 (epoch 1165), train_loss = 0.240, time/batch = 0.029, All_Time = 13045.592
441800/758000 (epoch 1165), train_loss = 0.246, time/batch = 0.030, All_Time = 13047.065
441850/758000 (epoch 1165), train_loss = 0.246, time/batch = 0.032, All_Time = 13048.560
441900/758000 (epoch 1165), train_loss = 0.257, time/batch = 0.030, All_Time = 13050.064
441950/758000 (epoch 1166), train_loss = 0.266, time/batch = 0.030, All_Time = 13051.541
442000/758000 (epoch 1166), train_loss = 0.224, time/batch = 0.028, All_Time = 13053.017
model saved to NER/polyglot/model.ckpt
442050/758000 (epoch 1166), train_loss = 0.248, time/batch = 0.029, All_Time = 13054.488
442100/758000 (epoch 1166), train_loss = 0.227, time/batch = 0.029, All_Time = 13055.958
442150/758000 (epoch 1166), train_loss = 0.279, time/batch = 0.028, All_Time = 13057.427
442200/758000 (epoch 1166), train_loss = 0.255, time/batch = 0.028, All_Time = 13058.949
442250/758000 (epoch 1166), train_loss = 0.253, time/batch = 0.029, All_Time = 13060.438
442300/758000 (epoch 1167), train_loss = 0.244, time/batch = 0.030, All_Time = 13061.928
442350/758000 (epoch 1167), train_loss = 0.247, time/batch = 0.030, All_Time = 13063.386
442400/758000 (epoch 1167), train_loss = 0.270, time/batch = 0.029, All_Time = 13064.851
442450/758000 (epoch 1167), train_loss = 0.246, time/batch = 0.030, All_Time = 13066.313
442500/758000 (epoch 1167), train_loss = 0.237, time/batch = 0.030, All_Time = 13067.817
442550/758000 (epoch 1167), train_loss = 0.224, time/batch = 0.030, All_Time = 13069.313
442600/758000 (epoch 1167), train_loss = 0.229, time/batch = 0.030, All_Time = 13070.799
442650/758000 (epoch 1167), train_loss = 0.246, time/batch = 0.029, All_Time = 13072.274
442700/758000 (epoch 1168), train_loss = 0.249, time/batch = 0.029, All_Time = 13073.760
442750/758000 (epoch 1168), train_loss = 0.264, time/batch = 0.029, All_Time = 13075.229
442800/758000 (epoch 1168), train_loss = 0.240, time/batch = 0.030, All_Time = 13076.701
442850/758000 (epoch 1168), train_loss = 0.250, time/batch = 0.029, All_Time = 13078.182
442900/758000 (epoch 1168), train_loss = 0.227, time/batch = 0.029, All_Time = 13079.667
442950/758000 (epoch 1168), train_loss = 0.217, time/batch = 0.030, All_Time = 13081.154
443000/758000 (epoch 1168), train_loss = 0.277, time/batch = 0.030, All_Time = 13082.626
model saved to NER/polyglot/model.ckpt
443050/758000 (epoch 1168), train_loss = 0.259, time/batch = 0.030, All_Time = 13084.096
443100/758000 (epoch 1169), train_loss = 0.269, time/batch = 0.029, All_Time = 13085.559
443150/758000 (epoch 1169), train_loss = 0.296, time/batch = 0.029, All_Time = 13087.016
443200/758000 (epoch 1169), train_loss = 0.228, time/batch = 0.029, All_Time = 13088.481
443250/758000 (epoch 1169), train_loss = 0.220, time/batch = 0.029, All_Time = 13089.942
443300/758000 (epoch 1169), train_loss = 0.257, time/batch = 0.029, All_Time = 13091.402
443350/758000 (epoch 1169), train_loss = 0.255, time/batch = 0.030, All_Time = 13092.858
443400/758000 (epoch 1169), train_loss = 0.237, time/batch = 0.029, All_Time = 13094.327
443450/758000 (epoch 1170), train_loss = 0.225, time/batch = 0.028, All_Time = 13095.808
443500/758000 (epoch 1170), train_loss = 0.234, time/batch = 0.029, All_Time = 13097.266
443550/758000 (epoch 1170), train_loss = 0.243, time/batch = 0.029, All_Time = 13098.746
443600/758000 (epoch 1170), train_loss = 0.234, time/batch = 0.029, All_Time = 13100.220
443650/758000 (epoch 1170), train_loss = 0.223, time/batch = 0.030, All_Time = 13101.693
443700/758000 (epoch 1170), train_loss = 0.239, time/batch = 0.030, All_Time = 13103.212
443750/758000 (epoch 1170), train_loss = 0.264, time/batch = 0.028, All_Time = 13104.699
443800/758000 (epoch 1170), train_loss = 0.244, time/batch = 0.030, All_Time = 13106.187
443850/758000 (epoch 1171), train_loss = 0.257, time/batch = 0.029, All_Time = 13107.669
443900/758000 (epoch 1171), train_loss = 0.287, time/batch = 0.029, All_Time = 13109.130
443950/758000 (epoch 1171), train_loss = 0.255, time/batch = 0.029, All_Time = 13110.589
444000/758000 (epoch 1171), train_loss = 0.248, time/batch = 0.028, All_Time = 13112.051
model saved to NER/polyglot/model.ckpt
444050/758000 (epoch 1171), train_loss = 0.212, time/batch = 0.029, All_Time = 13113.529
444100/758000 (epoch 1171), train_loss = 0.229, time/batch = 0.030, All_Time = 13115.037
444150/758000 (epoch 1171), train_loss = 0.272, time/batch = 0.031, All_Time = 13116.522
444200/758000 (epoch 1172), train_loss = 0.249, time/batch = 0.029, All_Time = 13118.021
444250/758000 (epoch 1172), train_loss = 0.227, time/batch = 0.029, All_Time = 13119.488
444300/758000 (epoch 1172), train_loss = 0.267, time/batch = 0.029, All_Time = 13120.949
444350/758000 (epoch 1172), train_loss = 0.239, time/batch = 0.031, All_Time = 13122.419
444400/758000 (epoch 1172), train_loss = 0.247, time/batch = 0.030, All_Time = 13123.898
444450/758000 (epoch 1172), train_loss = 0.241, time/batch = 0.030, All_Time = 13125.408
444500/758000 (epoch 1172), train_loss = 0.274, time/batch = 0.029, All_Time = 13126.903
444550/758000 (epoch 1172), train_loss = 0.279, time/batch = 0.028, All_Time = 13128.388
444600/758000 (epoch 1173), train_loss = 0.238, time/batch = 0.029, All_Time = 13129.871
444650/758000 (epoch 1173), train_loss = 0.248, time/batch = 0.029, All_Time = 13131.327
444700/758000 (epoch 1173), train_loss = 0.299, time/batch = 0.030, All_Time = 13132.802
444750/758000 (epoch 1173), train_loss = 0.230, time/batch = 0.030, All_Time = 13134.259
444800/758000 (epoch 1173), train_loss = 0.216, time/batch = 0.030, All_Time = 13135.736
444850/758000 (epoch 1173), train_loss = 0.244, time/batch = 0.029, All_Time = 13137.227
444900/758000 (epoch 1173), train_loss = 0.274, time/batch = 0.028, All_Time = 13138.709
444950/758000 (epoch 1174), train_loss = 0.221, time/batch = 0.030, All_Time = 13140.189
445000/758000 (epoch 1174), train_loss = 0.257, time/batch = 0.030, All_Time = 13141.658
model saved to NER/polyglot/model.ckpt
445050/758000 (epoch 1174), train_loss = 0.241, time/batch = 0.029, All_Time = 13143.128
445100/758000 (epoch 1174), train_loss = 0.240, time/batch = 0.030, All_Time = 13144.613
445150/758000 (epoch 1174), train_loss = 0.256, time/batch = 0.030, All_Time = 13146.120
445200/758000 (epoch 1174), train_loss = 0.219, time/batch = 0.029, All_Time = 13147.602
445250/758000 (epoch 1174), train_loss = 0.224, time/batch = 0.028, All_Time = 13149.070
445300/758000 (epoch 1174), train_loss = 0.257, time/batch = 0.030, All_Time = 13150.543
445350/758000 (epoch 1175), train_loss = 0.255, time/batch = 0.029, All_Time = 13152.022
445400/758000 (epoch 1175), train_loss = 0.267, time/batch = 0.029, All_Time = 13153.482
445450/758000 (epoch 1175), train_loss = 0.269, time/batch = 0.029, All_Time = 13154.947
445500/758000 (epoch 1175), train_loss = 0.228, time/batch = 0.029, All_Time = 13156.441
445550/758000 (epoch 1175), train_loss = 0.234, time/batch = 0.029, All_Time = 13157.953
445600/758000 (epoch 1175), train_loss = 0.245, time/batch = 0.030, All_Time = 13159.444
445650/758000 (epoch 1175), train_loss = 0.279, time/batch = 0.029, All_Time = 13160.930
445700/758000 (epoch 1175), train_loss = 0.240, time/batch = 0.030, All_Time = 13162.415
445750/758000 (epoch 1176), train_loss = 0.236, time/batch = 0.030, All_Time = 13163.897
445800/758000 (epoch 1176), train_loss = 0.234, time/batch = 0.030, All_Time = 13165.377
445850/758000 (epoch 1176), train_loss = 0.233, time/batch = 0.029, All_Time = 13166.843
445900/758000 (epoch 1176), train_loss = 0.276, time/batch = 0.029, All_Time = 13168.328
445950/758000 (epoch 1176), train_loss = 0.206, time/batch = 0.027, All_Time = 13169.822
446000/758000 (epoch 1176), train_loss = 0.259, time/batch = 0.029, All_Time = 13171.314
model saved to NER/polyglot/model.ckpt
446050/758000 (epoch 1176), train_loss = 0.234, time/batch = 0.029, All_Time = 13172.802
446100/758000 (epoch 1177), train_loss = 0.245, time/batch = 0.027, All_Time = 13174.270
446150/758000 (epoch 1177), train_loss = 0.223, time/batch = 0.028, All_Time = 13175.735
446200/758000 (epoch 1177), train_loss = 0.240, time/batch = 0.028, All_Time = 13177.212
446250/758000 (epoch 1177), train_loss = 0.256, time/batch = 0.029, All_Time = 13178.673
446300/758000 (epoch 1177), train_loss = 0.214, time/batch = 0.031, All_Time = 13180.139
446350/758000 (epoch 1177), train_loss = 0.272, time/batch = 0.030, All_Time = 13181.611
446400/758000 (epoch 1177), train_loss = 0.213, time/batch = 0.029, All_Time = 13183.077
446450/758000 (epoch 1177), train_loss = 0.251, time/batch = 0.030, All_Time = 13184.552
446500/758000 (epoch 1178), train_loss = 0.247, time/batch = 0.029, All_Time = 13186.026
446550/758000 (epoch 1178), train_loss = 0.229, time/batch = 0.029, All_Time = 13187.496
446600/758000 (epoch 1178), train_loss = 0.217, time/batch = 0.030, All_Time = 13188.969
446650/758000 (epoch 1178), train_loss = 0.220, time/batch = 0.031, All_Time = 13190.455
446700/758000 (epoch 1178), train_loss = 0.250, time/batch = 0.031, All_Time = 13191.961
446750/758000 (epoch 1178), train_loss = 0.207, time/batch = 0.029, All_Time = 13193.444
446800/758000 (epoch 1178), train_loss = 0.268, time/batch = 0.030, All_Time = 13194.931
446850/758000 (epoch 1179), train_loss = 0.256, time/batch = 0.031, All_Time = 13196.439
446900/758000 (epoch 1179), train_loss = 0.264, time/batch = 0.030, All_Time = 13197.900
446950/758000 (epoch 1179), train_loss = 0.284, time/batch = 0.029, All_Time = 13199.363
447000/758000 (epoch 1179), train_loss = 0.239, time/batch = 0.029, All_Time = 13200.827
model saved to NER/polyglot/model.ckpt
447050/758000 (epoch 1179), train_loss = 0.267, time/batch = 0.028, All_Time = 13202.290
447100/758000 (epoch 1179), train_loss = 0.256, time/batch = 0.029, All_Time = 13203.767
447150/758000 (epoch 1179), train_loss = 0.236, time/batch = 0.031, All_Time = 13205.241
447200/758000 (epoch 1179), train_loss = 0.268, time/batch = 0.028, All_Time = 13206.725
447250/758000 (epoch 1180), train_loss = 0.226, time/batch = 0.029, All_Time = 13208.216
447300/758000 (epoch 1180), train_loss = 0.222, time/batch = 0.029, All_Time = 13209.677
447350/758000 (epoch 1180), train_loss = 0.261, time/batch = 0.029, All_Time = 13211.151
447400/758000 (epoch 1180), train_loss = 0.254, time/batch = 0.029, All_Time = 13212.635
447450/758000 (epoch 1180), train_loss = 0.223, time/batch = 0.030, All_Time = 13214.139
447500/758000 (epoch 1180), train_loss = 0.242, time/batch = 0.029, All_Time = 13215.638
447550/758000 (epoch 1180), train_loss = 0.251, time/batch = 0.029, All_Time = 13217.124
447600/758000 (epoch 1181), train_loss = 0.192, time/batch = 0.031, All_Time = 13218.620
447650/758000 (epoch 1181), train_loss = 0.273, time/batch = 0.029, All_Time = 13220.093
447700/758000 (epoch 1181), train_loss = 0.217, time/batch = 0.030, All_Time = 13221.576
447750/758000 (epoch 1181), train_loss = 0.240, time/batch = 0.030, All_Time = 13223.057
447800/758000 (epoch 1181), train_loss = 0.221, time/batch = 0.028, All_Time = 13224.532
447850/758000 (epoch 1181), train_loss = 0.221, time/batch = 0.030, All_Time = 13226.002
447900/758000 (epoch 1181), train_loss = 0.252, time/batch = 0.029, All_Time = 13227.465
447950/758000 (epoch 1181), train_loss = 0.272, time/batch = 0.029, All_Time = 13228.950
448000/758000 (epoch 1182), train_loss = 0.222, time/batch = 0.029, All_Time = 13230.447
model saved to NER/polyglot/model.ckpt
448050/758000 (epoch 1182), train_loss = 0.279, time/batch = 0.029, All_Time = 13231.918
448100/758000 (epoch 1182), train_loss = 0.242, time/batch = 0.029, All_Time = 13233.384
448150/758000 (epoch 1182), train_loss = 0.274, time/batch = 0.031, All_Time = 13234.851
448200/758000 (epoch 1182), train_loss = 0.262, time/batch = 0.029, All_Time = 13236.358
448250/758000 (epoch 1182), train_loss = 0.197, time/batch = 0.029, All_Time = 13237.841
448300/758000 (epoch 1182), train_loss = 0.233, time/batch = 0.029, All_Time = 13239.330
448350/758000 (epoch 1182), train_loss = 0.281, time/batch = 0.029, All_Time = 13240.833
448400/758000 (epoch 1183), train_loss = 0.246, time/batch = 0.028, All_Time = 13242.313
448450/758000 (epoch 1183), train_loss = 0.212, time/batch = 0.029, All_Time = 13243.775
448500/758000 (epoch 1183), train_loss = 0.255, time/batch = 0.031, All_Time = 13245.252
448550/758000 (epoch 1183), train_loss = 0.271, time/batch = 0.031, All_Time = 13246.720
448600/758000 (epoch 1183), train_loss = 0.203, time/batch = 0.028, All_Time = 13248.192
448650/758000 (epoch 1183), train_loss = 0.226, time/batch = 0.029, All_Time = 13249.664
448700/758000 (epoch 1183), train_loss = 0.254, time/batch = 0.029, All_Time = 13251.144
448750/758000 (epoch 1184), train_loss = 0.219, time/batch = 0.031, All_Time = 13252.635
448800/758000 (epoch 1184), train_loss = 0.265, time/batch = 0.029, All_Time = 13254.102
448850/758000 (epoch 1184), train_loss = 0.227, time/batch = 0.029, All_Time = 13255.580
448900/758000 (epoch 1184), train_loss = 0.213, time/batch = 0.030, All_Time = 13257.048
448950/758000 (epoch 1184), train_loss = 0.224, time/batch = 0.031, All_Time = 13258.527
449000/758000 (epoch 1184), train_loss = 0.213, time/batch = 0.030, All_Time = 13259.989
model saved to NER/polyglot/model.ckpt
449050/758000 (epoch 1184), train_loss = 0.230, time/batch = 0.031, All_Time = 13261.455
449100/758000 (epoch 1184), train_loss = 0.223, time/batch = 0.031, All_Time = 13262.957
449150/758000 (epoch 1185), train_loss = 0.275, time/batch = 0.029, All_Time = 13264.444
449200/758000 (epoch 1185), train_loss = 0.229, time/batch = 0.030, All_Time = 13265.918
449250/758000 (epoch 1185), train_loss = 0.270, time/batch = 0.030, All_Time = 13267.397
449300/758000 (epoch 1185), train_loss = 0.273, time/batch = 0.029, All_Time = 13268.868
449350/758000 (epoch 1185), train_loss = 0.233, time/batch = 0.030, All_Time = 13270.342
449400/758000 (epoch 1185), train_loss = 0.268, time/batch = 0.029, All_Time = 13271.836
449450/758000 (epoch 1185), train_loss = 0.280, time/batch = 0.030, All_Time = 13273.332
449500/758000 (epoch 1186), train_loss = 0.239, time/batch = 0.029, All_Time = 13274.838
449550/758000 (epoch 1186), train_loss = 0.218, time/batch = 0.029, All_Time = 13276.307
449600/758000 (epoch 1186), train_loss = 0.243, time/batch = 0.031, All_Time = 13277.781
449650/758000 (epoch 1186), train_loss = 0.244, time/batch = 0.028, All_Time = 13279.251
449700/758000 (epoch 1186), train_loss = 0.243, time/batch = 0.029, All_Time = 13280.719
449750/758000 (epoch 1186), train_loss = 0.244, time/batch = 0.029, All_Time = 13282.197
449800/758000 (epoch 1186), train_loss = 0.213, time/batch = 0.030, All_Time = 13283.668
449850/758000 (epoch 1186), train_loss = 0.289, time/batch = 0.031, All_Time = 13285.140
449900/758000 (epoch 1187), train_loss = 0.237, time/batch = 0.031, All_Time = 13286.647
449950/758000 (epoch 1187), train_loss = 0.246, time/batch = 0.030, All_Time = 13288.121
450000/758000 (epoch 1187), train_loss = 0.288, time/batch = 0.030, All_Time = 13289.601
model saved to NER/polyglot/model.ckpt
450050/758000 (epoch 1187), train_loss = 0.257, time/batch = 0.029, All_Time = 13291.067
450100/758000 (epoch 1187), train_loss = 0.218, time/batch = 0.030, All_Time = 13292.539
450150/758000 (epoch 1187), train_loss = 0.238, time/batch = 0.028, All_Time = 13293.998
450200/758000 (epoch 1187), train_loss = 0.251, time/batch = 0.029, All_Time = 13295.478
450250/758000 (epoch 1187), train_loss = 0.251, time/batch = 0.028, All_Time = 13296.953
450300/758000 (epoch 1188), train_loss = 0.252, time/batch = 0.029, All_Time = 13298.444
450350/758000 (epoch 1188), train_loss = 0.280, time/batch = 0.029, All_Time = 13299.909
450400/758000 (epoch 1188), train_loss = 0.242, time/batch = 0.030, All_Time = 13301.396
450450/758000 (epoch 1188), train_loss = 0.250, time/batch = 0.029, All_Time = 13302.874
450500/758000 (epoch 1188), train_loss = 0.239, time/batch = 0.030, All_Time = 13304.355
450550/758000 (epoch 1188), train_loss = 0.239, time/batch = 0.031, All_Time = 13305.836
450600/758000 (epoch 1188), train_loss = 0.250, time/batch = 0.029, All_Time = 13307.326
450650/758000 (epoch 1189), train_loss = 0.221, time/batch = 0.030, All_Time = 13308.816
450700/758000 (epoch 1189), train_loss = 0.219, time/batch = 0.029, All_Time = 13310.292
450750/758000 (epoch 1189), train_loss = 0.246, time/batch = 0.030, All_Time = 13311.775
450800/758000 (epoch 1189), train_loss = 0.262, time/batch = 0.029, All_Time = 13313.239
450850/758000 (epoch 1189), train_loss = 0.260, time/batch = 0.029, All_Time = 13314.707
450900/758000 (epoch 1189), train_loss = 0.241, time/batch = 0.029, All_Time = 13316.167
450950/758000 (epoch 1189), train_loss = 0.210, time/batch = 0.029, All_Time = 13317.651
451000/758000 (epoch 1189), train_loss = 0.239, time/batch = 0.031, All_Time = 13319.147
model saved to NER/polyglot/model.ckpt
451050/758000 (epoch 1190), train_loss = 0.230, time/batch = 0.030, All_Time = 13320.641
451100/758000 (epoch 1190), train_loss = 0.226, time/batch = 0.032, All_Time = 13322.108
451150/758000 (epoch 1190), train_loss = 0.264, time/batch = 0.029, All_Time = 13323.568
451200/758000 (epoch 1190), train_loss = 0.240, time/batch = 0.029, All_Time = 13325.034
451250/758000 (epoch 1190), train_loss = 0.253, time/batch = 0.030, All_Time = 13326.496
451300/758000 (epoch 1190), train_loss = 0.251, time/batch = 0.028, All_Time = 13327.967
451350/758000 (epoch 1190), train_loss = 0.248, time/batch = 0.029, All_Time = 13329.438
451400/758000 (epoch 1191), train_loss = 0.216, time/batch = 0.030, All_Time = 13330.941
451450/758000 (epoch 1191), train_loss = 0.233, time/batch = 0.030, All_Time = 13332.412
451500/758000 (epoch 1191), train_loss = 0.250, time/batch = 0.029, All_Time = 13333.914
451550/758000 (epoch 1191), train_loss = 0.241, time/batch = 0.030, All_Time = 13335.417
451600/758000 (epoch 1191), train_loss = 0.243, time/batch = 0.031, All_Time = 13336.903
451650/758000 (epoch 1191), train_loss = 0.242, time/batch = 0.029, All_Time = 13338.386
451700/758000 (epoch 1191), train_loss = 0.230, time/batch = 0.032, All_Time = 13339.867
451750/758000 (epoch 1191), train_loss = 0.259, time/batch = 0.030, All_Time = 13341.353
451800/758000 (epoch 1192), train_loss = 0.250, time/batch = 0.030, All_Time = 13342.849
451850/758000 (epoch 1192), train_loss = 0.253, time/batch = 0.029, All_Time = 13344.326
451900/758000 (epoch 1192), train_loss = 0.245, time/batch = 0.030, All_Time = 13345.801
451950/758000 (epoch 1192), train_loss = 0.231, time/batch = 0.030, All_Time = 13347.273
452000/758000 (epoch 1192), train_loss = 0.228, time/batch = 0.032, All_Time = 13348.743
model saved to NER/polyglot/model.ckpt
452050/758000 (epoch 1192), train_loss = 0.238, time/batch = 0.029, All_Time = 13350.213
452100/758000 (epoch 1192), train_loss = 0.268, time/batch = 0.030, All_Time = 13351.672
452150/758000 (epoch 1193), train_loss = 0.248, time/batch = 0.030, All_Time = 13353.173
452200/758000 (epoch 1193), train_loss = 0.280, time/batch = 0.029, All_Time = 13354.644
452250/758000 (epoch 1193), train_loss = 0.242, time/batch = 0.029, All_Time = 13356.112
452300/758000 (epoch 1193), train_loss = 0.258, time/batch = 0.030, All_Time = 13357.582
452350/758000 (epoch 1193), train_loss = 0.224, time/batch = 0.030, All_Time = 13359.071
452400/758000 (epoch 1193), train_loss = 0.243, time/batch = 0.031, All_Time = 13360.563
452450/758000 (epoch 1193), train_loss = 0.219, time/batch = 0.031, All_Time = 13362.054
452500/758000 (epoch 1193), train_loss = 0.232, time/batch = 0.031, All_Time = 13363.549
452550/758000 (epoch 1194), train_loss = 0.237, time/batch = 0.030, All_Time = 13365.016
452600/758000 (epoch 1194), train_loss = 0.239, time/batch = 0.030, All_Time = 13366.486
452650/758000 (epoch 1194), train_loss = 0.293, time/batch = 0.029, All_Time = 13367.946
452700/758000 (epoch 1194), train_loss = 0.318, time/batch = 0.028, All_Time = 13369.408
452750/758000 (epoch 1194), train_loss = 0.196, time/batch = 0.030, All_Time = 13370.894
452800/758000 (epoch 1194), train_loss = 0.213, time/batch = 0.029, All_Time = 13372.380
452850/758000 (epoch 1194), train_loss = 0.250, time/batch = 0.031, All_Time = 13373.876
452900/758000 (epoch 1194), train_loss = 0.297, time/batch = 0.030, All_Time = 13375.371
452950/758000 (epoch 1195), train_loss = 0.226, time/batch = 0.029, All_Time = 13376.851
453000/758000 (epoch 1195), train_loss = 0.259, time/batch = 0.029, All_Time = 13378.322
model saved to NER/polyglot/model.ckpt
453050/758000 (epoch 1195), train_loss = 0.223, time/batch = 0.029, All_Time = 13379.792
453100/758000 (epoch 1195), train_loss = 0.239, time/batch = 0.030, All_Time = 13381.248
453150/758000 (epoch 1195), train_loss = 0.212, time/batch = 0.029, All_Time = 13382.710
453200/758000 (epoch 1195), train_loss = 0.243, time/batch = 0.031, All_Time = 13384.187
453250/758000 (epoch 1195), train_loss = 0.215, time/batch = 0.031, All_Time = 13385.688
453300/758000 (epoch 1196), train_loss = 0.228, time/batch = 0.029, All_Time = 13387.187
453350/758000 (epoch 1196), train_loss = 0.252, time/batch = 0.029, All_Time = 13388.671
453400/758000 (epoch 1196), train_loss = 0.260, time/batch = 0.030, All_Time = 13390.144
453450/758000 (epoch 1196), train_loss = 0.228, time/batch = 0.029, All_Time = 13391.607
453500/758000 (epoch 1196), train_loss = 0.236, time/batch = 0.029, All_Time = 13393.082
453550/758000 (epoch 1196), train_loss = 0.271, time/batch = 0.030, All_Time = 13394.556
453600/758000 (epoch 1196), train_loss = 0.238, time/batch = 0.030, All_Time = 13396.034
453650/758000 (epoch 1196), train_loss = 0.268, time/batch = 0.029, All_Time = 13397.498
453700/758000 (epoch 1197), train_loss = 0.248, time/batch = 0.028, All_Time = 13398.987
453750/758000 (epoch 1197), train_loss = 0.249, time/batch = 0.029, All_Time = 13400.449
453800/758000 (epoch 1197), train_loss = 0.240, time/batch = 0.030, All_Time = 13401.951
453850/758000 (epoch 1197), train_loss = 0.247, time/batch = 0.031, All_Time = 13403.451
453900/758000 (epoch 1197), train_loss = 0.235, time/batch = 0.030, All_Time = 13404.939
453950/758000 (epoch 1197), train_loss = 0.247, time/batch = 0.033, All_Time = 13406.428
454000/758000 (epoch 1197), train_loss = 0.251, time/batch = 0.030, All_Time = 13407.913
model saved to NER/polyglot/model.ckpt
454050/758000 (epoch 1198), train_loss = 0.242, time/batch = 0.030, All_Time = 13409.392
454100/758000 (epoch 1198), train_loss = 0.276, time/batch = 0.029, All_Time = 13410.861
454150/758000 (epoch 1198), train_loss = 0.256, time/batch = 0.031, All_Time = 13412.328
454200/758000 (epoch 1198), train_loss = 0.258, time/batch = 0.032, All_Time = 13413.816
454250/758000 (epoch 1198), train_loss = 0.213, time/batch = 0.030, All_Time = 13415.311
454300/758000 (epoch 1198), train_loss = 0.237, time/batch = 0.030, All_Time = 13416.854
454350/758000 (epoch 1198), train_loss = 0.249, time/batch = 0.030, All_Time = 13418.355
454400/758000 (epoch 1198), train_loss = 0.251, time/batch = 0.029, All_Time = 13419.848
454450/758000 (epoch 1199), train_loss = 0.232, time/batch = 0.031, All_Time = 13421.344
454500/758000 (epoch 1199), train_loss = 0.255, time/batch = 0.029, All_Time = 13422.806
454550/758000 (epoch 1199), train_loss = 0.265, time/batch = 0.029, All_Time = 13424.281
454600/758000 (epoch 1199), train_loss = 0.229, time/batch = 0.029, All_Time = 13425.750
454650/758000 (epoch 1199), train_loss = 0.263, time/batch = 0.029, All_Time = 13427.264
454700/758000 (epoch 1199), train_loss = 0.217, time/batch = 0.029, All_Time = 13428.753
454750/758000 (epoch 1199), train_loss = 0.248, time/batch = 0.030, All_Time = 13430.242
454800/758000 (epoch 1200), train_loss = 0.059, time/batch = 0.041, All_Time = 13431.740
454850/758000 (epoch 1200), train_loss = 0.250, time/batch = 0.029, All_Time = 13433.216
454900/758000 (epoch 1200), train_loss = 0.223, time/batch = 0.029, All_Time = 13434.687
454950/758000 (epoch 1200), train_loss = 0.250, time/batch = 0.028, All_Time = 13436.161
455000/758000 (epoch 1200), train_loss = 0.231, time/batch = 0.029, All_Time = 13437.638
model saved to NER/polyglot/model.ckpt
455050/758000 (epoch 1200), train_loss = 0.250, time/batch = 0.029, All_Time = 13439.109
455100/758000 (epoch 1200), train_loss = 0.232, time/batch = 0.028, All_Time = 13440.575
455150/758000 (epoch 1200), train_loss = 0.230, time/batch = 0.028, All_Time = 13442.032
455200/758000 (epoch 1201), train_loss = 0.224, time/batch = 0.031, All_Time = 13443.538
455250/758000 (epoch 1201), train_loss = 0.233, time/batch = 0.029, All_Time = 13445.018
455300/758000 (epoch 1201), train_loss = 0.224, time/batch = 0.029, All_Time = 13446.492
455350/758000 (epoch 1201), train_loss = 0.262, time/batch = 0.029, All_Time = 13447.968
455400/758000 (epoch 1201), train_loss = 0.220, time/batch = 0.031, All_Time = 13449.465
455450/758000 (epoch 1201), train_loss = 0.228, time/batch = 0.030, All_Time = 13450.946
455500/758000 (epoch 1201), train_loss = 0.280, time/batch = 0.029, All_Time = 13452.419
455550/758000 (epoch 1201), train_loss = 0.272, time/batch = 0.029, All_Time = 13453.891
455600/758000 (epoch 1202), train_loss = 0.230, time/batch = 0.030, All_Time = 13455.369
455650/758000 (epoch 1202), train_loss = 0.224, time/batch = 0.029, All_Time = 13456.855
455700/758000 (epoch 1202), train_loss = 0.201, time/batch = 0.029, All_Time = 13458.324
455750/758000 (epoch 1202), train_loss = 0.270, time/batch = 0.029, All_Time = 13459.794
455800/758000 (epoch 1202), train_loss = 0.259, time/batch = 0.029, All_Time = 13461.267
455850/758000 (epoch 1202), train_loss = 0.209, time/batch = 0.029, All_Time = 13462.748
455900/758000 (epoch 1202), train_loss = 0.218, time/batch = 0.030, All_Time = 13464.234
455950/758000 (epoch 1203), train_loss = 0.229, time/batch = 0.030, All_Time = 13465.733
456000/758000 (epoch 1203), train_loss = 0.283, time/batch = 0.030, All_Time = 13467.221
model saved to NER/polyglot/model.ckpt
456050/758000 (epoch 1203), train_loss = 0.231, time/batch = 0.029, All_Time = 13468.693
456100/758000 (epoch 1203), train_loss = 0.307, time/batch = 0.029, All_Time = 13470.169
456150/758000 (epoch 1203), train_loss = 0.221, time/batch = 0.030, All_Time = 13471.670
456200/758000 (epoch 1203), train_loss = 0.208, time/batch = 0.030, All_Time = 13473.161
456250/758000 (epoch 1203), train_loss = 0.247, time/batch = 0.029, All_Time = 13474.655
456300/758000 (epoch 1203), train_loss = 0.252, time/batch = 0.029, All_Time = 13476.143
456350/758000 (epoch 1204), train_loss = 0.264, time/batch = 0.029, All_Time = 13477.634
456400/758000 (epoch 1204), train_loss = 0.229, time/batch = 0.029, All_Time = 13479.098
456450/758000 (epoch 1204), train_loss = 0.242, time/batch = 0.030, All_Time = 13480.570
456500/758000 (epoch 1204), train_loss = 0.267, time/batch = 0.030, All_Time = 13482.042
456550/758000 (epoch 1204), train_loss = 0.249, time/batch = 0.029, All_Time = 13483.522
456600/758000 (epoch 1204), train_loss = 0.237, time/batch = 0.029, All_Time = 13485.000
456650/758000 (epoch 1204), train_loss = 0.276, time/batch = 0.030, All_Time = 13486.476
456700/758000 (epoch 1205), train_loss = 0.256, time/batch = 0.032, All_Time = 13488.008
456750/758000 (epoch 1205), train_loss = 0.222, time/batch = 0.030, All_Time = 13489.488
456800/758000 (epoch 1205), train_loss = 0.266, time/batch = 0.029, All_Time = 13490.960
456850/758000 (epoch 1205), train_loss = 0.216, time/batch = 0.029, All_Time = 13492.437
456900/758000 (epoch 1205), train_loss = 0.223, time/batch = 0.032, All_Time = 13493.913
456950/758000 (epoch 1205), train_loss = 0.261, time/batch = 0.030, All_Time = 13495.388
457000/758000 (epoch 1205), train_loss = 0.238, time/batch = 0.029, All_Time = 13496.874
model saved to NER/polyglot/model.ckpt
457050/758000 (epoch 1205), train_loss = 0.264, time/batch = 0.030, All_Time = 13498.352
457100/758000 (epoch 1206), train_loss = 0.223, time/batch = 0.030, All_Time = 13499.833
457150/758000 (epoch 1206), train_loss = 0.231, time/batch = 0.030, All_Time = 13501.298
457200/758000 (epoch 1206), train_loss = 0.238, time/batch = 0.030, All_Time = 13502.770
457250/758000 (epoch 1206), train_loss = 0.266, time/batch = 0.030, All_Time = 13504.236
457300/758000 (epoch 1206), train_loss = 0.239, time/batch = 0.029, All_Time = 13505.696
457350/758000 (epoch 1206), train_loss = 0.226, time/batch = 0.030, All_Time = 13507.175
457400/758000 (epoch 1206), train_loss = 0.276, time/batch = 0.032, All_Time = 13508.689
457450/758000 (epoch 1206), train_loss = 0.240, time/batch = 0.030, All_Time = 13510.164
457500/758000 (epoch 1207), train_loss = 0.281, time/batch = 0.031, All_Time = 13511.655
457550/758000 (epoch 1207), train_loss = 0.257, time/batch = 0.030, All_Time = 13513.115
457600/758000 (epoch 1207), train_loss = 0.240, time/batch = 0.030, All_Time = 13514.574
457650/758000 (epoch 1207), train_loss = 0.231, time/batch = 0.030, All_Time = 13516.037
457700/758000 (epoch 1207), train_loss = 0.217, time/batch = 0.029, All_Time = 13517.503
457750/758000 (epoch 1207), train_loss = 0.224, time/batch = 0.030, All_Time = 13518.965
457800/758000 (epoch 1207), train_loss = 0.215, time/batch = 0.029, All_Time = 13520.439
457850/758000 (epoch 1208), train_loss = 0.249, time/batch = 0.028, All_Time = 13521.930
457900/758000 (epoch 1208), train_loss = 0.211, time/batch = 0.029, All_Time = 13523.403
457950/758000 (epoch 1208), train_loss = 0.245, time/batch = 0.031, All_Time = 13524.923
458000/758000 (epoch 1208), train_loss = 0.217, time/batch = 0.029, All_Time = 13526.400
model saved to NER/polyglot/model.ckpt
458050/758000 (epoch 1208), train_loss = 0.233, time/batch = 0.029, All_Time = 13527.878
458100/758000 (epoch 1208), train_loss = 0.228, time/batch = 0.030, All_Time = 13529.352
458150/758000 (epoch 1208), train_loss = 0.248, time/batch = 0.029, All_Time = 13530.825
458200/758000 (epoch 1208), train_loss = 0.229, time/batch = 0.029, All_Time = 13532.294
458250/758000 (epoch 1209), train_loss = 0.218, time/batch = 0.030, All_Time = 13533.769
458300/758000 (epoch 1209), train_loss = 0.237, time/batch = 0.028, All_Time = 13535.232
458350/758000 (epoch 1209), train_loss = 0.212, time/batch = 0.031, All_Time = 13536.736
458400/758000 (epoch 1209), train_loss = 0.266, time/batch = 0.029, All_Time = 13538.217
458450/758000 (epoch 1209), train_loss = 0.255, time/batch = 0.029, All_Time = 13539.693
458500/758000 (epoch 1209), train_loss = 0.232, time/batch = 0.030, All_Time = 13541.167
458550/758000 (epoch 1209), train_loss = 0.262, time/batch = 0.030, All_Time = 13542.645
458600/758000 (epoch 1210), train_loss = 0.282, time/batch = 0.030, All_Time = 13544.116
458650/758000 (epoch 1210), train_loss = 0.292, time/batch = 0.029, All_Time = 13545.580
458700/758000 (epoch 1210), train_loss = 0.253, time/batch = 0.029, All_Time = 13547.057
458750/758000 (epoch 1210), train_loss = 0.222, time/batch = 0.030, All_Time = 13548.523
458800/758000 (epoch 1210), train_loss = 0.221, time/batch = 0.031, All_Time = 13549.991
458850/758000 (epoch 1210), train_loss = 0.260, time/batch = 0.031, All_Time = 13551.477
458900/758000 (epoch 1210), train_loss = 0.244, time/batch = 0.031, All_Time = 13552.977
458950/758000 (epoch 1210), train_loss = 0.247, time/batch = 0.030, All_Time = 13554.473
459000/758000 (epoch 1211), train_loss = 0.210, time/batch = 0.029, All_Time = 13555.971
model saved to NER/polyglot/model.ckpt
459050/758000 (epoch 1211), train_loss = 0.265, time/batch = 0.028, All_Time = 13557.451
459100/758000 (epoch 1211), train_loss = 0.229, time/batch = 0.029, All_Time = 13558.924
459150/758000 (epoch 1211), train_loss = 0.232, time/batch = 0.029, All_Time = 13560.395
459200/758000 (epoch 1211), train_loss = 0.230, time/batch = 0.028, All_Time = 13561.872
459250/758000 (epoch 1211), train_loss = 0.253, time/batch = 0.031, All_Time = 13563.351
459300/758000 (epoch 1211), train_loss = 0.258, time/batch = 0.030, All_Time = 13564.832
459350/758000 (epoch 1212), train_loss = 0.196, time/batch = 0.029, All_Time = 13566.304
459400/758000 (epoch 1212), train_loss = 0.254, time/batch = 0.030, All_Time = 13567.784
459450/758000 (epoch 1212), train_loss = 0.281, time/batch = 0.029, All_Time = 13569.255
459500/758000 (epoch 1212), train_loss = 0.235, time/batch = 0.030, All_Time = 13570.731
459550/758000 (epoch 1212), train_loss = 0.247, time/batch = 0.031, All_Time = 13572.215
459600/758000 (epoch 1212), train_loss = 0.251, time/batch = 0.030, All_Time = 13573.852
459650/758000 (epoch 1212), train_loss = 0.203, time/batch = 0.030, All_Time = 13575.335
459700/758000 (epoch 1212), train_loss = 0.268, time/batch = 0.030, All_Time = 13576.832
459750/758000 (epoch 1213), train_loss = 0.233, time/batch = 0.030, All_Time = 13578.344
459800/758000 (epoch 1213), train_loss = 0.241, time/batch = 0.030, All_Time = 13579.823
459850/758000 (epoch 1213), train_loss = 0.252, time/batch = 0.030, All_Time = 13581.288
459900/758000 (epoch 1213), train_loss = 0.258, time/batch = 0.032, All_Time = 13582.762
459950/758000 (epoch 1213), train_loss = 0.243, time/batch = 0.030, All_Time = 13584.240
460000/758000 (epoch 1213), train_loss = 0.243, time/batch = 0.031, All_Time = 13585.719
model saved to NER/polyglot/model.ckpt
460050/758000 (epoch 1213), train_loss = 0.244, time/batch = 0.028, All_Time = 13587.193
460100/758000 (epoch 1213), train_loss = 0.286, time/batch = 0.029, All_Time = 13588.669
460150/758000 (epoch 1214), train_loss = 0.207, time/batch = 0.031, All_Time = 13590.134
460200/758000 (epoch 1214), train_loss = 0.244, time/batch = 0.031, All_Time = 13591.618
460250/758000 (epoch 1214), train_loss = 0.217, time/batch = 0.031, All_Time = 13593.119
460300/758000 (epoch 1214), train_loss = 0.233, time/batch = 0.029, All_Time = 13594.609
460350/758000 (epoch 1214), train_loss = 0.260, time/batch = 0.029, All_Time = 13596.104
460400/758000 (epoch 1214), train_loss = 0.253, time/batch = 0.030, All_Time = 13597.591
460450/758000 (epoch 1214), train_loss = 0.238, time/batch = 0.030, All_Time = 13599.067
460500/758000 (epoch 1215), train_loss = 0.227, time/batch = 0.029, All_Time = 13600.568
460550/758000 (epoch 1215), train_loss = 0.250, time/batch = 0.028, All_Time = 13602.034
460600/758000 (epoch 1215), train_loss = 0.250, time/batch = 0.029, All_Time = 13603.513
460650/758000 (epoch 1215), train_loss = 0.223, time/batch = 0.028, All_Time = 13604.983
460700/758000 (epoch 1215), train_loss = 0.240, time/batch = 0.029, All_Time = 13606.459
460750/758000 (epoch 1215), train_loss = 0.246, time/batch = 0.031, All_Time = 13607.937
460800/758000 (epoch 1215), train_loss = 0.246, time/batch = 0.030, All_Time = 13609.426
460850/758000 (epoch 1215), train_loss = 0.257, time/batch = 0.029, All_Time = 13610.924
460900/758000 (epoch 1216), train_loss = 0.266, time/batch = 0.030, All_Time = 13612.419
460950/758000 (epoch 1216), train_loss = 0.224, time/batch = 0.031, All_Time = 13613.893
461000/758000 (epoch 1216), train_loss = 0.248, time/batch = 0.028, All_Time = 13615.365
model saved to NER/polyglot/model.ckpt
461050/758000 (epoch 1216), train_loss = 0.227, time/batch = 0.031, All_Time = 13616.834
461100/758000 (epoch 1216), train_loss = 0.279, time/batch = 0.029, All_Time = 13618.299
461150/758000 (epoch 1216), train_loss = 0.255, time/batch = 0.030, All_Time = 13619.761
461200/758000 (epoch 1216), train_loss = 0.253, time/batch = 0.030, All_Time = 13621.225
461250/758000 (epoch 1217), train_loss = 0.244, time/batch = 0.029, All_Time = 13622.692
461300/758000 (epoch 1217), train_loss = 0.247, time/batch = 0.031, All_Time = 13624.184
461350/758000 (epoch 1217), train_loss = 0.270, time/batch = 0.030, All_Time = 13625.679
461400/758000 (epoch 1217), train_loss = 0.246, time/batch = 0.031, All_Time = 13627.170
461450/758000 (epoch 1217), train_loss = 0.237, time/batch = 0.030, All_Time = 13628.657
461500/758000 (epoch 1217), train_loss = 0.224, time/batch = 0.030, All_Time = 13630.141
461550/758000 (epoch 1217), train_loss = 0.229, time/batch = 0.029, All_Time = 13631.632
461600/758000 (epoch 1217), train_loss = 0.246, time/batch = 0.031, All_Time = 13633.120
461650/758000 (epoch 1218), train_loss = 0.249, time/batch = 0.030, All_Time = 13634.608
461700/758000 (epoch 1218), train_loss = 0.264, time/batch = 0.029, All_Time = 13636.077
461750/758000 (epoch 1218), train_loss = 0.240, time/batch = 0.031, All_Time = 13637.558
461800/758000 (epoch 1218), train_loss = 0.250, time/batch = 0.030, All_Time = 13639.019
461850/758000 (epoch 1218), train_loss = 0.227, time/batch = 0.029, All_Time = 13640.508
461900/758000 (epoch 1218), train_loss = 0.217, time/batch = 0.029, All_Time = 13642.002
461950/758000 (epoch 1218), train_loss = 0.277, time/batch = 0.031, All_Time = 13643.492
462000/758000 (epoch 1218), train_loss = 0.259, time/batch = 0.031, All_Time = 13644.967
model saved to NER/polyglot/model.ckpt
462050/758000 (epoch 1219), train_loss = 0.269, time/batch = 0.028, All_Time = 13646.439
462100/758000 (epoch 1219), train_loss = 0.296, time/batch = 0.029, All_Time = 13647.901
462150/758000 (epoch 1219), train_loss = 0.228, time/batch = 0.029, All_Time = 13649.364
462200/758000 (epoch 1219), train_loss = 0.220, time/batch = 0.028, All_Time = 13650.824
462250/758000 (epoch 1219), train_loss = 0.257, time/batch = 0.029, All_Time = 13652.282
462300/758000 (epoch 1219), train_loss = 0.255, time/batch = 0.029, All_Time = 13653.772
462350/758000 (epoch 1219), train_loss = 0.237, time/batch = 0.029, All_Time = 13655.271
462400/758000 (epoch 1220), train_loss = 0.225, time/batch = 0.031, All_Time = 13656.748
462450/758000 (epoch 1220), train_loss = 0.234, time/batch = 0.030, All_Time = 13658.216
462500/758000 (epoch 1220), train_loss = 0.243, time/batch = 0.029, All_Time = 13659.678
462550/758000 (epoch 1220), train_loss = 0.234, time/batch = 0.029, All_Time = 13661.136
462600/758000 (epoch 1220), train_loss = 0.223, time/batch = 0.029, All_Time = 13662.608
462650/758000 (epoch 1220), train_loss = 0.239, time/batch = 0.030, All_Time = 13664.083
462700/758000 (epoch 1220), train_loss = 0.264, time/batch = 0.031, All_Time = 13665.576
462750/758000 (epoch 1220), train_loss = 0.244, time/batch = 0.029, All_Time = 13667.062
462800/758000 (epoch 1221), train_loss = 0.257, time/batch = 0.028, All_Time = 13668.535
462850/758000 (epoch 1221), train_loss = 0.287, time/batch = 0.029, All_Time = 13670.002
462900/758000 (epoch 1221), train_loss = 0.255, time/batch = 0.030, All_Time = 13671.507
462950/758000 (epoch 1221), train_loss = 0.248, time/batch = 0.030, All_Time = 13673.002
463000/758000 (epoch 1221), train_loss = 0.212, time/batch = 0.030, All_Time = 13674.485
model saved to NER/polyglot/model.ckpt
463050/758000 (epoch 1221), train_loss = 0.229, time/batch = 0.029, All_Time = 13675.966
463100/758000 (epoch 1221), train_loss = 0.272, time/batch = 0.028, All_Time = 13677.439
463150/758000 (epoch 1222), train_loss = 0.249, time/batch = 0.031, All_Time = 13678.904
463200/758000 (epoch 1222), train_loss = 0.227, time/batch = 0.030, All_Time = 13680.378
463250/758000 (epoch 1222), train_loss = 0.267, time/batch = 0.029, All_Time = 13681.844
463300/758000 (epoch 1222), train_loss = 0.239, time/batch = 0.030, All_Time = 13683.315
463350/758000 (epoch 1222), train_loss = 0.247, time/batch = 0.029, All_Time = 13684.777
463400/758000 (epoch 1222), train_loss = 0.241, time/batch = 0.031, All_Time = 13686.258
463450/758000 (epoch 1222), train_loss = 0.274, time/batch = 0.029, All_Time = 13687.726
463500/758000 (epoch 1222), train_loss = 0.279, time/batch = 0.030, All_Time = 13689.213
463550/758000 (epoch 1223), train_loss = 0.238, time/batch = 0.030, All_Time = 13690.692
463600/758000 (epoch 1223), train_loss = 0.248, time/batch = 0.029, All_Time = 13692.158
463650/758000 (epoch 1223), train_loss = 0.299, time/batch = 0.030, All_Time = 13693.648
463700/758000 (epoch 1223), train_loss = 0.230, time/batch = 0.029, All_Time = 13695.131
463750/758000 (epoch 1223), train_loss = 0.216, time/batch = 0.031, All_Time = 13696.615
463800/758000 (epoch 1223), train_loss = 0.244, time/batch = 0.029, All_Time = 13698.099
463850/758000 (epoch 1223), train_loss = 0.274, time/batch = 0.030, All_Time = 13699.586
463900/758000 (epoch 1224), train_loss = 0.221, time/batch = 0.030, All_Time = 13701.079
463950/758000 (epoch 1224), train_loss = 0.257, time/batch = 0.030, All_Time = 13702.554
464000/758000 (epoch 1224), train_loss = 0.241, time/batch = 0.029, All_Time = 13704.022
model saved to NER/polyglot/model.ckpt
464050/758000 (epoch 1224), train_loss = 0.240, time/batch = 0.029, All_Time = 13705.498
464100/758000 (epoch 1224), train_loss = 0.256, time/batch = 0.029, All_Time = 13706.966
464150/758000 (epoch 1224), train_loss = 0.219, time/batch = 0.029, All_Time = 13708.446
464200/758000 (epoch 1224), train_loss = 0.224, time/batch = 0.029, All_Time = 13709.948
464250/758000 (epoch 1224), train_loss = 0.257, time/batch = 0.031, All_Time = 13711.430
464300/758000 (epoch 1225), train_loss = 0.255, time/batch = 0.030, All_Time = 13712.914
464350/758000 (epoch 1225), train_loss = 0.267, time/batch = 0.028, All_Time = 13714.377
464400/758000 (epoch 1225), train_loss = 0.269, time/batch = 0.029, All_Time = 13715.839
464450/758000 (epoch 1225), train_loss = 0.228, time/batch = 0.030, All_Time = 13717.315
464500/758000 (epoch 1225), train_loss = 0.234, time/batch = 0.028, All_Time = 13718.797
464550/758000 (epoch 1225), train_loss = 0.245, time/batch = 0.031, All_Time = 13720.277
464600/758000 (epoch 1225), train_loss = 0.279, time/batch = 0.030, All_Time = 13721.769
464650/758000 (epoch 1225), train_loss = 0.240, time/batch = 0.031, All_Time = 13723.260
464700/758000 (epoch 1226), train_loss = 0.236, time/batch = 0.029, All_Time = 13724.729
464750/758000 (epoch 1226), train_loss = 0.234, time/batch = 0.030, All_Time = 13726.197
464800/758000 (epoch 1226), train_loss = 0.233, time/batch = 0.029, All_Time = 13727.670
464850/758000 (epoch 1226), train_loss = 0.276, time/batch = 0.031, All_Time = 13729.146
464900/758000 (epoch 1226), train_loss = 0.206, time/batch = 0.029, All_Time = 13730.656
464950/758000 (epoch 1226), train_loss = 0.259, time/batch = 0.030, All_Time = 13732.138
465000/758000 (epoch 1226), train_loss = 0.234, time/batch = 0.030, All_Time = 13733.628
model saved to NER/polyglot/model.ckpt
465050/758000 (epoch 1227), train_loss = 0.245, time/batch = 0.030, All_Time = 13735.109
465100/758000 (epoch 1227), train_loss = 0.223, time/batch = 0.030, All_Time = 13736.575
465150/758000 (epoch 1227), train_loss = 0.240, time/batch = 0.029, All_Time = 13738.041
465200/758000 (epoch 1227), train_loss = 0.256, time/batch = 0.032, All_Time = 13739.542
465250/758000 (epoch 1227), train_loss = 0.214, time/batch = 0.029, All_Time = 13741.047
465300/758000 (epoch 1227), train_loss = 0.272, time/batch = 0.029, All_Time = 13742.530
465350/758000 (epoch 1227), train_loss = 0.213, time/batch = 0.029, All_Time = 13744.024
465400/758000 (epoch 1227), train_loss = 0.251, time/batch = 0.029, All_Time = 13745.508
465450/758000 (epoch 1228), train_loss = 0.247, time/batch = 0.030, All_Time = 13746.985
465500/758000 (epoch 1228), train_loss = 0.229, time/batch = 0.029, All_Time = 13748.443
465550/758000 (epoch 1228), train_loss = 0.217, time/batch = 0.029, All_Time = 13749.903
465600/758000 (epoch 1228), train_loss = 0.220, time/batch = 0.030, All_Time = 13751.380
465650/758000 (epoch 1228), train_loss = 0.250, time/batch = 0.029, All_Time = 13752.885
465700/758000 (epoch 1228), train_loss = 0.207, time/batch = 0.030, All_Time = 13754.369
465750/758000 (epoch 1228), train_loss = 0.268, time/batch = 0.031, All_Time = 13755.855
465800/758000 (epoch 1229), train_loss = 0.256, time/batch = 0.028, All_Time = 13757.334
465850/758000 (epoch 1229), train_loss = 0.264, time/batch = 0.029, All_Time = 13758.802
465900/758000 (epoch 1229), train_loss = 0.284, time/batch = 0.030, All_Time = 13760.268
465950/758000 (epoch 1229), train_loss = 0.239, time/batch = 0.029, All_Time = 13761.743
466000/758000 (epoch 1229), train_loss = 0.267, time/batch = 0.029, All_Time = 13763.226
model saved to NER/polyglot/model.ckpt
466050/758000 (epoch 1229), train_loss = 0.256, time/batch = 0.030, All_Time = 13764.707
466100/758000 (epoch 1229), train_loss = 0.236, time/batch = 0.029, All_Time = 13766.165
466150/758000 (epoch 1229), train_loss = 0.268, time/batch = 0.032, All_Time = 13767.656
466200/758000 (epoch 1230), train_loss = 0.226, time/batch = 0.029, All_Time = 13769.155
466250/758000 (epoch 1230), train_loss = 0.222, time/batch = 0.029, All_Time = 13770.629
466300/758000 (epoch 1230), train_loss = 0.261, time/batch = 0.029, All_Time = 13772.096
466350/758000 (epoch 1230), train_loss = 0.254, time/batch = 0.029, All_Time = 13773.567
466400/758000 (epoch 1230), train_loss = 0.223, time/batch = 0.029, All_Time = 13775.033
466450/758000 (epoch 1230), train_loss = 0.242, time/batch = 0.030, All_Time = 13776.524
466500/758000 (epoch 1230), train_loss = 0.251, time/batch = 0.029, All_Time = 13778.016
466550/758000 (epoch 1231), train_loss = 0.192, time/batch = 0.030, All_Time = 13779.493
466600/758000 (epoch 1231), train_loss = 0.273, time/batch = 0.029, All_Time = 13780.964
466650/758000 (epoch 1231), train_loss = 0.217, time/batch = 0.030, All_Time = 13782.429
466700/758000 (epoch 1231), train_loss = 0.240, time/batch = 0.029, All_Time = 13783.909
466750/758000 (epoch 1231), train_loss = 0.221, time/batch = 0.029, All_Time = 13785.398
466800/758000 (epoch 1231), train_loss = 0.221, time/batch = 0.031, All_Time = 13786.891
466850/758000 (epoch 1231), train_loss = 0.252, time/batch = 0.029, All_Time = 13788.385
466900/758000 (epoch 1231), train_loss = 0.272, time/batch = 0.033, All_Time = 13789.870
466950/758000 (epoch 1232), train_loss = 0.222, time/batch = 0.030, All_Time = 13791.348
467000/758000 (epoch 1232), train_loss = 0.279, time/batch = 0.029, All_Time = 13792.814
model saved to NER/polyglot/model.ckpt
467050/758000 (epoch 1232), train_loss = 0.242, time/batch = 0.031, All_Time = 13794.621
467100/758000 (epoch 1232), train_loss = 0.274, time/batch = 0.030, All_Time = 13796.082
467150/758000 (epoch 1232), train_loss = 0.262, time/batch = 0.028, All_Time = 13797.555
467200/758000 (epoch 1232), train_loss = 0.197, time/batch = 0.029, All_Time = 13799.065
467250/758000 (epoch 1232), train_loss = 0.233, time/batch = 0.031, All_Time = 13800.538
467300/758000 (epoch 1232), train_loss = 0.281, time/batch = 0.030, All_Time = 13802.031
467350/758000 (epoch 1233), train_loss = 0.246, time/batch = 0.029, All_Time = 13803.517
467400/758000 (epoch 1233), train_loss = 0.212, time/batch = 0.030, All_Time = 13804.986
467450/758000 (epoch 1233), train_loss = 0.255, time/batch = 0.029, All_Time = 13806.453
467500/758000 (epoch 1233), train_loss = 0.271, time/batch = 0.031, All_Time = 13807.946
467550/758000 (epoch 1233), train_loss = 0.203, time/batch = 0.030, All_Time = 13809.450
467600/758000 (epoch 1233), train_loss = 0.226, time/batch = 0.030, All_Time = 13810.940
467650/758000 (epoch 1233), train_loss = 0.254, time/batch = 0.029, All_Time = 13812.436
467700/758000 (epoch 1234), train_loss = 0.219, time/batch = 0.029, All_Time = 13813.917
467750/758000 (epoch 1234), train_loss = 0.265, time/batch = 0.029, All_Time = 13815.400
467800/758000 (epoch 1234), train_loss = 0.227, time/batch = 0.028, All_Time = 13816.866
467850/758000 (epoch 1234), train_loss = 0.213, time/batch = 0.030, All_Time = 13818.331
467900/758000 (epoch 1234), train_loss = 0.224, time/batch = 0.029, All_Time = 13819.801
467950/758000 (epoch 1234), train_loss = 0.213, time/batch = 0.029, All_Time = 13821.266
468000/758000 (epoch 1234), train_loss = 0.230, time/batch = 0.030, All_Time = 13822.732
model saved to NER/polyglot/model.ckpt
468050/758000 (epoch 1234), train_loss = 0.223, time/batch = 0.030, All_Time = 13824.230
468100/758000 (epoch 1235), train_loss = 0.275, time/batch = 0.029, All_Time = 13825.711
468150/758000 (epoch 1235), train_loss = 0.229, time/batch = 0.032, All_Time = 13827.192
468200/758000 (epoch 1235), train_loss = 0.270, time/batch = 0.029, All_Time = 13828.664
468250/758000 (epoch 1235), train_loss = 0.273, time/batch = 0.030, All_Time = 13830.144
468300/758000 (epoch 1235), train_loss = 0.233, time/batch = 0.029, All_Time = 13831.618
468350/758000 (epoch 1235), train_loss = 0.268, time/batch = 0.029, All_Time = 13833.096
468400/758000 (epoch 1235), train_loss = 0.280, time/batch = 0.030, All_Time = 13834.575
468450/758000 (epoch 1236), train_loss = 0.239, time/batch = 0.031, All_Time = 13836.066
468500/758000 (epoch 1236), train_loss = 0.218, time/batch = 0.030, All_Time = 13837.547
468550/758000 (epoch 1236), train_loss = 0.243, time/batch = 0.029, All_Time = 13839.015
468600/758000 (epoch 1236), train_loss = 0.244, time/batch = 0.030, All_Time = 13840.495
468650/758000 (epoch 1236), train_loss = 0.243, time/batch = 0.030, All_Time = 13841.981
468700/758000 (epoch 1236), train_loss = 0.244, time/batch = 0.029, All_Time = 13843.466
468750/758000 (epoch 1236), train_loss = 0.213, time/batch = 0.030, All_Time = 13844.950
468800/758000 (epoch 1236), train_loss = 0.289, time/batch = 0.030, All_Time = 13846.434
468850/758000 (epoch 1237), train_loss = 0.237, time/batch = 0.029, All_Time = 13847.902
468900/758000 (epoch 1237), train_loss = 0.246, time/batch = 0.029, All_Time = 13849.373
468950/758000 (epoch 1237), train_loss = 0.288, time/batch = 0.029, All_Time = 13850.838
469000/758000 (epoch 1237), train_loss = 0.257, time/batch = 0.030, All_Time = 13852.310
model saved to NER/polyglot/model.ckpt
469050/758000 (epoch 1237), train_loss = 0.218, time/batch = 0.029, All_Time = 13853.780
469100/758000 (epoch 1237), train_loss = 0.238, time/batch = 0.031, All_Time = 13855.267
469150/758000 (epoch 1237), train_loss = 0.251, time/batch = 0.031, All_Time = 13856.787
469200/758000 (epoch 1237), train_loss = 0.251, time/batch = 0.030, All_Time = 13858.270
469250/758000 (epoch 1238), train_loss = 0.252, time/batch = 0.030, All_Time = 13859.754
469300/758000 (epoch 1238), train_loss = 0.280, time/batch = 0.030, All_Time = 13861.232
469350/758000 (epoch 1238), train_loss = 0.242, time/batch = 0.029, All_Time = 13862.702
469400/758000 (epoch 1238), train_loss = 0.250, time/batch = 0.030, All_Time = 13864.221
469450/758000 (epoch 1238), train_loss = 0.239, time/batch = 0.031, All_Time = 13865.709
469500/758000 (epoch 1238), train_loss = 0.239, time/batch = 0.030, All_Time = 13867.197
469550/758000 (epoch 1238), train_loss = 0.250, time/batch = 0.029, All_Time = 13868.675
469600/758000 (epoch 1239), train_loss = 0.221, time/batch = 0.028, All_Time = 13870.167
469650/758000 (epoch 1239), train_loss = 0.219, time/batch = 0.030, All_Time = 13871.643
469700/758000 (epoch 1239), train_loss = 0.246, time/batch = 0.030, All_Time = 13873.107
469750/758000 (epoch 1239), train_loss = 0.262, time/batch = 0.028, All_Time = 13874.569
469800/758000 (epoch 1239), train_loss = 0.260, time/batch = 0.030, All_Time = 13876.074
469850/758000 (epoch 1239), train_loss = 0.241, time/batch = 0.030, All_Time = 13877.565
469900/758000 (epoch 1239), train_loss = 0.210, time/batch = 0.028, All_Time = 13879.037
469950/758000 (epoch 1239), train_loss = 0.239, time/batch = 0.031, All_Time = 13880.518
470000/758000 (epoch 1240), train_loss = 0.230, time/batch = 0.029, All_Time = 13881.984
model saved to NER/polyglot/model.ckpt
470050/758000 (epoch 1240), train_loss = 0.226, time/batch = 0.028, All_Time = 13883.458
470100/758000 (epoch 1240), train_loss = 0.264, time/batch = 0.028, All_Time = 13884.920
470150/758000 (epoch 1240), train_loss = 0.240, time/batch = 0.031, All_Time = 13886.395
470200/758000 (epoch 1240), train_loss = 0.253, time/batch = 0.031, All_Time = 13887.857
470250/758000 (epoch 1240), train_loss = 0.251, time/batch = 0.028, All_Time = 13889.347
470300/758000 (epoch 1240), train_loss = 0.248, time/batch = 0.031, All_Time = 13890.839
470350/758000 (epoch 1241), train_loss = 0.216, time/batch = 0.029, All_Time = 13892.325
470400/758000 (epoch 1241), train_loss = 0.233, time/batch = 0.029, All_Time = 13893.799
470450/758000 (epoch 1241), train_loss = 0.250, time/batch = 0.029, All_Time = 13895.269
470500/758000 (epoch 1241), train_loss = 0.241, time/batch = 0.029, All_Time = 13896.730
470550/758000 (epoch 1241), train_loss = 0.243, time/batch = 0.030, All_Time = 13898.197
470600/758000 (epoch 1241), train_loss = 0.242, time/batch = 0.029, All_Time = 13899.682
470650/758000 (epoch 1241), train_loss = 0.230, time/batch = 0.031, All_Time = 13901.170
470700/758000 (epoch 1241), train_loss = 0.259, time/batch = 0.030, All_Time = 13902.673
470750/758000 (epoch 1242), train_loss = 0.250, time/batch = 0.029, All_Time = 13904.171
470800/758000 (epoch 1242), train_loss = 0.253, time/batch = 0.031, All_Time = 13905.650
470850/758000 (epoch 1242), train_loss = 0.245, time/batch = 0.029, All_Time = 13907.137
470900/758000 (epoch 1242), train_loss = 0.231, time/batch = 0.029, All_Time = 13908.621
470950/758000 (epoch 1242), train_loss = 0.228, time/batch = 0.029, All_Time = 13910.094
471000/758000 (epoch 1242), train_loss = 0.238, time/batch = 0.030, All_Time = 13911.559
model saved to NER/polyglot/model.ckpt
471050/758000 (epoch 1242), train_loss = 0.268, time/batch = 0.029, All_Time = 13913.041
471100/758000 (epoch 1243), train_loss = 0.248, time/batch = 0.030, All_Time = 13914.515
471150/758000 (epoch 1243), train_loss = 0.280, time/batch = 0.029, All_Time = 13916.018
471200/758000 (epoch 1243), train_loss = 0.242, time/batch = 0.030, All_Time = 13917.511
471250/758000 (epoch 1243), train_loss = 0.258, time/batch = 0.031, All_Time = 13919.008
471300/758000 (epoch 1243), train_loss = 0.224, time/batch = 0.030, All_Time = 13920.499
471350/758000 (epoch 1243), train_loss = 0.243, time/batch = 0.030, All_Time = 13921.978
471400/758000 (epoch 1243), train_loss = 0.219, time/batch = 0.032, All_Time = 13923.520
471450/758000 (epoch 1243), train_loss = 0.232, time/batch = 0.029, All_Time = 13925.030
471500/758000 (epoch 1244), train_loss = 0.237, time/batch = 0.030, All_Time = 13926.500
471550/758000 (epoch 1244), train_loss = 0.239, time/batch = 0.029, All_Time = 13927.970
471600/758000 (epoch 1244), train_loss = 0.293, time/batch = 0.029, All_Time = 13929.432
471650/758000 (epoch 1244), train_loss = 0.318, time/batch = 0.028, All_Time = 13930.899
471700/758000 (epoch 1244), train_loss = 0.196, time/batch = 0.029, All_Time = 13932.355
471750/758000 (epoch 1244), train_loss = 0.213, time/batch = 0.029, All_Time = 13933.838
471800/758000 (epoch 1244), train_loss = 0.250, time/batch = 0.030, All_Time = 13935.311
471850/758000 (epoch 1244), train_loss = 0.297, time/batch = 0.031, All_Time = 13936.791
471900/758000 (epoch 1245), train_loss = 0.226, time/batch = 0.028, All_Time = 13938.276
471950/758000 (epoch 1245), train_loss = 0.259, time/batch = 0.030, All_Time = 13939.747
472000/758000 (epoch 1245), train_loss = 0.223, time/batch = 0.029, All_Time = 13941.231
model saved to NER/polyglot/model.ckpt
472050/758000 (epoch 1245), train_loss = 0.239, time/batch = 0.030, All_Time = 13942.703
472100/758000 (epoch 1245), train_loss = 0.212, time/batch = 0.031, All_Time = 13944.177
472150/758000 (epoch 1245), train_loss = 0.243, time/batch = 0.030, All_Time = 13945.662
472200/758000 (epoch 1245), train_loss = 0.215, time/batch = 0.029, All_Time = 13947.174
472250/758000 (epoch 1246), train_loss = 0.228, time/batch = 0.030, All_Time = 13948.661
472300/758000 (epoch 1246), train_loss = 0.252, time/batch = 0.029, All_Time = 13950.126
472350/758000 (epoch 1246), train_loss = 0.260, time/batch = 0.029, All_Time = 13951.593
472400/758000 (epoch 1246), train_loss = 0.228, time/batch = 0.031, All_Time = 13953.098
472450/758000 (epoch 1246), train_loss = 0.236, time/batch = 0.033, All_Time = 13954.585
472500/758000 (epoch 1246), train_loss = 0.271, time/batch = 0.030, All_Time = 13956.058
472550/758000 (epoch 1246), train_loss = 0.238, time/batch = 0.030, All_Time = 13957.548
472600/758000 (epoch 1246), train_loss = 0.268, time/batch = 0.031, All_Time = 13959.031
472650/758000 (epoch 1247), train_loss = 0.248, time/batch = 0.030, All_Time = 13960.536
472700/758000 (epoch 1247), train_loss = 0.249, time/batch = 0.031, All_Time = 13961.999
472750/758000 (epoch 1247), train_loss = 0.240, time/batch = 0.030, All_Time = 13963.470
472800/758000 (epoch 1247), train_loss = 0.247, time/batch = 0.029, All_Time = 13964.946
472850/758000 (epoch 1247), train_loss = 0.235, time/batch = 0.030, All_Time = 13966.406
472900/758000 (epoch 1247), train_loss = 0.247, time/batch = 0.030, All_Time = 13967.898
472950/758000 (epoch 1247), train_loss = 0.251, time/batch = 0.030, All_Time = 13969.395
473000/758000 (epoch 1248), train_loss = 0.242, time/batch = 0.031, All_Time = 13970.878
model saved to NER/polyglot/model.ckpt
473050/758000 (epoch 1248), train_loss = 0.276, time/batch = 0.029, All_Time = 13972.352
473100/758000 (epoch 1248), train_loss = 0.256, time/batch = 0.030, All_Time = 13973.824
473150/758000 (epoch 1248), train_loss = 0.258, time/batch = 0.029, All_Time = 13975.281
473200/758000 (epoch 1248), train_loss = 0.213, time/batch = 0.029, All_Time = 13976.744
473250/758000 (epoch 1248), train_loss = 0.237, time/batch = 0.029, All_Time = 13978.263
473300/758000 (epoch 1248), train_loss = 0.249, time/batch = 0.030, All_Time = 13979.744
473350/758000 (epoch 1248), train_loss = 0.251, time/batch = 0.030, All_Time = 13981.224
473400/758000 (epoch 1249), train_loss = 0.232, time/batch = 0.029, All_Time = 13982.706
473450/758000 (epoch 1249), train_loss = 0.255, time/batch = 0.030, All_Time = 13984.166
473500/758000 (epoch 1249), train_loss = 0.265, time/batch = 0.030, All_Time = 13985.634
473550/758000 (epoch 1249), train_loss = 0.229, time/batch = 0.029, All_Time = 13987.106
473600/758000 (epoch 1249), train_loss = 0.263, time/batch = 0.029, All_Time = 13988.590
473650/758000 (epoch 1249), train_loss = 0.217, time/batch = 0.029, All_Time = 13990.096
473700/758000 (epoch 1249), train_loss = 0.248, time/batch = 0.028, All_Time = 13991.576
473750/758000 (epoch 1250), train_loss = 0.059, time/batch = 0.030, All_Time = 13993.053
473800/758000 (epoch 1250), train_loss = 0.250, time/batch = 0.031, All_Time = 13994.528
473850/758000 (epoch 1250), train_loss = 0.223, time/batch = 0.029, All_Time = 13996.004
473900/758000 (epoch 1250), train_loss = 0.250, time/batch = 0.031, All_Time = 13997.486
473950/758000 (epoch 1250), train_loss = 0.231, time/batch = 0.030, All_Time = 13998.955
474000/758000 (epoch 1250), train_loss = 0.250, time/batch = 0.029, All_Time = 14000.426
model saved to NER/polyglot/model.ckpt
474050/758000 (epoch 1250), train_loss = 0.232, time/batch = 0.028, All_Time = 14001.898
474100/758000 (epoch 1250), train_loss = 0.230, time/batch = 0.029, All_Time = 14003.373
474150/758000 (epoch 1251), train_loss = 0.224, time/batch = 0.030, All_Time = 14004.847
474200/758000 (epoch 1251), train_loss = 0.233, time/batch = 0.028, All_Time = 14006.317
474250/758000 (epoch 1251), train_loss = 0.224, time/batch = 0.031, All_Time = 14007.810
474300/758000 (epoch 1251), train_loss = 0.262, time/batch = 0.030, All_Time = 14009.308
474350/758000 (epoch 1251), train_loss = 0.220, time/batch = 0.029, All_Time = 14010.787
474400/758000 (epoch 1251), train_loss = 0.228, time/batch = 0.029, All_Time = 14012.270
474450/758000 (epoch 1251), train_loss = 0.280, time/batch = 0.030, All_Time = 14013.750
474500/758000 (epoch 1251), train_loss = 0.272, time/batch = 0.029, All_Time = 14015.228
474550/758000 (epoch 1252), train_loss = 0.230, time/batch = 0.030, All_Time = 14016.702
474600/758000 (epoch 1252), train_loss = 0.224, time/batch = 0.029, All_Time = 14018.177
474650/758000 (epoch 1252), train_loss = 0.201, time/batch = 0.030, All_Time = 14019.652
474700/758000 (epoch 1252), train_loss = 0.270, time/batch = 0.029, All_Time = 14021.133
474750/758000 (epoch 1252), train_loss = 0.259, time/batch = 0.029, All_Time = 14022.603
474800/758000 (epoch 1252), train_loss = 0.209, time/batch = 0.030, All_Time = 14024.096
474850/758000 (epoch 1252), train_loss = 0.218, time/batch = 0.028, All_Time = 14025.592
474900/758000 (epoch 1253), train_loss = 0.229, time/batch = 0.029, All_Time = 14027.083
474950/758000 (epoch 1253), train_loss = 0.283, time/batch = 0.030, All_Time = 14028.561
475000/758000 (epoch 1253), train_loss = 0.231, time/batch = 0.030, All_Time = 14030.025
model saved to NER/polyglot/model.ckpt
475050/758000 (epoch 1253), train_loss = 0.307, time/batch = 0.029, All_Time = 14031.496
475100/758000 (epoch 1253), train_loss = 0.221, time/batch = 0.031, All_Time = 14032.964
475150/758000 (epoch 1253), train_loss = 0.208, time/batch = 0.030, All_Time = 14034.428
475200/758000 (epoch 1253), train_loss = 0.247, time/batch = 0.029, All_Time = 14035.888
475250/758000 (epoch 1253), train_loss = 0.252, time/batch = 0.031, All_Time = 14037.419
475300/758000 (epoch 1254), train_loss = 0.264, time/batch = 0.030, All_Time = 14038.924
475350/758000 (epoch 1254), train_loss = 0.229, time/batch = 0.030, All_Time = 14040.400
475400/758000 (epoch 1254), train_loss = 0.242, time/batch = 0.030, All_Time = 14041.916
475450/758000 (epoch 1254), train_loss = 0.267, time/batch = 0.030, All_Time = 14043.407
475500/758000 (epoch 1254), train_loss = 0.249, time/batch = 0.030, All_Time = 14044.894
475550/758000 (epoch 1254), train_loss = 0.237, time/batch = 0.033, All_Time = 14046.391
475600/758000 (epoch 1254), train_loss = 0.276, time/batch = 0.029, All_Time = 14047.871
475650/758000 (epoch 1255), train_loss = 0.256, time/batch = 0.029, All_Time = 14049.377
475700/758000 (epoch 1255), train_loss = 0.222, time/batch = 0.030, All_Time = 14050.849
475750/758000 (epoch 1255), train_loss = 0.266, time/batch = 0.029, All_Time = 14052.316
475800/758000 (epoch 1255), train_loss = 0.216, time/batch = 0.030, All_Time = 14053.788
475850/758000 (epoch 1255), train_loss = 0.223, time/batch = 0.032, All_Time = 14055.271
475900/758000 (epoch 1255), train_loss = 0.261, time/batch = 0.029, All_Time = 14056.754
475950/758000 (epoch 1255), train_loss = 0.238, time/batch = 0.029, All_Time = 14058.246
476000/758000 (epoch 1255), train_loss = 0.264, time/batch = 0.030, All_Time = 14059.734
model saved to NER/polyglot/model.ckpt
476050/758000 (epoch 1256), train_loss = 0.223, time/batch = 0.029, All_Time = 14061.231
476100/758000 (epoch 1256), train_loss = 0.231, time/batch = 0.028, All_Time = 14062.694
476150/758000 (epoch 1256), train_loss = 0.238, time/batch = 0.029, All_Time = 14064.169
476200/758000 (epoch 1256), train_loss = 0.266, time/batch = 0.029, All_Time = 14065.649
476250/758000 (epoch 1256), train_loss = 0.239, time/batch = 0.030, All_Time = 14067.121
476300/758000 (epoch 1256), train_loss = 0.226, time/batch = 0.030, All_Time = 14068.600
476350/758000 (epoch 1256), train_loss = 0.276, time/batch = 0.029, All_Time = 14070.086
476400/758000 (epoch 1256), train_loss = 0.240, time/batch = 0.030, All_Time = 14071.566
476450/758000 (epoch 1257), train_loss = 0.281, time/batch = 0.029, All_Time = 14073.051
476500/758000 (epoch 1257), train_loss = 0.257, time/batch = 0.032, All_Time = 14074.521
476550/758000 (epoch 1257), train_loss = 0.240, time/batch = 0.028, All_Time = 14075.997
476600/758000 (epoch 1257), train_loss = 0.231, time/batch = 0.030, All_Time = 14077.464
476650/758000 (epoch 1257), train_loss = 0.217, time/batch = 0.031, All_Time = 14078.939
476700/758000 (epoch 1257), train_loss = 0.224, time/batch = 0.030, All_Time = 14080.442
476750/758000 (epoch 1257), train_loss = 0.215, time/batch = 0.029, All_Time = 14081.938
476800/758000 (epoch 1258), train_loss = 0.249, time/batch = 0.031, All_Time = 14083.425
476850/758000 (epoch 1258), train_loss = 0.211, time/batch = 0.029, All_Time = 14084.911
476900/758000 (epoch 1258), train_loss = 0.245, time/batch = 0.031, All_Time = 14086.396
476950/758000 (epoch 1258), train_loss = 0.217, time/batch = 0.030, All_Time = 14087.871
477000/758000 (epoch 1258), train_loss = 0.233, time/batch = 0.030, All_Time = 14089.339
model saved to NER/polyglot/model.ckpt
477050/758000 (epoch 1258), train_loss = 0.228, time/batch = 0.031, All_Time = 14090.820
477100/758000 (epoch 1258), train_loss = 0.248, time/batch = 0.031, All_Time = 14092.304
477150/758000 (epoch 1258), train_loss = 0.229, time/batch = 0.030, All_Time = 14093.802
477200/758000 (epoch 1259), train_loss = 0.218, time/batch = 0.029, All_Time = 14095.296
477250/758000 (epoch 1259), train_loss = 0.237, time/batch = 0.029, All_Time = 14096.755
477300/758000 (epoch 1259), train_loss = 0.212, time/batch = 0.030, All_Time = 14098.212
477350/758000 (epoch 1259), train_loss = 0.266, time/batch = 0.029, All_Time = 14099.689
477400/758000 (epoch 1259), train_loss = 0.255, time/batch = 0.029, All_Time = 14101.162
477450/758000 (epoch 1259), train_loss = 0.232, time/batch = 0.029, All_Time = 14102.632
477500/758000 (epoch 1259), train_loss = 0.262, time/batch = 0.031, All_Time = 14104.114
477550/758000 (epoch 1260), train_loss = 0.282, time/batch = 0.029, All_Time = 14105.600
477600/758000 (epoch 1260), train_loss = 0.292, time/batch = 0.030, All_Time = 14107.085
477650/758000 (epoch 1260), train_loss = 0.253, time/batch = 0.029, All_Time = 14108.562
477700/758000 (epoch 1260), train_loss = 0.222, time/batch = 0.030, All_Time = 14110.033
477750/758000 (epoch 1260), train_loss = 0.221, time/batch = 0.032, All_Time = 14111.512
477800/758000 (epoch 1260), train_loss = 0.260, time/batch = 0.030, All_Time = 14112.995
477850/758000 (epoch 1260), train_loss = 0.244, time/batch = 0.029, All_Time = 14114.485
477900/758000 (epoch 1260), train_loss = 0.247, time/batch = 0.030, All_Time = 14115.958
477950/758000 (epoch 1261), train_loss = 0.210, time/batch = 0.028, All_Time = 14117.444
478000/758000 (epoch 1261), train_loss = 0.265, time/batch = 0.028, All_Time = 14118.910
model saved to NER/polyglot/model.ckpt
478050/758000 (epoch 1261), train_loss = 0.229, time/batch = 0.028, All_Time = 14120.381
478100/758000 (epoch 1261), train_loss = 0.232, time/batch = 0.030, All_Time = 14121.870
478150/758000 (epoch 1261), train_loss = 0.230, time/batch = 0.030, All_Time = 14123.366
478200/758000 (epoch 1261), train_loss = 0.253, time/batch = 0.029, All_Time = 14124.843
478250/758000 (epoch 1261), train_loss = 0.258, time/batch = 0.029, All_Time = 14126.325
478300/758000 (epoch 1262), train_loss = 0.196, time/batch = 0.029, All_Time = 14127.815
478350/758000 (epoch 1262), train_loss = 0.254, time/batch = 0.030, All_Time = 14129.293
478400/758000 (epoch 1262), train_loss = 0.281, time/batch = 0.030, All_Time = 14130.766
478450/758000 (epoch 1262), train_loss = 0.235, time/batch = 0.030, All_Time = 14132.237
478500/758000 (epoch 1262), train_loss = 0.247, time/batch = 0.032, All_Time = 14133.751
478550/758000 (epoch 1262), train_loss = 0.251, time/batch = 0.030, All_Time = 14135.245
478600/758000 (epoch 1262), train_loss = 0.203, time/batch = 0.031, All_Time = 14136.725
478650/758000 (epoch 1262), train_loss = 0.268, time/batch = 0.030, All_Time = 14138.205
478700/758000 (epoch 1263), train_loss = 0.233, time/batch = 0.029, All_Time = 14139.698
478750/758000 (epoch 1263), train_loss = 0.241, time/batch = 0.030, All_Time = 14141.203
478800/758000 (epoch 1263), train_loss = 0.252, time/batch = 0.034, All_Time = 14142.725
478850/758000 (epoch 1263), train_loss = 0.258, time/batch = 0.030, All_Time = 14144.357
478900/758000 (epoch 1263), train_loss = 0.243, time/batch = 0.030, All_Time = 14145.878
478950/758000 (epoch 1263), train_loss = 0.243, time/batch = 0.029, All_Time = 14147.353
479000/758000 (epoch 1263), train_loss = 0.244, time/batch = 0.029, All_Time = 14148.831
model saved to NER/polyglot/model.ckpt
479050/758000 (epoch 1263), train_loss = 0.286, time/batch = 0.031, All_Time = 14150.313
479100/758000 (epoch 1264), train_loss = 0.207, time/batch = 0.028, All_Time = 14151.793
479150/758000 (epoch 1264), train_loss = 0.244, time/batch = 0.029, All_Time = 14153.252
479200/758000 (epoch 1264), train_loss = 0.217, time/batch = 0.029, All_Time = 14154.734
479250/758000 (epoch 1264), train_loss = 0.233, time/batch = 0.030, All_Time = 14156.211
479300/758000 (epoch 1264), train_loss = 0.260, time/batch = 0.029, All_Time = 14157.680
479350/758000 (epoch 1264), train_loss = 0.253, time/batch = 0.030, All_Time = 14159.144
479400/758000 (epoch 1264), train_loss = 0.238, time/batch = 0.028, All_Time = 14160.614
479450/758000 (epoch 1265), train_loss = 0.227, time/batch = 0.032, All_Time = 14162.109
479500/758000 (epoch 1265), train_loss = 0.250, time/batch = 0.030, All_Time = 14163.577
479550/758000 (epoch 1265), train_loss = 0.250, time/batch = 0.029, All_Time = 14165.041
479600/758000 (epoch 1265), train_loss = 0.223, time/batch = 0.030, All_Time = 14166.521
479650/758000 (epoch 1265), train_loss = 0.240, time/batch = 0.029, All_Time = 14168.023
479700/758000 (epoch 1265), train_loss = 0.246, time/batch = 0.029, All_Time = 14169.505
479750/758000 (epoch 1265), train_loss = 0.246, time/batch = 0.029, All_Time = 14170.995
479800/758000 (epoch 1265), train_loss = 0.257, time/batch = 0.029, All_Time = 14172.476
479850/758000 (epoch 1266), train_loss = 0.266, time/batch = 0.029, All_Time = 14173.976
479900/758000 (epoch 1266), train_loss = 0.224, time/batch = 0.029, All_Time = 14175.458
479950/758000 (epoch 1266), train_loss = 0.248, time/batch = 0.030, All_Time = 14176.947
480000/758000 (epoch 1266), train_loss = 0.227, time/batch = 0.030, All_Time = 14178.449
model saved to NER/polyglot/model.ckpt
480050/758000 (epoch 1266), train_loss = 0.279, time/batch = 0.029, All_Time = 14179.916
480100/758000 (epoch 1266), train_loss = 0.255, time/batch = 0.029, All_Time = 14181.377
480150/758000 (epoch 1266), train_loss = 0.253, time/batch = 0.029, All_Time = 14182.840
480200/758000 (epoch 1267), train_loss = 0.244, time/batch = 0.030, All_Time = 14184.321
480250/758000 (epoch 1267), train_loss = 0.247, time/batch = 0.031, All_Time = 14185.792
480300/758000 (epoch 1267), train_loss = 0.270, time/batch = 0.029, All_Time = 14187.254
480350/758000 (epoch 1267), train_loss = 0.246, time/batch = 0.029, All_Time = 14188.729
480400/758000 (epoch 1267), train_loss = 0.237, time/batch = 0.030, All_Time = 14190.241
480450/758000 (epoch 1267), train_loss = 0.224, time/batch = 0.028, All_Time = 14191.729
480500/758000 (epoch 1267), train_loss = 0.229, time/batch = 0.029, All_Time = 14193.201
480550/758000 (epoch 1267), train_loss = 0.246, time/batch = 0.030, All_Time = 14194.687
480600/758000 (epoch 1268), train_loss = 0.249, time/batch = 0.030, All_Time = 14196.171
480650/758000 (epoch 1268), train_loss = 0.264, time/batch = 0.030, All_Time = 14197.638
480700/758000 (epoch 1268), train_loss = 0.240, time/batch = 0.031, All_Time = 14199.110
480750/758000 (epoch 1268), train_loss = 0.250, time/batch = 0.031, All_Time = 14200.579
480800/758000 (epoch 1268), train_loss = 0.227, time/batch = 0.030, All_Time = 14202.058
480850/758000 (epoch 1268), train_loss = 0.217, time/batch = 0.030, All_Time = 14203.555
480900/758000 (epoch 1268), train_loss = 0.277, time/batch = 0.029, All_Time = 14205.048
480950/758000 (epoch 1268), train_loss = 0.259, time/batch = 0.030, All_Time = 14206.526
481000/758000 (epoch 1269), train_loss = 0.269, time/batch = 0.029, All_Time = 14208.020
model saved to NER/polyglot/model.ckpt
481050/758000 (epoch 1269), train_loss = 0.296, time/batch = 0.030, All_Time = 14209.495
481100/758000 (epoch 1269), train_loss = 0.228, time/batch = 0.032, All_Time = 14210.960
481150/758000 (epoch 1269), train_loss = 0.220, time/batch = 0.029, All_Time = 14212.431
481200/758000 (epoch 1269), train_loss = 0.257, time/batch = 0.030, All_Time = 14213.894
481250/758000 (epoch 1269), train_loss = 0.255, time/batch = 0.030, All_Time = 14215.415
481300/758000 (epoch 1269), train_loss = 0.237, time/batch = 0.029, All_Time = 14216.917
481350/758000 (epoch 1270), train_loss = 0.225, time/batch = 0.030, All_Time = 14218.407
481400/758000 (epoch 1270), train_loss = 0.234, time/batch = 0.030, All_Time = 14219.872
481450/758000 (epoch 1270), train_loss = 0.243, time/batch = 0.029, All_Time = 14221.330
481500/758000 (epoch 1270), train_loss = 0.234, time/batch = 0.028, All_Time = 14222.796
481550/758000 (epoch 1270), train_loss = 0.223, time/batch = 0.029, All_Time = 14224.270
481600/758000 (epoch 1270), train_loss = 0.239, time/batch = 0.029, All_Time = 14225.738
481650/758000 (epoch 1270), train_loss = 0.264, time/batch = 0.031, All_Time = 14227.210
481700/758000 (epoch 1270), train_loss = 0.244, time/batch = 0.031, All_Time = 14228.687
481750/758000 (epoch 1271), train_loss = 0.257, time/batch = 0.031, All_Time = 14230.194
481800/758000 (epoch 1271), train_loss = 0.287, time/batch = 0.029, All_Time = 14231.682
481850/758000 (epoch 1271), train_loss = 0.255, time/batch = 0.030, All_Time = 14233.169
481900/758000 (epoch 1271), train_loss = 0.248, time/batch = 0.029, All_Time = 14234.648
481950/758000 (epoch 1271), train_loss = 0.212, time/batch = 0.029, All_Time = 14236.118
482000/758000 (epoch 1271), train_loss = 0.229, time/batch = 0.031, All_Time = 14237.600
model saved to NER/polyglot/model.ckpt
482050/758000 (epoch 1271), train_loss = 0.272, time/batch = 0.028, All_Time = 14239.067
482100/758000 (epoch 1272), train_loss = 0.249, time/batch = 0.028, All_Time = 14240.558
482150/758000 (epoch 1272), train_loss = 0.227, time/batch = 0.029, All_Time = 14242.018
482200/758000 (epoch 1272), train_loss = 0.267, time/batch = 0.030, All_Time = 14243.487
482250/758000 (epoch 1272), train_loss = 0.239, time/batch = 0.031, All_Time = 14244.952
482300/758000 (epoch 1272), train_loss = 0.247, time/batch = 0.031, All_Time = 14246.447
482350/758000 (epoch 1272), train_loss = 0.241, time/batch = 0.031, All_Time = 14247.948
482400/758000 (epoch 1272), train_loss = 0.274, time/batch = 0.030, All_Time = 14249.436
482450/758000 (epoch 1272), train_loss = 0.279, time/batch = 0.031, All_Time = 14250.926
482500/758000 (epoch 1273), train_loss = 0.238, time/batch = 0.029, All_Time = 14252.412
482550/758000 (epoch 1273), train_loss = 0.248, time/batch = 0.028, All_Time = 14253.889
482600/758000 (epoch 1273), train_loss = 0.299, time/batch = 0.030, All_Time = 14255.361
482650/758000 (epoch 1273), train_loss = 0.230, time/batch = 0.031, All_Time = 14256.834
482700/758000 (epoch 1273), train_loss = 0.216, time/batch = 0.029, All_Time = 14258.324
482750/758000 (epoch 1273), train_loss = 0.244, time/batch = 0.030, All_Time = 14259.820
482800/758000 (epoch 1273), train_loss = 0.274, time/batch = 0.029, All_Time = 14261.309
482850/758000 (epoch 1274), train_loss = 0.221, time/batch = 0.029, All_Time = 14262.799
482900/758000 (epoch 1274), train_loss = 0.257, time/batch = 0.029, All_Time = 14264.262
482950/758000 (epoch 1274), train_loss = 0.241, time/batch = 0.029, All_Time = 14265.740
483000/758000 (epoch 1274), train_loss = 0.240, time/batch = 0.030, All_Time = 14267.206
model saved to NER/polyglot/model.ckpt
483050/758000 (epoch 1274), train_loss = 0.256, time/batch = 0.028, All_Time = 14268.682
483100/758000 (epoch 1274), train_loss = 0.219, time/batch = 0.030, All_Time = 14270.145
483150/758000 (epoch 1274), train_loss = 0.224, time/batch = 0.029, All_Time = 14271.604
483200/758000 (epoch 1274), train_loss = 0.257, time/batch = 0.029, All_Time = 14273.076
483250/758000 (epoch 1275), train_loss = 0.255, time/batch = 0.029, All_Time = 14274.566
483300/758000 (epoch 1275), train_loss = 0.267, time/batch = 0.028, All_Time = 14276.025
483350/758000 (epoch 1275), train_loss = 0.269, time/batch = 0.030, All_Time = 14277.493
483400/758000 (epoch 1275), train_loss = 0.228, time/batch = 0.030, All_Time = 14279.008
483450/758000 (epoch 1275), train_loss = 0.234, time/batch = 0.029, All_Time = 14280.495
483500/758000 (epoch 1275), train_loss = 0.245, time/batch = 0.029, All_Time = 14281.965
483550/758000 (epoch 1275), train_loss = 0.279, time/batch = 0.029, All_Time = 14283.437
483600/758000 (epoch 1275), train_loss = 0.240, time/batch = 0.030, All_Time = 14284.923
483650/758000 (epoch 1276), train_loss = 0.236, time/batch = 0.029, All_Time = 14286.416
483700/758000 (epoch 1276), train_loss = 0.234, time/batch = 0.029, All_Time = 14287.888
483750/758000 (epoch 1276), train_loss = 0.233, time/batch = 0.031, All_Time = 14289.362
483800/758000 (epoch 1276), train_loss = 0.276, time/batch = 0.032, All_Time = 14290.832
483850/758000 (epoch 1276), train_loss = 0.206, time/batch = 0.030, All_Time = 14292.342
483900/758000 (epoch 1276), train_loss = 0.259, time/batch = 0.030, All_Time = 14293.820
483950/758000 (epoch 1276), train_loss = 0.234, time/batch = 0.029, All_Time = 14295.302
484000/758000 (epoch 1277), train_loss = 0.245, time/batch = 0.029, All_Time = 14296.801
model saved to NER/polyglot/model.ckpt
484050/758000 (epoch 1277), train_loss = 0.223, time/batch = 0.029, All_Time = 14298.268
484100/758000 (epoch 1277), train_loss = 0.240, time/batch = 0.029, All_Time = 14299.749
484150/758000 (epoch 1277), train_loss = 0.256, time/batch = 0.030, All_Time = 14301.209
484200/758000 (epoch 1277), train_loss = 0.214, time/batch = 0.031, All_Time = 14302.670
484250/758000 (epoch 1277), train_loss = 0.272, time/batch = 0.030, All_Time = 14304.131
484300/758000 (epoch 1277), train_loss = 0.213, time/batch = 0.029, All_Time = 14305.650
484350/758000 (epoch 1277), train_loss = 0.251, time/batch = 0.029, All_Time = 14307.135
484400/758000 (epoch 1278), train_loss = 0.247, time/batch = 0.030, All_Time = 14308.635
484450/758000 (epoch 1278), train_loss = 0.229, time/batch = 0.029, All_Time = 14310.099
484500/758000 (epoch 1278), train_loss = 0.217, time/batch = 0.030, All_Time = 14311.565
484550/758000 (epoch 1278), train_loss = 0.220, time/batch = 0.029, All_Time = 14313.035
484600/758000 (epoch 1278), train_loss = 0.250, time/batch = 0.030, All_Time = 14314.513
484650/758000 (epoch 1278), train_loss = 0.207, time/batch = 0.029, All_Time = 14315.985
484700/758000 (epoch 1278), train_loss = 0.268, time/batch = 0.029, All_Time = 14317.449
484750/758000 (epoch 1279), train_loss = 0.256, time/batch = 0.030, All_Time = 14318.937
484800/758000 (epoch 1279), train_loss = 0.264, time/batch = 0.030, All_Time = 14320.404
484850/758000 (epoch 1279), train_loss = 0.284, time/batch = 0.031, All_Time = 14321.869
484900/758000 (epoch 1279), train_loss = 0.239, time/batch = 0.031, All_Time = 14323.387
484950/758000 (epoch 1279), train_loss = 0.267, time/batch = 0.030, All_Time = 14324.870
485000/758000 (epoch 1279), train_loss = 0.256, time/batch = 0.031, All_Time = 14326.370
model saved to NER/polyglot/model.ckpt
485050/758000 (epoch 1279), train_loss = 0.236, time/batch = 0.029, All_Time = 14327.849
485100/758000 (epoch 1279), train_loss = 0.268, time/batch = 0.030, All_Time = 14329.324
485150/758000 (epoch 1280), train_loss = 0.226, time/batch = 0.030, All_Time = 14330.801
485200/758000 (epoch 1280), train_loss = 0.222, time/batch = 0.030, All_Time = 14332.269
485250/758000 (epoch 1280), train_loss = 0.261, time/batch = 0.029, All_Time = 14333.737
485300/758000 (epoch 1280), train_loss = 0.254, time/batch = 0.029, All_Time = 14335.217
485350/758000 (epoch 1280), train_loss = 0.223, time/batch = 0.030, All_Time = 14336.703
485400/758000 (epoch 1280), train_loss = 0.242, time/batch = 0.029, All_Time = 14338.178
485450/758000 (epoch 1280), train_loss = 0.251, time/batch = 0.030, All_Time = 14339.662
485500/758000 (epoch 1281), train_loss = 0.192, time/batch = 0.029, All_Time = 14341.144
485550/758000 (epoch 1281), train_loss = 0.273, time/batch = 0.028, All_Time = 14342.627
485600/758000 (epoch 1281), train_loss = 0.217, time/batch = 0.028, All_Time = 14344.098
485650/758000 (epoch 1281), train_loss = 0.240, time/batch = 0.032, All_Time = 14345.572
485700/758000 (epoch 1281), train_loss = 0.221, time/batch = 0.030, All_Time = 14347.039
485750/758000 (epoch 1281), train_loss = 0.221, time/batch = 0.028, All_Time = 14348.516
485800/758000 (epoch 1281), train_loss = 0.252, time/batch = 0.031, All_Time = 14349.999
485850/758000 (epoch 1281), train_loss = 0.272, time/batch = 0.029, All_Time = 14351.509
485900/758000 (epoch 1282), train_loss = 0.222, time/batch = 0.030, All_Time = 14352.997
485950/758000 (epoch 1282), train_loss = 0.279, time/batch = 0.029, All_Time = 14354.460
486000/758000 (epoch 1282), train_loss = 0.242, time/batch = 0.029, All_Time = 14355.929
model saved to NER/polyglot/model.ckpt
486050/758000 (epoch 1282), train_loss = 0.274, time/batch = 0.029, All_Time = 14357.400
486100/758000 (epoch 1282), train_loss = 0.262, time/batch = 0.030, All_Time = 14358.871
486150/758000 (epoch 1282), train_loss = 0.197, time/batch = 0.031, All_Time = 14360.331
486200/758000 (epoch 1282), train_loss = 0.233, time/batch = 0.029, All_Time = 14361.851
486250/758000 (epoch 1282), train_loss = 0.281, time/batch = 0.030, All_Time = 14363.345
486300/758000 (epoch 1283), train_loss = 0.246, time/batch = 0.030, All_Time = 14364.835
486350/758000 (epoch 1283), train_loss = 0.212, time/batch = 0.030, All_Time = 14366.299
486400/758000 (epoch 1283), train_loss = 0.255, time/batch = 0.029, All_Time = 14367.767
486450/758000 (epoch 1283), train_loss = 0.271, time/batch = 0.031, All_Time = 14369.244
486500/758000 (epoch 1283), train_loss = 0.203, time/batch = 0.029, All_Time = 14370.724
486550/758000 (epoch 1283), train_loss = 0.226, time/batch = 0.030, All_Time = 14372.187
486600/758000 (epoch 1283), train_loss = 0.254, time/batch = 0.029, All_Time = 14373.651
486650/758000 (epoch 1284), train_loss = 0.219, time/batch = 0.031, All_Time = 14375.147
486700/758000 (epoch 1284), train_loss = 0.265, time/batch = 0.030, All_Time = 14376.644
486750/758000 (epoch 1284), train_loss = 0.227, time/batch = 0.029, All_Time = 14378.127
486800/758000 (epoch 1284), train_loss = 0.213, time/batch = 0.029, All_Time = 14379.595
486850/758000 (epoch 1284), train_loss = 0.224, time/batch = 0.029, All_Time = 14381.073
486900/758000 (epoch 1284), train_loss = 0.213, time/batch = 0.029, All_Time = 14382.545
486950/758000 (epoch 1284), train_loss = 0.230, time/batch = 0.029, All_Time = 14384.016
487000/758000 (epoch 1284), train_loss = 0.223, time/batch = 0.029, All_Time = 14385.493
model saved to NER/polyglot/model.ckpt
487050/758000 (epoch 1285), train_loss = 0.275, time/batch = 0.030, All_Time = 14386.960
487100/758000 (epoch 1285), train_loss = 0.229, time/batch = 0.030, All_Time = 14388.424
487150/758000 (epoch 1285), train_loss = 0.270, time/batch = 0.030, All_Time = 14389.882
487200/758000 (epoch 1285), train_loss = 0.273, time/batch = 0.029, All_Time = 14391.359
487250/758000 (epoch 1285), train_loss = 0.233, time/batch = 0.029, All_Time = 14392.821
487300/758000 (epoch 1285), train_loss = 0.268, time/batch = 0.029, All_Time = 14394.304
487350/758000 (epoch 1285), train_loss = 0.280, time/batch = 0.032, All_Time = 14395.782
487400/758000 (epoch 1286), train_loss = 0.239, time/batch = 0.029, All_Time = 14397.297
487450/758000 (epoch 1286), train_loss = 0.218, time/batch = 0.029, All_Time = 14398.771
487500/758000 (epoch 1286), train_loss = 0.243, time/batch = 0.029, All_Time = 14400.247
487550/758000 (epoch 1286), train_loss = 0.244, time/batch = 0.029, All_Time = 14401.719
487600/758000 (epoch 1286), train_loss = 0.243, time/batch = 0.029, All_Time = 14403.196
487650/758000 (epoch 1286), train_loss = 0.244, time/batch = 0.030, All_Time = 14404.670
487700/758000 (epoch 1286), train_loss = 0.213, time/batch = 0.028, All_Time = 14406.141
487750/758000 (epoch 1286), train_loss = 0.289, time/batch = 0.029, All_Time = 14407.618
487800/758000 (epoch 1287), train_loss = 0.237, time/batch = 0.029, All_Time = 14409.100
487850/758000 (epoch 1287), train_loss = 0.246, time/batch = 0.030, All_Time = 14410.561
487900/758000 (epoch 1287), train_loss = 0.288, time/batch = 0.030, All_Time = 14412.037
487950/758000 (epoch 1287), train_loss = 0.257, time/batch = 0.030, All_Time = 14413.542
488000/758000 (epoch 1287), train_loss = 0.218, time/batch = 0.030, All_Time = 14415.046
model saved to NER/polyglot/model.ckpt
488050/758000 (epoch 1287), train_loss = 0.238, time/batch = 0.030, All_Time = 14416.533
488100/758000 (epoch 1287), train_loss = 0.251, time/batch = 0.029, All_Time = 14418.007
488150/758000 (epoch 1287), train_loss = 0.251, time/batch = 0.030, All_Time = 14419.473
488200/758000 (epoch 1288), train_loss = 0.252, time/batch = 0.030, All_Time = 14420.956
488250/758000 (epoch 1288), train_loss = 0.280, time/batch = 0.029, All_Time = 14422.425
488300/758000 (epoch 1288), train_loss = 0.242, time/batch = 0.030, All_Time = 14423.907
488350/758000 (epoch 1288), train_loss = 0.250, time/batch = 0.029, All_Time = 14425.395
488400/758000 (epoch 1288), train_loss = 0.239, time/batch = 0.030, All_Time = 14426.885
488450/758000 (epoch 1288), train_loss = 0.239, time/batch = 0.028, All_Time = 14428.378
488500/758000 (epoch 1288), train_loss = 0.250, time/batch = 0.029, All_Time = 14429.864
488550/758000 (epoch 1289), train_loss = 0.221, time/batch = 0.027, All_Time = 14431.340
488600/758000 (epoch 1289), train_loss = 0.219, time/batch = 0.031, All_Time = 14432.809
488650/758000 (epoch 1289), train_loss = 0.246, time/batch = 0.031, All_Time = 14434.287
488700/758000 (epoch 1289), train_loss = 0.262, time/batch = 0.030, All_Time = 14435.759
488750/758000 (epoch 1289), train_loss = 0.260, time/batch = 0.029, All_Time = 14437.232
488800/758000 (epoch 1289), train_loss = 0.241, time/batch = 0.030, All_Time = 14438.701
488850/758000 (epoch 1289), train_loss = 0.210, time/batch = 0.029, All_Time = 14440.164
488900/758000 (epoch 1289), train_loss = 0.239, time/batch = 0.030, All_Time = 14441.639
488950/758000 (epoch 1290), train_loss = 0.230, time/batch = 0.028, All_Time = 14443.113
489000/758000 (epoch 1290), train_loss = 0.226, time/batch = 0.030, All_Time = 14444.589
model saved to NER/polyglot/model.ckpt
489050/758000 (epoch 1290), train_loss = 0.264, time/batch = 0.031, All_Time = 14446.061
489100/758000 (epoch 1290), train_loss = 0.240, time/batch = 0.030, All_Time = 14447.530
489150/758000 (epoch 1290), train_loss = 0.253, time/batch = 0.031, All_Time = 14449.036
489200/758000 (epoch 1290), train_loss = 0.251, time/batch = 0.030, All_Time = 14450.522
489250/758000 (epoch 1290), train_loss = 0.248, time/batch = 0.031, All_Time = 14452.008
489300/758000 (epoch 1291), train_loss = 0.216, time/batch = 0.028, All_Time = 14453.487
489350/758000 (epoch 1291), train_loss = 0.233, time/batch = 0.029, All_Time = 14454.964
489400/758000 (epoch 1291), train_loss = 0.250, time/batch = 0.029, All_Time = 14456.427
489450/758000 (epoch 1291), train_loss = 0.241, time/batch = 0.029, All_Time = 14457.892
489500/758000 (epoch 1291), train_loss = 0.243, time/batch = 0.028, All_Time = 14459.358
489550/758000 (epoch 1291), train_loss = 0.242, time/batch = 0.029, All_Time = 14460.832
489600/758000 (epoch 1291), train_loss = 0.230, time/batch = 0.029, All_Time = 14462.298
489650/758000 (epoch 1291), train_loss = 0.259, time/batch = 0.029, All_Time = 14463.763
489700/758000 (epoch 1292), train_loss = 0.250, time/batch = 0.030, All_Time = 14465.242
489750/758000 (epoch 1292), train_loss = 0.253, time/batch = 0.030, All_Time = 14466.716
489800/758000 (epoch 1292), train_loss = 0.245, time/batch = 0.029, All_Time = 14468.195
489850/758000 (epoch 1292), train_loss = 0.231, time/batch = 0.030, All_Time = 14469.685
489900/758000 (epoch 1292), train_loss = 0.228, time/batch = 0.028, All_Time = 14471.180
489950/758000 (epoch 1292), train_loss = 0.238, time/batch = 0.029, All_Time = 14472.660
490000/758000 (epoch 1292), train_loss = 0.268, time/batch = 0.029, All_Time = 14474.134
model saved to NER/polyglot/model.ckpt
490050/758000 (epoch 1293), train_loss = 0.248, time/batch = 0.030, All_Time = 14475.622
490100/758000 (epoch 1293), train_loss = 0.280, time/batch = 0.030, All_Time = 14477.095
490150/758000 (epoch 1293), train_loss = 0.242, time/batch = 0.030, All_Time = 14478.569
490200/758000 (epoch 1293), train_loss = 0.258, time/batch = 0.029, All_Time = 14480.042
490250/758000 (epoch 1293), train_loss = 0.224, time/batch = 0.029, All_Time = 14481.557
490300/758000 (epoch 1293), train_loss = 0.243, time/batch = 0.028, All_Time = 14483.044
490350/758000 (epoch 1293), train_loss = 0.219, time/batch = 0.030, All_Time = 14484.526
490400/758000 (epoch 1293), train_loss = 0.232, time/batch = 0.031, All_Time = 14486.015
490450/758000 (epoch 1294), train_loss = 0.237, time/batch = 0.029, All_Time = 14487.497
490500/758000 (epoch 1294), train_loss = 0.239, time/batch = 0.029, All_Time = 14488.950
490550/758000 (epoch 1294), train_loss = 0.293, time/batch = 0.031, All_Time = 14490.459
490600/758000 (epoch 1294), train_loss = 0.318, time/batch = 0.031, All_Time = 14491.946
490650/758000 (epoch 1294), train_loss = 0.196, time/batch = 0.031, All_Time = 14493.424
490700/758000 (epoch 1294), train_loss = 0.213, time/batch = 0.031, All_Time = 14494.905
490750/758000 (epoch 1294), train_loss = 0.250, time/batch = 0.030, All_Time = 14496.385
490800/758000 (epoch 1294), train_loss = 0.297, time/batch = 0.029, All_Time = 14497.863
490850/758000 (epoch 1295), train_loss = 0.226, time/batch = 0.029, All_Time = 14499.329
490900/758000 (epoch 1295), train_loss = 0.259, time/batch = 0.028, All_Time = 14500.802
490950/758000 (epoch 1295), train_loss = 0.223, time/batch = 0.029, All_Time = 14502.262
491000/758000 (epoch 1295), train_loss = 0.239, time/batch = 0.028, All_Time = 14503.723
model saved to NER/polyglot/model.ckpt
491050/758000 (epoch 1295), train_loss = 0.212, time/batch = 0.029, All_Time = 14505.195
491100/758000 (epoch 1295), train_loss = 0.243, time/batch = 0.031, All_Time = 14506.659
491150/758000 (epoch 1295), train_loss = 0.215, time/batch = 0.029, All_Time = 14508.119
491200/758000 (epoch 1296), train_loss = 0.228, time/batch = 0.029, All_Time = 14509.585
491250/758000 (epoch 1296), train_loss = 0.252, time/batch = 0.028, All_Time = 14511.048
491300/758000 (epoch 1296), train_loss = 0.260, time/batch = 0.030, All_Time = 14512.518
491350/758000 (epoch 1296), train_loss = 0.228, time/batch = 0.031, All_Time = 14514.024
491400/758000 (epoch 1296), train_loss = 0.236, time/batch = 0.031, All_Time = 14515.523
491450/758000 (epoch 1296), train_loss = 0.271, time/batch = 0.030, All_Time = 14517.021
491500/758000 (epoch 1296), train_loss = 0.238, time/batch = 0.028, All_Time = 14518.498
491550/758000 (epoch 1296), train_loss = 0.268, time/batch = 0.031, All_Time = 14519.987
491600/758000 (epoch 1297), train_loss = 0.248, time/batch = 0.029, All_Time = 14521.471
491650/758000 (epoch 1297), train_loss = 0.249, time/batch = 0.030, All_Time = 14522.944
491700/758000 (epoch 1297), train_loss = 0.240, time/batch = 0.029, All_Time = 14524.421
491750/758000 (epoch 1297), train_loss = 0.247, time/batch = 0.030, All_Time = 14525.915
491800/758000 (epoch 1297), train_loss = 0.235, time/batch = 0.031, All_Time = 14527.419
491850/758000 (epoch 1297), train_loss = 0.247, time/batch = 0.030, All_Time = 14528.900
491900/758000 (epoch 1297), train_loss = 0.251, time/batch = 0.029, All_Time = 14530.381
491950/758000 (epoch 1298), train_loss = 0.242, time/batch = 0.028, All_Time = 14531.869
492000/758000 (epoch 1298), train_loss = 0.276, time/batch = 0.027, All_Time = 14533.342
model saved to NER/polyglot/model.ckpt
492050/758000 (epoch 1298), train_loss = 0.256, time/batch = 0.028, All_Time = 14534.814
492100/758000 (epoch 1298), train_loss = 0.258, time/batch = 0.029, All_Time = 14536.281
492150/758000 (epoch 1298), train_loss = 0.213, time/batch = 0.030, All_Time = 14537.744
492200/758000 (epoch 1298), train_loss = 0.237, time/batch = 0.029, All_Time = 14539.243
492250/758000 (epoch 1298), train_loss = 0.249, time/batch = 0.031, All_Time = 14540.723
492300/758000 (epoch 1298), train_loss = 0.251, time/batch = 0.029, All_Time = 14542.202
492350/758000 (epoch 1299), train_loss = 0.232, time/batch = 0.029, All_Time = 14543.674
492400/758000 (epoch 1299), train_loss = 0.255, time/batch = 0.030, All_Time = 14545.136
492450/758000 (epoch 1299), train_loss = 0.265, time/batch = 0.028, All_Time = 14546.615
492500/758000 (epoch 1299), train_loss = 0.229, time/batch = 0.030, All_Time = 14548.068
492550/758000 (epoch 1299), train_loss = 0.263, time/batch = 0.030, All_Time = 14549.560
492600/758000 (epoch 1299), train_loss = 0.217, time/batch = 0.030, All_Time = 14551.057
492650/758000 (epoch 1299), train_loss = 0.248, time/batch = 0.029, All_Time = 14552.545
492700/758000 (epoch 1300), train_loss = 0.059, time/batch = 0.030, All_Time = 14554.045
492750/758000 (epoch 1300), train_loss = 0.250, time/batch = 0.033, All_Time = 14555.520
492800/758000 (epoch 1300), train_loss = 0.223, time/batch = 0.030, All_Time = 14556.998
492850/758000 (epoch 1300), train_loss = 0.250, time/batch = 0.030, All_Time = 14558.463
492900/758000 (epoch 1300), train_loss = 0.231, time/batch = 0.029, All_Time = 14559.933
492950/758000 (epoch 1300), train_loss = 0.250, time/batch = 0.029, All_Time = 14561.400
493000/758000 (epoch 1300), train_loss = 0.232, time/batch = 0.030, All_Time = 14562.892
model saved to NER/polyglot/model.ckpt
493050/758000 (epoch 1300), train_loss = 0.230, time/batch = 0.029, All_Time = 14564.376
493100/758000 (epoch 1301), train_loss = 0.224, time/batch = 0.028, All_Time = 14565.840
493150/758000 (epoch 1301), train_loss = 0.233, time/batch = 0.030, All_Time = 14567.300
493200/758000 (epoch 1301), train_loss = 0.224, time/batch = 0.029, All_Time = 14568.773
493250/758000 (epoch 1301), train_loss = 0.262, time/batch = 0.030, All_Time = 14570.284
493300/758000 (epoch 1301), train_loss = 0.220, time/batch = 0.030, All_Time = 14571.773
493350/758000 (epoch 1301), train_loss = 0.228, time/batch = 0.030, All_Time = 14573.268
493400/758000 (epoch 1301), train_loss = 0.280, time/batch = 0.030, All_Time = 14574.758
493450/758000 (epoch 1301), train_loss = 0.272, time/batch = 0.030, All_Time = 14576.256
493500/758000 (epoch 1302), train_loss = 0.230, time/batch = 0.029, All_Time = 14577.733
493550/758000 (epoch 1302), train_loss = 0.224, time/batch = 0.029, All_Time = 14579.216
493600/758000 (epoch 1302), train_loss = 0.201, time/batch = 0.028, All_Time = 14580.698
493650/758000 (epoch 1302), train_loss = 0.270, time/batch = 0.029, All_Time = 14582.180
493700/758000 (epoch 1302), train_loss = 0.259, time/batch = 0.031, All_Time = 14583.651
493750/758000 (epoch 1302), train_loss = 0.209, time/batch = 0.029, All_Time = 14585.163
493800/758000 (epoch 1302), train_loss = 0.218, time/batch = 0.030, All_Time = 14586.657
493850/758000 (epoch 1303), train_loss = 0.229, time/batch = 0.029, All_Time = 14588.141
493900/758000 (epoch 1303), train_loss = 0.283, time/batch = 0.030, All_Time = 14589.621
493950/758000 (epoch 1303), train_loss = 0.231, time/batch = 0.028, All_Time = 14591.096
494000/758000 (epoch 1303), train_loss = 0.307, time/batch = 0.030, All_Time = 14592.573
model saved to NER/polyglot/model.ckpt
494050/758000 (epoch 1303), train_loss = 0.221, time/batch = 0.030, All_Time = 14594.045
494100/758000 (epoch 1303), train_loss = 0.208, time/batch = 0.031, All_Time = 14595.525
494150/758000 (epoch 1303), train_loss = 0.247, time/batch = 0.029, All_Time = 14597.005
494200/758000 (epoch 1303), train_loss = 0.252, time/batch = 0.030, All_Time = 14598.492
494250/758000 (epoch 1304), train_loss = 0.264, time/batch = 0.029, All_Time = 14599.969
494300/758000 (epoch 1304), train_loss = 0.229, time/batch = 0.029, All_Time = 14601.435
494350/758000 (epoch 1304), train_loss = 0.242, time/batch = 0.030, All_Time = 14602.902
494400/758000 (epoch 1304), train_loss = 0.267, time/batch = 0.029, All_Time = 14604.377
494450/758000 (epoch 1304), train_loss = 0.249, time/batch = 0.028, All_Time = 14605.845
494500/758000 (epoch 1304), train_loss = 0.237, time/batch = 0.029, All_Time = 14607.318
494550/758000 (epoch 1304), train_loss = 0.276, time/batch = 0.030, All_Time = 14608.791
494600/758000 (epoch 1305), train_loss = 0.256, time/batch = 0.030, All_Time = 14610.272
494650/758000 (epoch 1305), train_loss = 0.222, time/batch = 0.029, All_Time = 14611.745
494700/758000 (epoch 1305), train_loss = 0.266, time/batch = 0.029, All_Time = 14613.230
494750/758000 (epoch 1305), train_loss = 0.216, time/batch = 0.030, All_Time = 14614.736
494800/758000 (epoch 1305), train_loss = 0.223, time/batch = 0.029, All_Time = 14616.220
494850/758000 (epoch 1305), train_loss = 0.261, time/batch = 0.030, All_Time = 14617.694
494900/758000 (epoch 1305), train_loss = 0.238, time/batch = 0.029, All_Time = 14619.170
494950/758000 (epoch 1305), train_loss = 0.264, time/batch = 0.030, All_Time = 14620.646
495000/758000 (epoch 1306), train_loss = 0.223, time/batch = 0.030, All_Time = 14622.126
model saved to NER/polyglot/model.ckpt
495050/758000 (epoch 1306), train_loss = 0.231, time/batch = 0.028, All_Time = 14623.588
495100/758000 (epoch 1306), train_loss = 0.238, time/batch = 0.029, All_Time = 14625.054
495150/758000 (epoch 1306), train_loss = 0.266, time/batch = 0.029, All_Time = 14626.554
495200/758000 (epoch 1306), train_loss = 0.239, time/batch = 0.030, All_Time = 14628.052
495250/758000 (epoch 1306), train_loss = 0.226, time/batch = 0.029, All_Time = 14629.547
495300/758000 (epoch 1306), train_loss = 0.276, time/batch = 0.031, All_Time = 14631.040
495350/758000 (epoch 1306), train_loss = 0.240, time/batch = 0.029, All_Time = 14632.530
495400/758000 (epoch 1307), train_loss = 0.281, time/batch = 0.029, All_Time = 14634.002
495450/758000 (epoch 1307), train_loss = 0.257, time/batch = 0.028, All_Time = 14635.466
495500/758000 (epoch 1307), train_loss = 0.240, time/batch = 0.029, All_Time = 14636.933
495550/758000 (epoch 1307), train_loss = 0.231, time/batch = 0.030, All_Time = 14638.398
495600/758000 (epoch 1307), train_loss = 0.217, time/batch = 0.029, All_Time = 14639.860
495650/758000 (epoch 1307), train_loss = 0.224, time/batch = 0.030, All_Time = 14641.355
495700/758000 (epoch 1307), train_loss = 0.215, time/batch = 0.030, All_Time = 14642.871
495750/758000 (epoch 1308), train_loss = 0.249, time/batch = 0.029, All_Time = 14644.360
495800/758000 (epoch 1308), train_loss = 0.211, time/batch = 0.029, All_Time = 14645.829
495850/758000 (epoch 1308), train_loss = 0.245, time/batch = 0.030, All_Time = 14647.302
495900/758000 (epoch 1308), train_loss = 0.217, time/batch = 0.029, All_Time = 14648.773
495950/758000 (epoch 1308), train_loss = 0.233, time/batch = 0.029, All_Time = 14650.241
496000/758000 (epoch 1308), train_loss = 0.228, time/batch = 0.030, All_Time = 14651.748
model saved to NER/polyglot/model.ckpt
496050/758000 (epoch 1308), train_loss = 0.248, time/batch = 0.029, All_Time = 14653.222
496100/758000 (epoch 1308), train_loss = 0.229, time/batch = 0.030, All_Time = 14654.694
496150/758000 (epoch 1309), train_loss = 0.218, time/batch = 0.029, All_Time = 14656.161
496200/758000 (epoch 1309), train_loss = 0.237, time/batch = 0.028, All_Time = 14657.626
496250/758000 (epoch 1309), train_loss = 0.212, time/batch = 0.029, All_Time = 14659.104
496300/758000 (epoch 1309), train_loss = 0.266, time/batch = 0.030, All_Time = 14660.585
496350/758000 (epoch 1309), train_loss = 0.255, time/batch = 0.029, All_Time = 14662.055
496400/758000 (epoch 1309), train_loss = 0.232, time/batch = 0.028, All_Time = 14663.533
496450/758000 (epoch 1309), train_loss = 0.262, time/batch = 0.029, All_Time = 14665.005
496500/758000 (epoch 1310), train_loss = 0.282, time/batch = 0.029, All_Time = 14666.480
496550/758000 (epoch 1310), train_loss = 0.292, time/batch = 0.028, All_Time = 14667.954
496600/758000 (epoch 1310), train_loss = 0.253, time/batch = 0.030, All_Time = 14669.423
496650/758000 (epoch 1310), train_loss = 0.222, time/batch = 0.031, All_Time = 14670.936
496700/758000 (epoch 1310), train_loss = 0.221, time/batch = 0.030, All_Time = 14672.427
496750/758000 (epoch 1310), train_loss = 0.260, time/batch = 0.030, All_Time = 14673.908
496800/758000 (epoch 1310), train_loss = 0.244, time/batch = 0.030, All_Time = 14675.392
496850/758000 (epoch 1310), train_loss = 0.247, time/batch = 0.029, All_Time = 14676.878
496900/758000 (epoch 1311), train_loss = 0.210, time/batch = 0.029, All_Time = 14678.348
496950/758000 (epoch 1311), train_loss = 0.265, time/batch = 0.031, All_Time = 14679.817
497000/758000 (epoch 1311), train_loss = 0.229, time/batch = 0.029, All_Time = 14681.291
model saved to NER/polyglot/model.ckpt
497050/758000 (epoch 1311), train_loss = 0.232, time/batch = 0.029, All_Time = 14682.764
497100/758000 (epoch 1311), train_loss = 0.230, time/batch = 0.030, All_Time = 14684.221
497150/758000 (epoch 1311), train_loss = 0.253, time/batch = 0.031, All_Time = 14685.689
497200/758000 (epoch 1311), train_loss = 0.258, time/batch = 0.028, All_Time = 14687.152
497250/758000 (epoch 1312), train_loss = 0.196, time/batch = 0.029, All_Time = 14688.610
497300/758000 (epoch 1312), train_loss = 0.254, time/batch = 0.031, All_Time = 14690.082
497350/758000 (epoch 1312), train_loss = 0.281, time/batch = 0.031, All_Time = 14691.548
497400/758000 (epoch 1312), train_loss = 0.235, time/batch = 0.030, All_Time = 14693.045
497450/758000 (epoch 1312), train_loss = 0.247, time/batch = 0.029, All_Time = 14694.551
497500/758000 (epoch 1312), train_loss = 0.251, time/batch = 0.031, All_Time = 14696.050
497550/758000 (epoch 1312), train_loss = 0.203, time/batch = 0.030, All_Time = 14697.535
497600/758000 (epoch 1312), train_loss = 0.268, time/batch = 0.030, All_Time = 14699.020
497650/758000 (epoch 1313), train_loss = 0.233, time/batch = 0.031, All_Time = 14700.502
497700/758000 (epoch 1313), train_loss = 0.241, time/batch = 0.029, All_Time = 14701.971
497750/758000 (epoch 1313), train_loss = 0.252, time/batch = 0.028, All_Time = 14703.431
497800/758000 (epoch 1313), train_loss = 0.258, time/batch = 0.029, All_Time = 14704.893
497850/758000 (epoch 1313), train_loss = 0.243, time/batch = 0.030, All_Time = 14706.400
497900/758000 (epoch 1313), train_loss = 0.243, time/batch = 0.030, All_Time = 14707.885
497950/758000 (epoch 1313), train_loss = 0.244, time/batch = 0.030, All_Time = 14709.364
498000/758000 (epoch 1313), train_loss = 0.286, time/batch = 0.030, All_Time = 14710.843
model saved to NER/polyglot/model.ckpt
498050/758000 (epoch 1314), train_loss = 0.207, time/batch = 0.031, All_Time = 14712.323
498100/758000 (epoch 1314), train_loss = 0.244, time/batch = 0.030, All_Time = 14713.781
498150/758000 (epoch 1314), train_loss = 0.217, time/batch = 0.029, All_Time = 14715.253
498200/758000 (epoch 1314), train_loss = 0.233, time/batch = 0.030, All_Time = 14716.726
498250/758000 (epoch 1314), train_loss = 0.260, time/batch = 0.030, All_Time = 14718.216
498300/758000 (epoch 1314), train_loss = 0.253, time/batch = 0.030, All_Time = 14719.728
498350/758000 (epoch 1314), train_loss = 0.238, time/batch = 0.029, All_Time = 14721.215
498400/758000 (epoch 1315), train_loss = 0.227, time/batch = 0.030, All_Time = 14722.696
498450/758000 (epoch 1315), train_loss = 0.250, time/batch = 0.030, All_Time = 14724.168
498500/758000 (epoch 1315), train_loss = 0.250, time/batch = 0.031, All_Time = 14725.638
498550/758000 (epoch 1315), train_loss = 0.223, time/batch = 0.030, All_Time = 14727.117
498600/758000 (epoch 1315), train_loss = 0.240, time/batch = 0.028, All_Time = 14728.585
498650/758000 (epoch 1315), train_loss = 0.246, time/batch = 0.030, All_Time = 14730.055
498700/758000 (epoch 1315), train_loss = 0.246, time/batch = 0.030, All_Time = 14731.541
498750/758000 (epoch 1315), train_loss = 0.257, time/batch = 0.030, All_Time = 14733.059
498800/758000 (epoch 1316), train_loss = 0.266, time/batch = 0.030, All_Time = 14734.537
498850/758000 (epoch 1316), train_loss = 0.224, time/batch = 0.029, All_Time = 14736.101
498900/758000 (epoch 1316), train_loss = 0.248, time/batch = 0.029, All_Time = 14737.603
498950/758000 (epoch 1316), train_loss = 0.227, time/batch = 0.030, All_Time = 14739.090
499000/758000 (epoch 1316), train_loss = 0.279, time/batch = 0.030, All_Time = 14740.562
model saved to NER/polyglot/model.ckpt
499050/758000 (epoch 1316), train_loss = 0.255, time/batch = 0.029, All_Time = 14742.069
499100/758000 (epoch 1316), train_loss = 0.253, time/batch = 0.030, All_Time = 14743.550
499150/758000 (epoch 1317), train_loss = 0.244, time/batch = 0.030, All_Time = 14745.035
499200/758000 (epoch 1317), train_loss = 0.247, time/batch = 0.029, All_Time = 14746.508
499250/758000 (epoch 1317), train_loss = 0.270, time/batch = 0.028, All_Time = 14747.962
499300/758000 (epoch 1317), train_loss = 0.246, time/batch = 0.032, All_Time = 14749.456
499350/758000 (epoch 1317), train_loss = 0.237, time/batch = 0.031, All_Time = 14750.959
499400/758000 (epoch 1317), train_loss = 0.224, time/batch = 0.029, All_Time = 14752.442
499450/758000 (epoch 1317), train_loss = 0.229, time/batch = 0.030, All_Time = 14753.916
499500/758000 (epoch 1317), train_loss = 0.246, time/batch = 0.029, All_Time = 14755.401
499550/758000 (epoch 1318), train_loss = 0.249, time/batch = 0.030, All_Time = 14756.865
499600/758000 (epoch 1318), train_loss = 0.264, time/batch = 0.030, All_Time = 14758.337
499650/758000 (epoch 1318), train_loss = 0.240, time/batch = 0.029, All_Time = 14759.808
499700/758000 (epoch 1318), train_loss = 0.250, time/batch = 0.030, All_Time = 14761.325
499750/758000 (epoch 1318), train_loss = 0.227, time/batch = 0.031, All_Time = 14762.814
499800/758000 (epoch 1318), train_loss = 0.217, time/batch = 0.028, All_Time = 14764.300
499850/758000 (epoch 1318), train_loss = 0.277, time/batch = 0.029, All_Time = 14765.784
499900/758000 (epoch 1318), train_loss = 0.259, time/batch = 0.029, All_Time = 14767.265
499950/758000 (epoch 1319), train_loss = 0.269, time/batch = 0.029, All_Time = 14768.734
500000/758000 (epoch 1319), train_loss = 0.296, time/batch = 0.030, All_Time = 14770.204
model saved to NER/polyglot/model.ckpt
500050/758000 (epoch 1319), train_loss = 0.228, time/batch = 0.029, All_Time = 14771.674
500100/758000 (epoch 1319), train_loss = 0.220, time/batch = 0.030, All_Time = 14773.136
500150/758000 (epoch 1319), train_loss = 0.257, time/batch = 0.029, All_Time = 14774.605
500200/758000 (epoch 1319), train_loss = 0.255, time/batch = 0.030, All_Time = 14776.058
500250/758000 (epoch 1319), train_loss = 0.237, time/batch = 0.030, All_Time = 14777.540
500300/758000 (epoch 1320), train_loss = 0.225, time/batch = 0.029, All_Time = 14779.015
500350/758000 (epoch 1320), train_loss = 0.234, time/batch = 0.030, All_Time = 14780.492
500400/758000 (epoch 1320), train_loss = 0.243, time/batch = 0.028, All_Time = 14781.961
500450/758000 (epoch 1320), train_loss = 0.234, time/batch = 0.029, All_Time = 14783.464
500500/758000 (epoch 1320), train_loss = 0.223, time/batch = 0.029, All_Time = 14784.943
500550/758000 (epoch 1320), train_loss = 0.239, time/batch = 0.030, All_Time = 14786.440
500600/758000 (epoch 1320), train_loss = 0.264, time/batch = 0.028, All_Time = 14787.910
500650/758000 (epoch 1320), train_loss = 0.244, time/batch = 0.030, All_Time = 14789.400
500700/758000 (epoch 1321), train_loss = 0.257, time/batch = 0.030, All_Time = 14790.885
500750/758000 (epoch 1321), train_loss = 0.287, time/batch = 0.029, All_Time = 14792.360
500800/758000 (epoch 1321), train_loss = 0.255, time/batch = 0.031, All_Time = 14793.833
500850/758000 (epoch 1321), train_loss = 0.248, time/batch = 0.030, All_Time = 14795.316
500900/758000 (epoch 1321), train_loss = 0.212, time/batch = 0.030, All_Time = 14796.802
500950/758000 (epoch 1321), train_loss = 0.229, time/batch = 0.029, All_Time = 14798.274
501000/758000 (epoch 1321), train_loss = 0.272, time/batch = 0.031, All_Time = 14799.751
model saved to NER/polyglot/model.ckpt
501050/758000 (epoch 1322), train_loss = 0.249, time/batch = 0.030, All_Time = 14801.225
501100/758000 (epoch 1322), train_loss = 0.227, time/batch = 0.030, All_Time = 14802.684
501150/758000 (epoch 1322), train_loss = 0.267, time/batch = 0.030, All_Time = 14804.141
501200/758000 (epoch 1322), train_loss = 0.239, time/batch = 0.030, All_Time = 14805.648
501250/758000 (epoch 1322), train_loss = 0.247, time/batch = 0.030, All_Time = 14807.147
501300/758000 (epoch 1322), train_loss = 0.241, time/batch = 0.031, All_Time = 14808.627
501350/758000 (epoch 1322), train_loss = 0.274, time/batch = 0.030, All_Time = 14810.106
501400/758000 (epoch 1322), train_loss = 0.279, time/batch = 0.029, All_Time = 14811.583
501450/758000 (epoch 1323), train_loss = 0.238, time/batch = 0.031, All_Time = 14813.054
501500/758000 (epoch 1323), train_loss = 0.248, time/batch = 0.029, All_Time = 14814.525
501550/758000 (epoch 1323), train_loss = 0.299, time/batch = 0.030, All_Time = 14815.999
501600/758000 (epoch 1323), train_loss = 0.230, time/batch = 0.030, All_Time = 14817.459
501650/758000 (epoch 1323), train_loss = 0.216, time/batch = 0.030, All_Time = 14818.929
501700/758000 (epoch 1323), train_loss = 0.244, time/batch = 0.032, All_Time = 14820.400
501750/758000 (epoch 1323), train_loss = 0.274, time/batch = 0.032, All_Time = 14821.880
501800/758000 (epoch 1324), train_loss = 0.221, time/batch = 0.030, All_Time = 14823.400
501850/758000 (epoch 1324), train_loss = 0.257, time/batch = 0.030, All_Time = 14824.881
501900/758000 (epoch 1324), train_loss = 0.241, time/batch = 0.029, All_Time = 14826.376
501950/758000 (epoch 1324), train_loss = 0.240, time/batch = 0.028, All_Time = 14827.860
502000/758000 (epoch 1324), train_loss = 0.256, time/batch = 0.029, All_Time = 14829.332
model saved to NER/polyglot/model.ckpt
502050/758000 (epoch 1324), train_loss = 0.219, time/batch = 0.029, All_Time = 14830.809
502100/758000 (epoch 1324), train_loss = 0.224, time/batch = 0.029, All_Time = 14832.271
502150/758000 (epoch 1324), train_loss = 0.257, time/batch = 0.031, All_Time = 14833.742
502200/758000 (epoch 1325), train_loss = 0.255, time/batch = 0.029, All_Time = 14835.256
502250/758000 (epoch 1325), train_loss = 0.267, time/batch = 0.029, All_Time = 14836.731
502300/758000 (epoch 1325), train_loss = 0.269, time/batch = 0.029, All_Time = 14838.203
502350/758000 (epoch 1325), train_loss = 0.228, time/batch = 0.030, All_Time = 14839.685
502400/758000 (epoch 1325), train_loss = 0.234, time/batch = 0.029, All_Time = 14841.151
502450/758000 (epoch 1325), train_loss = 0.245, time/batch = 0.029, All_Time = 14842.617
502500/758000 (epoch 1325), train_loss = 0.279, time/batch = 0.030, All_Time = 14844.095
502550/758000 (epoch 1325), train_loss = 0.240, time/batch = 0.030, All_Time = 14845.579
502600/758000 (epoch 1326), train_loss = 0.236, time/batch = 0.029, All_Time = 14847.047
502650/758000 (epoch 1326), train_loss = 0.234, time/batch = 0.028, All_Time = 14848.513
502700/758000 (epoch 1326), train_loss = 0.233, time/batch = 0.030, All_Time = 14849.989
502750/758000 (epoch 1326), train_loss = 0.276, time/batch = 0.029, All_Time = 14851.474
502800/758000 (epoch 1326), train_loss = 0.206, time/batch = 0.030, All_Time = 14852.969
502850/758000 (epoch 1326), train_loss = 0.259, time/batch = 0.030, All_Time = 14854.460
502900/758000 (epoch 1326), train_loss = 0.234, time/batch = 0.031, All_Time = 14855.934
502950/758000 (epoch 1327), train_loss = 0.245, time/batch = 0.029, All_Time = 14857.430
503000/758000 (epoch 1327), train_loss = 0.223, time/batch = 0.029, All_Time = 14858.901
model saved to NER/polyglot/model.ckpt
503050/758000 (epoch 1327), train_loss = 0.240, time/batch = 0.029, All_Time = 14860.370
503100/758000 (epoch 1327), train_loss = 0.256, time/batch = 0.030, All_Time = 14861.833
503150/758000 (epoch 1327), train_loss = 0.214, time/batch = 0.030, All_Time = 14863.333
503200/758000 (epoch 1327), train_loss = 0.272, time/batch = 0.031, All_Time = 14864.848
503250/758000 (epoch 1327), train_loss = 0.213, time/batch = 0.029, All_Time = 14866.329
503300/758000 (epoch 1327), train_loss = 0.251, time/batch = 0.030, All_Time = 14867.832
503350/758000 (epoch 1328), train_loss = 0.247, time/batch = 0.030, All_Time = 14869.321
503400/758000 (epoch 1328), train_loss = 0.229, time/batch = 0.029, All_Time = 14870.799
503450/758000 (epoch 1328), train_loss = 0.217, time/batch = 0.029, All_Time = 14872.276
503500/758000 (epoch 1328), train_loss = 0.220, time/batch = 0.028, All_Time = 14873.764
503550/758000 (epoch 1328), train_loss = 0.250, time/batch = 0.029, All_Time = 14875.252
503600/758000 (epoch 1328), train_loss = 0.207, time/batch = 0.030, All_Time = 14876.725
503650/758000 (epoch 1328), train_loss = 0.268, time/batch = 0.032, All_Time = 14878.214
503700/758000 (epoch 1329), train_loss = 0.256, time/batch = 0.031, All_Time = 14879.683
503750/758000 (epoch 1329), train_loss = 0.264, time/batch = 0.030, All_Time = 14881.161
503800/758000 (epoch 1329), train_loss = 0.284, time/batch = 0.030, All_Time = 14882.647
503850/758000 (epoch 1329), train_loss = 0.239, time/batch = 0.029, All_Time = 14884.141
503900/758000 (epoch 1329), train_loss = 0.267, time/batch = 0.029, All_Time = 14885.635
503950/758000 (epoch 1329), train_loss = 0.256, time/batch = 0.030, All_Time = 14887.118
504000/758000 (epoch 1329), train_loss = 0.236, time/batch = 0.030, All_Time = 14888.604
model saved to NER/polyglot/model.ckpt
504050/758000 (epoch 1329), train_loss = 0.268, time/batch = 0.029, All_Time = 14890.088
504100/758000 (epoch 1330), train_loss = 0.226, time/batch = 0.031, All_Time = 14891.566
504150/758000 (epoch 1330), train_loss = 0.222, time/batch = 0.029, All_Time = 14893.027
504200/758000 (epoch 1330), train_loss = 0.261, time/batch = 0.028, All_Time = 14894.494
504250/758000 (epoch 1330), train_loss = 0.254, time/batch = 0.030, All_Time = 14895.965
504300/758000 (epoch 1330), train_loss = 0.223, time/batch = 0.029, All_Time = 14897.436
504350/758000 (epoch 1330), train_loss = 0.242, time/batch = 0.030, All_Time = 14898.947
504400/758000 (epoch 1330), train_loss = 0.251, time/batch = 0.031, All_Time = 14900.434
504450/758000 (epoch 1331), train_loss = 0.192, time/batch = 0.030, All_Time = 14901.917
504500/758000 (epoch 1331), train_loss = 0.273, time/batch = 0.029, All_Time = 14903.378
504550/758000 (epoch 1331), train_loss = 0.217, time/batch = 0.028, All_Time = 14904.847
504600/758000 (epoch 1331), train_loss = 0.240, time/batch = 0.031, All_Time = 14906.315
504650/758000 (epoch 1331), train_loss = 0.221, time/batch = 0.029, All_Time = 14907.784
504700/758000 (epoch 1331), train_loss = 0.221, time/batch = 0.029, All_Time = 14909.254
504750/758000 (epoch 1331), train_loss = 0.252, time/batch = 0.032, All_Time = 14910.780
504800/758000 (epoch 1331), train_loss = 0.272, time/batch = 0.031, All_Time = 14912.266
504850/758000 (epoch 1332), train_loss = 0.222, time/batch = 0.030, All_Time = 14913.766
504900/758000 (epoch 1332), train_loss = 0.279, time/batch = 0.030, All_Time = 14915.226
504950/758000 (epoch 1332), train_loss = 0.242, time/batch = 0.029, All_Time = 14916.682
505000/758000 (epoch 1332), train_loss = 0.274, time/batch = 0.029, All_Time = 14918.158
model saved to NER/polyglot/model.ckpt
505050/758000 (epoch 1332), train_loss = 0.262, time/batch = 0.030, All_Time = 14919.632
505100/758000 (epoch 1332), train_loss = 0.197, time/batch = 0.029, All_Time = 14921.107
505150/758000 (epoch 1332), train_loss = 0.233, time/batch = 0.029, All_Time = 14922.579
505200/758000 (epoch 1332), train_loss = 0.281, time/batch = 0.030, All_Time = 14924.054
505250/758000 (epoch 1333), train_loss = 0.246, time/batch = 0.030, All_Time = 14925.526
505300/758000 (epoch 1333), train_loss = 0.212, time/batch = 0.030, All_Time = 14927.020
505350/758000 (epoch 1333), train_loss = 0.255, time/batch = 0.030, All_Time = 14928.502
505400/758000 (epoch 1333), train_loss = 0.271, time/batch = 0.030, All_Time = 14929.992
505450/758000 (epoch 1333), train_loss = 0.203, time/batch = 0.029, All_Time = 14931.474
505500/758000 (epoch 1333), train_loss = 0.226, time/batch = 0.030, All_Time = 14932.949
505550/758000 (epoch 1333), train_loss = 0.254, time/batch = 0.029, All_Time = 14934.444
505600/758000 (epoch 1334), train_loss = 0.219, time/batch = 0.028, All_Time = 14935.931
505650/758000 (epoch 1334), train_loss = 0.265, time/batch = 0.029, All_Time = 14937.393
505700/758000 (epoch 1334), train_loss = 0.227, time/batch = 0.030, All_Time = 14938.857
505750/758000 (epoch 1334), train_loss = 0.213, time/batch = 0.029, All_Time = 14940.321
505800/758000 (epoch 1334), train_loss = 0.224, time/batch = 0.029, All_Time = 14941.790
505850/758000 (epoch 1334), train_loss = 0.213, time/batch = 0.030, All_Time = 14943.263
505900/758000 (epoch 1334), train_loss = 0.230, time/batch = 0.030, All_Time = 14944.739
505950/758000 (epoch 1334), train_loss = 0.223, time/batch = 0.030, All_Time = 14946.240
506000/758000 (epoch 1335), train_loss = 0.275, time/batch = 0.028, All_Time = 14947.717
model saved to NER/polyglot/model.ckpt
506050/758000 (epoch 1335), train_loss = 0.229, time/batch = 0.029, All_Time = 14949.186
506100/758000 (epoch 1335), train_loss = 0.270, time/batch = 0.030, All_Time = 14950.649
506150/758000 (epoch 1335), train_loss = 0.273, time/batch = 0.030, All_Time = 14952.134
506200/758000 (epoch 1335), train_loss = 0.233, time/batch = 0.029, All_Time = 14953.643
506250/758000 (epoch 1335), train_loss = 0.268, time/batch = 0.029, All_Time = 14955.136
506300/758000 (epoch 1335), train_loss = 0.280, time/batch = 0.029, All_Time = 14956.619
506350/758000 (epoch 1336), train_loss = 0.239, time/batch = 0.029, All_Time = 14958.097
506400/758000 (epoch 1336), train_loss = 0.218, time/batch = 0.029, All_Time = 14959.564
506450/758000 (epoch 1336), train_loss = 0.243, time/batch = 0.029, All_Time = 14961.031
506500/758000 (epoch 1336), train_loss = 0.244, time/batch = 0.029, All_Time = 14962.505
506550/758000 (epoch 1336), train_loss = 0.243, time/batch = 0.031, All_Time = 14963.979
506600/758000 (epoch 1336), train_loss = 0.244, time/batch = 0.030, All_Time = 14965.464
506650/758000 (epoch 1336), train_loss = 0.213, time/batch = 0.028, All_Time = 14966.953
506700/758000 (epoch 1336), train_loss = 0.289, time/batch = 0.031, All_Time = 14968.453
506750/758000 (epoch 1337), train_loss = 0.237, time/batch = 0.029, All_Time = 14969.926
506800/758000 (epoch 1337), train_loss = 0.246, time/batch = 0.031, All_Time = 14971.408
506850/758000 (epoch 1337), train_loss = 0.288, time/batch = 0.030, All_Time = 14972.875
506900/758000 (epoch 1337), train_loss = 0.257, time/batch = 0.029, All_Time = 14974.336
506950/758000 (epoch 1337), train_loss = 0.218, time/batch = 0.029, All_Time = 14975.796
507000/758000 (epoch 1337), train_loss = 0.238, time/batch = 0.029, All_Time = 14977.301
model saved to NER/polyglot/model.ckpt
507050/758000 (epoch 1337), train_loss = 0.251, time/batch = 0.029, All_Time = 14978.789
507100/758000 (epoch 1337), train_loss = 0.251, time/batch = 0.030, All_Time = 14980.261
507150/758000 (epoch 1338), train_loss = 0.252, time/batch = 0.029, All_Time = 14981.729
507200/758000 (epoch 1338), train_loss = 0.280, time/batch = 0.030, All_Time = 14983.194
507250/758000 (epoch 1338), train_loss = 0.242, time/batch = 0.031, All_Time = 14984.660
507300/758000 (epoch 1338), train_loss = 0.250, time/batch = 0.030, All_Time = 14986.148
507350/758000 (epoch 1338), train_loss = 0.239, time/batch = 0.029, All_Time = 14987.632
507400/758000 (epoch 1338), train_loss = 0.239, time/batch = 0.031, All_Time = 14989.120
507450/758000 (epoch 1338), train_loss = 0.250, time/batch = 0.031, All_Time = 14990.601
507500/758000 (epoch 1339), train_loss = 0.221, time/batch = 0.029, All_Time = 14992.070
507550/758000 (epoch 1339), train_loss = 0.219, time/batch = 0.030, All_Time = 14993.530
507600/758000 (epoch 1339), train_loss = 0.246, time/batch = 0.028, All_Time = 14994.994
507650/758000 (epoch 1339), train_loss = 0.262, time/batch = 0.028, All_Time = 14996.455
507700/758000 (epoch 1339), train_loss = 0.260, time/batch = 0.031, All_Time = 14997.944
507750/758000 (epoch 1339), train_loss = 0.241, time/batch = 0.029, All_Time = 14999.443
507800/758000 (epoch 1339), train_loss = 0.210, time/batch = 0.030, All_Time = 15000.935
507850/758000 (epoch 1339), train_loss = 0.239, time/batch = 0.029, All_Time = 15002.433
507900/758000 (epoch 1340), train_loss = 0.230, time/batch = 0.028, All_Time = 15003.903
507950/758000 (epoch 1340), train_loss = 0.226, time/batch = 0.030, All_Time = 15005.383
508000/758000 (epoch 1340), train_loss = 0.264, time/batch = 0.029, All_Time = 15006.860
model saved to NER/polyglot/model.ckpt
508050/758000 (epoch 1340), train_loss = 0.240, time/batch = 0.030, All_Time = 15008.327
508100/758000 (epoch 1340), train_loss = 0.253, time/batch = 0.029, All_Time = 15009.782
508150/758000 (epoch 1340), train_loss = 0.251, time/batch = 0.029, All_Time = 15011.248
508200/758000 (epoch 1340), train_loss = 0.248, time/batch = 0.030, All_Time = 15012.726
508250/758000 (epoch 1341), train_loss = 0.216, time/batch = 0.030, All_Time = 15014.209
508300/758000 (epoch 1341), train_loss = 0.233, time/batch = 0.030, All_Time = 15015.685
508350/758000 (epoch 1341), train_loss = 0.250, time/batch = 0.028, All_Time = 15017.149
508400/758000 (epoch 1341), train_loss = 0.241, time/batch = 0.030, All_Time = 15018.621
508450/758000 (epoch 1341), train_loss = 0.243, time/batch = 0.031, All_Time = 15020.102
508500/758000 (epoch 1341), train_loss = 0.242, time/batch = 0.032, All_Time = 15021.584
508550/758000 (epoch 1341), train_loss = 0.230, time/batch = 0.032, All_Time = 15023.100
508600/758000 (epoch 1341), train_loss = 0.259, time/batch = 0.029, All_Time = 15024.596
508650/758000 (epoch 1342), train_loss = 0.250, time/batch = 0.030, All_Time = 15026.070
508700/758000 (epoch 1342), train_loss = 0.253, time/batch = 0.030, All_Time = 15027.534
508750/758000 (epoch 1342), train_loss = 0.245, time/batch = 0.029, All_Time = 15028.999
508800/758000 (epoch 1342), train_loss = 0.231, time/batch = 0.029, All_Time = 15030.513
508850/758000 (epoch 1342), train_loss = 0.228, time/batch = 0.030, All_Time = 15032.013
508900/758000 (epoch 1342), train_loss = 0.238, time/batch = 0.031, All_Time = 15033.508
508950/758000 (epoch 1342), train_loss = 0.268, time/batch = 0.032, All_Time = 15035.005
509000/758000 (epoch 1343), train_loss = 0.248, time/batch = 0.029, All_Time = 15036.481
model saved to NER/polyglot/model.ckpt
509050/758000 (epoch 1343), train_loss = 0.280, time/batch = 0.028, All_Time = 15037.946
509100/758000 (epoch 1343), train_loss = 0.242, time/batch = 0.028, All_Time = 15039.402
509150/758000 (epoch 1343), train_loss = 0.258, time/batch = 0.029, All_Time = 15040.862
509200/758000 (epoch 1343), train_loss = 0.224, time/batch = 0.029, All_Time = 15042.324
509250/758000 (epoch 1343), train_loss = 0.243, time/batch = 0.030, All_Time = 15043.813
509300/758000 (epoch 1343), train_loss = 0.219, time/batch = 0.031, All_Time = 15045.317
509350/758000 (epoch 1343), train_loss = 0.232, time/batch = 0.030, All_Time = 15046.796
509400/758000 (epoch 1344), train_loss = 0.237, time/batch = 0.029, All_Time = 15048.274
509450/758000 (epoch 1344), train_loss = 0.239, time/batch = 0.031, All_Time = 15049.741
509500/758000 (epoch 1344), train_loss = 0.293, time/batch = 0.029, All_Time = 15051.220
509550/758000 (epoch 1344), train_loss = 0.318, time/batch = 0.031, All_Time = 15052.686
509600/758000 (epoch 1344), train_loss = 0.196, time/batch = 0.031, All_Time = 15054.148
509650/758000 (epoch 1344), train_loss = 0.213, time/batch = 0.028, All_Time = 15055.602
509700/758000 (epoch 1344), train_loss = 0.250, time/batch = 0.031, All_Time = 15057.074
509750/758000 (epoch 1344), train_loss = 0.297, time/batch = 0.029, All_Time = 15058.575
509800/758000 (epoch 1345), train_loss = 0.226, time/batch = 0.030, All_Time = 15060.068
509850/758000 (epoch 1345), train_loss = 0.259, time/batch = 0.031, All_Time = 15061.557
509900/758000 (epoch 1345), train_loss = 0.223, time/batch = 0.029, All_Time = 15063.033
509950/758000 (epoch 1345), train_loss = 0.239, time/batch = 0.029, All_Time = 15064.506
510000/758000 (epoch 1345), train_loss = 0.212, time/batch = 0.030, All_Time = 15065.977
model saved to NER/polyglot/model.ckpt
510050/758000 (epoch 1345), train_loss = 0.243, time/batch = 0.030, All_Time = 15067.457
510100/758000 (epoch 1345), train_loss = 0.215, time/batch = 0.030, All_Time = 15068.924
510150/758000 (epoch 1346), train_loss = 0.228, time/batch = 0.029, All_Time = 15070.398
510200/758000 (epoch 1346), train_loss = 0.252, time/batch = 0.031, All_Time = 15071.867
510250/758000 (epoch 1346), train_loss = 0.260, time/batch = 0.032, All_Time = 15073.386
510300/758000 (epoch 1346), train_loss = 0.228, time/batch = 0.030, All_Time = 15074.890
510350/758000 (epoch 1346), train_loss = 0.236, time/batch = 0.030, All_Time = 15076.377
510400/758000 (epoch 1346), train_loss = 0.271, time/batch = 0.032, All_Time = 15077.864
510450/758000 (epoch 1346), train_loss = 0.238, time/batch = 0.029, All_Time = 15079.344
510500/758000 (epoch 1346), train_loss = 0.268, time/batch = 0.030, All_Time = 15080.829
510550/758000 (epoch 1347), train_loss = 0.248, time/batch = 0.029, All_Time = 15082.302
510600/758000 (epoch 1347), train_loss = 0.249, time/batch = 0.030, All_Time = 15083.773
510650/758000 (epoch 1347), train_loss = 0.240, time/batch = 0.030, All_Time = 15085.246
510700/758000 (epoch 1347), train_loss = 0.247, time/batch = 0.029, All_Time = 15086.711
510750/758000 (epoch 1347), train_loss = 0.235, time/batch = 0.029, All_Time = 15088.199
510800/758000 (epoch 1347), train_loss = 0.247, time/batch = 0.030, All_Time = 15089.685
510850/758000 (epoch 1347), train_loss = 0.251, time/batch = 0.029, All_Time = 15091.182
510900/758000 (epoch 1348), train_loss = 0.242, time/batch = 0.031, All_Time = 15092.666
510950/758000 (epoch 1348), train_loss = 0.276, time/batch = 0.031, All_Time = 15094.147
511000/758000 (epoch 1348), train_loss = 0.256, time/batch = 0.029, All_Time = 15095.618
model saved to NER/polyglot/model.ckpt
511050/758000 (epoch 1348), train_loss = 0.258, time/batch = 0.029, All_Time = 15097.086
511100/758000 (epoch 1348), train_loss = 0.213, time/batch = 0.031, All_Time = 15098.558
511150/758000 (epoch 1348), train_loss = 0.237, time/batch = 0.030, All_Time = 15100.074
511200/758000 (epoch 1348), train_loss = 0.249, time/batch = 0.032, All_Time = 15101.563
511250/758000 (epoch 1348), train_loss = 0.251, time/batch = 0.031, All_Time = 15103.045
511300/758000 (epoch 1349), train_loss = 0.232, time/batch = 0.030, All_Time = 15104.517
511350/758000 (epoch 1349), train_loss = 0.255, time/batch = 0.029, All_Time = 15106.005
511400/758000 (epoch 1349), train_loss = 0.265, time/batch = 0.029, All_Time = 15107.503
511450/758000 (epoch 1349), train_loss = 0.229, time/batch = 0.029, All_Time = 15108.990
511500/758000 (epoch 1349), train_loss = 0.263, time/batch = 0.029, All_Time = 15110.475
511550/758000 (epoch 1349), train_loss = 0.217, time/batch = 0.031, All_Time = 15111.952
511600/758000 (epoch 1349), train_loss = 0.248, time/batch = 0.029, All_Time = 15113.429
511650/758000 (epoch 1350), train_loss = 0.059, time/batch = 0.030, All_Time = 15114.909
511700/758000 (epoch 1350), train_loss = 0.250, time/batch = 0.029, All_Time = 15116.385
511750/758000 (epoch 1350), train_loss = 0.223, time/batch = 0.028, All_Time = 15117.847
511800/758000 (epoch 1350), train_loss = 0.250, time/batch = 0.030, All_Time = 15119.311
511850/758000 (epoch 1350), train_loss = 0.231, time/batch = 0.031, All_Time = 15120.830
511900/758000 (epoch 1350), train_loss = 0.250, time/batch = 0.030, All_Time = 15122.319
511950/758000 (epoch 1350), train_loss = 0.232, time/batch = 0.029, All_Time = 15123.796
512000/758000 (epoch 1350), train_loss = 0.230, time/batch = 0.029, All_Time = 15125.273
model saved to NER/polyglot/model.ckpt
512050/758000 (epoch 1351), train_loss = 0.224, time/batch = 0.029, All_Time = 15126.745
512100/758000 (epoch 1351), train_loss = 0.233, time/batch = 0.028, All_Time = 15128.216
512150/758000 (epoch 1351), train_loss = 0.224, time/batch = 0.029, All_Time = 15129.679
512200/758000 (epoch 1351), train_loss = 0.262, time/batch = 0.029, All_Time = 15131.131
512250/758000 (epoch 1351), train_loss = 0.220, time/batch = 0.030, All_Time = 15132.610
512300/758000 (epoch 1351), train_loss = 0.228, time/batch = 0.029, All_Time = 15134.100
512350/758000 (epoch 1351), train_loss = 0.280, time/batch = 0.031, All_Time = 15135.608
512400/758000 (epoch 1351), train_loss = 0.272, time/batch = 0.029, All_Time = 15137.090
512450/758000 (epoch 1352), train_loss = 0.230, time/batch = 0.030, All_Time = 15138.579
512500/758000 (epoch 1352), train_loss = 0.224, time/batch = 0.029, All_Time = 15140.049
512550/758000 (epoch 1352), train_loss = 0.201, time/batch = 0.028, All_Time = 15141.519
512600/758000 (epoch 1352), train_loss = 0.270, time/batch = 0.029, All_Time = 15142.997
512650/758000 (epoch 1352), train_loss = 0.259, time/batch = 0.030, All_Time = 15144.467
512700/758000 (epoch 1352), train_loss = 0.209, time/batch = 0.030, All_Time = 15145.957
512750/758000 (epoch 1352), train_loss = 0.218, time/batch = 0.029, All_Time = 15147.456
512800/758000 (epoch 1353), train_loss = 0.229, time/batch = 0.029, All_Time = 15148.958
512850/758000 (epoch 1353), train_loss = 0.283, time/batch = 0.030, All_Time = 15150.424
512900/758000 (epoch 1353), train_loss = 0.231, time/batch = 0.030, All_Time = 15151.891
512950/758000 (epoch 1353), train_loss = 0.307, time/batch = 0.032, All_Time = 15153.365
513000/758000 (epoch 1353), train_loss = 0.221, time/batch = 0.029, All_Time = 15154.860
model saved to NER/polyglot/model.ckpt
513050/758000 (epoch 1353), train_loss = 0.208, time/batch = 0.030, All_Time = 15156.338
513100/758000 (epoch 1353), train_loss = 0.247, time/batch = 0.029, All_Time = 15157.818
513150/758000 (epoch 1353), train_loss = 0.252, time/batch = 0.028, All_Time = 15159.295
513200/758000 (epoch 1354), train_loss = 0.264, time/batch = 0.028, All_Time = 15160.781
513250/758000 (epoch 1354), train_loss = 0.229, time/batch = 0.029, All_Time = 15162.252
513300/758000 (epoch 1354), train_loss = 0.242, time/batch = 0.028, All_Time = 15163.717
513350/758000 (epoch 1354), train_loss = 0.267, time/batch = 0.029, All_Time = 15165.208
513400/758000 (epoch 1354), train_loss = 0.249, time/batch = 0.029, All_Time = 15166.696
513450/758000 (epoch 1354), train_loss = 0.237, time/batch = 0.029, All_Time = 15168.172
513500/758000 (epoch 1354), train_loss = 0.276, time/batch = 0.028, All_Time = 15169.656
513550/758000 (epoch 1355), train_loss = 0.256, time/batch = 0.030, All_Time = 15171.147
513600/758000 (epoch 1355), train_loss = 0.222, time/batch = 0.030, All_Time = 15172.640
513650/758000 (epoch 1355), train_loss = 0.266, time/batch = 0.029, All_Time = 15174.126
513700/758000 (epoch 1355), train_loss = 0.216, time/batch = 0.032, All_Time = 15175.615
513750/758000 (epoch 1355), train_loss = 0.223, time/batch = 0.030, All_Time = 15177.101
513800/758000 (epoch 1355), train_loss = 0.261, time/batch = 0.029, All_Time = 15178.584
513850/758000 (epoch 1355), train_loss = 0.238, time/batch = 0.030, All_Time = 15180.068
513900/758000 (epoch 1355), train_loss = 0.264, time/batch = 0.030, All_Time = 15181.546
513950/758000 (epoch 1356), train_loss = 0.223, time/batch = 0.030, All_Time = 15183.032
514000/758000 (epoch 1356), train_loss = 0.231, time/batch = 0.029, All_Time = 15184.506
model saved to NER/polyglot/model.ckpt
514050/758000 (epoch 1356), train_loss = 0.238, time/batch = 0.028, All_Time = 15185.984
514100/758000 (epoch 1356), train_loss = 0.266, time/batch = 0.029, All_Time = 15187.453
514150/758000 (epoch 1356), train_loss = 0.239, time/batch = 0.030, All_Time = 15188.923
514200/758000 (epoch 1356), train_loss = 0.226, time/batch = 0.030, All_Time = 15190.406
514250/758000 (epoch 1356), train_loss = 0.276, time/batch = 0.029, All_Time = 15191.926
514300/758000 (epoch 1356), train_loss = 0.240, time/batch = 0.029, All_Time = 15193.429
514350/758000 (epoch 1357), train_loss = 0.281, time/batch = 0.030, All_Time = 15194.910
514400/758000 (epoch 1357), train_loss = 0.257, time/batch = 0.031, All_Time = 15196.383
514450/758000 (epoch 1357), train_loss = 0.240, time/batch = 0.031, All_Time = 15197.867
514500/758000 (epoch 1357), train_loss = 0.231, time/batch = 0.031, All_Time = 15199.350
514550/758000 (epoch 1357), train_loss = 0.217, time/batch = 0.030, All_Time = 15200.819
514600/758000 (epoch 1357), train_loss = 0.224, time/batch = 0.029, All_Time = 15202.292
514650/758000 (epoch 1357), train_loss = 0.215, time/batch = 0.029, All_Time = 15203.764
514700/758000 (epoch 1358), train_loss = 0.249, time/batch = 0.030, All_Time = 15205.248
514750/758000 (epoch 1358), train_loss = 0.211, time/batch = 0.030, All_Time = 15206.714
514800/758000 (epoch 1358), train_loss = 0.245, time/batch = 0.029, All_Time = 15208.201
514850/758000 (epoch 1358), train_loss = 0.217, time/batch = 0.032, All_Time = 15209.718
514900/758000 (epoch 1358), train_loss = 0.233, time/batch = 0.029, All_Time = 15211.198
514950/758000 (epoch 1358), train_loss = 0.228, time/batch = 0.031, All_Time = 15212.688
515000/758000 (epoch 1358), train_loss = 0.248, time/batch = 0.030, All_Time = 15214.182
model saved to NER/polyglot/model.ckpt
515050/758000 (epoch 1358), train_loss = 0.229, time/batch = 0.030, All_Time = 15215.650
515100/758000 (epoch 1359), train_loss = 0.218, time/batch = 0.028, All_Time = 15217.132
515150/758000 (epoch 1359), train_loss = 0.237, time/batch = 0.029, All_Time = 15218.592
515200/758000 (epoch 1359), train_loss = 0.212, time/batch = 0.029, All_Time = 15220.067
515250/758000 (epoch 1359), train_loss = 0.266, time/batch = 0.032, All_Time = 15221.567
515300/758000 (epoch 1359), train_loss = 0.255, time/batch = 0.031, All_Time = 15223.054
515350/758000 (epoch 1359), train_loss = 0.232, time/batch = 0.030, All_Time = 15224.542
515400/758000 (epoch 1359), train_loss = 0.262, time/batch = 0.030, All_Time = 15226.017
515450/758000 (epoch 1360), train_loss = 0.282, time/batch = 0.030, All_Time = 15227.494
515500/758000 (epoch 1360), train_loss = 0.292, time/batch = 0.028, All_Time = 15228.966
515550/758000 (epoch 1360), train_loss = 0.253, time/batch = 0.029, All_Time = 15230.480
515600/758000 (epoch 1360), train_loss = 0.222, time/batch = 0.029, All_Time = 15231.975
515650/758000 (epoch 1360), train_loss = 0.221, time/batch = 0.031, All_Time = 15233.465
515700/758000 (epoch 1360), train_loss = 0.260, time/batch = 0.029, All_Time = 15234.951
515750/758000 (epoch 1360), train_loss = 0.244, time/batch = 0.031, All_Time = 15236.431
515800/758000 (epoch 1360), train_loss = 0.247, time/batch = 0.030, All_Time = 15237.912
515850/758000 (epoch 1361), train_loss = 0.210, time/batch = 0.030, All_Time = 15239.388
515900/758000 (epoch 1361), train_loss = 0.265, time/batch = 0.028, All_Time = 15240.856
515950/758000 (epoch 1361), train_loss = 0.229, time/batch = 0.029, All_Time = 15242.322
516000/758000 (epoch 1361), train_loss = 0.232, time/batch = 0.030, All_Time = 15243.824
model saved to NER/polyglot/model.ckpt
516050/758000 (epoch 1361), train_loss = 0.230, time/batch = 0.031, All_Time = 15245.305
516100/758000 (epoch 1361), train_loss = 0.253, time/batch = 0.030, All_Time = 15246.783
516150/758000 (epoch 1361), train_loss = 0.258, time/batch = 0.030, All_Time = 15248.261
516200/758000 (epoch 1362), train_loss = 0.196, time/batch = 0.029, All_Time = 15249.735
516250/758000 (epoch 1362), train_loss = 0.254, time/batch = 0.029, All_Time = 15251.210
516300/758000 (epoch 1362), train_loss = 0.281, time/batch = 0.031, All_Time = 15252.680
516350/758000 (epoch 1362), train_loss = 0.235, time/batch = 0.029, All_Time = 15254.166
516400/758000 (epoch 1362), train_loss = 0.247, time/batch = 0.029, All_Time = 15255.683
516450/758000 (epoch 1362), train_loss = 0.251, time/batch = 0.030, All_Time = 15257.163
516500/758000 (epoch 1362), train_loss = 0.203, time/batch = 0.030, All_Time = 15258.656
516550/758000 (epoch 1362), train_loss = 0.268, time/batch = 0.029, All_Time = 15260.131
516600/758000 (epoch 1363), train_loss = 0.233, time/batch = 0.030, All_Time = 15261.609
516650/758000 (epoch 1363), train_loss = 0.241, time/batch = 0.029, All_Time = 15263.082
516700/758000 (epoch 1363), train_loss = 0.252, time/batch = 0.031, All_Time = 15264.546
516750/758000 (epoch 1363), train_loss = 0.258, time/batch = 0.031, All_Time = 15266.022
516800/758000 (epoch 1363), train_loss = 0.243, time/batch = 0.029, All_Time = 15267.500
516850/758000 (epoch 1363), train_loss = 0.243, time/batch = 0.031, All_Time = 15268.971
516900/758000 (epoch 1363), train_loss = 0.244, time/batch = 0.030, All_Time = 15270.461
516950/758000 (epoch 1363), train_loss = 0.286, time/batch = 0.030, All_Time = 15271.947
517000/758000 (epoch 1364), train_loss = 0.207, time/batch = 0.030, All_Time = 15273.419
model saved to NER/polyglot/model.ckpt
517050/758000 (epoch 1364), train_loss = 0.244, time/batch = 0.030, All_Time = 15274.882
517100/758000 (epoch 1364), train_loss = 0.217, time/batch = 0.031, All_Time = 15276.347
517150/758000 (epoch 1364), train_loss = 0.233, time/batch = 0.029, All_Time = 15277.851
517200/758000 (epoch 1364), train_loss = 0.260, time/batch = 0.029, All_Time = 15279.344
517250/758000 (epoch 1364), train_loss = 0.253, time/batch = 0.031, All_Time = 15280.816
517300/758000 (epoch 1364), train_loss = 0.238, time/batch = 0.029, All_Time = 15282.301
517350/758000 (epoch 1365), train_loss = 0.227, time/batch = 0.029, All_Time = 15283.788
517400/758000 (epoch 1365), train_loss = 0.250, time/batch = 0.029, All_Time = 15285.255
517450/758000 (epoch 1365), train_loss = 0.250, time/batch = 0.030, All_Time = 15286.734
517500/758000 (epoch 1365), train_loss = 0.223, time/batch = 0.032, All_Time = 15288.220
517550/758000 (epoch 1365), train_loss = 0.240, time/batch = 0.029, All_Time = 15289.730
517600/758000 (epoch 1365), train_loss = 0.246, time/batch = 0.029, All_Time = 15291.218
517650/758000 (epoch 1365), train_loss = 0.246, time/batch = 0.030, All_Time = 15292.710
517700/758000 (epoch 1365), train_loss = 0.257, time/batch = 0.033, All_Time = 15294.203
517750/758000 (epoch 1366), train_loss = 0.266, time/batch = 0.029, All_Time = 15295.682
517800/758000 (epoch 1366), train_loss = 0.224, time/batch = 0.030, All_Time = 15297.222
517850/758000 (epoch 1366), train_loss = 0.248, time/batch = 0.029, All_Time = 15298.697
517900/758000 (epoch 1366), train_loss = 0.227, time/batch = 0.030, All_Time = 15300.167
517950/758000 (epoch 1366), train_loss = 0.279, time/batch = 0.030, All_Time = 15301.671
518000/758000 (epoch 1366), train_loss = 0.255, time/batch = 0.029, All_Time = 15303.179
model saved to NER/polyglot/model.ckpt
518050/758000 (epoch 1366), train_loss = 0.253, time/batch = 0.030, All_Time = 15304.647
518100/758000 (epoch 1367), train_loss = 0.244, time/batch = 0.028, All_Time = 15306.112
518150/758000 (epoch 1367), train_loss = 0.247, time/batch = 0.030, All_Time = 15307.582
518200/758000 (epoch 1367), train_loss = 0.270, time/batch = 0.028, All_Time = 15309.051
518250/758000 (epoch 1367), train_loss = 0.246, time/batch = 0.030, All_Time = 15310.528
518300/758000 (epoch 1367), train_loss = 0.237, time/batch = 0.029, All_Time = 15312.005
518350/758000 (epoch 1367), train_loss = 0.224, time/batch = 0.028, All_Time = 15313.479
518400/758000 (epoch 1367), train_loss = 0.229, time/batch = 0.030, All_Time = 15314.950
518450/758000 (epoch 1367), train_loss = 0.246, time/batch = 0.031, All_Time = 15316.435
518500/758000 (epoch 1368), train_loss = 0.249, time/batch = 0.029, All_Time = 15317.911
518550/758000 (epoch 1368), train_loss = 0.264, time/batch = 0.030, All_Time = 15319.388
518600/758000 (epoch 1368), train_loss = 0.240, time/batch = 0.031, All_Time = 15320.895
518650/758000 (epoch 1368), train_loss = 0.250, time/batch = 0.029, All_Time = 15322.390
518700/758000 (epoch 1368), train_loss = 0.227, time/batch = 0.029, All_Time = 15323.881
518750/758000 (epoch 1368), train_loss = 0.217, time/batch = 0.029, All_Time = 15325.360
518800/758000 (epoch 1368), train_loss = 0.277, time/batch = 0.029, All_Time = 15326.847
518850/758000 (epoch 1368), train_loss = 0.259, time/batch = 0.031, All_Time = 15328.330
518900/758000 (epoch 1369), train_loss = 0.269, time/batch = 0.029, All_Time = 15329.799
518950/758000 (epoch 1369), train_loss = 0.296, time/batch = 0.029, All_Time = 15331.273
519000/758000 (epoch 1369), train_loss = 0.228, time/batch = 0.030, All_Time = 15332.738
model saved to NER/polyglot/model.ckpt
519050/758000 (epoch 1369), train_loss = 0.220, time/batch = 0.029, All_Time = 15334.207
519100/758000 (epoch 1369), train_loss = 0.257, time/batch = 0.032, All_Time = 15335.671
519150/758000 (epoch 1369), train_loss = 0.255, time/batch = 0.030, All_Time = 15337.140
519200/758000 (epoch 1369), train_loss = 0.237, time/batch = 0.029, All_Time = 15338.613
519250/758000 (epoch 1370), train_loss = 0.225, time/batch = 0.028, All_Time = 15340.088
519300/758000 (epoch 1370), train_loss = 0.234, time/batch = 0.030, All_Time = 15341.559
519350/758000 (epoch 1370), train_loss = 0.243, time/batch = 0.031, All_Time = 15343.081
519400/758000 (epoch 1370), train_loss = 0.234, time/batch = 0.030, All_Time = 15344.577
519450/758000 (epoch 1370), train_loss = 0.223, time/batch = 0.030, All_Time = 15346.056
519500/758000 (epoch 1370), train_loss = 0.239, time/batch = 0.029, All_Time = 15347.537
519550/758000 (epoch 1370), train_loss = 0.264, time/batch = 0.029, All_Time = 15349.017
519600/758000 (epoch 1370), train_loss = 0.244, time/batch = 0.029, All_Time = 15350.492
519650/758000 (epoch 1371), train_loss = 0.257, time/batch = 0.029, All_Time = 15351.955
519700/758000 (epoch 1371), train_loss = 0.287, time/batch = 0.031, All_Time = 15353.425
519750/758000 (epoch 1371), train_loss = 0.255, time/batch = 0.029, All_Time = 15354.893
519800/758000 (epoch 1371), train_loss = 0.248, time/batch = 0.029, All_Time = 15356.366
519850/758000 (epoch 1371), train_loss = 0.212, time/batch = 0.029, All_Time = 15357.839
519900/758000 (epoch 1371), train_loss = 0.229, time/batch = 0.032, All_Time = 15359.332
519950/758000 (epoch 1371), train_loss = 0.272, time/batch = 0.029, All_Time = 15360.824
520000/758000 (epoch 1372), train_loss = 0.249, time/batch = 0.029, All_Time = 15362.308
model saved to NER/polyglot/model.ckpt
520050/758000 (epoch 1372), train_loss = 0.227, time/batch = 0.030, All_Time = 15363.776
520100/758000 (epoch 1372), train_loss = 0.267, time/batch = 0.029, All_Time = 15365.242
520150/758000 (epoch 1372), train_loss = 0.239, time/batch = 0.029, All_Time = 15366.707
520200/758000 (epoch 1372), train_loss = 0.247, time/batch = 0.029, All_Time = 15368.190
520250/758000 (epoch 1372), train_loss = 0.241, time/batch = 0.031, All_Time = 15369.669
520300/758000 (epoch 1372), train_loss = 0.274, time/batch = 0.029, All_Time = 15371.150
520350/758000 (epoch 1372), train_loss = 0.279, time/batch = 0.030, All_Time = 15372.619
520400/758000 (epoch 1373), train_loss = 0.238, time/batch = 0.030, All_Time = 15374.106
520450/758000 (epoch 1373), train_loss = 0.248, time/batch = 0.030, All_Time = 15375.576
520500/758000 (epoch 1373), train_loss = 0.299, time/batch = 0.030, All_Time = 15377.054
520550/758000 (epoch 1373), train_loss = 0.230, time/batch = 0.031, All_Time = 15378.535
520600/758000 (epoch 1373), train_loss = 0.216, time/batch = 0.029, All_Time = 15380.015
520650/758000 (epoch 1373), train_loss = 0.244, time/batch = 0.030, All_Time = 15381.508
520700/758000 (epoch 1373), train_loss = 0.274, time/batch = 0.030, All_Time = 15383.006
520750/758000 (epoch 1374), train_loss = 0.221, time/batch = 0.031, All_Time = 15384.496
520800/758000 (epoch 1374), train_loss = 0.257, time/batch = 0.030, All_Time = 15385.966
520850/758000 (epoch 1374), train_loss = 0.241, time/batch = 0.031, All_Time = 15387.432
520900/758000 (epoch 1374), train_loss = 0.240, time/batch = 0.029, All_Time = 15388.913
520950/758000 (epoch 1374), train_loss = 0.256, time/batch = 0.029, All_Time = 15390.396
521000/758000 (epoch 1374), train_loss = 0.219, time/batch = 0.029, All_Time = 15391.862
model saved to NER/polyglot/model.ckpt
521050/758000 (epoch 1374), train_loss = 0.224, time/batch = 0.029, All_Time = 15393.335
521100/758000 (epoch 1374), train_loss = 0.257, time/batch = 0.029, All_Time = 15394.794
521150/758000 (epoch 1375), train_loss = 0.255, time/batch = 0.030, All_Time = 15396.263
521200/758000 (epoch 1375), train_loss = 0.267, time/batch = 0.030, All_Time = 15397.743
521250/758000 (epoch 1375), train_loss = 0.269, time/batch = 0.031, All_Time = 15399.231
521300/758000 (epoch 1375), train_loss = 0.228, time/batch = 0.029, All_Time = 15400.711
521350/758000 (epoch 1375), train_loss = 0.234, time/batch = 0.028, All_Time = 15402.193
521400/758000 (epoch 1375), train_loss = 0.245, time/batch = 0.031, All_Time = 15403.688
521450/758000 (epoch 1375), train_loss = 0.279, time/batch = 0.030, All_Time = 15405.187
521500/758000 (epoch 1375), train_loss = 0.240, time/batch = 0.028, All_Time = 15406.665
521550/758000 (epoch 1376), train_loss = 0.236, time/batch = 0.031, All_Time = 15408.145
521600/758000 (epoch 1376), train_loss = 0.234, time/batch = 0.030, All_Time = 15409.619
521650/758000 (epoch 1376), train_loss = 0.233, time/batch = 0.029, All_Time = 15411.094
521700/758000 (epoch 1376), train_loss = 0.276, time/batch = 0.029, All_Time = 15412.560
521750/758000 (epoch 1376), train_loss = 0.206, time/batch = 0.029, All_Time = 15414.036
521800/758000 (epoch 1376), train_loss = 0.259, time/batch = 0.030, All_Time = 15415.544
521850/758000 (epoch 1376), train_loss = 0.234, time/batch = 0.031, All_Time = 15417.040
521900/758000 (epoch 1377), train_loss = 0.245, time/batch = 0.031, All_Time = 15418.511
521950/758000 (epoch 1377), train_loss = 0.223, time/batch = 0.028, All_Time = 15419.981
522000/758000 (epoch 1377), train_loss = 0.240, time/batch = 0.029, All_Time = 15421.454
model saved to NER/polyglot/model.ckpt
522050/758000 (epoch 1377), train_loss = 0.256, time/batch = 0.031, All_Time = 15422.912
522100/758000 (epoch 1377), train_loss = 0.214, time/batch = 0.029, All_Time = 15424.372
522150/758000 (epoch 1377), train_loss = 0.272, time/batch = 0.030, All_Time = 15425.848
522200/758000 (epoch 1377), train_loss = 0.213, time/batch = 0.029, All_Time = 15427.311
522250/758000 (epoch 1377), train_loss = 0.251, time/batch = 0.029, All_Time = 15428.818
522300/758000 (epoch 1378), train_loss = 0.247, time/batch = 0.030, All_Time = 15430.309
522350/758000 (epoch 1378), train_loss = 0.229, time/batch = 0.029, All_Time = 15431.775
522400/758000 (epoch 1378), train_loss = 0.217, time/batch = 0.030, All_Time = 15433.243
522450/758000 (epoch 1378), train_loss = 0.220, time/batch = 0.030, All_Time = 15434.712
522500/758000 (epoch 1378), train_loss = 0.250, time/batch = 0.030, All_Time = 15436.187
522550/758000 (epoch 1378), train_loss = 0.207, time/batch = 0.030, All_Time = 15437.708
522600/758000 (epoch 1378), train_loss = 0.268, time/batch = 0.030, All_Time = 15439.216
522650/758000 (epoch 1379), train_loss = 0.256, time/batch = 0.031, All_Time = 15440.716
522700/758000 (epoch 1379), train_loss = 0.264, time/batch = 0.028, All_Time = 15442.186
522750/758000 (epoch 1379), train_loss = 0.284, time/batch = 0.030, All_Time = 15443.660
522800/758000 (epoch 1379), train_loss = 0.239, time/batch = 0.029, All_Time = 15445.125
522850/758000 (epoch 1379), train_loss = 0.267, time/batch = 0.029, All_Time = 15446.600
522900/758000 (epoch 1379), train_loss = 0.256, time/batch = 0.029, All_Time = 15448.076
522950/758000 (epoch 1379), train_loss = 0.236, time/batch = 0.030, All_Time = 15449.551
523000/758000 (epoch 1379), train_loss = 0.268, time/batch = 0.030, All_Time = 15451.029
model saved to NER/polyglot/model.ckpt
523050/758000 (epoch 1380), train_loss = 0.226, time/batch = 0.030, All_Time = 15452.497
523100/758000 (epoch 1380), train_loss = 0.222, time/batch = 0.029, All_Time = 15453.981
523150/758000 (epoch 1380), train_loss = 0.261, time/batch = 0.029, All_Time = 15455.443
523200/758000 (epoch 1380), train_loss = 0.254, time/batch = 0.029, All_Time = 15456.913
523250/758000 (epoch 1380), train_loss = 0.223, time/batch = 0.030, All_Time = 15458.430
523300/758000 (epoch 1380), train_loss = 0.242, time/batch = 0.030, All_Time = 15459.920
523350/758000 (epoch 1380), train_loss = 0.251, time/batch = 0.030, All_Time = 15461.404
523400/758000 (epoch 1381), train_loss = 0.192, time/batch = 0.031, All_Time = 15462.897
523450/758000 (epoch 1381), train_loss = 0.273, time/batch = 0.029, All_Time = 15464.370
523500/758000 (epoch 1381), train_loss = 0.217, time/batch = 0.029, All_Time = 15465.838
523550/758000 (epoch 1381), train_loss = 0.240, time/batch = 0.031, All_Time = 15467.309
523600/758000 (epoch 1381), train_loss = 0.221, time/batch = 0.030, All_Time = 15468.829
523650/758000 (epoch 1381), train_loss = 0.221, time/batch = 0.030, All_Time = 15470.302
523700/758000 (epoch 1381), train_loss = 0.252, time/batch = 0.029, All_Time = 15471.789
523750/758000 (epoch 1381), train_loss = 0.272, time/batch = 0.029, All_Time = 15473.272
523800/758000 (epoch 1382), train_loss = 0.222, time/batch = 0.028, All_Time = 15474.750
523850/758000 (epoch 1382), train_loss = 0.279, time/batch = 0.028, All_Time = 15476.216
523900/758000 (epoch 1382), train_loss = 0.242, time/batch = 0.029, All_Time = 15477.681
523950/758000 (epoch 1382), train_loss = 0.274, time/batch = 0.028, All_Time = 15479.149
524000/758000 (epoch 1382), train_loss = 0.262, time/batch = 0.028, All_Time = 15480.630
model saved to NER/polyglot/model.ckpt
524050/758000 (epoch 1382), train_loss = 0.197, time/batch = 0.030, All_Time = 15482.115
524100/758000 (epoch 1382), train_loss = 0.233, time/batch = 0.028, All_Time = 15483.635
524150/758000 (epoch 1382), train_loss = 0.281, time/batch = 0.030, All_Time = 15485.130
524200/758000 (epoch 1383), train_loss = 0.246, time/batch = 0.032, All_Time = 15486.638
524250/758000 (epoch 1383), train_loss = 0.212, time/batch = 0.030, All_Time = 15488.141
524300/758000 (epoch 1383), train_loss = 0.255, time/batch = 0.030, All_Time = 15489.616
524350/758000 (epoch 1383), train_loss = 0.271, time/batch = 0.030, All_Time = 15491.100
524400/758000 (epoch 1383), train_loss = 0.203, time/batch = 0.028, All_Time = 15492.584
524450/758000 (epoch 1383), train_loss = 0.226, time/batch = 0.029, All_Time = 15494.078
524500/758000 (epoch 1383), train_loss = 0.254, time/batch = 0.029, All_Time = 15495.551
524550/758000 (epoch 1384), train_loss = 0.219, time/batch = 0.030, All_Time = 15497.031
524600/758000 (epoch 1384), train_loss = 0.265, time/batch = 0.029, All_Time = 15498.498
524650/758000 (epoch 1384), train_loss = 0.227, time/batch = 0.030, All_Time = 15499.956
524700/758000 (epoch 1384), train_loss = 0.213, time/batch = 0.028, All_Time = 15501.423
524750/758000 (epoch 1384), train_loss = 0.224, time/batch = 0.029, All_Time = 15502.898
524800/758000 (epoch 1384), train_loss = 0.213, time/batch = 0.031, All_Time = 15504.396
524850/758000 (epoch 1384), train_loss = 0.230, time/batch = 0.030, All_Time = 15505.911
524900/758000 (epoch 1384), train_loss = 0.223, time/batch = 0.029, All_Time = 15507.392
524950/758000 (epoch 1385), train_loss = 0.275, time/batch = 0.032, All_Time = 15508.872
525000/758000 (epoch 1385), train_loss = 0.229, time/batch = 0.029, All_Time = 15510.343
model saved to NER/polyglot/model.ckpt
525050/758000 (epoch 1385), train_loss = 0.270, time/batch = 0.029, All_Time = 15511.821
525100/758000 (epoch 1385), train_loss = 0.273, time/batch = 0.030, All_Time = 15513.281
525150/758000 (epoch 1385), train_loss = 0.233, time/batch = 0.029, All_Time = 15514.763
525200/758000 (epoch 1385), train_loss = 0.268, time/batch = 0.030, All_Time = 15516.243
525250/758000 (epoch 1385), train_loss = 0.280, time/batch = 0.030, All_Time = 15517.727
525300/758000 (epoch 1386), train_loss = 0.239, time/batch = 0.030, All_Time = 15519.208
525350/758000 (epoch 1386), train_loss = 0.218, time/batch = 0.029, All_Time = 15520.689
525400/758000 (epoch 1386), train_loss = 0.243, time/batch = 0.030, All_Time = 15522.164
525450/758000 (epoch 1386), train_loss = 0.244, time/batch = 0.030, All_Time = 15523.631
525500/758000 (epoch 1386), train_loss = 0.243, time/batch = 0.029, All_Time = 15525.105
525550/758000 (epoch 1386), train_loss = 0.244, time/batch = 0.029, All_Time = 15526.574
525600/758000 (epoch 1386), train_loss = 0.213, time/batch = 0.030, All_Time = 15528.046
525650/758000 (epoch 1386), train_loss = 0.289, time/batch = 0.029, All_Time = 15529.526
525700/758000 (epoch 1387), train_loss = 0.237, time/batch = 0.029, All_Time = 15531.005
525750/758000 (epoch 1387), train_loss = 0.246, time/batch = 0.030, All_Time = 15532.474
525800/758000 (epoch 1387), train_loss = 0.288, time/batch = 0.029, All_Time = 15533.961
525850/758000 (epoch 1387), train_loss = 0.257, time/batch = 0.029, All_Time = 15535.461
525900/758000 (epoch 1387), train_loss = 0.218, time/batch = 0.033, All_Time = 15536.949
525950/758000 (epoch 1387), train_loss = 0.238, time/batch = 0.029, All_Time = 15538.434
526000/758000 (epoch 1387), train_loss = 0.251, time/batch = 0.031, All_Time = 15539.994
model saved to NER/polyglot/model.ckpt
526050/758000 (epoch 1387), train_loss = 0.251, time/batch = 0.029, All_Time = 15541.463
526100/758000 (epoch 1388), train_loss = 0.252, time/batch = 0.028, All_Time = 15542.931
526150/758000 (epoch 1388), train_loss = 0.280, time/batch = 0.029, All_Time = 15544.391
526200/758000 (epoch 1388), train_loss = 0.242, time/batch = 0.030, All_Time = 15545.868
526250/758000 (epoch 1388), train_loss = 0.250, time/batch = 0.030, All_Time = 15547.336
526300/758000 (epoch 1388), train_loss = 0.239, time/batch = 0.029, All_Time = 15548.814
526350/758000 (epoch 1388), train_loss = 0.239, time/batch = 0.030, All_Time = 15550.282
526400/758000 (epoch 1388), train_loss = 0.250, time/batch = 0.030, All_Time = 15551.802
526450/758000 (epoch 1389), train_loss = 0.221, time/batch = 0.030, All_Time = 15553.291
526500/758000 (epoch 1389), train_loss = 0.219, time/batch = 0.029, All_Time = 15554.782
526550/758000 (epoch 1389), train_loss = 0.246, time/batch = 0.029, All_Time = 15556.263
526600/758000 (epoch 1389), train_loss = 0.262, time/batch = 0.029, All_Time = 15557.740
526650/758000 (epoch 1389), train_loss = 0.260, time/batch = 0.030, All_Time = 15559.215
526700/758000 (epoch 1389), train_loss = 0.241, time/batch = 0.033, All_Time = 15560.692
526750/758000 (epoch 1389), train_loss = 0.210, time/batch = 0.029, All_Time = 15562.181
526800/758000 (epoch 1389), train_loss = 0.239, time/batch = 0.029, All_Time = 15563.658
526850/758000 (epoch 1390), train_loss = 0.230, time/batch = 0.029, All_Time = 15565.124
526900/758000 (epoch 1390), train_loss = 0.226, time/batch = 0.030, All_Time = 15566.622
526950/758000 (epoch 1390), train_loss = 0.264, time/batch = 0.031, All_Time = 15568.128
527000/758000 (epoch 1390), train_loss = 0.240, time/batch = 0.029, All_Time = 15569.609
model saved to NER/polyglot/model.ckpt
527050/758000 (epoch 1390), train_loss = 0.253, time/batch = 0.028, All_Time = 15571.077
527100/758000 (epoch 1390), train_loss = 0.251, time/batch = 0.028, All_Time = 15572.532
527150/758000 (epoch 1390), train_loss = 0.248, time/batch = 0.028, All_Time = 15573.998
527200/758000 (epoch 1391), train_loss = 0.216, time/batch = 0.030, All_Time = 15575.485
527250/758000 (epoch 1391), train_loss = 0.233, time/batch = 0.029, All_Time = 15576.981
527300/758000 (epoch 1391), train_loss = 0.250, time/batch = 0.030, All_Time = 15578.457
527350/758000 (epoch 1391), train_loss = 0.241, time/batch = 0.030, All_Time = 15579.932
527400/758000 (epoch 1391), train_loss = 0.243, time/batch = 0.031, All_Time = 15581.411
527450/758000 (epoch 1391), train_loss = 0.242, time/batch = 0.029, All_Time = 15582.890
527500/758000 (epoch 1391), train_loss = 0.230, time/batch = 0.029, All_Time = 15584.371
527550/758000 (epoch 1391), train_loss = 0.259, time/batch = 0.029, All_Time = 15585.853
527600/758000 (epoch 1392), train_loss = 0.250, time/batch = 0.030, All_Time = 15587.334
527650/758000 (epoch 1392), train_loss = 0.253, time/batch = 0.029, All_Time = 15588.808
527700/758000 (epoch 1392), train_loss = 0.245, time/batch = 0.029, All_Time = 15590.283
527750/758000 (epoch 1392), train_loss = 0.231, time/batch = 0.028, All_Time = 15591.773
527800/758000 (epoch 1392), train_loss = 0.228, time/batch = 0.030, All_Time = 15593.282
527850/758000 (epoch 1392), train_loss = 0.238, time/batch = 0.031, All_Time = 15594.767
527900/758000 (epoch 1392), train_loss = 0.268, time/batch = 0.029, All_Time = 15596.246
527950/758000 (epoch 1393), train_loss = 0.248, time/batch = 0.031, All_Time = 15597.727
528000/758000 (epoch 1393), train_loss = 0.280, time/batch = 0.028, All_Time = 15599.206
model saved to NER/polyglot/model.ckpt
528050/758000 (epoch 1393), train_loss = 0.242, time/batch = 0.030, All_Time = 15600.685
528100/758000 (epoch 1393), train_loss = 0.258, time/batch = 0.029, All_Time = 15602.147
528150/758000 (epoch 1393), train_loss = 0.224, time/batch = 0.028, All_Time = 15603.665
528200/758000 (epoch 1393), train_loss = 0.243, time/batch = 0.028, All_Time = 15605.147
528250/758000 (epoch 1393), train_loss = 0.219, time/batch = 0.030, All_Time = 15606.612
528300/758000 (epoch 1393), train_loss = 0.232, time/batch = 0.030, All_Time = 15608.095
528350/758000 (epoch 1394), train_loss = 0.237, time/batch = 0.029, All_Time = 15609.568
528400/758000 (epoch 1394), train_loss = 0.239, time/batch = 0.028, All_Time = 15611.044
528450/758000 (epoch 1394), train_loss = 0.293, time/batch = 0.030, All_Time = 15612.518
528500/758000 (epoch 1394), train_loss = 0.318, time/batch = 0.030, All_Time = 15613.989
528550/758000 (epoch 1394), train_loss = 0.196, time/batch = 0.030, All_Time = 15615.510
528600/758000 (epoch 1394), train_loss = 0.213, time/batch = 0.030, All_Time = 15617.001
528650/758000 (epoch 1394), train_loss = 0.250, time/batch = 0.031, All_Time = 15618.485
528700/758000 (epoch 1394), train_loss = 0.297, time/batch = 0.029, All_Time = 15619.974
528750/758000 (epoch 1395), train_loss = 0.226, time/batch = 0.031, All_Time = 15621.453
528800/758000 (epoch 1395), train_loss = 0.259, time/batch = 0.031, All_Time = 15622.926
528850/758000 (epoch 1395), train_loss = 0.223, time/batch = 0.029, All_Time = 15624.394
528900/758000 (epoch 1395), train_loss = 0.239, time/batch = 0.031, All_Time = 15625.877
528950/758000 (epoch 1395), train_loss = 0.212, time/batch = 0.028, All_Time = 15627.348
529000/758000 (epoch 1395), train_loss = 0.243, time/batch = 0.029, All_Time = 15628.856
model saved to NER/polyglot/model.ckpt
529050/758000 (epoch 1395), train_loss = 0.215, time/batch = 0.030, All_Time = 15630.345
529100/758000 (epoch 1396), train_loss = 0.228, time/batch = 0.030, All_Time = 15631.829
529150/758000 (epoch 1396), train_loss = 0.252, time/batch = 0.032, All_Time = 15633.464
529200/758000 (epoch 1396), train_loss = 0.260, time/batch = 0.030, All_Time = 15634.939
529250/758000 (epoch 1396), train_loss = 0.228, time/batch = 0.029, All_Time = 15636.408
529300/758000 (epoch 1396), train_loss = 0.236, time/batch = 0.029, All_Time = 15637.910
529350/758000 (epoch 1396), train_loss = 0.271, time/batch = 0.029, All_Time = 15639.407
529400/758000 (epoch 1396), train_loss = 0.238, time/batch = 0.029, All_Time = 15640.885
529450/758000 (epoch 1396), train_loss = 0.268, time/batch = 0.031, All_Time = 15642.366
529500/758000 (epoch 1397), train_loss = 0.248, time/batch = 0.031, All_Time = 15643.844
529550/758000 (epoch 1397), train_loss = 0.249, time/batch = 0.030, All_Time = 15645.315
529600/758000 (epoch 1397), train_loss = 0.240, time/batch = 0.030, All_Time = 15646.798
529650/758000 (epoch 1397), train_loss = 0.247, time/batch = 0.030, All_Time = 15648.279
529700/758000 (epoch 1397), train_loss = 0.235, time/batch = 0.029, All_Time = 15649.782
529750/758000 (epoch 1397), train_loss = 0.247, time/batch = 0.031, All_Time = 15651.270
529800/758000 (epoch 1397), train_loss = 0.251, time/batch = 0.030, All_Time = 15652.751
529850/758000 (epoch 1398), train_loss = 0.242, time/batch = 0.029, All_Time = 15654.245
529900/758000 (epoch 1398), train_loss = 0.276, time/batch = 0.029, All_Time = 15655.711
529950/758000 (epoch 1398), train_loss = 0.256, time/batch = 0.030, All_Time = 15657.177
530000/758000 (epoch 1398), train_loss = 0.258, time/batch = 0.030, All_Time = 15658.642
model saved to NER/polyglot/model.ckpt
530050/758000 (epoch 1398), train_loss = 0.213, time/batch = 0.029, All_Time = 15660.121
530100/758000 (epoch 1398), train_loss = 0.237, time/batch = 0.031, All_Time = 15661.582
530150/758000 (epoch 1398), train_loss = 0.249, time/batch = 0.030, All_Time = 15663.089
530200/758000 (epoch 1398), train_loss = 0.251, time/batch = 0.031, All_Time = 15664.567
530250/758000 (epoch 1399), train_loss = 0.232, time/batch = 0.030, All_Time = 15666.046
530300/758000 (epoch 1399), train_loss = 0.255, time/batch = 0.030, All_Time = 15667.529
530350/758000 (epoch 1399), train_loss = 0.265, time/batch = 0.028, All_Time = 15668.997
530400/758000 (epoch 1399), train_loss = 0.229, time/batch = 0.031, All_Time = 15670.471
530450/758000 (epoch 1399), train_loss = 0.263, time/batch = 0.030, All_Time = 15671.988
530500/758000 (epoch 1399), train_loss = 0.217, time/batch = 0.030, All_Time = 15673.468
530550/758000 (epoch 1399), train_loss = 0.248, time/batch = 0.028, All_Time = 15674.955
530600/758000 (epoch 1400), train_loss = 0.059, time/batch = 0.031, All_Time = 15676.449
530650/758000 (epoch 1400), train_loss = 0.250, time/batch = 0.029, All_Time = 15677.916
530700/758000 (epoch 1400), train_loss = 0.223, time/batch = 0.030, All_Time = 15679.373
530750/758000 (epoch 1400), train_loss = 0.250, time/batch = 0.029, All_Time = 15680.839
530800/758000 (epoch 1400), train_loss = 0.231, time/batch = 0.029, All_Time = 15682.320
530850/758000 (epoch 1400), train_loss = 0.250, time/batch = 0.030, All_Time = 15683.797
530900/758000 (epoch 1400), train_loss = 0.232, time/batch = 0.030, All_Time = 15685.298
530950/758000 (epoch 1400), train_loss = 0.230, time/batch = 0.031, All_Time = 15686.790
531000/758000 (epoch 1401), train_loss = 0.224, time/batch = 0.031, All_Time = 15688.280
model saved to NER/polyglot/model.ckpt
531050/758000 (epoch 1401), train_loss = 0.233, time/batch = 0.030, All_Time = 15689.749
531100/758000 (epoch 1401), train_loss = 0.224, time/batch = 0.029, All_Time = 15691.222
531150/758000 (epoch 1401), train_loss = 0.262, time/batch = 0.030, All_Time = 15692.698
531200/758000 (epoch 1401), train_loss = 0.220, time/batch = 0.029, All_Time = 15694.164
531250/758000 (epoch 1401), train_loss = 0.228, time/batch = 0.031, All_Time = 15695.635
531300/758000 (epoch 1401), train_loss = 0.280, time/batch = 0.029, All_Time = 15697.147
531350/758000 (epoch 1401), train_loss = 0.272, time/batch = 0.031, All_Time = 15698.637
531400/758000 (epoch 1402), train_loss = 0.230, time/batch = 0.028, All_Time = 15700.117
531450/758000 (epoch 1402), train_loss = 0.224, time/batch = 0.029, All_Time = 15701.593
531500/758000 (epoch 1402), train_loss = 0.201, time/batch = 0.030, All_Time = 15703.071
531550/758000 (epoch 1402), train_loss = 0.270, time/batch = 0.029, All_Time = 15704.558
531600/758000 (epoch 1402), train_loss = 0.259, time/batch = 0.029, All_Time = 15706.036
531650/758000 (epoch 1402), train_loss = 0.209, time/batch = 0.030, All_Time = 15707.514
531700/758000 (epoch 1402), train_loss = 0.218, time/batch = 0.029, All_Time = 15708.985
531750/758000 (epoch 1403), train_loss = 0.229, time/batch = 0.031, All_Time = 15710.470
531800/758000 (epoch 1403), train_loss = 0.283, time/batch = 0.029, All_Time = 15711.936
531850/758000 (epoch 1403), train_loss = 0.231, time/batch = 0.031, All_Time = 15713.450
531900/758000 (epoch 1403), train_loss = 0.307, time/batch = 0.029, All_Time = 15714.954
531950/758000 (epoch 1403), train_loss = 0.221, time/batch = 0.029, All_Time = 15716.439
532000/758000 (epoch 1403), train_loss = 0.208, time/batch = 0.030, All_Time = 15717.933
model saved to NER/polyglot/model.ckpt
532050/758000 (epoch 1403), train_loss = 0.247, time/batch = 0.029, All_Time = 15719.412
532100/758000 (epoch 1403), train_loss = 0.252, time/batch = 0.030, All_Time = 15720.908
532150/758000 (epoch 1404), train_loss = 0.264, time/batch = 0.031, All_Time = 15722.412
532200/758000 (epoch 1404), train_loss = 0.229, time/batch = 0.030, All_Time = 15723.886
532250/758000 (epoch 1404), train_loss = 0.242, time/batch = 0.029, All_Time = 15725.363
532300/758000 (epoch 1404), train_loss = 0.267, time/batch = 0.029, All_Time = 15726.831
532350/758000 (epoch 1404), train_loss = 0.249, time/batch = 0.029, All_Time = 15728.300
532400/758000 (epoch 1404), train_loss = 0.237, time/batch = 0.028, All_Time = 15729.782
532450/758000 (epoch 1404), train_loss = 0.276, time/batch = 0.029, All_Time = 15731.257
532500/758000 (epoch 1405), train_loss = 0.256, time/batch = 0.029, All_Time = 15732.739
532550/758000 (epoch 1405), train_loss = 0.222, time/batch = 0.028, All_Time = 15734.221
532600/758000 (epoch 1405), train_loss = 0.266, time/batch = 0.031, All_Time = 15735.706
532650/758000 (epoch 1405), train_loss = 0.216, time/batch = 0.029, All_Time = 15737.185
532700/758000 (epoch 1405), train_loss = 0.223, time/batch = 0.030, All_Time = 15738.672
532750/758000 (epoch 1405), train_loss = 0.261, time/batch = 0.031, All_Time = 15740.167
532800/758000 (epoch 1405), train_loss = 0.238, time/batch = 0.029, All_Time = 15741.671
532850/758000 (epoch 1405), train_loss = 0.264, time/batch = 0.030, All_Time = 15743.158
532900/758000 (epoch 1406), train_loss = 0.223, time/batch = 0.029, All_Time = 15744.637
532950/758000 (epoch 1406), train_loss = 0.231, time/batch = 0.029, All_Time = 15746.114
533000/758000 (epoch 1406), train_loss = 0.238, time/batch = 0.029, All_Time = 15747.587
model saved to NER/polyglot/model.ckpt
533050/758000 (epoch 1406), train_loss = 0.266, time/batch = 0.028, All_Time = 15749.058
533100/758000 (epoch 1406), train_loss = 0.239, time/batch = 0.029, All_Time = 15750.519
533150/758000 (epoch 1406), train_loss = 0.226, time/batch = 0.030, All_Time = 15751.999
533200/758000 (epoch 1406), train_loss = 0.276, time/batch = 0.031, All_Time = 15753.518
533250/758000 (epoch 1406), train_loss = 0.240, time/batch = 0.029, All_Time = 15755.003
533300/758000 (epoch 1407), train_loss = 0.281, time/batch = 0.028, All_Time = 15756.473
533350/758000 (epoch 1407), train_loss = 0.257, time/batch = 0.030, All_Time = 15757.942
533400/758000 (epoch 1407), train_loss = 0.240, time/batch = 0.031, All_Time = 15759.401
533450/758000 (epoch 1407), train_loss = 0.231, time/batch = 0.030, All_Time = 15760.896
533500/758000 (epoch 1407), train_loss = 0.217, time/batch = 0.029, All_Time = 15762.379
533550/758000 (epoch 1407), train_loss = 0.224, time/batch = 0.030, All_Time = 15763.857
533600/758000 (epoch 1407), train_loss = 0.215, time/batch = 0.031, All_Time = 15765.338
533650/758000 (epoch 1408), train_loss = 0.249, time/batch = 0.028, All_Time = 15766.844
533700/758000 (epoch 1408), train_loss = 0.211, time/batch = 0.029, All_Time = 15768.302
533750/758000 (epoch 1408), train_loss = 0.245, time/batch = 0.030, All_Time = 15769.775
533800/758000 (epoch 1408), train_loss = 0.217, time/batch = 0.031, All_Time = 15771.254
533850/758000 (epoch 1408), train_loss = 0.233, time/batch = 0.029, All_Time = 15772.823
533900/758000 (epoch 1408), train_loss = 0.228, time/batch = 0.029, All_Time = 15774.305
533950/758000 (epoch 1408), train_loss = 0.248, time/batch = 0.029, All_Time = 15775.776
534000/758000 (epoch 1408), train_loss = 0.229, time/batch = 0.029, All_Time = 15777.252
model saved to NER/polyglot/model.ckpt
534050/758000 (epoch 1409), train_loss = 0.218, time/batch = 0.029, All_Time = 15778.719
534100/758000 (epoch 1409), train_loss = 0.237, time/batch = 0.030, All_Time = 15780.188
534150/758000 (epoch 1409), train_loss = 0.212, time/batch = 0.030, All_Time = 15781.654
534200/758000 (epoch 1409), train_loss = 0.266, time/batch = 0.030, All_Time = 15783.120
534250/758000 (epoch 1409), train_loss = 0.255, time/batch = 0.028, All_Time = 15784.595
534300/758000 (epoch 1409), train_loss = 0.232, time/batch = 0.030, All_Time = 15786.078
534350/758000 (epoch 1409), train_loss = 0.262, time/batch = 0.029, All_Time = 15787.578
534400/758000 (epoch 1410), train_loss = 0.282, time/batch = 0.030, All_Time = 15789.058
534450/758000 (epoch 1410), train_loss = 0.292, time/batch = 0.029, All_Time = 15790.535
534500/758000 (epoch 1410), train_loss = 0.253, time/batch = 0.030, All_Time = 15792.005
534550/758000 (epoch 1410), train_loss = 0.222, time/batch = 0.029, All_Time = 15793.469
534600/758000 (epoch 1410), train_loss = 0.221, time/batch = 0.029, All_Time = 15794.941
534650/758000 (epoch 1410), train_loss = 0.260, time/batch = 0.031, All_Time = 15796.410
534700/758000 (epoch 1410), train_loss = 0.244, time/batch = 0.030, All_Time = 15797.898
534750/758000 (epoch 1410), train_loss = 0.247, time/batch = 0.029, All_Time = 15799.390
534800/758000 (epoch 1411), train_loss = 0.210, time/batch = 0.030, All_Time = 15800.879
534850/758000 (epoch 1411), train_loss = 0.265, time/batch = 0.029, All_Time = 15802.346
534900/758000 (epoch 1411), train_loss = 0.229, time/batch = 0.029, All_Time = 15803.810
534950/758000 (epoch 1411), train_loss = 0.232, time/batch = 0.031, All_Time = 15805.289
535000/758000 (epoch 1411), train_loss = 0.230, time/batch = 0.030, All_Time = 15806.775
model saved to NER/polyglot/model.ckpt
535050/758000 (epoch 1411), train_loss = 0.253, time/batch = 0.030, All_Time = 15808.247
535100/758000 (epoch 1411), train_loss = 0.258, time/batch = 0.030, All_Time = 15809.716
535150/758000 (epoch 1412), train_loss = 0.196, time/batch = 0.030, All_Time = 15811.182
535200/758000 (epoch 1412), train_loss = 0.254, time/batch = 0.029, All_Time = 15812.646
535250/758000 (epoch 1412), train_loss = 0.281, time/batch = 0.029, All_Time = 15814.109
535300/758000 (epoch 1412), train_loss = 0.235, time/batch = 0.029, All_Time = 15815.605
535350/758000 (epoch 1412), train_loss = 0.247, time/batch = 0.029, All_Time = 15817.105
535400/758000 (epoch 1412), train_loss = 0.251, time/batch = 0.029, All_Time = 15818.603
535450/758000 (epoch 1412), train_loss = 0.203, time/batch = 0.030, All_Time = 15820.094
535500/758000 (epoch 1412), train_loss = 0.268, time/batch = 0.030, All_Time = 15821.583
535550/758000 (epoch 1413), train_loss = 0.233, time/batch = 0.029, All_Time = 15823.063
535600/758000 (epoch 1413), train_loss = 0.241, time/batch = 0.030, All_Time = 15824.531
535650/758000 (epoch 1413), train_loss = 0.252, time/batch = 0.030, All_Time = 15826.005
535700/758000 (epoch 1413), train_loss = 0.258, time/batch = 0.031, All_Time = 15827.476
535750/758000 (epoch 1413), train_loss = 0.243, time/batch = 0.029, All_Time = 15828.940
535800/758000 (epoch 1413), train_loss = 0.243, time/batch = 0.029, All_Time = 15830.418
535850/758000 (epoch 1413), train_loss = 0.244, time/batch = 0.029, All_Time = 15831.891
535900/758000 (epoch 1413), train_loss = 0.286, time/batch = 0.029, All_Time = 15833.389
535950/758000 (epoch 1414), train_loss = 0.207, time/batch = 0.029, All_Time = 15834.889
536000/758000 (epoch 1414), train_loss = 0.244, time/batch = 0.030, All_Time = 15836.378
model saved to NER/polyglot/model.ckpt
536050/758000 (epoch 1414), train_loss = 0.217, time/batch = 0.030, All_Time = 15837.873
536100/758000 (epoch 1414), train_loss = 0.233, time/batch = 0.029, All_Time = 15839.365
536150/758000 (epoch 1414), train_loss = 0.260, time/batch = 0.028, All_Time = 15840.837
536200/758000 (epoch 1414), train_loss = 0.253, time/batch = 0.029, All_Time = 15842.308
536250/758000 (epoch 1414), train_loss = 0.238, time/batch = 0.029, All_Time = 15843.778
536300/758000 (epoch 1415), train_loss = 0.227, time/batch = 0.029, All_Time = 15845.254
536350/758000 (epoch 1415), train_loss = 0.250, time/batch = 0.028, All_Time = 15846.725
536400/758000 (epoch 1415), train_loss = 0.250, time/batch = 0.031, All_Time = 15848.196
536450/758000 (epoch 1415), train_loss = 0.223, time/batch = 0.029, All_Time = 15849.692
536500/758000 (epoch 1415), train_loss = 0.240, time/batch = 0.030, All_Time = 15851.184
536550/758000 (epoch 1415), train_loss = 0.246, time/batch = 0.029, All_Time = 15852.670
536600/758000 (epoch 1415), train_loss = 0.246, time/batch = 0.030, All_Time = 15854.157
536650/758000 (epoch 1415), train_loss = 0.257, time/batch = 0.030, All_Time = 15855.651
536700/758000 (epoch 1416), train_loss = 0.266, time/batch = 0.030, All_Time = 15857.128
536750/758000 (epoch 1416), train_loss = 0.224, time/batch = 0.030, All_Time = 15858.593
536800/758000 (epoch 1416), train_loss = 0.248, time/batch = 0.031, All_Time = 15860.071
536850/758000 (epoch 1416), train_loss = 0.227, time/batch = 0.029, All_Time = 15861.576
536900/758000 (epoch 1416), train_loss = 0.279, time/batch = 0.029, All_Time = 15863.056
536950/758000 (epoch 1416), train_loss = 0.255, time/batch = 0.029, All_Time = 15864.528
537000/758000 (epoch 1416), train_loss = 0.253, time/batch = 0.031, All_Time = 15866.015
model saved to NER/polyglot/model.ckpt
537050/758000 (epoch 1417), train_loss = 0.244, time/batch = 0.029, All_Time = 15867.491
537100/758000 (epoch 1417), train_loss = 0.247, time/batch = 0.029, All_Time = 15868.970
537150/758000 (epoch 1417), train_loss = 0.270, time/batch = 0.030, All_Time = 15870.442
537200/758000 (epoch 1417), train_loss = 0.246, time/batch = 0.030, All_Time = 15871.913
537250/758000 (epoch 1417), train_loss = 0.237, time/batch = 0.029, All_Time = 15873.384
537300/758000 (epoch 1417), train_loss = 0.224, time/batch = 0.029, All_Time = 15874.863
537350/758000 (epoch 1417), train_loss = 0.229, time/batch = 0.031, All_Time = 15876.342
537400/758000 (epoch 1417), train_loss = 0.246, time/batch = 0.028, All_Time = 15877.831
537450/758000 (epoch 1418), train_loss = 0.249, time/batch = 0.030, All_Time = 15879.312
537500/758000 (epoch 1418), train_loss = 0.264, time/batch = 0.028, All_Time = 15880.772
537550/758000 (epoch 1418), train_loss = 0.240, time/batch = 0.029, All_Time = 15882.242
537600/758000 (epoch 1418), train_loss = 0.250, time/batch = 0.030, All_Time = 15883.719
537650/758000 (epoch 1418), train_loss = 0.227, time/batch = 0.031, All_Time = 15885.201
537700/758000 (epoch 1418), train_loss = 0.217, time/batch = 0.030, All_Time = 15886.683
537750/758000 (epoch 1418), train_loss = 0.277, time/batch = 0.030, All_Time = 15888.173
537800/758000 (epoch 1418), train_loss = 0.259, time/batch = 0.031, All_Time = 15889.659
537850/758000 (epoch 1419), train_loss = 0.269, time/batch = 0.028, All_Time = 15891.142
537900/758000 (epoch 1419), train_loss = 0.296, time/batch = 0.028, All_Time = 15892.630
537950/758000 (epoch 1419), train_loss = 0.228, time/batch = 0.029, All_Time = 15894.119
538000/758000 (epoch 1419), train_loss = 0.220, time/batch = 0.029, All_Time = 15895.593
model saved to NER/polyglot/model.ckpt
538050/758000 (epoch 1419), train_loss = 0.257, time/batch = 0.029, All_Time = 15897.057
538100/758000 (epoch 1419), train_loss = 0.255, time/batch = 0.030, All_Time = 15898.536
538150/758000 (epoch 1419), train_loss = 0.237, time/batch = 0.029, All_Time = 15900.008
538200/758000 (epoch 1420), train_loss = 0.225, time/batch = 0.030, All_Time = 15901.477
538250/758000 (epoch 1420), train_loss = 0.234, time/batch = 0.032, All_Time = 15902.947
538300/758000 (epoch 1420), train_loss = 0.243, time/batch = 0.030, All_Time = 15904.461
538350/758000 (epoch 1420), train_loss = 0.234, time/batch = 0.031, All_Time = 15905.942
538400/758000 (epoch 1420), train_loss = 0.223, time/batch = 0.029, All_Time = 15907.433
538450/758000 (epoch 1420), train_loss = 0.239, time/batch = 0.030, All_Time = 15908.912
538500/758000 (epoch 1420), train_loss = 0.264, time/batch = 0.029, All_Time = 15910.391
538550/758000 (epoch 1420), train_loss = 0.244, time/batch = 0.029, All_Time = 15911.877
538600/758000 (epoch 1421), train_loss = 0.257, time/batch = 0.029, All_Time = 15913.353
538650/758000 (epoch 1421), train_loss = 0.287, time/batch = 0.031, All_Time = 15914.825
538700/758000 (epoch 1421), train_loss = 0.255, time/batch = 0.030, All_Time = 15916.302
538750/758000 (epoch 1421), train_loss = 0.248, time/batch = 0.030, All_Time = 15917.794
538800/758000 (epoch 1421), train_loss = 0.212, time/batch = 0.030, All_Time = 15919.313
538850/758000 (epoch 1421), train_loss = 0.229, time/batch = 0.029, All_Time = 15920.783
538900/758000 (epoch 1421), train_loss = 0.272, time/batch = 0.029, All_Time = 15922.263
538950/758000 (epoch 1422), train_loss = 0.249, time/batch = 0.030, All_Time = 15923.742
539000/758000 (epoch 1422), train_loss = 0.227, time/batch = 0.029, All_Time = 15925.221
model saved to NER/polyglot/model.ckpt
539050/758000 (epoch 1422), train_loss = 0.267, time/batch = 0.030, All_Time = 15926.685
539100/758000 (epoch 1422), train_loss = 0.239, time/batch = 0.030, All_Time = 15928.153
539150/758000 (epoch 1422), train_loss = 0.247, time/batch = 0.029, All_Time = 15929.655
539200/758000 (epoch 1422), train_loss = 0.241, time/batch = 0.029, All_Time = 15931.162
539250/758000 (epoch 1422), train_loss = 0.274, time/batch = 0.030, All_Time = 15932.638
539300/758000 (epoch 1422), train_loss = 0.279, time/batch = 0.029, All_Time = 15934.109
539350/758000 (epoch 1423), train_loss = 0.238, time/batch = 0.029, All_Time = 15935.580
539400/758000 (epoch 1423), train_loss = 0.248, time/batch = 0.030, All_Time = 15937.045
539450/758000 (epoch 1423), train_loss = 0.299, time/batch = 0.029, All_Time = 15938.518
539500/758000 (epoch 1423), train_loss = 0.230, time/batch = 0.030, All_Time = 15939.993
539550/758000 (epoch 1423), train_loss = 0.216, time/batch = 0.031, All_Time = 15941.512
539600/758000 (epoch 1423), train_loss = 0.244, time/batch = 0.030, All_Time = 15943.003
539650/758000 (epoch 1423), train_loss = 0.274, time/batch = 0.030, All_Time = 15944.477
539700/758000 (epoch 1424), train_loss = 0.221, time/batch = 0.031, All_Time = 15945.962
539750/758000 (epoch 1424), train_loss = 0.257, time/batch = 0.029, All_Time = 15947.435
539800/758000 (epoch 1424), train_loss = 0.241, time/batch = 0.030, All_Time = 15948.898
539850/758000 (epoch 1424), train_loss = 0.240, time/batch = 0.029, All_Time = 15950.367
539900/758000 (epoch 1424), train_loss = 0.256, time/batch = 0.030, All_Time = 15951.881
539950/758000 (epoch 1424), train_loss = 0.219, time/batch = 0.031, All_Time = 15953.359
540000/758000 (epoch 1424), train_loss = 0.224, time/batch = 0.029, All_Time = 15954.839
model saved to NER/polyglot/model.ckpt
540050/758000 (epoch 1424), train_loss = 0.257, time/batch = 0.029, All_Time = 15956.323
540100/758000 (epoch 1425), train_loss = 0.255, time/batch = 0.030, All_Time = 15957.796
540150/758000 (epoch 1425), train_loss = 0.267, time/batch = 0.030, All_Time = 15959.255
540200/758000 (epoch 1425), train_loss = 0.269, time/batch = 0.030, All_Time = 15960.719
540250/758000 (epoch 1425), train_loss = 0.228, time/batch = 0.029, All_Time = 15962.191
540300/758000 (epoch 1425), train_loss = 0.234, time/batch = 0.029, All_Time = 15963.675
540350/758000 (epoch 1425), train_loss = 0.245, time/batch = 0.028, All_Time = 15965.172
540400/758000 (epoch 1425), train_loss = 0.279, time/batch = 0.029, All_Time = 15966.659
540450/758000 (epoch 1425), train_loss = 0.240, time/batch = 0.030, All_Time = 15968.150
540500/758000 (epoch 1426), train_loss = 0.236, time/batch = 0.030, All_Time = 15969.627
540550/758000 (epoch 1426), train_loss = 0.234, time/batch = 0.029, All_Time = 15971.090
540600/758000 (epoch 1426), train_loss = 0.233, time/batch = 0.029, All_Time = 15972.560
540650/758000 (epoch 1426), train_loss = 0.276, time/batch = 0.030, All_Time = 15974.036
540700/758000 (epoch 1426), train_loss = 0.206, time/batch = 0.032, All_Time = 15975.523
540750/758000 (epoch 1426), train_loss = 0.259, time/batch = 0.030, All_Time = 15977.028
540800/758000 (epoch 1426), train_loss = 0.234, time/batch = 0.031, All_Time = 15978.514
540850/758000 (epoch 1427), train_loss = 0.245, time/batch = 0.029, All_Time = 15979.991
540900/758000 (epoch 1427), train_loss = 0.223, time/batch = 0.029, All_Time = 15981.463
540950/758000 (epoch 1427), train_loss = 0.240, time/batch = 0.029, All_Time = 15982.935
541000/758000 (epoch 1427), train_loss = 0.256, time/batch = 0.030, All_Time = 15984.424
model saved to NER/polyglot/model.ckpt
541050/758000 (epoch 1427), train_loss = 0.214, time/batch = 0.029, All_Time = 15985.911
541100/758000 (epoch 1427), train_loss = 0.272, time/batch = 0.031, All_Time = 15987.399
541150/758000 (epoch 1427), train_loss = 0.213, time/batch = 0.031, All_Time = 15988.881
541200/758000 (epoch 1427), train_loss = 0.251, time/batch = 0.030, All_Time = 15990.366
541250/758000 (epoch 1428), train_loss = 0.247, time/batch = 0.029, All_Time = 15991.842
541300/758000 (epoch 1428), train_loss = 0.229, time/batch = 0.029, All_Time = 15993.304
541350/758000 (epoch 1428), train_loss = 0.217, time/batch = 0.029, All_Time = 15994.766
541400/758000 (epoch 1428), train_loss = 0.220, time/batch = 0.030, All_Time = 15996.240
541450/758000 (epoch 1428), train_loss = 0.250, time/batch = 0.029, All_Time = 15997.706
541500/758000 (epoch 1428), train_loss = 0.207, time/batch = 0.031, All_Time = 15999.164
541550/758000 (epoch 1428), train_loss = 0.268, time/batch = 0.029, All_Time = 16000.663
541600/758000 (epoch 1429), train_loss = 0.256, time/batch = 0.029, All_Time = 16002.135
541650/758000 (epoch 1429), train_loss = 0.264, time/batch = 0.030, All_Time = 16003.601
541700/758000 (epoch 1429), train_loss = 0.284, time/batch = 0.030, All_Time = 16005.083
541750/758000 (epoch 1429), train_loss = 0.239, time/batch = 0.031, All_Time = 16006.567
541800/758000 (epoch 1429), train_loss = 0.267, time/batch = 0.029, All_Time = 16008.053
541850/758000 (epoch 1429), train_loss = 0.256, time/batch = 0.029, All_Time = 16009.533
541900/758000 (epoch 1429), train_loss = 0.236, time/batch = 0.030, All_Time = 16011.019
541950/758000 (epoch 1429), train_loss = 0.268, time/batch = 0.029, All_Time = 16012.505
542000/758000 (epoch 1430), train_loss = 0.226, time/batch = 0.029, All_Time = 16014.010
model saved to NER/polyglot/model.ckpt
542050/758000 (epoch 1430), train_loss = 0.222, time/batch = 0.030, All_Time = 16015.472
542100/758000 (epoch 1430), train_loss = 0.261, time/batch = 0.030, All_Time = 16016.941
542150/758000 (epoch 1430), train_loss = 0.254, time/batch = 0.031, All_Time = 16018.430
542200/758000 (epoch 1430), train_loss = 0.223, time/batch = 0.028, All_Time = 16019.931
542250/758000 (epoch 1430), train_loss = 0.242, time/batch = 0.029, All_Time = 16021.416
542300/758000 (epoch 1430), train_loss = 0.251, time/batch = 0.030, All_Time = 16022.903
542350/758000 (epoch 1431), train_loss = 0.192, time/batch = 0.031, All_Time = 16024.390
542400/758000 (epoch 1431), train_loss = 0.273, time/batch = 0.030, All_Time = 16025.873
542450/758000 (epoch 1431), train_loss = 0.217, time/batch = 0.030, All_Time = 16027.347
542500/758000 (epoch 1431), train_loss = 0.240, time/batch = 0.029, All_Time = 16028.812
542550/758000 (epoch 1431), train_loss = 0.221, time/batch = 0.030, All_Time = 16030.274
542600/758000 (epoch 1431), train_loss = 0.221, time/batch = 0.029, All_Time = 16031.742
542650/758000 (epoch 1431), train_loss = 0.252, time/batch = 0.029, All_Time = 16033.219
542700/758000 (epoch 1431), train_loss = 0.272, time/batch = 0.029, All_Time = 16034.698
542750/758000 (epoch 1432), train_loss = 0.222, time/batch = 0.029, All_Time = 16036.190
542800/758000 (epoch 1432), train_loss = 0.279, time/batch = 0.029, All_Time = 16037.660
542850/758000 (epoch 1432), train_loss = 0.242, time/batch = 0.028, All_Time = 16039.136
542900/758000 (epoch 1432), train_loss = 0.274, time/batch = 0.030, All_Time = 16040.608
542950/758000 (epoch 1432), train_loss = 0.262, time/batch = 0.030, All_Time = 16042.079
543000/758000 (epoch 1432), train_loss = 0.197, time/batch = 0.029, All_Time = 16043.560
model saved to NER/polyglot/model.ckpt
543050/758000 (epoch 1432), train_loss = 0.233, time/batch = 0.028, All_Time = 16045.031
543100/758000 (epoch 1432), train_loss = 0.281, time/batch = 0.029, All_Time = 16046.550
543150/758000 (epoch 1433), train_loss = 0.246, time/batch = 0.029, All_Time = 16048.030
543200/758000 (epoch 1433), train_loss = 0.212, time/batch = 0.030, All_Time = 16049.505
543250/758000 (epoch 1433), train_loss = 0.255, time/batch = 0.029, All_Time = 16050.972
543300/758000 (epoch 1433), train_loss = 0.271, time/batch = 0.031, All_Time = 16052.448
543350/758000 (epoch 1433), train_loss = 0.203, time/batch = 0.029, All_Time = 16053.914
543400/758000 (epoch 1433), train_loss = 0.226, time/batch = 0.030, All_Time = 16055.395
543450/758000 (epoch 1433), train_loss = 0.254, time/batch = 0.031, All_Time = 16056.895
543500/758000 (epoch 1434), train_loss = 0.219, time/batch = 0.029, All_Time = 16058.396
543550/758000 (epoch 1434), train_loss = 0.265, time/batch = 0.030, All_Time = 16059.873
543600/758000 (epoch 1434), train_loss = 0.227, time/batch = 0.029, All_Time = 16061.339
543650/758000 (epoch 1434), train_loss = 0.213, time/batch = 0.029, All_Time = 16062.822
543700/758000 (epoch 1434), train_loss = 0.224, time/batch = 0.031, All_Time = 16064.308
543750/758000 (epoch 1434), train_loss = 0.213, time/batch = 0.029, All_Time = 16065.783
543800/758000 (epoch 1434), train_loss = 0.230, time/batch = 0.029, All_Time = 16067.262
543850/758000 (epoch 1434), train_loss = 0.223, time/batch = 0.029, All_Time = 16068.736
543900/758000 (epoch 1435), train_loss = 0.275, time/batch = 0.029, All_Time = 16070.205
543950/758000 (epoch 1435), train_loss = 0.229, time/batch = 0.029, All_Time = 16071.686
544000/758000 (epoch 1435), train_loss = 0.270, time/batch = 0.030, All_Time = 16073.185
model saved to NER/polyglot/model.ckpt
544050/758000 (epoch 1435), train_loss = 0.273, time/batch = 0.028, All_Time = 16074.658
544100/758000 (epoch 1435), train_loss = 0.233, time/batch = 0.030, All_Time = 16076.128
544150/758000 (epoch 1435), train_loss = 0.268, time/batch = 0.030, All_Time = 16077.602
544200/758000 (epoch 1435), train_loss = 0.280, time/batch = 0.029, All_Time = 16079.072
544250/758000 (epoch 1436), train_loss = 0.239, time/batch = 0.029, All_Time = 16080.550
544300/758000 (epoch 1436), train_loss = 0.218, time/batch = 0.028, All_Time = 16082.018
544350/758000 (epoch 1436), train_loss = 0.243, time/batch = 0.030, All_Time = 16083.486
544400/758000 (epoch 1436), train_loss = 0.244, time/batch = 0.029, All_Time = 16084.973
544450/758000 (epoch 1436), train_loss = 0.243, time/batch = 0.031, All_Time = 16086.466
544500/758000 (epoch 1436), train_loss = 0.244, time/batch = 0.028, All_Time = 16087.951
544550/758000 (epoch 1436), train_loss = 0.213, time/batch = 0.030, All_Time = 16089.432
544600/758000 (epoch 1436), train_loss = 0.289, time/batch = 0.030, All_Time = 16090.940
544650/758000 (epoch 1437), train_loss = 0.237, time/batch = 0.031, All_Time = 16092.432
544700/758000 (epoch 1437), train_loss = 0.246, time/batch = 0.028, All_Time = 16093.898
544750/758000 (epoch 1437), train_loss = 0.288, time/batch = 0.030, All_Time = 16095.372
544800/758000 (epoch 1437), train_loss = 0.257, time/batch = 0.030, All_Time = 16096.842
544850/758000 (epoch 1437), train_loss = 0.218, time/batch = 0.030, All_Time = 16098.313
544900/758000 (epoch 1437), train_loss = 0.238, time/batch = 0.030, All_Time = 16099.789
544950/758000 (epoch 1437), train_loss = 0.251, time/batch = 0.030, All_Time = 16101.281
545000/758000 (epoch 1437), train_loss = 0.251, time/batch = 0.028, All_Time = 16102.750
model saved to NER/polyglot/model.ckpt
545050/758000 (epoch 1438), train_loss = 0.252, time/batch = 0.028, All_Time = 16104.217
545100/758000 (epoch 1438), train_loss = 0.280, time/batch = 0.031, All_Time = 16105.710
545150/758000 (epoch 1438), train_loss = 0.242, time/batch = 0.029, All_Time = 16107.205
545200/758000 (epoch 1438), train_loss = 0.250, time/batch = 0.029, All_Time = 16108.691
545250/758000 (epoch 1438), train_loss = 0.239, time/batch = 0.029, All_Time = 16110.169
545300/758000 (epoch 1438), train_loss = 0.239, time/batch = 0.031, All_Time = 16111.716
545350/758000 (epoch 1438), train_loss = 0.250, time/batch = 0.029, All_Time = 16113.244
545400/758000 (epoch 1439), train_loss = 0.221, time/batch = 0.030, All_Time = 16114.728
545450/758000 (epoch 1439), train_loss = 0.219, time/batch = 0.030, All_Time = 16116.196
545500/758000 (epoch 1439), train_loss = 0.246, time/batch = 0.029, All_Time = 16117.660
545550/758000 (epoch 1439), train_loss = 0.262, time/batch = 0.029, All_Time = 16119.130
545600/758000 (epoch 1439), train_loss = 0.260, time/batch = 0.033, All_Time = 16120.659
545650/758000 (epoch 1439), train_loss = 0.241, time/batch = 0.030, All_Time = 16122.158
545700/758000 (epoch 1439), train_loss = 0.210, time/batch = 0.031, All_Time = 16123.658
545750/758000 (epoch 1439), train_loss = 0.239, time/batch = 0.029, All_Time = 16125.140
545800/758000 (epoch 1440), train_loss = 0.230, time/batch = 0.029, All_Time = 16126.614
545850/758000 (epoch 1440), train_loss = 0.226, time/batch = 0.030, All_Time = 16128.077
545900/758000 (epoch 1440), train_loss = 0.264, time/batch = 0.027, All_Time = 16129.542
545950/758000 (epoch 1440), train_loss = 0.240, time/batch = 0.027, All_Time = 16131.007
546000/758000 (epoch 1440), train_loss = 0.253, time/batch = 0.030, All_Time = 16132.471
model saved to NER/polyglot/model.ckpt
546050/758000 (epoch 1440), train_loss = 0.251, time/batch = 0.028, All_Time = 16133.932
546100/758000 (epoch 1440), train_loss = 0.248, time/batch = 0.030, All_Time = 16135.403
546150/758000 (epoch 1441), train_loss = 0.216, time/batch = 0.030, All_Time = 16136.898
546200/758000 (epoch 1441), train_loss = 0.233, time/batch = 0.029, All_Time = 16138.389
546250/758000 (epoch 1441), train_loss = 0.250, time/batch = 0.030, All_Time = 16139.861
546300/758000 (epoch 1441), train_loss = 0.241, time/batch = 0.029, All_Time = 16141.336
546350/758000 (epoch 1441), train_loss = 0.243, time/batch = 0.029, All_Time = 16142.813
546400/758000 (epoch 1441), train_loss = 0.242, time/batch = 0.029, All_Time = 16144.286
546450/758000 (epoch 1441), train_loss = 0.230, time/batch = 0.030, All_Time = 16145.757
546500/758000 (epoch 1441), train_loss = 0.259, time/batch = 0.030, All_Time = 16147.227
546550/758000 (epoch 1442), train_loss = 0.250, time/batch = 0.030, All_Time = 16148.712
546600/758000 (epoch 1442), train_loss = 0.253, time/batch = 0.029, All_Time = 16150.175
546650/758000 (epoch 1442), train_loss = 0.245, time/batch = 0.031, All_Time = 16151.644
546700/758000 (epoch 1442), train_loss = 0.231, time/batch = 0.030, All_Time = 16153.106
546750/758000 (epoch 1442), train_loss = 0.228, time/batch = 0.030, All_Time = 16154.577
546800/758000 (epoch 1442), train_loss = 0.238, time/batch = 0.030, All_Time = 16156.058
546850/758000 (epoch 1442), train_loss = 0.268, time/batch = 0.030, All_Time = 16157.537
546900/758000 (epoch 1443), train_loss = 0.248, time/batch = 0.031, All_Time = 16159.028
546950/758000 (epoch 1443), train_loss = 0.280, time/batch = 0.028, All_Time = 16160.508
547000/758000 (epoch 1443), train_loss = 0.242, time/batch = 0.029, All_Time = 16161.977
model saved to NER/polyglot/model.ckpt
547050/758000 (epoch 1443), train_loss = 0.258, time/batch = 0.030, All_Time = 16163.454
547100/758000 (epoch 1443), train_loss = 0.224, time/batch = 0.032, All_Time = 16164.937
547150/758000 (epoch 1443), train_loss = 0.243, time/batch = 0.029, All_Time = 16166.461
547200/758000 (epoch 1443), train_loss = 0.219, time/batch = 0.029, All_Time = 16167.949
547250/758000 (epoch 1443), train_loss = 0.232, time/batch = 0.030, All_Time = 16169.431
547300/758000 (epoch 1444), train_loss = 0.237, time/batch = 0.031, All_Time = 16170.916
547350/758000 (epoch 1444), train_loss = 0.239, time/batch = 0.029, All_Time = 16172.381
547400/758000 (epoch 1444), train_loss = 0.293, time/batch = 0.029, All_Time = 16173.858
547450/758000 (epoch 1444), train_loss = 0.318, time/batch = 0.030, All_Time = 16175.342
547500/758000 (epoch 1444), train_loss = 0.196, time/batch = 0.029, All_Time = 16176.825
547550/758000 (epoch 1444), train_loss = 0.213, time/batch = 0.031, All_Time = 16178.304
547600/758000 (epoch 1444), train_loss = 0.250, time/batch = 0.029, All_Time = 16179.793
547650/758000 (epoch 1444), train_loss = 0.297, time/batch = 0.031, All_Time = 16181.276
547700/758000 (epoch 1445), train_loss = 0.226, time/batch = 0.029, All_Time = 16182.749
547750/758000 (epoch 1445), train_loss = 0.259, time/batch = 0.029, All_Time = 16184.220
547800/758000 (epoch 1445), train_loss = 0.223, time/batch = 0.030, All_Time = 16185.695
547850/758000 (epoch 1445), train_loss = 0.239, time/batch = 0.029, All_Time = 16187.183
547900/758000 (epoch 1445), train_loss = 0.212, time/batch = 0.030, All_Time = 16188.686
547950/758000 (epoch 1445), train_loss = 0.243, time/batch = 0.030, All_Time = 16190.173
548000/758000 (epoch 1445), train_loss = 0.215, time/batch = 0.030, All_Time = 16191.661
model saved to NER/polyglot/model.ckpt
548050/758000 (epoch 1446), train_loss = 0.228, time/batch = 0.028, All_Time = 16193.135
548100/758000 (epoch 1446), train_loss = 0.252, time/batch = 0.029, All_Time = 16194.590
548150/758000 (epoch 1446), train_loss = 0.260, time/batch = 0.030, All_Time = 16196.055
548200/758000 (epoch 1446), train_loss = 0.228, time/batch = 0.029, All_Time = 16197.549
548250/758000 (epoch 1446), train_loss = 0.236, time/batch = 0.031, All_Time = 16199.043
548300/758000 (epoch 1446), train_loss = 0.271, time/batch = 0.030, All_Time = 16200.529
548350/758000 (epoch 1446), train_loss = 0.238, time/batch = 0.029, All_Time = 16202.020
548400/758000 (epoch 1446), train_loss = 0.268, time/batch = 0.028, All_Time = 16203.513
548450/758000 (epoch 1447), train_loss = 0.248, time/batch = 0.029, All_Time = 16204.995
548500/758000 (epoch 1447), train_loss = 0.249, time/batch = 0.029, All_Time = 16206.471
548550/758000 (epoch 1447), train_loss = 0.240, time/batch = 0.031, All_Time = 16207.950
548600/758000 (epoch 1447), train_loss = 0.247, time/batch = 0.029, All_Time = 16209.419
548650/758000 (epoch 1447), train_loss = 0.235, time/batch = 0.029, All_Time = 16210.898
548700/758000 (epoch 1447), train_loss = 0.247, time/batch = 0.031, All_Time = 16212.382
548750/758000 (epoch 1447), train_loss = 0.251, time/batch = 0.031, All_Time = 16213.893
548800/758000 (epoch 1448), train_loss = 0.242, time/batch = 0.030, All_Time = 16215.382
548850/758000 (epoch 1448), train_loss = 0.276, time/batch = 0.029, All_Time = 16216.854
548900/758000 (epoch 1448), train_loss = 0.256, time/batch = 0.029, All_Time = 16218.339
548950/758000 (epoch 1448), train_loss = 0.258, time/batch = 0.029, All_Time = 16219.832
549000/758000 (epoch 1448), train_loss = 0.213, time/batch = 0.031, All_Time = 16221.319
model saved to NER/polyglot/model.ckpt
549050/758000 (epoch 1448), train_loss = 0.237, time/batch = 0.029, All_Time = 16222.796
549100/758000 (epoch 1448), train_loss = 0.249, time/batch = 0.028, All_Time = 16224.253
549150/758000 (epoch 1448), train_loss = 0.251, time/batch = 0.030, All_Time = 16225.719
549200/758000 (epoch 1449), train_loss = 0.232, time/batch = 0.028, All_Time = 16227.235
549250/758000 (epoch 1449), train_loss = 0.255, time/batch = 0.032, All_Time = 16228.707
549300/758000 (epoch 1449), train_loss = 0.265, time/batch = 0.030, All_Time = 16230.178
549350/758000 (epoch 1449), train_loss = 0.229, time/batch = 0.030, All_Time = 16231.671
549400/758000 (epoch 1449), train_loss = 0.263, time/batch = 0.029, All_Time = 16233.165
549450/758000 (epoch 1449), train_loss = 0.217, time/batch = 0.028, All_Time = 16234.647
549500/758000 (epoch 1449), train_loss = 0.248, time/batch = 0.028, All_Time = 16236.122
549550/758000 (epoch 1450), train_loss = 0.059, time/batch = 0.029, All_Time = 16237.597
549600/758000 (epoch 1450), train_loss = 0.250, time/batch = 0.029, All_Time = 16239.075
549650/758000 (epoch 1450), train_loss = 0.223, time/batch = 0.028, All_Time = 16240.551
549700/758000 (epoch 1450), train_loss = 0.250, time/batch = 0.028, All_Time = 16242.006
549750/758000 (epoch 1450), train_loss = 0.231, time/batch = 0.029, All_Time = 16243.510
549800/758000 (epoch 1450), train_loss = 0.250, time/batch = 0.030, All_Time = 16244.989
549850/758000 (epoch 1450), train_loss = 0.232, time/batch = 0.031, All_Time = 16246.461
549900/758000 (epoch 1450), train_loss = 0.230, time/batch = 0.030, All_Time = 16247.944
549950/758000 (epoch 1451), train_loss = 0.224, time/batch = 0.031, All_Time = 16249.420
550000/758000 (epoch 1451), train_loss = 0.233, time/batch = 0.029, All_Time = 16250.877
model saved to NER/polyglot/model.ckpt
550050/758000 (epoch 1451), train_loss = 0.224, time/batch = 0.029, All_Time = 16252.351
550100/758000 (epoch 1451), train_loss = 0.262, time/batch = 0.029, All_Time = 16253.819
550150/758000 (epoch 1451), train_loss = 0.220, time/batch = 0.032, All_Time = 16255.298
550200/758000 (epoch 1451), train_loss = 0.228, time/batch = 0.030, All_Time = 16256.805
550250/758000 (epoch 1451), train_loss = 0.280, time/batch = 0.029, All_Time = 16258.300
550300/758000 (epoch 1451), train_loss = 0.272, time/batch = 0.029, All_Time = 16259.775
550350/758000 (epoch 1452), train_loss = 0.230, time/batch = 0.030, All_Time = 16261.261
550400/758000 (epoch 1452), train_loss = 0.224, time/batch = 0.030, All_Time = 16262.727
550450/758000 (epoch 1452), train_loss = 0.201, time/batch = 0.030, All_Time = 16264.205
550500/758000 (epoch 1452), train_loss = 0.270, time/batch = 0.031, All_Time = 16265.683
550550/758000 (epoch 1452), train_loss = 0.259, time/batch = 0.029, All_Time = 16267.165
550600/758000 (epoch 1452), train_loss = 0.209, time/batch = 0.029, All_Time = 16268.627
550650/758000 (epoch 1452), train_loss = 0.218, time/batch = 0.031, All_Time = 16270.101
550700/758000 (epoch 1453), train_loss = 0.229, time/batch = 0.031, All_Time = 16271.575
550750/758000 (epoch 1453), train_loss = 0.283, time/batch = 0.030, All_Time = 16273.040
550800/758000 (epoch 1453), train_loss = 0.231, time/batch = 0.031, All_Time = 16274.548
550850/758000 (epoch 1453), train_loss = 0.307, time/batch = 0.029, All_Time = 16276.052
550900/758000 (epoch 1453), train_loss = 0.221, time/batch = 0.029, All_Time = 16277.540
550950/758000 (epoch 1453), train_loss = 0.208, time/batch = 0.028, All_Time = 16279.024
551000/758000 (epoch 1453), train_loss = 0.247, time/batch = 0.031, All_Time = 16280.514
model saved to NER/polyglot/model.ckpt
551050/758000 (epoch 1453), train_loss = 0.252, time/batch = 0.029, All_Time = 16281.990
551100/758000 (epoch 1454), train_loss = 0.264, time/batch = 0.029, All_Time = 16283.460
551150/758000 (epoch 1454), train_loss = 0.229, time/batch = 0.031, All_Time = 16284.929
551200/758000 (epoch 1454), train_loss = 0.242, time/batch = 0.029, All_Time = 16286.396
551250/758000 (epoch 1454), train_loss = 0.267, time/batch = 0.028, All_Time = 16287.915
551300/758000 (epoch 1454), train_loss = 0.249, time/batch = 0.030, All_Time = 16289.408
551350/758000 (epoch 1454), train_loss = 0.237, time/batch = 0.030, All_Time = 16290.885
551400/758000 (epoch 1454), train_loss = 0.276, time/batch = 0.030, All_Time = 16292.371
551450/758000 (epoch 1455), train_loss = 0.256, time/batch = 0.029, All_Time = 16293.846
551500/758000 (epoch 1455), train_loss = 0.222, time/batch = 0.030, All_Time = 16295.318
551550/758000 (epoch 1455), train_loss = 0.266, time/batch = 0.029, All_Time = 16296.781
551600/758000 (epoch 1455), train_loss = 0.216, time/batch = 0.031, All_Time = 16298.252
551650/758000 (epoch 1455), train_loss = 0.223, time/batch = 0.028, All_Time = 16299.716
551700/758000 (epoch 1455), train_loss = 0.261, time/batch = 0.030, All_Time = 16301.180
551750/758000 (epoch 1455), train_loss = 0.238, time/batch = 0.029, All_Time = 16302.692
551800/758000 (epoch 1455), train_loss = 0.264, time/batch = 0.028, All_Time = 16304.170
551850/758000 (epoch 1456), train_loss = 0.223, time/batch = 0.029, All_Time = 16305.644
551900/758000 (epoch 1456), train_loss = 0.231, time/batch = 0.030, All_Time = 16307.116
551950/758000 (epoch 1456), train_loss = 0.238, time/batch = 0.030, All_Time = 16308.581
552000/758000 (epoch 1456), train_loss = 0.266, time/batch = 0.030, All_Time = 16310.058
model saved to NER/polyglot/model.ckpt
552050/758000 (epoch 1456), train_loss = 0.239, time/batch = 0.028, All_Time = 16311.532
552100/758000 (epoch 1456), train_loss = 0.226, time/batch = 0.030, All_Time = 16313.003
552150/758000 (epoch 1456), train_loss = 0.276, time/batch = 0.028, All_Time = 16314.477
552200/758000 (epoch 1456), train_loss = 0.240, time/batch = 0.029, All_Time = 16315.987
552250/758000 (epoch 1457), train_loss = 0.281, time/batch = 0.030, All_Time = 16317.460
552300/758000 (epoch 1457), train_loss = 0.257, time/batch = 0.030, All_Time = 16318.939
552350/758000 (epoch 1457), train_loss = 0.240, time/batch = 0.029, All_Time = 16320.410
552400/758000 (epoch 1457), train_loss = 0.231, time/batch = 0.031, All_Time = 16321.883
552450/758000 (epoch 1457), train_loss = 0.217, time/batch = 0.030, All_Time = 16323.367
552500/758000 (epoch 1457), train_loss = 0.224, time/batch = 0.029, All_Time = 16324.843
552550/758000 (epoch 1457), train_loss = 0.215, time/batch = 0.030, All_Time = 16326.314
552600/758000 (epoch 1458), train_loss = 0.249, time/batch = 0.030, All_Time = 16327.791
552650/758000 (epoch 1458), train_loss = 0.211, time/batch = 0.029, All_Time = 16329.255
552700/758000 (epoch 1458), train_loss = 0.245, time/batch = 0.030, All_Time = 16330.726
552750/758000 (epoch 1458), train_loss = 0.217, time/batch = 0.029, All_Time = 16332.205
552800/758000 (epoch 1458), train_loss = 0.233, time/batch = 0.029, All_Time = 16333.677
552850/758000 (epoch 1458), train_loss = 0.228, time/batch = 0.029, All_Time = 16335.165
552900/758000 (epoch 1458), train_loss = 0.248, time/batch = 0.029, All_Time = 16336.669
552950/758000 (epoch 1458), train_loss = 0.229, time/batch = 0.030, All_Time = 16338.154
553000/758000 (epoch 1459), train_loss = 0.218, time/batch = 0.027, All_Time = 16339.635
model saved to NER/polyglot/model.ckpt
553050/758000 (epoch 1459), train_loss = 0.237, time/batch = 0.028, All_Time = 16341.106
553100/758000 (epoch 1459), train_loss = 0.212, time/batch = 0.029, All_Time = 16342.566
553150/758000 (epoch 1459), train_loss = 0.266, time/batch = 0.030, All_Time = 16344.022
553200/758000 (epoch 1459), train_loss = 0.255, time/batch = 0.032, All_Time = 16345.531
553250/758000 (epoch 1459), train_loss = 0.232, time/batch = 0.030, All_Time = 16347.019
553300/758000 (epoch 1459), train_loss = 0.262, time/batch = 0.031, All_Time = 16348.517
553350/758000 (epoch 1460), train_loss = 0.282, time/batch = 0.030, All_Time = 16350.005
553400/758000 (epoch 1460), train_loss = 0.292, time/batch = 0.030, All_Time = 16351.479
553450/758000 (epoch 1460), train_loss = 0.253, time/batch = 0.029, All_Time = 16352.946
553500/758000 (epoch 1460), train_loss = 0.222, time/batch = 0.030, All_Time = 16354.455
553550/758000 (epoch 1460), train_loss = 0.221, time/batch = 0.031, All_Time = 16355.938
553600/758000 (epoch 1460), train_loss = 0.260, time/batch = 0.029, All_Time = 16357.413
553650/758000 (epoch 1460), train_loss = 0.244, time/batch = 0.029, All_Time = 16358.873
553700/758000 (epoch 1460), train_loss = 0.247, time/batch = 0.031, All_Time = 16360.355
553750/758000 (epoch 1461), train_loss = 0.210, time/batch = 0.030, All_Time = 16361.836
553800/758000 (epoch 1461), train_loss = 0.265, time/batch = 0.029, All_Time = 16363.312
553850/758000 (epoch 1461), train_loss = 0.229, time/batch = 0.029, All_Time = 16364.792
553900/758000 (epoch 1461), train_loss = 0.232, time/batch = 0.030, All_Time = 16366.243
553950/758000 (epoch 1461), train_loss = 0.230, time/batch = 0.028, All_Time = 16367.709
554000/758000 (epoch 1461), train_loss = 0.253, time/batch = 0.030, All_Time = 16369.189
model saved to NER/polyglot/model.ckpt
554050/758000 (epoch 1461), train_loss = 0.258, time/batch = 0.029, All_Time = 16370.694
554100/758000 (epoch 1462), train_loss = 0.196, time/batch = 0.029, All_Time = 16372.164
554150/758000 (epoch 1462), train_loss = 0.254, time/batch = 0.029, All_Time = 16373.645
554200/758000 (epoch 1462), train_loss = 0.281, time/batch = 0.029, All_Time = 16375.110
554250/758000 (epoch 1462), train_loss = 0.235, time/batch = 0.029, All_Time = 16376.569
554300/758000 (epoch 1462), train_loss = 0.247, time/batch = 0.028, All_Time = 16378.028
554350/758000 (epoch 1462), train_loss = 0.251, time/batch = 0.030, All_Time = 16379.494
554400/758000 (epoch 1462), train_loss = 0.203, time/batch = 0.029, All_Time = 16380.969
554450/758000 (epoch 1462), train_loss = 0.268, time/batch = 0.030, All_Time = 16382.483
554500/758000 (epoch 1463), train_loss = 0.233, time/batch = 0.029, All_Time = 16383.974
554550/758000 (epoch 1463), train_loss = 0.241, time/batch = 0.029, All_Time = 16385.446
554600/758000 (epoch 1463), train_loss = 0.252, time/batch = 0.030, All_Time = 16386.915
554650/758000 (epoch 1463), train_loss = 0.258, time/batch = 0.029, All_Time = 16388.376
554700/758000 (epoch 1463), train_loss = 0.243, time/batch = 0.031, All_Time = 16389.844
554750/758000 (epoch 1463), train_loss = 0.243, time/batch = 0.030, All_Time = 16391.317
554800/758000 (epoch 1463), train_loss = 0.244, time/batch = 0.030, All_Time = 16392.807
554850/758000 (epoch 1463), train_loss = 0.286, time/batch = 0.031, All_Time = 16394.306
554900/758000 (epoch 1464), train_loss = 0.207, time/batch = 0.029, All_Time = 16395.784
554950/758000 (epoch 1464), train_loss = 0.244, time/batch = 0.030, All_Time = 16397.263
555000/758000 (epoch 1464), train_loss = 0.217, time/batch = 0.031, All_Time = 16398.733
model saved to NER/polyglot/model.ckpt
555050/758000 (epoch 1464), train_loss = 0.233, time/batch = 0.029, All_Time = 16400.205
555100/758000 (epoch 1464), train_loss = 0.260, time/batch = 0.029, All_Time = 16401.669
555150/758000 (epoch 1464), train_loss = 0.253, time/batch = 0.029, All_Time = 16403.178
555200/758000 (epoch 1464), train_loss = 0.238, time/batch = 0.031, All_Time = 16404.675
555250/758000 (epoch 1465), train_loss = 0.227, time/batch = 0.030, All_Time = 16406.166
555300/758000 (epoch 1465), train_loss = 0.250, time/batch = 0.029, All_Time = 16407.644
555350/758000 (epoch 1465), train_loss = 0.250, time/batch = 0.029, All_Time = 16409.121
555400/758000 (epoch 1465), train_loss = 0.223, time/batch = 0.030, All_Time = 16410.601
555450/758000 (epoch 1465), train_loss = 0.240, time/batch = 0.031, All_Time = 16412.072
555500/758000 (epoch 1465), train_loss = 0.246, time/batch = 0.029, All_Time = 16413.542
555550/758000 (epoch 1465), train_loss = 0.246, time/batch = 0.030, All_Time = 16415.013
555600/758000 (epoch 1465), train_loss = 0.257, time/batch = 0.028, All_Time = 16416.494
555650/758000 (epoch 1466), train_loss = 0.266, time/batch = 0.029, All_Time = 16417.971
555700/758000 (epoch 1466), train_loss = 0.224, time/batch = 0.030, All_Time = 16419.467
555750/758000 (epoch 1466), train_loss = 0.248, time/batch = 0.031, All_Time = 16420.967
555800/758000 (epoch 1466), train_loss = 0.227, time/batch = 0.029, All_Time = 16422.461
555850/758000 (epoch 1466), train_loss = 0.279, time/batch = 0.030, All_Time = 16423.953
555900/758000 (epoch 1466), train_loss = 0.255, time/batch = 0.028, All_Time = 16425.436
555950/758000 (epoch 1466), train_loss = 0.253, time/batch = 0.031, All_Time = 16426.936
556000/758000 (epoch 1467), train_loss = 0.244, time/batch = 0.030, All_Time = 16428.425
model saved to NER/polyglot/model.ckpt
556050/758000 (epoch 1467), train_loss = 0.247, time/batch = 0.028, All_Time = 16429.881
556100/758000 (epoch 1467), train_loss = 0.270, time/batch = 0.028, All_Time = 16431.346
556150/758000 (epoch 1467), train_loss = 0.246, time/batch = 0.030, All_Time = 16432.809
556200/758000 (epoch 1467), train_loss = 0.237, time/batch = 0.031, All_Time = 16434.274
556250/758000 (epoch 1467), train_loss = 0.224, time/batch = 0.031, All_Time = 16435.766
556300/758000 (epoch 1467), train_loss = 0.229, time/batch = 0.029, All_Time = 16437.233
556350/758000 (epoch 1467), train_loss = 0.246, time/batch = 0.029, All_Time = 16438.719
556400/758000 (epoch 1468), train_loss = 0.249, time/batch = 0.029, All_Time = 16440.201
556450/758000 (epoch 1468), train_loss = 0.264, time/batch = 0.030, All_Time = 16441.677
556500/758000 (epoch 1468), train_loss = 0.240, time/batch = 0.029, All_Time = 16443.140
556550/758000 (epoch 1468), train_loss = 0.250, time/batch = 0.031, All_Time = 16444.617
556600/758000 (epoch 1468), train_loss = 0.227, time/batch = 0.029, All_Time = 16446.115
556650/758000 (epoch 1468), train_loss = 0.217, time/batch = 0.030, All_Time = 16447.601
556700/758000 (epoch 1468), train_loss = 0.277, time/batch = 0.029, All_Time = 16449.079
556750/758000 (epoch 1468), train_loss = 0.259, time/batch = 0.029, All_Time = 16450.566
556800/758000 (epoch 1469), train_loss = 0.269, time/batch = 0.030, All_Time = 16452.046
556850/758000 (epoch 1469), train_loss = 0.296, time/batch = 0.031, All_Time = 16453.564
556900/758000 (epoch 1469), train_loss = 0.228, time/batch = 0.029, All_Time = 16455.045
556950/758000 (epoch 1469), train_loss = 0.220, time/batch = 0.030, All_Time = 16456.517
557000/758000 (epoch 1469), train_loss = 0.257, time/batch = 0.031, All_Time = 16457.987
model saved to NER/polyglot/model.ckpt
557050/758000 (epoch 1469), train_loss = 0.255, time/batch = 0.028, All_Time = 16459.443
557100/758000 (epoch 1469), train_loss = 0.237, time/batch = 0.029, All_Time = 16460.913
557150/758000 (epoch 1470), train_loss = 0.225, time/batch = 0.030, All_Time = 16462.379
557200/758000 (epoch 1470), train_loss = 0.234, time/batch = 0.031, All_Time = 16463.854
557250/758000 (epoch 1470), train_loss = 0.243, time/batch = 0.029, All_Time = 16465.354
557300/758000 (epoch 1470), train_loss = 0.234, time/batch = 0.030, All_Time = 16466.838
557350/758000 (epoch 1470), train_loss = 0.223, time/batch = 0.029, All_Time = 16468.308
557400/758000 (epoch 1470), train_loss = 0.239, time/batch = 0.031, All_Time = 16469.800
557450/758000 (epoch 1470), train_loss = 0.264, time/batch = 0.030, All_Time = 16471.268
557500/758000 (epoch 1470), train_loss = 0.244, time/batch = 0.029, All_Time = 16472.750
557550/758000 (epoch 1471), train_loss = 0.257, time/batch = 0.029, All_Time = 16474.230
557600/758000 (epoch 1471), train_loss = 0.287, time/batch = 0.030, All_Time = 16475.695
557650/758000 (epoch 1471), train_loss = 0.255, time/batch = 0.029, All_Time = 16477.178
557700/758000 (epoch 1471), train_loss = 0.248, time/batch = 0.029, All_Time = 16478.670
557750/758000 (epoch 1471), train_loss = 0.212, time/batch = 0.029, All_Time = 16480.155
557800/758000 (epoch 1471), train_loss = 0.229, time/batch = 0.030, All_Time = 16481.627
557850/758000 (epoch 1471), train_loss = 0.272, time/batch = 0.030, All_Time = 16483.102
557900/758000 (epoch 1472), train_loss = 0.249, time/batch = 0.029, All_Time = 16484.590
557950/758000 (epoch 1472), train_loss = 0.227, time/batch = 0.030, All_Time = 16486.070
558000/758000 (epoch 1472), train_loss = 0.267, time/batch = 0.030, All_Time = 16487.546
model saved to NER/polyglot/model.ckpt
558050/758000 (epoch 1472), train_loss = 0.239, time/batch = 0.030, All_Time = 16489.017
558100/758000 (epoch 1472), train_loss = 0.247, time/batch = 0.029, All_Time = 16490.484
558150/758000 (epoch 1472), train_loss = 0.241, time/batch = 0.029, All_Time = 16491.946
558200/758000 (epoch 1472), train_loss = 0.274, time/batch = 0.030, All_Time = 16493.418
558250/758000 (epoch 1472), train_loss = 0.279, time/batch = 0.029, All_Time = 16494.911
558300/758000 (epoch 1473), train_loss = 0.238, time/batch = 0.029, All_Time = 16496.390
558350/758000 (epoch 1473), train_loss = 0.248, time/batch = 0.028, All_Time = 16497.858
558400/758000 (epoch 1473), train_loss = 0.299, time/batch = 0.029, All_Time = 16499.330
558450/758000 (epoch 1473), train_loss = 0.230, time/batch = 0.030, All_Time = 16500.845
558500/758000 (epoch 1473), train_loss = 0.216, time/batch = 0.029, All_Time = 16502.317
558550/758000 (epoch 1473), train_loss = 0.244, time/batch = 0.029, All_Time = 16503.791
558600/758000 (epoch 1473), train_loss = 0.274, time/batch = 0.030, All_Time = 16505.267
558650/758000 (epoch 1474), train_loss = 0.221, time/batch = 0.030, All_Time = 16506.745
558700/758000 (epoch 1474), train_loss = 0.257, time/batch = 0.030, All_Time = 16508.217
558750/758000 (epoch 1474), train_loss = 0.241, time/batch = 0.029, All_Time = 16509.689
558800/758000 (epoch 1474), train_loss = 0.240, time/batch = 0.031, All_Time = 16511.161
558850/758000 (epoch 1474), train_loss = 0.256, time/batch = 0.030, All_Time = 16512.627
558900/758000 (epoch 1474), train_loss = 0.219, time/batch = 0.031, All_Time = 16514.128
558950/758000 (epoch 1474), train_loss = 0.224, time/batch = 0.031, All_Time = 16515.622
559000/758000 (epoch 1474), train_loss = 0.257, time/batch = 0.034, All_Time = 16517.111
model saved to NER/polyglot/model.ckpt
559050/758000 (epoch 1475), train_loss = 0.255, time/batch = 0.031, All_Time = 16518.589
559100/758000 (epoch 1475), train_loss = 0.267, time/batch = 0.029, All_Time = 16520.079
559150/758000 (epoch 1475), train_loss = 0.269, time/batch = 0.029, All_Time = 16521.555
559200/758000 (epoch 1475), train_loss = 0.228, time/batch = 0.029, All_Time = 16523.030
559250/758000 (epoch 1475), train_loss = 0.234, time/batch = 0.029, All_Time = 16524.521
559300/758000 (epoch 1475), train_loss = 0.245, time/batch = 0.028, All_Time = 16525.990
559350/758000 (epoch 1475), train_loss = 0.279, time/batch = 0.029, All_Time = 16527.463
559400/758000 (epoch 1475), train_loss = 0.240, time/batch = 0.029, All_Time = 16528.936
559450/758000 (epoch 1476), train_loss = 0.236, time/batch = 0.028, All_Time = 16530.403
559500/758000 (epoch 1476), train_loss = 0.234, time/batch = 0.029, All_Time = 16531.864
559550/758000 (epoch 1476), train_loss = 0.233, time/batch = 0.029, All_Time = 16533.332
559600/758000 (epoch 1476), train_loss = 0.276, time/batch = 0.029, All_Time = 16534.811
559650/758000 (epoch 1476), train_loss = 0.206, time/batch = 0.030, All_Time = 16536.297
559700/758000 (epoch 1476), train_loss = 0.259, time/batch = 0.031, All_Time = 16537.777
559750/758000 (epoch 1476), train_loss = 0.234, time/batch = 0.029, All_Time = 16539.264
559800/758000 (epoch 1477), train_loss = 0.245, time/batch = 0.029, All_Time = 16540.756
559850/758000 (epoch 1477), train_loss = 0.223, time/batch = 0.029, All_Time = 16542.229
559900/758000 (epoch 1477), train_loss = 0.240, time/batch = 0.030, All_Time = 16543.710
559950/758000 (epoch 1477), train_loss = 0.256, time/batch = 0.030, All_Time = 16545.192
560000/758000 (epoch 1477), train_loss = 0.214, time/batch = 0.029, All_Time = 16546.695
model saved to NER/polyglot/model.ckpt
560050/758000 (epoch 1477), train_loss = 0.272, time/batch = 0.030, All_Time = 16548.162
560100/758000 (epoch 1477), train_loss = 0.213, time/batch = 0.030, All_Time = 16549.625
560150/758000 (epoch 1477), train_loss = 0.251, time/batch = 0.029, All_Time = 16551.086
560200/758000 (epoch 1478), train_loss = 0.247, time/batch = 0.028, All_Time = 16552.545
560250/758000 (epoch 1478), train_loss = 0.229, time/batch = 0.030, All_Time = 16554.028
560300/758000 (epoch 1478), train_loss = 0.217, time/batch = 0.030, All_Time = 16555.522
560350/758000 (epoch 1478), train_loss = 0.220, time/batch = 0.029, All_Time = 16557.013
560400/758000 (epoch 1478), train_loss = 0.250, time/batch = 0.032, All_Time = 16558.516
560450/758000 (epoch 1478), train_loss = 0.207, time/batch = 0.029, All_Time = 16560.004
560500/758000 (epoch 1478), train_loss = 0.268, time/batch = 0.031, All_Time = 16561.489
560550/758000 (epoch 1479), train_loss = 0.256, time/batch = 0.031, All_Time = 16562.979
560600/758000 (epoch 1479), train_loss = 0.264, time/batch = 0.030, All_Time = 16564.455
560650/758000 (epoch 1479), train_loss = 0.284, time/batch = 0.028, All_Time = 16565.927
560700/758000 (epoch 1479), train_loss = 0.239, time/batch = 0.030, All_Time = 16567.406
560750/758000 (epoch 1479), train_loss = 0.267, time/batch = 0.029, All_Time = 16568.875
560800/758000 (epoch 1479), train_loss = 0.256, time/batch = 0.032, All_Time = 16570.392
560850/758000 (epoch 1479), train_loss = 0.236, time/batch = 0.030, All_Time = 16571.878
560900/758000 (epoch 1479), train_loss = 0.268, time/batch = 0.030, All_Time = 16573.349
560950/758000 (epoch 1480), train_loss = 0.226, time/batch = 0.030, All_Time = 16574.819
561000/758000 (epoch 1480), train_loss = 0.222, time/batch = 0.029, All_Time = 16576.281
model saved to NER/polyglot/model.ckpt
561050/758000 (epoch 1480), train_loss = 0.261, time/batch = 0.029, All_Time = 16577.754
561100/758000 (epoch 1480), train_loss = 0.254, time/batch = 0.029, All_Time = 16579.213
561150/758000 (epoch 1480), train_loss = 0.223, time/batch = 0.030, All_Time = 16580.692
561200/758000 (epoch 1480), train_loss = 0.242, time/batch = 0.030, All_Time = 16582.196
561250/758000 (epoch 1480), train_loss = 0.251, time/batch = 0.030, All_Time = 16583.680
561300/758000 (epoch 1481), train_loss = 0.192, time/batch = 0.030, All_Time = 16585.162
561350/758000 (epoch 1481), train_loss = 0.273, time/batch = 0.030, All_Time = 16586.630
561400/758000 (epoch 1481), train_loss = 0.217, time/batch = 0.031, All_Time = 16588.105
561450/758000 (epoch 1481), train_loss = 0.240, time/batch = 0.029, All_Time = 16589.585
561500/758000 (epoch 1481), train_loss = 0.221, time/batch = 0.029, All_Time = 16591.063
561550/758000 (epoch 1481), train_loss = 0.221, time/batch = 0.030, All_Time = 16592.530
561600/758000 (epoch 1481), train_loss = 0.252, time/batch = 0.031, All_Time = 16594.004
561650/758000 (epoch 1481), train_loss = 0.272, time/batch = 0.030, All_Time = 16595.466
561700/758000 (epoch 1482), train_loss = 0.222, time/batch = 0.030, All_Time = 16596.938
561750/758000 (epoch 1482), train_loss = 0.279, time/batch = 0.030, All_Time = 16598.409
561800/758000 (epoch 1482), train_loss = 0.242, time/batch = 0.030, All_Time = 16599.878
561850/758000 (epoch 1482), train_loss = 0.274, time/batch = 0.030, All_Time = 16601.358
561900/758000 (epoch 1482), train_loss = 0.262, time/batch = 0.029, All_Time = 16602.863
561950/758000 (epoch 1482), train_loss = 0.197, time/batch = 0.029, All_Time = 16604.339
562000/758000 (epoch 1482), train_loss = 0.233, time/batch = 0.031, All_Time = 16605.832
model saved to NER/polyglot/model.ckpt
562050/758000 (epoch 1482), train_loss = 0.281, time/batch = 0.030, All_Time = 16607.302
562100/758000 (epoch 1483), train_loss = 0.246, time/batch = 0.029, All_Time = 16608.764
562150/758000 (epoch 1483), train_loss = 0.212, time/batch = 0.029, All_Time = 16610.233
562200/758000 (epoch 1483), train_loss = 0.255, time/batch = 0.029, All_Time = 16611.695
562250/758000 (epoch 1483), train_loss = 0.271, time/batch = 0.033, All_Time = 16613.193
562300/758000 (epoch 1483), train_loss = 0.203, time/batch = 0.030, All_Time = 16614.685
562350/758000 (epoch 1483), train_loss = 0.226, time/batch = 0.029, All_Time = 16616.179
562400/758000 (epoch 1483), train_loss = 0.254, time/batch = 0.029, All_Time = 16617.661
562450/758000 (epoch 1484), train_loss = 0.219, time/batch = 0.030, All_Time = 16619.155
562500/758000 (epoch 1484), train_loss = 0.265, time/batch = 0.031, All_Time = 16620.625
562550/758000 (epoch 1484), train_loss = 0.227, time/batch = 0.031, All_Time = 16622.097
562600/758000 (epoch 1484), train_loss = 0.213, time/batch = 0.030, All_Time = 16623.559
562650/758000 (epoch 1484), train_loss = 0.224, time/batch = 0.029, All_Time = 16625.029
562700/758000 (epoch 1484), train_loss = 0.213, time/batch = 0.031, All_Time = 16626.519
562750/758000 (epoch 1484), train_loss = 0.230, time/batch = 0.030, All_Time = 16628.019
562800/758000 (epoch 1484), train_loss = 0.223, time/batch = 0.030, All_Time = 16629.520
562850/758000 (epoch 1485), train_loss = 0.275, time/batch = 0.030, All_Time = 16631.004
562900/758000 (epoch 1485), train_loss = 0.229, time/batch = 0.029, All_Time = 16632.486
562950/758000 (epoch 1485), train_loss = 0.270, time/batch = 0.029, All_Time = 16633.957
563000/758000 (epoch 1485), train_loss = 0.273, time/batch = 0.030, All_Time = 16635.447
model saved to NER/polyglot/model.ckpt
563050/758000 (epoch 1485), train_loss = 0.233, time/batch = 0.031, All_Time = 16636.966
563100/758000 (epoch 1485), train_loss = 0.268, time/batch = 0.030, All_Time = 16638.444
563150/758000 (epoch 1485), train_loss = 0.280, time/batch = 0.029, All_Time = 16639.917
563200/758000 (epoch 1486), train_loss = 0.239, time/batch = 0.031, All_Time = 16641.383
563250/758000 (epoch 1486), train_loss = 0.218, time/batch = 0.030, All_Time = 16642.855
563300/758000 (epoch 1486), train_loss = 0.243, time/batch = 0.028, All_Time = 16644.321
563350/758000 (epoch 1486), train_loss = 0.244, time/batch = 0.030, All_Time = 16645.826
563400/758000 (epoch 1486), train_loss = 0.243, time/batch = 0.029, All_Time = 16647.325
563450/758000 (epoch 1486), train_loss = 0.244, time/batch = 0.031, All_Time = 16648.814
563500/758000 (epoch 1486), train_loss = 0.213, time/batch = 0.031, All_Time = 16650.292
563550/758000 (epoch 1486), train_loss = 0.289, time/batch = 0.030, All_Time = 16651.784
563600/758000 (epoch 1487), train_loss = 0.237, time/batch = 0.029, All_Time = 16653.281
563650/758000 (epoch 1487), train_loss = 0.246, time/batch = 0.029, All_Time = 16654.744
563700/758000 (epoch 1487), train_loss = 0.288, time/batch = 0.029, All_Time = 16656.220
563750/758000 (epoch 1487), train_loss = 0.257, time/batch = 0.030, All_Time = 16657.685
563800/758000 (epoch 1487), train_loss = 0.218, time/batch = 0.030, All_Time = 16659.150
563850/758000 (epoch 1487), train_loss = 0.238, time/batch = 0.030, All_Time = 16660.620
563900/758000 (epoch 1487), train_loss = 0.251, time/batch = 0.030, All_Time = 16662.099
563950/758000 (epoch 1487), train_loss = 0.251, time/batch = 0.031, All_Time = 16663.574
564000/758000 (epoch 1488), train_loss = 0.252, time/batch = 0.029, All_Time = 16665.050
model saved to NER/polyglot/model.ckpt
564050/758000 (epoch 1488), train_loss = 0.280, time/batch = 0.030, All_Time = 16666.516
564100/758000 (epoch 1488), train_loss = 0.242, time/batch = 0.029, All_Time = 16667.983
564150/758000 (epoch 1488), train_loss = 0.250, time/batch = 0.029, All_Time = 16669.479
564200/758000 (epoch 1488), train_loss = 0.239, time/batch = 0.033, All_Time = 16671.090
564250/758000 (epoch 1488), train_loss = 0.239, time/batch = 0.030, All_Time = 16672.625
564300/758000 (epoch 1488), train_loss = 0.250, time/batch = 0.029, All_Time = 16674.120
564350/758000 (epoch 1489), train_loss = 0.221, time/batch = 0.029, All_Time = 16675.609
564400/758000 (epoch 1489), train_loss = 0.219, time/batch = 0.030, All_Time = 16677.088
564450/758000 (epoch 1489), train_loss = 0.246, time/batch = 0.029, All_Time = 16678.547
564500/758000 (epoch 1489), train_loss = 0.262, time/batch = 0.029, All_Time = 16680.043
564550/758000 (epoch 1489), train_loss = 0.260, time/batch = 0.030, All_Time = 16681.527
564600/758000 (epoch 1489), train_loss = 0.241, time/batch = 0.030, All_Time = 16683.017
564650/758000 (epoch 1489), train_loss = 0.210, time/batch = 0.029, All_Time = 16684.496
564700/758000 (epoch 1489), train_loss = 0.239, time/batch = 0.032, All_Time = 16685.998
564750/758000 (epoch 1490), train_loss = 0.230, time/batch = 0.028, All_Time = 16687.479
564800/758000 (epoch 1490), train_loss = 0.226, time/batch = 0.029, All_Time = 16688.956
564850/758000 (epoch 1490), train_loss = 0.264, time/batch = 0.034, All_Time = 16690.514
564900/758000 (epoch 1490), train_loss = 0.240, time/batch = 0.030, All_Time = 16692.067
564950/758000 (epoch 1490), train_loss = 0.253, time/batch = 0.030, All_Time = 16693.562
565000/758000 (epoch 1490), train_loss = 0.251, time/batch = 0.030, All_Time = 16695.037
model saved to NER/polyglot/model.ckpt
565050/758000 (epoch 1490), train_loss = 0.248, time/batch = 0.030, All_Time = 16696.517
565100/758000 (epoch 1491), train_loss = 0.216, time/batch = 0.028, All_Time = 16698.001
565150/758000 (epoch 1491), train_loss = 0.233, time/batch = 0.029, All_Time = 16699.476
565200/758000 (epoch 1491), train_loss = 0.250, time/batch = 0.031, All_Time = 16700.947
565250/758000 (epoch 1491), train_loss = 0.241, time/batch = 0.029, All_Time = 16702.420
565300/758000 (epoch 1491), train_loss = 0.243, time/batch = 0.029, All_Time = 16703.889
565350/758000 (epoch 1491), train_loss = 0.242, time/batch = 0.029, All_Time = 16705.370
565400/758000 (epoch 1491), train_loss = 0.230, time/batch = 0.030, All_Time = 16706.853
565450/758000 (epoch 1491), train_loss = 0.259, time/batch = 0.030, All_Time = 16708.348
565500/758000 (epoch 1492), train_loss = 0.250, time/batch = 0.031, All_Time = 16709.853
565550/758000 (epoch 1492), train_loss = 0.253, time/batch = 0.031, All_Time = 16711.342
565600/758000 (epoch 1492), train_loss = 0.245, time/batch = 0.030, All_Time = 16712.824
565650/758000 (epoch 1492), train_loss = 0.231, time/batch = 0.030, All_Time = 16714.308
565700/758000 (epoch 1492), train_loss = 0.228, time/batch = 0.030, All_Time = 16715.778
565750/758000 (epoch 1492), train_loss = 0.238, time/batch = 0.029, All_Time = 16717.255
565800/758000 (epoch 1492), train_loss = 0.268, time/batch = 0.029, All_Time = 16718.729
565850/758000 (epoch 1493), train_loss = 0.248, time/batch = 0.031, All_Time = 16720.206
565900/758000 (epoch 1493), train_loss = 0.280, time/batch = 0.029, All_Time = 16721.678
565950/758000 (epoch 1493), train_loss = 0.242, time/batch = 0.030, All_Time = 16723.143
566000/758000 (epoch 1493), train_loss = 0.258, time/batch = 0.030, All_Time = 16724.624
model saved to NER/polyglot/model.ckpt
566050/758000 (epoch 1493), train_loss = 0.224, time/batch = 0.029, All_Time = 16726.106
566100/758000 (epoch 1493), train_loss = 0.243, time/batch = 0.030, All_Time = 16727.565
566150/758000 (epoch 1493), train_loss = 0.219, time/batch = 0.030, All_Time = 16729.056
566200/758000 (epoch 1493), train_loss = 0.232, time/batch = 0.030, All_Time = 16730.552
566250/758000 (epoch 1494), train_loss = 0.237, time/batch = 0.029, All_Time = 16732.040
566300/758000 (epoch 1494), train_loss = 0.239, time/batch = 0.029, All_Time = 16733.510
566350/758000 (epoch 1494), train_loss = 0.293, time/batch = 0.030, All_Time = 16734.976
566400/758000 (epoch 1494), train_loss = 0.318, time/batch = 0.030, All_Time = 16736.475
566450/758000 (epoch 1494), train_loss = 0.196, time/batch = 0.029, All_Time = 16737.992
566500/758000 (epoch 1494), train_loss = 0.213, time/batch = 0.031, All_Time = 16739.462
566550/758000 (epoch 1494), train_loss = 0.250, time/batch = 0.029, All_Time = 16740.922
566600/758000 (epoch 1494), train_loss = 0.297, time/batch = 0.030, All_Time = 16742.392
566650/758000 (epoch 1495), train_loss = 0.226, time/batch = 0.030, All_Time = 16743.864
566700/758000 (epoch 1495), train_loss = 0.259, time/batch = 0.031, All_Time = 16745.338
566750/758000 (epoch 1495), train_loss = 0.223, time/batch = 0.028, All_Time = 16746.820
566800/758000 (epoch 1495), train_loss = 0.239, time/batch = 0.028, All_Time = 16748.305
566850/758000 (epoch 1495), train_loss = 0.212, time/batch = 0.031, All_Time = 16749.783
566900/758000 (epoch 1495), train_loss = 0.243, time/batch = 0.028, All_Time = 16751.266
566950/758000 (epoch 1495), train_loss = 0.215, time/batch = 0.029, All_Time = 16752.739
567000/758000 (epoch 1496), train_loss = 0.228, time/batch = 0.029, All_Time = 16754.215
model saved to NER/polyglot/model.ckpt
567050/758000 (epoch 1496), train_loss = 0.252, time/batch = 0.030, All_Time = 16755.694
567100/758000 (epoch 1496), train_loss = 0.260, time/batch = 0.030, All_Time = 16757.152
567150/758000 (epoch 1496), train_loss = 0.228, time/batch = 0.028, All_Time = 16758.624
567200/758000 (epoch 1496), train_loss = 0.236, time/batch = 0.028, All_Time = 16760.102
567250/758000 (epoch 1496), train_loss = 0.271, time/batch = 0.029, All_Time = 16761.594
567300/758000 (epoch 1496), train_loss = 0.238, time/batch = 0.032, All_Time = 16763.086
567350/758000 (epoch 1496), train_loss = 0.268, time/batch = 0.031, All_Time = 16764.561
567400/758000 (epoch 1497), train_loss = 0.248, time/batch = 0.028, All_Time = 16766.034
567450/758000 (epoch 1497), train_loss = 0.249, time/batch = 0.029, All_Time = 16767.499
567500/758000 (epoch 1497), train_loss = 0.240, time/batch = 0.031, All_Time = 16768.971
567550/758000 (epoch 1497), train_loss = 0.247, time/batch = 0.029, All_Time = 16770.450
567600/758000 (epoch 1497), train_loss = 0.235, time/batch = 0.029, All_Time = 16771.925
567650/758000 (epoch 1497), train_loss = 0.247, time/batch = 0.030, All_Time = 16773.408
567700/758000 (epoch 1497), train_loss = 0.251, time/batch = 0.029, All_Time = 16774.898
567750/758000 (epoch 1498), train_loss = 0.242, time/batch = 0.030, All_Time = 16776.384
567800/758000 (epoch 1498), train_loss = 0.276, time/batch = 0.029, All_Time = 16777.860
567850/758000 (epoch 1498), train_loss = 0.256, time/batch = 0.029, All_Time = 16779.325
567900/758000 (epoch 1498), train_loss = 0.258, time/batch = 0.030, All_Time = 16780.804
567950/758000 (epoch 1498), train_loss = 0.213, time/batch = 0.032, All_Time = 16782.287
568000/758000 (epoch 1498), train_loss = 0.237, time/batch = 0.031, All_Time = 16783.803
model saved to NER/polyglot/model.ckpt
568050/758000 (epoch 1498), train_loss = 0.249, time/batch = 0.030, All_Time = 16785.284
568100/758000 (epoch 1498), train_loss = 0.251, time/batch = 0.029, All_Time = 16786.775
568150/758000 (epoch 1499), train_loss = 0.232, time/batch = 0.030, All_Time = 16788.261
568200/758000 (epoch 1499), train_loss = 0.255, time/batch = 0.030, All_Time = 16789.758
568250/758000 (epoch 1499), train_loss = 0.265, time/batch = 0.029, All_Time = 16791.250
568300/758000 (epoch 1499), train_loss = 0.229, time/batch = 0.028, All_Time = 16792.732
568350/758000 (epoch 1499), train_loss = 0.263, time/batch = 0.029, All_Time = 16794.215
568400/758000 (epoch 1499), train_loss = 0.217, time/batch = 0.030, All_Time = 16795.694
568450/758000 (epoch 1499), train_loss = 0.248, time/batch = 0.029, All_Time = 16797.163
568500/758000 (epoch 1500), train_loss = 0.059, time/batch = 0.030, All_Time = 16798.653
568550/758000 (epoch 1500), train_loss = 0.250, time/batch = 0.029, All_Time = 16800.140
568600/758000 (epoch 1500), train_loss = 0.223, time/batch = 0.029, All_Time = 16801.606
568650/758000 (epoch 1500), train_loss = 0.250, time/batch = 0.030, All_Time = 16803.069
568700/758000 (epoch 1500), train_loss = 0.231, time/batch = 0.031, All_Time = 16804.555
568750/758000 (epoch 1500), train_loss = 0.250, time/batch = 0.029, All_Time = 16806.032
568800/758000 (epoch 1500), train_loss = 0.232, time/batch = 0.031, All_Time = 16807.513
568850/758000 (epoch 1500), train_loss = 0.230, time/batch = 0.029, All_Time = 16808.995
568900/758000 (epoch 1501), train_loss = 0.224, time/batch = 0.029, All_Time = 16810.480
568950/758000 (epoch 1501), train_loss = 0.233, time/batch = 0.029, All_Time = 16811.958
569000/758000 (epoch 1501), train_loss = 0.224, time/batch = 0.028, All_Time = 16813.420
model saved to NER/polyglot/model.ckpt
569050/758000 (epoch 1501), train_loss = 0.262, time/batch = 0.029, All_Time = 16814.882
569100/758000 (epoch 1501), train_loss = 0.220, time/batch = 0.030, All_Time = 16816.342
569150/758000 (epoch 1501), train_loss = 0.228, time/batch = 0.029, All_Time = 16817.816
569200/758000 (epoch 1501), train_loss = 0.280, time/batch = 0.029, All_Time = 16819.308
569250/758000 (epoch 1501), train_loss = 0.272, time/batch = 0.029, All_Time = 16820.789
569300/758000 (epoch 1502), train_loss = 0.230, time/batch = 0.030, All_Time = 16822.257
569350/758000 (epoch 1502), train_loss = 0.224, time/batch = 0.029, All_Time = 16823.784
569400/758000 (epoch 1502), train_loss = 0.201, time/batch = 0.029, All_Time = 16825.258
569450/758000 (epoch 1502), train_loss = 0.270, time/batch = 0.029, All_Time = 16826.715
569500/758000 (epoch 1502), train_loss = 0.259, time/batch = 0.033, All_Time = 16828.203
569550/758000 (epoch 1502), train_loss = 0.209, time/batch = 0.031, All_Time = 16829.713
569600/758000 (epoch 1502), train_loss = 0.218, time/batch = 0.029, All_Time = 16831.207
569650/758000 (epoch 1503), train_loss = 0.229, time/batch = 0.029, All_Time = 16832.692
569700/758000 (epoch 1503), train_loss = 0.283, time/batch = 0.029, All_Time = 16834.165
569750/758000 (epoch 1503), train_loss = 0.231, time/batch = 0.029, All_Time = 16835.632
569800/758000 (epoch 1503), train_loss = 0.307, time/batch = 0.030, All_Time = 16837.102
569850/758000 (epoch 1503), train_loss = 0.221, time/batch = 0.030, All_Time = 16838.594
569900/758000 (epoch 1503), train_loss = 0.208, time/batch = 0.029, All_Time = 16840.084
569950/758000 (epoch 1503), train_loss = 0.247, time/batch = 0.030, All_Time = 16841.571
570000/758000 (epoch 1503), train_loss = 0.252, time/batch = 0.029, All_Time = 16843.057
model saved to NER/polyglot/model.ckpt
570050/758000 (epoch 1504), train_loss = 0.264, time/batch = 0.030, All_Time = 16844.534
570100/758000 (epoch 1504), train_loss = 0.229, time/batch = 0.029, All_Time = 16845.995
570150/758000 (epoch 1504), train_loss = 0.242, time/batch = 0.031, All_Time = 16847.477
570200/758000 (epoch 1504), train_loss = 0.267, time/batch = 0.030, All_Time = 16848.969
570250/758000 (epoch 1504), train_loss = 0.249, time/batch = 0.030, All_Time = 16850.447
570300/758000 (epoch 1504), train_loss = 0.237, time/batch = 0.028, All_Time = 16851.921
570350/758000 (epoch 1504), train_loss = 0.276, time/batch = 0.031, All_Time = 16853.406
570400/758000 (epoch 1505), train_loss = 0.256, time/batch = 0.029, All_Time = 16854.887
570450/758000 (epoch 1505), train_loss = 0.222, time/batch = 0.029, All_Time = 16856.355
570500/758000 (epoch 1505), train_loss = 0.266, time/batch = 0.029, All_Time = 16857.817
570550/758000 (epoch 1505), train_loss = 0.216, time/batch = 0.030, All_Time = 16859.295
570600/758000 (epoch 1505), train_loss = 0.223, time/batch = 0.030, All_Time = 16860.779
570650/758000 (epoch 1505), train_loss = 0.261, time/batch = 0.029, All_Time = 16862.271
570700/758000 (epoch 1505), train_loss = 0.238, time/batch = 0.030, All_Time = 16863.778
570750/758000 (epoch 1505), train_loss = 0.264, time/batch = 0.028, All_Time = 16865.252
570800/758000 (epoch 1506), train_loss = 0.223, time/batch = 0.029, All_Time = 16866.735
570850/758000 (epoch 1506), train_loss = 0.231, time/batch = 0.029, All_Time = 16868.206
570900/758000 (epoch 1506), train_loss = 0.238, time/batch = 0.029, All_Time = 16869.678
570950/758000 (epoch 1506), train_loss = 0.266, time/batch = 0.030, All_Time = 16871.148
571000/758000 (epoch 1506), train_loss = 0.239, time/batch = 0.029, All_Time = 16872.630
model saved to NER/polyglot/model.ckpt
571050/758000 (epoch 1506), train_loss = 0.226, time/batch = 0.029, All_Time = 16874.098
571100/758000 (epoch 1506), train_loss = 0.276, time/batch = 0.032, All_Time = 16875.580
571150/758000 (epoch 1506), train_loss = 0.240, time/batch = 0.029, All_Time = 16877.080
571200/758000 (epoch 1507), train_loss = 0.281, time/batch = 0.030, All_Time = 16878.562
571250/758000 (epoch 1507), train_loss = 0.257, time/batch = 0.030, All_Time = 16880.033
571300/758000 (epoch 1507), train_loss = 0.240, time/batch = 0.029, All_Time = 16881.499
571350/758000 (epoch 1507), train_loss = 0.231, time/batch = 0.029, All_Time = 16882.960
571400/758000 (epoch 1507), train_loss = 0.217, time/batch = 0.030, All_Time = 16884.440
571450/758000 (epoch 1507), train_loss = 0.224, time/batch = 0.030, All_Time = 16885.916
571500/758000 (epoch 1507), train_loss = 0.215, time/batch = 0.030, All_Time = 16887.384
571550/758000 (epoch 1508), train_loss = 0.249, time/batch = 0.031, All_Time = 16888.869
571600/758000 (epoch 1508), train_loss = 0.211, time/batch = 0.029, All_Time = 16890.338
571650/758000 (epoch 1508), train_loss = 0.245, time/batch = 0.029, All_Time = 16891.815
571700/758000 (epoch 1508), train_loss = 0.217, time/batch = 0.028, All_Time = 16893.286
571750/758000 (epoch 1508), train_loss = 0.233, time/batch = 0.029, All_Time = 16894.764
571800/758000 (epoch 1508), train_loss = 0.228, time/batch = 0.030, All_Time = 16896.236
571850/758000 (epoch 1508), train_loss = 0.248, time/batch = 0.029, All_Time = 16897.708
571900/758000 (epoch 1508), train_loss = 0.229, time/batch = 0.030, All_Time = 16899.182
571950/758000 (epoch 1509), train_loss = 0.218, time/batch = 0.029, All_Time = 16900.663
572000/758000 (epoch 1509), train_loss = 0.237, time/batch = 0.031, All_Time = 16902.138
model saved to NER/polyglot/model.ckpt
572050/758000 (epoch 1509), train_loss = 0.212, time/batch = 0.030, All_Time = 16903.618
572100/758000 (epoch 1509), train_loss = 0.266, time/batch = 0.030, All_Time = 16905.131
572150/758000 (epoch 1509), train_loss = 0.255, time/batch = 0.031, All_Time = 16906.626
572200/758000 (epoch 1509), train_loss = 0.232, time/batch = 0.029, All_Time = 16908.112
572250/758000 (epoch 1509), train_loss = 0.262, time/batch = 0.029, All_Time = 16909.591
572300/758000 (epoch 1510), train_loss = 0.282, time/batch = 0.030, All_Time = 16911.065
572350/758000 (epoch 1510), train_loss = 0.292, time/batch = 0.030, All_Time = 16912.538
572400/758000 (epoch 1510), train_loss = 0.253, time/batch = 0.029, All_Time = 16914.013
572450/758000 (epoch 1510), train_loss = 0.222, time/batch = 0.031, All_Time = 16915.487
572500/758000 (epoch 1510), train_loss = 0.221, time/batch = 0.031, All_Time = 16916.960
572550/758000 (epoch 1510), train_loss = 0.260, time/batch = 0.030, All_Time = 16918.431
572600/758000 (epoch 1510), train_loss = 0.244, time/batch = 0.030, All_Time = 16919.912
572650/758000 (epoch 1510), train_loss = 0.247, time/batch = 0.029, All_Time = 16921.383
572700/758000 (epoch 1511), train_loss = 0.210, time/batch = 0.029, All_Time = 16922.855
572750/758000 (epoch 1511), train_loss = 0.265, time/batch = 0.029, All_Time = 16924.326
572800/758000 (epoch 1511), train_loss = 0.229, time/batch = 0.029, All_Time = 16925.828
572850/758000 (epoch 1511), train_loss = 0.232, time/batch = 0.033, All_Time = 16927.321
572900/758000 (epoch 1511), train_loss = 0.230, time/batch = 0.030, All_Time = 16928.800
572950/758000 (epoch 1511), train_loss = 0.253, time/batch = 0.029, All_Time = 16930.288
573000/758000 (epoch 1511), train_loss = 0.258, time/batch = 0.029, All_Time = 16931.774
model saved to NER/polyglot/model.ckpt
573050/758000 (epoch 1512), train_loss = 0.196, time/batch = 0.031, All_Time = 16933.244
573100/758000 (epoch 1512), train_loss = 0.254, time/batch = 0.028, All_Time = 16934.708
573150/758000 (epoch 1512), train_loss = 0.281, time/batch = 0.031, All_Time = 16936.163
573200/758000 (epoch 1512), train_loss = 0.235, time/batch = 0.029, All_Time = 16937.645
573250/758000 (epoch 1512), train_loss = 0.247, time/batch = 0.030, All_Time = 16939.136
573300/758000 (epoch 1512), train_loss = 0.251, time/batch = 0.031, All_Time = 16940.623
573350/758000 (epoch 1512), train_loss = 0.203, time/batch = 0.029, All_Time = 16942.113
573400/758000 (epoch 1512), train_loss = 0.268, time/batch = 0.028, All_Time = 16943.590
573450/758000 (epoch 1513), train_loss = 0.233, time/batch = 0.029, All_Time = 16945.073
573500/758000 (epoch 1513), train_loss = 0.241, time/batch = 0.030, All_Time = 16946.547
573550/758000 (epoch 1513), train_loss = 0.252, time/batch = 0.031, All_Time = 16948.026
573600/758000 (epoch 1513), train_loss = 0.258, time/batch = 0.029, All_Time = 16949.493
573650/758000 (epoch 1513), train_loss = 0.243, time/batch = 0.031, All_Time = 16950.979
573700/758000 (epoch 1513), train_loss = 0.243, time/batch = 0.030, All_Time = 16952.463
573750/758000 (epoch 1513), train_loss = 0.244, time/batch = 0.029, All_Time = 16953.954
573800/758000 (epoch 1513), train_loss = 0.286, time/batch = 0.031, All_Time = 16955.430
573850/758000 (epoch 1514), train_loss = 0.207, time/batch = 0.030, All_Time = 16956.909
573900/758000 (epoch 1514), train_loss = 0.244, time/batch = 0.028, All_Time = 16958.394
573950/758000 (epoch 1514), train_loss = 0.217, time/batch = 0.030, All_Time = 16959.886
574000/758000 (epoch 1514), train_loss = 0.233, time/batch = 0.030, All_Time = 16961.374
model saved to NER/polyglot/model.ckpt
574050/758000 (epoch 1514), train_loss = 0.260, time/batch = 0.030, All_Time = 16962.854
574100/758000 (epoch 1514), train_loss = 0.253, time/batch = 0.029, All_Time = 16964.327
574150/758000 (epoch 1514), train_loss = 0.238, time/batch = 0.032, All_Time = 16965.806
574200/758000 (epoch 1515), train_loss = 0.227, time/batch = 0.030, All_Time = 16967.307
574250/758000 (epoch 1515), train_loss = 0.250, time/batch = 0.029, All_Time = 16968.822
574300/758000 (epoch 1515), train_loss = 0.250, time/batch = 0.030, All_Time = 16970.308
574350/758000 (epoch 1515), train_loss = 0.223, time/batch = 0.029, All_Time = 16971.790
574400/758000 (epoch 1515), train_loss = 0.240, time/batch = 0.029, All_Time = 16973.278
574450/758000 (epoch 1515), train_loss = 0.246, time/batch = 0.031, All_Time = 16974.751
574500/758000 (epoch 1515), train_loss = 0.246, time/batch = 0.031, All_Time = 16976.270
574550/758000 (epoch 1515), train_loss = 0.257, time/batch = 0.029, All_Time = 16977.767
574600/758000 (epoch 1516), train_loss = 0.266, time/batch = 0.029, All_Time = 16979.249
574650/758000 (epoch 1516), train_loss = 0.224, time/batch = 0.029, All_Time = 16980.719
574700/758000 (epoch 1516), train_loss = 0.248, time/batch = 0.029, All_Time = 16982.187
574750/758000 (epoch 1516), train_loss = 0.227, time/batch = 0.030, All_Time = 16983.658
574800/758000 (epoch 1516), train_loss = 0.279, time/batch = 0.031, All_Time = 16985.176
574850/758000 (epoch 1516), train_loss = 0.255, time/batch = 0.029, All_Time = 16986.667
574900/758000 (epoch 1516), train_loss = 0.253, time/batch = 0.031, All_Time = 16988.160
574950/758000 (epoch 1517), train_loss = 0.244, time/batch = 0.029, All_Time = 16989.657
575000/758000 (epoch 1517), train_loss = 0.247, time/batch = 0.030, All_Time = 16991.124
model saved to NER/polyglot/model.ckpt
575050/758000 (epoch 1517), train_loss = 0.270, time/batch = 0.030, All_Time = 16992.594
575100/758000 (epoch 1517), train_loss = 0.246, time/batch = 0.029, All_Time = 16994.057
575150/758000 (epoch 1517), train_loss = 0.237, time/batch = 0.032, All_Time = 16995.519
575200/758000 (epoch 1517), train_loss = 0.224, time/batch = 0.030, All_Time = 16997.035
575250/758000 (epoch 1517), train_loss = 0.229, time/batch = 0.029, All_Time = 16998.527
575300/758000 (epoch 1517), train_loss = 0.246, time/batch = 0.029, All_Time = 17000.013
575350/758000 (epoch 1518), train_loss = 0.249, time/batch = 0.030, All_Time = 17001.492
575400/758000 (epoch 1518), train_loss = 0.264, time/batch = 0.028, All_Time = 17002.950
575450/758000 (epoch 1518), train_loss = 0.240, time/batch = 0.030, All_Time = 17004.423
575500/758000 (epoch 1518), train_loss = 0.250, time/batch = 0.029, All_Time = 17005.998
575550/758000 (epoch 1518), train_loss = 0.227, time/batch = 0.029, All_Time = 17007.474
575600/758000 (epoch 1518), train_loss = 0.217, time/batch = 0.030, All_Time = 17008.983
575650/758000 (epoch 1518), train_loss = 0.277, time/batch = 0.030, All_Time = 17010.468
575700/758000 (epoch 1518), train_loss = 0.259, time/batch = 0.029, All_Time = 17011.941
575750/758000 (epoch 1519), train_loss = 0.269, time/batch = 0.030, All_Time = 17013.402
575800/758000 (epoch 1519), train_loss = 0.296, time/batch = 0.030, All_Time = 17014.884
575850/758000 (epoch 1519), train_loss = 0.228, time/batch = 0.030, All_Time = 17016.380
575900/758000 (epoch 1519), train_loss = 0.220, time/batch = 0.028, All_Time = 17017.859
575950/758000 (epoch 1519), train_loss = 0.257, time/batch = 0.031, All_Time = 17019.341
576000/758000 (epoch 1519), train_loss = 0.255, time/batch = 0.031, All_Time = 17020.827
model saved to NER/polyglot/model.ckpt
576050/758000 (epoch 1519), train_loss = 0.237, time/batch = 0.030, All_Time = 17022.307
576100/758000 (epoch 1520), train_loss = 0.225, time/batch = 0.028, All_Time = 17023.778
576150/758000 (epoch 1520), train_loss = 0.234, time/batch = 0.030, All_Time = 17025.254
576200/758000 (epoch 1520), train_loss = 0.243, time/batch = 0.029, All_Time = 17026.710
576250/758000 (epoch 1520), train_loss = 0.234, time/batch = 0.030, All_Time = 17028.185
576300/758000 (epoch 1520), train_loss = 0.223, time/batch = 0.032, All_Time = 17029.683
576350/758000 (epoch 1520), train_loss = 0.239, time/batch = 0.030, All_Time = 17031.198
576400/758000 (epoch 1520), train_loss = 0.264, time/batch = 0.031, All_Time = 17032.692
576450/758000 (epoch 1520), train_loss = 0.244, time/batch = 0.030, All_Time = 17034.175
576500/758000 (epoch 1521), train_loss = 0.257, time/batch = 0.029, All_Time = 17035.637
576550/758000 (epoch 1521), train_loss = 0.287, time/batch = 0.030, All_Time = 17037.110
576600/758000 (epoch 1521), train_loss = 0.255, time/batch = 0.030, All_Time = 17038.572
576650/758000 (epoch 1521), train_loss = 0.248, time/batch = 0.029, All_Time = 17040.039
576700/758000 (epoch 1521), train_loss = 0.212, time/batch = 0.032, All_Time = 17041.512
576750/758000 (epoch 1521), train_loss = 0.229, time/batch = 0.030, All_Time = 17042.994
576800/758000 (epoch 1521), train_loss = 0.272, time/batch = 0.030, All_Time = 17044.491
576850/758000 (epoch 1522), train_loss = 0.249, time/batch = 0.029, All_Time = 17045.982
576900/758000 (epoch 1522), train_loss = 0.227, time/batch = 0.029, All_Time = 17047.454
576950/758000 (epoch 1522), train_loss = 0.267, time/batch = 0.030, All_Time = 17048.932
577000/758000 (epoch 1522), train_loss = 0.239, time/batch = 0.029, All_Time = 17050.400
model saved to NER/polyglot/model.ckpt
577050/758000 (epoch 1522), train_loss = 0.247, time/batch = 0.030, All_Time = 17051.868
577100/758000 (epoch 1522), train_loss = 0.241, time/batch = 0.029, All_Time = 17053.344
577150/758000 (epoch 1522), train_loss = 0.274, time/batch = 0.030, All_Time = 17054.831
577200/758000 (epoch 1522), train_loss = 0.279, time/batch = 0.031, All_Time = 17056.324
577250/758000 (epoch 1523), train_loss = 0.238, time/batch = 0.029, All_Time = 17057.803
577300/758000 (epoch 1523), train_loss = 0.248, time/batch = 0.030, All_Time = 17059.286
577350/758000 (epoch 1523), train_loss = 0.299, time/batch = 0.030, All_Time = 17060.770
577400/758000 (epoch 1523), train_loss = 0.230, time/batch = 0.029, All_Time = 17062.244
577450/758000 (epoch 1523), train_loss = 0.216, time/batch = 0.030, All_Time = 17063.720
577500/758000 (epoch 1523), train_loss = 0.244, time/batch = 0.029, All_Time = 17065.196
577550/758000 (epoch 1523), train_loss = 0.274, time/batch = 0.031, All_Time = 17066.715
577600/758000 (epoch 1524), train_loss = 0.221, time/batch = 0.031, All_Time = 17068.219
577650/758000 (epoch 1524), train_loss = 0.257, time/batch = 0.030, All_Time = 17069.695
577700/758000 (epoch 1524), train_loss = 0.241, time/batch = 0.028, All_Time = 17071.183
577750/758000 (epoch 1524), train_loss = 0.240, time/batch = 0.031, All_Time = 17072.651
577800/758000 (epoch 1524), train_loss = 0.256, time/batch = 0.030, All_Time = 17074.119
577850/758000 (epoch 1524), train_loss = 0.219, time/batch = 0.029, All_Time = 17075.598
577900/758000 (epoch 1524), train_loss = 0.224, time/batch = 0.030, All_Time = 17077.074
577950/758000 (epoch 1524), train_loss = 0.257, time/batch = 0.028, All_Time = 17078.594
578000/758000 (epoch 1525), train_loss = 0.255, time/batch = 0.029, All_Time = 17080.091
model saved to NER/polyglot/model.ckpt
578050/758000 (epoch 1525), train_loss = 0.267, time/batch = 0.028, All_Time = 17081.563
578100/758000 (epoch 1525), train_loss = 0.269, time/batch = 0.029, All_Time = 17083.030
578150/758000 (epoch 1525), train_loss = 0.228, time/batch = 0.030, All_Time = 17084.507
578200/758000 (epoch 1525), train_loss = 0.234, time/batch = 0.029, All_Time = 17086.005
578250/758000 (epoch 1525), train_loss = 0.245, time/batch = 0.029, All_Time = 17087.482
578300/758000 (epoch 1525), train_loss = 0.279, time/batch = 0.030, All_Time = 17088.962
578350/758000 (epoch 1525), train_loss = 0.240, time/batch = 0.031, All_Time = 17090.463
578400/758000 (epoch 1526), train_loss = 0.236, time/batch = 0.029, All_Time = 17091.941
578450/758000 (epoch 1526), train_loss = 0.234, time/batch = 0.030, All_Time = 17093.412
578500/758000 (epoch 1526), train_loss = 0.233, time/batch = 0.030, All_Time = 17094.881
578550/758000 (epoch 1526), train_loss = 0.276, time/batch = 0.030, All_Time = 17096.351
578600/758000 (epoch 1526), train_loss = 0.206, time/batch = 0.030, All_Time = 17097.817
578650/758000 (epoch 1526), train_loss = 0.259, time/batch = 0.029, All_Time = 17099.295
578700/758000 (epoch 1526), train_loss = 0.234, time/batch = 0.029, All_Time = 17100.765
578750/758000 (epoch 1527), train_loss = 0.245, time/batch = 0.030, All_Time = 17102.255
578800/758000 (epoch 1527), train_loss = 0.223, time/batch = 0.030, All_Time = 17103.726
578850/758000 (epoch 1527), train_loss = 0.240, time/batch = 0.029, All_Time = 17105.219
578900/758000 (epoch 1527), train_loss = 0.256, time/batch = 0.029, All_Time = 17106.689
578950/758000 (epoch 1527), train_loss = 0.214, time/batch = 0.029, All_Time = 17108.156
579000/758000 (epoch 1527), train_loss = 0.272, time/batch = 0.030, All_Time = 17109.646
model saved to NER/polyglot/model.ckpt
579050/758000 (epoch 1527), train_loss = 0.213, time/batch = 0.029, All_Time = 17111.129
579100/758000 (epoch 1527), train_loss = 0.251, time/batch = 0.027, All_Time = 17112.583
579150/758000 (epoch 1528), train_loss = 0.247, time/batch = 0.030, All_Time = 17114.042
579200/758000 (epoch 1528), train_loss = 0.229, time/batch = 0.029, All_Time = 17115.508
579250/758000 (epoch 1528), train_loss = 0.217, time/batch = 0.031, All_Time = 17117.013
579300/758000 (epoch 1528), train_loss = 0.220, time/batch = 0.029, All_Time = 17118.500
579350/758000 (epoch 1528), train_loss = 0.250, time/batch = 0.029, All_Time = 17119.994
579400/758000 (epoch 1528), train_loss = 0.207, time/batch = 0.029, All_Time = 17121.475
579450/758000 (epoch 1528), train_loss = 0.268, time/batch = 0.029, All_Time = 17122.968
579500/758000 (epoch 1529), train_loss = 0.256, time/batch = 0.030, All_Time = 17124.462
579550/758000 (epoch 1529), train_loss = 0.264, time/batch = 0.030, All_Time = 17125.938
579600/758000 (epoch 1529), train_loss = 0.284, time/batch = 0.029, All_Time = 17127.406
579650/758000 (epoch 1529), train_loss = 0.239, time/batch = 0.029, All_Time = 17128.876
579700/758000 (epoch 1529), train_loss = 0.267, time/batch = 0.029, All_Time = 17130.344
579750/758000 (epoch 1529), train_loss = 0.256, time/batch = 0.030, All_Time = 17131.822
579800/758000 (epoch 1529), train_loss = 0.236, time/batch = 0.030, All_Time = 17133.330
579850/758000 (epoch 1529), train_loss = 0.268, time/batch = 0.029, All_Time = 17134.831
579900/758000 (epoch 1530), train_loss = 0.226, time/batch = 0.029, All_Time = 17136.325
579950/758000 (epoch 1530), train_loss = 0.222, time/batch = 0.029, All_Time = 17137.800
580000/758000 (epoch 1530), train_loss = 0.261, time/batch = 0.030, All_Time = 17139.274
model saved to NER/polyglot/model.ckpt
580050/758000 (epoch 1530), train_loss = 0.254, time/batch = 0.028, All_Time = 17140.743
580100/758000 (epoch 1530), train_loss = 0.223, time/batch = 0.030, All_Time = 17142.207
580150/758000 (epoch 1530), train_loss = 0.242, time/batch = 0.030, All_Time = 17143.670
580200/758000 (epoch 1530), train_loss = 0.251, time/batch = 0.031, All_Time = 17145.136
580250/758000 (epoch 1531), train_loss = 0.192, time/batch = 0.028, All_Time = 17146.601
580300/758000 (epoch 1531), train_loss = 0.273, time/batch = 0.030, All_Time = 17148.083
580350/758000 (epoch 1531), train_loss = 0.217, time/batch = 0.030, All_Time = 17149.554
580400/758000 (epoch 1531), train_loss = 0.240, time/batch = 0.029, All_Time = 17151.033
580450/758000 (epoch 1531), train_loss = 0.221, time/batch = 0.031, All_Time = 17152.500
580500/758000 (epoch 1531), train_loss = 0.221, time/batch = 0.030, All_Time = 17153.978
580550/758000 (epoch 1531), train_loss = 0.252, time/batch = 0.029, All_Time = 17155.467
580600/758000 (epoch 1531), train_loss = 0.272, time/batch = 0.029, All_Time = 17156.954
580650/758000 (epoch 1532), train_loss = 0.222, time/batch = 0.029, All_Time = 17158.430
580700/758000 (epoch 1532), train_loss = 0.279, time/batch = 0.030, All_Time = 17159.908
580750/758000 (epoch 1532), train_loss = 0.242, time/batch = 0.028, All_Time = 17161.375
580800/758000 (epoch 1532), train_loss = 0.274, time/batch = 0.030, All_Time = 17162.846
580850/758000 (epoch 1532), train_loss = 0.262, time/batch = 0.029, All_Time = 17164.323
580900/758000 (epoch 1532), train_loss = 0.197, time/batch = 0.029, All_Time = 17165.798
580950/758000 (epoch 1532), train_loss = 0.233, time/batch = 0.030, All_Time = 17167.274
581000/758000 (epoch 1532), train_loss = 0.281, time/batch = 0.030, All_Time = 17168.805
model saved to NER/polyglot/model.ckpt
581050/758000 (epoch 1533), train_loss = 0.246, time/batch = 0.030, All_Time = 17170.287
581100/758000 (epoch 1533), train_loss = 0.212, time/batch = 0.028, All_Time = 17171.757
581150/758000 (epoch 1533), train_loss = 0.255, time/batch = 0.029, All_Time = 17173.230
581200/758000 (epoch 1533), train_loss = 0.271, time/batch = 0.029, All_Time = 17174.697
581250/758000 (epoch 1533), train_loss = 0.203, time/batch = 0.028, All_Time = 17176.173
581300/758000 (epoch 1533), train_loss = 0.226, time/batch = 0.030, All_Time = 17177.644
581350/758000 (epoch 1533), train_loss = 0.254, time/batch = 0.031, All_Time = 17179.139
581400/758000 (epoch 1534), train_loss = 0.219, time/batch = 0.030, All_Time = 17180.647
581450/758000 (epoch 1534), train_loss = 0.265, time/batch = 0.028, All_Time = 17182.122
581500/758000 (epoch 1534), train_loss = 0.227, time/batch = 0.028, All_Time = 17183.579
581550/758000 (epoch 1534), train_loss = 0.213, time/batch = 0.029, All_Time = 17185.046
581600/758000 (epoch 1534), train_loss = 0.224, time/batch = 0.031, All_Time = 17186.511
581650/758000 (epoch 1534), train_loss = 0.213, time/batch = 0.030, All_Time = 17187.976
581700/758000 (epoch 1534), train_loss = 0.230, time/batch = 0.029, All_Time = 17189.438
581750/758000 (epoch 1534), train_loss = 0.223, time/batch = 0.028, All_Time = 17190.902
581800/758000 (epoch 1535), train_loss = 0.275, time/batch = 0.029, All_Time = 17192.370
581850/758000 (epoch 1535), train_loss = 0.229, time/batch = 0.029, All_Time = 17193.834
581900/758000 (epoch 1535), train_loss = 0.270, time/batch = 0.029, All_Time = 17195.298
581950/758000 (epoch 1535), train_loss = 0.273, time/batch = 0.028, All_Time = 17196.762
582000/758000 (epoch 1535), train_loss = 0.233, time/batch = 0.030, All_Time = 17198.224
model saved to NER/polyglot/model.ckpt
582050/758000 (epoch 1535), train_loss = 0.268, time/batch = 0.029, All_Time = 17199.702
582100/758000 (epoch 1535), train_loss = 0.280, time/batch = 0.029, All_Time = 17201.167
582150/758000 (epoch 1536), train_loss = 0.239, time/batch = 0.031, All_Time = 17202.634
582200/758000 (epoch 1536), train_loss = 0.218, time/batch = 0.029, All_Time = 17204.113
582250/758000 (epoch 1536), train_loss = 0.243, time/batch = 0.028, All_Time = 17205.589
582300/758000 (epoch 1536), train_loss = 0.244, time/batch = 0.030, All_Time = 17207.068
582350/758000 (epoch 1536), train_loss = 0.243, time/batch = 0.029, All_Time = 17208.545
582400/758000 (epoch 1536), train_loss = 0.244, time/batch = 0.030, All_Time = 17210.015
582450/758000 (epoch 1536), train_loss = 0.213, time/batch = 0.029, All_Time = 17211.478
582500/758000 (epoch 1536), train_loss = 0.289, time/batch = 0.030, All_Time = 17212.948
582550/758000 (epoch 1537), train_loss = 0.237, time/batch = 0.029, All_Time = 17214.412
582600/758000 (epoch 1537), train_loss = 0.246, time/batch = 0.030, All_Time = 17215.932
582650/758000 (epoch 1537), train_loss = 0.288, time/batch = 0.029, All_Time = 17217.425
582700/758000 (epoch 1537), train_loss = 0.257, time/batch = 0.029, All_Time = 17218.918
582750/758000 (epoch 1537), train_loss = 0.218, time/batch = 0.029, All_Time = 17220.388
582800/758000 (epoch 1537), train_loss = 0.238, time/batch = 0.029, All_Time = 17221.841
582850/758000 (epoch 1537), train_loss = 0.251, time/batch = 0.030, All_Time = 17223.312
582900/758000 (epoch 1537), train_loss = 0.251, time/batch = 0.028, All_Time = 17224.776
582950/758000 (epoch 1538), train_loss = 0.252, time/batch = 0.029, All_Time = 17226.236
583000/758000 (epoch 1538), train_loss = 0.280, time/batch = 0.031, All_Time = 17227.702
model saved to NER/polyglot/model.ckpt
583050/758000 (epoch 1538), train_loss = 0.242, time/batch = 0.030, All_Time = 17229.173
583100/758000 (epoch 1538), train_loss = 0.250, time/batch = 0.031, All_Time = 17230.635
583150/758000 (epoch 1538), train_loss = 0.239, time/batch = 0.030, All_Time = 17232.099
583200/758000 (epoch 1538), train_loss = 0.239, time/batch = 0.030, All_Time = 17233.563
583250/758000 (epoch 1538), train_loss = 0.250, time/batch = 0.028, All_Time = 17235.034
583300/758000 (epoch 1539), train_loss = 0.221, time/batch = 0.029, All_Time = 17236.508
583350/758000 (epoch 1539), train_loss = 0.219, time/batch = 0.030, All_Time = 17237.979
583400/758000 (epoch 1539), train_loss = 0.246, time/batch = 0.030, All_Time = 17239.440
583450/758000 (epoch 1539), train_loss = 0.262, time/batch = 0.030, All_Time = 17240.921
583500/758000 (epoch 1539), train_loss = 0.260, time/batch = 0.029, All_Time = 17242.378
583550/758000 (epoch 1539), train_loss = 0.241, time/batch = 0.030, All_Time = 17243.850
583600/758000 (epoch 1539), train_loss = 0.210, time/batch = 0.029, All_Time = 17245.326
583650/758000 (epoch 1539), train_loss = 0.239, time/batch = 0.030, All_Time = 17246.785
583700/758000 (epoch 1540), train_loss = 0.230, time/batch = 0.029, All_Time = 17248.254
583750/758000 (epoch 1540), train_loss = 0.226, time/batch = 0.030, All_Time = 17249.723
583800/758000 (epoch 1540), train_loss = 0.264, time/batch = 0.028, All_Time = 17251.184
583850/758000 (epoch 1540), train_loss = 0.240, time/batch = 0.030, All_Time = 17252.647
583900/758000 (epoch 1540), train_loss = 0.253, time/batch = 0.030, All_Time = 17254.112
583950/758000 (epoch 1540), train_loss = 0.251, time/batch = 0.029, All_Time = 17255.570
584000/758000 (epoch 1540), train_loss = 0.248, time/batch = 0.029, All_Time = 17257.036
model saved to NER/polyglot/model.ckpt
584050/758000 (epoch 1541), train_loss = 0.216, time/batch = 0.031, All_Time = 17258.515
584100/758000 (epoch 1541), train_loss = 0.233, time/batch = 0.030, All_Time = 17259.980
584150/758000 (epoch 1541), train_loss = 0.250, time/batch = 0.029, All_Time = 17261.447
584200/758000 (epoch 1541), train_loss = 0.241, time/batch = 0.029, All_Time = 17262.916
584250/758000 (epoch 1541), train_loss = 0.243, time/batch = 0.028, All_Time = 17264.370
584300/758000 (epoch 1541), train_loss = 0.242, time/batch = 0.029, All_Time = 17265.842
584350/758000 (epoch 1541), train_loss = 0.230, time/batch = 0.028, All_Time = 17267.294
584400/758000 (epoch 1541), train_loss = 0.259, time/batch = 0.028, All_Time = 17268.765
584450/758000 (epoch 1542), train_loss = 0.250, time/batch = 0.029, All_Time = 17270.227
584500/758000 (epoch 1542), train_loss = 0.253, time/batch = 0.031, All_Time = 17271.690
584550/758000 (epoch 1542), train_loss = 0.245, time/batch = 0.028, All_Time = 17273.151
584600/758000 (epoch 1542), train_loss = 0.231, time/batch = 0.028, All_Time = 17274.615
584650/758000 (epoch 1542), train_loss = 0.228, time/batch = 0.029, All_Time = 17276.079
584700/758000 (epoch 1542), train_loss = 0.238, time/batch = 0.028, All_Time = 17277.552
584750/758000 (epoch 1542), train_loss = 0.268, time/batch = 0.028, All_Time = 17279.016
584800/758000 (epoch 1543), train_loss = 0.248, time/batch = 0.031, All_Time = 17280.487
584850/758000 (epoch 1543), train_loss = 0.280, time/batch = 0.029, All_Time = 17281.947
584900/758000 (epoch 1543), train_loss = 0.242, time/batch = 0.029, All_Time = 17283.405
584950/758000 (epoch 1543), train_loss = 0.258, time/batch = 0.029, All_Time = 17284.878
585000/758000 (epoch 1543), train_loss = 0.224, time/batch = 0.028, All_Time = 17286.338
model saved to NER/polyglot/model.ckpt
585050/758000 (epoch 1543), train_loss = 0.243, time/batch = 0.028, All_Time = 17287.802
585100/758000 (epoch 1543), train_loss = 0.219, time/batch = 0.028, All_Time = 17289.266
585150/758000 (epoch 1543), train_loss = 0.232, time/batch = 0.030, All_Time = 17290.727
585200/758000 (epoch 1544), train_loss = 0.237, time/batch = 0.031, All_Time = 17292.200
585250/758000 (epoch 1544), train_loss = 0.239, time/batch = 0.029, All_Time = 17293.666
585300/758000 (epoch 1544), train_loss = 0.293, time/batch = 0.029, All_Time = 17295.148
585350/758000 (epoch 1544), train_loss = 0.318, time/batch = 0.029, All_Time = 17296.618
585400/758000 (epoch 1544), train_loss = 0.196, time/batch = 0.030, All_Time = 17298.084
585450/758000 (epoch 1544), train_loss = 0.213, time/batch = 0.029, All_Time = 17299.554
585500/758000 (epoch 1544), train_loss = 0.250, time/batch = 0.029, All_Time = 17301.018
585550/758000 (epoch 1544), train_loss = 0.297, time/batch = 0.028, All_Time = 17302.484
585600/758000 (epoch 1545), train_loss = 0.226, time/batch = 0.030, All_Time = 17303.956
585650/758000 (epoch 1545), train_loss = 0.259, time/batch = 0.029, All_Time = 17305.414
585700/758000 (epoch 1545), train_loss = 0.223, time/batch = 0.029, All_Time = 17306.886
585750/758000 (epoch 1545), train_loss = 0.239, time/batch = 0.029, All_Time = 17308.360
585800/758000 (epoch 1545), train_loss = 0.212, time/batch = 0.030, All_Time = 17309.824
585850/758000 (epoch 1545), train_loss = 0.243, time/batch = 0.028, All_Time = 17311.287
585900/758000 (epoch 1545), train_loss = 0.215, time/batch = 0.029, All_Time = 17312.748
585950/758000 (epoch 1546), train_loss = 0.228, time/batch = 0.029, All_Time = 17314.210
586000/758000 (epoch 1546), train_loss = 0.252, time/batch = 0.029, All_Time = 17315.682
model saved to NER/polyglot/model.ckpt
586050/758000 (epoch 1546), train_loss = 0.260, time/batch = 0.029, All_Time = 17317.142
586100/758000 (epoch 1546), train_loss = 0.228, time/batch = 0.029, All_Time = 17318.607
586150/758000 (epoch 1546), train_loss = 0.236, time/batch = 0.030, All_Time = 17320.068
586200/758000 (epoch 1546), train_loss = 0.271, time/batch = 0.031, All_Time = 17321.528
586250/758000 (epoch 1546), train_loss = 0.238, time/batch = 0.029, All_Time = 17322.987
586300/758000 (epoch 1546), train_loss = 0.268, time/batch = 0.029, All_Time = 17324.458
586350/758000 (epoch 1547), train_loss = 0.248, time/batch = 0.030, All_Time = 17325.924
586400/758000 (epoch 1547), train_loss = 0.249, time/batch = 0.030, All_Time = 17327.403
586450/758000 (epoch 1547), train_loss = 0.240, time/batch = 0.029, All_Time = 17328.877
586500/758000 (epoch 1547), train_loss = 0.247, time/batch = 0.029, All_Time = 17330.344
586550/758000 (epoch 1547), train_loss = 0.235, time/batch = 0.028, All_Time = 17331.806
586600/758000 (epoch 1547), train_loss = 0.247, time/batch = 0.030, All_Time = 17333.271
586650/758000 (epoch 1547), train_loss = 0.251, time/batch = 0.029, All_Time = 17334.729
586700/758000 (epoch 1548), train_loss = 0.242, time/batch = 0.029, All_Time = 17336.201
586750/758000 (epoch 1548), train_loss = 0.276, time/batch = 0.028, All_Time = 17337.669
586800/758000 (epoch 1548), train_loss = 0.256, time/batch = 0.029, All_Time = 17339.137
586850/758000 (epoch 1548), train_loss = 0.258, time/batch = 0.029, All_Time = 17340.612
586900/758000 (epoch 1548), train_loss = 0.213, time/batch = 0.029, All_Time = 17342.070
586950/758000 (epoch 1548), train_loss = 0.237, time/batch = 0.029, All_Time = 17343.527
587000/758000 (epoch 1548), train_loss = 0.249, time/batch = 0.029, All_Time = 17344.993
model saved to NER/polyglot/model.ckpt
587050/758000 (epoch 1548), train_loss = 0.251, time/batch = 0.029, All_Time = 17346.459
587100/758000 (epoch 1549), train_loss = 0.232, time/batch = 0.029, All_Time = 17347.923
587150/758000 (epoch 1549), train_loss = 0.255, time/batch = 0.028, All_Time = 17349.387
587200/758000 (epoch 1549), train_loss = 0.265, time/batch = 0.030, All_Time = 17350.856
587250/758000 (epoch 1549), train_loss = 0.229, time/batch = 0.029, All_Time = 17352.332
587300/758000 (epoch 1549), train_loss = 0.263, time/batch = 0.030, All_Time = 17353.791
587350/758000 (epoch 1549), train_loss = 0.217, time/batch = 0.028, All_Time = 17355.256
587400/758000 (epoch 1549), train_loss = 0.248, time/batch = 0.030, All_Time = 17356.716
587450/758000 (epoch 1550), train_loss = 0.059, time/batch = 0.031, All_Time = 17358.186
587500/758000 (epoch 1550), train_loss = 0.250, time/batch = 0.029, All_Time = 17359.656
587550/758000 (epoch 1550), train_loss = 0.223, time/batch = 0.028, All_Time = 17361.129
587600/758000 (epoch 1550), train_loss = 0.250, time/batch = 0.028, All_Time = 17362.596
587650/758000 (epoch 1550), train_loss = 0.231, time/batch = 0.030, All_Time = 17364.056
587700/758000 (epoch 1550), train_loss = 0.250, time/batch = 0.029, All_Time = 17365.523
587750/758000 (epoch 1550), train_loss = 0.232, time/batch = 0.031, All_Time = 17366.988
587800/758000 (epoch 1550), train_loss = 0.230, time/batch = 0.029, All_Time = 17368.455
587850/758000 (epoch 1551), train_loss = 0.224, time/batch = 0.028, All_Time = 17369.914
587900/758000 (epoch 1551), train_loss = 0.233, time/batch = 0.028, All_Time = 17371.374
587950/758000 (epoch 1551), train_loss = 0.224, time/batch = 0.028, All_Time = 17372.838
588000/758000 (epoch 1551), train_loss = 0.262, time/batch = 0.030, All_Time = 17374.303
model saved to NER/polyglot/model.ckpt
588050/758000 (epoch 1551), train_loss = 0.220, time/batch = 0.029, All_Time = 17375.765
588100/758000 (epoch 1551), train_loss = 0.228, time/batch = 0.031, All_Time = 17377.220
588150/758000 (epoch 1551), train_loss = 0.280, time/batch = 0.031, All_Time = 17378.686
588200/758000 (epoch 1551), train_loss = 0.272, time/batch = 0.029, All_Time = 17380.148
588250/758000 (epoch 1552), train_loss = 0.230, time/batch = 0.029, All_Time = 17381.639
588300/758000 (epoch 1552), train_loss = 0.224, time/batch = 0.028, All_Time = 17383.093
588350/758000 (epoch 1552), train_loss = 0.201, time/batch = 0.030, All_Time = 17384.554
588400/758000 (epoch 1552), train_loss = 0.270, time/batch = 0.029, All_Time = 17386.014
588450/758000 (epoch 1552), train_loss = 0.259, time/batch = 0.028, All_Time = 17387.483
588500/758000 (epoch 1552), train_loss = 0.209, time/batch = 0.030, All_Time = 17388.936
588550/758000 (epoch 1552), train_loss = 0.218, time/batch = 0.029, All_Time = 17390.404
588600/758000 (epoch 1553), train_loss = 0.229, time/batch = 0.029, All_Time = 17391.878
588650/758000 (epoch 1553), train_loss = 0.283, time/batch = 0.029, All_Time = 17393.335
588700/758000 (epoch 1553), train_loss = 0.231, time/batch = 0.030, All_Time = 17394.800
588750/758000 (epoch 1553), train_loss = 0.307, time/batch = 0.030, All_Time = 17396.258
588800/758000 (epoch 1553), train_loss = 0.221, time/batch = 0.030, All_Time = 17397.719
588850/758000 (epoch 1553), train_loss = 0.208, time/batch = 0.028, All_Time = 17399.178
588900/758000 (epoch 1553), train_loss = 0.247, time/batch = 0.029, All_Time = 17400.637
588950/758000 (epoch 1553), train_loss = 0.252, time/batch = 0.029, All_Time = 17402.107
589000/758000 (epoch 1554), train_loss = 0.264, time/batch = 0.030, All_Time = 17403.581
model saved to NER/polyglot/model.ckpt
589050/758000 (epoch 1554), train_loss = 0.229, time/batch = 0.029, All_Time = 17405.056
589100/758000 (epoch 1554), train_loss = 0.242, time/batch = 0.029, All_Time = 17406.525
589150/758000 (epoch 1554), train_loss = 0.267, time/batch = 0.031, All_Time = 17407.993
589200/758000 (epoch 1554), train_loss = 0.249, time/batch = 0.029, All_Time = 17409.452
589250/758000 (epoch 1554), train_loss = 0.237, time/batch = 0.029, All_Time = 17410.913
589300/758000 (epoch 1554), train_loss = 0.276, time/batch = 0.030, All_Time = 17412.378
589350/758000 (epoch 1555), train_loss = 0.256, time/batch = 0.029, All_Time = 17413.839
589400/758000 (epoch 1555), train_loss = 0.222, time/batch = 0.030, All_Time = 17415.302
589450/758000 (epoch 1555), train_loss = 0.266, time/batch = 0.030, All_Time = 17416.771
589500/758000 (epoch 1555), train_loss = 0.216, time/batch = 0.029, All_Time = 17418.238
589550/758000 (epoch 1555), train_loss = 0.223, time/batch = 0.029, All_Time = 17419.708
589600/758000 (epoch 1555), train_loss = 0.261, time/batch = 0.031, All_Time = 17421.188
589650/758000 (epoch 1555), train_loss = 0.238, time/batch = 0.030, All_Time = 17422.658
589700/758000 (epoch 1555), train_loss = 0.264, time/batch = 0.028, All_Time = 17424.132
589750/758000 (epoch 1556), train_loss = 0.223, time/batch = 0.029, All_Time = 17425.613
589800/758000 (epoch 1556), train_loss = 0.231, time/batch = 0.029, All_Time = 17427.091
589850/758000 (epoch 1556), train_loss = 0.238, time/batch = 0.028, All_Time = 17428.550
589900/758000 (epoch 1556), train_loss = 0.266, time/batch = 0.029, All_Time = 17430.020
589950/758000 (epoch 1556), train_loss = 0.239, time/batch = 0.031, All_Time = 17431.499
590000/758000 (epoch 1556), train_loss = 0.226, time/batch = 0.031, All_Time = 17432.957
model saved to NER/polyglot/model.ckpt
590050/758000 (epoch 1556), train_loss = 0.276, time/batch = 0.028, All_Time = 17434.423
590100/758000 (epoch 1556), train_loss = 0.240, time/batch = 0.030, All_Time = 17435.889
590150/758000 (epoch 1557), train_loss = 0.281, time/batch = 0.030, All_Time = 17437.350
590200/758000 (epoch 1557), train_loss = 0.257, time/batch = 0.028, All_Time = 17438.816
590250/758000 (epoch 1557), train_loss = 0.240, time/batch = 0.029, All_Time = 17440.292
590300/758000 (epoch 1557), train_loss = 0.231, time/batch = 0.030, All_Time = 17441.757
590350/758000 (epoch 1557), train_loss = 0.217, time/batch = 0.029, All_Time = 17443.219
590400/758000 (epoch 1557), train_loss = 0.224, time/batch = 0.029, All_Time = 17444.674
590450/758000 (epoch 1557), train_loss = 0.215, time/batch = 0.029, All_Time = 17446.137
590500/758000 (epoch 1558), train_loss = 0.249, time/batch = 0.029, All_Time = 17447.603
590550/758000 (epoch 1558), train_loss = 0.211, time/batch = 0.031, All_Time = 17449.082
590600/758000 (epoch 1558), train_loss = 0.245, time/batch = 0.033, All_Time = 17450.552
590650/758000 (epoch 1558), train_loss = 0.217, time/batch = 0.028, All_Time = 17452.023
590700/758000 (epoch 1558), train_loss = 0.233, time/batch = 0.029, All_Time = 17453.492
590750/758000 (epoch 1558), train_loss = 0.228, time/batch = 0.031, All_Time = 17454.956
590800/758000 (epoch 1558), train_loss = 0.248, time/batch = 0.031, All_Time = 17456.429
590850/758000 (epoch 1558), train_loss = 0.229, time/batch = 0.029, All_Time = 17457.905
590900/758000 (epoch 1559), train_loss = 0.218, time/batch = 0.029, All_Time = 17459.375
590950/758000 (epoch 1559), train_loss = 0.237, time/batch = 0.029, All_Time = 17460.830
591000/758000 (epoch 1559), train_loss = 0.212, time/batch = 0.029, All_Time = 17462.298
model saved to NER/polyglot/model.ckpt
591050/758000 (epoch 1559), train_loss = 0.266, time/batch = 0.028, All_Time = 17463.761
591100/758000 (epoch 1559), train_loss = 0.255, time/batch = 0.031, All_Time = 17465.232
591150/758000 (epoch 1559), train_loss = 0.232, time/batch = 0.030, All_Time = 17466.703
591200/758000 (epoch 1559), train_loss = 0.262, time/batch = 0.030, All_Time = 17468.167
591250/758000 (epoch 1560), train_loss = 0.282, time/batch = 0.030, All_Time = 17469.633
591300/758000 (epoch 1560), train_loss = 0.292, time/batch = 0.029, All_Time = 17471.102
591350/758000 (epoch 1560), train_loss = 0.253, time/batch = 0.028, All_Time = 17472.568
591400/758000 (epoch 1560), train_loss = 0.222, time/batch = 0.029, All_Time = 17474.031
591450/758000 (epoch 1560), train_loss = 0.221, time/batch = 0.029, All_Time = 17475.505
591500/758000 (epoch 1560), train_loss = 0.260, time/batch = 0.030, All_Time = 17476.979
591550/758000 (epoch 1560), train_loss = 0.244, time/batch = 0.030, All_Time = 17478.434
591600/758000 (epoch 1560), train_loss = 0.247, time/batch = 0.030, All_Time = 17479.898
591650/758000 (epoch 1561), train_loss = 0.210, time/batch = 0.030, All_Time = 17481.357
591700/758000 (epoch 1561), train_loss = 0.265, time/batch = 0.030, All_Time = 17482.821
591750/758000 (epoch 1561), train_loss = 0.229, time/batch = 0.028, All_Time = 17484.294
591800/758000 (epoch 1561), train_loss = 0.232, time/batch = 0.029, All_Time = 17485.755
591850/758000 (epoch 1561), train_loss = 0.230, time/batch = 0.030, All_Time = 17487.224
591900/758000 (epoch 1561), train_loss = 0.253, time/batch = 0.030, All_Time = 17488.690
591950/758000 (epoch 1561), train_loss = 0.258, time/batch = 0.029, All_Time = 17490.162
592000/758000 (epoch 1562), train_loss = 0.196, time/batch = 0.030, All_Time = 17491.635
model saved to NER/polyglot/model.ckpt
592050/758000 (epoch 1562), train_loss = 0.254, time/batch = 0.029, All_Time = 17493.109
592100/758000 (epoch 1562), train_loss = 0.281, time/batch = 0.029, All_Time = 17494.574
592150/758000 (epoch 1562), train_loss = 0.235, time/batch = 0.030, All_Time = 17496.033
592200/758000 (epoch 1562), train_loss = 0.247, time/batch = 0.029, All_Time = 17497.503
592250/758000 (epoch 1562), train_loss = 0.251, time/batch = 0.030, All_Time = 17498.974
592300/758000 (epoch 1562), train_loss = 0.203, time/batch = 0.029, All_Time = 17500.434
592350/758000 (epoch 1562), train_loss = 0.268, time/batch = 0.029, All_Time = 17501.897
592400/758000 (epoch 1563), train_loss = 0.233, time/batch = 0.030, All_Time = 17503.371
592450/758000 (epoch 1563), train_loss = 0.241, time/batch = 0.031, All_Time = 17504.848
592500/758000 (epoch 1563), train_loss = 0.252, time/batch = 0.029, All_Time = 17506.322
592550/758000 (epoch 1563), train_loss = 0.258, time/batch = 0.028, All_Time = 17507.787
592600/758000 (epoch 1563), train_loss = 0.243, time/batch = 0.029, All_Time = 17509.236
592650/758000 (epoch 1563), train_loss = 0.243, time/batch = 0.030, All_Time = 17510.703
592700/758000 (epoch 1563), train_loss = 0.244, time/batch = 0.028, All_Time = 17512.173
592750/758000 (epoch 1563), train_loss = 0.286, time/batch = 0.030, All_Time = 17513.641
592800/758000 (epoch 1564), train_loss = 0.207, time/batch = 0.029, All_Time = 17515.110
592850/758000 (epoch 1564), train_loss = 0.244, time/batch = 0.029, All_Time = 17516.576
592900/758000 (epoch 1564), train_loss = 0.217, time/batch = 0.028, All_Time = 17518.028
592950/758000 (epoch 1564), train_loss = 0.233, time/batch = 0.029, All_Time = 17519.493
593000/758000 (epoch 1564), train_loss = 0.260, time/batch = 0.029, All_Time = 17520.957
model saved to NER/polyglot/model.ckpt
593050/758000 (epoch 1564), train_loss = 0.253, time/batch = 0.029, All_Time = 17522.423
593100/758000 (epoch 1564), train_loss = 0.238, time/batch = 0.030, All_Time = 17523.889
593150/758000 (epoch 1565), train_loss = 0.227, time/batch = 0.029, All_Time = 17525.348
593200/758000 (epoch 1565), train_loss = 0.250, time/batch = 0.030, All_Time = 17526.807
593250/758000 (epoch 1565), train_loss = 0.250, time/batch = 0.029, All_Time = 17528.282
593300/758000 (epoch 1565), train_loss = 0.223, time/batch = 0.029, All_Time = 17529.744
593350/758000 (epoch 1565), train_loss = 0.240, time/batch = 0.030, All_Time = 17531.207
593400/758000 (epoch 1565), train_loss = 0.246, time/batch = 0.030, All_Time = 17532.673
593450/758000 (epoch 1565), train_loss = 0.246, time/batch = 0.029, All_Time = 17534.139
593500/758000 (epoch 1565), train_loss = 0.257, time/batch = 0.028, All_Time = 17535.610
593550/758000 (epoch 1566), train_loss = 0.266, time/batch = 0.029, All_Time = 17537.081
593600/758000 (epoch 1566), train_loss = 0.224, time/batch = 0.031, All_Time = 17538.554
593650/758000 (epoch 1566), train_loss = 0.248, time/batch = 0.029, All_Time = 17540.019
593700/758000 (epoch 1566), train_loss = 0.227, time/batch = 0.029, All_Time = 17541.474
593750/758000 (epoch 1566), train_loss = 0.279, time/batch = 0.030, All_Time = 17542.929
593800/758000 (epoch 1566), train_loss = 0.255, time/batch = 0.030, All_Time = 17544.396
593850/758000 (epoch 1566), train_loss = 0.253, time/batch = 0.029, All_Time = 17545.861
593900/758000 (epoch 1567), train_loss = 0.244, time/batch = 0.029, All_Time = 17547.327
593950/758000 (epoch 1567), train_loss = 0.247, time/batch = 0.029, All_Time = 17548.795
594000/758000 (epoch 1567), train_loss = 0.270, time/batch = 0.029, All_Time = 17550.263
model saved to NER/polyglot/model.ckpt
594050/758000 (epoch 1567), train_loss = 0.246, time/batch = 0.030, All_Time = 17551.737
594100/758000 (epoch 1567), train_loss = 0.237, time/batch = 0.029, All_Time = 17553.202
594150/758000 (epoch 1567), train_loss = 0.224, time/batch = 0.029, All_Time = 17554.662
594200/758000 (epoch 1567), train_loss = 0.229, time/batch = 0.030, All_Time = 17556.130
594250/758000 (epoch 1567), train_loss = 0.246, time/batch = 0.030, All_Time = 17557.598
594300/758000 (epoch 1568), train_loss = 0.249, time/batch = 0.029, All_Time = 17559.076
594350/758000 (epoch 1568), train_loss = 0.264, time/batch = 0.030, All_Time = 17560.539
594400/758000 (epoch 1568), train_loss = 0.240, time/batch = 0.029, All_Time = 17562.002
594450/758000 (epoch 1568), train_loss = 0.250, time/batch = 0.029, All_Time = 17563.469
594500/758000 (epoch 1568), train_loss = 0.227, time/batch = 0.030, All_Time = 17564.939
594550/758000 (epoch 1568), train_loss = 0.217, time/batch = 0.029, All_Time = 17566.391
594600/758000 (epoch 1568), train_loss = 0.277, time/batch = 0.030, All_Time = 17567.850
594650/758000 (epoch 1568), train_loss = 0.259, time/batch = 0.030, All_Time = 17569.313
594700/758000 (epoch 1569), train_loss = 0.269, time/batch = 0.029, All_Time = 17570.781
594750/758000 (epoch 1569), train_loss = 0.296, time/batch = 0.028, All_Time = 17572.251
594800/758000 (epoch 1569), train_loss = 0.228, time/batch = 0.029, All_Time = 17573.709
594850/758000 (epoch 1569), train_loss = 0.220, time/batch = 0.029, All_Time = 17575.180
594900/758000 (epoch 1569), train_loss = 0.257, time/batch = 0.028, All_Time = 17576.633
594950/758000 (epoch 1569), train_loss = 0.255, time/batch = 0.029, All_Time = 17578.102
595000/758000 (epoch 1569), train_loss = 0.237, time/batch = 0.028, All_Time = 17579.565
model saved to NER/polyglot/model.ckpt
595050/758000 (epoch 1570), train_loss = 0.225, time/batch = 0.031, All_Time = 17581.036
595100/758000 (epoch 1570), train_loss = 0.234, time/batch = 0.028, All_Time = 17582.497
595150/758000 (epoch 1570), train_loss = 0.243, time/batch = 0.031, All_Time = 17583.958
595200/758000 (epoch 1570), train_loss = 0.234, time/batch = 0.030, All_Time = 17585.425
595250/758000 (epoch 1570), train_loss = 0.223, time/batch = 0.029, All_Time = 17586.892
595300/758000 (epoch 1570), train_loss = 0.239, time/batch = 0.030, All_Time = 17588.362
595350/758000 (epoch 1570), train_loss = 0.264, time/batch = 0.028, All_Time = 17589.825
595400/758000 (epoch 1570), train_loss = 0.244, time/batch = 0.029, All_Time = 17591.284
595450/758000 (epoch 1571), train_loss = 0.257, time/batch = 0.030, All_Time = 17592.746
595500/758000 (epoch 1571), train_loss = 0.287, time/batch = 0.028, All_Time = 17594.211
595550/758000 (epoch 1571), train_loss = 0.255, time/batch = 0.029, All_Time = 17595.674
595600/758000 (epoch 1571), train_loss = 0.248, time/batch = 0.029, All_Time = 17597.139
595650/758000 (epoch 1571), train_loss = 0.212, time/batch = 0.028, All_Time = 17598.606
595700/758000 (epoch 1571), train_loss = 0.229, time/batch = 0.030, All_Time = 17600.079
595750/758000 (epoch 1571), train_loss = 0.272, time/batch = 0.028, All_Time = 17601.541
595800/758000 (epoch 1572), train_loss = 0.249, time/batch = 0.030, All_Time = 17603.018
595850/758000 (epoch 1572), train_loss = 0.227, time/batch = 0.028, All_Time = 17604.479
595900/758000 (epoch 1572), train_loss = 0.267, time/batch = 0.030, All_Time = 17605.946
595950/758000 (epoch 1572), train_loss = 0.239, time/batch = 0.030, All_Time = 17607.417
596000/758000 (epoch 1572), train_loss = 0.247, time/batch = 0.030, All_Time = 17608.878
model saved to NER/polyglot/model.ckpt
596050/758000 (epoch 1572), train_loss = 0.241, time/batch = 0.029, All_Time = 17610.345
596100/758000 (epoch 1572), train_loss = 0.274, time/batch = 0.029, All_Time = 17611.811
596150/758000 (epoch 1572), train_loss = 0.279, time/batch = 0.028, All_Time = 17613.285
596200/758000 (epoch 1573), train_loss = 0.238, time/batch = 0.028, All_Time = 17614.750
596250/758000 (epoch 1573), train_loss = 0.248, time/batch = 0.028, All_Time = 17616.218
596300/758000 (epoch 1573), train_loss = 0.299, time/batch = 0.031, All_Time = 17617.682
596350/758000 (epoch 1573), train_loss = 0.230, time/batch = 0.030, All_Time = 17619.157
596400/758000 (epoch 1573), train_loss = 0.216, time/batch = 0.029, All_Time = 17620.617
596450/758000 (epoch 1573), train_loss = 0.244, time/batch = 0.031, All_Time = 17622.086
596500/758000 (epoch 1573), train_loss = 0.274, time/batch = 0.029, All_Time = 17623.549
596550/758000 (epoch 1574), train_loss = 0.221, time/batch = 0.030, All_Time = 17625.020
596600/758000 (epoch 1574), train_loss = 0.257, time/batch = 0.030, All_Time = 17626.491
596650/758000 (epoch 1574), train_loss = 0.241, time/batch = 0.029, All_Time = 17627.961
596700/758000 (epoch 1574), train_loss = 0.240, time/batch = 0.029, All_Time = 17629.429
596750/758000 (epoch 1574), train_loss = 0.256, time/batch = 0.028, All_Time = 17630.893
596800/758000 (epoch 1574), train_loss = 0.219, time/batch = 0.029, All_Time = 17632.358
596850/758000 (epoch 1574), train_loss = 0.224, time/batch = 0.030, All_Time = 17633.822
596900/758000 (epoch 1574), train_loss = 0.257, time/batch = 0.027, All_Time = 17635.280
596950/758000 (epoch 1575), train_loss = 0.255, time/batch = 0.028, All_Time = 17636.743
597000/758000 (epoch 1575), train_loss = 0.267, time/batch = 0.029, All_Time = 17638.205
model saved to NER/polyglot/model.ckpt
597050/758000 (epoch 1575), train_loss = 0.269, time/batch = 0.030, All_Time = 17639.684
597100/758000 (epoch 1575), train_loss = 0.228, time/batch = 0.029, All_Time = 17641.157
597150/758000 (epoch 1575), train_loss = 0.234, time/batch = 0.029, All_Time = 17642.623
597200/758000 (epoch 1575), train_loss = 0.245, time/batch = 0.029, All_Time = 17644.073
597250/758000 (epoch 1575), train_loss = 0.279, time/batch = 0.029, All_Time = 17645.538
597300/758000 (epoch 1575), train_loss = 0.240, time/batch = 0.029, All_Time = 17647.008
597350/758000 (epoch 1576), train_loss = 0.236, time/batch = 0.030, All_Time = 17648.476
597400/758000 (epoch 1576), train_loss = 0.234, time/batch = 0.028, All_Time = 17649.939
597450/758000 (epoch 1576), train_loss = 0.233, time/batch = 0.029, All_Time = 17651.405
597500/758000 (epoch 1576), train_loss = 0.276, time/batch = 0.030, All_Time = 17652.880
597550/758000 (epoch 1576), train_loss = 0.206, time/batch = 0.031, All_Time = 17654.345
597600/758000 (epoch 1576), train_loss = 0.259, time/batch = 0.029, All_Time = 17655.813
597650/758000 (epoch 1576), train_loss = 0.234, time/batch = 0.030, All_Time = 17657.278
597700/758000 (epoch 1577), train_loss = 0.245, time/batch = 0.029, All_Time = 17658.747
597750/758000 (epoch 1577), train_loss = 0.223, time/batch = 0.029, All_Time = 17660.214
597800/758000 (epoch 1577), train_loss = 0.240, time/batch = 0.030, All_Time = 17661.682
597850/758000 (epoch 1577), train_loss = 0.256, time/batch = 0.030, All_Time = 17663.146
597900/758000 (epoch 1577), train_loss = 0.214, time/batch = 0.029, All_Time = 17664.608
597950/758000 (epoch 1577), train_loss = 0.272, time/batch = 0.028, All_Time = 17666.071
598000/758000 (epoch 1577), train_loss = 0.213, time/batch = 0.030, All_Time = 17667.544
model saved to NER/polyglot/model.ckpt
598050/758000 (epoch 1577), train_loss = 0.251, time/batch = 0.027, All_Time = 17669.007
598100/758000 (epoch 1578), train_loss = 0.247, time/batch = 0.029, All_Time = 17670.482
598150/758000 (epoch 1578), train_loss = 0.229, time/batch = 0.029, All_Time = 17671.943
598200/758000 (epoch 1578), train_loss = 0.217, time/batch = 0.029, All_Time = 17673.408
598250/758000 (epoch 1578), train_loss = 0.220, time/batch = 0.029, All_Time = 17674.881
598300/758000 (epoch 1578), train_loss = 0.250, time/batch = 0.028, All_Time = 17676.341
598350/758000 (epoch 1578), train_loss = 0.207, time/batch = 0.028, All_Time = 17677.804
598400/758000 (epoch 1578), train_loss = 0.268, time/batch = 0.031, All_Time = 17679.357
598450/758000 (epoch 1579), train_loss = 0.256, time/batch = 0.028, All_Time = 17680.849
598500/758000 (epoch 1579), train_loss = 0.264, time/batch = 0.030, All_Time = 17682.320
598550/758000 (epoch 1579), train_loss = 0.284, time/batch = 0.030, All_Time = 17683.780
598600/758000 (epoch 1579), train_loss = 0.239, time/batch = 0.030, All_Time = 17685.252
598650/758000 (epoch 1579), train_loss = 0.267, time/batch = 0.030, All_Time = 17686.713
598700/758000 (epoch 1579), train_loss = 0.256, time/batch = 0.030, All_Time = 17688.186
598750/758000 (epoch 1579), train_loss = 0.236, time/batch = 0.029, All_Time = 17689.656
598800/758000 (epoch 1579), train_loss = 0.268, time/batch = 0.029, All_Time = 17691.118
598850/758000 (epoch 1580), train_loss = 0.226, time/batch = 0.029, All_Time = 17692.574
598900/758000 (epoch 1580), train_loss = 0.222, time/batch = 0.029, All_Time = 17694.041
598950/758000 (epoch 1580), train_loss = 0.261, time/batch = 0.029, All_Time = 17695.514
599000/758000 (epoch 1580), train_loss = 0.254, time/batch = 0.029, All_Time = 17696.983
model saved to NER/polyglot/model.ckpt
599050/758000 (epoch 1580), train_loss = 0.223, time/batch = 0.030, All_Time = 17698.445
599100/758000 (epoch 1580), train_loss = 0.242, time/batch = 0.030, All_Time = 17699.913
599150/758000 (epoch 1580), train_loss = 0.251, time/batch = 0.030, All_Time = 17701.375
599200/758000 (epoch 1581), train_loss = 0.192, time/batch = 0.031, All_Time = 17702.839
599250/758000 (epoch 1581), train_loss = 0.273, time/batch = 0.029, All_Time = 17704.302
599300/758000 (epoch 1581), train_loss = 0.217, time/batch = 0.028, All_Time = 17705.773
599350/758000 (epoch 1581), train_loss = 0.240, time/batch = 0.032, All_Time = 17707.238
599400/758000 (epoch 1581), train_loss = 0.221, time/batch = 0.029, All_Time = 17708.697
599450/758000 (epoch 1581), train_loss = 0.221, time/batch = 0.029, All_Time = 17710.156
599500/758000 (epoch 1581), train_loss = 0.252, time/batch = 0.029, All_Time = 17711.627
599550/758000 (epoch 1581), train_loss = 0.272, time/batch = 0.030, All_Time = 17713.092
599600/758000 (epoch 1582), train_loss = 0.222, time/batch = 0.030, All_Time = 17714.566
599650/758000 (epoch 1582), train_loss = 0.279, time/batch = 0.029, All_Time = 17716.033
599700/758000 (epoch 1582), train_loss = 0.242, time/batch = 0.029, All_Time = 17717.493
599750/758000 (epoch 1582), train_loss = 0.274, time/batch = 0.030, All_Time = 17718.958
599800/758000 (epoch 1582), train_loss = 0.262, time/batch = 0.029, All_Time = 17720.425
599850/758000 (epoch 1582), train_loss = 0.197, time/batch = 0.030, All_Time = 17721.904
599900/758000 (epoch 1582), train_loss = 0.233, time/batch = 0.031, All_Time = 17723.373
599950/758000 (epoch 1582), train_loss = 0.281, time/batch = 0.030, All_Time = 17724.847
600000/758000 (epoch 1583), train_loss = 0.246, time/batch = 0.029, All_Time = 17726.304
model saved to NER/polyglot/model.ckpt
600050/758000 (epoch 1583), train_loss = 0.212, time/batch = 0.029, All_Time = 17727.777
600100/758000 (epoch 1583), train_loss = 0.255, time/batch = 0.031, All_Time = 17729.250
600150/758000 (epoch 1583), train_loss = 0.271, time/batch = 0.030, All_Time = 17730.704
600200/758000 (epoch 1583), train_loss = 0.203, time/batch = 0.029, All_Time = 17732.165
600250/758000 (epoch 1583), train_loss = 0.226, time/batch = 0.030, All_Time = 17733.624
600300/758000 (epoch 1583), train_loss = 0.254, time/batch = 0.029, All_Time = 17735.086
600350/758000 (epoch 1584), train_loss = 0.219, time/batch = 0.029, All_Time = 17736.550
600400/758000 (epoch 1584), train_loss = 0.265, time/batch = 0.030, All_Time = 17738.017
600450/758000 (epoch 1584), train_loss = 0.227, time/batch = 0.028, All_Time = 17739.474
600500/758000 (epoch 1584), train_loss = 0.213, time/batch = 0.028, All_Time = 17740.932
600550/758000 (epoch 1584), train_loss = 0.224, time/batch = 0.030, All_Time = 17742.403
600600/758000 (epoch 1584), train_loss = 0.213, time/batch = 0.030, All_Time = 17743.869
600650/758000 (epoch 1584), train_loss = 0.230, time/batch = 0.029, All_Time = 17745.349
600700/758000 (epoch 1584), train_loss = 0.223, time/batch = 0.032, All_Time = 17746.819
600750/758000 (epoch 1585), train_loss = 0.275, time/batch = 0.030, All_Time = 17748.294
600800/758000 (epoch 1585), train_loss = 0.229, time/batch = 0.029, All_Time = 17749.756
600850/758000 (epoch 1585), train_loss = 0.270, time/batch = 0.030, All_Time = 17751.229
600900/758000 (epoch 1585), train_loss = 0.273, time/batch = 0.029, All_Time = 17752.690
600950/758000 (epoch 1585), train_loss = 0.233, time/batch = 0.029, All_Time = 17754.162
601000/758000 (epoch 1585), train_loss = 0.268, time/batch = 0.030, All_Time = 17755.624
model saved to NER/polyglot/model.ckpt
601050/758000 (epoch 1585), train_loss = 0.280, time/batch = 0.028, All_Time = 17757.094
601100/758000 (epoch 1586), train_loss = 0.239, time/batch = 0.029, All_Time = 17758.564
601150/758000 (epoch 1586), train_loss = 0.218, time/batch = 0.029, All_Time = 17760.026
601200/758000 (epoch 1586), train_loss = 0.243, time/batch = 0.030, All_Time = 17761.489
601250/758000 (epoch 1586), train_loss = 0.244, time/batch = 0.030, All_Time = 17762.956
601300/758000 (epoch 1586), train_loss = 0.243, time/batch = 0.029, All_Time = 17764.429
601350/758000 (epoch 1586), train_loss = 0.244, time/batch = 0.030, All_Time = 17765.896
601400/758000 (epoch 1586), train_loss = 0.213, time/batch = 0.029, All_Time = 17767.357
601450/758000 (epoch 1586), train_loss = 0.289, time/batch = 0.030, All_Time = 17768.814
601500/758000 (epoch 1587), train_loss = 0.237, time/batch = 0.027, All_Time = 17770.279
601550/758000 (epoch 1587), train_loss = 0.246, time/batch = 0.029, All_Time = 17771.740
601600/758000 (epoch 1587), train_loss = 0.288, time/batch = 0.030, All_Time = 17773.215
601650/758000 (epoch 1587), train_loss = 0.257, time/batch = 0.030, All_Time = 17774.680
601700/758000 (epoch 1587), train_loss = 0.218, time/batch = 0.031, All_Time = 17776.149
601750/758000 (epoch 1587), train_loss = 0.238, time/batch = 0.028, All_Time = 17777.605
601800/758000 (epoch 1587), train_loss = 0.251, time/batch = 0.029, All_Time = 17779.065
601850/758000 (epoch 1587), train_loss = 0.251, time/batch = 0.030, All_Time = 17780.530
601900/758000 (epoch 1588), train_loss = 0.252, time/batch = 0.030, All_Time = 17781.996
601950/758000 (epoch 1588), train_loss = 0.280, time/batch = 0.030, All_Time = 17783.471
602000/758000 (epoch 1588), train_loss = 0.242, time/batch = 0.030, All_Time = 17784.941
model saved to NER/polyglot/model.ckpt
602050/758000 (epoch 1588), train_loss = 0.250, time/batch = 0.028, All_Time = 17786.400
602100/758000 (epoch 1588), train_loss = 0.239, time/batch = 0.029, All_Time = 17787.865
602150/758000 (epoch 1588), train_loss = 0.239, time/batch = 0.028, All_Time = 17789.331
602200/758000 (epoch 1588), train_loss = 0.250, time/batch = 0.029, All_Time = 17790.794
602250/758000 (epoch 1589), train_loss = 0.221, time/batch = 0.029, All_Time = 17792.267
602300/758000 (epoch 1589), train_loss = 0.219, time/batch = 0.031, All_Time = 17793.730
602350/758000 (epoch 1589), train_loss = 0.246, time/batch = 0.029, All_Time = 17795.194
602400/758000 (epoch 1589), train_loss = 0.262, time/batch = 0.029, All_Time = 17796.667
602450/758000 (epoch 1589), train_loss = 0.260, time/batch = 0.028, All_Time = 17798.133
602500/758000 (epoch 1589), train_loss = 0.241, time/batch = 0.029, All_Time = 17799.602
602550/758000 (epoch 1589), train_loss = 0.210, time/batch = 0.028, All_Time = 17801.070
602600/758000 (epoch 1589), train_loss = 0.239, time/batch = 0.029, All_Time = 17802.532
602650/758000 (epoch 1590), train_loss = 0.230, time/batch = 0.030, All_Time = 17804.000
602700/758000 (epoch 1590), train_loss = 0.226, time/batch = 0.028, All_Time = 17805.460
602750/758000 (epoch 1590), train_loss = 0.264, time/batch = 0.028, All_Time = 17806.925
602800/758000 (epoch 1590), train_loss = 0.240, time/batch = 0.029, All_Time = 17808.386
602850/758000 (epoch 1590), train_loss = 0.253, time/batch = 0.030, All_Time = 17809.840
602900/758000 (epoch 1590), train_loss = 0.251, time/batch = 0.028, All_Time = 17811.309
602950/758000 (epoch 1590), train_loss = 0.248, time/batch = 0.028, All_Time = 17812.776
603000/758000 (epoch 1591), train_loss = 0.216, time/batch = 0.030, All_Time = 17814.240
model saved to NER/polyglot/model.ckpt
603050/758000 (epoch 1591), train_loss = 0.233, time/batch = 0.030, All_Time = 17815.705
603100/758000 (epoch 1591), train_loss = 0.250, time/batch = 0.030, All_Time = 17817.168
603150/758000 (epoch 1591), train_loss = 0.241, time/batch = 0.029, All_Time = 17818.630
603200/758000 (epoch 1591), train_loss = 0.243, time/batch = 0.030, All_Time = 17820.100
603250/758000 (epoch 1591), train_loss = 0.242, time/batch = 0.031, All_Time = 17821.580
603300/758000 (epoch 1591), train_loss = 0.230, time/batch = 0.029, All_Time = 17823.042
603350/758000 (epoch 1591), train_loss = 0.259, time/batch = 0.028, All_Time = 17824.509
603400/758000 (epoch 1592), train_loss = 0.250, time/batch = 0.029, All_Time = 17825.975
603450/758000 (epoch 1592), train_loss = 0.253, time/batch = 0.029, All_Time = 17827.438
603500/758000 (epoch 1592), train_loss = 0.245, time/batch = 0.030, All_Time = 17828.913
603550/758000 (epoch 1592), train_loss = 0.231, time/batch = 0.029, All_Time = 17830.378
603600/758000 (epoch 1592), train_loss = 0.228, time/batch = 0.029, All_Time = 17831.841
603650/758000 (epoch 1592), train_loss = 0.238, time/batch = 0.030, All_Time = 17833.298
603700/758000 (epoch 1592), train_loss = 0.268, time/batch = 0.030, All_Time = 17834.763
603750/758000 (epoch 1593), train_loss = 0.248, time/batch = 0.030, All_Time = 17836.221
603800/758000 (epoch 1593), train_loss = 0.280, time/batch = 0.028, All_Time = 17837.683
603850/758000 (epoch 1593), train_loss = 0.242, time/batch = 0.030, All_Time = 17839.153
603900/758000 (epoch 1593), train_loss = 0.258, time/batch = 0.029, All_Time = 17840.620
603950/758000 (epoch 1593), train_loss = 0.224, time/batch = 0.030, All_Time = 17842.084
604000/758000 (epoch 1593), train_loss = 0.243, time/batch = 0.029, All_Time = 17843.555
model saved to NER/polyglot/model.ckpt
604050/758000 (epoch 1593), train_loss = 0.219, time/batch = 0.029, All_Time = 17845.032
604100/758000 (epoch 1593), train_loss = 0.232, time/batch = 0.030, All_Time = 17846.500
604150/758000 (epoch 1594), train_loss = 0.237, time/batch = 0.030, All_Time = 17847.980
604200/758000 (epoch 1594), train_loss = 0.239, time/batch = 0.028, All_Time = 17849.451
604250/758000 (epoch 1594), train_loss = 0.293, time/batch = 0.030, All_Time = 17850.911
604300/758000 (epoch 1594), train_loss = 0.318, time/batch = 0.030, All_Time = 17852.381
604350/758000 (epoch 1594), train_loss = 0.196, time/batch = 0.029, All_Time = 17853.846
604400/758000 (epoch 1594), train_loss = 0.213, time/batch = 0.030, All_Time = 17855.318
604450/758000 (epoch 1594), train_loss = 0.250, time/batch = 0.030, All_Time = 17856.796
604500/758000 (epoch 1594), train_loss = 0.297, time/batch = 0.029, All_Time = 17858.263
604550/758000 (epoch 1595), train_loss = 0.226, time/batch = 0.030, All_Time = 17859.732
604600/758000 (epoch 1595), train_loss = 0.259, time/batch = 0.030, All_Time = 17861.207
604650/758000 (epoch 1595), train_loss = 0.223, time/batch = 0.030, All_Time = 17862.667
604700/758000 (epoch 1595), train_loss = 0.239, time/batch = 0.030, All_Time = 17864.132
604750/758000 (epoch 1595), train_loss = 0.212, time/batch = 0.029, All_Time = 17865.599
604800/758000 (epoch 1595), train_loss = 0.243, time/batch = 0.029, All_Time = 17867.064
604850/758000 (epoch 1595), train_loss = 0.215, time/batch = 0.030, All_Time = 17868.534
604900/758000 (epoch 1596), train_loss = 0.228, time/batch = 0.031, All_Time = 17870.016
604950/758000 (epoch 1596), train_loss = 0.252, time/batch = 0.030, All_Time = 17871.499
605000/758000 (epoch 1596), train_loss = 0.260, time/batch = 0.029, All_Time = 17872.967
model saved to NER/polyglot/model.ckpt
605050/758000 (epoch 1596), train_loss = 0.228, time/batch = 0.030, All_Time = 17874.445
605100/758000 (epoch 1596), train_loss = 0.236, time/batch = 0.029, All_Time = 17875.928
605150/758000 (epoch 1596), train_loss = 0.271, time/batch = 0.029, All_Time = 17877.385
605200/758000 (epoch 1596), train_loss = 0.238, time/batch = 0.030, All_Time = 17878.856
605250/758000 (epoch 1596), train_loss = 0.268, time/batch = 0.028, All_Time = 17880.323
605300/758000 (epoch 1597), train_loss = 0.248, time/batch = 0.028, All_Time = 17881.786
605350/758000 (epoch 1597), train_loss = 0.249, time/batch = 0.030, All_Time = 17883.245
605400/758000 (epoch 1597), train_loss = 0.240, time/batch = 0.028, All_Time = 17884.714
605450/758000 (epoch 1597), train_loss = 0.247, time/batch = 0.028, All_Time = 17886.179
605500/758000 (epoch 1597), train_loss = 0.235, time/batch = 0.029, All_Time = 17887.648
605550/758000 (epoch 1597), train_loss = 0.247, time/batch = 0.029, All_Time = 17889.110
605600/758000 (epoch 1597), train_loss = 0.251, time/batch = 0.029, All_Time = 17890.578
605650/758000 (epoch 1598), train_loss = 0.242, time/batch = 0.029, All_Time = 17892.052
605700/758000 (epoch 1598), train_loss = 0.276, time/batch = 0.029, All_Time = 17893.517
605750/758000 (epoch 1598), train_loss = 0.256, time/batch = 0.029, All_Time = 17894.989
605800/758000 (epoch 1598), train_loss = 0.258, time/batch = 0.029, All_Time = 17896.467
605850/758000 (epoch 1598), train_loss = 0.213, time/batch = 0.031, All_Time = 17897.937
605900/758000 (epoch 1598), train_loss = 0.237, time/batch = 0.030, All_Time = 17899.393
605950/758000 (epoch 1598), train_loss = 0.249, time/batch = 0.029, All_Time = 17900.863
606000/758000 (epoch 1598), train_loss = 0.251, time/batch = 0.028, All_Time = 17902.332
model saved to NER/polyglot/model.ckpt
606050/758000 (epoch 1599), train_loss = 0.232, time/batch = 0.030, All_Time = 17903.798
606100/758000 (epoch 1599), train_loss = 0.255, time/batch = 0.028, All_Time = 17905.269
606150/758000 (epoch 1599), train_loss = 0.265, time/batch = 0.028, All_Time = 17906.738
606200/758000 (epoch 1599), train_loss = 0.229, time/batch = 0.029, All_Time = 17908.196
606250/758000 (epoch 1599), train_loss = 0.263, time/batch = 0.029, All_Time = 17909.667
606300/758000 (epoch 1599), train_loss = 0.217, time/batch = 0.030, All_Time = 17911.134
606350/758000 (epoch 1599), train_loss = 0.248, time/batch = 0.028, All_Time = 17912.606
606400/758000 (epoch 1600), train_loss = 0.059, time/batch = 0.031, All_Time = 17914.064
606450/758000 (epoch 1600), train_loss = 0.250, time/batch = 0.029, All_Time = 17915.536
606500/758000 (epoch 1600), train_loss = 0.223, time/batch = 0.029, All_Time = 17917.000
606550/758000 (epoch 1600), train_loss = 0.250, time/batch = 0.029, All_Time = 17918.463
606600/758000 (epoch 1600), train_loss = 0.231, time/batch = 0.031, All_Time = 17919.930
606650/758000 (epoch 1600), train_loss = 0.250, time/batch = 0.030, All_Time = 17921.383
606700/758000 (epoch 1600), train_loss = 0.232, time/batch = 0.030, All_Time = 17922.856
606750/758000 (epoch 1600), train_loss = 0.230, time/batch = 0.028, All_Time = 17924.323
606800/758000 (epoch 1601), train_loss = 0.224, time/batch = 0.029, All_Time = 17925.788
606850/758000 (epoch 1601), train_loss = 0.233, time/batch = 0.030, All_Time = 17927.246
606900/758000 (epoch 1601), train_loss = 0.224, time/batch = 0.029, All_Time = 17928.719
606950/758000 (epoch 1601), train_loss = 0.262, time/batch = 0.029, All_Time = 17930.192
607000/758000 (epoch 1601), train_loss = 0.220, time/batch = 0.028, All_Time = 17931.665
model saved to NER/polyglot/model.ckpt
607050/758000 (epoch 1601), train_loss = 0.228, time/batch = 0.029, All_Time = 17933.144
607100/758000 (epoch 1601), train_loss = 0.280, time/batch = 0.028, All_Time = 17934.609
607150/758000 (epoch 1601), train_loss = 0.272, time/batch = 0.029, All_Time = 17936.064
607200/758000 (epoch 1602), train_loss = 0.230, time/batch = 0.028, All_Time = 17937.534
607250/758000 (epoch 1602), train_loss = 0.224, time/batch = 0.029, All_Time = 17938.997
607300/758000 (epoch 1602), train_loss = 0.201, time/batch = 0.029, All_Time = 17940.451
607350/758000 (epoch 1602), train_loss = 0.270, time/batch = 0.028, All_Time = 17941.903
607400/758000 (epoch 1602), train_loss = 0.259, time/batch = 0.028, All_Time = 17943.371
607450/758000 (epoch 1602), train_loss = 0.209, time/batch = 0.029, All_Time = 17944.830
607500/758000 (epoch 1602), train_loss = 0.218, time/batch = 0.029, All_Time = 17946.291
607550/758000 (epoch 1603), train_loss = 0.229, time/batch = 0.029, All_Time = 17947.756
607600/758000 (epoch 1603), train_loss = 0.283, time/batch = 0.030, All_Time = 17949.227
607650/758000 (epoch 1603), train_loss = 0.231, time/batch = 0.030, All_Time = 17950.691
607700/758000 (epoch 1603), train_loss = 0.307, time/batch = 0.030, All_Time = 17952.155
607750/758000 (epoch 1603), train_loss = 0.221, time/batch = 0.029, All_Time = 17953.627
607800/758000 (epoch 1603), train_loss = 0.208, time/batch = 0.031, All_Time = 17955.092
607850/758000 (epoch 1603), train_loss = 0.247, time/batch = 0.029, All_Time = 17956.551
607900/758000 (epoch 1603), train_loss = 0.252, time/batch = 0.029, All_Time = 17958.016
607950/758000 (epoch 1604), train_loss = 0.264, time/batch = 0.029, All_Time = 17959.481
608000/758000 (epoch 1604), train_loss = 0.229, time/batch = 0.029, All_Time = 17960.950
model saved to NER/polyglot/model.ckpt
608050/758000 (epoch 1604), train_loss = 0.242, time/batch = 0.028, All_Time = 17962.419
608100/758000 (epoch 1604), train_loss = 0.267, time/batch = 0.028, All_Time = 17963.881
608150/758000 (epoch 1604), train_loss = 0.249, time/batch = 0.028, All_Time = 17965.351
608200/758000 (epoch 1604), train_loss = 0.237, time/batch = 0.028, All_Time = 17966.825
608250/758000 (epoch 1604), train_loss = 0.276, time/batch = 0.029, All_Time = 17968.284
608300/758000 (epoch 1605), train_loss = 0.256, time/batch = 0.029, All_Time = 17969.749
608350/758000 (epoch 1605), train_loss = 0.222, time/batch = 0.031, All_Time = 17971.210
608400/758000 (epoch 1605), train_loss = 0.266, time/batch = 0.028, All_Time = 17972.666
608450/758000 (epoch 1605), train_loss = 0.216, time/batch = 0.030, All_Time = 17974.232
608500/758000 (epoch 1605), train_loss = 0.223, time/batch = 0.030, All_Time = 17975.720
608550/758000 (epoch 1605), train_loss = 0.261, time/batch = 0.029, All_Time = 17977.199
608600/758000 (epoch 1605), train_loss = 0.238, time/batch = 0.030, All_Time = 17978.669
608650/758000 (epoch 1605), train_loss = 0.264, time/batch = 0.032, All_Time = 17980.271
608700/758000 (epoch 1606), train_loss = 0.223, time/batch = 0.028, All_Time = 17981.793
608750/758000 (epoch 1606), train_loss = 0.231, time/batch = 0.030, All_Time = 17983.255
608800/758000 (epoch 1606), train_loss = 0.238, time/batch = 0.031, All_Time = 17984.737
608850/758000 (epoch 1606), train_loss = 0.266, time/batch = 0.029, All_Time = 17986.195
608900/758000 (epoch 1606), train_loss = 0.239, time/batch = 0.029, All_Time = 17987.667
608950/758000 (epoch 1606), train_loss = 0.226, time/batch = 0.029, All_Time = 17989.131
609000/758000 (epoch 1606), train_loss = 0.276, time/batch = 0.030, All_Time = 17990.600
model saved to NER/polyglot/model.ckpt
609050/758000 (epoch 1606), train_loss = 0.240, time/batch = 0.029, All_Time = 17992.069
609100/758000 (epoch 1607), train_loss = 0.281, time/batch = 0.029, All_Time = 17993.530
609150/758000 (epoch 1607), train_loss = 0.257, time/batch = 0.029, All_Time = 17994.986
609200/758000 (epoch 1607), train_loss = 0.240, time/batch = 0.029, All_Time = 17996.453
609250/758000 (epoch 1607), train_loss = 0.231, time/batch = 0.029, All_Time = 17997.911
609300/758000 (epoch 1607), train_loss = 0.217, time/batch = 0.029, All_Time = 17999.374
609350/758000 (epoch 1607), train_loss = 0.224, time/batch = 0.028, All_Time = 18000.839
609400/758000 (epoch 1607), train_loss = 0.215, time/batch = 0.031, All_Time = 18002.317
609450/758000 (epoch 1608), train_loss = 0.249, time/batch = 0.030, All_Time = 18003.783
609500/758000 (epoch 1608), train_loss = 0.211, time/batch = 0.030, All_Time = 18005.245
609550/758000 (epoch 1608), train_loss = 0.245, time/batch = 0.029, All_Time = 18006.711
609600/758000 (epoch 1608), train_loss = 0.217, time/batch = 0.028, All_Time = 18008.170
609650/758000 (epoch 1608), train_loss = 0.233, time/batch = 0.029, All_Time = 18009.645
609700/758000 (epoch 1608), train_loss = 0.228, time/batch = 0.031, All_Time = 18011.113
609750/758000 (epoch 1608), train_loss = 0.248, time/batch = 0.029, All_Time = 18012.575
609800/758000 (epoch 1608), train_loss = 0.229, time/batch = 0.030, All_Time = 18014.043
609850/758000 (epoch 1609), train_loss = 0.218, time/batch = 0.029, All_Time = 18015.509
609900/758000 (epoch 1609), train_loss = 0.237, time/batch = 0.028, All_Time = 18016.976
609950/758000 (epoch 1609), train_loss = 0.212, time/batch = 0.028, All_Time = 18018.446
610000/758000 (epoch 1609), train_loss = 0.266, time/batch = 0.029, All_Time = 18019.911
model saved to NER/polyglot/model.ckpt
610050/758000 (epoch 1609), train_loss = 0.255, time/batch = 0.030, All_Time = 18021.376
610100/758000 (epoch 1609), train_loss = 0.232, time/batch = 0.030, All_Time = 18022.841
610150/758000 (epoch 1609), train_loss = 0.262, time/batch = 0.028, All_Time = 18024.305
610200/758000 (epoch 1610), train_loss = 0.282, time/batch = 0.029, All_Time = 18025.773
610250/758000 (epoch 1610), train_loss = 0.292, time/batch = 0.030, All_Time = 18027.246
610300/758000 (epoch 1610), train_loss = 0.253, time/batch = 0.031, All_Time = 18028.720
610350/758000 (epoch 1610), train_loss = 0.222, time/batch = 0.030, All_Time = 18030.180
610400/758000 (epoch 1610), train_loss = 0.221, time/batch = 0.028, All_Time = 18031.661
610450/758000 (epoch 1610), train_loss = 0.260, time/batch = 0.030, All_Time = 18033.125
610500/758000 (epoch 1610), train_loss = 0.244, time/batch = 0.028, All_Time = 18034.598
610550/758000 (epoch 1610), train_loss = 0.247, time/batch = 0.031, All_Time = 18036.059
610600/758000 (epoch 1611), train_loss = 0.210, time/batch = 0.030, All_Time = 18037.536
610650/758000 (epoch 1611), train_loss = 0.265, time/batch = 0.029, All_Time = 18039.011
610700/758000 (epoch 1611), train_loss = 0.229, time/batch = 0.030, All_Time = 18040.494
610750/758000 (epoch 1611), train_loss = 0.232, time/batch = 0.029, All_Time = 18041.963
610800/758000 (epoch 1611), train_loss = 0.230, time/batch = 0.031, All_Time = 18043.427
610850/758000 (epoch 1611), train_loss = 0.253, time/batch = 0.031, All_Time = 18044.896
610900/758000 (epoch 1611), train_loss = 0.258, time/batch = 0.028, All_Time = 18046.369
610950/758000 (epoch 1612), train_loss = 0.196, time/batch = 0.029, All_Time = 18047.832
611000/758000 (epoch 1612), train_loss = 0.254, time/batch = 0.029, All_Time = 18049.293
model saved to NER/polyglot/model.ckpt
611050/758000 (epoch 1612), train_loss = 0.281, time/batch = 0.029, All_Time = 18050.771
611100/758000 (epoch 1612), train_loss = 0.235, time/batch = 0.029, All_Time = 18052.239
611150/758000 (epoch 1612), train_loss = 0.247, time/batch = 0.030, All_Time = 18053.713
611200/758000 (epoch 1612), train_loss = 0.251, time/batch = 0.030, All_Time = 18055.172
611250/758000 (epoch 1612), train_loss = 0.203, time/batch = 0.030, All_Time = 18056.652
611300/758000 (epoch 1612), train_loss = 0.268, time/batch = 0.029, All_Time = 18058.113
611350/758000 (epoch 1613), train_loss = 0.233, time/batch = 0.029, All_Time = 18059.592
611400/758000 (epoch 1613), train_loss = 0.241, time/batch = 0.029, All_Time = 18061.065
611450/758000 (epoch 1613), train_loss = 0.252, time/batch = 0.030, All_Time = 18062.527
611500/758000 (epoch 1613), train_loss = 0.258, time/batch = 0.031, All_Time = 18063.997
611550/758000 (epoch 1613), train_loss = 0.243, time/batch = 0.029, All_Time = 18065.465
611600/758000 (epoch 1613), train_loss = 0.243, time/batch = 0.030, All_Time = 18066.943
611650/758000 (epoch 1613), train_loss = 0.244, time/batch = 0.030, All_Time = 18068.409
611700/758000 (epoch 1613), train_loss = 0.286, time/batch = 0.028, All_Time = 18069.877
611750/758000 (epoch 1614), train_loss = 0.207, time/batch = 0.028, All_Time = 18071.344
611800/758000 (epoch 1614), train_loss = 0.244, time/batch = 0.029, All_Time = 18072.819
611850/758000 (epoch 1614), train_loss = 0.217, time/batch = 0.029, All_Time = 18074.295
611900/758000 (epoch 1614), train_loss = 0.233, time/batch = 0.029, All_Time = 18075.765
611950/758000 (epoch 1614), train_loss = 0.260, time/batch = 0.028, All_Time = 18077.238
612000/758000 (epoch 1614), train_loss = 0.253, time/batch = 0.030, All_Time = 18078.710
model saved to NER/polyglot/model.ckpt
612050/758000 (epoch 1614), train_loss = 0.238, time/batch = 0.030, All_Time = 18080.185
612100/758000 (epoch 1615), train_loss = 0.227, time/batch = 0.030, All_Time = 18081.656
612150/758000 (epoch 1615), train_loss = 0.250, time/batch = 0.028, All_Time = 18083.118
612200/758000 (epoch 1615), train_loss = 0.250, time/batch = 0.029, All_Time = 18084.588
612250/758000 (epoch 1615), train_loss = 0.223, time/batch = 0.031, All_Time = 18086.051
612300/758000 (epoch 1615), train_loss = 0.240, time/batch = 0.031, All_Time = 18087.528
612350/758000 (epoch 1615), train_loss = 0.246, time/batch = 0.029, All_Time = 18088.989
612400/758000 (epoch 1615), train_loss = 0.246, time/batch = 0.029, All_Time = 18090.448
612450/758000 (epoch 1615), train_loss = 0.257, time/batch = 0.031, All_Time = 18091.917
612500/758000 (epoch 1616), train_loss = 0.266, time/batch = 0.029, All_Time = 18093.385
612550/758000 (epoch 1616), train_loss = 0.224, time/batch = 0.030, All_Time = 18094.850
612600/758000 (epoch 1616), train_loss = 0.248, time/batch = 0.030, All_Time = 18096.311
612650/758000 (epoch 1616), train_loss = 0.227, time/batch = 0.030, All_Time = 18097.775
612700/758000 (epoch 1616), train_loss = 0.279, time/batch = 0.030, All_Time = 18099.245
612750/758000 (epoch 1616), train_loss = 0.255, time/batch = 0.030, All_Time = 18100.724
612800/758000 (epoch 1616), train_loss = 0.253, time/batch = 0.032, All_Time = 18102.200
612850/758000 (epoch 1617), train_loss = 0.244, time/batch = 0.029, All_Time = 18103.666
612900/758000 (epoch 1617), train_loss = 0.247, time/batch = 0.029, All_Time = 18105.139
612950/758000 (epoch 1617), train_loss = 0.270, time/batch = 0.031, All_Time = 18106.625
613000/758000 (epoch 1617), train_loss = 0.246, time/batch = 0.031, All_Time = 18108.091
model saved to NER/polyglot/model.ckpt
613050/758000 (epoch 1617), train_loss = 0.237, time/batch = 0.030, All_Time = 18109.561
613100/758000 (epoch 1617), train_loss = 0.224, time/batch = 0.030, All_Time = 18111.022
613150/758000 (epoch 1617), train_loss = 0.229, time/batch = 0.029, All_Time = 18112.491
613200/758000 (epoch 1617), train_loss = 0.246, time/batch = 0.030, All_Time = 18113.958
613250/758000 (epoch 1618), train_loss = 0.249, time/batch = 0.030, All_Time = 18115.433
613300/758000 (epoch 1618), train_loss = 0.264, time/batch = 0.030, All_Time = 18116.899
613350/758000 (epoch 1618), train_loss = 0.240, time/batch = 0.029, All_Time = 18118.354
613400/758000 (epoch 1618), train_loss = 0.250, time/batch = 0.030, All_Time = 18119.830
613450/758000 (epoch 1618), train_loss = 0.227, time/batch = 0.029, All_Time = 18121.286
613500/758000 (epoch 1618), train_loss = 0.217, time/batch = 0.029, All_Time = 18122.756
613550/758000 (epoch 1618), train_loss = 0.277, time/batch = 0.028, All_Time = 18124.215
613600/758000 (epoch 1618), train_loss = 0.259, time/batch = 0.028, All_Time = 18125.691
613650/758000 (epoch 1619), train_loss = 0.269, time/batch = 0.030, All_Time = 18127.156
613700/758000 (epoch 1619), train_loss = 0.296, time/batch = 0.029, All_Time = 18128.619
613750/758000 (epoch 1619), train_loss = 0.228, time/batch = 0.028, All_Time = 18130.090
613800/758000 (epoch 1619), train_loss = 0.220, time/batch = 0.028, All_Time = 18131.550
613850/758000 (epoch 1619), train_loss = 0.257, time/batch = 0.030, All_Time = 18133.015
613900/758000 (epoch 1619), train_loss = 0.255, time/batch = 0.028, All_Time = 18134.479
613950/758000 (epoch 1619), train_loss = 0.237, time/batch = 0.030, All_Time = 18135.948
614000/758000 (epoch 1620), train_loss = 0.225, time/batch = 0.031, All_Time = 18137.414
model saved to NER/polyglot/model.ckpt
614050/758000 (epoch 1620), train_loss = 0.234, time/batch = 0.030, All_Time = 18138.881
614100/758000 (epoch 1620), train_loss = 0.243, time/batch = 0.030, All_Time = 18140.362
614150/758000 (epoch 1620), train_loss = 0.234, time/batch = 0.030, All_Time = 18141.821
614200/758000 (epoch 1620), train_loss = 0.223, time/batch = 0.030, All_Time = 18143.283
614250/758000 (epoch 1620), train_loss = 0.239, time/batch = 0.028, All_Time = 18144.748
614300/758000 (epoch 1620), train_loss = 0.264, time/batch = 0.030, All_Time = 18146.220
614350/758000 (epoch 1620), train_loss = 0.244, time/batch = 0.029, All_Time = 18147.693
614400/758000 (epoch 1621), train_loss = 0.257, time/batch = 0.031, All_Time = 18149.158
614450/758000 (epoch 1621), train_loss = 0.287, time/batch = 0.028, All_Time = 18150.623
614500/758000 (epoch 1621), train_loss = 0.255, time/batch = 0.029, All_Time = 18152.091
614550/758000 (epoch 1621), train_loss = 0.248, time/batch = 0.028, All_Time = 18153.550
614600/758000 (epoch 1621), train_loss = 0.212, time/batch = 0.030, All_Time = 18155.026
614650/758000 (epoch 1621), train_loss = 0.229, time/batch = 0.031, All_Time = 18156.490
614700/758000 (epoch 1621), train_loss = 0.272, time/batch = 0.030, All_Time = 18157.959
614750/758000 (epoch 1622), train_loss = 0.249, time/batch = 0.029, All_Time = 18159.430
614800/758000 (epoch 1622), train_loss = 0.227, time/batch = 0.030, All_Time = 18160.897
614850/758000 (epoch 1622), train_loss = 0.267, time/batch = 0.029, All_Time = 18162.359
614900/758000 (epoch 1622), train_loss = 0.239, time/batch = 0.029, All_Time = 18163.827
614950/758000 (epoch 1622), train_loss = 0.247, time/batch = 0.029, All_Time = 18165.284
615000/758000 (epoch 1622), train_loss = 0.241, time/batch = 0.027, All_Time = 18166.753
model saved to NER/polyglot/model.ckpt
615050/758000 (epoch 1622), train_loss = 0.274, time/batch = 0.028, All_Time = 18168.212
615100/758000 (epoch 1622), train_loss = 0.279, time/batch = 0.031, All_Time = 18169.685
615150/758000 (epoch 1623), train_loss = 0.238, time/batch = 0.029, All_Time = 18171.147
615200/758000 (epoch 1623), train_loss = 0.248, time/batch = 0.030, All_Time = 18172.616
615250/758000 (epoch 1623), train_loss = 0.299, time/batch = 0.029, All_Time = 18174.090
615300/758000 (epoch 1623), train_loss = 0.230, time/batch = 0.031, All_Time = 18175.556
615350/758000 (epoch 1623), train_loss = 0.216, time/batch = 0.030, All_Time = 18177.035
615400/758000 (epoch 1623), train_loss = 0.244, time/batch = 0.030, All_Time = 18178.511
615450/758000 (epoch 1623), train_loss = 0.274, time/batch = 0.029, All_Time = 18179.973
615500/758000 (epoch 1624), train_loss = 0.221, time/batch = 0.029, All_Time = 18181.435
615550/758000 (epoch 1624), train_loss = 0.257, time/batch = 0.028, All_Time = 18182.901
615600/758000 (epoch 1624), train_loss = 0.241, time/batch = 0.031, All_Time = 18184.369
615650/758000 (epoch 1624), train_loss = 0.240, time/batch = 0.029, All_Time = 18185.843
615700/758000 (epoch 1624), train_loss = 0.256, time/batch = 0.031, All_Time = 18187.323
615750/758000 (epoch 1624), train_loss = 0.219, time/batch = 0.028, All_Time = 18188.788
615800/758000 (epoch 1624), train_loss = 0.224, time/batch = 0.030, All_Time = 18190.259
615850/758000 (epoch 1624), train_loss = 0.257, time/batch = 0.030, All_Time = 18191.729
615900/758000 (epoch 1625), train_loss = 0.255, time/batch = 0.029, All_Time = 18193.207
615950/758000 (epoch 1625), train_loss = 0.267, time/batch = 0.030, All_Time = 18194.665
616000/758000 (epoch 1625), train_loss = 0.269, time/batch = 0.029, All_Time = 18196.128
model saved to NER/polyglot/model.ckpt
616050/758000 (epoch 1625), train_loss = 0.228, time/batch = 0.029, All_Time = 18197.605
616100/758000 (epoch 1625), train_loss = 0.234, time/batch = 0.029, All_Time = 18199.065
616150/758000 (epoch 1625), train_loss = 0.245, time/batch = 0.029, All_Time = 18200.532
616200/758000 (epoch 1625), train_loss = 0.279, time/batch = 0.030, All_Time = 18201.996
616250/758000 (epoch 1625), train_loss = 0.240, time/batch = 0.029, All_Time = 18203.457
616300/758000 (epoch 1626), train_loss = 0.236, time/batch = 0.029, All_Time = 18204.926
616350/758000 (epoch 1626), train_loss = 0.234, time/batch = 0.028, All_Time = 18206.392
616400/758000 (epoch 1626), train_loss = 0.233, time/batch = 0.029, All_Time = 18207.872
616450/758000 (epoch 1626), train_loss = 0.276, time/batch = 0.029, All_Time = 18209.347
616500/758000 (epoch 1626), train_loss = 0.206, time/batch = 0.028, All_Time = 18210.821
616550/758000 (epoch 1626), train_loss = 0.259, time/batch = 0.031, All_Time = 18212.286
616600/758000 (epoch 1626), train_loss = 0.234, time/batch = 0.029, All_Time = 18213.760
616650/758000 (epoch 1627), train_loss = 0.245, time/batch = 0.030, All_Time = 18215.227
616700/758000 (epoch 1627), train_loss = 0.223, time/batch = 0.029, All_Time = 18216.688
616750/758000 (epoch 1627), train_loss = 0.240, time/batch = 0.029, All_Time = 18218.157
616800/758000 (epoch 1627), train_loss = 0.256, time/batch = 0.027, All_Time = 18219.626
616850/758000 (epoch 1627), train_loss = 0.214, time/batch = 0.028, All_Time = 18221.093
616900/758000 (epoch 1627), train_loss = 0.272, time/batch = 0.029, All_Time = 18222.566
616950/758000 (epoch 1627), train_loss = 0.213, time/batch = 0.030, All_Time = 18224.025
617000/758000 (epoch 1627), train_loss = 0.251, time/batch = 0.030, All_Time = 18225.494
model saved to NER/polyglot/model.ckpt
617050/758000 (epoch 1628), train_loss = 0.247, time/batch = 0.027, All_Time = 18226.964
617100/758000 (epoch 1628), train_loss = 0.229, time/batch = 0.028, All_Time = 18228.431
617150/758000 (epoch 1628), train_loss = 0.217, time/batch = 0.029, All_Time = 18229.901
617200/758000 (epoch 1628), train_loss = 0.220, time/batch = 0.029, All_Time = 18231.372
617250/758000 (epoch 1628), train_loss = 0.250, time/batch = 0.028, All_Time = 18232.835
617300/758000 (epoch 1628), train_loss = 0.207, time/batch = 0.028, All_Time = 18234.298
617350/758000 (epoch 1628), train_loss = 0.268, time/batch = 0.030, All_Time = 18235.768
617400/758000 (epoch 1629), train_loss = 0.256, time/batch = 0.030, All_Time = 18237.244
617450/758000 (epoch 1629), train_loss = 0.264, time/batch = 0.029, All_Time = 18238.712
617500/758000 (epoch 1629), train_loss = 0.284, time/batch = 0.030, All_Time = 18240.176
617550/758000 (epoch 1629), train_loss = 0.239, time/batch = 0.028, All_Time = 18241.643
617600/758000 (epoch 1629), train_loss = 0.267, time/batch = 0.028, All_Time = 18243.098
617650/758000 (epoch 1629), train_loss = 0.256, time/batch = 0.029, All_Time = 18244.567
617700/758000 (epoch 1629), train_loss = 0.236, time/batch = 0.029, All_Time = 18246.027
617750/758000 (epoch 1629), train_loss = 0.268, time/batch = 0.030, All_Time = 18247.499
617800/758000 (epoch 1630), train_loss = 0.226, time/batch = 0.029, All_Time = 18248.974
617850/758000 (epoch 1630), train_loss = 0.222, time/batch = 0.029, All_Time = 18250.435
617900/758000 (epoch 1630), train_loss = 0.261, time/batch = 0.028, All_Time = 18251.904
617950/758000 (epoch 1630), train_loss = 0.254, time/batch = 0.028, All_Time = 18253.368
618000/758000 (epoch 1630), train_loss = 0.223, time/batch = 0.029, All_Time = 18254.841
model saved to NER/polyglot/model.ckpt
618050/758000 (epoch 1630), train_loss = 0.242, time/batch = 0.030, All_Time = 18256.312
618100/758000 (epoch 1630), train_loss = 0.251, time/batch = 0.030, All_Time = 18257.783
618150/758000 (epoch 1631), train_loss = 0.192, time/batch = 0.029, All_Time = 18259.259
618200/758000 (epoch 1631), train_loss = 0.273, time/batch = 0.030, All_Time = 18260.730
618250/758000 (epoch 1631), train_loss = 0.217, time/batch = 0.030, All_Time = 18262.193
618300/758000 (epoch 1631), train_loss = 0.240, time/batch = 0.030, All_Time = 18263.664
618350/758000 (epoch 1631), train_loss = 0.221, time/batch = 0.030, All_Time = 18265.130
618400/758000 (epoch 1631), train_loss = 0.221, time/batch = 0.030, All_Time = 18266.594
618450/758000 (epoch 1631), train_loss = 0.252, time/batch = 0.029, All_Time = 18268.068
618500/758000 (epoch 1631), train_loss = 0.272, time/batch = 0.031, All_Time = 18269.527
618550/758000 (epoch 1632), train_loss = 0.222, time/batch = 0.029, All_Time = 18270.992
618600/758000 (epoch 1632), train_loss = 0.279, time/batch = 0.029, All_Time = 18272.454
618650/758000 (epoch 1632), train_loss = 0.242, time/batch = 0.029, All_Time = 18273.922
618700/758000 (epoch 1632), train_loss = 0.274, time/batch = 0.028, All_Time = 18275.390
618750/758000 (epoch 1632), train_loss = 0.262, time/batch = 0.029, All_Time = 18276.856
618800/758000 (epoch 1632), train_loss = 0.197, time/batch = 0.029, All_Time = 18278.320
618850/758000 (epoch 1632), train_loss = 0.233, time/batch = 0.029, All_Time = 18279.790
618900/758000 (epoch 1632), train_loss = 0.281, time/batch = 0.030, All_Time = 18281.261
618950/758000 (epoch 1633), train_loss = 0.246, time/batch = 0.030, All_Time = 18282.733
619000/758000 (epoch 1633), train_loss = 0.212, time/batch = 0.029, All_Time = 18284.199
model saved to NER/polyglot/model.ckpt
619050/758000 (epoch 1633), train_loss = 0.255, time/batch = 0.030, All_Time = 18285.690
619100/758000 (epoch 1633), train_loss = 0.271, time/batch = 0.030, All_Time = 18287.167
619150/758000 (epoch 1633), train_loss = 0.203, time/batch = 0.029, All_Time = 18288.633
619200/758000 (epoch 1633), train_loss = 0.226, time/batch = 0.029, All_Time = 18290.091
619250/758000 (epoch 1633), train_loss = 0.254, time/batch = 0.030, All_Time = 18291.555
619300/758000 (epoch 1634), train_loss = 0.219, time/batch = 0.030, All_Time = 18293.023
619350/758000 (epoch 1634), train_loss = 0.265, time/batch = 0.028, All_Time = 18294.490
619400/758000 (epoch 1634), train_loss = 0.227, time/batch = 0.031, All_Time = 18295.963
619450/758000 (epoch 1634), train_loss = 0.213, time/batch = 0.029, All_Time = 18297.426
619500/758000 (epoch 1634), train_loss = 0.224, time/batch = 0.029, All_Time = 18298.884
619550/758000 (epoch 1634), train_loss = 0.213, time/batch = 0.029, All_Time = 18300.349
619600/758000 (epoch 1634), train_loss = 0.230, time/batch = 0.030, All_Time = 18301.823
619650/758000 (epoch 1634), train_loss = 0.223, time/batch = 0.030, All_Time = 18303.286
619700/758000 (epoch 1635), train_loss = 0.275, time/batch = 0.030, All_Time = 18304.754
619750/758000 (epoch 1635), train_loss = 0.229, time/batch = 0.029, All_Time = 18306.230
619800/758000 (epoch 1635), train_loss = 0.270, time/batch = 0.030, All_Time = 18307.702
619850/758000 (epoch 1635), train_loss = 0.273, time/batch = 0.029, All_Time = 18309.168
619900/758000 (epoch 1635), train_loss = 0.233, time/batch = 0.028, All_Time = 18310.635
619950/758000 (epoch 1635), train_loss = 0.268, time/batch = 0.029, All_Time = 18312.115
620000/758000 (epoch 1635), train_loss = 0.280, time/batch = 0.029, All_Time = 18313.583
model saved to NER/polyglot/model.ckpt
620050/758000 (epoch 1636), train_loss = 0.239, time/batch = 0.029, All_Time = 18315.055
620100/758000 (epoch 1636), train_loss = 0.218, time/batch = 0.029, All_Time = 18316.524
620150/758000 (epoch 1636), train_loss = 0.243, time/batch = 0.029, All_Time = 18318.000
620200/758000 (epoch 1636), train_loss = 0.244, time/batch = 0.029, All_Time = 18319.480
620250/758000 (epoch 1636), train_loss = 0.243, time/batch = 0.030, All_Time = 18320.961
620300/758000 (epoch 1636), train_loss = 0.244, time/batch = 0.029, All_Time = 18322.416
620350/758000 (epoch 1636), train_loss = 0.213, time/batch = 0.028, All_Time = 18323.886
620400/758000 (epoch 1636), train_loss = 0.289, time/batch = 0.029, All_Time = 18325.358
620450/758000 (epoch 1637), train_loss = 0.237, time/batch = 0.031, All_Time = 18326.830
620500/758000 (epoch 1637), train_loss = 0.246, time/batch = 0.029, All_Time = 18328.299
620550/758000 (epoch 1637), train_loss = 0.288, time/batch = 0.028, All_Time = 18329.766
620600/758000 (epoch 1637), train_loss = 0.257, time/batch = 0.029, All_Time = 18331.222
620650/758000 (epoch 1637), train_loss = 0.218, time/batch = 0.029, All_Time = 18332.687
620700/758000 (epoch 1637), train_loss = 0.238, time/batch = 0.030, All_Time = 18334.158
620750/758000 (epoch 1637), train_loss = 0.251, time/batch = 0.029, All_Time = 18335.636
620800/758000 (epoch 1637), train_loss = 0.251, time/batch = 0.029, All_Time = 18337.113
620850/758000 (epoch 1638), train_loss = 0.252, time/batch = 0.030, All_Time = 18338.584
620900/758000 (epoch 1638), train_loss = 0.280, time/batch = 0.030, All_Time = 18340.054
620950/758000 (epoch 1638), train_loss = 0.242, time/batch = 0.029, All_Time = 18341.517
621000/758000 (epoch 1638), train_loss = 0.250, time/batch = 0.030, All_Time = 18342.980
model saved to NER/polyglot/model.ckpt
621050/758000 (epoch 1638), train_loss = 0.239, time/batch = 0.029, All_Time = 18344.444
621100/758000 (epoch 1638), train_loss = 0.239, time/batch = 0.029, All_Time = 18345.901
621150/758000 (epoch 1638), train_loss = 0.250, time/batch = 0.029, All_Time = 18347.361
621200/758000 (epoch 1639), train_loss = 0.221, time/batch = 0.031, All_Time = 18348.840
621250/758000 (epoch 1639), train_loss = 0.219, time/batch = 0.030, All_Time = 18350.304
621300/758000 (epoch 1639), train_loss = 0.246, time/batch = 0.029, All_Time = 18351.769
621350/758000 (epoch 1639), train_loss = 0.262, time/batch = 0.029, All_Time = 18353.237
621400/758000 (epoch 1639), train_loss = 0.260, time/batch = 0.030, All_Time = 18354.698
621450/758000 (epoch 1639), train_loss = 0.241, time/batch = 0.032, All_Time = 18356.167
621500/758000 (epoch 1639), train_loss = 0.210, time/batch = 0.029, All_Time = 18357.633
621550/758000 (epoch 1639), train_loss = 0.239, time/batch = 0.029, All_Time = 18359.100
621600/758000 (epoch 1640), train_loss = 0.230, time/batch = 0.029, All_Time = 18360.587
621650/758000 (epoch 1640), train_loss = 0.226, time/batch = 0.031, All_Time = 18362.050
621700/758000 (epoch 1640), train_loss = 0.264, time/batch = 0.029, All_Time = 18363.511
621750/758000 (epoch 1640), train_loss = 0.240, time/batch = 0.030, All_Time = 18364.963
621800/758000 (epoch 1640), train_loss = 0.253, time/batch = 0.029, All_Time = 18366.428
621850/758000 (epoch 1640), train_loss = 0.251, time/batch = 0.030, All_Time = 18367.904
621900/758000 (epoch 1640), train_loss = 0.248, time/batch = 0.030, All_Time = 18369.373
621950/758000 (epoch 1641), train_loss = 0.216, time/batch = 0.029, All_Time = 18370.844
622000/758000 (epoch 1641), train_loss = 0.233, time/batch = 0.030, All_Time = 18372.307
model saved to NER/polyglot/model.ckpt
622050/758000 (epoch 1641), train_loss = 0.250, time/batch = 0.029, All_Time = 18373.780
622100/758000 (epoch 1641), train_loss = 0.241, time/batch = 0.029, All_Time = 18375.253
622150/758000 (epoch 1641), train_loss = 0.243, time/batch = 0.030, All_Time = 18376.720
622200/758000 (epoch 1641), train_loss = 0.242, time/batch = 0.030, All_Time = 18378.189
622250/758000 (epoch 1641), train_loss = 0.230, time/batch = 0.030, All_Time = 18379.653
622300/758000 (epoch 1641), train_loss = 0.259, time/batch = 0.029, All_Time = 18381.123
622350/758000 (epoch 1642), train_loss = 0.250, time/batch = 0.029, All_Time = 18382.595
622400/758000 (epoch 1642), train_loss = 0.253, time/batch = 0.029, All_Time = 18384.062
622450/758000 (epoch 1642), train_loss = 0.245, time/batch = 0.030, All_Time = 18385.531
622500/758000 (epoch 1642), train_loss = 0.231, time/batch = 0.030, All_Time = 18387.006
622550/758000 (epoch 1642), train_loss = 0.228, time/batch = 0.030, All_Time = 18388.469
622600/758000 (epoch 1642), train_loss = 0.238, time/batch = 0.030, All_Time = 18389.945
622650/758000 (epoch 1642), train_loss = 0.268, time/batch = 0.029, All_Time = 18391.412
622700/758000 (epoch 1643), train_loss = 0.248, time/batch = 0.028, All_Time = 18392.891
622750/758000 (epoch 1643), train_loss = 0.280, time/batch = 0.029, All_Time = 18394.352
622800/758000 (epoch 1643), train_loss = 0.242, time/batch = 0.028, All_Time = 18395.805
622850/758000 (epoch 1643), train_loss = 0.258, time/batch = 0.030, All_Time = 18397.271
622900/758000 (epoch 1643), train_loss = 0.224, time/batch = 0.031, All_Time = 18398.739
622950/758000 (epoch 1643), train_loss = 0.243, time/batch = 0.029, All_Time = 18400.204
623000/758000 (epoch 1643), train_loss = 0.219, time/batch = 0.030, All_Time = 18401.678
model saved to NER/polyglot/model.ckpt
623050/758000 (epoch 1643), train_loss = 0.232, time/batch = 0.030, All_Time = 18403.152
623100/758000 (epoch 1644), train_loss = 0.237, time/batch = 0.030, All_Time = 18404.620
623150/758000 (epoch 1644), train_loss = 0.239, time/batch = 0.028, All_Time = 18406.083
623200/758000 (epoch 1644), train_loss = 0.293, time/batch = 0.029, All_Time = 18407.549
623250/758000 (epoch 1644), train_loss = 0.318, time/batch = 0.030, All_Time = 18409.009
623300/758000 (epoch 1644), train_loss = 0.196, time/batch = 0.029, All_Time = 18410.475
623350/758000 (epoch 1644), train_loss = 0.213, time/batch = 0.028, All_Time = 18411.945
623400/758000 (epoch 1644), train_loss = 0.250, time/batch = 0.031, All_Time = 18413.426
623450/758000 (epoch 1644), train_loss = 0.297, time/batch = 0.029, All_Time = 18414.894
623500/758000 (epoch 1645), train_loss = 0.226, time/batch = 0.030, All_Time = 18416.364
623550/758000 (epoch 1645), train_loss = 0.259, time/batch = 0.034, All_Time = 18417.953
623600/758000 (epoch 1645), train_loss = 0.223, time/batch = 0.032, All_Time = 18419.556
623650/758000 (epoch 1645), train_loss = 0.239, time/batch = 0.031, All_Time = 18421.103
623700/758000 (epoch 1645), train_loss = 0.212, time/batch = 0.030, All_Time = 18422.619
623750/758000 (epoch 1645), train_loss = 0.243, time/batch = 0.030, All_Time = 18424.111
623800/758000 (epoch 1645), train_loss = 0.215, time/batch = 0.029, All_Time = 18425.594
623850/758000 (epoch 1646), train_loss = 0.228, time/batch = 0.029, All_Time = 18427.070
623900/758000 (epoch 1646), train_loss = 0.252, time/batch = 0.030, All_Time = 18428.534
623950/758000 (epoch 1646), train_loss = 0.260, time/batch = 0.029, All_Time = 18430.001
624000/758000 (epoch 1646), train_loss = 0.228, time/batch = 0.030, All_Time = 18431.466
model saved to NER/polyglot/model.ckpt
624050/758000 (epoch 1646), train_loss = 0.236, time/batch = 0.029, All_Time = 18432.930
624100/758000 (epoch 1646), train_loss = 0.271, time/batch = 0.030, All_Time = 18434.403
624150/758000 (epoch 1646), train_loss = 0.238, time/batch = 0.030, All_Time = 18435.869
624200/758000 (epoch 1646), train_loss = 0.268, time/batch = 0.030, All_Time = 18437.330
624250/758000 (epoch 1647), train_loss = 0.248, time/batch = 0.029, All_Time = 18438.807
624300/758000 (epoch 1647), train_loss = 0.249, time/batch = 0.030, All_Time = 18440.266
624350/758000 (epoch 1647), train_loss = 0.240, time/batch = 0.029, All_Time = 18441.733
624400/758000 (epoch 1647), train_loss = 0.247, time/batch = 0.030, All_Time = 18443.196
624450/758000 (epoch 1647), train_loss = 0.235, time/batch = 0.029, All_Time = 18444.664
624500/758000 (epoch 1647), train_loss = 0.247, time/batch = 0.029, All_Time = 18446.131
624550/758000 (epoch 1647), train_loss = 0.251, time/batch = 0.030, All_Time = 18447.605
624600/758000 (epoch 1648), train_loss = 0.242, time/batch = 0.030, All_Time = 18449.071
624650/758000 (epoch 1648), train_loss = 0.276, time/batch = 0.029, All_Time = 18450.548
624700/758000 (epoch 1648), train_loss = 0.256, time/batch = 0.029, All_Time = 18452.019
624750/758000 (epoch 1648), train_loss = 0.258, time/batch = 0.031, All_Time = 18453.516
624800/758000 (epoch 1648), train_loss = 0.213, time/batch = 0.030, All_Time = 18455.006
624850/758000 (epoch 1648), train_loss = 0.237, time/batch = 0.031, All_Time = 18456.492
624900/758000 (epoch 1648), train_loss = 0.249, time/batch = 0.028, All_Time = 18457.980
624950/758000 (epoch 1648), train_loss = 0.251, time/batch = 0.028, All_Time = 18459.453
625000/758000 (epoch 1649), train_loss = 0.232, time/batch = 0.030, All_Time = 18460.927
model saved to NER/polyglot/model.ckpt
625050/758000 (epoch 1649), train_loss = 0.255, time/batch = 0.030, All_Time = 18462.393
625100/758000 (epoch 1649), train_loss = 0.265, time/batch = 0.031, All_Time = 18463.854
625150/758000 (epoch 1649), train_loss = 0.229, time/batch = 0.029, All_Time = 18465.326
625200/758000 (epoch 1649), train_loss = 0.263, time/batch = 0.029, All_Time = 18466.793
625250/758000 (epoch 1649), train_loss = 0.217, time/batch = 0.029, All_Time = 18468.249
625300/758000 (epoch 1649), train_loss = 0.248, time/batch = 0.028, All_Time = 18469.720
625350/758000 (epoch 1650), train_loss = 0.059, time/batch = 0.029, All_Time = 18471.195
625400/758000 (epoch 1650), train_loss = 0.250, time/batch = 0.032, All_Time = 18472.666
625450/758000 (epoch 1650), train_loss = 0.223, time/batch = 0.030, All_Time = 18474.141
625500/758000 (epoch 1650), train_loss = 0.250, time/batch = 0.029, All_Time = 18475.613
625550/758000 (epoch 1650), train_loss = 0.231, time/batch = 0.029, All_Time = 18477.074
625600/758000 (epoch 1650), train_loss = 0.250, time/batch = 0.029, All_Time = 18478.542
625650/758000 (epoch 1650), train_loss = 0.232, time/batch = 0.029, All_Time = 18480.010
625700/758000 (epoch 1650), train_loss = 0.230, time/batch = 0.029, All_Time = 18481.483
625750/758000 (epoch 1651), train_loss = 0.224, time/batch = 0.030, All_Time = 18482.942
625800/758000 (epoch 1651), train_loss = 0.233, time/batch = 0.028, All_Time = 18484.396
625850/758000 (epoch 1651), train_loss = 0.224, time/batch = 0.030, All_Time = 18485.857
625900/758000 (epoch 1651), train_loss = 0.262, time/batch = 0.030, All_Time = 18487.318
625950/758000 (epoch 1651), train_loss = 0.220, time/batch = 0.028, All_Time = 18488.790
626000/758000 (epoch 1651), train_loss = 0.228, time/batch = 0.030, All_Time = 18490.260
model saved to NER/polyglot/model.ckpt
626050/758000 (epoch 1651), train_loss = 0.280, time/batch = 0.030, All_Time = 18491.734
626100/758000 (epoch 1651), train_loss = 0.272, time/batch = 0.029, All_Time = 18493.195
626150/758000 (epoch 1652), train_loss = 0.230, time/batch = 0.028, All_Time = 18494.659
626200/758000 (epoch 1652), train_loss = 0.224, time/batch = 0.030, All_Time = 18496.122
626250/758000 (epoch 1652), train_loss = 0.201, time/batch = 0.030, All_Time = 18497.584
626300/758000 (epoch 1652), train_loss = 0.270, time/batch = 0.031, All_Time = 18499.044
626350/758000 (epoch 1652), train_loss = 0.259, time/batch = 0.028, All_Time = 18500.513
626400/758000 (epoch 1652), train_loss = 0.209, time/batch = 0.029, All_Time = 18501.972
626450/758000 (epoch 1652), train_loss = 0.218, time/batch = 0.030, All_Time = 18503.439
626500/758000 (epoch 1653), train_loss = 0.229, time/batch = 0.029, All_Time = 18504.902
626550/758000 (epoch 1653), train_loss = 0.283, time/batch = 0.030, All_Time = 18506.378
626600/758000 (epoch 1653), train_loss = 0.231, time/batch = 0.030, All_Time = 18507.842
626650/758000 (epoch 1653), train_loss = 0.307, time/batch = 0.030, All_Time = 18509.325
626700/758000 (epoch 1653), train_loss = 0.221, time/batch = 0.030, All_Time = 18510.796
626750/758000 (epoch 1653), train_loss = 0.208, time/batch = 0.028, All_Time = 18512.265
626800/758000 (epoch 1653), train_loss = 0.247, time/batch = 0.029, All_Time = 18513.719
626850/758000 (epoch 1653), train_loss = 0.252, time/batch = 0.029, All_Time = 18515.183
626900/758000 (epoch 1654), train_loss = 0.264, time/batch = 0.029, All_Time = 18516.661
626950/758000 (epoch 1654), train_loss = 0.229, time/batch = 0.029, All_Time = 18518.132
627000/758000 (epoch 1654), train_loss = 0.242, time/batch = 0.028, All_Time = 18519.595
model saved to NER/polyglot/model.ckpt
627050/758000 (epoch 1654), train_loss = 0.267, time/batch = 0.031, All_Time = 18521.068
627100/758000 (epoch 1654), train_loss = 0.249, time/batch = 0.030, All_Time = 18522.537
627150/758000 (epoch 1654), train_loss = 0.237, time/batch = 0.029, All_Time = 18524.006
627200/758000 (epoch 1654), train_loss = 0.276, time/batch = 0.029, All_Time = 18525.477
627250/758000 (epoch 1655), train_loss = 0.256, time/batch = 0.031, All_Time = 18526.947
627300/758000 (epoch 1655), train_loss = 0.222, time/batch = 0.030, All_Time = 18528.416
627350/758000 (epoch 1655), train_loss = 0.266, time/batch = 0.030, All_Time = 18529.878
627400/758000 (epoch 1655), train_loss = 0.216, time/batch = 0.029, All_Time = 18531.340
627450/758000 (epoch 1655), train_loss = 0.223, time/batch = 0.031, All_Time = 18532.808
627500/758000 (epoch 1655), train_loss = 0.261, time/batch = 0.029, All_Time = 18534.263
627550/758000 (epoch 1655), train_loss = 0.238, time/batch = 0.029, All_Time = 18535.734
627600/758000 (epoch 1655), train_loss = 0.264, time/batch = 0.030, All_Time = 18537.193
627650/758000 (epoch 1656), train_loss = 0.223, time/batch = 0.029, All_Time = 18538.667
627700/758000 (epoch 1656), train_loss = 0.231, time/batch = 0.029, All_Time = 18540.141
627750/758000 (epoch 1656), train_loss = 0.238, time/batch = 0.029, All_Time = 18541.614
627800/758000 (epoch 1656), train_loss = 0.266, time/batch = 0.029, All_Time = 18543.089
627850/758000 (epoch 1656), train_loss = 0.239, time/batch = 0.029, All_Time = 18544.552
627900/758000 (epoch 1656), train_loss = 0.226, time/batch = 0.028, All_Time = 18546.031
627950/758000 (epoch 1656), train_loss = 0.276, time/batch = 0.029, All_Time = 18547.510
628000/758000 (epoch 1656), train_loss = 0.240, time/batch = 0.031, All_Time = 18548.975
model saved to NER/polyglot/model.ckpt
628050/758000 (epoch 1657), train_loss = 0.281, time/batch = 0.029, All_Time = 18550.442
628100/758000 (epoch 1657), train_loss = 0.257, time/batch = 0.029, All_Time = 18551.909
628150/758000 (epoch 1657), train_loss = 0.240, time/batch = 0.029, All_Time = 18553.377
628200/758000 (epoch 1657), train_loss = 0.231, time/batch = 0.029, All_Time = 18554.852
628250/758000 (epoch 1657), train_loss = 0.217, time/batch = 0.028, All_Time = 18556.312
628300/758000 (epoch 1657), train_loss = 0.224, time/batch = 0.029, All_Time = 18557.773
628350/758000 (epoch 1657), train_loss = 0.215, time/batch = 0.028, All_Time = 18559.252
628400/758000 (epoch 1658), train_loss = 0.249, time/batch = 0.031, All_Time = 18560.725
628450/758000 (epoch 1658), train_loss = 0.211, time/batch = 0.029, All_Time = 18562.182
628500/758000 (epoch 1658), train_loss = 0.245, time/batch = 0.029, All_Time = 18563.647
628550/758000 (epoch 1658), train_loss = 0.217, time/batch = 0.029, All_Time = 18565.111
628600/758000 (epoch 1658), train_loss = 0.233, time/batch = 0.030, All_Time = 18566.581
628650/758000 (epoch 1658), train_loss = 0.228, time/batch = 0.028, All_Time = 18568.046
628700/758000 (epoch 1658), train_loss = 0.248, time/batch = 0.029, All_Time = 18569.512
628750/758000 (epoch 1658), train_loss = 0.229, time/batch = 0.031, All_Time = 18570.971
628800/758000 (epoch 1659), train_loss = 0.218, time/batch = 0.030, All_Time = 18572.441
628850/758000 (epoch 1659), train_loss = 0.237, time/batch = 0.028, All_Time = 18573.905
628900/758000 (epoch 1659), train_loss = 0.212, time/batch = 0.030, All_Time = 18575.377
628950/758000 (epoch 1659), train_loss = 0.266, time/batch = 0.030, All_Time = 18576.845
629000/758000 (epoch 1659), train_loss = 0.255, time/batch = 0.029, All_Time = 18578.309
model saved to NER/polyglot/model.ckpt
629050/758000 (epoch 1659), train_loss = 0.232, time/batch = 0.029, All_Time = 18579.769
629100/758000 (epoch 1659), train_loss = 0.262, time/batch = 0.029, All_Time = 18581.231
629150/758000 (epoch 1660), train_loss = 0.282, time/batch = 0.031, All_Time = 18582.701
629200/758000 (epoch 1660), train_loss = 0.292, time/batch = 0.029, All_Time = 18584.172
629250/758000 (epoch 1660), train_loss = 0.253, time/batch = 0.029, All_Time = 18585.634
629300/758000 (epoch 1660), train_loss = 0.222, time/batch = 0.029, All_Time = 18587.100
629350/758000 (epoch 1660), train_loss = 0.221, time/batch = 0.028, All_Time = 18588.563
629400/758000 (epoch 1660), train_loss = 0.260, time/batch = 0.029, All_Time = 18590.032
629450/758000 (epoch 1660), train_loss = 0.244, time/batch = 0.029, All_Time = 18591.491
629500/758000 (epoch 1660), train_loss = 0.247, time/batch = 0.030, All_Time = 18592.962
629550/758000 (epoch 1661), train_loss = 0.210, time/batch = 0.029, All_Time = 18594.433
629600/758000 (epoch 1661), train_loss = 0.265, time/batch = 0.028, All_Time = 18595.903
629650/758000 (epoch 1661), train_loss = 0.229, time/batch = 0.030, All_Time = 18597.368
629700/758000 (epoch 1661), train_loss = 0.232, time/batch = 0.030, All_Time = 18598.837
629750/758000 (epoch 1661), train_loss = 0.230, time/batch = 0.029, All_Time = 18600.310
629800/758000 (epoch 1661), train_loss = 0.253, time/batch = 0.029, All_Time = 18601.777
629850/758000 (epoch 1661), train_loss = 0.258, time/batch = 0.028, All_Time = 18603.241
629900/758000 (epoch 1662), train_loss = 0.196, time/batch = 0.029, All_Time = 18604.712
629950/758000 (epoch 1662), train_loss = 0.254, time/batch = 0.031, All_Time = 18606.174
630000/758000 (epoch 1662), train_loss = 0.281, time/batch = 0.030, All_Time = 18607.642
model saved to NER/polyglot/model.ckpt
630050/758000 (epoch 1662), train_loss = 0.235, time/batch = 0.031, All_Time = 18609.101
630100/758000 (epoch 1662), train_loss = 0.247, time/batch = 0.030, All_Time = 18610.581
630150/758000 (epoch 1662), train_loss = 0.251, time/batch = 0.030, All_Time = 18612.047
630200/758000 (epoch 1662), train_loss = 0.203, time/batch = 0.029, All_Time = 18613.522
630250/758000 (epoch 1662), train_loss = 0.268, time/batch = 0.029, All_Time = 18614.983
630300/758000 (epoch 1663), train_loss = 0.233, time/batch = 0.029, All_Time = 18616.444
630350/758000 (epoch 1663), train_loss = 0.241, time/batch = 0.029, All_Time = 18617.914
630400/758000 (epoch 1663), train_loss = 0.252, time/batch = 0.030, All_Time = 18619.383
630450/758000 (epoch 1663), train_loss = 0.258, time/batch = 0.028, All_Time = 18620.843
630500/758000 (epoch 1663), train_loss = 0.243, time/batch = 0.030, All_Time = 18622.308
630550/758000 (epoch 1663), train_loss = 0.243, time/batch = 0.029, All_Time = 18623.771
630600/758000 (epoch 1663), train_loss = 0.244, time/batch = 0.030, All_Time = 18625.239
630650/758000 (epoch 1663), train_loss = 0.286, time/batch = 0.030, All_Time = 18626.702
630700/758000 (epoch 1664), train_loss = 0.207, time/batch = 0.029, All_Time = 18628.174
630750/758000 (epoch 1664), train_loss = 0.244, time/batch = 0.029, All_Time = 18629.634
630800/758000 (epoch 1664), train_loss = 0.217, time/batch = 0.030, All_Time = 18631.103
630850/758000 (epoch 1664), train_loss = 0.233, time/batch = 0.029, All_Time = 18632.566
630900/758000 (epoch 1664), train_loss = 0.260, time/batch = 0.030, All_Time = 18634.030
630950/758000 (epoch 1664), train_loss = 0.253, time/batch = 0.030, All_Time = 18635.496
631000/758000 (epoch 1664), train_loss = 0.238, time/batch = 0.029, All_Time = 18636.968
model saved to NER/polyglot/model.ckpt
631050/758000 (epoch 1665), train_loss = 0.227, time/batch = 0.031, All_Time = 18638.440
631100/758000 (epoch 1665), train_loss = 0.250, time/batch = 0.029, All_Time = 18639.903
631150/758000 (epoch 1665), train_loss = 0.250, time/batch = 0.029, All_Time = 18641.375
631200/758000 (epoch 1665), train_loss = 0.223, time/batch = 0.030, All_Time = 18642.843
631250/758000 (epoch 1665), train_loss = 0.240, time/batch = 0.030, All_Time = 18644.307
631300/758000 (epoch 1665), train_loss = 0.246, time/batch = 0.029, All_Time = 18645.766
631350/758000 (epoch 1665), train_loss = 0.246, time/batch = 0.030, All_Time = 18647.227
631400/758000 (epoch 1665), train_loss = 0.257, time/batch = 0.030, All_Time = 18648.702
631450/758000 (epoch 1666), train_loss = 0.266, time/batch = 0.029, All_Time = 18650.171
631500/758000 (epoch 1666), train_loss = 0.224, time/batch = 0.029, All_Time = 18651.640
631550/758000 (epoch 1666), train_loss = 0.248, time/batch = 0.029, All_Time = 18653.115
631600/758000 (epoch 1666), train_loss = 0.227, time/batch = 0.030, All_Time = 18654.595
631650/758000 (epoch 1666), train_loss = 0.279, time/batch = 0.029, All_Time = 18656.052
631700/758000 (epoch 1666), train_loss = 0.255, time/batch = 0.029, All_Time = 18657.519
631750/758000 (epoch 1666), train_loss = 0.253, time/batch = 0.030, All_Time = 18658.995
631800/758000 (epoch 1667), train_loss = 0.244, time/batch = 0.028, All_Time = 18660.464
631850/758000 (epoch 1667), train_loss = 0.247, time/batch = 0.029, All_Time = 18661.936
631900/758000 (epoch 1667), train_loss = 0.270, time/batch = 0.030, All_Time = 18663.407
631950/758000 (epoch 1667), train_loss = 0.246, time/batch = 0.030, All_Time = 18664.864
632000/758000 (epoch 1667), train_loss = 0.237, time/batch = 0.030, All_Time = 18666.326
model saved to NER/polyglot/model.ckpt
632050/758000 (epoch 1667), train_loss = 0.224, time/batch = 0.031, All_Time = 18667.802
632100/758000 (epoch 1667), train_loss = 0.229, time/batch = 0.029, All_Time = 18669.271
632150/758000 (epoch 1667), train_loss = 0.246, time/batch = 0.030, All_Time = 18670.744
632200/758000 (epoch 1668), train_loss = 0.249, time/batch = 0.029, All_Time = 18672.210
632250/758000 (epoch 1668), train_loss = 0.264, time/batch = 0.029, All_Time = 18673.684
632300/758000 (epoch 1668), train_loss = 0.240, time/batch = 0.030, All_Time = 18675.153
632350/758000 (epoch 1668), train_loss = 0.250, time/batch = 0.029, All_Time = 18676.619
632400/758000 (epoch 1668), train_loss = 0.227, time/batch = 0.029, All_Time = 18678.084
632450/758000 (epoch 1668), train_loss = 0.217, time/batch = 0.030, All_Time = 18679.548
632500/758000 (epoch 1668), train_loss = 0.277, time/batch = 0.029, All_Time = 18681.016
632550/758000 (epoch 1668), train_loss = 0.259, time/batch = 0.030, All_Time = 18682.490
632600/758000 (epoch 1669), train_loss = 0.269, time/batch = 0.029, All_Time = 18683.961
632650/758000 (epoch 1669), train_loss = 0.296, time/batch = 0.031, All_Time = 18685.421
632700/758000 (epoch 1669), train_loss = 0.228, time/batch = 0.028, All_Time = 18686.894
632750/758000 (epoch 1669), train_loss = 0.220, time/batch = 0.031, All_Time = 18688.361
632800/758000 (epoch 1669), train_loss = 0.257, time/batch = 0.030, All_Time = 18689.835
632850/758000 (epoch 1669), train_loss = 0.255, time/batch = 0.030, All_Time = 18691.299
632900/758000 (epoch 1669), train_loss = 0.237, time/batch = 0.028, All_Time = 18692.762
632950/758000 (epoch 1670), train_loss = 0.225, time/batch = 0.030, All_Time = 18694.232
633000/758000 (epoch 1670), train_loss = 0.234, time/batch = 0.028, All_Time = 18695.702
model saved to NER/polyglot/model.ckpt
633050/758000 (epoch 1670), train_loss = 0.243, time/batch = 0.030, All_Time = 18697.178
633100/758000 (epoch 1670), train_loss = 0.234, time/batch = 0.030, All_Time = 18698.650
633150/758000 (epoch 1670), train_loss = 0.223, time/batch = 0.029, All_Time = 18700.118
633200/758000 (epoch 1670), train_loss = 0.239, time/batch = 0.030, All_Time = 18701.580
633250/758000 (epoch 1670), train_loss = 0.264, time/batch = 0.030, All_Time = 18703.039
633300/758000 (epoch 1670), train_loss = 0.244, time/batch = 0.029, All_Time = 18704.511
633350/758000 (epoch 1671), train_loss = 0.257, time/batch = 0.030, All_Time = 18705.987
633400/758000 (epoch 1671), train_loss = 0.287, time/batch = 0.029, All_Time = 18707.458
633450/758000 (epoch 1671), train_loss = 0.255, time/batch = 0.029, All_Time = 18708.929
633500/758000 (epoch 1671), train_loss = 0.248, time/batch = 0.029, All_Time = 18710.401
633550/758000 (epoch 1671), train_loss = 0.212, time/batch = 0.029, All_Time = 18711.889
633600/758000 (epoch 1671), train_loss = 0.229, time/batch = 0.028, All_Time = 18713.354
633650/758000 (epoch 1671), train_loss = 0.272, time/batch = 0.028, All_Time = 18714.826
633700/758000 (epoch 1672), train_loss = 0.249, time/batch = 0.031, All_Time = 18716.294
633750/758000 (epoch 1672), train_loss = 0.227, time/batch = 0.029, All_Time = 18717.755
633800/758000 (epoch 1672), train_loss = 0.267, time/batch = 0.030, All_Time = 18719.221
633850/758000 (epoch 1672), train_loss = 0.239, time/batch = 0.029, All_Time = 18720.690
633900/758000 (epoch 1672), train_loss = 0.247, time/batch = 0.029, All_Time = 18722.162
633950/758000 (epoch 1672), train_loss = 0.241, time/batch = 0.031, All_Time = 18723.636
634000/758000 (epoch 1672), train_loss = 0.274, time/batch = 0.029, All_Time = 18725.099
model saved to NER/polyglot/model.ckpt
634050/758000 (epoch 1672), train_loss = 0.279, time/batch = 0.030, All_Time = 18726.579
634100/758000 (epoch 1673), train_loss = 0.238, time/batch = 0.031, All_Time = 18728.049
634150/758000 (epoch 1673), train_loss = 0.248, time/batch = 0.028, All_Time = 18729.506
634200/758000 (epoch 1673), train_loss = 0.299, time/batch = 0.030, All_Time = 18730.977
634250/758000 (epoch 1673), train_loss = 0.230, time/batch = 0.028, All_Time = 18732.435
634300/758000 (epoch 1673), train_loss = 0.216, time/batch = 0.030, All_Time = 18733.904
634350/758000 (epoch 1673), train_loss = 0.244, time/batch = 0.029, All_Time = 18735.381
634400/758000 (epoch 1673), train_loss = 0.274, time/batch = 0.030, All_Time = 18736.846
634450/758000 (epoch 1674), train_loss = 0.221, time/batch = 0.029, All_Time = 18738.299
634500/758000 (epoch 1674), train_loss = 0.257, time/batch = 0.029, All_Time = 18739.760
634550/758000 (epoch 1674), train_loss = 0.241, time/batch = 0.029, All_Time = 18741.237
634600/758000 (epoch 1674), train_loss = 0.240, time/batch = 0.029, All_Time = 18742.691
634650/758000 (epoch 1674), train_loss = 0.256, time/batch = 0.029, All_Time = 18744.154
634700/758000 (epoch 1674), train_loss = 0.219, time/batch = 0.029, All_Time = 18745.620
634750/758000 (epoch 1674), train_loss = 0.224, time/batch = 0.029, All_Time = 18747.088
634800/758000 (epoch 1674), train_loss = 0.257, time/batch = 0.030, All_Time = 18748.556
634850/758000 (epoch 1675), train_loss = 0.255, time/batch = 0.029, All_Time = 18750.020
634900/758000 (epoch 1675), train_loss = 0.267, time/batch = 0.030, All_Time = 18751.488
634950/758000 (epoch 1675), train_loss = 0.269, time/batch = 0.028, All_Time = 18752.946
635000/758000 (epoch 1675), train_loss = 0.228, time/batch = 0.029, All_Time = 18754.409
model saved to NER/polyglot/model.ckpt
635050/758000 (epoch 1675), train_loss = 0.234, time/batch = 0.029, All_Time = 18755.877
635100/758000 (epoch 1675), train_loss = 0.245, time/batch = 0.030, All_Time = 18757.339
635150/758000 (epoch 1675), train_loss = 0.279, time/batch = 0.029, All_Time = 18758.795
635200/758000 (epoch 1675), train_loss = 0.240, time/batch = 0.030, All_Time = 18760.263
635250/758000 (epoch 1676), train_loss = 0.236, time/batch = 0.030, All_Time = 18761.737
635300/758000 (epoch 1676), train_loss = 0.234, time/batch = 0.029, All_Time = 18763.196
635350/758000 (epoch 1676), train_loss = 0.233, time/batch = 0.030, All_Time = 18764.659
635400/758000 (epoch 1676), train_loss = 0.276, time/batch = 0.030, All_Time = 18766.130
635450/758000 (epoch 1676), train_loss = 0.206, time/batch = 0.030, All_Time = 18767.594
635500/758000 (epoch 1676), train_loss = 0.259, time/batch = 0.029, All_Time = 18769.060
635550/758000 (epoch 1676), train_loss = 0.234, time/batch = 0.030, All_Time = 18770.526
635600/758000 (epoch 1677), train_loss = 0.245, time/batch = 0.029, All_Time = 18771.987
635650/758000 (epoch 1677), train_loss = 0.223, time/batch = 0.031, All_Time = 18773.530
635700/758000 (epoch 1677), train_loss = 0.240, time/batch = 0.031, All_Time = 18775.013
635750/758000 (epoch 1677), train_loss = 0.256, time/batch = 0.029, All_Time = 18776.483
635800/758000 (epoch 1677), train_loss = 0.214, time/batch = 0.030, All_Time = 18777.957
635850/758000 (epoch 1677), train_loss = 0.272, time/batch = 0.029, All_Time = 18779.425
635900/758000 (epoch 1677), train_loss = 0.213, time/batch = 0.028, All_Time = 18780.889
635950/758000 (epoch 1677), train_loss = 0.251, time/batch = 0.029, All_Time = 18782.358
636000/758000 (epoch 1678), train_loss = 0.247, time/batch = 0.028, All_Time = 18783.828
model saved to NER/polyglot/model.ckpt
636050/758000 (epoch 1678), train_loss = 0.229, time/batch = 0.030, All_Time = 18785.299
636100/758000 (epoch 1678), train_loss = 0.217, time/batch = 0.030, All_Time = 18786.768
636150/758000 (epoch 1678), train_loss = 0.220, time/batch = 0.028, All_Time = 18788.236
636200/758000 (epoch 1678), train_loss = 0.250, time/batch = 0.029, All_Time = 18789.700
636250/758000 (epoch 1678), train_loss = 0.207, time/batch = 0.030, All_Time = 18791.164
636300/758000 (epoch 1678), train_loss = 0.268, time/batch = 0.030, All_Time = 18792.646
636350/758000 (epoch 1679), train_loss = 0.256, time/batch = 0.029, All_Time = 18794.102
636400/758000 (epoch 1679), train_loss = 0.264, time/batch = 0.028, All_Time = 18795.556
636450/758000 (epoch 1679), train_loss = 0.284, time/batch = 0.028, All_Time = 18797.026
636500/758000 (epoch 1679), train_loss = 0.239, time/batch = 0.029, All_Time = 18798.497
636550/758000 (epoch 1679), train_loss = 0.267, time/batch = 0.030, All_Time = 18799.962
636600/758000 (epoch 1679), train_loss = 0.256, time/batch = 0.030, All_Time = 18801.426
636650/758000 (epoch 1679), train_loss = 0.236, time/batch = 0.029, All_Time = 18802.883
636700/758000 (epoch 1679), train_loss = 0.268, time/batch = 0.029, All_Time = 18804.351
636750/758000 (epoch 1680), train_loss = 0.226, time/batch = 0.029, All_Time = 18805.830
636800/758000 (epoch 1680), train_loss = 0.222, time/batch = 0.029, All_Time = 18807.296
636850/758000 (epoch 1680), train_loss = 0.261, time/batch = 0.029, All_Time = 18808.771
636900/758000 (epoch 1680), train_loss = 0.254, time/batch = 0.031, All_Time = 18810.242
636950/758000 (epoch 1680), train_loss = 0.223, time/batch = 0.030, All_Time = 18811.709
637000/758000 (epoch 1680), train_loss = 0.242, time/batch = 0.031, All_Time = 18813.170
model saved to NER/polyglot/model.ckpt
637050/758000 (epoch 1680), train_loss = 0.251, time/batch = 0.030, All_Time = 18814.639
637100/758000 (epoch 1681), train_loss = 0.192, time/batch = 0.029, All_Time = 18816.109
637150/758000 (epoch 1681), train_loss = 0.273, time/batch = 0.029, All_Time = 18817.575
637200/758000 (epoch 1681), train_loss = 0.217, time/batch = 0.029, All_Time = 18819.035
637250/758000 (epoch 1681), train_loss = 0.240, time/batch = 0.029, All_Time = 18820.499
637300/758000 (epoch 1681), train_loss = 0.221, time/batch = 0.029, All_Time = 18821.958
637350/758000 (epoch 1681), train_loss = 0.221, time/batch = 0.030, All_Time = 18823.419
637400/758000 (epoch 1681), train_loss = 0.252, time/batch = 0.029, All_Time = 18824.883
637450/758000 (epoch 1681), train_loss = 0.272, time/batch = 0.029, All_Time = 18826.335
637500/758000 (epoch 1682), train_loss = 0.222, time/batch = 0.031, All_Time = 18827.801
637550/758000 (epoch 1682), train_loss = 0.279, time/batch = 0.029, All_Time = 18829.268
637600/758000 (epoch 1682), train_loss = 0.242, time/batch = 0.031, All_Time = 18830.727
637650/758000 (epoch 1682), train_loss = 0.274, time/batch = 0.029, All_Time = 18832.191
637700/758000 (epoch 1682), train_loss = 0.262, time/batch = 0.029, All_Time = 18833.650
637750/758000 (epoch 1682), train_loss = 0.197, time/batch = 0.030, All_Time = 18835.112
637800/758000 (epoch 1682), train_loss = 0.233, time/batch = 0.030, All_Time = 18836.572
637850/758000 (epoch 1682), train_loss = 0.281, time/batch = 0.028, All_Time = 18838.031
637900/758000 (epoch 1683), train_loss = 0.246, time/batch = 0.029, All_Time = 18839.503
637950/758000 (epoch 1683), train_loss = 0.212, time/batch = 0.030, All_Time = 18840.973
638000/758000 (epoch 1683), train_loss = 0.255, time/batch = 0.032, All_Time = 18842.454
model saved to NER/polyglot/model.ckpt
638050/758000 (epoch 1683), train_loss = 0.271, time/batch = 0.027, All_Time = 18843.918
638100/758000 (epoch 1683), train_loss = 0.203, time/batch = 0.030, All_Time = 18845.381
638150/758000 (epoch 1683), train_loss = 0.226, time/batch = 0.029, All_Time = 18846.844
638200/758000 (epoch 1683), train_loss = 0.254, time/batch = 0.032, All_Time = 18848.352
638250/758000 (epoch 1684), train_loss = 0.219, time/batch = 0.029, All_Time = 18849.828
638300/758000 (epoch 1684), train_loss = 0.265, time/batch = 0.031, All_Time = 18851.300
638350/758000 (epoch 1684), train_loss = 0.227, time/batch = 0.029, All_Time = 18852.762
638400/758000 (epoch 1684), train_loss = 0.213, time/batch = 0.028, All_Time = 18854.220
638450/758000 (epoch 1684), train_loss = 0.224, time/batch = 0.028, All_Time = 18855.681
638500/758000 (epoch 1684), train_loss = 0.213, time/batch = 0.032, All_Time = 18857.151
638550/758000 (epoch 1684), train_loss = 0.230, time/batch = 0.029, All_Time = 18858.621
638600/758000 (epoch 1684), train_loss = 0.223, time/batch = 0.028, All_Time = 18860.090
638650/758000 (epoch 1685), train_loss = 0.275, time/batch = 0.029, All_Time = 18861.562
638700/758000 (epoch 1685), train_loss = 0.229, time/batch = 0.029, All_Time = 18863.027
638750/758000 (epoch 1685), train_loss = 0.270, time/batch = 0.030, All_Time = 18864.503
638800/758000 (epoch 1685), train_loss = 0.273, time/batch = 0.031, All_Time = 18865.974
638850/758000 (epoch 1685), train_loss = 0.233, time/batch = 0.028, All_Time = 18867.443
638900/758000 (epoch 1685), train_loss = 0.268, time/batch = 0.029, All_Time = 18868.906
638950/758000 (epoch 1685), train_loss = 0.280, time/batch = 0.031, All_Time = 18870.367
639000/758000 (epoch 1686), train_loss = 0.239, time/batch = 0.028, All_Time = 18871.827
model saved to NER/polyglot/model.ckpt
639050/758000 (epoch 1686), train_loss = 0.218, time/batch = 0.029, All_Time = 18873.301
639100/758000 (epoch 1686), train_loss = 0.243, time/batch = 0.030, All_Time = 18874.769
639150/758000 (epoch 1686), train_loss = 0.244, time/batch = 0.030, All_Time = 18876.230
639200/758000 (epoch 1686), train_loss = 0.243, time/batch = 0.030, All_Time = 18877.693
639250/758000 (epoch 1686), train_loss = 0.244, time/batch = 0.030, All_Time = 18879.168
639300/758000 (epoch 1686), train_loss = 0.213, time/batch = 0.030, All_Time = 18880.637
639350/758000 (epoch 1686), train_loss = 0.289, time/batch = 0.030, All_Time = 18882.104
639400/758000 (epoch 1687), train_loss = 0.237, time/batch = 0.030, All_Time = 18883.579
639450/758000 (epoch 1687), train_loss = 0.246, time/batch = 0.029, All_Time = 18885.047
639500/758000 (epoch 1687), train_loss = 0.288, time/batch = 0.030, All_Time = 18886.516
639550/758000 (epoch 1687), train_loss = 0.257, time/batch = 0.029, All_Time = 18887.980
639600/758000 (epoch 1687), train_loss = 0.218, time/batch = 0.029, All_Time = 18889.447
639650/758000 (epoch 1687), train_loss = 0.238, time/batch = 0.030, All_Time = 18890.910
639700/758000 (epoch 1687), train_loss = 0.251, time/batch = 0.029, All_Time = 18892.383
639750/758000 (epoch 1687), train_loss = 0.251, time/batch = 0.029, All_Time = 18893.847
639800/758000 (epoch 1688), train_loss = 0.252, time/batch = 0.029, All_Time = 18895.310
639850/758000 (epoch 1688), train_loss = 0.280, time/batch = 0.030, All_Time = 18896.779
639900/758000 (epoch 1688), train_loss = 0.242, time/batch = 0.030, All_Time = 18898.254
639950/758000 (epoch 1688), train_loss = 0.250, time/batch = 0.028, All_Time = 18899.716
640000/758000 (epoch 1688), train_loss = 0.239, time/batch = 0.028, All_Time = 18901.175
model saved to NER/polyglot/model.ckpt
640050/758000 (epoch 1688), train_loss = 0.239, time/batch = 0.029, All_Time = 18902.640
640100/758000 (epoch 1688), train_loss = 0.250, time/batch = 0.030, All_Time = 18904.108
640150/758000 (epoch 1689), train_loss = 0.221, time/batch = 0.029, All_Time = 18905.574
640200/758000 (epoch 1689), train_loss = 0.219, time/batch = 0.029, All_Time = 18907.044
640250/758000 (epoch 1689), train_loss = 0.246, time/batch = 0.030, All_Time = 18908.527
640300/758000 (epoch 1689), train_loss = 0.262, time/batch = 0.030, All_Time = 18909.985
640350/758000 (epoch 1689), train_loss = 0.260, time/batch = 0.030, All_Time = 18911.447
640400/758000 (epoch 1689), train_loss = 0.241, time/batch = 0.029, All_Time = 18912.911
640450/758000 (epoch 1689), train_loss = 0.210, time/batch = 0.029, All_Time = 18914.366
640500/758000 (epoch 1689), train_loss = 0.239, time/batch = 0.030, All_Time = 18915.840
640550/758000 (epoch 1690), train_loss = 0.230, time/batch = 0.028, All_Time = 18917.310
640600/758000 (epoch 1690), train_loss = 0.226, time/batch = 0.028, All_Time = 18918.773
640650/758000 (epoch 1690), train_loss = 0.264, time/batch = 0.029, All_Time = 18920.244
640700/758000 (epoch 1690), train_loss = 0.240, time/batch = 0.029, All_Time = 18921.718
640750/758000 (epoch 1690), train_loss = 0.253, time/batch = 0.029, All_Time = 18923.192
640800/758000 (epoch 1690), train_loss = 0.251, time/batch = 0.030, All_Time = 18924.656
640850/758000 (epoch 1690), train_loss = 0.248, time/batch = 0.030, All_Time = 18926.122
640900/758000 (epoch 1691), train_loss = 0.216, time/batch = 0.031, All_Time = 18927.594
640950/758000 (epoch 1691), train_loss = 0.233, time/batch = 0.029, All_Time = 18929.065
641000/758000 (epoch 1691), train_loss = 0.250, time/batch = 0.030, All_Time = 18930.539
model saved to NER/polyglot/model.ckpt
641050/758000 (epoch 1691), train_loss = 0.241, time/batch = 0.030, All_Time = 18932.002
641100/758000 (epoch 1691), train_loss = 0.243, time/batch = 0.029, All_Time = 18933.466
641150/758000 (epoch 1691), train_loss = 0.242, time/batch = 0.028, All_Time = 18934.925
641200/758000 (epoch 1691), train_loss = 0.230, time/batch = 0.030, All_Time = 18936.388
641250/758000 (epoch 1691), train_loss = 0.259, time/batch = 0.029, All_Time = 18937.863
641300/758000 (epoch 1692), train_loss = 0.250, time/batch = 0.030, All_Time = 18939.337
641350/758000 (epoch 1692), train_loss = 0.253, time/batch = 0.029, All_Time = 18940.804
641400/758000 (epoch 1692), train_loss = 0.245, time/batch = 0.029, All_Time = 18942.276
641450/758000 (epoch 1692), train_loss = 0.231, time/batch = 0.030, All_Time = 18943.745
641500/758000 (epoch 1692), train_loss = 0.228, time/batch = 0.029, All_Time = 18945.200
641550/758000 (epoch 1692), train_loss = 0.238, time/batch = 0.031, All_Time = 18946.677
641600/758000 (epoch 1692), train_loss = 0.268, time/batch = 0.029, All_Time = 18948.141
641650/758000 (epoch 1693), train_loss = 0.248, time/batch = 0.029, All_Time = 18949.594
641700/758000 (epoch 1693), train_loss = 0.280, time/batch = 0.028, All_Time = 18951.064
641750/758000 (epoch 1693), train_loss = 0.242, time/batch = 0.029, All_Time = 18952.540
641800/758000 (epoch 1693), train_loss = 0.258, time/batch = 0.030, All_Time = 18954.009
641850/758000 (epoch 1693), train_loss = 0.224, time/batch = 0.030, All_Time = 18955.477
641900/758000 (epoch 1693), train_loss = 0.243, time/batch = 0.030, All_Time = 18956.937
641950/758000 (epoch 1693), train_loss = 0.219, time/batch = 0.029, All_Time = 18958.402
642000/758000 (epoch 1693), train_loss = 0.232, time/batch = 0.029, All_Time = 18959.870
model saved to NER/polyglot/model.ckpt
642050/758000 (epoch 1694), train_loss = 0.237, time/batch = 0.030, All_Time = 18961.348
642100/758000 (epoch 1694), train_loss = 0.239, time/batch = 0.028, All_Time = 18962.808
642150/758000 (epoch 1694), train_loss = 0.293, time/batch = 0.030, All_Time = 18964.285
642200/758000 (epoch 1694), train_loss = 0.318, time/batch = 0.031, All_Time = 18965.763
642250/758000 (epoch 1694), train_loss = 0.196, time/batch = 0.028, All_Time = 18967.227
642300/758000 (epoch 1694), train_loss = 0.213, time/batch = 0.029, All_Time = 18968.690
642350/758000 (epoch 1694), train_loss = 0.250, time/batch = 0.029, All_Time = 18970.153
642400/758000 (epoch 1694), train_loss = 0.297, time/batch = 0.030, All_Time = 18971.627
642450/758000 (epoch 1695), train_loss = 0.226, time/batch = 0.030, All_Time = 18973.096
642500/758000 (epoch 1695), train_loss = 0.259, time/batch = 0.030, All_Time = 18974.575
642550/758000 (epoch 1695), train_loss = 0.223, time/batch = 0.030, All_Time = 18976.041
642600/758000 (epoch 1695), train_loss = 0.239, time/batch = 0.029, All_Time = 18977.497
642650/758000 (epoch 1695), train_loss = 0.212, time/batch = 0.029, All_Time = 18978.974
642700/758000 (epoch 1695), train_loss = 0.243, time/batch = 0.031, All_Time = 18980.443
642750/758000 (epoch 1695), train_loss = 0.215, time/batch = 0.028, All_Time = 18981.916
642800/758000 (epoch 1696), train_loss = 0.228, time/batch = 0.030, All_Time = 18983.382
642850/758000 (epoch 1696), train_loss = 0.252, time/batch = 0.031, All_Time = 18984.856
642900/758000 (epoch 1696), train_loss = 0.260, time/batch = 0.029, All_Time = 18986.316
642950/758000 (epoch 1696), train_loss = 0.228, time/batch = 0.030, All_Time = 18987.785
643000/758000 (epoch 1696), train_loss = 0.236, time/batch = 0.029, All_Time = 18989.252
model saved to NER/polyglot/model.ckpt
643050/758000 (epoch 1696), train_loss = 0.271, time/batch = 0.028, All_Time = 18990.720
643100/758000 (epoch 1696), train_loss = 0.238, time/batch = 0.030, All_Time = 18992.185
643150/758000 (epoch 1696), train_loss = 0.268, time/batch = 0.029, All_Time = 18993.649
643200/758000 (epoch 1697), train_loss = 0.248, time/batch = 0.031, All_Time = 18995.124
643250/758000 (epoch 1697), train_loss = 0.249, time/batch = 0.027, All_Time = 18996.581
643300/758000 (epoch 1697), train_loss = 0.240, time/batch = 0.030, All_Time = 18998.045
643350/758000 (epoch 1697), train_loss = 0.247, time/batch = 0.029, All_Time = 18999.506
643400/758000 (epoch 1697), train_loss = 0.235, time/batch = 0.028, All_Time = 19000.974
643450/758000 (epoch 1697), train_loss = 0.247, time/batch = 0.029, All_Time = 19002.442
643500/758000 (epoch 1697), train_loss = 0.251, time/batch = 0.031, All_Time = 19003.911
643550/758000 (epoch 1698), train_loss = 0.242, time/batch = 0.031, All_Time = 19005.379
643600/758000 (epoch 1698), train_loss = 0.276, time/batch = 0.029, All_Time = 19006.839
643650/758000 (epoch 1698), train_loss = 0.256, time/batch = 0.029, All_Time = 19008.303
643700/758000 (epoch 1698), train_loss = 0.258, time/batch = 0.030, All_Time = 19009.770
643750/758000 (epoch 1698), train_loss = 0.213, time/batch = 0.028, All_Time = 19011.233
643800/758000 (epoch 1698), train_loss = 0.237, time/batch = 0.029, All_Time = 19012.703
643850/758000 (epoch 1698), train_loss = 0.249, time/batch = 0.030, All_Time = 19014.168
643900/758000 (epoch 1698), train_loss = 0.251, time/batch = 0.031, All_Time = 19015.634
643950/758000 (epoch 1699), train_loss = 0.232, time/batch = 0.029, All_Time = 19017.095
644000/758000 (epoch 1699), train_loss = 0.255, time/batch = 0.029, All_Time = 19018.571
model saved to NER/polyglot/model.ckpt
644050/758000 (epoch 1699), train_loss = 0.265, time/batch = 0.029, All_Time = 19020.046
644100/758000 (epoch 1699), train_loss = 0.229, time/batch = 0.030, All_Time = 19021.514
644150/758000 (epoch 1699), train_loss = 0.263, time/batch = 0.029, All_Time = 19022.971
644200/758000 (epoch 1699), train_loss = 0.217, time/batch = 0.029, All_Time = 19024.434
644250/758000 (epoch 1699), train_loss = 0.248, time/batch = 0.029, All_Time = 19025.892
644300/758000 (epoch 1700), train_loss = 0.059, time/batch = 0.029, All_Time = 19027.359
644350/758000 (epoch 1700), train_loss = 0.250, time/batch = 0.030, All_Time = 19028.824
644400/758000 (epoch 1700), train_loss = 0.223, time/batch = 0.029, All_Time = 19030.291
644450/758000 (epoch 1700), train_loss = 0.250, time/batch = 0.030, All_Time = 19031.762
644500/758000 (epoch 1700), train_loss = 0.231, time/batch = 0.029, All_Time = 19033.225
644550/758000 (epoch 1700), train_loss = 0.250, time/batch = 0.030, All_Time = 19034.699
644600/758000 (epoch 1700), train_loss = 0.232, time/batch = 0.030, All_Time = 19036.162
644650/758000 (epoch 1700), train_loss = 0.230, time/batch = 0.028, All_Time = 19037.619
644700/758000 (epoch 1701), train_loss = 0.224, time/batch = 0.030, All_Time = 19039.090
644750/758000 (epoch 1701), train_loss = 0.233, time/batch = 0.028, All_Time = 19040.554
644800/758000 (epoch 1701), train_loss = 0.224, time/batch = 0.029, All_Time = 19042.020
644850/758000 (epoch 1701), train_loss = 0.262, time/batch = 0.028, All_Time = 19043.475
644900/758000 (epoch 1701), train_loss = 0.220, time/batch = 0.030, All_Time = 19044.949
644950/758000 (epoch 1701), train_loss = 0.228, time/batch = 0.029, All_Time = 19046.406
645000/758000 (epoch 1701), train_loss = 0.280, time/batch = 0.034, All_Time = 19047.971
model saved to NER/polyglot/model.ckpt
645050/758000 (epoch 1701), train_loss = 0.272, time/batch = 0.030, All_Time = 19049.431
645100/758000 (epoch 1702), train_loss = 0.230, time/batch = 0.028, All_Time = 19050.899
645150/758000 (epoch 1702), train_loss = 0.224, time/batch = 0.029, All_Time = 19052.356
645200/758000 (epoch 1702), train_loss = 0.201, time/batch = 0.029, All_Time = 19053.831
645250/758000 (epoch 1702), train_loss = 0.270, time/batch = 0.030, All_Time = 19055.305
645300/758000 (epoch 1702), train_loss = 0.259, time/batch = 0.028, All_Time = 19056.781
645350/758000 (epoch 1702), train_loss = 0.209, time/batch = 0.029, All_Time = 19058.252
645400/758000 (epoch 1702), train_loss = 0.218, time/batch = 0.030, All_Time = 19059.705
645450/758000 (epoch 1703), train_loss = 0.229, time/batch = 0.029, All_Time = 19061.173
645500/758000 (epoch 1703), train_loss = 0.283, time/batch = 0.030, All_Time = 19062.632
645550/758000 (epoch 1703), train_loss = 0.231, time/batch = 0.030, All_Time = 19064.098
645600/758000 (epoch 1703), train_loss = 0.307, time/batch = 0.029, All_Time = 19065.561
645650/758000 (epoch 1703), train_loss = 0.221, time/batch = 0.029, All_Time = 19067.028
645700/758000 (epoch 1703), train_loss = 0.208, time/batch = 0.029, All_Time = 19068.505
645750/758000 (epoch 1703), train_loss = 0.247, time/batch = 0.029, All_Time = 19069.972
645800/758000 (epoch 1703), train_loss = 0.252, time/batch = 0.030, All_Time = 19071.429
645850/758000 (epoch 1704), train_loss = 0.264, time/batch = 0.029, All_Time = 19072.900
645900/758000 (epoch 1704), train_loss = 0.229, time/batch = 0.030, All_Time = 19074.362
645950/758000 (epoch 1704), train_loss = 0.242, time/batch = 0.029, All_Time = 19075.831
646000/758000 (epoch 1704), train_loss = 0.267, time/batch = 0.029, All_Time = 19077.300
model saved to NER/polyglot/model.ckpt
646050/758000 (epoch 1704), train_loss = 0.249, time/batch = 0.030, All_Time = 19078.760
646100/758000 (epoch 1704), train_loss = 0.237, time/batch = 0.029, All_Time = 19080.223
646150/758000 (epoch 1704), train_loss = 0.276, time/batch = 0.029, All_Time = 19081.677
646200/758000 (epoch 1705), train_loss = 0.256, time/batch = 0.029, All_Time = 19083.153
646250/758000 (epoch 1705), train_loss = 0.222, time/batch = 0.029, All_Time = 19084.626
646300/758000 (epoch 1705), train_loss = 0.266, time/batch = 0.029, All_Time = 19086.090
646350/758000 (epoch 1705), train_loss = 0.216, time/batch = 0.029, All_Time = 19087.546
646400/758000 (epoch 1705), train_loss = 0.223, time/batch = 0.029, All_Time = 19089.005
646450/758000 (epoch 1705), train_loss = 0.261, time/batch = 0.031, All_Time = 19090.458
646500/758000 (epoch 1705), train_loss = 0.238, time/batch = 0.030, All_Time = 19091.911
646550/758000 (epoch 1705), train_loss = 0.264, time/batch = 0.028, All_Time = 19093.372
646600/758000 (epoch 1706), train_loss = 0.223, time/batch = 0.029, All_Time = 19094.841
646650/758000 (epoch 1706), train_loss = 0.231, time/batch = 0.028, All_Time = 19096.308
646700/758000 (epoch 1706), train_loss = 0.238, time/batch = 0.028, All_Time = 19097.769
646750/758000 (epoch 1706), train_loss = 0.266, time/batch = 0.029, All_Time = 19099.232
646800/758000 (epoch 1706), train_loss = 0.239, time/batch = 0.029, All_Time = 19100.691
646850/758000 (epoch 1706), train_loss = 0.226, time/batch = 0.030, All_Time = 19102.152
646900/758000 (epoch 1706), train_loss = 0.276, time/batch = 0.029, All_Time = 19103.617
646950/758000 (epoch 1706), train_loss = 0.240, time/batch = 0.028, All_Time = 19105.082
647000/758000 (epoch 1707), train_loss = 0.281, time/batch = 0.029, All_Time = 19106.561
model saved to NER/polyglot/model.ckpt
647050/758000 (epoch 1707), train_loss = 0.257, time/batch = 0.031, All_Time = 19108.040
647100/758000 (epoch 1707), train_loss = 0.240, time/batch = 0.027, All_Time = 19109.513
647150/758000 (epoch 1707), train_loss = 0.231, time/batch = 0.029, All_Time = 19110.969
647200/758000 (epoch 1707), train_loss = 0.217, time/batch = 0.029, All_Time = 19112.444
647250/758000 (epoch 1707), train_loss = 0.224, time/batch = 0.030, All_Time = 19113.913
647300/758000 (epoch 1707), train_loss = 0.215, time/batch = 0.029, All_Time = 19115.381
647350/758000 (epoch 1708), train_loss = 0.249, time/batch = 0.029, All_Time = 19116.848
647400/758000 (epoch 1708), train_loss = 0.211, time/batch = 0.030, All_Time = 19118.311
647450/758000 (epoch 1708), train_loss = 0.245, time/batch = 0.029, All_Time = 19119.767
647500/758000 (epoch 1708), train_loss = 0.217, time/batch = 0.028, All_Time = 19121.233
647550/758000 (epoch 1708), train_loss = 0.233, time/batch = 0.029, All_Time = 19122.701
647600/758000 (epoch 1708), train_loss = 0.228, time/batch = 0.030, All_Time = 19124.167
647650/758000 (epoch 1708), train_loss = 0.248, time/batch = 0.030, All_Time = 19125.629
647700/758000 (epoch 1708), train_loss = 0.229, time/batch = 0.030, All_Time = 19127.091
647750/758000 (epoch 1709), train_loss = 0.218, time/batch = 0.030, All_Time = 19128.566
647800/758000 (epoch 1709), train_loss = 0.237, time/batch = 0.030, All_Time = 19130.027
647850/758000 (epoch 1709), train_loss = 0.212, time/batch = 0.030, All_Time = 19131.497
647900/758000 (epoch 1709), train_loss = 0.266, time/batch = 0.029, All_Time = 19132.965
647950/758000 (epoch 1709), train_loss = 0.255, time/batch = 0.029, All_Time = 19134.431
648000/758000 (epoch 1709), train_loss = 0.232, time/batch = 0.029, All_Time = 19135.896
model saved to NER/polyglot/model.ckpt
648050/758000 (epoch 1709), train_loss = 0.262, time/batch = 0.029, All_Time = 19137.366
648100/758000 (epoch 1710), train_loss = 0.282, time/batch = 0.030, All_Time = 19138.843
648150/758000 (epoch 1710), train_loss = 0.292, time/batch = 0.029, All_Time = 19140.306
648200/758000 (epoch 1710), train_loss = 0.253, time/batch = 0.030, All_Time = 19141.765
648250/758000 (epoch 1710), train_loss = 0.222, time/batch = 0.029, All_Time = 19143.233
648300/758000 (epoch 1710), train_loss = 0.221, time/batch = 0.030, All_Time = 19144.702
648350/758000 (epoch 1710), train_loss = 0.260, time/batch = 0.031, All_Time = 19146.171
648400/758000 (epoch 1710), train_loss = 0.244, time/batch = 0.030, All_Time = 19147.634
648450/758000 (epoch 1710), train_loss = 0.247, time/batch = 0.031, All_Time = 19149.100
648500/758000 (epoch 1711), train_loss = 0.210, time/batch = 0.029, All_Time = 19150.571
648550/758000 (epoch 1711), train_loss = 0.265, time/batch = 0.029, All_Time = 19152.029
648600/758000 (epoch 1711), train_loss = 0.229, time/batch = 0.029, All_Time = 19153.517
648650/758000 (epoch 1711), train_loss = 0.232, time/batch = 0.028, All_Time = 19154.984
648700/758000 (epoch 1711), train_loss = 0.230, time/batch = 0.032, All_Time = 19156.450
648750/758000 (epoch 1711), train_loss = 0.253, time/batch = 0.031, All_Time = 19157.915
648800/758000 (epoch 1711), train_loss = 0.258, time/batch = 0.030, All_Time = 19159.379
648850/758000 (epoch 1712), train_loss = 0.196, time/batch = 0.027, All_Time = 19160.847
648900/758000 (epoch 1712), train_loss = 0.254, time/batch = 0.029, All_Time = 19162.306
648950/758000 (epoch 1712), train_loss = 0.281, time/batch = 0.030, All_Time = 19163.787
649000/758000 (epoch 1712), train_loss = 0.235, time/batch = 0.030, All_Time = 19165.249
model saved to NER/polyglot/model.ckpt
649050/758000 (epoch 1712), train_loss = 0.247, time/batch = 0.028, All_Time = 19166.722
649100/758000 (epoch 1712), train_loss = 0.251, time/batch = 0.031, All_Time = 19168.176
649150/758000 (epoch 1712), train_loss = 0.203, time/batch = 0.030, All_Time = 19169.650
649200/758000 (epoch 1712), train_loss = 0.268, time/batch = 0.030, All_Time = 19171.115
649250/758000 (epoch 1713), train_loss = 0.233, time/batch = 0.029, All_Time = 19172.583
649300/758000 (epoch 1713), train_loss = 0.241, time/batch = 0.029, All_Time = 19174.042
649350/758000 (epoch 1713), train_loss = 0.252, time/batch = 0.031, All_Time = 19175.511
649400/758000 (epoch 1713), train_loss = 0.258, time/batch = 0.031, All_Time = 19176.965
649450/758000 (epoch 1713), train_loss = 0.243, time/batch = 0.029, All_Time = 19178.432
649500/758000 (epoch 1713), train_loss = 0.243, time/batch = 0.030, All_Time = 19179.887
649550/758000 (epoch 1713), train_loss = 0.244, time/batch = 0.028, All_Time = 19181.353
649600/758000 (epoch 1713), train_loss = 0.286, time/batch = 0.029, All_Time = 19182.818
649650/758000 (epoch 1714), train_loss = 0.207, time/batch = 0.030, All_Time = 19184.285
649700/758000 (epoch 1714), train_loss = 0.244, time/batch = 0.031, All_Time = 19185.753
649750/758000 (epoch 1714), train_loss = 0.217, time/batch = 0.029, All_Time = 19187.229
649800/758000 (epoch 1714), train_loss = 0.233, time/batch = 0.029, All_Time = 19188.713
649850/758000 (epoch 1714), train_loss = 0.260, time/batch = 0.029, All_Time = 19190.160
649900/758000 (epoch 1714), train_loss = 0.253, time/batch = 0.030, All_Time = 19191.625
649950/758000 (epoch 1714), train_loss = 0.238, time/batch = 0.030, All_Time = 19193.095
650000/758000 (epoch 1715), train_loss = 0.227, time/batch = 0.028, All_Time = 19194.781
model saved to NER/polyglot/model.ckpt
650050/758000 (epoch 1715), train_loss = 0.250, time/batch = 0.030, All_Time = 19196.254
650100/758000 (epoch 1715), train_loss = 0.250, time/batch = 0.030, All_Time = 19197.708
650150/758000 (epoch 1715), train_loss = 0.223, time/batch = 0.030, All_Time = 19199.171
650200/758000 (epoch 1715), train_loss = 0.240, time/batch = 0.031, All_Time = 19200.631
650250/758000 (epoch 1715), train_loss = 0.246, time/batch = 0.031, All_Time = 19202.102
650300/758000 (epoch 1715), train_loss = 0.246, time/batch = 0.031, All_Time = 19203.565
650350/758000 (epoch 1715), train_loss = 0.257, time/batch = 0.029, All_Time = 19205.041
650400/758000 (epoch 1716), train_loss = 0.266, time/batch = 0.030, All_Time = 19206.505
650450/758000 (epoch 1716), train_loss = 0.224, time/batch = 0.029, All_Time = 19207.971
650500/758000 (epoch 1716), train_loss = 0.248, time/batch = 0.030, All_Time = 19209.429
650550/758000 (epoch 1716), train_loss = 0.227, time/batch = 0.030, All_Time = 19210.900
650600/758000 (epoch 1716), train_loss = 0.279, time/batch = 0.030, All_Time = 19212.363
650650/758000 (epoch 1716), train_loss = 0.255, time/batch = 0.028, All_Time = 19213.831
650700/758000 (epoch 1716), train_loss = 0.253, time/batch = 0.029, All_Time = 19215.300
650750/758000 (epoch 1717), train_loss = 0.244, time/batch = 0.029, All_Time = 19216.767
650800/758000 (epoch 1717), train_loss = 0.247, time/batch = 0.029, All_Time = 19218.237
650850/758000 (epoch 1717), train_loss = 0.270, time/batch = 0.030, All_Time = 19219.704
650900/758000 (epoch 1717), train_loss = 0.246, time/batch = 0.029, All_Time = 19221.189
650950/758000 (epoch 1717), train_loss = 0.237, time/batch = 0.029, All_Time = 19222.646
651000/758000 (epoch 1717), train_loss = 0.224, time/batch = 0.029, All_Time = 19224.114
model saved to NER/polyglot/model.ckpt
651050/758000 (epoch 1717), train_loss = 0.229, time/batch = 0.029, All_Time = 19225.583
651100/758000 (epoch 1717), train_loss = 0.246, time/batch = 0.029, All_Time = 19227.048
651150/758000 (epoch 1718), train_loss = 0.249, time/batch = 0.029, All_Time = 19228.519
651200/758000 (epoch 1718), train_loss = 0.264, time/batch = 0.028, All_Time = 19229.991
651250/758000 (epoch 1718), train_loss = 0.240, time/batch = 0.031, All_Time = 19231.456
651300/758000 (epoch 1718), train_loss = 0.250, time/batch = 0.030, All_Time = 19232.926
651350/758000 (epoch 1718), train_loss = 0.227, time/batch = 0.028, All_Time = 19234.390
651400/758000 (epoch 1718), train_loss = 0.217, time/batch = 0.029, All_Time = 19235.850
651450/758000 (epoch 1718), train_loss = 0.277, time/batch = 0.030, All_Time = 19237.311
651500/758000 (epoch 1718), train_loss = 0.259, time/batch = 0.029, All_Time = 19238.776
651550/758000 (epoch 1719), train_loss = 0.269, time/batch = 0.031, All_Time = 19240.240
651600/758000 (epoch 1719), train_loss = 0.296, time/batch = 0.029, All_Time = 19241.698
651650/758000 (epoch 1719), train_loss = 0.228, time/batch = 0.030, All_Time = 19243.164
651700/758000 (epoch 1719), train_loss = 0.220, time/batch = 0.029, All_Time = 19244.622
651750/758000 (epoch 1719), train_loss = 0.257, time/batch = 0.028, All_Time = 19246.089
651800/758000 (epoch 1719), train_loss = 0.255, time/batch = 0.028, All_Time = 19247.555
651850/758000 (epoch 1719), train_loss = 0.237, time/batch = 0.031, All_Time = 19249.038
651900/758000 (epoch 1720), train_loss = 0.225, time/batch = 0.028, All_Time = 19250.514
651950/758000 (epoch 1720), train_loss = 0.234, time/batch = 0.029, All_Time = 19251.968
652000/758000 (epoch 1720), train_loss = 0.243, time/batch = 0.030, All_Time = 19253.447
model saved to NER/polyglot/model.ckpt
652050/758000 (epoch 1720), train_loss = 0.234, time/batch = 0.029, All_Time = 19254.909
652100/758000 (epoch 1720), train_loss = 0.223, time/batch = 0.029, All_Time = 19256.379
652150/758000 (epoch 1720), train_loss = 0.239, time/batch = 0.029, All_Time = 19257.851
652200/758000 (epoch 1720), train_loss = 0.264, time/batch = 0.029, All_Time = 19259.311
652250/758000 (epoch 1720), train_loss = 0.244, time/batch = 0.030, All_Time = 19260.773
652300/758000 (epoch 1721), train_loss = 0.257, time/batch = 0.030, All_Time = 19262.247
652350/758000 (epoch 1721), train_loss = 0.287, time/batch = 0.028, All_Time = 19263.705
652400/758000 (epoch 1721), train_loss = 0.255, time/batch = 0.029, All_Time = 19265.173
652450/758000 (epoch 1721), train_loss = 0.248, time/batch = 0.029, All_Time = 19266.637
652500/758000 (epoch 1721), train_loss = 0.212, time/batch = 0.030, All_Time = 19268.096
652550/758000 (epoch 1721), train_loss = 0.229, time/batch = 0.030, All_Time = 19269.563
652600/758000 (epoch 1721), train_loss = 0.272, time/batch = 0.029, All_Time = 19271.016
652650/758000 (epoch 1722), train_loss = 0.249, time/batch = 0.029, All_Time = 19272.483
652700/758000 (epoch 1722), train_loss = 0.227, time/batch = 0.028, All_Time = 19273.936
652750/758000 (epoch 1722), train_loss = 0.267, time/batch = 0.030, All_Time = 19275.404
652800/758000 (epoch 1722), train_loss = 0.239, time/batch = 0.030, All_Time = 19276.860
652850/758000 (epoch 1722), train_loss = 0.247, time/batch = 0.029, All_Time = 19278.326
652900/758000 (epoch 1722), train_loss = 0.241, time/batch = 0.029, All_Time = 19279.790
652950/758000 (epoch 1722), train_loss = 0.274, time/batch = 0.030, All_Time = 19281.262
653000/758000 (epoch 1722), train_loss = 0.279, time/batch = 0.030, All_Time = 19282.727
model saved to NER/polyglot/model.ckpt
653050/758000 (epoch 1723), train_loss = 0.238, time/batch = 0.030, All_Time = 19284.195
653100/758000 (epoch 1723), train_loss = 0.248, time/batch = 0.028, All_Time = 19285.657
653150/758000 (epoch 1723), train_loss = 0.299, time/batch = 0.028, All_Time = 19287.133
653200/758000 (epoch 1723), train_loss = 0.230, time/batch = 0.029, All_Time = 19288.593
653250/758000 (epoch 1723), train_loss = 0.216, time/batch = 0.032, All_Time = 19290.121
653300/758000 (epoch 1723), train_loss = 0.244, time/batch = 0.031, All_Time = 19291.642
653350/758000 (epoch 1723), train_loss = 0.274, time/batch = 0.030, All_Time = 19293.129
653400/758000 (epoch 1724), train_loss = 0.221, time/batch = 0.029, All_Time = 19294.599
653450/758000 (epoch 1724), train_loss = 0.257, time/batch = 0.029, All_Time = 19296.072
653500/758000 (epoch 1724), train_loss = 0.241, time/batch = 0.030, All_Time = 19297.540
653550/758000 (epoch 1724), train_loss = 0.240, time/batch = 0.028, All_Time = 19299.007
653600/758000 (epoch 1724), train_loss = 0.256, time/batch = 0.029, All_Time = 19300.467
653650/758000 (epoch 1724), train_loss = 0.219, time/batch = 0.031, All_Time = 19301.936
653700/758000 (epoch 1724), train_loss = 0.224, time/batch = 0.030, All_Time = 19303.407
653750/758000 (epoch 1724), train_loss = 0.257, time/batch = 0.029, All_Time = 19304.874
653800/758000 (epoch 1725), train_loss = 0.255, time/batch = 0.030, All_Time = 19306.337
653850/758000 (epoch 1725), train_loss = 0.267, time/batch = 0.028, All_Time = 19307.804
653900/758000 (epoch 1725), train_loss = 0.269, time/batch = 0.029, All_Time = 19309.278
653950/758000 (epoch 1725), train_loss = 0.228, time/batch = 0.029, All_Time = 19310.751
654000/758000 (epoch 1725), train_loss = 0.234, time/batch = 0.030, All_Time = 19312.217
model saved to NER/polyglot/model.ckpt
654050/758000 (epoch 1725), train_loss = 0.245, time/batch = 0.029, All_Time = 19313.690
654100/758000 (epoch 1725), train_loss = 0.279, time/batch = 0.029, All_Time = 19315.154
654150/758000 (epoch 1725), train_loss = 0.240, time/batch = 0.029, All_Time = 19316.619
654200/758000 (epoch 1726), train_loss = 0.236, time/batch = 0.028, All_Time = 19318.085
654250/758000 (epoch 1726), train_loss = 0.234, time/batch = 0.030, All_Time = 19319.541
654300/758000 (epoch 1726), train_loss = 0.233, time/batch = 0.030, All_Time = 19321.010
654350/758000 (epoch 1726), train_loss = 0.276, time/batch = 0.029, All_Time = 19322.473
654400/758000 (epoch 1726), train_loss = 0.206, time/batch = 0.028, All_Time = 19323.928
654450/758000 (epoch 1726), train_loss = 0.259, time/batch = 0.030, All_Time = 19325.402
654500/758000 (epoch 1726), train_loss = 0.234, time/batch = 0.030, All_Time = 19326.874
654550/758000 (epoch 1727), train_loss = 0.245, time/batch = 0.029, All_Time = 19328.344
654600/758000 (epoch 1727), train_loss = 0.223, time/batch = 0.029, All_Time = 19329.811
654650/758000 (epoch 1727), train_loss = 0.240, time/batch = 0.030, All_Time = 19331.279
654700/758000 (epoch 1727), train_loss = 0.256, time/batch = 0.028, All_Time = 19332.739
654750/758000 (epoch 1727), train_loss = 0.214, time/batch = 0.031, All_Time = 19334.203
654800/758000 (epoch 1727), train_loss = 0.272, time/batch = 0.029, All_Time = 19335.668
654850/758000 (epoch 1727), train_loss = 0.213, time/batch = 0.029, All_Time = 19337.125
654900/758000 (epoch 1727), train_loss = 0.251, time/batch = 0.030, All_Time = 19338.586
654950/758000 (epoch 1728), train_loss = 0.247, time/batch = 0.029, All_Time = 19340.053
655000/758000 (epoch 1728), train_loss = 0.229, time/batch = 0.028, All_Time = 19341.521
model saved to NER/polyglot/model.ckpt
655050/758000 (epoch 1728), train_loss = 0.217, time/batch = 0.029, All_Time = 19342.984
655100/758000 (epoch 1728), train_loss = 0.220, time/batch = 0.029, All_Time = 19344.451
655150/758000 (epoch 1728), train_loss = 0.250, time/batch = 0.030, All_Time = 19345.907
655200/758000 (epoch 1728), train_loss = 0.207, time/batch = 0.029, All_Time = 19347.370
655250/758000 (epoch 1728), train_loss = 0.268, time/batch = 0.029, All_Time = 19348.827
655300/758000 (epoch 1729), train_loss = 0.256, time/batch = 0.029, All_Time = 19350.293
655350/758000 (epoch 1729), train_loss = 0.264, time/batch = 0.030, All_Time = 19351.760
655400/758000 (epoch 1729), train_loss = 0.284, time/batch = 0.030, All_Time = 19353.229
655450/758000 (epoch 1729), train_loss = 0.239, time/batch = 0.029, All_Time = 19354.689
655500/758000 (epoch 1729), train_loss = 0.267, time/batch = 0.029, All_Time = 19356.155
655550/758000 (epoch 1729), train_loss = 0.256, time/batch = 0.029, All_Time = 19357.619
655600/758000 (epoch 1729), train_loss = 0.236, time/batch = 0.030, All_Time = 19359.087
655650/758000 (epoch 1729), train_loss = 0.268, time/batch = 0.030, All_Time = 19360.543
655700/758000 (epoch 1730), train_loss = 0.226, time/batch = 0.029, All_Time = 19362.006
655750/758000 (epoch 1730), train_loss = 0.222, time/batch = 0.030, All_Time = 19363.480
655800/758000 (epoch 1730), train_loss = 0.261, time/batch = 0.031, All_Time = 19364.958
655850/758000 (epoch 1730), train_loss = 0.254, time/batch = 0.029, All_Time = 19366.425
655900/758000 (epoch 1730), train_loss = 0.223, time/batch = 0.029, All_Time = 19367.895
655950/758000 (epoch 1730), train_loss = 0.242, time/batch = 0.029, All_Time = 19369.363
656000/758000 (epoch 1730), train_loss = 0.251, time/batch = 0.028, All_Time = 19370.823
model saved to NER/polyglot/model.ckpt
656050/758000 (epoch 1731), train_loss = 0.192, time/batch = 0.031, All_Time = 19372.289
656100/758000 (epoch 1731), train_loss = 0.273, time/batch = 0.033, All_Time = 19373.766
656150/758000 (epoch 1731), train_loss = 0.217, time/batch = 0.029, All_Time = 19375.234
656200/758000 (epoch 1731), train_loss = 0.240, time/batch = 0.030, All_Time = 19376.701
656250/758000 (epoch 1731), train_loss = 0.221, time/batch = 0.030, All_Time = 19378.168
656300/758000 (epoch 1731), train_loss = 0.221, time/batch = 0.029, All_Time = 19379.635
656350/758000 (epoch 1731), train_loss = 0.252, time/batch = 0.029, All_Time = 19381.106
656400/758000 (epoch 1731), train_loss = 0.272, time/batch = 0.030, All_Time = 19382.572
656450/758000 (epoch 1732), train_loss = 0.222, time/batch = 0.029, All_Time = 19384.038
656500/758000 (epoch 1732), train_loss = 0.279, time/batch = 0.030, All_Time = 19385.500
656550/758000 (epoch 1732), train_loss = 0.242, time/batch = 0.028, All_Time = 19386.962
656600/758000 (epoch 1732), train_loss = 0.274, time/batch = 0.030, All_Time = 19388.422
656650/758000 (epoch 1732), train_loss = 0.262, time/batch = 0.029, All_Time = 19389.885
656700/758000 (epoch 1732), train_loss = 0.197, time/batch = 0.028, All_Time = 19391.347
656750/758000 (epoch 1732), train_loss = 0.233, time/batch = 0.030, All_Time = 19392.813
656800/758000 (epoch 1732), train_loss = 0.281, time/batch = 0.030, All_Time = 19394.290
656850/758000 (epoch 1733), train_loss = 0.246, time/batch = 0.029, All_Time = 19395.747
656900/758000 (epoch 1733), train_loss = 0.212, time/batch = 0.029, All_Time = 19397.207
656950/758000 (epoch 1733), train_loss = 0.255, time/batch = 0.029, All_Time = 19398.671
657000/758000 (epoch 1733), train_loss = 0.271, time/batch = 0.031, All_Time = 19400.133
model saved to NER/polyglot/model.ckpt
657050/758000 (epoch 1733), train_loss = 0.203, time/batch = 0.030, All_Time = 19401.596
657100/758000 (epoch 1733), train_loss = 0.226, time/batch = 0.029, All_Time = 19403.055
657150/758000 (epoch 1733), train_loss = 0.254, time/batch = 0.029, All_Time = 19404.519
657200/758000 (epoch 1734), train_loss = 0.219, time/batch = 0.029, All_Time = 19405.976
657250/758000 (epoch 1734), train_loss = 0.265, time/batch = 0.030, All_Time = 19407.443
657300/758000 (epoch 1734), train_loss = 0.227, time/batch = 0.030, All_Time = 19408.902
657350/758000 (epoch 1734), train_loss = 0.213, time/batch = 0.029, All_Time = 19410.372
657400/758000 (epoch 1734), train_loss = 0.224, time/batch = 0.029, All_Time = 19411.837
657450/758000 (epoch 1734), train_loss = 0.213, time/batch = 0.028, All_Time = 19413.294
657500/758000 (epoch 1734), train_loss = 0.230, time/batch = 0.029, All_Time = 19414.761
657550/758000 (epoch 1734), train_loss = 0.223, time/batch = 0.030, All_Time = 19416.231
657600/758000 (epoch 1735), train_loss = 0.275, time/batch = 0.030, All_Time = 19417.698
657650/758000 (epoch 1735), train_loss = 0.229, time/batch = 0.029, All_Time = 19419.165
657700/758000 (epoch 1735), train_loss = 0.270, time/batch = 0.029, All_Time = 19420.635
657750/758000 (epoch 1735), train_loss = 0.273, time/batch = 0.028, All_Time = 19422.095
657800/758000 (epoch 1735), train_loss = 0.233, time/batch = 0.030, All_Time = 19423.568
657850/758000 (epoch 1735), train_loss = 0.268, time/batch = 0.030, All_Time = 19425.025
657900/758000 (epoch 1735), train_loss = 0.280, time/batch = 0.029, All_Time = 19426.484
657950/758000 (epoch 1736), train_loss = 0.239, time/batch = 0.030, All_Time = 19427.956
658000/758000 (epoch 1736), train_loss = 0.218, time/batch = 0.030, All_Time = 19429.428
model saved to NER/polyglot/model.ckpt
658050/758000 (epoch 1736), train_loss = 0.243, time/batch = 0.030, All_Time = 19430.889
658100/758000 (epoch 1736), train_loss = 0.244, time/batch = 0.029, All_Time = 19432.349
658150/758000 (epoch 1736), train_loss = 0.243, time/batch = 0.029, All_Time = 19433.816
658200/758000 (epoch 1736), train_loss = 0.244, time/batch = 0.029, All_Time = 19435.275
658250/758000 (epoch 1736), train_loss = 0.213, time/batch = 0.028, All_Time = 19436.744
658300/758000 (epoch 1736), train_loss = 0.289, time/batch = 0.030, All_Time = 19438.204
658350/758000 (epoch 1737), train_loss = 0.237, time/batch = 0.030, All_Time = 19439.679
658400/758000 (epoch 1737), train_loss = 0.246, time/batch = 0.031, All_Time = 19441.156
658450/758000 (epoch 1737), train_loss = 0.288, time/batch = 0.029, All_Time = 19442.632
658500/758000 (epoch 1737), train_loss = 0.257, time/batch = 0.029, All_Time = 19444.102
658550/758000 (epoch 1737), train_loss = 0.218, time/batch = 0.029, All_Time = 19445.570
658600/758000 (epoch 1737), train_loss = 0.238, time/batch = 0.030, All_Time = 19447.035
658650/758000 (epoch 1737), train_loss = 0.251, time/batch = 0.030, All_Time = 19448.499
658700/758000 (epoch 1737), train_loss = 0.251, time/batch = 0.029, All_Time = 19449.968
658750/758000 (epoch 1738), train_loss = 0.252, time/batch = 0.028, All_Time = 19451.446
658800/758000 (epoch 1738), train_loss = 0.280, time/batch = 0.029, All_Time = 19452.914
658850/758000 (epoch 1738), train_loss = 0.242, time/batch = 0.030, All_Time = 19454.381
658900/758000 (epoch 1738), train_loss = 0.250, time/batch = 0.029, All_Time = 19455.840
658950/758000 (epoch 1738), train_loss = 0.239, time/batch = 0.030, All_Time = 19457.304
659000/758000 (epoch 1738), train_loss = 0.239, time/batch = 0.030, All_Time = 19458.777
model saved to NER/polyglot/model.ckpt
659050/758000 (epoch 1738), train_loss = 0.250, time/batch = 0.029, All_Time = 19460.240
659100/758000 (epoch 1739), train_loss = 0.221, time/batch = 0.031, All_Time = 19461.715
659150/758000 (epoch 1739), train_loss = 0.219, time/batch = 0.029, All_Time = 19463.182
659200/758000 (epoch 1739), train_loss = 0.246, time/batch = 0.029, All_Time = 19464.651
659250/758000 (epoch 1739), train_loss = 0.262, time/batch = 0.028, All_Time = 19466.125
659300/758000 (epoch 1739), train_loss = 0.260, time/batch = 0.029, All_Time = 19467.589
659350/758000 (epoch 1739), train_loss = 0.241, time/batch = 0.029, All_Time = 19469.048
659400/758000 (epoch 1739), train_loss = 0.210, time/batch = 0.028, All_Time = 19470.503
659450/758000 (epoch 1739), train_loss = 0.239, time/batch = 0.029, All_Time = 19471.970
659500/758000 (epoch 1740), train_loss = 0.230, time/batch = 0.028, All_Time = 19473.436
659550/758000 (epoch 1740), train_loss = 0.226, time/batch = 0.028, All_Time = 19474.899
659600/758000 (epoch 1740), train_loss = 0.264, time/batch = 0.030, All_Time = 19476.364
659650/758000 (epoch 1740), train_loss = 0.240, time/batch = 0.030, All_Time = 19477.828
659700/758000 (epoch 1740), train_loss = 0.253, time/batch = 0.029, All_Time = 19479.304
659750/758000 (epoch 1740), train_loss = 0.251, time/batch = 0.029, All_Time = 19480.768
659800/758000 (epoch 1740), train_loss = 0.248, time/batch = 0.029, All_Time = 19482.224
659850/758000 (epoch 1741), train_loss = 0.216, time/batch = 0.029, All_Time = 19483.693
659900/758000 (epoch 1741), train_loss = 0.233, time/batch = 0.030, All_Time = 19485.161
659950/758000 (epoch 1741), train_loss = 0.250, time/batch = 0.028, All_Time = 19486.622
660000/758000 (epoch 1741), train_loss = 0.241, time/batch = 0.028, All_Time = 19488.082
model saved to NER/polyglot/model.ckpt
660050/758000 (epoch 1741), train_loss = 0.243, time/batch = 0.029, All_Time = 19489.543
660100/758000 (epoch 1741), train_loss = 0.242, time/batch = 0.030, All_Time = 19491.001
660150/758000 (epoch 1741), train_loss = 0.230, time/batch = 0.029, All_Time = 19492.594
660200/758000 (epoch 1741), train_loss = 0.259, time/batch = 0.031, All_Time = 19494.118
660250/758000 (epoch 1742), train_loss = 0.250, time/batch = 0.029, All_Time = 19495.606
660300/758000 (epoch 1742), train_loss = 0.253, time/batch = 0.030, All_Time = 19497.072
660350/758000 (epoch 1742), train_loss = 0.245, time/batch = 0.028, All_Time = 19498.538
660400/758000 (epoch 1742), train_loss = 0.231, time/batch = 0.029, All_Time = 19500.007
660450/758000 (epoch 1742), train_loss = 0.228, time/batch = 0.029, All_Time = 19501.468
660500/758000 (epoch 1742), train_loss = 0.238, time/batch = 0.031, All_Time = 19502.935
660550/758000 (epoch 1742), train_loss = 0.268, time/batch = 0.030, All_Time = 19504.395
660600/758000 (epoch 1743), train_loss = 0.248, time/batch = 0.028, All_Time = 19505.854
660650/758000 (epoch 1743), train_loss = 0.280, time/batch = 0.029, All_Time = 19507.313
660700/758000 (epoch 1743), train_loss = 0.242, time/batch = 0.029, All_Time = 19508.789
660750/758000 (epoch 1743), train_loss = 0.258, time/batch = 0.028, All_Time = 19510.246
660800/758000 (epoch 1743), train_loss = 0.224, time/batch = 0.028, All_Time = 19511.720
660850/758000 (epoch 1743), train_loss = 0.243, time/batch = 0.030, All_Time = 19513.193
660900/758000 (epoch 1743), train_loss = 0.219, time/batch = 0.030, All_Time = 19514.662
660950/758000 (epoch 1743), train_loss = 0.232, time/batch = 0.030, All_Time = 19516.136
661000/758000 (epoch 1744), train_loss = 0.237, time/batch = 0.029, All_Time = 19517.600
model saved to NER/polyglot/model.ckpt
661050/758000 (epoch 1744), train_loss = 0.239, time/batch = 0.030, All_Time = 19519.060
661100/758000 (epoch 1744), train_loss = 0.293, time/batch = 0.030, All_Time = 19520.519
661150/758000 (epoch 1744), train_loss = 0.318, time/batch = 0.030, All_Time = 19521.975
661200/758000 (epoch 1744), train_loss = 0.196, time/batch = 0.028, All_Time = 19523.442
661250/758000 (epoch 1744), train_loss = 0.213, time/batch = 0.028, All_Time = 19524.912
661300/758000 (epoch 1744), train_loss = 0.250, time/batch = 0.030, All_Time = 19526.374
661350/758000 (epoch 1744), train_loss = 0.297, time/batch = 0.030, All_Time = 19527.848
661400/758000 (epoch 1745), train_loss = 0.226, time/batch = 0.030, All_Time = 19529.325
661450/758000 (epoch 1745), train_loss = 0.259, time/batch = 0.030, All_Time = 19530.803
661500/758000 (epoch 1745), train_loss = 0.223, time/batch = 0.029, All_Time = 19532.272
661550/758000 (epoch 1745), train_loss = 0.239, time/batch = 0.028, All_Time = 19533.733
661600/758000 (epoch 1745), train_loss = 0.212, time/batch = 0.029, All_Time = 19535.196
661650/758000 (epoch 1745), train_loss = 0.243, time/batch = 0.030, All_Time = 19536.662
661700/758000 (epoch 1745), train_loss = 0.215, time/batch = 0.030, All_Time = 19538.118
661750/758000 (epoch 1746), train_loss = 0.228, time/batch = 0.030, All_Time = 19539.592
661800/758000 (epoch 1746), train_loss = 0.252, time/batch = 0.030, All_Time = 19541.056
661850/758000 (epoch 1746), train_loss = 0.260, time/batch = 0.030, All_Time = 19542.522
661900/758000 (epoch 1746), train_loss = 0.228, time/batch = 0.031, All_Time = 19543.990
661950/758000 (epoch 1746), train_loss = 0.236, time/batch = 0.029, All_Time = 19545.460
662000/758000 (epoch 1746), train_loss = 0.271, time/batch = 0.028, All_Time = 19546.922
model saved to NER/polyglot/model.ckpt
662050/758000 (epoch 1746), train_loss = 0.238, time/batch = 0.030, All_Time = 19548.387
662100/758000 (epoch 1746), train_loss = 0.268, time/batch = 0.029, All_Time = 19549.856
662150/758000 (epoch 1747), train_loss = 0.248, time/batch = 0.030, All_Time = 19551.312
662200/758000 (epoch 1747), train_loss = 0.249, time/batch = 0.030, All_Time = 19552.781
662250/758000 (epoch 1747), train_loss = 0.240, time/batch = 0.029, All_Time = 19554.365
662300/758000 (epoch 1747), train_loss = 0.247, time/batch = 0.029, All_Time = 19555.867
662350/758000 (epoch 1747), train_loss = 0.235, time/batch = 0.030, All_Time = 19557.368
662400/758000 (epoch 1747), train_loss = 0.247, time/batch = 0.029, All_Time = 19558.837
662450/758000 (epoch 1747), train_loss = 0.251, time/batch = 0.029, All_Time = 19560.305
662500/758000 (epoch 1748), train_loss = 0.242, time/batch = 0.029, All_Time = 19561.772
662550/758000 (epoch 1748), train_loss = 0.276, time/batch = 0.031, All_Time = 19563.242
662600/758000 (epoch 1748), train_loss = 0.256, time/batch = 0.030, All_Time = 19564.703
662650/758000 (epoch 1748), train_loss = 0.258, time/batch = 0.029, All_Time = 19566.176
662700/758000 (epoch 1748), train_loss = 0.213, time/batch = 0.029, All_Time = 19567.637
662750/758000 (epoch 1748), train_loss = 0.237, time/batch = 0.030, All_Time = 19569.103
662800/758000 (epoch 1748), train_loss = 0.249, time/batch = 0.028, All_Time = 19570.559
662850/758000 (epoch 1748), train_loss = 0.251, time/batch = 0.030, All_Time = 19572.036
662900/758000 (epoch 1749), train_loss = 0.232, time/batch = 0.029, All_Time = 19573.515
662950/758000 (epoch 1749), train_loss = 0.255, time/batch = 0.031, All_Time = 19574.995
663000/758000 (epoch 1749), train_loss = 0.265, time/batch = 0.029, All_Time = 19576.467
model saved to NER/polyglot/model.ckpt
663050/758000 (epoch 1749), train_loss = 0.229, time/batch = 0.029, All_Time = 19577.931
663100/758000 (epoch 1749), train_loss = 0.263, time/batch = 0.029, All_Time = 19579.390
663150/758000 (epoch 1749), train_loss = 0.217, time/batch = 0.030, All_Time = 19580.858
663200/758000 (epoch 1749), train_loss = 0.248, time/batch = 0.029, All_Time = 19582.323
663250/758000 (epoch 1750), train_loss = 0.059, time/batch = 0.031, All_Time = 19583.795
663300/758000 (epoch 1750), train_loss = 0.250, time/batch = 0.030, All_Time = 19585.265
663350/758000 (epoch 1750), train_loss = 0.223, time/batch = 0.030, All_Time = 19586.739
663400/758000 (epoch 1750), train_loss = 0.250, time/batch = 0.030, All_Time = 19588.207
663450/758000 (epoch 1750), train_loss = 0.231, time/batch = 0.029, All_Time = 19589.685
663500/758000 (epoch 1750), train_loss = 0.250, time/batch = 0.029, All_Time = 19591.149
663550/758000 (epoch 1750), train_loss = 0.232, time/batch = 0.029, All_Time = 19592.622
663600/758000 (epoch 1750), train_loss = 0.230, time/batch = 0.029, All_Time = 19594.092
663650/758000 (epoch 1751), train_loss = 0.224, time/batch = 0.028, All_Time = 19595.563
663700/758000 (epoch 1751), train_loss = 0.233, time/batch = 0.029, All_Time = 19597.042
663750/758000 (epoch 1751), train_loss = 0.224, time/batch = 0.029, All_Time = 19598.515
663800/758000 (epoch 1751), train_loss = 0.262, time/batch = 0.029, All_Time = 19599.982
663850/758000 (epoch 1751), train_loss = 0.220, time/batch = 0.028, All_Time = 19601.454
663900/758000 (epoch 1751), train_loss = 0.228, time/batch = 0.029, All_Time = 19602.916
663950/758000 (epoch 1751), train_loss = 0.280, time/batch = 0.031, All_Time = 19604.391
664000/758000 (epoch 1751), train_loss = 0.272, time/batch = 0.030, All_Time = 19605.851
model saved to NER/polyglot/model.ckpt
664050/758000 (epoch 1752), train_loss = 0.230, time/batch = 0.029, All_Time = 19607.320
664100/758000 (epoch 1752), train_loss = 0.224, time/batch = 0.030, All_Time = 19608.788
664150/758000 (epoch 1752), train_loss = 0.201, time/batch = 0.030, All_Time = 19610.252
664200/758000 (epoch 1752), train_loss = 0.270, time/batch = 0.031, All_Time = 19611.717
664250/758000 (epoch 1752), train_loss = 0.259, time/batch = 0.029, All_Time = 19613.187
664300/758000 (epoch 1752), train_loss = 0.209, time/batch = 0.030, All_Time = 19614.660
664350/758000 (epoch 1752), train_loss = 0.218, time/batch = 0.029, All_Time = 19616.129
664400/758000 (epoch 1753), train_loss = 0.229, time/batch = 0.030, All_Time = 19617.596
664450/758000 (epoch 1753), train_loss = 0.283, time/batch = 0.028, All_Time = 19619.051
664500/758000 (epoch 1753), train_loss = 0.231, time/batch = 0.030, All_Time = 19620.515
664550/758000 (epoch 1753), train_loss = 0.307, time/batch = 0.029, All_Time = 19621.973
664600/758000 (epoch 1753), train_loss = 0.221, time/batch = 0.029, All_Time = 19623.433
664650/758000 (epoch 1753), train_loss = 0.208, time/batch = 0.028, All_Time = 19624.896
664700/758000 (epoch 1753), train_loss = 0.247, time/batch = 0.031, All_Time = 19626.363
664750/758000 (epoch 1753), train_loss = 0.252, time/batch = 0.030, All_Time = 19627.825
664800/758000 (epoch 1754), train_loss = 0.264, time/batch = 0.029, All_Time = 19629.303
664850/758000 (epoch 1754), train_loss = 0.229, time/batch = 0.029, All_Time = 19630.764
664900/758000 (epoch 1754), train_loss = 0.242, time/batch = 0.030, All_Time = 19632.234
664950/758000 (epoch 1754), train_loss = 0.267, time/batch = 0.030, All_Time = 19633.691
665000/758000 (epoch 1754), train_loss = 0.249, time/batch = 0.029, All_Time = 19635.164
model saved to NER/polyglot/model.ckpt
665050/758000 (epoch 1754), train_loss = 0.237, time/batch = 0.030, All_Time = 19636.636
665100/758000 (epoch 1754), train_loss = 0.276, time/batch = 0.030, All_Time = 19638.106
665150/758000 (epoch 1755), train_loss = 0.256, time/batch = 0.029, All_Time = 19639.565
665200/758000 (epoch 1755), train_loss = 0.222, time/batch = 0.029, All_Time = 19641.028
665250/758000 (epoch 1755), train_loss = 0.266, time/batch = 0.029, All_Time = 19642.486
665300/758000 (epoch 1755), train_loss = 0.216, time/batch = 0.029, All_Time = 19643.947
665350/758000 (epoch 1755), train_loss = 0.223, time/batch = 0.029, All_Time = 19645.404
665400/758000 (epoch 1755), train_loss = 0.261, time/batch = 0.029, All_Time = 19646.861
665450/758000 (epoch 1755), train_loss = 0.238, time/batch = 0.030, All_Time = 19648.325
665500/758000 (epoch 1755), train_loss = 0.264, time/batch = 0.031, All_Time = 19649.898
665550/758000 (epoch 1756), train_loss = 0.223, time/batch = 0.029, All_Time = 19651.399
665600/758000 (epoch 1756), train_loss = 0.231, time/batch = 0.029, All_Time = 19652.861
665650/758000 (epoch 1756), train_loss = 0.238, time/batch = 0.030, All_Time = 19654.330
665700/758000 (epoch 1756), train_loss = 0.266, time/batch = 0.029, All_Time = 19655.788
665750/758000 (epoch 1756), train_loss = 0.239, time/batch = 0.029, All_Time = 19657.260
665800/758000 (epoch 1756), train_loss = 0.226, time/batch = 0.030, All_Time = 19658.728
665850/758000 (epoch 1756), train_loss = 0.276, time/batch = 0.031, All_Time = 19660.197
665900/758000 (epoch 1756), train_loss = 0.240, time/batch = 0.031, All_Time = 19661.669
665950/758000 (epoch 1757), train_loss = 0.281, time/batch = 0.030, All_Time = 19663.153
666000/758000 (epoch 1757), train_loss = 0.257, time/batch = 0.030, All_Time = 19664.619
model saved to NER/polyglot/model.ckpt
666050/758000 (epoch 1757), train_loss = 0.240, time/batch = 0.028, All_Time = 19666.090
666100/758000 (epoch 1757), train_loss = 0.231, time/batch = 0.030, All_Time = 19667.563
666150/758000 (epoch 1757), train_loss = 0.217, time/batch = 0.032, All_Time = 19669.111
666200/758000 (epoch 1757), train_loss = 0.224, time/batch = 0.030, All_Time = 19670.614
666250/758000 (epoch 1757), train_loss = 0.215, time/batch = 0.030, All_Time = 19672.081
666300/758000 (epoch 1758), train_loss = 0.249, time/batch = 0.030, All_Time = 19673.543
666350/758000 (epoch 1758), train_loss = 0.211, time/batch = 0.029, All_Time = 19674.999
666400/758000 (epoch 1758), train_loss = 0.245, time/batch = 0.030, All_Time = 19676.467
666450/758000 (epoch 1758), train_loss = 0.217, time/batch = 0.029, All_Time = 19677.931
666500/758000 (epoch 1758), train_loss = 0.233, time/batch = 0.028, All_Time = 19679.397
666550/758000 (epoch 1758), train_loss = 0.228, time/batch = 0.030, All_Time = 19680.866
666600/758000 (epoch 1758), train_loss = 0.248, time/batch = 0.028, All_Time = 19682.331
666650/758000 (epoch 1758), train_loss = 0.229, time/batch = 0.028, All_Time = 19683.804
666700/758000 (epoch 1759), train_loss = 0.218, time/batch = 0.029, All_Time = 19685.273
666750/758000 (epoch 1759), train_loss = 0.237, time/batch = 0.031, All_Time = 19686.746
666800/758000 (epoch 1759), train_loss = 0.212, time/batch = 0.029, All_Time = 19688.213
666850/758000 (epoch 1759), train_loss = 0.266, time/batch = 0.029, All_Time = 19689.691
666900/758000 (epoch 1759), train_loss = 0.255, time/batch = 0.030, All_Time = 19691.151
666950/758000 (epoch 1759), train_loss = 0.232, time/batch = 0.030, All_Time = 19692.622
667000/758000 (epoch 1759), train_loss = 0.262, time/batch = 0.028, All_Time = 19694.090
model saved to NER/polyglot/model.ckpt
667050/758000 (epoch 1760), train_loss = 0.282, time/batch = 0.029, All_Time = 19695.550
667100/758000 (epoch 1760), train_loss = 0.292, time/batch = 0.029, All_Time = 19697.004
667150/758000 (epoch 1760), train_loss = 0.253, time/batch = 0.030, All_Time = 19698.471
667200/758000 (epoch 1760), train_loss = 0.222, time/batch = 0.030, All_Time = 19699.930
667250/758000 (epoch 1760), train_loss = 0.221, time/batch = 0.030, All_Time = 19701.398
667300/758000 (epoch 1760), train_loss = 0.260, time/batch = 0.030, All_Time = 19702.864
667350/758000 (epoch 1760), train_loss = 0.244, time/batch = 0.028, All_Time = 19704.332
667400/758000 (epoch 1760), train_loss = 0.247, time/batch = 0.030, All_Time = 19705.803
667450/758000 (epoch 1761), train_loss = 0.210, time/batch = 0.030, All_Time = 19707.276
667500/758000 (epoch 1761), train_loss = 0.265, time/batch = 0.030, All_Time = 19708.750
667550/758000 (epoch 1761), train_loss = 0.229, time/batch = 0.029, All_Time = 19710.221
667600/758000 (epoch 1761), train_loss = 0.232, time/batch = 0.030, All_Time = 19711.680
667650/758000 (epoch 1761), train_loss = 0.230, time/batch = 0.030, All_Time = 19713.150
667700/758000 (epoch 1761), train_loss = 0.253, time/batch = 0.030, All_Time = 19714.614
667750/758000 (epoch 1761), train_loss = 0.258, time/batch = 0.029, All_Time = 19716.077
667800/758000 (epoch 1762), train_loss = 0.196, time/batch = 0.030, All_Time = 19717.539
667850/758000 (epoch 1762), train_loss = 0.254, time/batch = 0.029, All_Time = 19719.010
667900/758000 (epoch 1762), train_loss = 0.281, time/batch = 0.028, All_Time = 19720.482
667950/758000 (epoch 1762), train_loss = 0.235, time/batch = 0.031, All_Time = 19721.952
668000/758000 (epoch 1762), train_loss = 0.247, time/batch = 0.030, All_Time = 19723.416
model saved to NER/polyglot/model.ckpt
668050/758000 (epoch 1762), train_loss = 0.251, time/batch = 0.029, All_Time = 19724.882
668100/758000 (epoch 1762), train_loss = 0.203, time/batch = 0.029, All_Time = 19726.340
668150/758000 (epoch 1762), train_loss = 0.268, time/batch = 0.028, All_Time = 19727.806
668200/758000 (epoch 1763), train_loss = 0.233, time/batch = 0.030, All_Time = 19729.271
668250/758000 (epoch 1763), train_loss = 0.241, time/batch = 0.030, All_Time = 19730.728
668300/758000 (epoch 1763), train_loss = 0.252, time/batch = 0.029, All_Time = 19732.194
668350/758000 (epoch 1763), train_loss = 0.258, time/batch = 0.031, All_Time = 19733.658
668400/758000 (epoch 1763), train_loss = 0.243, time/batch = 0.029, All_Time = 19735.124
668450/758000 (epoch 1763), train_loss = 0.243, time/batch = 0.030, All_Time = 19736.593
668500/758000 (epoch 1763), train_loss = 0.244, time/batch = 0.030, All_Time = 19738.063
668550/758000 (epoch 1763), train_loss = 0.286, time/batch = 0.029, All_Time = 19739.524
668600/758000 (epoch 1764), train_loss = 0.207, time/batch = 0.029, All_Time = 19740.982
668650/758000 (epoch 1764), train_loss = 0.244, time/batch = 0.029, All_Time = 19742.450
668700/758000 (epoch 1764), train_loss = 0.217, time/batch = 0.029, All_Time = 19743.922
668750/758000 (epoch 1764), train_loss = 0.233, time/batch = 0.029, All_Time = 19745.384
668800/758000 (epoch 1764), train_loss = 0.260, time/batch = 0.029, All_Time = 19746.850
668850/758000 (epoch 1764), train_loss = 0.253, time/batch = 0.029, All_Time = 19748.321
668900/758000 (epoch 1764), train_loss = 0.238, time/batch = 0.031, All_Time = 19749.780
668950/758000 (epoch 1765), train_loss = 0.227, time/batch = 0.030, All_Time = 19751.248
669000/758000 (epoch 1765), train_loss = 0.250, time/batch = 0.030, All_Time = 19752.711
model saved to NER/polyglot/model.ckpt
669050/758000 (epoch 1765), train_loss = 0.250, time/batch = 0.029, All_Time = 19754.185
669100/758000 (epoch 1765), train_loss = 0.223, time/batch = 0.030, All_Time = 19755.657
669150/758000 (epoch 1765), train_loss = 0.240, time/batch = 0.029, All_Time = 19757.114
669200/758000 (epoch 1765), train_loss = 0.246, time/batch = 0.030, All_Time = 19758.586
669250/758000 (epoch 1765), train_loss = 0.246, time/batch = 0.029, All_Time = 19760.066
669300/758000 (epoch 1765), train_loss = 0.257, time/batch = 0.029, All_Time = 19761.527
669350/758000 (epoch 1766), train_loss = 0.266, time/batch = 0.030, All_Time = 19762.993
669400/758000 (epoch 1766), train_loss = 0.224, time/batch = 0.031, All_Time = 19764.455
669450/758000 (epoch 1766), train_loss = 0.248, time/batch = 0.029, All_Time = 19765.918
669500/758000 (epoch 1766), train_loss = 0.227, time/batch = 0.027, All_Time = 19767.369
669550/758000 (epoch 1766), train_loss = 0.279, time/batch = 0.030, All_Time = 19768.835
669600/758000 (epoch 1766), train_loss = 0.255, time/batch = 0.028, All_Time = 19770.297
669650/758000 (epoch 1766), train_loss = 0.253, time/batch = 0.028, All_Time = 19771.758
669700/758000 (epoch 1767), train_loss = 0.244, time/batch = 0.029, All_Time = 19773.225
669750/758000 (epoch 1767), train_loss = 0.247, time/batch = 0.029, All_Time = 19774.701
669800/758000 (epoch 1767), train_loss = 0.270, time/batch = 0.030, All_Time = 19776.167
669850/758000 (epoch 1767), train_loss = 0.246, time/batch = 0.029, All_Time = 19777.623
669900/758000 (epoch 1767), train_loss = 0.237, time/batch = 0.031, All_Time = 19779.221
669950/758000 (epoch 1767), train_loss = 0.224, time/batch = 0.029, All_Time = 19780.697
670000/758000 (epoch 1767), train_loss = 0.229, time/batch = 0.029, All_Time = 19782.165
model saved to NER/polyglot/model.ckpt
670050/758000 (epoch 1767), train_loss = 0.246, time/batch = 0.031, All_Time = 19783.639
670100/758000 (epoch 1768), train_loss = 0.249, time/batch = 0.029, All_Time = 19785.107
670150/758000 (epoch 1768), train_loss = 0.264, time/batch = 0.030, All_Time = 19786.568
670200/758000 (epoch 1768), train_loss = 0.240, time/batch = 0.029, All_Time = 19788.035
670250/758000 (epoch 1768), train_loss = 0.250, time/batch = 0.030, All_Time = 19789.505
670300/758000 (epoch 1768), train_loss = 0.227, time/batch = 0.029, All_Time = 19790.975
670350/758000 (epoch 1768), train_loss = 0.217, time/batch = 0.031, All_Time = 19792.439
670400/758000 (epoch 1768), train_loss = 0.277, time/batch = 0.030, All_Time = 19793.907
670450/758000 (epoch 1768), train_loss = 0.259, time/batch = 0.029, All_Time = 19795.374
670500/758000 (epoch 1769), train_loss = 0.269, time/batch = 0.028, All_Time = 19796.836
670550/758000 (epoch 1769), train_loss = 0.296, time/batch = 0.029, All_Time = 19798.295
670600/758000 (epoch 1769), train_loss = 0.228, time/batch = 0.030, All_Time = 19799.765
670650/758000 (epoch 1769), train_loss = 0.220, time/batch = 0.028, All_Time = 19801.242
670700/758000 (epoch 1769), train_loss = 0.257, time/batch = 0.030, All_Time = 19802.713
670750/758000 (epoch 1769), train_loss = 0.255, time/batch = 0.030, All_Time = 19804.178
670800/758000 (epoch 1769), train_loss = 0.237, time/batch = 0.028, All_Time = 19805.646
670850/758000 (epoch 1770), train_loss = 0.225, time/batch = 0.030, All_Time = 19807.126
670900/758000 (epoch 1770), train_loss = 0.234, time/batch = 0.029, All_Time = 19808.591
670950/758000 (epoch 1770), train_loss = 0.243, time/batch = 0.030, All_Time = 19810.058
671000/758000 (epoch 1770), train_loss = 0.234, time/batch = 0.029, All_Time = 19811.525
model saved to NER/polyglot/model.ckpt
671050/758000 (epoch 1770), train_loss = 0.223, time/batch = 0.031, All_Time = 19813.529
671100/758000 (epoch 1770), train_loss = 0.239, time/batch = 0.031, All_Time = 19814.997
671150/758000 (epoch 1770), train_loss = 0.264, time/batch = 0.030, All_Time = 19816.462
671200/758000 (epoch 1770), train_loss = 0.244, time/batch = 0.029, All_Time = 19817.939
671250/758000 (epoch 1771), train_loss = 0.257, time/batch = 0.030, All_Time = 19819.415
671300/758000 (epoch 1771), train_loss = 0.287, time/batch = 0.030, All_Time = 19820.882
671350/758000 (epoch 1771), train_loss = 0.255, time/batch = 0.029, All_Time = 19822.345
671400/758000 (epoch 1771), train_loss = 0.248, time/batch = 0.030, All_Time = 19823.811
671450/758000 (epoch 1771), train_loss = 0.212, time/batch = 0.031, All_Time = 19825.277
671500/758000 (epoch 1771), train_loss = 0.229, time/batch = 0.031, All_Time = 19826.748
671550/758000 (epoch 1771), train_loss = 0.272, time/batch = 0.030, All_Time = 19828.206
671600/758000 (epoch 1772), train_loss = 0.249, time/batch = 0.029, All_Time = 19829.677
671650/758000 (epoch 1772), train_loss = 0.227, time/batch = 0.029, All_Time = 19831.146
671700/758000 (epoch 1772), train_loss = 0.267, time/batch = 0.031, All_Time = 19832.622
671750/758000 (epoch 1772), train_loss = 0.239, time/batch = 0.030, All_Time = 19834.095
671800/758000 (epoch 1772), train_loss = 0.247, time/batch = 0.028, All_Time = 19835.560
671850/758000 (epoch 1772), train_loss = 0.241, time/batch = 0.029, All_Time = 19837.022
671900/758000 (epoch 1772), train_loss = 0.274, time/batch = 0.030, All_Time = 19838.485
671950/758000 (epoch 1772), train_loss = 0.279, time/batch = 0.030, All_Time = 19839.956
672000/758000 (epoch 1773), train_loss = 0.238, time/batch = 0.028, All_Time = 19841.423
model saved to NER/polyglot/model.ckpt
672050/758000 (epoch 1773), train_loss = 0.248, time/batch = 0.028, All_Time = 19842.893
672100/758000 (epoch 1773), train_loss = 0.299, time/batch = 0.029, All_Time = 19844.355
672150/758000 (epoch 1773), train_loss = 0.230, time/batch = 0.029, All_Time = 19845.818
672200/758000 (epoch 1773), train_loss = 0.216, time/batch = 0.029, All_Time = 19847.292
672250/758000 (epoch 1773), train_loss = 0.244, time/batch = 0.029, All_Time = 19848.759
672300/758000 (epoch 1773), train_loss = 0.274, time/batch = 0.029, All_Time = 19850.216
672350/758000 (epoch 1774), train_loss = 0.221, time/batch = 0.029, All_Time = 19851.682
672400/758000 (epoch 1774), train_loss = 0.257, time/batch = 0.029, All_Time = 19853.156
672450/758000 (epoch 1774), train_loss = 0.241, time/batch = 0.029, All_Time = 19854.618
672500/758000 (epoch 1774), train_loss = 0.240, time/batch = 0.029, All_Time = 19856.082
672550/758000 (epoch 1774), train_loss = 0.256, time/batch = 0.030, All_Time = 19857.555
672600/758000 (epoch 1774), train_loss = 0.219, time/batch = 0.028, All_Time = 19859.022
672650/758000 (epoch 1774), train_loss = 0.224, time/batch = 0.030, All_Time = 19860.492
672700/758000 (epoch 1774), train_loss = 0.257, time/batch = 0.028, All_Time = 19861.950
672750/758000 (epoch 1775), train_loss = 0.255, time/batch = 0.029, All_Time = 19863.427
672800/758000 (epoch 1775), train_loss = 0.267, time/batch = 0.030, All_Time = 19864.895
672850/758000 (epoch 1775), train_loss = 0.269, time/batch = 0.029, All_Time = 19866.361
672900/758000 (epoch 1775), train_loss = 0.228, time/batch = 0.030, All_Time = 19867.829
672950/758000 (epoch 1775), train_loss = 0.234, time/batch = 0.029, All_Time = 19869.296
673000/758000 (epoch 1775), train_loss = 0.245, time/batch = 0.030, All_Time = 19870.774
model saved to NER/polyglot/model.ckpt
673050/758000 (epoch 1775), train_loss = 0.279, time/batch = 0.030, All_Time = 19872.232
673100/758000 (epoch 1775), train_loss = 0.240, time/batch = 0.029, All_Time = 19873.694
673150/758000 (epoch 1776), train_loss = 0.236, time/batch = 0.029, All_Time = 19875.164
673200/758000 (epoch 1776), train_loss = 0.234, time/batch = 0.030, All_Time = 19876.630
673250/758000 (epoch 1776), train_loss = 0.233, time/batch = 0.030, All_Time = 19878.102
673300/758000 (epoch 1776), train_loss = 0.276, time/batch = 0.030, All_Time = 19879.561
673350/758000 (epoch 1776), train_loss = 0.206, time/batch = 0.029, All_Time = 19881.024
673400/758000 (epoch 1776), train_loss = 0.259, time/batch = 0.029, All_Time = 19882.486
673450/758000 (epoch 1776), train_loss = 0.234, time/batch = 0.030, All_Time = 19883.952
673500/758000 (epoch 1777), train_loss = 0.245, time/batch = 0.028, All_Time = 19885.419
673550/758000 (epoch 1777), train_loss = 0.223, time/batch = 0.028, All_Time = 19886.892
673600/758000 (epoch 1777), train_loss = 0.240, time/batch = 0.028, All_Time = 19888.351
673650/758000 (epoch 1777), train_loss = 0.256, time/batch = 0.029, All_Time = 19889.814
673700/758000 (epoch 1777), train_loss = 0.214, time/batch = 0.030, All_Time = 19891.285
673750/758000 (epoch 1777), train_loss = 0.272, time/batch = 0.031, All_Time = 19892.749
673800/758000 (epoch 1777), train_loss = 0.213, time/batch = 0.029, All_Time = 19894.220
673850/758000 (epoch 1777), train_loss = 0.251, time/batch = 0.029, All_Time = 19895.682
673900/758000 (epoch 1778), train_loss = 0.247, time/batch = 0.030, All_Time = 19897.157
673950/758000 (epoch 1778), train_loss = 0.229, time/batch = 0.028, All_Time = 19898.621
674000/758000 (epoch 1778), train_loss = 0.217, time/batch = 0.029, All_Time = 19900.079
model saved to NER/polyglot/model.ckpt
674050/758000 (epoch 1778), train_loss = 0.220, time/batch = 0.029, All_Time = 19901.539
674100/758000 (epoch 1778), train_loss = 0.250, time/batch = 0.029, All_Time = 19903.001
674150/758000 (epoch 1778), train_loss = 0.207, time/batch = 0.029, All_Time = 19904.470
674200/758000 (epoch 1778), train_loss = 0.268, time/batch = 0.028, All_Time = 19905.939
674250/758000 (epoch 1779), train_loss = 0.256, time/batch = 0.029, All_Time = 19907.412
674300/758000 (epoch 1779), train_loss = 0.264, time/batch = 0.030, All_Time = 19908.870
674350/758000 (epoch 1779), train_loss = 0.284, time/batch = 0.029, All_Time = 19910.336
674400/758000 (epoch 1779), train_loss = 0.239, time/batch = 0.030, All_Time = 19911.810
674450/758000 (epoch 1779), train_loss = 0.267, time/batch = 0.029, All_Time = 19913.277
674500/758000 (epoch 1779), train_loss = 0.256, time/batch = 0.029, All_Time = 19914.743
674550/758000 (epoch 1779), train_loss = 0.236, time/batch = 0.029, All_Time = 19916.213
674600/758000 (epoch 1779), train_loss = 0.268, time/batch = 0.029, All_Time = 19917.685
674650/758000 (epoch 1780), train_loss = 0.226, time/batch = 0.031, All_Time = 19919.148
674700/758000 (epoch 1780), train_loss = 0.222, time/batch = 0.028, All_Time = 19920.621
674750/758000 (epoch 1780), train_loss = 0.261, time/batch = 0.030, All_Time = 19922.085
674800/758000 (epoch 1780), train_loss = 0.254, time/batch = 0.030, All_Time = 19923.551
674850/758000 (epoch 1780), train_loss = 0.223, time/batch = 0.030, All_Time = 19925.019
674900/758000 (epoch 1780), train_loss = 0.242, time/batch = 0.029, All_Time = 19926.486
674950/758000 (epoch 1780), train_loss = 0.251, time/batch = 0.031, All_Time = 19927.963
675000/758000 (epoch 1781), train_loss = 0.192, time/batch = 0.031, All_Time = 19929.434
model saved to NER/polyglot/model.ckpt
675050/758000 (epoch 1781), train_loss = 0.273, time/batch = 0.029, All_Time = 19930.895
675100/758000 (epoch 1781), train_loss = 0.217, time/batch = 0.030, All_Time = 19932.357
675150/758000 (epoch 1781), train_loss = 0.240, time/batch = 0.030, All_Time = 19933.827
675200/758000 (epoch 1781), train_loss = 0.221, time/batch = 0.028, All_Time = 19935.302
675250/758000 (epoch 1781), train_loss = 0.221, time/batch = 0.028, All_Time = 19936.773
675300/758000 (epoch 1781), train_loss = 0.252, time/batch = 0.029, All_Time = 19938.245
675350/758000 (epoch 1781), train_loss = 0.272, time/batch = 0.030, All_Time = 19939.709
675400/758000 (epoch 1782), train_loss = 0.222, time/batch = 0.030, All_Time = 19941.175
675450/758000 (epoch 1782), train_loss = 0.279, time/batch = 0.030, All_Time = 19942.646
675500/758000 (epoch 1782), train_loss = 0.242, time/batch = 0.029, All_Time = 19944.111
675550/758000 (epoch 1782), train_loss = 0.274, time/batch = 0.029, All_Time = 19945.573
675600/758000 (epoch 1782), train_loss = 0.262, time/batch = 0.029, All_Time = 19947.041
675650/758000 (epoch 1782), train_loss = 0.197, time/batch = 0.029, All_Time = 19948.497
675700/758000 (epoch 1782), train_loss = 0.233, time/batch = 0.030, All_Time = 19949.962
675750/758000 (epoch 1782), train_loss = 0.281, time/batch = 0.028, All_Time = 19951.434
675800/758000 (epoch 1783), train_loss = 0.246, time/batch = 0.029, All_Time = 19952.902
675850/758000 (epoch 1783), train_loss = 0.212, time/batch = 0.031, All_Time = 19954.382
675900/758000 (epoch 1783), train_loss = 0.255, time/batch = 0.029, All_Time = 19955.849
675950/758000 (epoch 1783), train_loss = 0.271, time/batch = 0.029, All_Time = 19957.305
676000/758000 (epoch 1783), train_loss = 0.203, time/batch = 0.029, All_Time = 19958.765
model saved to NER/polyglot/model.ckpt
676050/758000 (epoch 1783), train_loss = 0.226, time/batch = 0.028, All_Time = 19960.229
676100/758000 (epoch 1783), train_loss = 0.254, time/batch = 0.031, All_Time = 19961.699
676150/758000 (epoch 1784), train_loss = 0.219, time/batch = 0.029, All_Time = 19963.166
676200/758000 (epoch 1784), train_loss = 0.265, time/batch = 0.029, All_Time = 19964.637
676250/758000 (epoch 1784), train_loss = 0.227, time/batch = 0.030, All_Time = 19966.104
676300/758000 (epoch 1784), train_loss = 0.213, time/batch = 0.029, All_Time = 19967.567
676350/758000 (epoch 1784), train_loss = 0.224, time/batch = 0.028, All_Time = 19969.030
676400/758000 (epoch 1784), train_loss = 0.213, time/batch = 0.029, All_Time = 19970.485
676450/758000 (epoch 1784), train_loss = 0.230, time/batch = 0.029, All_Time = 19971.948
676500/758000 (epoch 1784), train_loss = 0.223, time/batch = 0.029, All_Time = 19973.418
676550/758000 (epoch 1785), train_loss = 0.275, time/batch = 0.031, All_Time = 19974.884
676600/758000 (epoch 1785), train_loss = 0.229, time/batch = 0.031, All_Time = 19976.351
676650/758000 (epoch 1785), train_loss = 0.270, time/batch = 0.030, All_Time = 19977.808
676700/758000 (epoch 1785), train_loss = 0.273, time/batch = 0.030, All_Time = 19979.273
676750/758000 (epoch 1785), train_loss = 0.233, time/batch = 0.029, All_Time = 19980.738
676800/758000 (epoch 1785), train_loss = 0.268, time/batch = 0.029, All_Time = 19982.196
676850/758000 (epoch 1785), train_loss = 0.280, time/batch = 0.030, All_Time = 19983.668
676900/758000 (epoch 1786), train_loss = 0.239, time/batch = 0.029, All_Time = 19985.115
676950/758000 (epoch 1786), train_loss = 0.218, time/batch = 0.030, All_Time = 19986.587
677000/758000 (epoch 1786), train_loss = 0.243, time/batch = 0.029, All_Time = 19988.049
model saved to NER/polyglot/model.ckpt
677050/758000 (epoch 1786), train_loss = 0.244, time/batch = 0.029, All_Time = 19989.524
677100/758000 (epoch 1786), train_loss = 0.243, time/batch = 0.029, All_Time = 19990.983
677150/758000 (epoch 1786), train_loss = 0.244, time/batch = 0.028, All_Time = 19992.439
677200/758000 (epoch 1786), train_loss = 0.213, time/batch = 0.030, All_Time = 19993.916
677250/758000 (epoch 1786), train_loss = 0.289, time/batch = 0.029, All_Time = 19995.390
677300/758000 (epoch 1787), train_loss = 0.237, time/batch = 0.029, All_Time = 19996.865
677350/758000 (epoch 1787), train_loss = 0.246, time/batch = 0.028, All_Time = 19998.337
677400/758000 (epoch 1787), train_loss = 0.288, time/batch = 0.029, All_Time = 19999.805
677450/758000 (epoch 1787), train_loss = 0.257, time/batch = 0.030, All_Time = 20001.271
677500/758000 (epoch 1787), train_loss = 0.218, time/batch = 0.030, All_Time = 20002.739
677550/758000 (epoch 1787), train_loss = 0.238, time/batch = 0.028, All_Time = 20004.209
677600/758000 (epoch 1787), train_loss = 0.251, time/batch = 0.029, All_Time = 20005.682
677650/758000 (epoch 1787), train_loss = 0.251, time/batch = 0.029, All_Time = 20007.148
677700/758000 (epoch 1788), train_loss = 0.252, time/batch = 0.030, All_Time = 20008.619
677750/758000 (epoch 1788), train_loss = 0.280, time/batch = 0.029, All_Time = 20010.084
677800/758000 (epoch 1788), train_loss = 0.242, time/batch = 0.030, All_Time = 20011.551
677850/758000 (epoch 1788), train_loss = 0.250, time/batch = 0.029, All_Time = 20013.013
677900/758000 (epoch 1788), train_loss = 0.239, time/batch = 0.029, All_Time = 20014.482
677950/758000 (epoch 1788), train_loss = 0.239, time/batch = 0.029, All_Time = 20015.948
678000/758000 (epoch 1788), train_loss = 0.250, time/batch = 0.028, All_Time = 20017.412
model saved to NER/polyglot/model.ckpt
678050/758000 (epoch 1789), train_loss = 0.221, time/batch = 0.029, All_Time = 20018.872
678100/758000 (epoch 1789), train_loss = 0.219, time/batch = 0.030, All_Time = 20020.343
678150/758000 (epoch 1789), train_loss = 0.246, time/batch = 0.029, All_Time = 20021.800
678200/758000 (epoch 1789), train_loss = 0.262, time/batch = 0.030, All_Time = 20023.274
678250/758000 (epoch 1789), train_loss = 0.260, time/batch = 0.029, All_Time = 20024.734
678300/758000 (epoch 1789), train_loss = 0.241, time/batch = 0.029, All_Time = 20026.253
678350/758000 (epoch 1789), train_loss = 0.210, time/batch = 0.030, All_Time = 20027.760
678400/758000 (epoch 1789), train_loss = 0.239, time/batch = 0.031, All_Time = 20029.270
678450/758000 (epoch 1790), train_loss = 0.230, time/batch = 0.029, All_Time = 20030.749
678500/758000 (epoch 1790), train_loss = 0.226, time/batch = 0.029, All_Time = 20032.208
678550/758000 (epoch 1790), train_loss = 0.264, time/batch = 0.029, All_Time = 20033.684
678600/758000 (epoch 1790), train_loss = 0.240, time/batch = 0.029, All_Time = 20035.153
678650/758000 (epoch 1790), train_loss = 0.253, time/batch = 0.028, All_Time = 20036.622
678700/758000 (epoch 1790), train_loss = 0.251, time/batch = 0.028, All_Time = 20038.093
678750/758000 (epoch 1790), train_loss = 0.248, time/batch = 0.029, All_Time = 20039.558
678800/758000 (epoch 1791), train_loss = 0.216, time/batch = 0.029, All_Time = 20041.019
678850/758000 (epoch 1791), train_loss = 0.233, time/batch = 0.028, All_Time = 20042.483
678900/758000 (epoch 1791), train_loss = 0.250, time/batch = 0.030, All_Time = 20043.946
678950/758000 (epoch 1791), train_loss = 0.241, time/batch = 0.030, All_Time = 20045.425
679000/758000 (epoch 1791), train_loss = 0.243, time/batch = 0.028, All_Time = 20046.893
model saved to NER/polyglot/model.ckpt
679050/758000 (epoch 1791), train_loss = 0.242, time/batch = 0.028, All_Time = 20048.355
679100/758000 (epoch 1791), train_loss = 0.230, time/batch = 0.028, All_Time = 20049.819
679150/758000 (epoch 1791), train_loss = 0.259, time/batch = 0.030, All_Time = 20051.291
679200/758000 (epoch 1792), train_loss = 0.250, time/batch = 0.029, All_Time = 20052.761
679250/758000 (epoch 1792), train_loss = 0.253, time/batch = 0.030, All_Time = 20054.231
679300/758000 (epoch 1792), train_loss = 0.245, time/batch = 0.030, All_Time = 20055.692
679350/758000 (epoch 1792), train_loss = 0.231, time/batch = 0.030, All_Time = 20057.154
679400/758000 (epoch 1792), train_loss = 0.228, time/batch = 0.029, All_Time = 20058.619
679450/758000 (epoch 1792), train_loss = 0.238, time/batch = 0.029, All_Time = 20060.083
679500/758000 (epoch 1792), train_loss = 0.268, time/batch = 0.028, All_Time = 20061.543
679550/758000 (epoch 1793), train_loss = 0.248, time/batch = 0.029, All_Time = 20063.009
679600/758000 (epoch 1793), train_loss = 0.280, time/batch = 0.030, All_Time = 20064.477
679650/758000 (epoch 1793), train_loss = 0.242, time/batch = 0.030, All_Time = 20065.947
679700/758000 (epoch 1793), train_loss = 0.258, time/batch = 0.031, All_Time = 20067.408
679750/758000 (epoch 1793), train_loss = 0.224, time/batch = 0.028, All_Time = 20068.871
679800/758000 (epoch 1793), train_loss = 0.243, time/batch = 0.031, All_Time = 20070.340
679850/758000 (epoch 1793), train_loss = 0.219, time/batch = 0.029, All_Time = 20071.802
679900/758000 (epoch 1793), train_loss = 0.232, time/batch = 0.030, All_Time = 20073.276
679950/758000 (epoch 1794), train_loss = 0.237, time/batch = 0.030, All_Time = 20074.747
680000/758000 (epoch 1794), train_loss = 0.239, time/batch = 0.030, All_Time = 20076.211
model saved to NER/polyglot/model.ckpt
680050/758000 (epoch 1794), train_loss = 0.293, time/batch = 0.031, All_Time = 20077.678
680100/758000 (epoch 1794), train_loss = 0.318, time/batch = 0.029, All_Time = 20079.138
680150/758000 (epoch 1794), train_loss = 0.196, time/batch = 0.029, All_Time = 20080.609
680200/758000 (epoch 1794), train_loss = 0.213, time/batch = 0.029, All_Time = 20082.076
680250/758000 (epoch 1794), train_loss = 0.250, time/batch = 0.030, All_Time = 20083.544
680300/758000 (epoch 1794), train_loss = 0.297, time/batch = 0.029, All_Time = 20085.019
680350/758000 (epoch 1795), train_loss = 0.226, time/batch = 0.028, All_Time = 20086.486
680400/758000 (epoch 1795), train_loss = 0.259, time/batch = 0.029, All_Time = 20087.957
680450/758000 (epoch 1795), train_loss = 0.223, time/batch = 0.029, All_Time = 20089.425
680500/758000 (epoch 1795), train_loss = 0.239, time/batch = 0.030, All_Time = 20090.903
680550/758000 (epoch 1795), train_loss = 0.212, time/batch = 0.028, All_Time = 20092.372
680600/758000 (epoch 1795), train_loss = 0.243, time/batch = 0.030, All_Time = 20093.838
680650/758000 (epoch 1795), train_loss = 0.215, time/batch = 0.031, All_Time = 20095.305
680700/758000 (epoch 1796), train_loss = 0.228, time/batch = 0.029, All_Time = 20096.772
680750/758000 (epoch 1796), train_loss = 0.252, time/batch = 0.029, All_Time = 20098.243
680800/758000 (epoch 1796), train_loss = 0.260, time/batch = 0.030, All_Time = 20099.703
680850/758000 (epoch 1796), train_loss = 0.228, time/batch = 0.029, All_Time = 20101.175
680900/758000 (epoch 1796), train_loss = 0.236, time/batch = 0.030, All_Time = 20102.637
680950/758000 (epoch 1796), train_loss = 0.271, time/batch = 0.030, All_Time = 20104.095
681000/758000 (epoch 1796), train_loss = 0.238, time/batch = 0.029, All_Time = 20105.569
model saved to NER/polyglot/model.ckpt
681050/758000 (epoch 1796), train_loss = 0.268, time/batch = 0.031, All_Time = 20107.046
681100/758000 (epoch 1797), train_loss = 0.248, time/batch = 0.029, All_Time = 20108.503
681150/758000 (epoch 1797), train_loss = 0.249, time/batch = 0.031, All_Time = 20109.971
681200/758000 (epoch 1797), train_loss = 0.240, time/batch = 0.030, All_Time = 20111.440
681250/758000 (epoch 1797), train_loss = 0.247, time/batch = 0.029, All_Time = 20112.912
681300/758000 (epoch 1797), train_loss = 0.235, time/batch = 0.029, All_Time = 20114.381
681350/758000 (epoch 1797), train_loss = 0.247, time/batch = 0.030, All_Time = 20115.852
681400/758000 (epoch 1797), train_loss = 0.251, time/batch = 0.029, All_Time = 20117.315
681450/758000 (epoch 1798), train_loss = 0.242, time/batch = 0.030, All_Time = 20118.772
681500/758000 (epoch 1798), train_loss = 0.276, time/batch = 0.031, All_Time = 20120.241
681550/758000 (epoch 1798), train_loss = 0.256, time/batch = 0.029, All_Time = 20121.704
681600/758000 (epoch 1798), train_loss = 0.258, time/batch = 0.030, All_Time = 20123.169
681650/758000 (epoch 1798), train_loss = 0.213, time/batch = 0.028, All_Time = 20124.628
681700/758000 (epoch 1798), train_loss = 0.237, time/batch = 0.030, All_Time = 20126.086
681750/758000 (epoch 1798), train_loss = 0.249, time/batch = 0.030, All_Time = 20127.556
681800/758000 (epoch 1798), train_loss = 0.251, time/batch = 0.030, All_Time = 20129.020
681850/758000 (epoch 1799), train_loss = 0.232, time/batch = 0.030, All_Time = 20130.490
681900/758000 (epoch 1799), train_loss = 0.255, time/batch = 0.029, All_Time = 20131.949
681950/758000 (epoch 1799), train_loss = 0.265, time/batch = 0.030, All_Time = 20133.411
682000/758000 (epoch 1799), train_loss = 0.229, time/batch = 0.029, All_Time = 20134.882
model saved to NER/polyglot/model.ckpt
682050/758000 (epoch 1799), train_loss = 0.263, time/batch = 0.029, All_Time = 20136.343
682100/758000 (epoch 1799), train_loss = 0.217, time/batch = 0.029, All_Time = 20137.799
682150/758000 (epoch 1799), train_loss = 0.248, time/batch = 0.030, All_Time = 20139.271
682200/758000 (epoch 1800), train_loss = 0.059, time/batch = 0.029, All_Time = 20140.735
682250/758000 (epoch 1800), train_loss = 0.250, time/batch = 0.029, All_Time = 20142.189
682300/758000 (epoch 1800), train_loss = 0.223, time/batch = 0.029, All_Time = 20143.653
682350/758000 (epoch 1800), train_loss = 0.250, time/batch = 0.029, All_Time = 20145.114
682400/758000 (epoch 1800), train_loss = 0.231, time/batch = 0.030, All_Time = 20146.584
682450/758000 (epoch 1800), train_loss = 0.250, time/batch = 0.028, All_Time = 20148.051
682500/758000 (epoch 1800), train_loss = 0.232, time/batch = 0.030, All_Time = 20149.505
682550/758000 (epoch 1800), train_loss = 0.230, time/batch = 0.029, All_Time = 20150.963
682600/758000 (epoch 1801), train_loss = 0.224, time/batch = 0.030, All_Time = 20152.425
682650/758000 (epoch 1801), train_loss = 0.233, time/batch = 0.029, All_Time = 20153.886
682700/758000 (epoch 1801), train_loss = 0.224, time/batch = 0.030, All_Time = 20155.339
682750/758000 (epoch 1801), train_loss = 0.262, time/batch = 0.029, All_Time = 20156.809
682800/758000 (epoch 1801), train_loss = 0.220, time/batch = 0.028, All_Time = 20158.273
682850/758000 (epoch 1801), train_loss = 0.228, time/batch = 0.030, All_Time = 20159.740
682900/758000 (epoch 1801), train_loss = 0.280, time/batch = 0.029, All_Time = 20161.197
682950/758000 (epoch 1801), train_loss = 0.272, time/batch = 0.029, All_Time = 20162.662
683000/758000 (epoch 1802), train_loss = 0.230, time/batch = 0.028, All_Time = 20164.136
model saved to NER/polyglot/model.ckpt
683050/758000 (epoch 1802), train_loss = 0.224, time/batch = 0.029, All_Time = 20165.601
683100/758000 (epoch 1802), train_loss = 0.201, time/batch = 0.030, All_Time = 20167.075
683150/758000 (epoch 1802), train_loss = 0.270, time/batch = 0.031, All_Time = 20168.545
683200/758000 (epoch 1802), train_loss = 0.259, time/batch = 0.030, All_Time = 20170.012
683250/758000 (epoch 1802), train_loss = 0.209, time/batch = 0.029, All_Time = 20171.475
683300/758000 (epoch 1802), train_loss = 0.218, time/batch = 0.030, All_Time = 20172.939
683350/758000 (epoch 1803), train_loss = 0.229, time/batch = 0.028, All_Time = 20174.405
683400/758000 (epoch 1803), train_loss = 0.283, time/batch = 0.030, All_Time = 20175.876
683450/758000 (epoch 1803), train_loss = 0.231, time/batch = 0.028, All_Time = 20177.345
683500/758000 (epoch 1803), train_loss = 0.307, time/batch = 0.028, All_Time = 20178.812
683550/758000 (epoch 1803), train_loss = 0.221, time/batch = 0.029, All_Time = 20180.280
683600/758000 (epoch 1803), train_loss = 0.208, time/batch = 0.031, All_Time = 20181.751
683650/758000 (epoch 1803), train_loss = 0.247, time/batch = 0.030, All_Time = 20183.219
683700/758000 (epoch 1803), train_loss = 0.252, time/batch = 0.030, All_Time = 20184.690
683750/758000 (epoch 1804), train_loss = 0.264, time/batch = 0.029, All_Time = 20186.153
683800/758000 (epoch 1804), train_loss = 0.229, time/batch = 0.029, All_Time = 20187.623
683850/758000 (epoch 1804), train_loss = 0.242, time/batch = 0.029, All_Time = 20189.096
683900/758000 (epoch 1804), train_loss = 0.267, time/batch = 0.030, All_Time = 20190.552
683950/758000 (epoch 1804), train_loss = 0.249, time/batch = 0.028, All_Time = 20192.018
684000/758000 (epoch 1804), train_loss = 0.237, time/batch = 0.029, All_Time = 20193.480
model saved to NER/polyglot/model.ckpt
684050/758000 (epoch 1804), train_loss = 0.276, time/batch = 0.029, All_Time = 20194.947
684100/758000 (epoch 1805), train_loss = 0.256, time/batch = 0.030, All_Time = 20196.408
684150/758000 (epoch 1805), train_loss = 0.222, time/batch = 0.028, All_Time = 20197.886
684200/758000 (epoch 1805), train_loss = 0.266, time/batch = 0.031, All_Time = 20199.355
684250/758000 (epoch 1805), train_loss = 0.216, time/batch = 0.030, All_Time = 20200.820
684300/758000 (epoch 1805), train_loss = 0.223, time/batch = 0.030, All_Time = 20202.281
684350/758000 (epoch 1805), train_loss = 0.261, time/batch = 0.029, All_Time = 20203.752
684400/758000 (epoch 1805), train_loss = 0.238, time/batch = 0.028, All_Time = 20205.218
684450/758000 (epoch 1805), train_loss = 0.264, time/batch = 0.029, All_Time = 20206.690
684500/758000 (epoch 1806), train_loss = 0.223, time/batch = 0.030, All_Time = 20208.159
684550/758000 (epoch 1806), train_loss = 0.231, time/batch = 0.030, All_Time = 20209.623
684600/758000 (epoch 1806), train_loss = 0.238, time/batch = 0.028, All_Time = 20211.098
684650/758000 (epoch 1806), train_loss = 0.266, time/batch = 0.030, All_Time = 20212.571
684700/758000 (epoch 1806), train_loss = 0.239, time/batch = 0.029, All_Time = 20214.044
684750/758000 (epoch 1806), train_loss = 0.226, time/batch = 0.030, All_Time = 20215.502
684800/758000 (epoch 1806), train_loss = 0.276, time/batch = 0.029, All_Time = 20216.958
684850/758000 (epoch 1806), train_loss = 0.240, time/batch = 0.030, All_Time = 20218.427
684900/758000 (epoch 1807), train_loss = 0.281, time/batch = 0.031, All_Time = 20219.903
684950/758000 (epoch 1807), train_loss = 0.257, time/batch = 0.028, All_Time = 20221.358
685000/758000 (epoch 1807), train_loss = 0.240, time/batch = 0.030, All_Time = 20222.817
model saved to NER/polyglot/model.ckpt
685050/758000 (epoch 1807), train_loss = 0.231, time/batch = 0.029, All_Time = 20224.288
685100/758000 (epoch 1807), train_loss = 0.217, time/batch = 0.029, All_Time = 20225.755
685150/758000 (epoch 1807), train_loss = 0.224, time/batch = 0.030, All_Time = 20227.216
685200/758000 (epoch 1807), train_loss = 0.215, time/batch = 0.029, All_Time = 20228.684
685250/758000 (epoch 1808), train_loss = 0.249, time/batch = 0.030, All_Time = 20230.161
685300/758000 (epoch 1808), train_loss = 0.211, time/batch = 0.030, All_Time = 20231.617
685350/758000 (epoch 1808), train_loss = 0.245, time/batch = 0.028, All_Time = 20233.087
685400/758000 (epoch 1808), train_loss = 0.217, time/batch = 0.028, All_Time = 20234.552
685450/758000 (epoch 1808), train_loss = 0.233, time/batch = 0.031, All_Time = 20236.022
685500/758000 (epoch 1808), train_loss = 0.228, time/batch = 0.030, All_Time = 20237.490
685550/758000 (epoch 1808), train_loss = 0.248, time/batch = 0.030, All_Time = 20238.956
685600/758000 (epoch 1808), train_loss = 0.229, time/batch = 0.029, All_Time = 20240.422
685650/758000 (epoch 1809), train_loss = 0.218, time/batch = 0.031, All_Time = 20241.899
685700/758000 (epoch 1809), train_loss = 0.237, time/batch = 0.030, All_Time = 20243.369
685750/758000 (epoch 1809), train_loss = 0.212, time/batch = 0.031, All_Time = 20244.843
685800/758000 (epoch 1809), train_loss = 0.266, time/batch = 0.028, All_Time = 20246.302
685850/758000 (epoch 1809), train_loss = 0.255, time/batch = 0.030, All_Time = 20247.762
685900/758000 (epoch 1809), train_loss = 0.232, time/batch = 0.030, All_Time = 20249.232
685950/758000 (epoch 1809), train_loss = 0.262, time/batch = 0.030, All_Time = 20250.702
686000/758000 (epoch 1810), train_loss = 0.282, time/batch = 0.029, All_Time = 20252.187
model saved to NER/polyglot/model.ckpt
686050/758000 (epoch 1810), train_loss = 0.292, time/batch = 0.029, All_Time = 20253.660
686100/758000 (epoch 1810), train_loss = 0.253, time/batch = 0.030, All_Time = 20255.131
686150/758000 (epoch 1810), train_loss = 0.222, time/batch = 0.028, All_Time = 20256.587
686200/758000 (epoch 1810), train_loss = 0.221, time/batch = 0.029, All_Time = 20258.057
686250/758000 (epoch 1810), train_loss = 0.260, time/batch = 0.028, All_Time = 20259.521
686300/758000 (epoch 1810), train_loss = 0.244, time/batch = 0.029, All_Time = 20260.984
686350/758000 (epoch 1810), train_loss = 0.247, time/batch = 0.029, All_Time = 20262.451
686400/758000 (epoch 1811), train_loss = 0.210, time/batch = 0.030, All_Time = 20263.921
686450/758000 (epoch 1811), train_loss = 0.265, time/batch = 0.031, All_Time = 20265.383
686500/758000 (epoch 1811), train_loss = 0.229, time/batch = 0.031, All_Time = 20266.849
686550/758000 (epoch 1811), train_loss = 0.232, time/batch = 0.029, All_Time = 20268.312
686600/758000 (epoch 1811), train_loss = 0.230, time/batch = 0.030, All_Time = 20269.790
686650/758000 (epoch 1811), train_loss = 0.253, time/batch = 0.030, All_Time = 20271.259
686700/758000 (epoch 1811), train_loss = 0.258, time/batch = 0.029, All_Time = 20272.722
686750/758000 (epoch 1812), train_loss = 0.196, time/batch = 0.029, All_Time = 20274.198
686800/758000 (epoch 1812), train_loss = 0.254, time/batch = 0.028, All_Time = 20275.658
686850/758000 (epoch 1812), train_loss = 0.281, time/batch = 0.029, All_Time = 20277.126
686900/758000 (epoch 1812), train_loss = 0.235, time/batch = 0.031, All_Time = 20278.595
686950/758000 (epoch 1812), train_loss = 0.247, time/batch = 0.031, All_Time = 20280.056
687000/758000 (epoch 1812), train_loss = 0.251, time/batch = 0.030, All_Time = 20281.527
model saved to NER/polyglot/model.ckpt
687050/758000 (epoch 1812), train_loss = 0.203, time/batch = 0.028, All_Time = 20282.996
687100/758000 (epoch 1812), train_loss = 0.268, time/batch = 0.028, All_Time = 20284.476
687150/758000 (epoch 1813), train_loss = 0.233, time/batch = 0.030, All_Time = 20285.948
687200/758000 (epoch 1813), train_loss = 0.241, time/batch = 0.028, All_Time = 20287.413
687250/758000 (epoch 1813), train_loss = 0.252, time/batch = 0.030, All_Time = 20288.881
687300/758000 (epoch 1813), train_loss = 0.258, time/batch = 0.029, All_Time = 20290.350
687350/758000 (epoch 1813), train_loss = 0.243, time/batch = 0.030, All_Time = 20291.812
687400/758000 (epoch 1813), train_loss = 0.243, time/batch = 0.030, All_Time = 20293.271
687450/758000 (epoch 1813), train_loss = 0.244, time/batch = 0.029, All_Time = 20294.737
687500/758000 (epoch 1813), train_loss = 0.286, time/batch = 0.030, All_Time = 20296.214
687550/758000 (epoch 1814), train_loss = 0.207, time/batch = 0.031, All_Time = 20297.677
687600/758000 (epoch 1814), train_loss = 0.244, time/batch = 0.030, All_Time = 20299.148
687650/758000 (epoch 1814), train_loss = 0.217, time/batch = 0.030, All_Time = 20300.614
687700/758000 (epoch 1814), train_loss = 0.233, time/batch = 0.028, All_Time = 20302.085
687750/758000 (epoch 1814), train_loss = 0.260, time/batch = 0.031, All_Time = 20303.554
687800/758000 (epoch 1814), train_loss = 0.253, time/batch = 0.029, All_Time = 20305.021
687850/758000 (epoch 1814), train_loss = 0.238, time/batch = 0.029, All_Time = 20306.492
687900/758000 (epoch 1815), train_loss = 0.227, time/batch = 0.029, All_Time = 20307.958
687950/758000 (epoch 1815), train_loss = 0.250, time/batch = 0.029, All_Time = 20309.426
688000/758000 (epoch 1815), train_loss = 0.250, time/batch = 0.030, All_Time = 20310.894
model saved to NER/polyglot/model.ckpt
688050/758000 (epoch 1815), train_loss = 0.223, time/batch = 0.029, All_Time = 20312.354
688100/758000 (epoch 1815), train_loss = 0.240, time/batch = 0.032, All_Time = 20313.827
688150/758000 (epoch 1815), train_loss = 0.246, time/batch = 0.029, All_Time = 20315.290
688200/758000 (epoch 1815), train_loss = 0.246, time/batch = 0.030, All_Time = 20316.762
688250/758000 (epoch 1815), train_loss = 0.257, time/batch = 0.029, All_Time = 20318.218
688300/758000 (epoch 1816), train_loss = 0.266, time/batch = 0.028, All_Time = 20319.697
688350/758000 (epoch 1816), train_loss = 0.224, time/batch = 0.030, All_Time = 20321.163
688400/758000 (epoch 1816), train_loss = 0.248, time/batch = 0.029, All_Time = 20322.631
688450/758000 (epoch 1816), train_loss = 0.227, time/batch = 0.029, All_Time = 20324.099
688500/758000 (epoch 1816), train_loss = 0.279, time/batch = 0.028, All_Time = 20325.563
688550/758000 (epoch 1816), train_loss = 0.255, time/batch = 0.031, All_Time = 20327.027
688600/758000 (epoch 1816), train_loss = 0.253, time/batch = 0.028, All_Time = 20328.493
688650/758000 (epoch 1817), train_loss = 0.244, time/batch = 0.029, All_Time = 20329.962
688700/758000 (epoch 1817), train_loss = 0.247, time/batch = 0.030, All_Time = 20331.432
688750/758000 (epoch 1817), train_loss = 0.270, time/batch = 0.029, All_Time = 20332.906
688800/758000 (epoch 1817), train_loss = 0.246, time/batch = 0.029, All_Time = 20334.373
688850/758000 (epoch 1817), train_loss = 0.237, time/batch = 0.029, All_Time = 20335.840
688900/758000 (epoch 1817), train_loss = 0.224, time/batch = 0.030, All_Time = 20337.308
688950/758000 (epoch 1817), train_loss = 0.229, time/batch = 0.029, All_Time = 20338.791
689000/758000 (epoch 1817), train_loss = 0.246, time/batch = 0.028, All_Time = 20340.259
model saved to NER/polyglot/model.ckpt
689050/758000 (epoch 1818), train_loss = 0.249, time/batch = 0.030, All_Time = 20341.739
689100/758000 (epoch 1818), train_loss = 0.264, time/batch = 0.029, All_Time = 20343.198
689150/758000 (epoch 1818), train_loss = 0.240, time/batch = 0.029, All_Time = 20344.665
689200/758000 (epoch 1818), train_loss = 0.250, time/batch = 0.028, All_Time = 20346.128
689250/758000 (epoch 1818), train_loss = 0.227, time/batch = 0.029, All_Time = 20347.598
689300/758000 (epoch 1818), train_loss = 0.217, time/batch = 0.029, All_Time = 20349.069
689350/758000 (epoch 1818), train_loss = 0.277, time/batch = 0.030, All_Time = 20350.520
689400/758000 (epoch 1818), train_loss = 0.259, time/batch = 0.030, All_Time = 20351.987
689450/758000 (epoch 1819), train_loss = 0.269, time/batch = 0.030, All_Time = 20353.472
689500/758000 (epoch 1819), train_loss = 0.296, time/batch = 0.028, All_Time = 20354.933
689550/758000 (epoch 1819), train_loss = 0.228, time/batch = 0.031, All_Time = 20356.410
689600/758000 (epoch 1819), train_loss = 0.220, time/batch = 0.030, All_Time = 20357.879
689650/758000 (epoch 1819), train_loss = 0.257, time/batch = 0.028, All_Time = 20359.345
689700/758000 (epoch 1819), train_loss = 0.255, time/batch = 0.029, All_Time = 20360.803
689750/758000 (epoch 1819), train_loss = 0.237, time/batch = 0.028, All_Time = 20362.269
689800/758000 (epoch 1820), train_loss = 0.225, time/batch = 0.030, All_Time = 20363.730
689850/758000 (epoch 1820), train_loss = 0.234, time/batch = 0.030, All_Time = 20365.198
689900/758000 (epoch 1820), train_loss = 0.243, time/batch = 0.030, All_Time = 20366.674
689950/758000 (epoch 1820), train_loss = 0.234, time/batch = 0.029, All_Time = 20368.138
690000/758000 (epoch 1820), train_loss = 0.223, time/batch = 0.029, All_Time = 20369.613
model saved to NER/polyglot/model.ckpt
690050/758000 (epoch 1820), train_loss = 0.239, time/batch = 0.028, All_Time = 20371.082
690100/758000 (epoch 1820), train_loss = 0.264, time/batch = 0.030, All_Time = 20372.540
690150/758000 (epoch 1820), train_loss = 0.244, time/batch = 0.029, All_Time = 20374.005
690200/758000 (epoch 1821), train_loss = 0.257, time/batch = 0.029, All_Time = 20375.470
690250/758000 (epoch 1821), train_loss = 0.287, time/batch = 0.029, All_Time = 20376.944
690300/758000 (epoch 1821), train_loss = 0.255, time/batch = 0.029, All_Time = 20378.402
690350/758000 (epoch 1821), train_loss = 0.248, time/batch = 0.030, All_Time = 20379.867
690400/758000 (epoch 1821), train_loss = 0.212, time/batch = 0.030, All_Time = 20381.339
690450/758000 (epoch 1821), train_loss = 0.229, time/batch = 0.030, All_Time = 20382.803
690500/758000 (epoch 1821), train_loss = 0.272, time/batch = 0.029, All_Time = 20384.262
690550/758000 (epoch 1822), train_loss = 0.249, time/batch = 0.030, All_Time = 20385.743
690600/758000 (epoch 1822), train_loss = 0.227, time/batch = 0.030, All_Time = 20387.207
690650/758000 (epoch 1822), train_loss = 0.267, time/batch = 0.029, All_Time = 20388.661
690700/758000 (epoch 1822), train_loss = 0.239, time/batch = 0.030, All_Time = 20390.135
690750/758000 (epoch 1822), train_loss = 0.247, time/batch = 0.028, All_Time = 20391.592
690800/758000 (epoch 1822), train_loss = 0.241, time/batch = 0.029, All_Time = 20393.053
690850/758000 (epoch 1822), train_loss = 0.274, time/batch = 0.030, All_Time = 20394.514
690900/758000 (epoch 1822), train_loss = 0.279, time/batch = 0.028, All_Time = 20395.978
690950/758000 (epoch 1823), train_loss = 0.238, time/batch = 0.031, All_Time = 20397.457
691000/758000 (epoch 1823), train_loss = 0.248, time/batch = 0.029, All_Time = 20398.922
model saved to NER/polyglot/model.ckpt
691050/758000 (epoch 1823), train_loss = 0.299, time/batch = 0.030, All_Time = 20400.395
691100/758000 (epoch 1823), train_loss = 0.230, time/batch = 0.029, All_Time = 20401.857
691150/758000 (epoch 1823), train_loss = 0.216, time/batch = 0.028, All_Time = 20403.327
691200/758000 (epoch 1823), train_loss = 0.244, time/batch = 0.030, All_Time = 20404.806
691250/758000 (epoch 1823), train_loss = 0.274, time/batch = 0.029, All_Time = 20406.273
691300/758000 (epoch 1824), train_loss = 0.221, time/batch = 0.029, All_Time = 20407.732
691350/758000 (epoch 1824), train_loss = 0.257, time/batch = 0.029, All_Time = 20409.198
691400/758000 (epoch 1824), train_loss = 0.241, time/batch = 0.030, All_Time = 20410.660
691450/758000 (epoch 1824), train_loss = 0.240, time/batch = 0.029, All_Time = 20412.135
691500/758000 (epoch 1824), train_loss = 0.256, time/batch = 0.029, All_Time = 20413.592
691550/758000 (epoch 1824), train_loss = 0.219, time/batch = 0.030, All_Time = 20415.066
691600/758000 (epoch 1824), train_loss = 0.224, time/batch = 0.028, All_Time = 20416.537
691650/758000 (epoch 1824), train_loss = 0.257, time/batch = 0.029, All_Time = 20418.002
691700/758000 (epoch 1825), train_loss = 0.255, time/batch = 0.029, All_Time = 20419.488
691750/758000 (epoch 1825), train_loss = 0.267, time/batch = 0.030, All_Time = 20420.957
691800/758000 (epoch 1825), train_loss = 0.269, time/batch = 0.030, All_Time = 20422.422
691850/758000 (epoch 1825), train_loss = 0.228, time/batch = 0.028, All_Time = 20423.882
691900/758000 (epoch 1825), train_loss = 0.234, time/batch = 0.029, All_Time = 20425.360
691950/758000 (epoch 1825), train_loss = 0.245, time/batch = 0.030, All_Time = 20426.825
692000/758000 (epoch 1825), train_loss = 0.279, time/batch = 0.029, All_Time = 20428.285
model saved to NER/polyglot/model.ckpt
692050/758000 (epoch 1825), train_loss = 0.240, time/batch = 0.029, All_Time = 20429.748
692100/758000 (epoch 1826), train_loss = 0.236, time/batch = 0.030, All_Time = 20431.227
692150/758000 (epoch 1826), train_loss = 0.234, time/batch = 0.029, All_Time = 20432.695
692200/758000 (epoch 1826), train_loss = 0.233, time/batch = 0.029, All_Time = 20434.173
692250/758000 (epoch 1826), train_loss = 0.276, time/batch = 0.029, All_Time = 20435.640
692300/758000 (epoch 1826), train_loss = 0.206, time/batch = 0.030, All_Time = 20437.104
692350/758000 (epoch 1826), train_loss = 0.259, time/batch = 0.029, All_Time = 20438.570
692400/758000 (epoch 1826), train_loss = 0.234, time/batch = 0.031, All_Time = 20440.039
692450/758000 (epoch 1827), train_loss = 0.245, time/batch = 0.029, All_Time = 20441.514
692500/758000 (epoch 1827), train_loss = 0.223, time/batch = 0.030, All_Time = 20442.975
692550/758000 (epoch 1827), train_loss = 0.240, time/batch = 0.028, All_Time = 20444.444
692600/758000 (epoch 1827), train_loss = 0.256, time/batch = 0.030, All_Time = 20445.914
692650/758000 (epoch 1827), train_loss = 0.214, time/batch = 0.028, All_Time = 20447.377
692700/758000 (epoch 1827), train_loss = 0.272, time/batch = 0.028, All_Time = 20448.854
692750/758000 (epoch 1827), train_loss = 0.213, time/batch = 0.029, All_Time = 20450.327
692800/758000 (epoch 1827), train_loss = 0.251, time/batch = 0.030, All_Time = 20451.798
692850/758000 (epoch 1828), train_loss = 0.247, time/batch = 0.028, All_Time = 20453.293
692900/758000 (epoch 1828), train_loss = 0.229, time/batch = 0.030, All_Time = 20454.772
692950/758000 (epoch 1828), train_loss = 0.217, time/batch = 0.029, All_Time = 20456.241
693000/758000 (epoch 1828), train_loss = 0.220, time/batch = 0.029, All_Time = 20457.706
model saved to NER/polyglot/model.ckpt
693050/758000 (epoch 1828), train_loss = 0.250, time/batch = 0.029, All_Time = 20459.177
693100/758000 (epoch 1828), train_loss = 0.207, time/batch = 0.029, All_Time = 20460.635
693150/758000 (epoch 1828), train_loss = 0.268, time/batch = 0.028, All_Time = 20462.099
693200/758000 (epoch 1829), train_loss = 0.256, time/batch = 0.030, All_Time = 20463.568
693250/758000 (epoch 1829), train_loss = 0.264, time/batch = 0.029, All_Time = 20465.036
693300/758000 (epoch 1829), train_loss = 0.284, time/batch = 0.029, All_Time = 20466.510
693350/758000 (epoch 1829), train_loss = 0.239, time/batch = 0.030, All_Time = 20467.975
693400/758000 (epoch 1829), train_loss = 0.267, time/batch = 0.029, All_Time = 20469.439
693450/758000 (epoch 1829), train_loss = 0.256, time/batch = 0.030, All_Time = 20470.906
693500/758000 (epoch 1829), train_loss = 0.236, time/batch = 0.029, All_Time = 20472.370
693550/758000 (epoch 1829), train_loss = 0.268, time/batch = 0.031, All_Time = 20473.830
693600/758000 (epoch 1830), train_loss = 0.226, time/batch = 0.029, All_Time = 20475.306
693650/758000 (epoch 1830), train_loss = 0.222, time/batch = 0.029, All_Time = 20476.767
693700/758000 (epoch 1830), train_loss = 0.261, time/batch = 0.030, All_Time = 20478.235
693750/758000 (epoch 1830), train_loss = 0.254, time/batch = 0.029, All_Time = 20479.700
693800/758000 (epoch 1830), train_loss = 0.223, time/batch = 0.030, All_Time = 20481.173
693850/758000 (epoch 1830), train_loss = 0.242, time/batch = 0.029, All_Time = 20482.642
693900/758000 (epoch 1830), train_loss = 0.251, time/batch = 0.029, All_Time = 20484.121
693950/758000 (epoch 1831), train_loss = 0.192, time/batch = 0.030, All_Time = 20485.588
694000/758000 (epoch 1831), train_loss = 0.273, time/batch = 0.029, All_Time = 20487.057
model saved to NER/polyglot/model.ckpt
694050/758000 (epoch 1831), train_loss = 0.217, time/batch = 0.030, All_Time = 20488.534
694100/758000 (epoch 1831), train_loss = 0.240, time/batch = 0.029, All_Time = 20490.006
694150/758000 (epoch 1831), train_loss = 0.221, time/batch = 0.029, All_Time = 20491.469
694200/758000 (epoch 1831), train_loss = 0.221, time/batch = 0.029, All_Time = 20492.938
694250/758000 (epoch 1831), train_loss = 0.252, time/batch = 0.030, All_Time = 20494.400
694300/758000 (epoch 1831), train_loss = 0.272, time/batch = 0.029, All_Time = 20495.863
694350/758000 (epoch 1832), train_loss = 0.222, time/batch = 0.028, All_Time = 20497.334
694400/758000 (epoch 1832), train_loss = 0.279, time/batch = 0.029, All_Time = 20498.790
694450/758000 (epoch 1832), train_loss = 0.242, time/batch = 0.030, All_Time = 20500.247
694500/758000 (epoch 1832), train_loss = 0.274, time/batch = 0.028, All_Time = 20501.709
694550/758000 (epoch 1832), train_loss = 0.262, time/batch = 0.028, All_Time = 20503.171
694600/758000 (epoch 1832), train_loss = 0.197, time/batch = 0.030, All_Time = 20504.644
694650/758000 (epoch 1832), train_loss = 0.233, time/batch = 0.028, All_Time = 20506.106
694700/758000 (epoch 1832), train_loss = 0.281, time/batch = 0.029, All_Time = 20507.566
694750/758000 (epoch 1833), train_loss = 0.246, time/batch = 0.030, All_Time = 20509.037
694800/758000 (epoch 1833), train_loss = 0.212, time/batch = 0.029, All_Time = 20510.504
694850/758000 (epoch 1833), train_loss = 0.255, time/batch = 0.029, All_Time = 20511.971
694900/758000 (epoch 1833), train_loss = 0.271, time/batch = 0.031, All_Time = 20513.442
694950/758000 (epoch 1833), train_loss = 0.203, time/batch = 0.030, All_Time = 20514.918
695000/758000 (epoch 1833), train_loss = 0.226, time/batch = 0.029, All_Time = 20516.383
model saved to NER/polyglot/model.ckpt
695050/758000 (epoch 1833), train_loss = 0.254, time/batch = 0.029, All_Time = 20517.849
695100/758000 (epoch 1834), train_loss = 0.219, time/batch = 0.030, All_Time = 20519.314
695150/758000 (epoch 1834), train_loss = 0.265, time/batch = 0.030, All_Time = 20520.790
695200/758000 (epoch 1834), train_loss = 0.227, time/batch = 0.030, All_Time = 20522.256
695250/758000 (epoch 1834), train_loss = 0.213, time/batch = 0.029, All_Time = 20523.722
695300/758000 (epoch 1834), train_loss = 0.224, time/batch = 0.028, All_Time = 20525.199
695350/758000 (epoch 1834), train_loss = 0.213, time/batch = 0.030, All_Time = 20526.667
695400/758000 (epoch 1834), train_loss = 0.230, time/batch = 0.030, All_Time = 20528.138
695450/758000 (epoch 1834), train_loss = 0.223, time/batch = 0.028, All_Time = 20529.613
695500/758000 (epoch 1835), train_loss = 0.275, time/batch = 0.028, All_Time = 20531.082
695550/758000 (epoch 1835), train_loss = 0.229, time/batch = 0.028, All_Time = 20532.548
695600/758000 (epoch 1835), train_loss = 0.270, time/batch = 0.029, All_Time = 20534.016
695650/758000 (epoch 1835), train_loss = 0.273, time/batch = 0.029, All_Time = 20535.478
695700/758000 (epoch 1835), train_loss = 0.233, time/batch = 0.030, All_Time = 20536.949
695750/758000 (epoch 1835), train_loss = 0.268, time/batch = 0.030, All_Time = 20538.421
695800/758000 (epoch 1835), train_loss = 0.280, time/batch = 0.030, All_Time = 20539.879
695850/758000 (epoch 1836), train_loss = 0.239, time/batch = 0.028, All_Time = 20541.352
695900/758000 (epoch 1836), train_loss = 0.218, time/batch = 0.029, All_Time = 20542.818
695950/758000 (epoch 1836), train_loss = 0.243, time/batch = 0.030, All_Time = 20544.283
696000/758000 (epoch 1836), train_loss = 0.244, time/batch = 0.030, All_Time = 20545.746
model saved to NER/polyglot/model.ckpt
696050/758000 (epoch 1836), train_loss = 0.243, time/batch = 0.028, All_Time = 20547.217
696100/758000 (epoch 1836), train_loss = 0.244, time/batch = 0.031, All_Time = 20548.691
696150/758000 (epoch 1836), train_loss = 0.213, time/batch = 0.030, All_Time = 20550.156
696200/758000 (epoch 1836), train_loss = 0.289, time/batch = 0.029, All_Time = 20551.631
696250/758000 (epoch 1837), train_loss = 0.237, time/batch = 0.029, All_Time = 20553.102
696300/758000 (epoch 1837), train_loss = 0.246, time/batch = 0.029, All_Time = 20554.572
696350/758000 (epoch 1837), train_loss = 0.288, time/batch = 0.028, All_Time = 20556.039
696400/758000 (epoch 1837), train_loss = 0.257, time/batch = 0.030, All_Time = 20557.507
696450/758000 (epoch 1837), train_loss = 0.218, time/batch = 0.030, All_Time = 20558.974
696500/758000 (epoch 1837), train_loss = 0.238, time/batch = 0.028, All_Time = 20560.443
696550/758000 (epoch 1837), train_loss = 0.251, time/batch = 0.029, All_Time = 20561.909
696600/758000 (epoch 1837), train_loss = 0.251, time/batch = 0.029, All_Time = 20563.373
696650/758000 (epoch 1838), train_loss = 0.252, time/batch = 0.030, All_Time = 20564.845
696700/758000 (epoch 1838), train_loss = 0.280, time/batch = 0.029, All_Time = 20566.320
696750/758000 (epoch 1838), train_loss = 0.242, time/batch = 0.029, All_Time = 20567.783
696800/758000 (epoch 1838), train_loss = 0.250, time/batch = 0.028, All_Time = 20569.249
696850/758000 (epoch 1838), train_loss = 0.239, time/batch = 0.030, All_Time = 20570.720
696900/758000 (epoch 1838), train_loss = 0.239, time/batch = 0.031, All_Time = 20572.191
696950/758000 (epoch 1838), train_loss = 0.250, time/batch = 0.028, All_Time = 20573.656
697000/758000 (epoch 1839), train_loss = 0.221, time/batch = 0.029, All_Time = 20575.126
model saved to NER/polyglot/model.ckpt
697050/758000 (epoch 1839), train_loss = 0.219, time/batch = 0.030, All_Time = 20576.589
697100/758000 (epoch 1839), train_loss = 0.246, time/batch = 0.030, All_Time = 20578.054
697150/758000 (epoch 1839), train_loss = 0.262, time/batch = 0.029, All_Time = 20579.530
697200/758000 (epoch 1839), train_loss = 0.260, time/batch = 0.030, All_Time = 20581.002
697250/758000 (epoch 1839), train_loss = 0.241, time/batch = 0.030, All_Time = 20582.468
697300/758000 (epoch 1839), train_loss = 0.210, time/batch = 0.031, All_Time = 20583.943
697350/758000 (epoch 1839), train_loss = 0.239, time/batch = 0.028, All_Time = 20585.408
697400/758000 (epoch 1840), train_loss = 0.230, time/batch = 0.028, All_Time = 20586.878
697450/758000 (epoch 1840), train_loss = 0.226, time/batch = 0.030, All_Time = 20588.344
697500/758000 (epoch 1840), train_loss = 0.264, time/batch = 0.029, All_Time = 20589.810
697550/758000 (epoch 1840), train_loss = 0.240, time/batch = 0.029, All_Time = 20591.283
697600/758000 (epoch 1840), train_loss = 0.253, time/batch = 0.030, All_Time = 20592.756
697650/758000 (epoch 1840), train_loss = 0.251, time/batch = 0.030, All_Time = 20594.228
697700/758000 (epoch 1840), train_loss = 0.248, time/batch = 0.031, All_Time = 20595.690
697750/758000 (epoch 1841), train_loss = 0.216, time/batch = 0.029, All_Time = 20597.151
697800/758000 (epoch 1841), train_loss = 0.233, time/batch = 0.029, All_Time = 20598.619
697850/758000 (epoch 1841), train_loss = 0.250, time/batch = 0.031, All_Time = 20600.085
697900/758000 (epoch 1841), train_loss = 0.241, time/batch = 0.028, All_Time = 20601.549
697950/758000 (epoch 1841), train_loss = 0.243, time/batch = 0.029, All_Time = 20603.015
698000/758000 (epoch 1841), train_loss = 0.242, time/batch = 0.029, All_Time = 20604.480
model saved to NER/polyglot/model.ckpt
698050/758000 (epoch 1841), train_loss = 0.230, time/batch = 0.029, All_Time = 20605.954
698100/758000 (epoch 1841), train_loss = 0.259, time/batch = 0.028, All_Time = 20607.421
698150/758000 (epoch 1842), train_loss = 0.250, time/batch = 0.031, All_Time = 20608.892
698200/758000 (epoch 1842), train_loss = 0.253, time/batch = 0.028, All_Time = 20610.347
698250/758000 (epoch 1842), train_loss = 0.245, time/batch = 0.030, All_Time = 20611.815
698300/758000 (epoch 1842), train_loss = 0.231, time/batch = 0.030, All_Time = 20613.282
698350/758000 (epoch 1842), train_loss = 0.228, time/batch = 0.028, All_Time = 20614.751
698400/758000 (epoch 1842), train_loss = 0.238, time/batch = 0.030, All_Time = 20616.217
698450/758000 (epoch 1842), train_loss = 0.268, time/batch = 0.029, All_Time = 20617.682
698500/758000 (epoch 1843), train_loss = 0.248, time/batch = 0.029, All_Time = 20619.144
698550/758000 (epoch 1843), train_loss = 0.280, time/batch = 0.030, All_Time = 20620.619
698600/758000 (epoch 1843), train_loss = 0.242, time/batch = 0.029, All_Time = 20622.091
698650/758000 (epoch 1843), train_loss = 0.258, time/batch = 0.029, All_Time = 20623.567
698700/758000 (epoch 1843), train_loss = 0.224, time/batch = 0.030, All_Time = 20625.034
698750/758000 (epoch 1843), train_loss = 0.243, time/batch = 0.029, All_Time = 20626.493
698800/758000 (epoch 1843), train_loss = 0.219, time/batch = 0.029, All_Time = 20627.962
698850/758000 (epoch 1843), train_loss = 0.232, time/batch = 0.031, All_Time = 20629.432
698900/758000 (epoch 1844), train_loss = 0.237, time/batch = 0.028, All_Time = 20630.904
698950/758000 (epoch 1844), train_loss = 0.239, time/batch = 0.030, All_Time = 20632.368
699000/758000 (epoch 1844), train_loss = 0.293, time/batch = 0.029, All_Time = 20633.836
model saved to NER/polyglot/model.ckpt
699050/758000 (epoch 1844), train_loss = 0.318, time/batch = 0.031, All_Time = 20635.317
699100/758000 (epoch 1844), train_loss = 0.196, time/batch = 0.029, All_Time = 20636.804
699150/758000 (epoch 1844), train_loss = 0.213, time/batch = 0.029, All_Time = 20638.272
699200/758000 (epoch 1844), train_loss = 0.250, time/batch = 0.029, All_Time = 20639.732
699250/758000 (epoch 1844), train_loss = 0.297, time/batch = 0.030, All_Time = 20641.195
699300/758000 (epoch 1845), train_loss = 0.226, time/batch = 0.030, All_Time = 20642.669
699350/758000 (epoch 1845), train_loss = 0.259, time/batch = 0.031, All_Time = 20644.134
699400/758000 (epoch 1845), train_loss = 0.223, time/batch = 0.028, All_Time = 20645.601
699450/758000 (epoch 1845), train_loss = 0.239, time/batch = 0.029, All_Time = 20647.060
699500/758000 (epoch 1845), train_loss = 0.212, time/batch = 0.029, All_Time = 20648.530
699550/758000 (epoch 1845), train_loss = 0.243, time/batch = 0.030, All_Time = 20649.997
699600/758000 (epoch 1845), train_loss = 0.215, time/batch = 0.029, All_Time = 20651.457
699650/758000 (epoch 1846), train_loss = 0.228, time/batch = 0.029, All_Time = 20652.933
699700/758000 (epoch 1846), train_loss = 0.252, time/batch = 0.029, All_Time = 20654.414
699750/758000 (epoch 1846), train_loss = 0.260, time/batch = 0.029, All_Time = 20655.881
699800/758000 (epoch 1846), train_loss = 0.228, time/batch = 0.031, All_Time = 20657.344
699850/758000 (epoch 1846), train_loss = 0.236, time/batch = 0.029, All_Time = 20658.801
699900/758000 (epoch 1846), train_loss = 0.271, time/batch = 0.029, All_Time = 20660.264
699950/758000 (epoch 1846), train_loss = 0.238, time/batch = 0.030, All_Time = 20661.734
700000/758000 (epoch 1846), train_loss = 0.268, time/batch = 0.029, All_Time = 20663.200
model saved to NER/polyglot/model.ckpt
700050/758000 (epoch 1847), train_loss = 0.248, time/batch = 0.030, All_Time = 20664.680
700100/758000 (epoch 1847), train_loss = 0.249, time/batch = 0.030, All_Time = 20666.147
700150/758000 (epoch 1847), train_loss = 0.240, time/batch = 0.030, All_Time = 20667.623
700200/758000 (epoch 1847), train_loss = 0.247, time/batch = 0.029, All_Time = 20669.090
700250/758000 (epoch 1847), train_loss = 0.235, time/batch = 0.030, All_Time = 20670.553
700300/758000 (epoch 1847), train_loss = 0.247, time/batch = 0.030, All_Time = 20672.021
700350/758000 (epoch 1847), train_loss = 0.251, time/batch = 0.030, All_Time = 20673.480
700400/758000 (epoch 1848), train_loss = 0.242, time/batch = 0.028, All_Time = 20674.934
700450/758000 (epoch 1848), train_loss = 0.276, time/batch = 0.029, All_Time = 20676.392
700500/758000 (epoch 1848), train_loss = 0.256, time/batch = 0.030, All_Time = 20677.867
700550/758000 (epoch 1848), train_loss = 0.258, time/batch = 0.029, All_Time = 20679.336
700600/758000 (epoch 1848), train_loss = 0.213, time/batch = 0.028, All_Time = 20680.795
700650/758000 (epoch 1848), train_loss = 0.237, time/batch = 0.031, All_Time = 20682.256
700700/758000 (epoch 1848), train_loss = 0.249, time/batch = 0.029, All_Time = 20683.710
700750/758000 (epoch 1848), train_loss = 0.251, time/batch = 0.029, All_Time = 20685.182
700800/758000 (epoch 1849), train_loss = 0.232, time/batch = 0.030, All_Time = 20686.647
700850/758000 (epoch 1849), train_loss = 0.255, time/batch = 0.030, All_Time = 20688.113
700900/758000 (epoch 1849), train_loss = 0.265, time/batch = 0.029, All_Time = 20689.572
700950/758000 (epoch 1849), train_loss = 0.229, time/batch = 0.029, All_Time = 20691.029
701000/758000 (epoch 1849), train_loss = 0.263, time/batch = 0.030, All_Time = 20692.502
model saved to NER/polyglot/model.ckpt
701050/758000 (epoch 1849), train_loss = 0.217, time/batch = 0.031, All_Time = 20693.971
701100/758000 (epoch 1849), train_loss = 0.248, time/batch = 0.030, All_Time = 20695.447
701150/758000 (epoch 1850), train_loss = 0.059, time/batch = 0.029, All_Time = 20696.916
701200/758000 (epoch 1850), train_loss = 0.250, time/batch = 0.028, All_Time = 20698.382
701250/758000 (epoch 1850), train_loss = 0.223, time/batch = 0.030, All_Time = 20699.844
701300/758000 (epoch 1850), train_loss = 0.250, time/batch = 0.029, All_Time = 20701.312
701350/758000 (epoch 1850), train_loss = 0.231, time/batch = 0.029, All_Time = 20702.773
701400/758000 (epoch 1850), train_loss = 0.250, time/batch = 0.029, All_Time = 20704.239
701450/758000 (epoch 1850), train_loss = 0.232, time/batch = 0.029, All_Time = 20705.704
701500/758000 (epoch 1850), train_loss = 0.230, time/batch = 0.031, All_Time = 20707.166
701550/758000 (epoch 1851), train_loss = 0.224, time/batch = 0.029, All_Time = 20708.622
701600/758000 (epoch 1851), train_loss = 0.233, time/batch = 0.029, All_Time = 20710.088
701650/758000 (epoch 1851), train_loss = 0.224, time/batch = 0.030, All_Time = 20711.555
701700/758000 (epoch 1851), train_loss = 0.262, time/batch = 0.029, All_Time = 20713.019
701750/758000 (epoch 1851), train_loss = 0.220, time/batch = 0.030, All_Time = 20714.490
701800/758000 (epoch 1851), train_loss = 0.228, time/batch = 0.029, All_Time = 20715.959
701850/758000 (epoch 1851), train_loss = 0.280, time/batch = 0.029, All_Time = 20717.428
701900/758000 (epoch 1851), train_loss = 0.272, time/batch = 0.029, All_Time = 20718.895
701950/758000 (epoch 1852), train_loss = 0.230, time/batch = 0.029, All_Time = 20720.364
702000/758000 (epoch 1852), train_loss = 0.224, time/batch = 0.030, All_Time = 20721.833
model saved to NER/polyglot/model.ckpt
702050/758000 (epoch 1852), train_loss = 0.201, time/batch = 0.029, All_Time = 20723.307
702100/758000 (epoch 1852), train_loss = 0.270, time/batch = 0.030, All_Time = 20724.780
702150/758000 (epoch 1852), train_loss = 0.259, time/batch = 0.030, All_Time = 20726.251
702200/758000 (epoch 1852), train_loss = 0.209, time/batch = 0.029, All_Time = 20727.725
702250/758000 (epoch 1852), train_loss = 0.218, time/batch = 0.029, All_Time = 20729.197
702300/758000 (epoch 1853), train_loss = 0.229, time/batch = 0.030, All_Time = 20730.661
702350/758000 (epoch 1853), train_loss = 0.283, time/batch = 0.029, All_Time = 20732.131
702400/758000 (epoch 1853), train_loss = 0.231, time/batch = 0.028, All_Time = 20733.601
702450/758000 (epoch 1853), train_loss = 0.307, time/batch = 0.028, All_Time = 20735.065
702500/758000 (epoch 1853), train_loss = 0.221, time/batch = 0.029, All_Time = 20736.540
702550/758000 (epoch 1853), train_loss = 0.208, time/batch = 0.030, All_Time = 20738.018
702600/758000 (epoch 1853), train_loss = 0.247, time/batch = 0.031, All_Time = 20739.489
702650/758000 (epoch 1853), train_loss = 0.252, time/batch = 0.028, All_Time = 20740.960
702700/758000 (epoch 1854), train_loss = 0.264, time/batch = 0.028, All_Time = 20742.422
702750/758000 (epoch 1854), train_loss = 0.229, time/batch = 0.030, All_Time = 20743.884
702800/758000 (epoch 1854), train_loss = 0.242, time/batch = 0.028, All_Time = 20745.343
702850/758000 (epoch 1854), train_loss = 0.267, time/batch = 0.030, All_Time = 20746.813
702900/758000 (epoch 1854), train_loss = 0.249, time/batch = 0.029, All_Time = 20748.273
702950/758000 (epoch 1854), train_loss = 0.237, time/batch = 0.030, All_Time = 20749.750
703000/758000 (epoch 1854), train_loss = 0.276, time/batch = 0.030, All_Time = 20751.217
model saved to NER/polyglot/model.ckpt
703050/758000 (epoch 1855), train_loss = 0.256, time/batch = 0.030, All_Time = 20752.681
703100/758000 (epoch 1855), train_loss = 0.222, time/batch = 0.029, All_Time = 20754.154
703150/758000 (epoch 1855), train_loss = 0.266, time/batch = 0.029, All_Time = 20755.623
703200/758000 (epoch 1855), train_loss = 0.216, time/batch = 0.029, All_Time = 20757.096
703250/758000 (epoch 1855), train_loss = 0.223, time/batch = 0.029, All_Time = 20758.563
703300/758000 (epoch 1855), train_loss = 0.261, time/batch = 0.030, All_Time = 20760.037
703350/758000 (epoch 1855), train_loss = 0.238, time/batch = 0.030, All_Time = 20761.504
703400/758000 (epoch 1855), train_loss = 0.264, time/batch = 0.030, All_Time = 20762.978
703450/758000 (epoch 1856), train_loss = 0.223, time/batch = 0.029, All_Time = 20764.437
703500/758000 (epoch 1856), train_loss = 0.231, time/batch = 0.029, All_Time = 20765.896
703550/758000 (epoch 1856), train_loss = 0.238, time/batch = 0.030, All_Time = 20767.357
703600/758000 (epoch 1856), train_loss = 0.266, time/batch = 0.029, All_Time = 20768.820
703650/758000 (epoch 1856), train_loss = 0.239, time/batch = 0.031, All_Time = 20770.284
703700/758000 (epoch 1856), train_loss = 0.226, time/batch = 0.029, All_Time = 20771.747
703750/758000 (epoch 1856), train_loss = 0.276, time/batch = 0.030, All_Time = 20773.216
703800/758000 (epoch 1856), train_loss = 0.240, time/batch = 0.029, All_Time = 20774.682
703850/758000 (epoch 1857), train_loss = 0.281, time/batch = 0.029, All_Time = 20776.151
703900/758000 (epoch 1857), train_loss = 0.257, time/batch = 0.029, All_Time = 20777.612
703950/758000 (epoch 1857), train_loss = 0.240, time/batch = 0.031, All_Time = 20779.318
704000/758000 (epoch 1857), train_loss = 0.231, time/batch = 0.029, All_Time = 20780.834
model saved to NER/polyglot/model.ckpt
704050/758000 (epoch 1857), train_loss = 0.217, time/batch = 0.030, All_Time = 20782.308
704100/758000 (epoch 1857), train_loss = 0.224, time/batch = 0.030, All_Time = 20783.770
704150/758000 (epoch 1857), train_loss = 0.215, time/batch = 0.030, All_Time = 20785.243
704200/758000 (epoch 1858), train_loss = 0.249, time/batch = 0.029, All_Time = 20786.712
704250/758000 (epoch 1858), train_loss = 0.211, time/batch = 0.028, All_Time = 20788.180
704300/758000 (epoch 1858), train_loss = 0.245, time/batch = 0.029, All_Time = 20789.645
704350/758000 (epoch 1858), train_loss = 0.217, time/batch = 0.029, All_Time = 20791.114
704400/758000 (epoch 1858), train_loss = 0.233, time/batch = 0.030, All_Time = 20792.578
704450/758000 (epoch 1858), train_loss = 0.228, time/batch = 0.032, All_Time = 20794.115
704500/758000 (epoch 1858), train_loss = 0.248, time/batch = 0.031, All_Time = 20795.645
704550/758000 (epoch 1858), train_loss = 0.229, time/batch = 0.029, All_Time = 20797.130
704600/758000 (epoch 1859), train_loss = 0.218, time/batch = 0.030, All_Time = 20798.602
704650/758000 (epoch 1859), train_loss = 0.237, time/batch = 0.029, All_Time = 20800.066
704700/758000 (epoch 1859), train_loss = 0.212, time/batch = 0.029, All_Time = 20801.535
704750/758000 (epoch 1859), train_loss = 0.266, time/batch = 0.030, All_Time = 20803.007
704800/758000 (epoch 1859), train_loss = 0.255, time/batch = 0.029, All_Time = 20804.474
704850/758000 (epoch 1859), train_loss = 0.232, time/batch = 0.028, All_Time = 20805.942
704900/758000 (epoch 1859), train_loss = 0.262, time/batch = 0.028, All_Time = 20807.414
704950/758000 (epoch 1860), train_loss = 0.282, time/batch = 0.029, All_Time = 20808.882
705000/758000 (epoch 1860), train_loss = 0.292, time/batch = 0.031, All_Time = 20810.355
model saved to NER/polyglot/model.ckpt
705050/758000 (epoch 1860), train_loss = 0.253, time/batch = 0.029, All_Time = 20811.834
705100/758000 (epoch 1860), train_loss = 0.222, time/batch = 0.031, All_Time = 20813.304
705150/758000 (epoch 1860), train_loss = 0.221, time/batch = 0.029, All_Time = 20814.765
705200/758000 (epoch 1860), train_loss = 0.260, time/batch = 0.029, All_Time = 20816.224
705250/758000 (epoch 1860), train_loss = 0.244, time/batch = 0.029, All_Time = 20817.693
705300/758000 (epoch 1860), train_loss = 0.247, time/batch = 0.030, All_Time = 20819.165
705350/758000 (epoch 1861), train_loss = 0.210, time/batch = 0.030, All_Time = 20820.637
705400/758000 (epoch 1861), train_loss = 0.265, time/batch = 0.028, All_Time = 20822.106
705450/758000 (epoch 1861), train_loss = 0.229, time/batch = 0.030, All_Time = 20823.567
705500/758000 (epoch 1861), train_loss = 0.232, time/batch = 0.031, All_Time = 20825.033
705550/758000 (epoch 1861), train_loss = 0.230, time/batch = 0.029, All_Time = 20826.504
705600/758000 (epoch 1861), train_loss = 0.253, time/batch = 0.031, All_Time = 20827.969
705650/758000 (epoch 1861), train_loss = 0.258, time/batch = 0.029, All_Time = 20829.437
705700/758000 (epoch 1862), train_loss = 0.196, time/batch = 0.029, All_Time = 20830.901
705750/758000 (epoch 1862), train_loss = 0.254, time/batch = 0.030, All_Time = 20832.361
705800/758000 (epoch 1862), train_loss = 0.281, time/batch = 0.030, All_Time = 20833.822
705850/758000 (epoch 1862), train_loss = 0.235, time/batch = 0.031, All_Time = 20835.278
705900/758000 (epoch 1862), train_loss = 0.247, time/batch = 0.029, All_Time = 20836.741
705950/758000 (epoch 1862), train_loss = 0.251, time/batch = 0.030, All_Time = 20838.205
706000/758000 (epoch 1862), train_loss = 0.203, time/batch = 0.031, All_Time = 20839.675
model saved to NER/polyglot/model.ckpt
706050/758000 (epoch 1862), train_loss = 0.268, time/batch = 0.028, All_Time = 20841.138
706100/758000 (epoch 1863), train_loss = 0.233, time/batch = 0.031, All_Time = 20842.612
706150/758000 (epoch 1863), train_loss = 0.241, time/batch = 0.029, All_Time = 20844.073
706200/758000 (epoch 1863), train_loss = 0.252, time/batch = 0.029, All_Time = 20845.545
706250/758000 (epoch 1863), train_loss = 0.258, time/batch = 0.029, All_Time = 20847.021
706300/758000 (epoch 1863), train_loss = 0.243, time/batch = 0.028, All_Time = 20848.484
706350/758000 (epoch 1863), train_loss = 0.243, time/batch = 0.031, All_Time = 20849.958
706400/758000 (epoch 1863), train_loss = 0.244, time/batch = 0.030, All_Time = 20851.434
706450/758000 (epoch 1863), train_loss = 0.286, time/batch = 0.029, All_Time = 20852.894
706500/758000 (epoch 1864), train_loss = 0.207, time/batch = 0.029, All_Time = 20854.373
706550/758000 (epoch 1864), train_loss = 0.244, time/batch = 0.030, All_Time = 20855.829
706600/758000 (epoch 1864), train_loss = 0.217, time/batch = 0.030, All_Time = 20857.300
706650/758000 (epoch 1864), train_loss = 0.233, time/batch = 0.029, All_Time = 20858.769
706700/758000 (epoch 1864), train_loss = 0.260, time/batch = 0.029, All_Time = 20860.237
706750/758000 (epoch 1864), train_loss = 0.253, time/batch = 0.031, All_Time = 20861.694
706800/758000 (epoch 1864), train_loss = 0.238, time/batch = 0.029, All_Time = 20863.158
706850/758000 (epoch 1865), train_loss = 0.227, time/batch = 0.031, All_Time = 20864.626
706900/758000 (epoch 1865), train_loss = 0.250, time/batch = 0.030, All_Time = 20866.097
706950/758000 (epoch 1865), train_loss = 0.250, time/batch = 0.030, All_Time = 20867.557
707000/758000 (epoch 1865), train_loss = 0.223, time/batch = 0.029, All_Time = 20869.010
model saved to NER/polyglot/model.ckpt
707050/758000 (epoch 1865), train_loss = 0.240, time/batch = 0.030, All_Time = 20870.479
707100/758000 (epoch 1865), train_loss = 0.246, time/batch = 0.027, All_Time = 20871.947
707150/758000 (epoch 1865), train_loss = 0.246, time/batch = 0.030, All_Time = 20873.420
707200/758000 (epoch 1865), train_loss = 0.257, time/batch = 0.028, All_Time = 20874.884
707250/758000 (epoch 1866), train_loss = 0.266, time/batch = 0.028, All_Time = 20876.357
707300/758000 (epoch 1866), train_loss = 0.224, time/batch = 0.029, All_Time = 20877.824
707350/758000 (epoch 1866), train_loss = 0.248, time/batch = 0.030, All_Time = 20879.296
707400/758000 (epoch 1866), train_loss = 0.227, time/batch = 0.030, All_Time = 20880.757
707450/758000 (epoch 1866), train_loss = 0.279, time/batch = 0.029, All_Time = 20882.224
707500/758000 (epoch 1866), train_loss = 0.255, time/batch = 0.031, All_Time = 20883.691
707550/758000 (epoch 1866), train_loss = 0.253, time/batch = 0.030, All_Time = 20885.164
707600/758000 (epoch 1867), train_loss = 0.244, time/batch = 0.030, All_Time = 20886.630
707650/758000 (epoch 1867), train_loss = 0.247, time/batch = 0.030, All_Time = 20888.101
707700/758000 (epoch 1867), train_loss = 0.270, time/batch = 0.028, All_Time = 20889.560
707750/758000 (epoch 1867), train_loss = 0.246, time/batch = 0.029, All_Time = 20891.036
707800/758000 (epoch 1867), train_loss = 0.237, time/batch = 0.031, All_Time = 20892.510
707850/758000 (epoch 1867), train_loss = 0.224, time/batch = 0.030, All_Time = 20893.982
707900/758000 (epoch 1867), train_loss = 0.229, time/batch = 0.031, All_Time = 20895.456
707950/758000 (epoch 1867), train_loss = 0.246, time/batch = 0.029, All_Time = 20896.921
708000/758000 (epoch 1868), train_loss = 0.249, time/batch = 0.029, All_Time = 20898.389
model saved to NER/polyglot/model.ckpt
708050/758000 (epoch 1868), train_loss = 0.264, time/batch = 0.029, All_Time = 20899.862
708100/758000 (epoch 1868), train_loss = 0.240, time/batch = 0.029, All_Time = 20901.325
708150/758000 (epoch 1868), train_loss = 0.250, time/batch = 0.029, All_Time = 20902.793
708200/758000 (epoch 1868), train_loss = 0.227, time/batch = 0.029, All_Time = 20904.259
708250/758000 (epoch 1868), train_loss = 0.217, time/batch = 0.031, All_Time = 20905.722
708300/758000 (epoch 1868), train_loss = 0.277, time/batch = 0.029, All_Time = 20907.196
708350/758000 (epoch 1868), train_loss = 0.259, time/batch = 0.029, All_Time = 20908.651
708400/758000 (epoch 1869), train_loss = 0.269, time/batch = 0.031, All_Time = 20910.114
708450/758000 (epoch 1869), train_loss = 0.296, time/batch = 0.028, All_Time = 20911.589
708500/758000 (epoch 1869), train_loss = 0.228, time/batch = 0.029, All_Time = 20913.052
708550/758000 (epoch 1869), train_loss = 0.220, time/batch = 0.031, All_Time = 20914.519
708600/758000 (epoch 1869), train_loss = 0.257, time/batch = 0.030, All_Time = 20915.986
708650/758000 (epoch 1869), train_loss = 0.255, time/batch = 0.028, All_Time = 20917.452
708700/758000 (epoch 1869), train_loss = 0.237, time/batch = 0.029, All_Time = 20918.922
708750/758000 (epoch 1870), train_loss = 0.225, time/batch = 0.030, All_Time = 20920.400
708800/758000 (epoch 1870), train_loss = 0.234, time/batch = 0.028, All_Time = 20921.861
708850/758000 (epoch 1870), train_loss = 0.243, time/batch = 0.028, All_Time = 20923.322
708900/758000 (epoch 1870), train_loss = 0.234, time/batch = 0.031, All_Time = 20924.788
708950/758000 (epoch 1870), train_loss = 0.223, time/batch = 0.030, All_Time = 20926.266
709000/758000 (epoch 1870), train_loss = 0.239, time/batch = 0.029, All_Time = 20927.727
model saved to NER/polyglot/model.ckpt
709050/758000 (epoch 1870), train_loss = 0.264, time/batch = 0.029, All_Time = 20929.196
709100/758000 (epoch 1870), train_loss = 0.244, time/batch = 0.029, All_Time = 20930.651
709150/758000 (epoch 1871), train_loss = 0.257, time/batch = 0.029, All_Time = 20932.115
709200/758000 (epoch 1871), train_loss = 0.287, time/batch = 0.028, All_Time = 20933.581
709250/758000 (epoch 1871), train_loss = 0.255, time/batch = 0.029, All_Time = 20935.048
709300/758000 (epoch 1871), train_loss = 0.248, time/batch = 0.029, All_Time = 20936.520
709350/758000 (epoch 1871), train_loss = 0.212, time/batch = 0.029, All_Time = 20937.976
709400/758000 (epoch 1871), train_loss = 0.229, time/batch = 0.031, All_Time = 20939.435
709450/758000 (epoch 1871), train_loss = 0.272, time/batch = 0.029, All_Time = 20940.899
709500/758000 (epoch 1872), train_loss = 0.249, time/batch = 0.030, All_Time = 20942.369
709550/758000 (epoch 1872), train_loss = 0.227, time/batch = 0.027, All_Time = 20943.846
709600/758000 (epoch 1872), train_loss = 0.267, time/batch = 0.028, All_Time = 20945.319
709650/758000 (epoch 1872), train_loss = 0.239, time/batch = 0.029, All_Time = 20946.791
709700/758000 (epoch 1872), train_loss = 0.247, time/batch = 0.028, All_Time = 20948.259
709750/758000 (epoch 1872), train_loss = 0.241, time/batch = 0.028, All_Time = 20949.723
709800/758000 (epoch 1872), train_loss = 0.274, time/batch = 0.029, All_Time = 20951.206
709850/758000 (epoch 1872), train_loss = 0.279, time/batch = 0.030, All_Time = 20952.666
709900/758000 (epoch 1873), train_loss = 0.238, time/batch = 0.028, All_Time = 20954.132
709950/758000 (epoch 1873), train_loss = 0.248, time/batch = 0.028, All_Time = 20955.590
710000/758000 (epoch 1873), train_loss = 0.299, time/batch = 0.029, All_Time = 20957.044
model saved to NER/polyglot/model.ckpt
710050/758000 (epoch 1873), train_loss = 0.230, time/batch = 0.028, All_Time = 20958.518
710100/758000 (epoch 1873), train_loss = 0.216, time/batch = 0.030, All_Time = 20959.985
710150/758000 (epoch 1873), train_loss = 0.244, time/batch = 0.031, All_Time = 20961.450
710200/758000 (epoch 1873), train_loss = 0.274, time/batch = 0.029, All_Time = 20962.912
710250/758000 (epoch 1874), train_loss = 0.221, time/batch = 0.031, All_Time = 20964.381
710300/758000 (epoch 1874), train_loss = 0.257, time/batch = 0.031, All_Time = 20965.842
710350/758000 (epoch 1874), train_loss = 0.241, time/batch = 0.030, All_Time = 20967.303
710400/758000 (epoch 1874), train_loss = 0.240, time/batch = 0.029, All_Time = 20968.771
710450/758000 (epoch 1874), train_loss = 0.256, time/batch = 0.029, All_Time = 20970.242
710500/758000 (epoch 1874), train_loss = 0.219, time/batch = 0.030, All_Time = 20971.701
710550/758000 (epoch 1874), train_loss = 0.224, time/batch = 0.029, All_Time = 20973.169
710600/758000 (epoch 1874), train_loss = 0.257, time/batch = 0.028, All_Time = 20974.635
710650/758000 (epoch 1875), train_loss = 0.255, time/batch = 0.030, All_Time = 20976.110
710700/758000 (epoch 1875), train_loss = 0.267, time/batch = 0.029, All_Time = 20977.575
710750/758000 (epoch 1875), train_loss = 0.269, time/batch = 0.028, All_Time = 20979.042
710800/758000 (epoch 1875), train_loss = 0.228, time/batch = 0.029, All_Time = 20980.502
710850/758000 (epoch 1875), train_loss = 0.234, time/batch = 0.028, All_Time = 20981.964
710900/758000 (epoch 1875), train_loss = 0.245, time/batch = 0.028, All_Time = 20983.435
710950/758000 (epoch 1875), train_loss = 0.279, time/batch = 0.031, All_Time = 20984.898
711000/758000 (epoch 1875), train_loss = 0.240, time/batch = 0.030, All_Time = 20986.366
model saved to NER/polyglot/model.ckpt
711050/758000 (epoch 1876), train_loss = 0.236, time/batch = 0.029, All_Time = 20987.834
711100/758000 (epoch 1876), train_loss = 0.234, time/batch = 0.028, All_Time = 20989.301
711150/758000 (epoch 1876), train_loss = 0.233, time/batch = 0.029, All_Time = 20990.757
711200/758000 (epoch 1876), train_loss = 0.276, time/batch = 0.029, All_Time = 20992.209
711250/758000 (epoch 1876), train_loss = 0.206, time/batch = 0.028, All_Time = 20993.667
711300/758000 (epoch 1876), train_loss = 0.259, time/batch = 0.029, All_Time = 20995.129
711350/758000 (epoch 1876), train_loss = 0.234, time/batch = 0.029, All_Time = 20996.595
711400/758000 (epoch 1877), train_loss = 0.245, time/batch = 0.031, All_Time = 20998.063
711450/758000 (epoch 1877), train_loss = 0.223, time/batch = 0.029, All_Time = 20999.528
711500/758000 (epoch 1877), train_loss = 0.240, time/batch = 0.030, All_Time = 21000.994
711550/758000 (epoch 1877), train_loss = 0.256, time/batch = 0.030, All_Time = 21002.475
711600/758000 (epoch 1877), train_loss = 0.214, time/batch = 0.029, All_Time = 21003.936
711650/758000 (epoch 1877), train_loss = 0.272, time/batch = 0.029, All_Time = 21005.398
711700/758000 (epoch 1877), train_loss = 0.213, time/batch = 0.029, All_Time = 21006.866
711750/758000 (epoch 1877), train_loss = 0.251, time/batch = 0.029, All_Time = 21008.330
711800/758000 (epoch 1878), train_loss = 0.247, time/batch = 0.030, All_Time = 21009.804
711850/758000 (epoch 1878), train_loss = 0.229, time/batch = 0.030, All_Time = 21011.269
711900/758000 (epoch 1878), train_loss = 0.217, time/batch = 0.030, All_Time = 21012.735
711950/758000 (epoch 1878), train_loss = 0.220, time/batch = 0.031, All_Time = 21014.200
712000/758000 (epoch 1878), train_loss = 0.250, time/batch = 0.031, All_Time = 21015.675
model saved to NER/polyglot/model.ckpt
712050/758000 (epoch 1878), train_loss = 0.207, time/batch = 0.029, All_Time = 21017.151
712100/758000 (epoch 1878), train_loss = 0.268, time/batch = 0.028, All_Time = 21018.619
712150/758000 (epoch 1879), train_loss = 0.256, time/batch = 0.029, All_Time = 21020.095
712200/758000 (epoch 1879), train_loss = 0.264, time/batch = 0.029, All_Time = 21021.563
712250/758000 (epoch 1879), train_loss = 0.284, time/batch = 0.030, All_Time = 21023.025
712300/758000 (epoch 1879), train_loss = 0.239, time/batch = 0.028, All_Time = 21024.485
712350/758000 (epoch 1879), train_loss = 0.267, time/batch = 0.029, All_Time = 21025.954
712400/758000 (epoch 1879), train_loss = 0.256, time/batch = 0.030, All_Time = 21027.412
712450/758000 (epoch 1879), train_loss = 0.236, time/batch = 0.030, All_Time = 21028.869
712500/758000 (epoch 1879), train_loss = 0.268, time/batch = 0.028, All_Time = 21030.326
712550/758000 (epoch 1880), train_loss = 0.226, time/batch = 0.029, All_Time = 21031.812
712600/758000 (epoch 1880), train_loss = 0.222, time/batch = 0.029, All_Time = 21033.276
712650/758000 (epoch 1880), train_loss = 0.261, time/batch = 0.029, All_Time = 21034.737
712700/758000 (epoch 1880), train_loss = 0.254, time/batch = 0.029, All_Time = 21036.200
712750/758000 (epoch 1880), train_loss = 0.223, time/batch = 0.030, All_Time = 21037.662
712800/758000 (epoch 1880), train_loss = 0.242, time/batch = 0.028, All_Time = 21039.129
712850/758000 (epoch 1880), train_loss = 0.251, time/batch = 0.029, All_Time = 21040.592
712900/758000 (epoch 1881), train_loss = 0.192, time/batch = 0.030, All_Time = 21042.067
712950/758000 (epoch 1881), train_loss = 0.273, time/batch = 0.030, All_Time = 21043.519
713000/758000 (epoch 1881), train_loss = 0.217, time/batch = 0.030, All_Time = 21044.992
model saved to NER/polyglot/model.ckpt
713050/758000 (epoch 1881), train_loss = 0.240, time/batch = 0.029, All_Time = 21046.465
713100/758000 (epoch 1881), train_loss = 0.221, time/batch = 0.029, All_Time = 21047.936
713150/758000 (epoch 1881), train_loss = 0.221, time/batch = 0.029, All_Time = 21049.408
713200/758000 (epoch 1881), train_loss = 0.252, time/batch = 0.030, All_Time = 21050.885
713250/758000 (epoch 1881), train_loss = 0.272, time/batch = 0.029, All_Time = 21052.340
713300/758000 (epoch 1882), train_loss = 0.222, time/batch = 0.029, All_Time = 21053.813
713350/758000 (epoch 1882), train_loss = 0.279, time/batch = 0.028, All_Time = 21055.294
713400/758000 (epoch 1882), train_loss = 0.242, time/batch = 0.030, All_Time = 21056.764
713450/758000 (epoch 1882), train_loss = 0.274, time/batch = 0.029, All_Time = 21058.236
713500/758000 (epoch 1882), train_loss = 0.262, time/batch = 0.029, All_Time = 21059.709
713550/758000 (epoch 1882), train_loss = 0.197, time/batch = 0.029, All_Time = 21061.172
713600/758000 (epoch 1882), train_loss = 0.233, time/batch = 0.029, All_Time = 21062.632
713650/758000 (epoch 1882), train_loss = 0.281, time/batch = 0.029, All_Time = 21064.098
713700/758000 (epoch 1883), train_loss = 0.246, time/batch = 0.029, All_Time = 21065.557
713750/758000 (epoch 1883), train_loss = 0.212, time/batch = 0.031, All_Time = 21067.023
713800/758000 (epoch 1883), train_loss = 0.255, time/batch = 0.029, All_Time = 21068.499
713850/758000 (epoch 1883), train_loss = 0.271, time/batch = 0.031, All_Time = 21069.968
713900/758000 (epoch 1883), train_loss = 0.203, time/batch = 0.030, All_Time = 21071.433
713950/758000 (epoch 1883), train_loss = 0.226, time/batch = 0.029, All_Time = 21072.902
714000/758000 (epoch 1883), train_loss = 0.254, time/batch = 0.028, All_Time = 21074.367
model saved to NER/polyglot/model.ckpt
714050/758000 (epoch 1884), train_loss = 0.219, time/batch = 0.030, All_Time = 21075.838
714100/758000 (epoch 1884), train_loss = 0.265, time/batch = 0.029, All_Time = 21077.303
714150/758000 (epoch 1884), train_loss = 0.227, time/batch = 0.029, All_Time = 21078.760
714200/758000 (epoch 1884), train_loss = 0.213, time/batch = 0.029, All_Time = 21080.231
714250/758000 (epoch 1884), train_loss = 0.224, time/batch = 0.029, All_Time = 21081.687
714300/758000 (epoch 1884), train_loss = 0.213, time/batch = 0.031, All_Time = 21083.151
714350/758000 (epoch 1884), train_loss = 0.230, time/batch = 0.029, All_Time = 21084.617
714400/758000 (epoch 1884), train_loss = 0.223, time/batch = 0.030, All_Time = 21086.083
714450/758000 (epoch 1885), train_loss = 0.275, time/batch = 0.029, All_Time = 21087.542
714500/758000 (epoch 1885), train_loss = 0.229, time/batch = 0.030, All_Time = 21089.002
714550/758000 (epoch 1885), train_loss = 0.270, time/batch = 0.029, All_Time = 21090.466
714600/758000 (epoch 1885), train_loss = 0.273, time/batch = 0.029, All_Time = 21091.935
714650/758000 (epoch 1885), train_loss = 0.233, time/batch = 0.029, All_Time = 21093.406
714700/758000 (epoch 1885), train_loss = 0.268, time/batch = 0.030, All_Time = 21094.878
714750/758000 (epoch 1885), train_loss = 0.280, time/batch = 0.030, All_Time = 21096.354
714800/758000 (epoch 1886), train_loss = 0.239, time/batch = 0.030, All_Time = 21097.808
714850/758000 (epoch 1886), train_loss = 0.218, time/batch = 0.028, All_Time = 21099.270
714900/758000 (epoch 1886), train_loss = 0.243, time/batch = 0.029, All_Time = 21100.729
714950/758000 (epoch 1886), train_loss = 0.244, time/batch = 0.029, All_Time = 21102.201
715000/758000 (epoch 1886), train_loss = 0.243, time/batch = 0.030, All_Time = 21103.666
model saved to NER/polyglot/model.ckpt
715050/758000 (epoch 1886), train_loss = 0.244, time/batch = 0.029, All_Time = 21105.128
715100/758000 (epoch 1886), train_loss = 0.213, time/batch = 0.030, All_Time = 21106.589
715150/758000 (epoch 1886), train_loss = 0.289, time/batch = 0.030, All_Time = 21108.048
715200/758000 (epoch 1887), train_loss = 0.237, time/batch = 0.030, All_Time = 21109.517
715250/758000 (epoch 1887), train_loss = 0.246, time/batch = 0.029, All_Time = 21110.988
715300/758000 (epoch 1887), train_loss = 0.288, time/batch = 0.029, All_Time = 21112.463
715350/758000 (epoch 1887), train_loss = 0.257, time/batch = 0.031, All_Time = 21113.922
715400/758000 (epoch 1887), train_loss = 0.218, time/batch = 0.031, All_Time = 21115.396
715450/758000 (epoch 1887), train_loss = 0.238, time/batch = 0.030, All_Time = 21116.856
715500/758000 (epoch 1887), train_loss = 0.251, time/batch = 0.029, All_Time = 21118.320
715550/758000 (epoch 1887), train_loss = 0.251, time/batch = 0.030, All_Time = 21119.787
715600/758000 (epoch 1888), train_loss = 0.252, time/batch = 0.029, All_Time = 21121.259
715650/758000 (epoch 1888), train_loss = 0.280, time/batch = 0.030, All_Time = 21122.733
715700/758000 (epoch 1888), train_loss = 0.242, time/batch = 0.029, All_Time = 21124.188
715750/758000 (epoch 1888), train_loss = 0.250, time/batch = 0.029, All_Time = 21125.663
715800/758000 (epoch 1888), train_loss = 0.239, time/batch = 0.028, All_Time = 21127.126
715850/758000 (epoch 1888), train_loss = 0.239, time/batch = 0.030, All_Time = 21128.582
715900/758000 (epoch 1888), train_loss = 0.250, time/batch = 0.029, All_Time = 21130.044
715950/758000 (epoch 1889), train_loss = 0.221, time/batch = 0.027, All_Time = 21131.515
716000/758000 (epoch 1889), train_loss = 0.219, time/batch = 0.031, All_Time = 21132.982
model saved to NER/polyglot/model.ckpt
716050/758000 (epoch 1889), train_loss = 0.246, time/batch = 0.029, All_Time = 21134.457
716100/758000 (epoch 1889), train_loss = 0.262, time/batch = 0.029, All_Time = 21135.919
716150/758000 (epoch 1889), train_loss = 0.260, time/batch = 0.029, All_Time = 21137.386
716200/758000 (epoch 1889), train_loss = 0.241, time/batch = 0.030, All_Time = 21138.861
716250/758000 (epoch 1889), train_loss = 0.210, time/batch = 0.029, All_Time = 21140.320
716300/758000 (epoch 1889), train_loss = 0.239, time/batch = 0.029, All_Time = 21141.784
716350/758000 (epoch 1890), train_loss = 0.230, time/batch = 0.029, All_Time = 21143.262
716400/758000 (epoch 1890), train_loss = 0.226, time/batch = 0.030, All_Time = 21144.721
716450/758000 (epoch 1890), train_loss = 0.264, time/batch = 0.029, All_Time = 21146.181
716500/758000 (epoch 1890), train_loss = 0.240, time/batch = 0.028, All_Time = 21147.650
716550/758000 (epoch 1890), train_loss = 0.253, time/batch = 0.028, All_Time = 21149.121
716600/758000 (epoch 1890), train_loss = 0.251, time/batch = 0.031, All_Time = 21150.584
716650/758000 (epoch 1890), train_loss = 0.248, time/batch = 0.030, All_Time = 21152.056
716700/758000 (epoch 1891), train_loss = 0.216, time/batch = 0.030, All_Time = 21153.511
716750/758000 (epoch 1891), train_loss = 0.233, time/batch = 0.030, All_Time = 21154.985
716800/758000 (epoch 1891), train_loss = 0.250, time/batch = 0.029, All_Time = 21156.446
716850/758000 (epoch 1891), train_loss = 0.241, time/batch = 0.029, All_Time = 21157.926
716900/758000 (epoch 1891), train_loss = 0.243, time/batch = 0.030, All_Time = 21159.383
716950/758000 (epoch 1891), train_loss = 0.242, time/batch = 0.028, All_Time = 21160.841
717000/758000 (epoch 1891), train_loss = 0.230, time/batch = 0.029, All_Time = 21162.300
model saved to NER/polyglot/model.ckpt
717050/758000 (epoch 1891), train_loss = 0.259, time/batch = 0.028, All_Time = 21163.762
717100/758000 (epoch 1892), train_loss = 0.250, time/batch = 0.030, All_Time = 21165.224
717150/758000 (epoch 1892), train_loss = 0.253, time/batch = 0.028, All_Time = 21166.685
717200/758000 (epoch 1892), train_loss = 0.245, time/batch = 0.029, All_Time = 21168.150
717250/758000 (epoch 1892), train_loss = 0.231, time/batch = 0.031, All_Time = 21169.613
717300/758000 (epoch 1892), train_loss = 0.228, time/batch = 0.029, All_Time = 21171.081
717350/758000 (epoch 1892), train_loss = 0.238, time/batch = 0.029, All_Time = 21172.540
717400/758000 (epoch 1892), train_loss = 0.268, time/batch = 0.030, All_Time = 21174.006
717450/758000 (epoch 1893), train_loss = 0.248, time/batch = 0.029, All_Time = 21175.476
717500/758000 (epoch 1893), train_loss = 0.280, time/batch = 0.031, All_Time = 21176.941
717550/758000 (epoch 1893), train_loss = 0.242, time/batch = 0.030, All_Time = 21178.402
717600/758000 (epoch 1893), train_loss = 0.258, time/batch = 0.030, All_Time = 21179.872
717650/758000 (epoch 1893), train_loss = 0.224, time/batch = 0.029, All_Time = 21181.334
717700/758000 (epoch 1893), train_loss = 0.243, time/batch = 0.031, All_Time = 21182.800
717750/758000 (epoch 1893), train_loss = 0.219, time/batch = 0.030, All_Time = 21184.268
717800/758000 (epoch 1893), train_loss = 0.232, time/batch = 0.029, All_Time = 21185.726
717850/758000 (epoch 1894), train_loss = 0.237, time/batch = 0.029, All_Time = 21187.195
717900/758000 (epoch 1894), train_loss = 0.239, time/batch = 0.030, All_Time = 21188.661
717950/758000 (epoch 1894), train_loss = 0.293, time/batch = 0.029, All_Time = 21190.123
718000/758000 (epoch 1894), train_loss = 0.318, time/batch = 0.028, All_Time = 21191.581
model saved to NER/polyglot/model.ckpt
718050/758000 (epoch 1894), train_loss = 0.196, time/batch = 0.030, All_Time = 21193.058
718100/758000 (epoch 1894), train_loss = 0.213, time/batch = 0.029, All_Time = 21194.516
718150/758000 (epoch 1894), train_loss = 0.250, time/batch = 0.029, All_Time = 21195.983
718200/758000 (epoch 1894), train_loss = 0.297, time/batch = 0.028, All_Time = 21197.447
718250/758000 (epoch 1895), train_loss = 0.226, time/batch = 0.028, All_Time = 21198.910
718300/758000 (epoch 1895), train_loss = 0.259, time/batch = 0.030, All_Time = 21200.385
718350/758000 (epoch 1895), train_loss = 0.223, time/batch = 0.029, All_Time = 21201.852
718400/758000 (epoch 1895), train_loss = 0.239, time/batch = 0.029, All_Time = 21203.315
718450/758000 (epoch 1895), train_loss = 0.212, time/batch = 0.029, All_Time = 21204.787
718500/758000 (epoch 1895), train_loss = 0.243, time/batch = 0.029, All_Time = 21206.250
718550/758000 (epoch 1895), train_loss = 0.215, time/batch = 0.030, All_Time = 21207.720
718600/758000 (epoch 1896), train_loss = 0.228, time/batch = 0.028, All_Time = 21209.180
718650/758000 (epoch 1896), train_loss = 0.252, time/batch = 0.028, All_Time = 21210.652
718700/758000 (epoch 1896), train_loss = 0.260, time/batch = 0.027, All_Time = 21212.110
718750/758000 (epoch 1896), train_loss = 0.228, time/batch = 0.028, All_Time = 21213.574
718800/758000 (epoch 1896), train_loss = 0.236, time/batch = 0.029, All_Time = 21215.037
718850/758000 (epoch 1896), train_loss = 0.271, time/batch = 0.028, All_Time = 21216.497
718900/758000 (epoch 1896), train_loss = 0.238, time/batch = 0.029, All_Time = 21217.961
718950/758000 (epoch 1896), train_loss = 0.268, time/batch = 0.031, All_Time = 21219.431
719000/758000 (epoch 1897), train_loss = 0.248, time/batch = 0.030, All_Time = 21220.908
model saved to NER/polyglot/model.ckpt
719050/758000 (epoch 1897), train_loss = 0.249, time/batch = 0.030, All_Time = 21222.375
719100/758000 (epoch 1897), train_loss = 0.240, time/batch = 0.030, All_Time = 21223.835
719150/758000 (epoch 1897), train_loss = 0.247, time/batch = 0.030, All_Time = 21225.302
719200/758000 (epoch 1897), train_loss = 0.235, time/batch = 0.030, All_Time = 21226.765
719250/758000 (epoch 1897), train_loss = 0.247, time/batch = 0.028, All_Time = 21228.241
719300/758000 (epoch 1897), train_loss = 0.251, time/batch = 0.030, All_Time = 21229.708
719350/758000 (epoch 1898), train_loss = 0.242, time/batch = 0.028, All_Time = 21231.182
719400/758000 (epoch 1898), train_loss = 0.276, time/batch = 0.029, All_Time = 21232.646
719450/758000 (epoch 1898), train_loss = 0.256, time/batch = 0.029, All_Time = 21234.106
719500/758000 (epoch 1898), train_loss = 0.258, time/batch = 0.030, All_Time = 21235.588
719550/758000 (epoch 1898), train_loss = 0.213, time/batch = 0.029, All_Time = 21237.056
719600/758000 (epoch 1898), train_loss = 0.237, time/batch = 0.029, All_Time = 21238.520
719650/758000 (epoch 1898), train_loss = 0.249, time/batch = 0.028, All_Time = 21239.992
719700/758000 (epoch 1898), train_loss = 0.251, time/batch = 0.029, All_Time = 21241.449
719750/758000 (epoch 1899), train_loss = 0.232, time/batch = 0.029, All_Time = 21242.914
719800/758000 (epoch 1899), train_loss = 0.255, time/batch = 0.029, All_Time = 21244.383
719850/758000 (epoch 1899), train_loss = 0.265, time/batch = 0.029, All_Time = 21245.849
719900/758000 (epoch 1899), train_loss = 0.229, time/batch = 0.029, All_Time = 21247.312
719950/758000 (epoch 1899), train_loss = 0.263, time/batch = 0.029, All_Time = 21248.777
720000/758000 (epoch 1899), train_loss = 0.217, time/batch = 0.029, All_Time = 21250.239
model saved to NER/polyglot/model.ckpt
720050/758000 (epoch 1899), train_loss = 0.248, time/batch = 0.028, All_Time = 21251.707
720100/758000 (epoch 1900), train_loss = 0.059, time/batch = 0.030, All_Time = 21253.168
720150/758000 (epoch 1900), train_loss = 0.250, time/batch = 0.030, All_Time = 21254.641
720200/758000 (epoch 1900), train_loss = 0.223, time/batch = 0.029, All_Time = 21256.113
720250/758000 (epoch 1900), train_loss = 0.250, time/batch = 0.030, All_Time = 21257.574
720300/758000 (epoch 1900), train_loss = 0.231, time/batch = 0.028, All_Time = 21259.036
720350/758000 (epoch 1900), train_loss = 0.250, time/batch = 0.028, All_Time = 21260.488
720400/758000 (epoch 1900), train_loss = 0.232, time/batch = 0.030, All_Time = 21261.955
720450/758000 (epoch 1900), train_loss = 0.230, time/batch = 0.030, All_Time = 21263.422
720500/758000 (epoch 1901), train_loss = 0.224, time/batch = 0.030, All_Time = 21264.894
720550/758000 (epoch 1901), train_loss = 0.233, time/batch = 0.029, All_Time = 21266.358
720600/758000 (epoch 1901), train_loss = 0.224, time/batch = 0.030, All_Time = 21267.825
720650/758000 (epoch 1901), train_loss = 0.262, time/batch = 0.029, All_Time = 21269.289
720700/758000 (epoch 1901), train_loss = 0.220, time/batch = 0.029, All_Time = 21270.743
720750/758000 (epoch 1901), train_loss = 0.228, time/batch = 0.031, All_Time = 21272.206
720800/758000 (epoch 1901), train_loss = 0.280, time/batch = 0.029, All_Time = 21273.680
720850/758000 (epoch 1901), train_loss = 0.272, time/batch = 0.030, All_Time = 21275.160
720900/758000 (epoch 1902), train_loss = 0.230, time/batch = 0.031, All_Time = 21276.636
720950/758000 (epoch 1902), train_loss = 0.224, time/batch = 0.029, All_Time = 21278.098
721000/758000 (epoch 1902), train_loss = 0.201, time/batch = 0.030, All_Time = 21279.565
model saved to NER/polyglot/model.ckpt
721050/758000 (epoch 1902), train_loss = 0.270, time/batch = 0.029, All_Time = 21281.034
721100/758000 (epoch 1902), train_loss = 0.259, time/batch = 0.028, All_Time = 21282.508
721150/758000 (epoch 1902), train_loss = 0.209, time/batch = 0.029, All_Time = 21283.979
721200/758000 (epoch 1902), train_loss = 0.218, time/batch = 0.029, All_Time = 21285.451
721250/758000 (epoch 1903), train_loss = 0.229, time/batch = 0.029, All_Time = 21286.928
721300/758000 (epoch 1903), train_loss = 0.283, time/batch = 0.029, All_Time = 21288.395
721350/758000 (epoch 1903), train_loss = 0.231, time/batch = 0.028, All_Time = 21289.863
721400/758000 (epoch 1903), train_loss = 0.307, time/batch = 0.028, All_Time = 21291.339
721450/758000 (epoch 1903), train_loss = 0.221, time/batch = 0.029, All_Time = 21292.798
721500/758000 (epoch 1903), train_loss = 0.208, time/batch = 0.029, All_Time = 21294.271
721550/758000 (epoch 1903), train_loss = 0.247, time/batch = 0.031, All_Time = 21295.732
721600/758000 (epoch 1903), train_loss = 0.252, time/batch = 0.030, All_Time = 21297.201
721650/758000 (epoch 1904), train_loss = 0.264, time/batch = 0.030, All_Time = 21298.663
721700/758000 (epoch 1904), train_loss = 0.229, time/batch = 0.030, All_Time = 21300.129
721750/758000 (epoch 1904), train_loss = 0.242, time/batch = 0.028, All_Time = 21301.588
721800/758000 (epoch 1904), train_loss = 0.267, time/batch = 0.029, All_Time = 21303.058
721850/758000 (epoch 1904), train_loss = 0.249, time/batch = 0.031, All_Time = 21304.524
721900/758000 (epoch 1904), train_loss = 0.237, time/batch = 0.029, All_Time = 21305.991
721950/758000 (epoch 1904), train_loss = 0.276, time/batch = 0.031, All_Time = 21307.468
722000/758000 (epoch 1905), train_loss = 0.256, time/batch = 0.031, All_Time = 21308.940
model saved to NER/polyglot/model.ckpt
722050/758000 (epoch 1905), train_loss = 0.222, time/batch = 0.030, All_Time = 21310.399
722100/758000 (epoch 1905), train_loss = 0.266, time/batch = 0.029, All_Time = 21311.869
722150/758000 (epoch 1905), train_loss = 0.216, time/batch = 0.030, All_Time = 21313.340
722200/758000 (epoch 1905), train_loss = 0.223, time/batch = 0.030, All_Time = 21314.811
722250/758000 (epoch 1905), train_loss = 0.261, time/batch = 0.030, All_Time = 21316.275
722300/758000 (epoch 1905), train_loss = 0.238, time/batch = 0.029, All_Time = 21317.734
722350/758000 (epoch 1905), train_loss = 0.264, time/batch = 0.030, All_Time = 21319.199
722400/758000 (epoch 1906), train_loss = 0.223, time/batch = 0.029, All_Time = 21320.660
722450/758000 (epoch 1906), train_loss = 0.231, time/batch = 0.030, All_Time = 21322.134
722500/758000 (epoch 1906), train_loss = 0.238, time/batch = 0.028, All_Time = 21323.598
722550/758000 (epoch 1906), train_loss = 0.266, time/batch = 0.030, All_Time = 21325.064
722600/758000 (epoch 1906), train_loss = 0.239, time/batch = 0.030, All_Time = 21326.535
722650/758000 (epoch 1906), train_loss = 0.226, time/batch = 0.031, All_Time = 21327.999
722700/758000 (epoch 1906), train_loss = 0.276, time/batch = 0.030, All_Time = 21329.472
722750/758000 (epoch 1906), train_loss = 0.240, time/batch = 0.029, All_Time = 21330.936
722800/758000 (epoch 1907), train_loss = 0.281, time/batch = 0.028, All_Time = 21332.393
722850/758000 (epoch 1907), train_loss = 0.257, time/batch = 0.030, All_Time = 21333.871
722900/758000 (epoch 1907), train_loss = 0.240, time/batch = 0.030, All_Time = 21335.328
722950/758000 (epoch 1907), train_loss = 0.231, time/batch = 0.030, All_Time = 21336.801
723000/758000 (epoch 1907), train_loss = 0.217, time/batch = 0.031, All_Time = 21338.271
model saved to NER/polyglot/model.ckpt
723050/758000 (epoch 1907), train_loss = 0.224, time/batch = 0.029, All_Time = 21339.744
723100/758000 (epoch 1907), train_loss = 0.215, time/batch = 0.029, All_Time = 21341.210
723150/758000 (epoch 1908), train_loss = 0.249, time/batch = 0.028, All_Time = 21342.678
723200/758000 (epoch 1908), train_loss = 0.211, time/batch = 0.029, All_Time = 21344.144
723250/758000 (epoch 1908), train_loss = 0.245, time/batch = 0.029, All_Time = 21345.606
723300/758000 (epoch 1908), train_loss = 0.217, time/batch = 0.028, All_Time = 21347.089
723350/758000 (epoch 1908), train_loss = 0.233, time/batch = 0.029, All_Time = 21348.554
723400/758000 (epoch 1908), train_loss = 0.228, time/batch = 0.028, All_Time = 21350.009
723450/758000 (epoch 1908), train_loss = 0.248, time/batch = 0.029, All_Time = 21351.477
723500/758000 (epoch 1908), train_loss = 0.229, time/batch = 0.030, All_Time = 21352.935
723550/758000 (epoch 1909), train_loss = 0.218, time/batch = 0.030, All_Time = 21354.420
723600/758000 (epoch 1909), train_loss = 0.237, time/batch = 0.028, All_Time = 21355.880
723650/758000 (epoch 1909), train_loss = 0.212, time/batch = 0.029, All_Time = 21357.342
723700/758000 (epoch 1909), train_loss = 0.266, time/batch = 0.029, All_Time = 21358.814
723750/758000 (epoch 1909), train_loss = 0.255, time/batch = 0.030, All_Time = 21360.293
723800/758000 (epoch 1909), train_loss = 0.232, time/batch = 0.029, All_Time = 21361.756
723850/758000 (epoch 1909), train_loss = 0.262, time/batch = 0.029, All_Time = 21363.221
723900/758000 (epoch 1910), train_loss = 0.282, time/batch = 0.030, All_Time = 21364.689
723950/758000 (epoch 1910), train_loss = 0.292, time/batch = 0.029, All_Time = 21366.160
724000/758000 (epoch 1910), train_loss = 0.253, time/batch = 0.028, All_Time = 21367.609
model saved to NER/polyglot/model.ckpt
724050/758000 (epoch 1910), train_loss = 0.222, time/batch = 0.029, All_Time = 21369.076
724100/758000 (epoch 1910), train_loss = 0.221, time/batch = 0.028, All_Time = 21370.543
724150/758000 (epoch 1910), train_loss = 0.260, time/batch = 0.030, All_Time = 21372.018
724200/758000 (epoch 1910), train_loss = 0.244, time/batch = 0.029, All_Time = 21373.476
724250/758000 (epoch 1910), train_loss = 0.247, time/batch = 0.030, All_Time = 21374.938
724300/758000 (epoch 1911), train_loss = 0.210, time/batch = 0.029, All_Time = 21376.399
724350/758000 (epoch 1911), train_loss = 0.265, time/batch = 0.030, All_Time = 21377.875
724400/758000 (epoch 1911), train_loss = 0.229, time/batch = 0.029, All_Time = 21379.339
724450/758000 (epoch 1911), train_loss = 0.232, time/batch = 0.029, All_Time = 21380.804
724500/758000 (epoch 1911), train_loss = 0.230, time/batch = 0.029, All_Time = 21382.262
724550/758000 (epoch 1911), train_loss = 0.253, time/batch = 0.029, All_Time = 21383.727
724600/758000 (epoch 1911), train_loss = 0.258, time/batch = 0.029, All_Time = 21385.204
724650/758000 (epoch 1912), train_loss = 0.196, time/batch = 0.030, All_Time = 21386.669
724700/758000 (epoch 1912), train_loss = 0.254, time/batch = 0.030, All_Time = 21388.138
724750/758000 (epoch 1912), train_loss = 0.281, time/batch = 0.030, All_Time = 21389.601
724800/758000 (epoch 1912), train_loss = 0.235, time/batch = 0.028, All_Time = 21391.069
724850/758000 (epoch 1912), train_loss = 0.247, time/batch = 0.028, All_Time = 21392.530
724900/758000 (epoch 1912), train_loss = 0.251, time/batch = 0.029, All_Time = 21393.992
724950/758000 (epoch 1912), train_loss = 0.203, time/batch = 0.030, All_Time = 21395.459
725000/758000 (epoch 1912), train_loss = 0.268, time/batch = 0.030, All_Time = 21396.919
model saved to NER/polyglot/model.ckpt
725050/758000 (epoch 1913), train_loss = 0.233, time/batch = 0.029, All_Time = 21398.413
725100/758000 (epoch 1913), train_loss = 0.241, time/batch = 0.030, All_Time = 21399.876
725150/758000 (epoch 1913), train_loss = 0.252, time/batch = 0.028, All_Time = 21401.337
725200/758000 (epoch 1913), train_loss = 0.258, time/batch = 0.028, All_Time = 21402.805
725250/758000 (epoch 1913), train_loss = 0.243, time/batch = 0.029, All_Time = 21404.276
725300/758000 (epoch 1913), train_loss = 0.243, time/batch = 0.028, All_Time = 21405.740
725350/758000 (epoch 1913), train_loss = 0.244, time/batch = 0.029, All_Time = 21407.203
725400/758000 (epoch 1913), train_loss = 0.286, time/batch = 0.030, All_Time = 21408.661
725450/758000 (epoch 1914), train_loss = 0.207, time/batch = 0.031, All_Time = 21410.130
725500/758000 (epoch 1914), train_loss = 0.244, time/batch = 0.030, All_Time = 21411.601
725550/758000 (epoch 1914), train_loss = 0.217, time/batch = 0.029, All_Time = 21413.059
725600/758000 (epoch 1914), train_loss = 0.233, time/batch = 0.029, All_Time = 21414.526
725650/758000 (epoch 1914), train_loss = 0.260, time/batch = 0.030, All_Time = 21415.995
725700/758000 (epoch 1914), train_loss = 0.253, time/batch = 0.030, All_Time = 21417.449
725750/758000 (epoch 1914), train_loss = 0.238, time/batch = 0.028, All_Time = 21418.916
725800/758000 (epoch 1915), train_loss = 0.227, time/batch = 0.029, All_Time = 21420.385
725850/758000 (epoch 1915), train_loss = 0.250, time/batch = 0.028, All_Time = 21421.849
725900/758000 (epoch 1915), train_loss = 0.250, time/batch = 0.029, All_Time = 21423.304
725950/758000 (epoch 1915), train_loss = 0.223, time/batch = 0.029, All_Time = 21424.770
726000/758000 (epoch 1915), train_loss = 0.240, time/batch = 0.029, All_Time = 21426.227
model saved to NER/polyglot/model.ckpt
726050/758000 (epoch 1915), train_loss = 0.246, time/batch = 0.031, All_Time = 21427.700
726100/758000 (epoch 1915), train_loss = 0.246, time/batch = 0.029, All_Time = 21429.159
726150/758000 (epoch 1915), train_loss = 0.257, time/batch = 0.029, All_Time = 21430.622
726200/758000 (epoch 1916), train_loss = 0.266, time/batch = 0.028, All_Time = 21432.089
726250/758000 (epoch 1916), train_loss = 0.224, time/batch = 0.030, All_Time = 21433.562
726300/758000 (epoch 1916), train_loss = 0.248, time/batch = 0.029, All_Time = 21435.024
726350/758000 (epoch 1916), train_loss = 0.227, time/batch = 0.029, All_Time = 21436.483
726400/758000 (epoch 1916), train_loss = 0.279, time/batch = 0.029, All_Time = 21437.939
726450/758000 (epoch 1916), train_loss = 0.255, time/batch = 0.028, All_Time = 21439.401
726500/758000 (epoch 1916), train_loss = 0.253, time/batch = 0.030, All_Time = 21440.865
726550/758000 (epoch 1917), train_loss = 0.244, time/batch = 0.029, All_Time = 21442.328
726600/758000 (epoch 1917), train_loss = 0.247, time/batch = 0.030, All_Time = 21443.804
726650/758000 (epoch 1917), train_loss = 0.270, time/batch = 0.028, All_Time = 21445.285
726700/758000 (epoch 1917), train_loss = 0.246, time/batch = 0.030, All_Time = 21446.747
726750/758000 (epoch 1917), train_loss = 0.237, time/batch = 0.029, All_Time = 21448.217
726800/758000 (epoch 1917), train_loss = 0.224, time/batch = 0.030, All_Time = 21449.687
726850/758000 (epoch 1917), train_loss = 0.229, time/batch = 0.028, All_Time = 21451.155
726900/758000 (epoch 1917), train_loss = 0.246, time/batch = 0.028, All_Time = 21452.615
726950/758000 (epoch 1918), train_loss = 0.249, time/batch = 0.029, All_Time = 21454.079
727000/758000 (epoch 1918), train_loss = 0.264, time/batch = 0.029, All_Time = 21455.536
model saved to NER/polyglot/model.ckpt
727050/758000 (epoch 1918), train_loss = 0.240, time/batch = 0.030, All_Time = 21456.999
727100/758000 (epoch 1918), train_loss = 0.250, time/batch = 0.030, All_Time = 21458.453
727150/758000 (epoch 1918), train_loss = 0.227, time/batch = 0.030, All_Time = 21459.997
727200/758000 (epoch 1918), train_loss = 0.217, time/batch = 0.030, All_Time = 21461.471
727250/758000 (epoch 1918), train_loss = 0.277, time/batch = 0.029, All_Time = 21462.951
727300/758000 (epoch 1918), train_loss = 0.259, time/batch = 0.030, All_Time = 21464.432
727350/758000 (epoch 1919), train_loss = 0.269, time/batch = 0.030, All_Time = 21465.913
727400/758000 (epoch 1919), train_loss = 0.296, time/batch = 0.028, All_Time = 21467.379
727450/758000 (epoch 1919), train_loss = 0.228, time/batch = 0.030, All_Time = 21468.858
727500/758000 (epoch 1919), train_loss = 0.220, time/batch = 0.031, All_Time = 21470.327
727550/758000 (epoch 1919), train_loss = 0.257, time/batch = 0.028, All_Time = 21471.789
727600/758000 (epoch 1919), train_loss = 0.255, time/batch = 0.031, All_Time = 21473.266
727650/758000 (epoch 1919), train_loss = 0.237, time/batch = 0.031, All_Time = 21474.735
727700/758000 (epoch 1920), train_loss = 0.225, time/batch = 0.030, All_Time = 21476.210
727750/758000 (epoch 1920), train_loss = 0.234, time/batch = 0.029, All_Time = 21477.671
727800/758000 (epoch 1920), train_loss = 0.243, time/batch = 0.030, All_Time = 21479.137
727850/758000 (epoch 1920), train_loss = 0.234, time/batch = 0.029, All_Time = 21480.610
727900/758000 (epoch 1920), train_loss = 0.223, time/batch = 0.029, All_Time = 21482.085
727950/758000 (epoch 1920), train_loss = 0.239, time/batch = 0.029, All_Time = 21483.545
728000/758000 (epoch 1920), train_loss = 0.264, time/batch = 0.029, All_Time = 21485.012
model saved to NER/polyglot/model.ckpt
728050/758000 (epoch 1920), train_loss = 0.244, time/batch = 0.030, All_Time = 21486.478
728100/758000 (epoch 1921), train_loss = 0.257, time/batch = 0.030, All_Time = 21487.937
728150/758000 (epoch 1921), train_loss = 0.287, time/batch = 0.029, All_Time = 21489.408
728200/758000 (epoch 1921), train_loss = 0.255, time/batch = 0.028, All_Time = 21490.878
728250/758000 (epoch 1921), train_loss = 0.248, time/batch = 0.030, All_Time = 21492.344
728300/758000 (epoch 1921), train_loss = 0.212, time/batch = 0.028, All_Time = 21493.818
728350/758000 (epoch 1921), train_loss = 0.229, time/batch = 0.029, All_Time = 21495.287
728400/758000 (epoch 1921), train_loss = 0.272, time/batch = 0.029, All_Time = 21496.755
728450/758000 (epoch 1922), train_loss = 0.249, time/batch = 0.029, All_Time = 21498.228
728500/758000 (epoch 1922), train_loss = 0.227, time/batch = 0.028, All_Time = 21499.698
728550/758000 (epoch 1922), train_loss = 0.267, time/batch = 0.031, All_Time = 21501.163
728600/758000 (epoch 1922), train_loss = 0.239, time/batch = 0.030, All_Time = 21502.630
728650/758000 (epoch 1922), train_loss = 0.247, time/batch = 0.031, All_Time = 21504.101
728700/758000 (epoch 1922), train_loss = 0.241, time/batch = 0.030, All_Time = 21505.574
728750/758000 (epoch 1922), train_loss = 0.274, time/batch = 0.030, All_Time = 21507.046
728800/758000 (epoch 1922), train_loss = 0.279, time/batch = 0.029, All_Time = 21508.510
728850/758000 (epoch 1923), train_loss = 0.238, time/batch = 0.030, All_Time = 21509.977
728900/758000 (epoch 1923), train_loss = 0.248, time/batch = 0.029, All_Time = 21511.440
728950/758000 (epoch 1923), train_loss = 0.299, time/batch = 0.029, All_Time = 21512.906
729000/758000 (epoch 1923), train_loss = 0.230, time/batch = 0.029, All_Time = 21514.381
model saved to NER/polyglot/model.ckpt
729050/758000 (epoch 1923), train_loss = 0.216, time/batch = 0.029, All_Time = 21515.839
729100/758000 (epoch 1923), train_loss = 0.244, time/batch = 0.029, All_Time = 21517.306
729150/758000 (epoch 1923), train_loss = 0.274, time/batch = 0.030, All_Time = 21518.769
729200/758000 (epoch 1924), train_loss = 0.221, time/batch = 0.030, All_Time = 21520.236
729250/758000 (epoch 1924), train_loss = 0.257, time/batch = 0.030, All_Time = 21521.711
729300/758000 (epoch 1924), train_loss = 0.241, time/batch = 0.030, All_Time = 21523.174
729350/758000 (epoch 1924), train_loss = 0.240, time/batch = 0.028, All_Time = 21524.646
729400/758000 (epoch 1924), train_loss = 0.256, time/batch = 0.030, All_Time = 21526.108
729450/758000 (epoch 1924), train_loss = 0.219, time/batch = 0.030, All_Time = 21527.580
729500/758000 (epoch 1924), train_loss = 0.224, time/batch = 0.030, All_Time = 21529.043
729550/758000 (epoch 1924), train_loss = 0.257, time/batch = 0.028, All_Time = 21530.494
729600/758000 (epoch 1925), train_loss = 0.255, time/batch = 0.028, All_Time = 21531.959
729650/758000 (epoch 1925), train_loss = 0.267, time/batch = 0.028, All_Time = 21533.421
729700/758000 (epoch 1925), train_loss = 0.269, time/batch = 0.030, All_Time = 21534.889
729750/758000 (epoch 1925), train_loss = 0.228, time/batch = 0.028, All_Time = 21536.357
729800/758000 (epoch 1925), train_loss = 0.234, time/batch = 0.030, All_Time = 21537.830
729850/758000 (epoch 1925), train_loss = 0.245, time/batch = 0.031, All_Time = 21539.283
729900/758000 (epoch 1925), train_loss = 0.279, time/batch = 0.030, All_Time = 21540.746
729950/758000 (epoch 1925), train_loss = 0.240, time/batch = 0.029, All_Time = 21542.212
730000/758000 (epoch 1926), train_loss = 0.236, time/batch = 0.029, All_Time = 21543.673
model saved to NER/polyglot/model.ckpt
730050/758000 (epoch 1926), train_loss = 0.234, time/batch = 0.030, All_Time = 21545.146
730100/758000 (epoch 1926), train_loss = 0.233, time/batch = 0.029, All_Time = 21546.620
730150/758000 (epoch 1926), train_loss = 0.276, time/batch = 0.030, All_Time = 21548.090
730200/758000 (epoch 1926), train_loss = 0.206, time/batch = 0.028, All_Time = 21549.551
730250/758000 (epoch 1926), train_loss = 0.259, time/batch = 0.030, All_Time = 21551.021
730300/758000 (epoch 1926), train_loss = 0.234, time/batch = 0.029, All_Time = 21552.487
730350/758000 (epoch 1927), train_loss = 0.245, time/batch = 0.029, All_Time = 21553.960
730400/758000 (epoch 1927), train_loss = 0.223, time/batch = 0.029, All_Time = 21555.423
730450/758000 (epoch 1927), train_loss = 0.240, time/batch = 0.029, All_Time = 21556.897
730500/758000 (epoch 1927), train_loss = 0.256, time/batch = 0.029, All_Time = 21558.361
730550/758000 (epoch 1927), train_loss = 0.214, time/batch = 0.030, All_Time = 21559.828
730600/758000 (epoch 1927), train_loss = 0.272, time/batch = 0.029, All_Time = 21561.292
730650/758000 (epoch 1927), train_loss = 0.213, time/batch = 0.029, All_Time = 21562.752
730700/758000 (epoch 1927), train_loss = 0.251, time/batch = 0.029, All_Time = 21564.218
730750/758000 (epoch 1928), train_loss = 0.247, time/batch = 0.031, All_Time = 21565.686
730800/758000 (epoch 1928), train_loss = 0.229, time/batch = 0.030, All_Time = 21567.249
730850/758000 (epoch 1928), train_loss = 0.217, time/batch = 0.031, All_Time = 21568.788
730900/758000 (epoch 1928), train_loss = 0.220, time/batch = 0.029, All_Time = 21570.291
730950/758000 (epoch 1928), train_loss = 0.250, time/batch = 0.029, All_Time = 21571.798
731000/758000 (epoch 1928), train_loss = 0.207, time/batch = 0.031, All_Time = 21573.286
model saved to NER/polyglot/model.ckpt
731050/758000 (epoch 1928), train_loss = 0.268, time/batch = 0.030, All_Time = 21574.764
731100/758000 (epoch 1929), train_loss = 0.256, time/batch = 0.029, All_Time = 21576.230
731150/758000 (epoch 1929), train_loss = 0.264, time/batch = 0.030, All_Time = 21577.702
731200/758000 (epoch 1929), train_loss = 0.284, time/batch = 0.030, All_Time = 21579.162
731250/758000 (epoch 1929), train_loss = 0.239, time/batch = 0.029, All_Time = 21580.625
731300/758000 (epoch 1929), train_loss = 0.267, time/batch = 0.031, All_Time = 21582.097
731350/758000 (epoch 1929), train_loss = 0.256, time/batch = 0.029, All_Time = 21583.572
731400/758000 (epoch 1929), train_loss = 0.236, time/batch = 0.028, All_Time = 21585.029
731450/758000 (epoch 1929), train_loss = 0.268, time/batch = 0.035, All_Time = 21586.519
731500/758000 (epoch 1930), train_loss = 0.226, time/batch = 0.029, All_Time = 21588.035
731550/758000 (epoch 1930), train_loss = 0.222, time/batch = 0.030, All_Time = 21589.497
731600/758000 (epoch 1930), train_loss = 0.261, time/batch = 0.030, All_Time = 21590.964
731650/758000 (epoch 1930), train_loss = 0.254, time/batch = 0.029, All_Time = 21592.428
731700/758000 (epoch 1930), train_loss = 0.223, time/batch = 0.028, All_Time = 21593.896
731750/758000 (epoch 1930), train_loss = 0.242, time/batch = 0.031, All_Time = 21595.364
731800/758000 (epoch 1930), train_loss = 0.251, time/batch = 0.030, All_Time = 21596.838
731850/758000 (epoch 1931), train_loss = 0.192, time/batch = 0.030, All_Time = 21598.295
731900/758000 (epoch 1931), train_loss = 0.273, time/batch = 0.029, All_Time = 21599.760
731950/758000 (epoch 1931), train_loss = 0.217, time/batch = 0.029, All_Time = 21601.217
732000/758000 (epoch 1931), train_loss = 0.240, time/batch = 0.031, All_Time = 21602.683
model saved to NER/polyglot/model.ckpt
732050/758000 (epoch 1931), train_loss = 0.221, time/batch = 0.030, All_Time = 21604.146
732100/758000 (epoch 1931), train_loss = 0.221, time/batch = 0.029, All_Time = 21605.611
732150/758000 (epoch 1931), train_loss = 0.252, time/batch = 0.031, All_Time = 21607.088
732200/758000 (epoch 1931), train_loss = 0.272, time/batch = 0.029, All_Time = 21608.557
732250/758000 (epoch 1932), train_loss = 0.222, time/batch = 0.029, All_Time = 21610.033
732300/758000 (epoch 1932), train_loss = 0.279, time/batch = 0.029, All_Time = 21611.495
732350/758000 (epoch 1932), train_loss = 0.242, time/batch = 0.030, All_Time = 21612.963
732400/758000 (epoch 1932), train_loss = 0.274, time/batch = 0.031, All_Time = 21614.433
732450/758000 (epoch 1932), train_loss = 0.262, time/batch = 0.028, All_Time = 21615.911
732500/758000 (epoch 1932), train_loss = 0.197, time/batch = 0.028, All_Time = 21617.372
732550/758000 (epoch 1932), train_loss = 0.233, time/batch = 0.030, All_Time = 21618.840
732600/758000 (epoch 1932), train_loss = 0.281, time/batch = 0.028, All_Time = 21620.306
732650/758000 (epoch 1933), train_loss = 0.246, time/batch = 0.029, All_Time = 21621.780
732700/758000 (epoch 1933), train_loss = 0.212, time/batch = 0.030, All_Time = 21623.244
732750/758000 (epoch 1933), train_loss = 0.255, time/batch = 0.028, All_Time = 21624.697
732800/758000 (epoch 1933), train_loss = 0.271, time/batch = 0.030, All_Time = 21626.158
732850/758000 (epoch 1933), train_loss = 0.203, time/batch = 0.029, All_Time = 21627.621
732900/758000 (epoch 1933), train_loss = 0.226, time/batch = 0.028, All_Time = 21629.087
732950/758000 (epoch 1933), train_loss = 0.254, time/batch = 0.028, All_Time = 21630.560
733000/758000 (epoch 1934), train_loss = 0.219, time/batch = 0.029, All_Time = 21632.035
model saved to NER/polyglot/model.ckpt
733050/758000 (epoch 1934), train_loss = 0.265, time/batch = 0.030, All_Time = 21633.518
733100/758000 (epoch 1934), train_loss = 0.227, time/batch = 0.030, All_Time = 21634.973
733150/758000 (epoch 1934), train_loss = 0.213, time/batch = 0.029, All_Time = 21636.449
733200/758000 (epoch 1934), train_loss = 0.224, time/batch = 0.030, All_Time = 21637.917
733250/758000 (epoch 1934), train_loss = 0.213, time/batch = 0.030, All_Time = 21639.382
733300/758000 (epoch 1934), train_loss = 0.230, time/batch = 0.030, All_Time = 21640.839
733350/758000 (epoch 1934), train_loss = 0.223, time/batch = 0.030, All_Time = 21642.309
733400/758000 (epoch 1935), train_loss = 0.275, time/batch = 0.030, All_Time = 21643.766
733450/758000 (epoch 1935), train_loss = 0.229, time/batch = 0.028, All_Time = 21645.242
733500/758000 (epoch 1935), train_loss = 0.270, time/batch = 0.028, All_Time = 21646.706
733550/758000 (epoch 1935), train_loss = 0.273, time/batch = 0.029, All_Time = 21648.169
733600/758000 (epoch 1935), train_loss = 0.233, time/batch = 0.029, All_Time = 21649.628
733650/758000 (epoch 1935), train_loss = 0.268, time/batch = 0.030, All_Time = 21651.097
733700/758000 (epoch 1935), train_loss = 0.280, time/batch = 0.029, All_Time = 21652.557
733750/758000 (epoch 1936), train_loss = 0.239, time/batch = 0.029, All_Time = 21654.023
733800/758000 (epoch 1936), train_loss = 0.218, time/batch = 0.028, All_Time = 21655.486
733850/758000 (epoch 1936), train_loss = 0.243, time/batch = 0.029, All_Time = 21656.966
733900/758000 (epoch 1936), train_loss = 0.244, time/batch = 0.030, All_Time = 21658.438
733950/758000 (epoch 1936), train_loss = 0.243, time/batch = 0.028, All_Time = 21659.913
734000/758000 (epoch 1936), train_loss = 0.244, time/batch = 0.029, All_Time = 21661.375
model saved to NER/polyglot/model.ckpt
734050/758000 (epoch 1936), train_loss = 0.213, time/batch = 0.029, All_Time = 21662.838
734100/758000 (epoch 1936), train_loss = 0.289, time/batch = 0.029, All_Time = 21664.310
734150/758000 (epoch 1937), train_loss = 0.237, time/batch = 0.029, All_Time = 21665.778
734200/758000 (epoch 1937), train_loss = 0.246, time/batch = 0.029, All_Time = 21667.244
734250/758000 (epoch 1937), train_loss = 0.288, time/batch = 0.031, All_Time = 21668.721
734300/758000 (epoch 1937), train_loss = 0.257, time/batch = 0.030, All_Time = 21670.191
734350/758000 (epoch 1937), train_loss = 0.218, time/batch = 0.030, All_Time = 21671.662
734400/758000 (epoch 1937), train_loss = 0.238, time/batch = 0.029, All_Time = 21673.131
734450/758000 (epoch 1937), train_loss = 0.251, time/batch = 0.028, All_Time = 21674.602
734500/758000 (epoch 1937), train_loss = 0.251, time/batch = 0.029, All_Time = 21676.072
734550/758000 (epoch 1938), train_loss = 0.252, time/batch = 0.030, All_Time = 21677.560
734600/758000 (epoch 1938), train_loss = 0.280, time/batch = 0.029, All_Time = 21679.029
734650/758000 (epoch 1938), train_loss = 0.242, time/batch = 0.029, All_Time = 21680.494
734700/758000 (epoch 1938), train_loss = 0.250, time/batch = 0.029, All_Time = 21681.947
734750/758000 (epoch 1938), train_loss = 0.239, time/batch = 0.029, All_Time = 21683.413
734800/758000 (epoch 1938), train_loss = 0.239, time/batch = 0.029, All_Time = 21684.881
734850/758000 (epoch 1938), train_loss = 0.250, time/batch = 0.030, All_Time = 21686.355
734900/758000 (epoch 1939), train_loss = 0.221, time/batch = 0.029, All_Time = 21687.821
734950/758000 (epoch 1939), train_loss = 0.219, time/batch = 0.030, All_Time = 21689.298
735000/758000 (epoch 1939), train_loss = 0.246, time/batch = 0.029, All_Time = 21690.765
model saved to NER/polyglot/model.ckpt
735050/758000 (epoch 1939), train_loss = 0.262, time/batch = 0.030, All_Time = 21692.235
735100/758000 (epoch 1939), train_loss = 0.260, time/batch = 0.029, All_Time = 21693.704
735150/758000 (epoch 1939), train_loss = 0.241, time/batch = 0.029, All_Time = 21695.170
735200/758000 (epoch 1939), train_loss = 0.210, time/batch = 0.030, All_Time = 21696.636
735250/758000 (epoch 1939), train_loss = 0.239, time/batch = 0.028, All_Time = 21698.104
735300/758000 (epoch 1940), train_loss = 0.230, time/batch = 0.030, All_Time = 21699.578
735350/758000 (epoch 1940), train_loss = 0.226, time/batch = 0.029, All_Time = 21701.030
735400/758000 (epoch 1940), train_loss = 0.264, time/batch = 0.029, All_Time = 21702.493
735450/758000 (epoch 1940), train_loss = 0.240, time/batch = 0.029, All_Time = 21703.958
735500/758000 (epoch 1940), train_loss = 0.253, time/batch = 0.029, All_Time = 21705.406
735550/758000 (epoch 1940), train_loss = 0.251, time/batch = 0.030, All_Time = 21706.875
735600/758000 (epoch 1940), train_loss = 0.248, time/batch = 0.028, All_Time = 21708.345
735650/758000 (epoch 1941), train_loss = 0.216, time/batch = 0.028, All_Time = 21709.812
735700/758000 (epoch 1941), train_loss = 0.233, time/batch = 0.030, All_Time = 21711.276
735750/758000 (epoch 1941), train_loss = 0.250, time/batch = 0.028, All_Time = 21712.733
735800/758000 (epoch 1941), train_loss = 0.241, time/batch = 0.029, All_Time = 21714.192
735850/758000 (epoch 1941), train_loss = 0.243, time/batch = 0.030, All_Time = 21715.659
735900/758000 (epoch 1941), train_loss = 0.242, time/batch = 0.029, All_Time = 21717.130
735950/758000 (epoch 1941), train_loss = 0.230, time/batch = 0.028, All_Time = 21718.595
736000/758000 (epoch 1941), train_loss = 0.259, time/batch = 0.031, All_Time = 21720.064
model saved to NER/polyglot/model.ckpt
736050/758000 (epoch 1942), train_loss = 0.250, time/batch = 0.029, All_Time = 21721.554
736100/758000 (epoch 1942), train_loss = 0.253, time/batch = 0.029, All_Time = 21723.017
736150/758000 (epoch 1942), train_loss = 0.245, time/batch = 0.029, All_Time = 21724.490
736200/758000 (epoch 1942), train_loss = 0.231, time/batch = 0.029, All_Time = 21725.953
736250/758000 (epoch 1942), train_loss = 0.228, time/batch = 0.028, All_Time = 21727.415
736300/758000 (epoch 1942), train_loss = 0.238, time/batch = 0.030, All_Time = 21728.881
736350/758000 (epoch 1942), train_loss = 0.268, time/batch = 0.029, All_Time = 21730.353
736400/758000 (epoch 1943), train_loss = 0.248, time/batch = 0.029, All_Time = 21731.805
736450/758000 (epoch 1943), train_loss = 0.280, time/batch = 0.030, All_Time = 21733.280
736500/758000 (epoch 1943), train_loss = 0.242, time/batch = 0.029, All_Time = 21734.739
736550/758000 (epoch 1943), train_loss = 0.258, time/batch = 0.031, All_Time = 21736.203
736600/758000 (epoch 1943), train_loss = 0.224, time/batch = 0.029, All_Time = 21737.667
736650/758000 (epoch 1943), train_loss = 0.243, time/batch = 0.030, All_Time = 21739.139
736700/758000 (epoch 1943), train_loss = 0.219, time/batch = 0.029, All_Time = 21740.594
736750/758000 (epoch 1943), train_loss = 0.232, time/batch = 0.029, All_Time = 21742.062
736800/758000 (epoch 1944), train_loss = 0.237, time/batch = 0.029, All_Time = 21743.542
736850/758000 (epoch 1944), train_loss = 0.239, time/batch = 0.030, All_Time = 21745.018
736900/758000 (epoch 1944), train_loss = 0.293, time/batch = 0.028, All_Time = 21746.481
736950/758000 (epoch 1944), train_loss = 0.318, time/batch = 0.030, All_Time = 21747.945
737000/758000 (epoch 1944), train_loss = 0.196, time/batch = 0.028, All_Time = 21749.404
model saved to NER/polyglot/model.ckpt
737050/758000 (epoch 1944), train_loss = 0.213, time/batch = 0.031, All_Time = 21750.880
737100/758000 (epoch 1944), train_loss = 0.250, time/batch = 0.030, All_Time = 21752.346
737150/758000 (epoch 1944), train_loss = 0.297, time/batch = 0.030, All_Time = 21753.807
737200/758000 (epoch 1945), train_loss = 0.226, time/batch = 0.029, All_Time = 21755.278
737250/758000 (epoch 1945), train_loss = 0.259, time/batch = 0.028, All_Time = 21756.747
737300/758000 (epoch 1945), train_loss = 0.223, time/batch = 0.030, All_Time = 21758.222
737350/758000 (epoch 1945), train_loss = 0.239, time/batch = 0.028, All_Time = 21759.693
737400/758000 (epoch 1945), train_loss = 0.212, time/batch = 0.029, All_Time = 21761.171
737450/758000 (epoch 1945), train_loss = 0.243, time/batch = 0.029, All_Time = 21762.636
737500/758000 (epoch 1945), train_loss = 0.215, time/batch = 0.029, All_Time = 21764.110
737550/758000 (epoch 1946), train_loss = 0.228, time/batch = 0.029, All_Time = 21765.588
737600/758000 (epoch 1946), train_loss = 0.252, time/batch = 0.029, All_Time = 21767.053
737650/758000 (epoch 1946), train_loss = 0.260, time/batch = 0.029, All_Time = 21768.518
737700/758000 (epoch 1946), train_loss = 0.228, time/batch = 0.031, All_Time = 21769.990
737750/758000 (epoch 1946), train_loss = 0.236, time/batch = 0.030, All_Time = 21771.459
737800/758000 (epoch 1946), train_loss = 0.271, time/batch = 0.030, All_Time = 21772.935
737850/758000 (epoch 1946), train_loss = 0.238, time/batch = 0.030, All_Time = 21774.403
737900/758000 (epoch 1946), train_loss = 0.268, time/batch = 0.030, All_Time = 21775.883
737950/758000 (epoch 1947), train_loss = 0.248, time/batch = 0.030, All_Time = 21777.357
738000/758000 (epoch 1947), train_loss = 0.249, time/batch = 0.029, All_Time = 21778.821
model saved to NER/polyglot/model.ckpt
738050/758000 (epoch 1947), train_loss = 0.240, time/batch = 0.031, All_Time = 21780.303
738100/758000 (epoch 1947), train_loss = 0.247, time/batch = 0.029, All_Time = 21781.779
738150/758000 (epoch 1947), train_loss = 0.235, time/batch = 0.029, All_Time = 21783.251
738200/758000 (epoch 1947), train_loss = 0.247, time/batch = 0.031, All_Time = 21784.728
738250/758000 (epoch 1947), train_loss = 0.251, time/batch = 0.029, All_Time = 21786.184
738300/758000 (epoch 1948), train_loss = 0.242, time/batch = 0.030, All_Time = 21787.656
738350/758000 (epoch 1948), train_loss = 0.276, time/batch = 0.029, All_Time = 21789.122
738400/758000 (epoch 1948), train_loss = 0.256, time/batch = 0.030, All_Time = 21790.585
738450/758000 (epoch 1948), train_loss = 0.258, time/batch = 0.030, All_Time = 21792.062
738500/758000 (epoch 1948), train_loss = 0.213, time/batch = 0.030, All_Time = 21793.531
738550/758000 (epoch 1948), train_loss = 0.237, time/batch = 0.028, All_Time = 21794.998
738600/758000 (epoch 1948), train_loss = 0.249, time/batch = 0.029, All_Time = 21796.464
738650/758000 (epoch 1948), train_loss = 0.251, time/batch = 0.029, All_Time = 21797.923
738700/758000 (epoch 1949), train_loss = 0.232, time/batch = 0.030, All_Time = 21799.381
738750/758000 (epoch 1949), train_loss = 0.255, time/batch = 0.030, All_Time = 21800.845
738800/758000 (epoch 1949), train_loss = 0.265, time/batch = 0.029, All_Time = 21802.318
738850/758000 (epoch 1949), train_loss = 0.229, time/batch = 0.030, All_Time = 21803.777
738900/758000 (epoch 1949), train_loss = 0.263, time/batch = 0.028, All_Time = 21805.244
738950/758000 (epoch 1949), train_loss = 0.217, time/batch = 0.030, All_Time = 21806.722
739000/758000 (epoch 1949), train_loss = 0.248, time/batch = 0.030, All_Time = 21808.192
model saved to NER/polyglot/model.ckpt
739050/758000 (epoch 1950), train_loss = 0.059, time/batch = 0.029, All_Time = 21809.653
739100/758000 (epoch 1950), train_loss = 0.250, time/batch = 0.030, All_Time = 21811.135
739150/758000 (epoch 1950), train_loss = 0.223, time/batch = 0.029, All_Time = 21812.604
739200/758000 (epoch 1950), train_loss = 0.250, time/batch = 0.030, All_Time = 21814.070
739250/758000 (epoch 1950), train_loss = 0.231, time/batch = 0.030, All_Time = 21815.548
739300/758000 (epoch 1950), train_loss = 0.250, time/batch = 0.031, All_Time = 21817.009
739350/758000 (epoch 1950), train_loss = 0.232, time/batch = 0.031, All_Time = 21818.480
739400/758000 (epoch 1950), train_loss = 0.230, time/batch = 0.030, All_Time = 21819.942
739450/758000 (epoch 1951), train_loss = 0.224, time/batch = 0.030, All_Time = 21821.408
739500/758000 (epoch 1951), train_loss = 0.233, time/batch = 0.030, All_Time = 21822.881
739550/758000 (epoch 1951), train_loss = 0.224, time/batch = 0.028, All_Time = 21824.352
739600/758000 (epoch 1951), train_loss = 0.262, time/batch = 0.029, All_Time = 21825.821
739650/758000 (epoch 1951), train_loss = 0.220, time/batch = 0.030, All_Time = 21827.287
739700/758000 (epoch 1951), train_loss = 0.228, time/batch = 0.029, All_Time = 21828.757
739750/758000 (epoch 1951), train_loss = 0.280, time/batch = 0.030, All_Time = 21830.221
739800/758000 (epoch 1951), train_loss = 0.272, time/batch = 0.031, All_Time = 21831.694
739850/758000 (epoch 1952), train_loss = 0.230, time/batch = 0.028, All_Time = 21833.174
739900/758000 (epoch 1952), train_loss = 0.224, time/batch = 0.029, All_Time = 21834.640
739950/758000 (epoch 1952), train_loss = 0.201, time/batch = 0.030, All_Time = 21836.101
740000/758000 (epoch 1952), train_loss = 0.270, time/batch = 0.030, All_Time = 21837.568
model saved to NER/polyglot/model.ckpt
740050/758000 (epoch 1952), train_loss = 0.259, time/batch = 0.029, All_Time = 21839.042
740100/758000 (epoch 1952), train_loss = 0.209, time/batch = 0.031, All_Time = 21840.508
740150/758000 (epoch 1952), train_loss = 0.218, time/batch = 0.028, All_Time = 21841.968
740200/758000 (epoch 1953), train_loss = 0.229, time/batch = 0.030, All_Time = 21843.437
740250/758000 (epoch 1953), train_loss = 0.283, time/batch = 0.031, All_Time = 21844.913
740300/758000 (epoch 1953), train_loss = 0.231, time/batch = 0.031, All_Time = 21846.376
740350/758000 (epoch 1953), train_loss = 0.307, time/batch = 0.028, All_Time = 21847.842
740400/758000 (epoch 1953), train_loss = 0.221, time/batch = 0.030, All_Time = 21849.315
740450/758000 (epoch 1953), train_loss = 0.208, time/batch = 0.029, All_Time = 21850.779
740500/758000 (epoch 1953), train_loss = 0.247, time/batch = 0.030, All_Time = 21852.248
740550/758000 (epoch 1953), train_loss = 0.252, time/batch = 0.028, All_Time = 21853.721
740600/758000 (epoch 1954), train_loss = 0.264, time/batch = 0.029, All_Time = 21855.208
740650/758000 (epoch 1954), train_loss = 0.229, time/batch = 0.030, All_Time = 21856.675
740700/758000 (epoch 1954), train_loss = 0.242, time/batch = 0.030, All_Time = 21858.136
740750/758000 (epoch 1954), train_loss = 0.267, time/batch = 0.028, All_Time = 21859.600
740800/758000 (epoch 1954), train_loss = 0.249, time/batch = 0.031, All_Time = 21861.065
740850/758000 (epoch 1954), train_loss = 0.237, time/batch = 0.028, All_Time = 21862.530
740900/758000 (epoch 1954), train_loss = 0.276, time/batch = 0.029, All_Time = 21863.989
740950/758000 (epoch 1955), train_loss = 0.256, time/batch = 0.028, All_Time = 21865.460
741000/758000 (epoch 1955), train_loss = 0.222, time/batch = 0.028, All_Time = 21866.920
model saved to NER/polyglot/model.ckpt
741050/758000 (epoch 1955), train_loss = 0.266, time/batch = 0.030, All_Time = 21868.388
741100/758000 (epoch 1955), train_loss = 0.216, time/batch = 0.029, All_Time = 21869.856
741150/758000 (epoch 1955), train_loss = 0.223, time/batch = 0.030, All_Time = 21871.322
741200/758000 (epoch 1955), train_loss = 0.261, time/batch = 0.030, All_Time = 21872.783
741250/758000 (epoch 1955), train_loss = 0.238, time/batch = 0.030, All_Time = 21874.246
741300/758000 (epoch 1955), train_loss = 0.264, time/batch = 0.029, All_Time = 21875.710
741350/758000 (epoch 1956), train_loss = 0.223, time/batch = 0.027, All_Time = 21877.182
741400/758000 (epoch 1956), train_loss = 0.231, time/batch = 0.029, All_Time = 21878.646
741450/758000 (epoch 1956), train_loss = 0.238, time/batch = 0.029, All_Time = 21880.121
741500/758000 (epoch 1956), train_loss = 0.266, time/batch = 0.029, All_Time = 21881.590
741550/758000 (epoch 1956), train_loss = 0.239, time/batch = 0.029, All_Time = 21883.053
741600/758000 (epoch 1956), train_loss = 0.226, time/batch = 0.030, All_Time = 21884.530
741650/758000 (epoch 1956), train_loss = 0.276, time/batch = 0.029, All_Time = 21885.999
741700/758000 (epoch 1956), train_loss = 0.240, time/batch = 0.030, All_Time = 21887.467
741750/758000 (epoch 1957), train_loss = 0.281, time/batch = 0.030, All_Time = 21888.950
741800/758000 (epoch 1957), train_loss = 0.257, time/batch = 0.029, All_Time = 21890.422
741850/758000 (epoch 1957), train_loss = 0.240, time/batch = 0.029, All_Time = 21891.889
741900/758000 (epoch 1957), train_loss = 0.231, time/batch = 0.028, All_Time = 21893.352
741950/758000 (epoch 1957), train_loss = 0.217, time/batch = 0.029, All_Time = 21894.821
742000/758000 (epoch 1957), train_loss = 0.224, time/batch = 0.028, All_Time = 21896.285
model saved to NER/polyglot/model.ckpt
742050/758000 (epoch 1957), train_loss = 0.215, time/batch = 0.030, All_Time = 21897.758
742100/758000 (epoch 1958), train_loss = 0.249, time/batch = 0.029, All_Time = 21899.212
742150/758000 (epoch 1958), train_loss = 0.211, time/batch = 0.030, All_Time = 21900.685
742200/758000 (epoch 1958), train_loss = 0.245, time/batch = 0.028, All_Time = 21902.146
742250/758000 (epoch 1958), train_loss = 0.217, time/batch = 0.030, All_Time = 21903.610
742300/758000 (epoch 1958), train_loss = 0.233, time/batch = 0.029, All_Time = 21905.077
742350/758000 (epoch 1958), train_loss = 0.228, time/batch = 0.030, All_Time = 21906.543
742400/758000 (epoch 1958), train_loss = 0.248, time/batch = 0.030, All_Time = 21908.016
742450/758000 (epoch 1958), train_loss = 0.229, time/batch = 0.029, All_Time = 21909.486
742500/758000 (epoch 1959), train_loss = 0.218, time/batch = 0.029, All_Time = 21910.956
742550/758000 (epoch 1959), train_loss = 0.237, time/batch = 0.029, All_Time = 21912.426
742600/758000 (epoch 1959), train_loss = 0.212, time/batch = 0.029, All_Time = 21913.878
742650/758000 (epoch 1959), train_loss = 0.266, time/batch = 0.029, All_Time = 21915.349
742700/758000 (epoch 1959), train_loss = 0.255, time/batch = 0.029, All_Time = 21916.804
742750/758000 (epoch 1959), train_loss = 0.232, time/batch = 0.029, All_Time = 21918.270
742800/758000 (epoch 1959), train_loss = 0.262, time/batch = 0.031, All_Time = 21919.752
742850/758000 (epoch 1960), train_loss = 0.282, time/batch = 0.029, All_Time = 21921.214
742900/758000 (epoch 1960), train_loss = 0.292, time/batch = 0.029, All_Time = 21922.683
742950/758000 (epoch 1960), train_loss = 0.253, time/batch = 0.029, All_Time = 21924.144
743000/758000 (epoch 1960), train_loss = 0.222, time/batch = 0.029, All_Time = 21925.607
model saved to NER/polyglot/model.ckpt
743050/758000 (epoch 1960), train_loss = 0.221, time/batch = 0.029, All_Time = 21927.080
743100/758000 (epoch 1960), train_loss = 0.260, time/batch = 0.029, All_Time = 21928.541
743150/758000 (epoch 1960), train_loss = 0.244, time/batch = 0.030, All_Time = 21930.006
743200/758000 (epoch 1960), train_loss = 0.247, time/batch = 0.029, All_Time = 21931.477
743250/758000 (epoch 1961), train_loss = 0.210, time/batch = 0.030, All_Time = 21932.947
743300/758000 (epoch 1961), train_loss = 0.265, time/batch = 0.030, All_Time = 21934.420
743350/758000 (epoch 1961), train_loss = 0.229, time/batch = 0.029, All_Time = 21935.894
743400/758000 (epoch 1961), train_loss = 0.232, time/batch = 0.030, All_Time = 21937.356
743450/758000 (epoch 1961), train_loss = 0.230, time/batch = 0.031, All_Time = 21938.823
743500/758000 (epoch 1961), train_loss = 0.253, time/batch = 0.030, All_Time = 21940.301
743550/758000 (epoch 1961), train_loss = 0.258, time/batch = 0.029, All_Time = 21941.765
743600/758000 (epoch 1962), train_loss = 0.196, time/batch = 0.029, All_Time = 21943.222
743650/758000 (epoch 1962), train_loss = 0.254, time/batch = 0.029, All_Time = 21944.695
743700/758000 (epoch 1962), train_loss = 0.281, time/batch = 0.030, All_Time = 21946.165
743750/758000 (epoch 1962), train_loss = 0.235, time/batch = 0.031, All_Time = 21947.641
743800/758000 (epoch 1962), train_loss = 0.247, time/batch = 0.029, All_Time = 21949.107
743850/758000 (epoch 1962), train_loss = 0.251, time/batch = 0.030, All_Time = 21950.563
743900/758000 (epoch 1962), train_loss = 0.203, time/batch = 0.030, All_Time = 21952.025
743950/758000 (epoch 1962), train_loss = 0.268, time/batch = 0.028, All_Time = 21953.490
744000/758000 (epoch 1963), train_loss = 0.233, time/batch = 0.030, All_Time = 21954.954
model saved to NER/polyglot/model.ckpt
744050/758000 (epoch 1963), train_loss = 0.241, time/batch = 0.028, All_Time = 21956.428
744100/758000 (epoch 1963), train_loss = 0.252, time/batch = 0.028, All_Time = 21957.888
744150/758000 (epoch 1963), train_loss = 0.258, time/batch = 0.029, All_Time = 21959.351
744200/758000 (epoch 1963), train_loss = 0.243, time/batch = 0.030, All_Time = 21960.818
744250/758000 (epoch 1963), train_loss = 0.243, time/batch = 0.030, All_Time = 21962.285
744300/758000 (epoch 1963), train_loss = 0.244, time/batch = 0.032, All_Time = 21963.752
744350/758000 (epoch 1963), train_loss = 0.286, time/batch = 0.029, All_Time = 21965.217
744400/758000 (epoch 1964), train_loss = 0.207, time/batch = 0.031, All_Time = 21966.688
744450/758000 (epoch 1964), train_loss = 0.244, time/batch = 0.029, All_Time = 21968.145
744500/758000 (epoch 1964), train_loss = 0.217, time/batch = 0.031, All_Time = 21969.617
744550/758000 (epoch 1964), train_loss = 0.233, time/batch = 0.029, All_Time = 21971.085
744600/758000 (epoch 1964), train_loss = 0.260, time/batch = 0.028, All_Time = 21972.554
744650/758000 (epoch 1964), train_loss = 0.253, time/batch = 0.031, All_Time = 21974.023
744700/758000 (epoch 1964), train_loss = 0.238, time/batch = 0.030, All_Time = 21975.489
744750/758000 (epoch 1965), train_loss = 0.227, time/batch = 0.029, All_Time = 21976.963
744800/758000 (epoch 1965), train_loss = 0.250, time/batch = 0.029, All_Time = 21978.437
744850/758000 (epoch 1965), train_loss = 0.250, time/batch = 0.028, All_Time = 21979.902
744900/758000 (epoch 1965), train_loss = 0.223, time/batch = 0.029, All_Time = 21981.370
744950/758000 (epoch 1965), train_loss = 0.240, time/batch = 0.029, All_Time = 21982.841
745000/758000 (epoch 1965), train_loss = 0.246, time/batch = 0.030, All_Time = 21984.303
model saved to NER/polyglot/model.ckpt
745050/758000 (epoch 1965), train_loss = 0.246, time/batch = 0.031, All_Time = 21985.767
745100/758000 (epoch 1965), train_loss = 0.257, time/batch = 0.031, All_Time = 21987.237
745150/758000 (epoch 1966), train_loss = 0.266, time/batch = 0.030, All_Time = 21988.708
745200/758000 (epoch 1966), train_loss = 0.224, time/batch = 0.029, All_Time = 21990.169
745250/758000 (epoch 1966), train_loss = 0.248, time/batch = 0.029, All_Time = 21991.643
745300/758000 (epoch 1966), train_loss = 0.227, time/batch = 0.029, All_Time = 21993.119
745350/758000 (epoch 1966), train_loss = 0.279, time/batch = 0.029, All_Time = 21994.578
745400/758000 (epoch 1966), train_loss = 0.255, time/batch = 0.030, All_Time = 21996.057
745450/758000 (epoch 1966), train_loss = 0.253, time/batch = 0.028, All_Time = 21997.511
745500/758000 (epoch 1967), train_loss = 0.244, time/batch = 0.030, All_Time = 21998.982
745550/758000 (epoch 1967), train_loss = 0.247, time/batch = 0.029, All_Time = 22000.452
745600/758000 (epoch 1967), train_loss = 0.270, time/batch = 0.029, All_Time = 22001.918
745650/758000 (epoch 1967), train_loss = 0.246, time/batch = 0.029, All_Time = 22003.384
745700/758000 (epoch 1967), train_loss = 0.237, time/batch = 0.029, All_Time = 22004.851
745750/758000 (epoch 1967), train_loss = 0.224, time/batch = 0.031, All_Time = 22006.319
745800/758000 (epoch 1967), train_loss = 0.229, time/batch = 0.028, All_Time = 22007.785
745850/758000 (epoch 1967), train_loss = 0.246, time/batch = 0.028, All_Time = 22009.249
745900/758000 (epoch 1968), train_loss = 0.249, time/batch = 0.030, All_Time = 22010.724
745950/758000 (epoch 1968), train_loss = 0.264, time/batch = 0.029, All_Time = 22012.181
746000/758000 (epoch 1968), train_loss = 0.240, time/batch = 0.029, All_Time = 22013.642
model saved to NER/polyglot/model.ckpt
746050/758000 (epoch 1968), train_loss = 0.250, time/batch = 0.029, All_Time = 22015.111
746100/758000 (epoch 1968), train_loss = 0.227, time/batch = 0.031, All_Time = 22016.571
746150/758000 (epoch 1968), train_loss = 0.217, time/batch = 0.030, All_Time = 22018.033
746200/758000 (epoch 1968), train_loss = 0.277, time/batch = 0.029, All_Time = 22019.497
746250/758000 (epoch 1968), train_loss = 0.259, time/batch = 0.029, All_Time = 22020.965
746300/758000 (epoch 1969), train_loss = 0.269, time/batch = 0.029, All_Time = 22022.439
746350/758000 (epoch 1969), train_loss = 0.296, time/batch = 0.028, All_Time = 22023.900
746400/758000 (epoch 1969), train_loss = 0.228, time/batch = 0.028, All_Time = 22025.368
746450/758000 (epoch 1969), train_loss = 0.220, time/batch = 0.029, All_Time = 22026.832
746500/758000 (epoch 1969), train_loss = 0.257, time/batch = 0.031, All_Time = 22028.297
746550/758000 (epoch 1969), train_loss = 0.255, time/batch = 0.030, All_Time = 22029.755
746600/758000 (epoch 1969), train_loss = 0.237, time/batch = 0.030, All_Time = 22031.228
746650/758000 (epoch 1970), train_loss = 0.225, time/batch = 0.029, All_Time = 22032.691
746700/758000 (epoch 1970), train_loss = 0.234, time/batch = 0.029, All_Time = 22034.163
746750/758000 (epoch 1970), train_loss = 0.243, time/batch = 0.029, All_Time = 22035.628
746800/758000 (epoch 1970), train_loss = 0.234, time/batch = 0.029, All_Time = 22037.097
746850/758000 (epoch 1970), train_loss = 0.223, time/batch = 0.030, All_Time = 22038.577
746900/758000 (epoch 1970), train_loss = 0.239, time/batch = 0.029, All_Time = 22040.042
746950/758000 (epoch 1970), train_loss = 0.264, time/batch = 0.030, All_Time = 22041.510
747000/758000 (epoch 1970), train_loss = 0.244, time/batch = 0.030, All_Time = 22042.987
model saved to NER/polyglot/model.ckpt
747050/758000 (epoch 1971), train_loss = 0.257, time/batch = 0.029, All_Time = 22044.457
747100/758000 (epoch 1971), train_loss = 0.287, time/batch = 0.027, All_Time = 22045.916
747150/758000 (epoch 1971), train_loss = 0.255, time/batch = 0.029, All_Time = 22047.380
747200/758000 (epoch 1971), train_loss = 0.248, time/batch = 0.030, All_Time = 22048.845
747250/758000 (epoch 1971), train_loss = 0.212, time/batch = 0.029, All_Time = 22050.310
747300/758000 (epoch 1971), train_loss = 0.229, time/batch = 0.028, All_Time = 22051.772
747350/758000 (epoch 1971), train_loss = 0.272, time/batch = 0.029, All_Time = 22053.228
747400/758000 (epoch 1972), train_loss = 0.249, time/batch = 0.030, All_Time = 22054.690
747450/758000 (epoch 1972), train_loss = 0.227, time/batch = 0.031, All_Time = 22056.149
747500/758000 (epoch 1972), train_loss = 0.267, time/batch = 0.028, All_Time = 22057.611
747550/758000 (epoch 1972), train_loss = 0.239, time/batch = 0.030, All_Time = 22059.079
747600/758000 (epoch 1972), train_loss = 0.247, time/batch = 0.028, All_Time = 22060.531
747650/758000 (epoch 1972), train_loss = 0.241, time/batch = 0.030, All_Time = 22062.000
747700/758000 (epoch 1972), train_loss = 0.274, time/batch = 0.029, All_Time = 22063.462
747750/758000 (epoch 1972), train_loss = 0.279, time/batch = 0.030, All_Time = 22064.943
747800/758000 (epoch 1973), train_loss = 0.238, time/batch = 0.030, All_Time = 22066.418
747850/758000 (epoch 1973), train_loss = 0.248, time/batch = 0.029, All_Time = 22067.885
747900/758000 (epoch 1973), train_loss = 0.299, time/batch = 0.030, All_Time = 22069.363
747950/758000 (epoch 1973), train_loss = 0.230, time/batch = 0.030, All_Time = 22070.819
748000/758000 (epoch 1973), train_loss = 0.216, time/batch = 0.028, All_Time = 22072.285
model saved to NER/polyglot/model.ckpt
748050/758000 (epoch 1973), train_loss = 0.244, time/batch = 0.030, All_Time = 22073.883
748100/758000 (epoch 1973), train_loss = 0.274, time/batch = 0.029, All_Time = 22075.367
748150/758000 (epoch 1974), train_loss = 0.221, time/batch = 0.030, All_Time = 22076.833
748200/758000 (epoch 1974), train_loss = 0.257, time/batch = 0.030, All_Time = 22078.295
748250/758000 (epoch 1974), train_loss = 0.241, time/batch = 0.029, All_Time = 22079.754
748300/758000 (epoch 1974), train_loss = 0.240, time/batch = 0.031, All_Time = 22081.224
748350/758000 (epoch 1974), train_loss = 0.256, time/batch = 0.029, All_Time = 22082.697
748400/758000 (epoch 1974), train_loss = 0.219, time/batch = 0.031, All_Time = 22084.178
748450/758000 (epoch 1974), train_loss = 0.224, time/batch = 0.030, All_Time = 22085.647
748500/758000 (epoch 1974), train_loss = 0.257, time/batch = 0.030, All_Time = 22087.108
748550/758000 (epoch 1975), train_loss = 0.255, time/batch = 0.028, All_Time = 22088.576
748600/758000 (epoch 1975), train_loss = 0.267, time/batch = 0.030, All_Time = 22090.034
748650/758000 (epoch 1975), train_loss = 0.269, time/batch = 0.029, All_Time = 22091.507
748700/758000 (epoch 1975), train_loss = 0.228, time/batch = 0.029, All_Time = 22092.981
748750/758000 (epoch 1975), train_loss = 0.234, time/batch = 0.029, All_Time = 22094.437
748800/758000 (epoch 1975), train_loss = 0.245, time/batch = 0.029, All_Time = 22095.904
748850/758000 (epoch 1975), train_loss = 0.279, time/batch = 0.030, All_Time = 22097.361
748900/758000 (epoch 1975), train_loss = 0.240, time/batch = 0.029, All_Time = 22098.839
748950/758000 (epoch 1976), train_loss = 0.236, time/batch = 0.028, All_Time = 22100.311
749000/758000 (epoch 1976), train_loss = 0.234, time/batch = 0.030, All_Time = 22101.789
model saved to NER/polyglot/model.ckpt
749050/758000 (epoch 1976), train_loss = 0.233, time/batch = 0.030, All_Time = 22103.260
749100/758000 (epoch 1976), train_loss = 0.276, time/batch = 0.028, All_Time = 22104.725
749150/758000 (epoch 1976), train_loss = 0.206, time/batch = 0.030, All_Time = 22106.190
749200/758000 (epoch 1976), train_loss = 0.259, time/batch = 0.029, All_Time = 22107.662
749250/758000 (epoch 1976), train_loss = 0.234, time/batch = 0.029, All_Time = 22109.127
749300/758000 (epoch 1977), train_loss = 0.245, time/batch = 0.030, All_Time = 22110.599
749350/758000 (epoch 1977), train_loss = 0.223, time/batch = 0.030, All_Time = 22112.069
749400/758000 (epoch 1977), train_loss = 0.240, time/batch = 0.029, All_Time = 22113.536
749450/758000 (epoch 1977), train_loss = 0.256, time/batch = 0.029, All_Time = 22115.000
749500/758000 (epoch 1977), train_loss = 0.214, time/batch = 0.029, All_Time = 22116.457
749550/758000 (epoch 1977), train_loss = 0.272, time/batch = 0.028, All_Time = 22117.931
749600/758000 (epoch 1977), train_loss = 0.213, time/batch = 0.030, All_Time = 22119.489
749650/758000 (epoch 1977), train_loss = 0.251, time/batch = 0.029, All_Time = 22120.955
749700/758000 (epoch 1978), train_loss = 0.247, time/batch = 0.031, All_Time = 22122.429
749750/758000 (epoch 1978), train_loss = 0.229, time/batch = 0.028, All_Time = 22123.900
749800/758000 (epoch 1978), train_loss = 0.217, time/batch = 0.029, All_Time = 22125.361
749850/758000 (epoch 1978), train_loss = 0.220, time/batch = 0.030, All_Time = 22126.819
749900/758000 (epoch 1978), train_loss = 0.250, time/batch = 0.028, All_Time = 22128.274
749950/758000 (epoch 1978), train_loss = 0.207, time/batch = 0.030, All_Time = 22129.739
750000/758000 (epoch 1978), train_loss = 0.268, time/batch = 0.029, All_Time = 22131.207
model saved to NER/polyglot/model.ckpt
750050/758000 (epoch 1979), train_loss = 0.256, time/batch = 0.029, All_Time = 22132.684
750100/758000 (epoch 1979), train_loss = 0.264, time/batch = 0.030, All_Time = 22134.153
750150/758000 (epoch 1979), train_loss = 0.284, time/batch = 0.030, All_Time = 22135.619
750200/758000 (epoch 1979), train_loss = 0.239, time/batch = 0.029, All_Time = 22137.086
750250/758000 (epoch 1979), train_loss = 0.267, time/batch = 0.028, All_Time = 22138.550
750300/758000 (epoch 1979), train_loss = 0.256, time/batch = 0.028, All_Time = 22140.012
750350/758000 (epoch 1979), train_loss = 0.236, time/batch = 0.030, All_Time = 22141.477
750400/758000 (epoch 1979), train_loss = 0.268, time/batch = 0.030, All_Time = 22142.949
750450/758000 (epoch 1980), train_loss = 0.226, time/batch = 0.030, All_Time = 22144.417
750500/758000 (epoch 1980), train_loss = 0.222, time/batch = 0.028, All_Time = 22145.881
750550/758000 (epoch 1980), train_loss = 0.261, time/batch = 0.029, All_Time = 22147.348
750600/758000 (epoch 1980), train_loss = 0.254, time/batch = 0.029, All_Time = 22148.813
750650/758000 (epoch 1980), train_loss = 0.223, time/batch = 0.030, All_Time = 22150.292
750700/758000 (epoch 1980), train_loss = 0.242, time/batch = 0.030, All_Time = 22151.759
750750/758000 (epoch 1980), train_loss = 0.251, time/batch = 0.031, All_Time = 22153.232
750800/758000 (epoch 1981), train_loss = 0.192, time/batch = 0.030, All_Time = 22154.704
750850/758000 (epoch 1981), train_loss = 0.273, time/batch = 0.028, All_Time = 22156.173
750900/758000 (epoch 1981), train_loss = 0.217, time/batch = 0.029, All_Time = 22157.634
750950/758000 (epoch 1981), train_loss = 0.240, time/batch = 0.029, All_Time = 22159.116
751000/758000 (epoch 1981), train_loss = 0.221, time/batch = 0.028, All_Time = 22160.588
model saved to NER/polyglot/model.ckpt
751050/758000 (epoch 1981), train_loss = 0.221, time/batch = 0.030, All_Time = 22162.061
751100/758000 (epoch 1981), train_loss = 0.252, time/batch = 0.030, All_Time = 22163.521
751150/758000 (epoch 1981), train_loss = 0.272, time/batch = 0.028, All_Time = 22164.981
751200/758000 (epoch 1982), train_loss = 0.222, time/batch = 0.029, All_Time = 22166.448
751250/758000 (epoch 1982), train_loss = 0.279, time/batch = 0.029, All_Time = 22167.904
751300/758000 (epoch 1982), train_loss = 0.242, time/batch = 0.029, All_Time = 22169.376
751350/758000 (epoch 1982), train_loss = 0.274, time/batch = 0.031, All_Time = 22170.840
751400/758000 (epoch 1982), train_loss = 0.262, time/batch = 0.030, All_Time = 22172.306
751450/758000 (epoch 1982), train_loss = 0.197, time/batch = 0.028, All_Time = 22173.766
751500/758000 (epoch 1982), train_loss = 0.233, time/batch = 0.030, All_Time = 22175.238
751550/758000 (epoch 1982), train_loss = 0.281, time/batch = 0.031, All_Time = 22176.707
751600/758000 (epoch 1983), train_loss = 0.246, time/batch = 0.029, All_Time = 22178.173
751650/758000 (epoch 1983), train_loss = 0.212, time/batch = 0.028, All_Time = 22179.640
751700/758000 (epoch 1983), train_loss = 0.255, time/batch = 0.029, All_Time = 22181.101
751750/758000 (epoch 1983), train_loss = 0.271, time/batch = 0.029, All_Time = 22182.557
751800/758000 (epoch 1983), train_loss = 0.203, time/batch = 0.029, All_Time = 22184.021
751850/758000 (epoch 1983), train_loss = 0.226, time/batch = 0.031, All_Time = 22185.493
751900/758000 (epoch 1983), train_loss = 0.254, time/batch = 0.030, All_Time = 22186.952
751950/758000 (epoch 1984), train_loss = 0.219, time/batch = 0.029, All_Time = 22188.416
752000/758000 (epoch 1984), train_loss = 0.265, time/batch = 0.029, All_Time = 22189.884
model saved to NER/polyglot/model.ckpt
752050/758000 (epoch 1984), train_loss = 0.227, time/batch = 0.031, All_Time = 22191.357
752100/758000 (epoch 1984), train_loss = 0.213, time/batch = 0.030, All_Time = 22192.826
752150/758000 (epoch 1984), train_loss = 0.224, time/batch = 0.029, All_Time = 22194.289
752200/758000 (epoch 1984), train_loss = 0.213, time/batch = 0.029, All_Time = 22195.750
752250/758000 (epoch 1984), train_loss = 0.230, time/batch = 0.029, All_Time = 22197.216
752300/758000 (epoch 1984), train_loss = 0.223, time/batch = 0.028, All_Time = 22198.679
752350/758000 (epoch 1985), train_loss = 0.275, time/batch = 0.029, All_Time = 22200.149
752400/758000 (epoch 1985), train_loss = 0.229, time/batch = 0.029, All_Time = 22201.612
752450/758000 (epoch 1985), train_loss = 0.270, time/batch = 0.028, All_Time = 22203.075
752500/758000 (epoch 1985), train_loss = 0.273, time/batch = 0.030, All_Time = 22204.532
752550/758000 (epoch 1985), train_loss = 0.233, time/batch = 0.029, All_Time = 22206.005
752600/758000 (epoch 1985), train_loss = 0.268, time/batch = 0.028, All_Time = 22207.470
752650/758000 (epoch 1985), train_loss = 0.280, time/batch = 0.029, All_Time = 22208.936
752700/758000 (epoch 1986), train_loss = 0.239, time/batch = 0.030, All_Time = 22210.400
752750/758000 (epoch 1986), train_loss = 0.218, time/batch = 0.029, All_Time = 22211.871
752800/758000 (epoch 1986), train_loss = 0.243, time/batch = 0.029, All_Time = 22213.333
752850/758000 (epoch 1986), train_loss = 0.244, time/batch = 0.029, All_Time = 22214.800
752900/758000 (epoch 1986), train_loss = 0.243, time/batch = 0.030, All_Time = 22216.267
752950/758000 (epoch 1986), train_loss = 0.244, time/batch = 0.029, All_Time = 22217.729
753000/758000 (epoch 1986), train_loss = 0.213, time/batch = 0.029, All_Time = 22219.196
model saved to NER/polyglot/model.ckpt
753050/758000 (epoch 1986), train_loss = 0.289, time/batch = 0.029, All_Time = 22220.661
753100/758000 (epoch 1987), train_loss = 0.237, time/batch = 0.029, All_Time = 22222.112
753150/758000 (epoch 1987), train_loss = 0.246, time/batch = 0.031, All_Time = 22223.593
753200/758000 (epoch 1987), train_loss = 0.288, time/batch = 0.030, All_Time = 22225.064
753250/758000 (epoch 1987), train_loss = 0.257, time/batch = 0.029, All_Time = 22226.530
753300/758000 (epoch 1987), train_loss = 0.218, time/batch = 0.030, All_Time = 22228.000
753350/758000 (epoch 1987), train_loss = 0.238, time/batch = 0.028, All_Time = 22229.470
753400/758000 (epoch 1987), train_loss = 0.251, time/batch = 0.028, All_Time = 22230.940
753450/758000 (epoch 1987), train_loss = 0.251, time/batch = 0.030, All_Time = 22232.413
753500/758000 (epoch 1988), train_loss = 0.252, time/batch = 0.030, All_Time = 22233.886
753550/758000 (epoch 1988), train_loss = 0.280, time/batch = 0.029, All_Time = 22235.351
753600/758000 (epoch 1988), train_loss = 0.242, time/batch = 0.028, All_Time = 22236.816
753650/758000 (epoch 1988), train_loss = 0.250, time/batch = 0.029, All_Time = 22238.285
753700/758000 (epoch 1988), train_loss = 0.239, time/batch = 0.029, All_Time = 22239.756
753750/758000 (epoch 1988), train_loss = 0.239, time/batch = 0.029, All_Time = 22241.225
753800/758000 (epoch 1988), train_loss = 0.250, time/batch = 0.030, All_Time = 22242.690
753850/758000 (epoch 1989), train_loss = 0.221, time/batch = 0.029, All_Time = 22244.153
753900/758000 (epoch 1989), train_loss = 0.219, time/batch = 0.028, All_Time = 22245.618
753950/758000 (epoch 1989), train_loss = 0.246, time/batch = 0.030, All_Time = 22247.085
754000/758000 (epoch 1989), train_loss = 0.262, time/batch = 0.030, All_Time = 22248.559
model saved to NER/polyglot/model.ckpt
754050/758000 (epoch 1989), train_loss = 0.260, time/batch = 0.030, All_Time = 22250.028
754100/758000 (epoch 1989), train_loss = 0.241, time/batch = 0.029, All_Time = 22251.492
754150/758000 (epoch 1989), train_loss = 0.210, time/batch = 0.030, All_Time = 22252.957
754200/758000 (epoch 1989), train_loss = 0.239, time/batch = 0.029, All_Time = 22254.431
754250/758000 (epoch 1990), train_loss = 0.230, time/batch = 0.030, All_Time = 22255.907
754300/758000 (epoch 1990), train_loss = 0.226, time/batch = 0.030, All_Time = 22257.370
754350/758000 (epoch 1990), train_loss = 0.264, time/batch = 0.029, All_Time = 22258.828
754400/758000 (epoch 1990), train_loss = 0.240, time/batch = 0.028, All_Time = 22260.282
754450/758000 (epoch 1990), train_loss = 0.253, time/batch = 0.030, All_Time = 22261.750
754500/758000 (epoch 1990), train_loss = 0.251, time/batch = 0.029, All_Time = 22263.224
754550/758000 (epoch 1990), train_loss = 0.248, time/batch = 0.029, All_Time = 22264.678
754600/758000 (epoch 1991), train_loss = 0.216, time/batch = 0.030, All_Time = 22266.143
754650/758000 (epoch 1991), train_loss = 0.233, time/batch = 0.030, All_Time = 22267.608
754700/758000 (epoch 1991), train_loss = 0.250, time/batch = 0.029, All_Time = 22269.081
754750/758000 (epoch 1991), train_loss = 0.241, time/batch = 0.029, All_Time = 22270.551
754800/758000 (epoch 1991), train_loss = 0.243, time/batch = 0.030, All_Time = 22272.024
754850/758000 (epoch 1991), train_loss = 0.242, time/batch = 0.029, All_Time = 22273.491
754900/758000 (epoch 1991), train_loss = 0.230, time/batch = 0.028, All_Time = 22274.952
754950/758000 (epoch 1991), train_loss = 0.259, time/batch = 0.031, All_Time = 22276.414
755000/758000 (epoch 1992), train_loss = 0.250, time/batch = 0.029, All_Time = 22277.880
model saved to NER/polyglot/model.ckpt
755050/758000 (epoch 1992), train_loss = 0.253, time/batch = 0.028, All_Time = 22279.350
755100/758000 (epoch 1992), train_loss = 0.245, time/batch = 0.029, All_Time = 22280.815
755150/758000 (epoch 1992), train_loss = 0.231, time/batch = 0.030, All_Time = 22282.285
755200/758000 (epoch 1992), train_loss = 0.228, time/batch = 0.030, All_Time = 22283.752
755250/758000 (epoch 1992), train_loss = 0.238, time/batch = 0.030, All_Time = 22285.219
755300/758000 (epoch 1992), train_loss = 0.268, time/batch = 0.030, All_Time = 22286.690
755350/758000 (epoch 1993), train_loss = 0.248, time/batch = 0.030, All_Time = 22288.157
755400/758000 (epoch 1993), train_loss = 0.280, time/batch = 0.030, All_Time = 22289.629
755450/758000 (epoch 1993), train_loss = 0.242, time/batch = 0.029, All_Time = 22291.098
755500/758000 (epoch 1993), train_loss = 0.258, time/batch = 0.029, All_Time = 22292.566
755550/758000 (epoch 1993), train_loss = 0.224, time/batch = 0.029, All_Time = 22294.022
755600/758000 (epoch 1993), train_loss = 0.243, time/batch = 0.028, All_Time = 22295.485
755650/758000 (epoch 1993), train_loss = 0.219, time/batch = 0.029, All_Time = 22296.964
755700/758000 (epoch 1993), train_loss = 0.232, time/batch = 0.029, All_Time = 22298.443
755750/758000 (epoch 1994), train_loss = 0.237, time/batch = 0.028, All_Time = 22299.913
755800/758000 (epoch 1994), train_loss = 0.239, time/batch = 0.029, All_Time = 22301.383
755850/758000 (epoch 1994), train_loss = 0.293, time/batch = 0.029, All_Time = 22302.849
755900/758000 (epoch 1994), train_loss = 0.318, time/batch = 0.029, All_Time = 22304.307
755950/758000 (epoch 1994), train_loss = 0.196, time/batch = 0.029, All_Time = 22305.765
756000/758000 (epoch 1994), train_loss = 0.213, time/batch = 0.030, All_Time = 22307.230
model saved to NER/polyglot/model.ckpt
756050/758000 (epoch 1994), train_loss = 0.250, time/batch = 0.029, All_Time = 22308.706
756100/758000 (epoch 1994), train_loss = 0.297, time/batch = 0.028, All_Time = 22310.176
756150/758000 (epoch 1995), train_loss = 0.226, time/batch = 0.030, All_Time = 22311.653
756200/758000 (epoch 1995), train_loss = 0.259, time/batch = 0.028, All_Time = 22313.108
756250/758000 (epoch 1995), train_loss = 0.223, time/batch = 0.030, All_Time = 22314.573
756300/758000 (epoch 1995), train_loss = 0.239, time/batch = 0.030, All_Time = 22316.044
756350/758000 (epoch 1995), train_loss = 0.212, time/batch = 0.030, All_Time = 22317.506
756400/758000 (epoch 1995), train_loss = 0.243, time/batch = 0.029, All_Time = 22318.976
756450/758000 (epoch 1995), train_loss = 0.215, time/batch = 0.029, All_Time = 22320.437
756500/758000 (epoch 1996), train_loss = 0.228, time/batch = 0.030, All_Time = 22321.895
756550/758000 (epoch 1996), train_loss = 0.252, time/batch = 0.028, All_Time = 22323.356
756600/758000 (epoch 1996), train_loss = 0.260, time/batch = 0.029, All_Time = 22324.817
756650/758000 (epoch 1996), train_loss = 0.228, time/batch = 0.028, All_Time = 22326.282
756700/758000 (epoch 1996), train_loss = 0.236, time/batch = 0.029, All_Time = 22327.755
756750/758000 (epoch 1996), train_loss = 0.271, time/batch = 0.029, All_Time = 22329.217
756800/758000 (epoch 1996), train_loss = 0.238, time/batch = 0.031, All_Time = 22330.684
756850/758000 (epoch 1996), train_loss = 0.268, time/batch = 0.030, All_Time = 22332.150
756900/758000 (epoch 1997), train_loss = 0.248, time/batch = 0.030, All_Time = 22333.622
756950/758000 (epoch 1997), train_loss = 0.249, time/batch = 0.030, All_Time = 22335.086
757000/758000 (epoch 1997), train_loss = 0.240, time/batch = 0.031, All_Time = 22336.561
model saved to NER/polyglot/model.ckpt
757050/758000 (epoch 1997), train_loss = 0.247, time/batch = 0.030, All_Time = 22338.028
757100/758000 (epoch 1997), train_loss = 0.235, time/batch = 0.028, All_Time = 22339.499
757150/758000 (epoch 1997), train_loss = 0.247, time/batch = 0.030, All_Time = 22340.967
757200/758000 (epoch 1997), train_loss = 0.251, time/batch = 0.029, All_Time = 22342.431
757250/758000 (epoch 1998), train_loss = 0.242, time/batch = 0.031, All_Time = 22343.912
757300/758000 (epoch 1998), train_loss = 0.276, time/batch = 0.030, All_Time = 22345.389
757350/758000 (epoch 1998), train_loss = 0.256, time/batch = 0.029, All_Time = 22346.853
757400/758000 (epoch 1998), train_loss = 0.258, time/batch = 0.028, All_Time = 22348.316
757450/758000 (epoch 1998), train_loss = 0.213, time/batch = 0.029, All_Time = 22349.773
757500/758000 (epoch 1998), train_loss = 0.237, time/batch = 0.030, All_Time = 22351.242
757550/758000 (epoch 1998), train_loss = 0.249, time/batch = 0.029, All_Time = 22352.712
757600/758000 (epoch 1998), train_loss = 0.251, time/batch = 0.030, All_Time = 22354.186
757650/758000 (epoch 1999), train_loss = 0.232, time/batch = 0.029, All_Time = 22355.651
757700/758000 (epoch 1999), train_loss = 0.255, time/batch = 0.030, All_Time = 22357.111
757750/758000 (epoch 1999), train_loss = 0.265, time/batch = 0.030, All_Time = 22358.579
757800/758000 (epoch 1999), train_loss = 0.229, time/batch = 0.030, All_Time = 22360.057
757850/758000 (epoch 1999), train_loss = 0.263, time/batch = 0.029, All_Time = 22361.533
757900/758000 (epoch 1999), train_loss = 0.217, time/batch = 0.029, All_Time = 22362.985
757950/758000 (epoch 1999), train_loss = 0.248, time/batch = 0.029, All_Time = 22364.451
model saved to NER/polyglot/model.ckpt
